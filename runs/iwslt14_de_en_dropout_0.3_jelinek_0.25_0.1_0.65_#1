Sender: LSF System <lsfadmin@eu-g3-057>
Subject: Job 210595814: <iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 11:39:38 2022
Job was executed on host(s) <eu-g3-057>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 11:40:01 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 11:40:01 2022
Terminated at Wed Mar 23 12:57:52 2022
Results reported at Wed Mar 23 12:57:52 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.25,0.1,0.65\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4661.56 sec.
    Max Memory :                                 5194 MB
    Average Memory :                             3949.89 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14806.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   4671 sec.
    Turnaround time :                            4694 sec.

The output (if any) follows:

2022-03-23 11:40:08 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.25,0.1,0.65)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.25,0.1,0.65)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 11:40:08 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 11:40:08 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 11:40:09 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:40:09 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:40:09 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1125/160239 [00:00<00:14, 11245.72it/s]  2%|▏         | 2444/160239 [00:00<00:12, 12379.69it/s]  2%|▏         | 3832/160239 [00:00<00:11, 13059.94it/s]  3%|▎         | 5154/160239 [00:00<00:11, 13122.94it/s]  4%|▍         | 6467/160239 [00:00<00:11, 12992.85it/s]  5%|▍         | 7767/160239 [00:00<00:11, 12894.05it/s]  6%|▌         | 9057/160239 [00:00<00:11, 12785.21it/s]  6%|▋         | 10409/160239 [00:00<00:11, 13015.66it/s]  7%|▋         | 11713/160239 [00:00<00:11, 13019.89it/s]  8%|▊         | 13020/160239 [00:01<00:11, 13032.72it/s]  9%|▉         | 14324/160239 [00:01<00:11, 12898.90it/s] 10%|▉         | 15615/160239 [00:01<00:11, 12860.75it/s] 11%|█         | 16902/160239 [00:01<00:11, 12651.67it/s] 11%|█▏        | 18193/160239 [00:01<00:11, 12727.46it/s] 12%|█▏        | 19467/160239 [00:01<00:11, 12652.54it/s] 13%|█▎        | 20864/160239 [00:01<00:10, 13042.35it/s] 14%|█▍        | 22170/160239 [00:01<00:10, 12750.34it/s] 15%|█▍        | 23450/160239 [00:01<00:10, 12764.04it/s] 15%|█▌        | 24759/160239 [00:01<00:10, 12857.35it/s] 16%|█▋        | 26046/160239 [00:02<00:10, 12804.85it/s] 17%|█▋        | 27328/160239 [00:02<00:10, 12752.13it/s] 18%|█▊        | 28646/160239 [00:02<00:10, 12876.01it/s] 19%|█▊        | 29935/160239 [00:02<00:10, 12699.28it/s] 19%|█▉        | 31206/160239 [00:02<00:10, 12647.95it/s] 20%|██        | 32577/160239 [00:02<00:09, 12960.15it/s] 21%|██        | 33874/160239 [00:02<00:10, 12585.48it/s] 22%|██▏       | 35136/160239 [00:02<00:10, 12465.96it/s] 23%|██▎       | 36448/160239 [00:02<00:09, 12656.13it/s] 24%|██▎       | 37716/160239 [00:02<00:09, 12643.19it/s] 24%|██▍       | 39023/160239 [00:03<00:09, 12764.45it/s] 25%|██▌       | 40322/160239 [00:03<00:09, 12829.28it/s] 26%|██▌       | 41625/160239 [00:03<00:09, 12888.29it/s] 27%|██▋       | 42915/160239 [00:03<00:09, 12557.62it/s] 28%|██▊       | 44173/160239 [00:03<00:09, 12419.18it/s] 28%|██▊       | 45427/160239 [00:03<00:09, 12453.47it/s] 29%|██▉       | 46774/160239 [00:03<00:08, 12753.10it/s] 30%|███       | 48086/160239 [00:03<00:08, 12857.42it/s] 31%|███       | 49373/160239 [00:03<00:08, 12858.14it/s] 32%|███▏      | 50660/160239 [00:03<00:08, 12730.81it/s] 32%|███▏      | 51941/160239 [00:04<00:08, 12753.14it/s] 33%|███▎      | 53257/160239 [00:04<00:08, 12873.11it/s] 34%|███▍      | 54545/160239 [00:04<00:08, 12854.22it/s] 35%|███▍      | 55831/160239 [00:04<00:08, 12849.83it/s] 36%|███▌      | 57180/160239 [00:04<00:07, 13038.90it/s] 37%|███▋      | 58561/160239 [00:04<00:07, 13266.83it/s] 37%|███▋      | 59888/160239 [00:04<00:07, 13245.09it/s] 38%|███▊      | 61213/160239 [00:04<00:07, 12751.47it/s] 39%|███▉      | 62563/160239 [00:04<00:07, 12969.15it/s] 40%|███▉      | 63874/160239 [00:04<00:07, 13007.11it/s] 41%|████      | 65414/160239 [00:05<00:06, 13713.69it/s] 42%|████▏     | 66789/160239 [00:05<00:06, 13498.02it/s] 43%|████▎     | 68142/160239 [00:05<00:06, 13318.82it/s] 43%|████▎     | 69476/160239 [00:05<00:07, 12793.28it/s] 44%|████▍     | 70799/160239 [00:05<00:06, 12917.46it/s] 45%|████▌     | 72120/160239 [00:05<00:06, 12998.55it/s] 46%|████▌     | 73423/160239 [00:05<00:06, 12778.88it/s] 47%|████▋     | 74704/160239 [00:05<00:06, 12718.79it/s] 47%|████▋     | 75999/160239 [00:05<00:06, 12784.44it/s] 48%|████▊     | 77378/160239 [00:06<00:06, 13076.93it/s] 49%|████▉     | 78704/160239 [00:06<00:06, 13127.64it/s] 50%|████▉     | 80048/160239 [00:06<00:06, 13218.44it/s] 51%|█████     | 81500/160239 [00:06<00:05, 13604.16it/s] 52%|█████▏    | 82862/160239 [00:06<00:05, 13468.92it/s] 53%|█████▎    | 84210/160239 [00:06<00:05, 13184.68it/s] 53%|█████▎    | 85596/160239 [00:06<00:05, 13382.50it/s] 54%|█████▍    | 87000/160239 [00:06<00:05, 13574.85it/s] 55%|█████▌    | 88359/160239 [00:06<00:05, 13298.59it/s] 56%|█████▌    | 89765/160239 [00:06<00:05, 13519.03it/s] 57%|█████▋    | 91119/160239 [00:07<00:05, 13285.17it/s] 58%|█████▊    | 92450/160239 [00:07<00:05, 13253.36it/s] 59%|█████▊    | 93777/160239 [00:07<00:05, 12999.71it/s] 59%|█████▉    | 95079/160239 [00:07<00:05, 12866.62it/s] 60%|██████    | 96409/160239 [00:07<00:04, 12991.52it/s] 61%|██████    | 97720/160239 [00:07<00:04, 13023.44it/s] 62%|██████▏   | 99070/160239 [00:07<00:04, 13163.25it/s] 63%|██████▎   | 100422/160239 [00:07<00:04, 13267.24it/s] 63%|██████▎   | 101750/160239 [00:07<00:04, 13251.53it/s] 64%|██████▍   | 103076/160239 [00:07<00:04, 13014.71it/s] 65%|██████▌   | 104379/160239 [00:08<00:04, 13007.89it/s] 66%|██████▌   | 105694/160239 [00:08<00:04, 13049.32it/s] 67%|██████▋   | 107000/160239 [00:08<00:04, 13021.60it/s] 68%|██████▊   | 108303/160239 [00:08<00:04, 12639.32it/s] 68%|██████▊   | 109585/160239 [00:08<00:03, 12689.98it/s] 69%|██████▉   | 110858/160239 [00:08<00:03, 12700.51it/s] 70%|███████   | 112226/160239 [00:08<00:03, 12989.39it/s] 71%|███████   | 113527/160239 [00:08<00:03, 12992.59it/s] 72%|███████▏  | 114828/160239 [00:08<00:03, 12950.90it/s] 73%|███████▎  | 116180/160239 [00:08<00:03, 13119.63it/s] 73%|███████▎  | 117493/160239 [00:09<00:03, 12863.19it/s] 74%|███████▍  | 118848/160239 [00:09<00:03, 13063.47it/s] 75%|███████▍  | 120179/160239 [00:09<00:03, 13134.47it/s] 76%|███████▌  | 121509/160239 [00:09<00:02, 13180.14it/s] 77%|███████▋  | 122902/160239 [00:09<00:02, 13396.72it/s] 78%|███████▊  | 124243/160239 [00:09<00:02, 13161.31it/s] 78%|███████▊  | 125561/160239 [00:09<00:02, 12858.16it/s] 79%|███████▉  | 126885/160239 [00:09<00:02, 12967.42it/s] 80%|████████  | 128218/160239 [00:09<00:02, 13070.77it/s] 81%|████████  | 129527/160239 [00:09<00:02, 13016.44it/s] 82%|████████▏ | 130830/160239 [00:10<00:02, 12652.87it/s] 82%|████████▏ | 132108/160239 [00:10<00:02, 12689.17it/s] 83%|████████▎ | 133379/160239 [00:10<00:02, 12563.35it/s] 84%|████████▍ | 134662/160239 [00:10<00:02, 12640.45it/s] 85%|████████▍ | 135984/160239 [00:10<00:01, 12805.09it/s] 86%|████████▌ | 137303/160239 [00:10<00:01, 12918.65it/s] 87%|████████▋ | 138668/160239 [00:10<00:01, 13134.65it/s] 87%|████████▋ | 140031/160239 [00:10<00:01, 13281.19it/s] 88%|████████▊ | 141391/160239 [00:10<00:01, 13376.00it/s] 89%|████████▉ | 142730/160239 [00:11<00:01, 13013.91it/s] 90%|████████▉ | 144034/160239 [00:11<00:01, 12997.03it/s] 91%|█████████ | 145336/160239 [00:11<00:01, 12970.93it/s] 92%|█████████▏| 146635/160239 [00:11<00:01, 12721.66it/s] 92%|█████████▏| 147909/160239 [00:11<00:00, 12719.39it/s] 93%|█████████▎| 149183/160239 [00:11<00:00, 12490.08it/s] 94%|█████████▍| 150499/160239 [00:11<00:00, 12685.28it/s] 95%|█████████▍| 151813/160239 [00:11<00:00, 12819.03it/s] 96%|█████████▌| 153097/160239 [00:11<00:00, 12804.67it/s] 96%|█████████▋| 154423/160239 [00:11<00:00, 12938.41it/s] 97%|█████████▋| 155782/160239 [00:12<00:00, 13129.81it/s] 98%|█████████▊| 157140/160239 [00:12<00:00, 13261.61it/s] 99%|█████████▉| 158467/160239 [00:12<00:00, 12784.24it/s]100%|█████████▉| 159798/160239 [00:12<00:00, 12936.20it/s]100%|██████████| 160239/160239 [00:12<00:00, 12943.17it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3915/160239 [00:00<00:03, 39140.89it/s]  5%|▍         | 7830/160239 [00:00<00:03, 39096.71it/s]  7%|▋         | 11797/160239 [00:00<00:03, 39356.21it/s] 10%|▉         | 15755/160239 [00:00<00:03, 39442.05it/s] 12%|█▏        | 19700/160239 [00:00<00:03, 39401.04it/s] 15%|█▍        | 23643/160239 [00:00<00:03, 39407.73it/s] 17%|█▋        | 27584/160239 [00:00<00:03, 39197.76it/s] 20%|█▉        | 31628/160239 [00:00<00:03, 39590.89it/s] 22%|██▏       | 35588/160239 [00:00<00:03, 39193.42it/s] 25%|██▍       | 39578/160239 [00:01<00:03, 39408.58it/s] 27%|██▋       | 43520/160239 [00:01<00:02, 39192.92it/s] 30%|██▉       | 47513/160239 [00:01<00:02, 39414.72it/s] 32%|███▏      | 51483/160239 [00:01<00:02, 39499.80it/s] 35%|███▍      | 55434/160239 [00:01<00:02, 39496.68it/s] 37%|███▋      | 59555/160239 [00:01<00:02, 40010.93it/s] 40%|███▉      | 63557/160239 [00:01<00:02, 39971.10it/s] 42%|████▏     | 67690/160239 [00:01<00:02, 40377.51it/s] 45%|████▍     | 71729/160239 [00:01<00:02, 40072.55it/s] 47%|████▋     | 75737/160239 [00:01<00:02, 39756.02it/s] 50%|████▉     | 79875/160239 [00:02<00:01, 40238.47it/s] 52%|█████▏    | 84032/160239 [00:02<00:01, 40634.50it/s] 55%|█████▌    | 88154/160239 [00:02<00:01, 40807.93it/s] 58%|█████▊    | 92240/160239 [00:02<00:01, 40822.84it/s] 60%|██████    | 96323/160239 [00:02<00:01, 40520.19it/s] 63%|██████▎   | 100396/160239 [00:02<00:01, 40581.71it/s] 65%|██████▌   | 104455/160239 [00:02<00:01, 40423.00it/s] 68%|██████▊   | 108498/160239 [00:02<00:01, 39955.91it/s] 70%|███████   | 112496/160239 [00:02<00:01, 39960.69it/s] 73%|███████▎  | 116493/160239 [00:02<00:01, 39872.19it/s] 75%|███████▌  | 120492/160239 [00:03<00:00, 39903.22it/s] 78%|███████▊  | 124560/160239 [00:03<00:00, 40132.64it/s] 80%|████████  | 128585/160239 [00:03<00:00, 40166.35it/s] 83%|████████▎ | 132602/160239 [00:03<00:00, 39748.92it/s] 85%|████████▌ | 136579/160239 [00:03<00:00, 39232.79it/s] 88%|████████▊ | 140677/160239 [00:03<00:00, 39746.03it/s] 90%|█████████ | 144654/160239 [00:03<00:00, 39659.43it/s] 93%|█████████▎| 148622/160239 [00:03<00:00, 39105.24it/s] 95%|█████████▌| 152599/160239 [00:03<00:00, 39299.26it/s] 98%|█████████▊| 156648/160239 [00:03<00:00, 39651.80it/s]100%|██████████| 160239/160239 [00:04<00:00, 39808.87it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2106.63it/s]2022-03-23 11:40:29 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 11:40:29 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 11:40:29 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 11:40:29 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-23 11:40:29 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 11:40:29 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 11:40:29 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 11:40:29 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 11:40:29 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 11:40:29 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 11:40:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:40:29 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 11:40:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:40:29 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 11:40:29 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 11:40:29 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 11:40:29 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 11:40:29 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 11:40:29 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:40:29 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:40:29 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 11:40:29 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 11:40:29 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 11:40:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 11:40:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 11:40:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 11:40:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 11:41:12 | INFO | train_inner | epoch 001:    104 / 157 loss=13.501, ppl=11590.8, wps=66065.5, ups=2.63, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=2.742, loss_scale=8, train_wall=43, gb_free=12.1, wall=44
2022-03-23 11:41:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:41:35 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 11:41:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:41:38 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 11:41:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:41:41 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 11:41:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:41:44 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 11:41:44 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:41:48 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,
2022-03-23 11:41:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:41:52 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:41:57 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:42:03 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:42:10 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:42:12 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:42:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 13.477 | ppl 11403.9 | bleu 0.02 | wps 4415.2 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 11:42:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 11:42:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:42:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:42:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.02) (writing took 1.6115073738619685 seconds)
2022-03-23 11:42:14 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 11:42:14 | INFO | train | epoch 001 | loss 13.128 | ppl 8954.13 | wps 38392.8 | ups 1.53 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 2.15 | loss_scale 8 | train_wall 62 | gb_free 22.3 | wall 105
KL Stats: Epoch 1 Divergences: Uniform: 0.5222113778466523 Unigram: 1.4553431539304547
2022-03-23 11:42:14 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 11:42:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:42:32 | INFO | train_inner | epoch 002:     47 / 157 loss=12.124, ppl=4462.32, wps=31742, ups=1.25, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=0.948, loss_scale=8, train_wall=37, gb_free=12.9, wall=123
2022-03-23 11:43:10 | INFO | train_inner | epoch 002:    147 / 157 loss=11.779, ppl=3514.74, wps=66367.8, ups=2.64, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=0.962, loss_scale=8, train_wall=38, gb_free=12.2, wall=161
2022-03-23 11:43:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:43:17 | INFO | fairseq.tasks.translation | example hypothesis: we we.
2022-03-23 11:43:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:43:20 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the.
2022-03-23 11:43:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:43:23 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the.
2022-03-23 11:43:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:43:27 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,.
2022-03-23 11:43:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:43:32 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:43:32 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:43:36 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 11:43:36 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:43:41 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:43:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:43:46 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:43:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:43:52 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:43:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:43:54 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:43:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:43:54 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 12.874 | ppl 7508.4 | bleu 0.03 | wps 4407.5 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.03
2022-03-23 11:43:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 11:43:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:43:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:43:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.03) (writing took 1.7310477402061224 seconds)
2022-03-23 11:43:56 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 11:43:56 | INFO | train | epoch 002 | loss 11.797 | ppl 3557.8 | wps 38863.3 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.923 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 207
KL Stats: Epoch 2 Divergences: Uniform: 0.5704145271245439 Unigram: 0.417986086162875
2022-03-23 11:43:56 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 11:43:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:44:30 | INFO | train_inner | epoch 003:     90 / 157 loss=11.568, ppl=3036.79, wps=30854.9, ups=1.26, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=0.788, loss_scale=8, train_wall=36, gb_free=11.8, wall=241
2022-03-23 11:44:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:44:58 | INFO | fairseq.tasks.translation | example hypothesis: we.
2022-03-23 11:44:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:45:02 | INFO | fairseq.tasks.translation | example hypothesis: it's's.
2022-03-23 11:45:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:45:05 | INFO | fairseq.tasks.translation | example hypothesis: and the the.
2022-03-23 11:45:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:45:08 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's.
2022-03-23 11:45:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:45:12 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, it's's, it's's's's.
2022-03-23 11:45:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:45:17 | INFO | fairseq.tasks.translation | example hypothesis: and the, and the, and the the, and the the the the the the the of the of the the the the the the the the the the the the the the the.
2022-03-23 11:45:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:45:22 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's, it's's, it's's, it's's's's's's's, and the the the the the the the, and it's, it's's, and it's's's, and it's's's's's's's's's's, and it's's's's's's's
2022-03-23 11:45:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:45:28 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, and we the the the the the the the the, and the the, and the the, and the the, and the the the the the the the the the the, and the the the the the, and the the the, and the the the the the the the the the the the the, and the the the, and the the the, and the the the the, and the the the the the the the, and the the
2022-03-23 11:45:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:45:35 | INFO | fairseq.tasks.translation | example hypothesis: and the, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:45:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:45:38 | INFO | fairseq.tasks.translation | example hypothesis: and the, we, we, we, we, we, we, we, we, the the the the the, the the the the the the the the the the the the the the the the, the the the the the the the the the the the the the the the the the the, the the the the the the the the the the the the the the the the the the the the the the the the, the the the the the the the the the the the the the the, and the the the the the the the the the, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the, and the to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to,
2022-03-23 11:45:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:45:38 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.722 | ppl 6758.07 | bleu 0.24 | wps 4161.8 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.24
2022-03-23 11:45:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 11:45:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:45:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:45:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.24) (writing took 1.7052752361632884 seconds)
2022-03-23 11:45:39 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 11:45:39 | INFO | train | epoch 003 | loss 11.465 | ppl 2827.62 | wps 38063 | ups 1.51 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.926 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 311
KL Stats: Epoch 3 Divergences: Uniform: 0.6765768668559011 Unigram: 0.36843406832398584
2022-03-23 11:45:40 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 11:45:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:45:53 | INFO | train_inner | epoch 004:     33 / 157 loss=11.363, ppl=2633.72, wps=30754.4, ups=1.21, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.052, loss_scale=8, train_wall=37, gb_free=12, wall=324
2022-03-23 11:46:30 | INFO | train_inner | epoch 004:    133 / 157 loss=11.248, ppl=2432.37, wps=67122.8, ups=2.66, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.1, loss_scale=8, train_wall=37, gb_free=10.8, wall=361
2022-03-23 11:46:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:46:43 | INFO | fairseq.tasks.translation | example hypothesis: we're the world.
2022-03-23 11:46:43 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:46:47 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world.
2022-03-23 11:46:47 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:46:51 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world.
2022-03-23 11:46:51 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:46:55 | INFO | fairseq.tasks.translation | example hypothesis: and it's a world of the world, and it's the world.
2022-03-23 11:46:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:47:00 | INFO | fairseq.tasks.translation | example hypothesis: and it's that's not not not not not not not not not not not not not that we have that we're not not not not not not not not not not not not not not not not not not not not not not that's the
2022-03-23 11:47:00 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:47:05 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world of the world of the world, and this is the world.
2022-03-23 11:47:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:47:10 | INFO | fairseq.tasks.translation | example hypothesis: and you can can can can't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't
2022-03-23 11:47:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:47:15 | INFO | fairseq.tasks.translation | example hypothesis: and so we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can the world, and that we're the world, and that we're the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 11:47:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:47:22 | INFO | fairseq.tasks.translation | example hypothesis: and "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:47:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:47:24 | INFO | fairseq.tasks.translation | example hypothesis: so, we have to have to be the world, and we're the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, and we can can can can can can can can can do that we can can can can can can can can can can can can do that we can can can can can can can can can can can can can do that that we can can can can can can can can can can can can can can can can be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be to be that that that that that that that that is the world of the world of the world, and that we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 11:47:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:47:24 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.412 | ppl 5451.64 | bleu 1.19 | wps 3966.8 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 1.19
2022-03-23 11:47:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 11:47:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:47:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:47:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 1.19) (writing took 1.7624028814025223 seconds)
2022-03-23 11:47:26 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 11:47:26 | INFO | train | epoch 004 | loss 11.246 | ppl 2428.13 | wps 37061.8 | ups 1.47 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.047 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 417
KL Stats: Epoch 4 Divergences: Uniform: 0.691525311623762 Unigram: 0.5331672015382393
2022-03-23 11:47:26 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 11:47:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:47:55 | INFO | train_inner | epoch 005:     76 / 157 loss=11.184, ppl=2326.99, wps=28962.3, ups=1.18, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.116, loss_scale=8, train_wall=37, gb_free=11.5, wall=446
2022-03-23 11:48:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:48:29 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the world.
2022-03-23 11:48:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:48:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world.
2022-03-23 11:48:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:48:36 | INFO | fairseq.tasks.translation | example hypothesis: now, we're a lot of the world.
2022-03-23 11:48:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:48:40 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot.
2022-03-23 11:48:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:48:43 | INFO | fairseq.tasks.translation | example hypothesis: and it's going to do it's going to do that we're not not not not not not not going to do it.
2022-03-23 11:48:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:48:47 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world of the world of the world of the world, and the world of the world of the world, and the world of the world of the world of the world.
2022-03-23 11:48:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:48:52 | INFO | fairseq.tasks.translation | example hypothesis: but it's a lot of the world, but they're not not not not not not a lot of the world, but they're going to be a lot of the world, but they're going to be a lot of the world, but they're going to be the world.
2022-03-23 11:48:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:48:57 | INFO | fairseq.tasks.translation | example hypothesis: and we can see the world of the world, and we can see the world, and we can see the lot of the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world.
2022-03-23 11:48:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:49:05 | INFO | fairseq.tasks.translation | example hypothesis: and so, "" "" "this is," it's a lot, "" it's a lot, "" it's a lot, "" it's a lot, "it's a lot of the world," "" "" and "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "and it's, and it's, and it's," "" "" "" "" "
2022-03-23 11:49:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:49:07 | INFO | fairseq.tasks.translation | example hypothesis: so, we're a lot of the world of the world, and the world, and it's a lot of the world, and the world, and it's a lot of the world of the world, and the world, and it's a lot of the world of the world, and the world, and it's a lot of the world, the world of the world, and the world, and it's a lot of the world of the world of the world of the world, and it's a lot of the world, and it's a lot of the world, and the world, and the world, and we have to be the world, and the world, and we have to be the world, and it's the world, and the world, and the world, and it's a lot of the world of the world, the world, and it's the world, and we have to be the world of the world, and we're a lot of the world, and we have to be the world, and we have to be a
2022-03-23 11:49:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:49:07 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 12.178 | ppl 4634.37 | bleu 1.77 | wps 4302.7 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.77
2022-03-23 11:49:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 11:49:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:49:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:49:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.77) (writing took 1.8367056120187044 seconds)
2022-03-23 11:49:09 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 11:49:09 | INFO | train | epoch 005 | loss 10.992 | ppl 2036 | wps 38368.3 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.037 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 520
KL Stats: Epoch 5 Divergences: Uniform: 0.7298410067405191 Unigram: 0.7015418373485026
2022-03-23 11:49:09 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 11:49:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:49:16 | INFO | train_inner | epoch 006:     19 / 157 loss=10.838, ppl=1830.05, wps=31218.9, ups=1.23, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=1.045, loss_scale=8, train_wall=37, gb_free=12.7, wall=528
2022-03-23 11:49:54 | INFO | train_inner | epoch 006:    119 / 157 loss=10.781, ppl=1758.99, wps=67120.8, ups=2.65, wpb=25320.5, bsz=1021.9, num_updates=900, lr=0.0001125, gnorm=1.015, loss_scale=8, train_wall=37, gb_free=11.9, wall=565
2022-03-23 11:50:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:50:12 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 11:50:12 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:50:16 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of this is that is the most of the world.
2022-03-23 11:50:16 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:50:21 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be a lot of the world.
2022-03-23 11:50:21 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:50:25 | INFO | fairseq.tasks.translation | example hypothesis: and there's a, there's a lot of, and there's a, there's going to be, and there's going to be, and there's going to be, and there's going to be
2022-03-23 11:50:25 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:50:31 | INFO | fairseq.tasks.translation | example hypothesis: and it's not that we don't know that we're going to do it, and it's not not going to do it, and it's going to do it's going to do it's going to do it's not not not not
2022-03-23 11:50:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:50:36 | INFO | fairseq.tasks.translation | example hypothesis: and this is in the world, in the world, and in the world, and in the world, and in the world, and in the world, and it's in the world, and in the world, and in the world, and in the world, and in the world, and
2022-03-23 11:50:36 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:50:42 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to see, but you're going to be a lot of the world, but they're going to be, but they're going to be, but they're going to be, but they're going to be, but they're going to be, but they're going to be, but they're going to be, but they're
2022-03-23 11:50:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:50:49 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to see that we're going to see, and we're going to see that we're going to see that we're going to see that we're going to make a lot of the world, and then we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see the
2022-03-23 11:50:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:50:56 | INFO | fairseq.tasks.translation | example hypothesis: and it's, "" it's, "it's," it's, "it's," it's, "it's," it's, "it's," it's, "it's," it's, "it's a," it's, "it's," it's, "it's," it's, "it's," it's, "it's," it's, "it's," "" "" "it's," "" "" it's, "it's," it's, "it's," it's, "" it's a, "it's," it's, "it's," it's, "it's," it's, "it's," it's, "it's," "it's a," "it's a," it's
2022-03-23 11:50:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:50:59 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to see that we're going to be a lot of that we're going to see that we're going to see that we're going to see that we're going to see that we're going to be a lot of the world, but it's going to see that we're going to see that we're going to see that we're going to do that we're going to see that we're going to see that we're going to be a lot of the world, which is that we're going to be a lot of that we're going to see that we're going to do that we're going to see that we're going to be going to do that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to do that we're going to see that we're going to see that we're going to see, but it, but it's going to see that we're going to see that we're going to
2022-03-23 11:50:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:50:59 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.987 | ppl 4057.9 | bleu 1.56 | wps 3511.8 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.77
2022-03-23 11:50:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 11:50:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 11:50:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 11:50:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt (epoch 6 @ 938 updates, score 1.56) (writing took 0.7943732519634068 seconds)
2022-03-23 11:50:59 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 11:50:59 | INFO | train | epoch 006 | loss 10.798 | ppl 1780.81 | wps 35736.6 | ups 1.42 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 1.045 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 631
KL Stats: Epoch 6 Divergences: Uniform: 0.7667674248691693 Unigram: 0.8084071868965016
2022-03-23 11:51:00 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 11:51:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:51:23 | INFO | train_inner | epoch 007:     62 / 157 loss=10.703, ppl=1667.06, wps=28279.5, ups=1.12, wpb=25195.5, bsz=1022.5, num_updates=1000, lr=0.000125, gnorm=0.962, loss_scale=8, train_wall=37, gb_free=11.6, wall=654
2022-03-23 11:51:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:52:03 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 11:52:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:52:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the most most of the most most most of the most of the most most of the most of the most of the most of
2022-03-23 11:52:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:52:12 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be able to be able to be a new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 11:52:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:52:17 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of, and you're going to see, and there's going to be going to be a lot.
2022-03-23 11:52:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:52:22 | INFO | fairseq.tasks.translation | example hypothesis: it's not a lot of it, and it's not going to do that we're going to do it, and it's going to do it's going to do it's going to do it and it's not not not not going to
2022-03-23 11:52:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:52:28 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's a lot of people in the world, and it's a lot of people in the people in the world, and the world, and it's in the world.
2022-03-23 11:52:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:52:33 | INFO | fairseq.tasks.translation | example hypothesis: if you're going to see, you're going to see, but they're going to see, but they're going to be a lot of the world, but they're going to be a lot of the same, and they're going to be not, and they're going to be not, but they're going to be, but they're going to
2022-03-23 11:52:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:52:39 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see the world, and we're going to see, and we're going to see the world, and we're going to see the world, and we're going to be going to be going to see the world, and we're going to be going to see the world, and we can see that we're going to be going to be going to be going to be going to be going to be going to see the world, and
2022-03-23 11:52:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:52:47 | INFO | fairseq.tasks.translation | example hypothesis: and if you know, "you're going to say," you know, "you know," you know, "you know," you know, "it's going to say," you know, "we're going to do it's going to say," you know, "we're going to say," you know, "we're going to say," it's going to say, "it's going to say," we're going to say, "we're going to say," we're going to say, "you know," we're going to say, "it's going to say," it's going to say, "it's going to say," you know, "you know," it's going to say, "it's going to say," it's going to say, "you're going to do it's going to say
2022-03-23 11:52:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:52:49 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to see that we're going to be a lot of the world, and we're going to see that we're going to see that we're going to see the world, and we're going to see that we're going to see the world, and we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see it's going to see the world, and then we're going to see that we're going to do it's going to see the world, and we're going to see that we're going to see that we're going to see that we're going to see it's going to see the world, and then we're going to do it's going to see the world, and then we're going to see that we're going to see it's going to see the world, and then we're going to see that we're going to see the
2022-03-23 11:52:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:52:49 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.853 | ppl 3698.8 | bleu 1.93 | wps 3532.8 | wpb 17862.2 | bsz 728.3 | num_updates 1095 | best_bleu 1.93
2022-03-23 11:52:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1095 updates
2022-03-23 11:52:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:52:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:52:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 7 @ 1095 updates, score 1.93) (writing took 1.7947492469102144 seconds)
2022-03-23 11:52:51 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 11:52:51 | INFO | train | epoch 007 | loss 10.629 | ppl 1583.61 | wps 35444.3 | ups 1.41 | wpb 25153.6 | bsz 1020.6 | num_updates 1095 | lr 0.000136875 | gnorm 0.971 | loss_scale 8 | train_wall 58 | gb_free 12.6 | wall 742
KL Stats: Epoch 7 Divergences: Uniform: 0.795002985849168 Unigram: 0.8875459096006983
2022-03-23 11:52:51 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 11:52:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:52:53 | INFO | train_inner | epoch 008:      5 / 157 loss=10.632, ppl=1587.11, wps=27788.8, ups=1.11, wpb=25002.6, bsz=1042.3, num_updates=1100, lr=0.0001375, gnorm=0.959, loss_scale=8, train_wall=37, gb_free=12, wall=744
2022-03-23 11:53:31 | INFO | train_inner | epoch 008:    105 / 157 loss=10.442, ppl=1390.85, wps=67140.4, ups=2.67, wpb=25137.5, bsz=1075.3, num_updates=1200, lr=0.00015, gnorm=0.907, loss_scale=8, train_wall=37, gb_free=12.3, wall=782
2022-03-23 11:53:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:53:54 | INFO | fairseq.tasks.translation | example hypothesis: we've got to go in the world.
2022-03-23 11:53:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:53:59 | INFO | fairseq.tasks.translation | example hypothesis: that's the most most of the most most most most of the most most most most of the most most most of the most most most most most of
2022-03-23 11:53:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:54:03 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 11:54:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:54:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, for example, and there's a lot of example.
2022-03-23 11:54:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:54:13 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're going to do it, and we're going to do what we're going to do.
2022-03-23 11:54:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:54:18 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the world, in the world, for the people who have to get a lot of people in the people in the people in the people in the people in the people in the people in the people in the people in the people, and the people.
2022-03-23 11:54:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:54:23 | INFO | fairseq.tasks.translation | example hypothesis: some of some of some people who are, but but they're going to get a lot of them, but but but they're not, but but they're going to get a lot of the but they're going to go to get the same, but they're going to get the same, but they're going to get the same same same, but they
2022-03-23 11:54:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:54:29 | INFO | fairseq.tasks.translation | example hypothesis: so, if we can see the brain, we can see, and we can see that we can see the world, and we can see that we can see that we can see the world.
2022-03-23 11:54:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:54:35 | INFO | fairseq.tasks.translation | example hypothesis: well, one: if you know, it's a lot of me, "you know," you know, "you know," you know, "you know," you know, "you know," it, "it's a lot of me," it's a little little little little bit, "it's a little bit," it's the first first first first first first first first first first first first first first first first first, "and it's a little bit," and it's a little bit, "it's a little bit to say," and it's a little bit of the first first first first first first, "and it's a little bit of the first first first first first first first first first," you know, "and it's a little bit," it's, "and it's a little bit of the first first first first first first
2022-03-23 11:54:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:54:37 | INFO | fairseq.tasks.translation | example hypothesis: now, it's a lot of us that we've got to be able to be a lot of the world, and if we're going to do that we're going to be able to be able to be able to be able to be able to be able to be a lot of the world.
2022-03-23 11:54:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:54:37 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.686 | ppl 3293.72 | bleu 3.35 | wps 3796.5 | wpb 17862.2 | bsz 728.3 | num_updates 1252 | best_bleu 3.35
2022-03-23 11:54:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1252 updates
2022-03-23 11:54:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:54:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:54:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 8 @ 1252 updates, score 3.35) (writing took 1.7686965693719685 seconds)
2022-03-23 11:54:39 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 11:54:39 | INFO | train | epoch 008 | loss 10.492 | ppl 1440.43 | wps 36441.7 | ups 1.45 | wpb 25153.6 | bsz 1020.6 | num_updates 1252 | lr 0.0001565 | gnorm 0.902 | loss_scale 8 | train_wall 58 | gb_free 11.7 | wall 850
KL Stats: Epoch 8 Divergences: Uniform: 0.821317846898364 Unigram: 0.9398834082588604
2022-03-23 11:54:40 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 11:54:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:54:58 | INFO | train_inner | epoch 009:     48 / 157 loss=10.382, ppl=1334.88, wps=29380.4, ups=1.14, wpb=25702.9, bsz=1011, num_updates=1300, lr=0.0001625, gnorm=0.852, loss_scale=8, train_wall=37, gb_free=12.6, wall=869
2022-03-23 11:55:36 | INFO | train_inner | epoch 009:    148 / 157 loss=10.4, ppl=1351.56, wps=66224.1, ups=2.67, wpb=24780.2, bsz=958.6, num_updates=1400, lr=0.000175, gnorm=0.84, loss_scale=8, train_wall=37, gb_free=11.9, wall=907
2022-03-23 11:55:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:55:43 | INFO | fairseq.tasks.translation | example hypothesis: we had this in this room in the way.
2022-03-23 11:55:43 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:55:47 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most of the most of the most of the most most of the most most most most most
2022-03-23 11:55:47 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:55:53 | INFO | fairseq.tasks.translation | example hypothesis: are new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 11:55:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:55:58 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's a lot of life, and there's a lot of where you're going to see, where you're going to see where are going to go with a, where the
2022-03-23 11:55:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:56:03 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we don't just just just just just just just just just just just just just just just just a little little little bit of what we're going to go on the right?
2022-03-23 11:56:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:56:09 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the people like people like the people for the people who have been able to get for the people in the people in the people in the most people in the people in the people in the people who have been able to see the people in the people in the people in the
2022-03-23 11:56:09 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:56:15 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some of some of them are going to see, but if you're going to see, it's a lot of course, but it's not a lot of course, but it's not, but if you're going to go to be able to be able to be able to be able to be able to be able to be
2022-03-23 11:56:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:56:21 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information that we can see the way that we can see that we can see that we can see the world, and we can see a lot of the world, and we can see that we can see that we can see a lot of the world, and see the brain, and we can see that we can see that we can see it's going to make a lot of the world, and see that we can see that can
2022-03-23 11:56:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:56:28 | INFO | fairseq.tasks.translation | example hypothesis: yeah, one of the one of the one of the first thing, "it's going to say," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you're going to say," you know, "you know," you know, "you know," you know, "you know," "" "you know," you know, "you know," you know, "you know," you know, "you know," you're going to do it's going to say, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you're going to do it's going to say,"
2022-03-23 11:56:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:56:31 | INFO | fairseq.tasks.translation | example hypothesis: so, in fact, it's still still still still still still still have a lot of course, and if we're going to be a lot of the same time, if we're going to get a lot of the same time, we're going to be a lot of the same time, we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the same time, we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get a lot of the world, and see that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 11:56:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:56:31 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 11.551 | ppl 3000.72 | bleu 3.81 | wps 3442.5 | wpb 17862.2 | bsz 728.3 | num_updates 1409 | best_bleu 3.81
2022-03-23 11:56:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1409 updates
2022-03-23 11:56:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:56:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:56:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 9 @ 1409 updates, score 3.81) (writing took 1.7501129540614784 seconds)
2022-03-23 11:56:32 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 11:56:32 | INFO | train | epoch 009 | loss 10.34 | ppl 1295.99 | wps 34938.2 | ups 1.39 | wpb 25153.6 | bsz 1020.6 | num_updates 1409 | lr 0.000176125 | gnorm 0.842 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 963
KL Stats: Epoch 9 Divergences: Uniform: 0.8460595305176328 Unigram: 0.9909069481268382
2022-03-23 11:56:33 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 11:56:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:57:08 | INFO | train_inner | epoch 010:     91 / 157 loss=10.283, ppl=1245.58, wps=27355.5, ups=1.09, wpb=25166.5, bsz=1026, num_updates=1500, lr=0.0001875, gnorm=0.791, loss_scale=8, train_wall=37, gb_free=12.6, wall=999
2022-03-23 11:57:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 11:57:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:57:35 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 11:57:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:57:39 | INFO | fairseq.tasks.translation | example hypothesis: this is what's not the most of you know.
2022-03-23 11:57:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:57:43 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new york.
2022-03-23 11:57:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:57:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a, and there's no.
2022-03-23 11:57:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:57:50 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just a few days, and what's going on.
2022-03-23 11:57:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:57:54 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, how people were working for the people, for the people, and the people, and that's a few years.
2022-03-23 11:57:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:57:59 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are going to be able to be able to be able to be able, but if you don't need to get it.
2022-03-23 11:57:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:58:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information that we can use this, we can use this.
2022-03-23 11:58:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:58:10 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the one of the interesting thing, and it's interesting, and it's interesting for me, and you know, and you know, and you know, for me, and you know, you know, you know, you're going to do it for me, and then you know, you know, and then we're going to do it's going to go back to me, and then you know, and then you know, and then you know, you know, you know, and then you know, and then you know, and you're going to do it's going to do that's a long time, and then we're going to do it's going to do that you're going to go to do that you know, and then you know, and then you know, and then you know, and then you're going to do it's a long time for me, and
2022-03-23 11:58:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:58:12 | INFO | fairseq.tasks.translation | example hypothesis: well, it's always always always always always always always been a lot of the world, and a lot of work, and if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get
2022-03-23 11:58:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:58:12 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 11.339 | ppl 2590.5 | bleu 6.67 | wps 4467.7 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 6.67
2022-03-23 11:58:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 11:58:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:58:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:58:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 6.67) (writing took 1.7708943481557071 seconds)
2022-03-23 11:58:14 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 11:58:14 | INFO | train | epoch 010 | loss 10.194 | ppl 1171.09 | wps 38571.4 | ups 1.54 | wpb 25127.3 | bsz 1014.9 | num_updates 1565 | lr 0.000195625 | gnorm 0.832 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1065
KL Stats: Epoch 10 Divergences: Uniform: 0.8758366294620834 Unigram: 1.0408192450296851
2022-03-23 11:58:14 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 11:58:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:58:28 | INFO | train_inner | epoch 011:     35 / 157 loss=10.179, ppl=1159.58, wps=30964.6, ups=1.25, wpb=24781, bsz=994.3, num_updates=1600, lr=0.0002, gnorm=0.884, loss_scale=4, train_wall=37, gb_free=11.5, wall=1079
2022-03-23 11:59:05 | INFO | train_inner | epoch 011:    135 / 157 loss=9.849, ppl=922.12, wps=67719.6, ups=2.65, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=0.797, loss_scale=4, train_wall=37, gb_free=11.5, wall=1116
2022-03-23 11:59:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:59:17 | INFO | fairseq.tasks.translation | example hypothesis: we had these ppppin the end.
2022-03-23 11:59:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:59:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most most of most of most most of most most most of the most most most most of here.
2022-03-23 11:59:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:59:25 | INFO | fairseq.tasks.translation | example hypothesis: these new new new new new new new new new new new new york are going to be able to be able to be able.
2022-03-23 11:59:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:59:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a war where they're going to go with the popppa, and they're going to be going to be able.
2022-03-23 11:59:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:59:34 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just a couple of your head, and what's going to understand.
2022-03-23 11:59:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:59:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamaal people like the most people for the number of the number, and that's a few years.
2022-03-23 11:59:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:59:41 | INFO | fairseq.tasks.translation | example hypothesis: first of some of you are going to go from the water, but if you don't need the energy, you need to have the energy.
2022-03-23 11:59:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:59:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that we can use this kind of information, we can take a kind of information that are going to be able to be able to take the structure of the structure of the information.
2022-03-23 11:59:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:59:50 | INFO | fairseq.tasks.translation | example hypothesis: and one of the reasons, it's interesting, and it's interesting for me for me that we've got to say, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you're going to know, "you're going to know," you know, "for this is that we're going to say," you know, "you know," you know, "you know," you know, "you know," for this is that there is that we're going to say, "you know," you know, "you know," you know, "you know," you know, "you're going to say," you know, "you know,"
2022-03-23 11:59:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:59:52 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still still still the mother, and we had a lot of work that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 11:59:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:59:52 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 11.136 | ppl 2250.34 | bleu 8.98 | wps 4751.9 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 8.98
2022-03-23 11:59:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 11:59:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:59:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 11:59:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 8.98) (writing took 1.7639750079251826 seconds)
2022-03-23 11:59:54 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 11:59:54 | INFO | train | epoch 011 | loss 10.012 | ppl 1032.31 | wps 39561.3 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.808 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 1165
KL Stats: Epoch 11 Divergences: Uniform: 0.8986053517096692 Unigram: 1.0811109378084565
2022-03-23 11:59:54 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 11:59:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:00:24 | INFO | train_inner | epoch 012:     78 / 157 loss=9.946, ppl=986.7, wps=31954.8, ups=1.28, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=0.773, loss_scale=4, train_wall=37, gb_free=12.1, wall=1195
2022-03-23 12:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:00:57 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 12:00:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:01:00 | INFO | fairseq.tasks.translation | example hypothesis: and that's the car that you know, most of most.
2022-03-23 12:01:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:01:04 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to be able.
2022-03-23 12:01:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:01:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an chinese chinese chinese chinese chinese, where they're going to get with the poppppppppy, and they're going to go.
2022-03-23 12:01:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:01:13 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just a couple of the brain on his head, and what all of his head are going to understand his mind.
2022-03-23 12:01:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:01:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamace of people like the ability for the number of animals, and that's a number of animals in the world.
2022-03-23 12:01:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:01:21 | INFO | fairseq.tasks.translation | example hypothesis: first.
2022-03-23 12:01:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:01:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information can be able to be able, we can start with a kind of structure, we can start with the structure of the structure of the structure, and the structure of the structure of the structure, and all the structure of the structure of the structure, and all the structure of the structure of the structure of the structure, and all the structure of the structure, and all the structure of the structure of the structure of the information.
2022-03-23 12:01:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:01:30 | INFO | fairseq.tasks.translation | example hypothesis: again, one of the reasons it's interesting, and it's interesting for me to be here for me, "oh," well, "if we're going to say," then we're going to say, "and then we're going to say that the best time," and then we're going to tell you're going to say, "you're going to tell you're going to say,"
2022-03-23 12:01:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:01:33 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still still the mother of the way that we had a lot of work, and we've got to see the whole way that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use
2022-03-23 12:01:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:01:33 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.927 | ppl 1946.93 | bleu 10.28 | wps 4558.5 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 10.28
2022-03-23 12:01:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 12:01:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:01:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:01:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 10.28) (writing took 1.7905798028223217 seconds)
2022-03-23 12:01:34 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 12:01:34 | INFO | train | epoch 012 | loss 9.811 | ppl 898.47 | wps 39249.8 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.77 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 1265
KL Stats: Epoch 12 Divergences: Uniform: 0.9254397976568774 Unigram: 1.1163459520157695
2022-03-23 12:01:35 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 12:01:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:01:43 | INFO | train_inner | epoch 013:     21 / 157 loss=9.711, ppl=838.15, wps=31637.7, ups=1.26, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=0.823, loss_scale=4, train_wall=37, gb_free=12, wall=1274
2022-03-23 12:02:21 | INFO | train_inner | epoch 013:    121 / 157 loss=9.671, ppl=815.42, wps=66750.6, ups=2.64, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=0.766, loss_scale=4, train_wall=38, gb_free=11.7, wall=1312
2022-03-23 12:02:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:02:38 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppk in the clinics.
2022-03-23 12:02:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:02:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the car of doha, most of most, most of the most of here.
2022-03-23 12:02:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:02:46 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to be able to make two new ways that are going to be used.
2022-03-23 12:02:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:02:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese food, where they're going to be in a poke.
2022-03-23 12:02:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:02:54 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just a couple of brain on his head, and what's going to understand his mind.
2022-03-23 12:02:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:02:58 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamace of people who had been working for the number of animals, and that's a number of animals.
2022-03-23 12:02:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:03:01 | INFO | fairseq.tasks.translation | example hypothesis: first of some of these are some kind of maddddddust in the same energy, but if you don't need your energy, and the energy.
2022-03-23 12:03:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:03:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information information that we can start from this structure, we can start able to start with a huge form of the structure of the structure of the structure, and the structure of all the information.
2022-03-23 12:03:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:03:09 | INFO | fairseq.tasks.translation | example hypothesis: hth: one of the reasons it's interesting for me, and i'm going to be here to be here, "oh," well, "if you say," the best revolution is a long revolution, "and if you have a long revolution."
2022-03-23 12:03:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:03:10 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need to be still the mother of the design, and we've got to do a lot of work on the ground, which is that we had to be able to be able to be able to be able to be able to be able to see it.
2022-03-23 12:03:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:03:10 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.799 | ppl 1781.4 | bleu 12.95 | wps 5063.3 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 12.95
2022-03-23 12:03:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 12:03:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:03:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:03:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 12.95) (writing took 1.8092463570646942 seconds)
2022-03-23 12:03:12 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 12:03:12 | INFO | train | epoch 013 | loss 9.636 | ppl 795.6 | wps 40441.8 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.772 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 1363
KL Stats: Epoch 13 Divergences: Uniform: 0.9560147366113068 Unigram: 1.1500138950816008
2022-03-23 12:03:12 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 12:03:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:03:37 | INFO | train_inner | epoch 014:     64 / 157 loss=9.562, ppl=755.96, wps=32881, ups=1.32, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=0.738, loss_scale=4, train_wall=37, gb_free=12.3, wall=1388
2022-03-23 12:04:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:04:15 | INFO | fairseq.tasks.translation | example hypothesis: we made these pppppure in the clinic.
2022-03-23 12:04:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:04:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of doha, doha, most of the most of you know, most of you know.
2022-03-23 12:04:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:04:24 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new orts. the two can create the new new.
2022-03-23 12:04:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:04:28 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food, where the legs are happy, and they're going to get up with.
2022-03-23 12:04:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:04:32 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just have a couple of electrodes on his head and understand what all of his mind are on the mind.
2022-03-23 12:04:32 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:04:36 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamats like the responsibility for the responsibility, the number of people came back to the number of animals, and this has become become become a very likely.
2022-03-23 12:04:36 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:04:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are a little bit of magic, but in the top of the lines, but if you don't need the energy, and you need the energy.
2022-03-23 12:04:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:04:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with one of the traditional traditional design of the information, and the whole structure of all the information.
2022-03-23 12:04:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:04:46 | INFO | fairseq.tasks.translation | example hypothesis: th reasons, one of the reasons it's interesting, and it's interesting for me to do here for tedtedson, "oh, when we said," and then we've come to you. "
2022-03-23 12:04:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:04:47 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need to do is still the mother, and the invention of the design part of our work, we had to see that if we had to see the united states in the ground, and all of us were able to see everything.
2022-03-23 12:04:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:04:47 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.659 | ppl 1616.85 | bleu 15.12 | wps 5158.8 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 15.12
2022-03-23 12:04:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 12:04:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:04:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:04:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 15.12) (writing took 1.8066269382834435 seconds)
2022-03-23 12:04:49 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 12:04:49 | INFO | train | epoch 014 | loss 9.451 | ppl 700.13 | wps 40680.7 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.724 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1460
KL Stats: Epoch 14 Divergences: Uniform: 0.9852068540239238 Unigram: 1.1723269566443204
2022-03-23 12:04:50 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 12:04:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:04:53 | INFO | train_inner | epoch 015:      7 / 157 loss=9.308, ppl=634, wps=33652.7, ups=1.32, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=0.683, loss_scale=4, train_wall=37, gb_free=12, wall=1464
2022-03-23 12:05:30 | INFO | train_inner | epoch 015:    107 / 157 loss=9.296, ppl=628.73, wps=66670.9, ups=2.65, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=0.76, loss_scale=4, train_wall=37, gb_free=12, wall=1501
2022-03-23 12:05:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:05:53 | INFO | fairseq.tasks.translation | example hypothesis: we made this pink in the clinic clinic clinic.
2022-03-23 12:05:53 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:05:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of doha, most of the doha, most of you know.
2022-03-23 12:05:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:06:01 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks.
2022-03-23 12:06:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:06:05 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food, where the legs are happy, and they're going.
2022-03-23 12:06:05 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:06:09 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a couple of electrodes on his head and understand what all of his mind are on the mind.
2022-03-23 12:06:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:06:14 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamating people like the responsibility of the responsibility, and the number of animals came back to the number of animals, and this is a devaiiibia.
2022-03-23 12:06:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:06:18 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of the magic lines are in the field, but it doesn't like, if you're not going to move it, it doesn't need to move the energy, and you need to move your energy, and you need your energy.
2022-03-23 12:06:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:06:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of this reflection, we can start with a traditional face that can start able to start with a huge view of the shape of the shape of the information, and the whole structure of the structure of the structure of the structure, and the whole structure of the structure, and the structure of the structure of the information is that we're all the information.
2022-03-23 12:06:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:06:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to be here for tedtalk, that's the best thing that it's the best thing that someone was going to say, "and then," if you're going to do this talk to you're going to give you a long time for a long time, "and then we're going to give you a long time to give you a long time to give you a long time," -- "oh," oh, "and then we've got a long time for you a long time to do," oh, "oh," oh, "oh," oh, "you know," you know, "you know," you know, "oh," oh, "oh," you know, "you know," you're going to do it's a long time to do it's a
2022-03-23 12:06:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:06:30 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, the mother is still the invention of the invention, and a lot of design, we had to solve the airplane on our airplane, that we had to solve a unique result of these problems that we had to solve it, and if we had to solve it, it's a unique system, it's a unique system that we had to see that we had to see that we had to see that it's either use it, it is to be able to see that if you had to see that it's a particular particular particular particular particular way to see that we had to see that it's a particular particular particular particular particular system, it's a huge, if you had to see that it's actually, it is to see that we had to see, it's a lot of a lot of a lot of a particular particular particular particular particular particular particular, or to see that we had to see that we had to see that we had to make it's a lot of a particular particular particular particular particular scale, or to see that it's a
2022-03-23 12:06:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:06:30 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.466 | ppl 1414.26 | bleu 15.72 | wps 4343.8 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 15.72
2022-03-23 12:06:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 12:06:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:06:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:06:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 15.72) (writing took 1.7980624069459736 seconds)
2022-03-23 12:06:32 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 12:06:32 | INFO | train | epoch 015 | loss 9.311 | ppl 634.99 | wps 38277.1 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.729 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1563
KL Stats: Epoch 15 Divergences: Uniform: 1.010292528613479 Unigram: 1.1867393205740564
2022-03-23 12:06:33 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 12:06:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:06:52 | INFO | train_inner | epoch 016:     50 / 157 loss=9.22, ppl=596.38, wps=31144.6, ups=1.22, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=0.668, loss_scale=4, train_wall=37, gb_free=12.4, wall=1583
2022-03-23 12:07:29 | INFO | train_inner | epoch 016:    150 / 157 loss=9.236, ppl=602.79, wps=66282.8, ups=2.69, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.656, loss_scale=4, train_wall=37, gb_free=12.6, wall=1620
2022-03-23 12:07:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:07:35 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic.
2022-03-23 12:07:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:07:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most know.
2022-03-23 12:07:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:07:43 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new logic.
2022-03-23 12:07:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:07:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs will be.
2022-03-23 12:07:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:07:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head and understand what all of the thoughts are.
2022-03-23 12:07:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:07:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility of life, the number of animals, and this is a number of animals.
2022-03-23 12:07:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:07:57 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magic lines in the field, but the susullant like this, if you don't need your energy, and you need your energy.
2022-03-23 12:07:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:08:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start able to start able to start able to start with a traditional view of the face of the shape, and that's the whole shape of the information.
2022-03-23 12:08:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:08:04 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure me to be here for tedwomen. "
2022-03-23 12:08:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:08:05 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the invention of the invention and a big design that we have to see in our airplane, is that we had to solve a result of the plane that we had to solve.
2022-03-23 12:08:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:08:05 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.388 | ppl 1339.53 | bleu 13.68 | wps 5571.8 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 15.72
2022-03-23 12:08:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 12:08:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:08:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:08:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 13.68) (writing took 0.7672808626666665 seconds)
2022-03-23 12:08:06 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 12:08:06 | INFO | train | epoch 016 | loss 9.148 | ppl 567.48 | wps 42251.4 | ups 1.68 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.668 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 1657
KL Stats: Epoch 16 Divergences: Uniform: 1.0361035373964183 Unigram: 1.2092700494385773
2022-03-23 12:08:06 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 12:08:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:08:41 | INFO | train_inner | epoch 017:     93 / 157 loss=9.03, ppl=522.86, wps=35014.6, ups=1.38, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=0.68, loss_scale=4, train_wall=37, gb_free=13.1, wall=1693
2022-03-23 12:09:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:09:09 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic clinic on the clinic clinic.
2022-03-23 12:09:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:09:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of the most know here.
2022-03-23 12:09:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:09:18 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to be able to create the two new picks.
2022-03-23 12:09:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:09:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food food food, where happy legs are going to be defemined with legs and salt.
2022-03-23 12:09:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:09:27 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand what all his thoughts are on the head.
2022-03-23 12:09:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:09:31 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamammals like the responsibility for the life, the number of the animals, and this is a foundation for conservation in the namibia.
2022-03-23 12:09:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:09:35 | INFO | fairseq.tasks.translation | example hypothesis: first of first, there are some bbols of magnetic lines, but the sullens, but the sulens don't like it, if you need your energy, and so that's what's going on.
2022-03-23 12:09:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:09:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of this reflection, we can start with a traditional face with a traditional face of traditional face, and the shape of the information, and that is the whole structure of the information, and the whole structure of the structure, and the whole structure of the structure of the structure, and the structure is all the structure, and the structure of the structure, and the structure is that all the structure of these reflection,
2022-03-23 12:09:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:09:47 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting, and you know, for me to be here for tedwomen, is that the best thing that someone was going to say, "when you say," if you're going to support you, "and then you're going to do it," if we've been working with you've been working on this, "and then we've been working with you've been working with you've been working with you know," and then we've been working with a long time for me, "
2022-03-23 12:09:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:09:49 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still the invention of the invention, and a lot of design work on the plane that we've had to solve is a unique result that we had to solve all the problems that we had to solve in the ground, and if you've been able to see it in the ground, it's a particular way that you're able to see, and you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the
2022-03-23 12:09:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:09:49 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.29 | ppl 1252.19 | bleu 16.69 | wps 4090.4 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 16.69
2022-03-23 12:09:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 12:09:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:09:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:09:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 16.69) (writing took 1.7843641708604991 seconds)
2022-03-23 12:09:51 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 12:09:51 | INFO | train | epoch 017 | loss 9.027 | ppl 521.74 | wps 37429.4 | ups 1.49 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.668 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1762
KL Stats: Epoch 17 Divergences: Uniform: 1.0592434480131396 Unigram: 1.222280870798588
2022-03-23 12:09:52 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 12:09:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:10:05 | INFO | train_inner | epoch 018:     36 / 157 loss=8.924, ppl=485.86, wps=30040.5, ups=1.19, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.654, loss_scale=4, train_wall=37, gb_free=12.5, wall=1777
2022-03-23 12:10:43 | INFO | train_inner | epoch 018:    136 / 157 loss=8.966, ppl=500.22, wps=66209, ups=2.67, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.598, loss_scale=4, train_wall=37, gb_free=12.3, wall=1814
2022-03-23 12:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:10:55 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 12:10:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:10:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that's probably the most familiar here.
2022-03-23 12:10:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:11:03 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks.
2022-03-23 12:11:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:11:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food food, where happy legs are going to be salt with salsalz and salt.
2022-03-23 12:11:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:11:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 12:11:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:11:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people who grew up for the wild responsibility, the number of wild animals, and this is a basis of natural protection in the namibia.
2022-03-23 12:11:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:11:19 | INFO | fairseq.tasks.translation | example hypothesis: first, you know, some of the magnetic field, but the sucks in the inside of the inside, it doesn't like that, if you need your energy, you don't need your energy, and you need your energy.
2022-03-23 12:11:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:11:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial facial facial face, which is the great face of the face, and the shape of the interfaces, and the whole structure, and the whole structure of the structure that's all the structure.
2022-03-23 12:11:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:11:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it very interesting, for me, for example, "is that..."
2022-03-23 12:11:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:11:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of the invention, and a big part of the design of the design that we're in our plane, is that we had to solve a result that we had to solve.
2022-03-23 12:11:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:11:30 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.101 | ppl 1098.26 | bleu 20.85 | wps 4622.6 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.85
2022-03-23 12:11:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 12:11:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:11:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:11:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.85) (writing took 1.7844117293134332 seconds)
2022-03-23 12:11:32 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 12:11:32 | INFO | train | epoch 018 | loss 8.889 | ppl 474.23 | wps 39210.8 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.593 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1863
KL Stats: Epoch 18 Divergences: Uniform: 1.0746885069323555 Unigram: 1.2381964097589484
2022-03-23 12:11:32 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 12:11:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:12:03 | INFO | train_inner | epoch 019:     79 / 157 loss=8.785, ppl=441.1, wps=32148.1, ups=1.25, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.581, loss_scale=4, train_wall=38, gb_free=12.2, wall=1894
2022-03-23 12:12:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:12:35 | INFO | fairseq.tasks.translation | example hypothesis: we made these beetles in the clinic.
2022-03-23 12:12:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:12:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably the most familiar here.
2022-03-23 12:12:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:12:43 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that are going to be able to be able to be the two new pigs.
2022-03-23 12:12:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:12:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are made with salsalz and fat.
2022-03-23 12:12:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:12:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head and understand exactly what all his thoughts are on the top.
2022-03-23 12:12:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:12:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammbia, people were growing for the wild, the number of wild animals, and this is a basis of natural protection in namibia.
2022-03-23 12:12:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:12:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are magnetic field lines in the interior lines, but the susulers don't like to move out when they need energy, and so the sucks.
2022-03-23 12:12:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:13:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial face, which is the big constructions of the face of the face and the information that the whole structure is.
2022-03-23 12:13:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:13:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and measure me here for tedwomen, is that, when you were in the best way, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, and you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know,
2022-03-23 12:13:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:13:09 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of invention, and a great part of the design work that we have to see in our airplane was a result of that we had to solve the unique problems in the ground -- all the way that it's an interior system, and that if you're in the ground, it's a certain part of us, or that it's an envelopy system, or to see that it's a particular way that we're going to see that it's an endangered for us to be a mechanism, and that we're either, or to be a mechanism, and that it's a mechanism, and that if you're going to see that it's a mechanism, or to be a mechanism, or to be a mechanism, it's a mechanism, and that you can be a mechanism, or to see that you're either, or to see that you can be a mechanism, or to be a mechanism, or to see that you can be a certain way to
2022-03-23 12:13:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:13:09 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.042 | ppl 1053.88 | bleu 21.5 | wps 4912 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.5
2022-03-23 12:13:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 12:13:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:13:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:13:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 21.5) (writing took 1.748634377028793 seconds)
2022-03-23 12:13:10 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 12:13:10 | INFO | train | epoch 019 | loss 8.759 | ppl 433.37 | wps 40068.4 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.571 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 1962
KL Stats: Epoch 19 Divergences: Uniform: 1.0889672949326008 Unigram: 1.2540550537329451
2022-03-23 12:13:11 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 12:13:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:13:19 | INFO | train_inner | epoch 020:     22 / 157 loss=8.727, ppl=423.78, wps=32329.4, ups=1.3, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.549, loss_scale=4, train_wall=36, gb_free=12.8, wall=1970
2022-03-23 12:13:58 | INFO | train_inner | epoch 020:    122 / 157 loss=8.568, ppl=379.5, wps=67501.6, ups=2.61, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.517, loss_scale=4, train_wall=38, gb_free=11.8, wall=2009
2022-03-23 12:14:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:14:14 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 12:14:14 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:14:18 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 12:14:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:14:22 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that create the two new pigs.
2022-03-23 12:14:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:14:26 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs with salsalz and pace of salt.
2022-03-23 12:14:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:14:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just making a couple of electroelectrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 12:14:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:14:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals, people like the responsibility for the wild, the number of wild animals grew up again, and that's a foundation of natural conservation in namibia.
2022-03-23 12:14:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:14:39 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of these are magnetic fields in the inner field, but the sulalty may not be able to move when they need their movements, and so the suicide disorders of magnetic disorders.
2022-03-23 12:14:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:14:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial can start with a traditional facial of the face of the face and the real shape of the face, and the real shape of the information, which is all the information that comes out of these reflection, the whole structure of these reflection, and we can start with a constructive structure.
2022-03-23 12:14:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:14:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting, and measure it interesting, and measure it interesting, for me here at tedwomen, is that... in tedwomen, in the best way, when someone said, "you know, the men in a table, the men who are doing it very interesting, and then we're doing it interesting," if we've been working on a talk about to you in tedwomen in tedwomen in tedwomen, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 12:14:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:14:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention of the invention, and a big part of the design work that we have to see in our airplane, was a result of them that we had to solve the unique problems that were connected to the ground -- all the way that the mother of the invention of the invention of the invention of the invention of the invention of design, and a big part of design work, and a big part of the design of the design of the design work that we have to see in the design work on the design work that we've had to see in the design work, in the aircraft, and a local local local local local local local local local local local local local local local local local, and a constructural work that we had to see in our airplane, in the design work that we had to see in the plane, and a very large part of our airplane, and a very much of the plane, in the way we had to see in our plane, in our plane, in the plane, in the plane, and
2022-03-23 12:14:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:14:52 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.971 | ppl 1003.73 | bleu 22.82 | wps 4330.6 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 22.82
2022-03-23 12:14:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 12:14:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:14:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:14:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 22.82) (writing took 1.7905204957351089 seconds)
2022-03-23 12:14:54 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 12:14:54 | INFO | train | epoch 020 | loss 8.651 | ppl 401.89 | wps 38271.7 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.555 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 2065
KL Stats: Epoch 20 Divergences: Uniform: 1.0963136496307035 Unigram: 1.2629477441693104
2022-03-23 12:14:54 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 12:14:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:15:19 | INFO | train_inner | epoch 021:     65 / 157 loss=8.553, ppl=375.57, wps=30718.3, ups=1.23, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.578, loss_scale=4, train_wall=36, gb_free=12, wall=2090
2022-03-23 12:15:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:15:57 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:15:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:16:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably the most familiar here.
2022-03-23 12:16:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:16:05 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks.
2022-03-23 12:16:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:16:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs will be served with salz.
2022-03-23 12:16:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:16:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 12:16:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:16:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people for the wild responsibility, the number of wild animals grew back, and that's a foundation for the natural protection in namibia.
2022-03-23 12:16:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:16:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloods of magnetic field in the internal field, but the suckers don't like it, if they're moving around, they need their energy, and the superconductors are going to disorders.
2022-03-23 12:16:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:16:26 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial.
2022-03-23 12:16:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:16:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen, is that... "
2022-03-23 12:16:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:16:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're in our plane, was a result that we had to solve the unique problems that were connected to the ground -- it's all the way that we're going to be able to be able to be able to use a refrightening system, and that allows us to use it to use it to be a specific machine that allows us to use.
2022-03-23 12:16:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:16:31 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.852 | ppl 924.19 | bleu 24.27 | wps 4751 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 24.27
2022-03-23 12:16:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 12:16:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:16:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:16:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 21 @ 3292 updates, score 24.27) (writing took 1.7723233960568905 seconds)
2022-03-23 12:16:33 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 12:16:33 | INFO | train | epoch 021 | loss 8.567 | ppl 379.13 | wps 39678.7 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.531 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 2164
KL Stats: Epoch 21 Divergences: Uniform: 1.1034810357840505 Unigram: 1.268892985998551
2022-03-23 12:16:34 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 12:16:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:16:37 | INFO | train_inner | epoch 022:      8 / 157 loss=8.675, ppl=408.8, wps=31684.9, ups=1.28, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.52, loss_scale=4, train_wall=37, gb_free=12, wall=2168
2022-03-23 12:17:14 | INFO | train_inner | epoch 022:    108 / 157 loss=8.59, ppl=385.22, wps=66030.6, ups=2.68, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.544, loss_scale=4, train_wall=37, gb_free=12, wall=2205
2022-03-23 12:17:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:17:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:17:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:17:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know here.
2022-03-23 12:17:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:17:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be new golden locks that make two new pigs.
2022-03-23 12:17:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:17:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and ppepper.
2022-03-23 12:17:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:17:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 12:17:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:17:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people of the wild, the number of wild animals grew again. and that's a foundation of conservation.
2022-03-23 12:17:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:17:59 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field in the inner field, but the sulalegters don't like to move, because their movements need to disorder.
2022-03-23 12:17:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:18:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face.
2022-03-23 12:18:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:18:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen, is that -- well, when somebody said to you, "you know."
2022-03-23 12:18:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:18:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're in the plane was a result that we had to solve the unique problems that were connected to the ground -- all of us have to be able to be able to be able to refrigered by a continually refrigered by a refrigered, and that if you're a refrightened to see the refrigeration of a mechanism.
2022-03-23 12:18:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:18:09 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.826 | ppl 907.96 | bleu 23.73 | wps 5024.5 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.27
2022-03-23 12:18:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 12:18:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:18:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:18:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt (epoch 22 @ 3449 updates, score 23.73) (writing took 0.7597910119220614 seconds)
2022-03-23 12:18:10 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 12:18:10 | INFO | train | epoch 022 | loss 8.491 | ppl 359.81 | wps 40940.5 | ups 1.63 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.508 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2261
KL Stats: Epoch 22 Divergences: Uniform: 1.111436833494136 Unigram: 1.2790163389582279
2022-03-23 12:18:10 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 12:18:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:18:29 | INFO | train_inner | epoch 023:     51 / 157 loss=8.439, ppl=347.07, wps=33852.7, ups=1.33, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.432, loss_scale=4, train_wall=37, gb_free=11.9, wall=2281
2022-03-23 12:19:07 | INFO | train_inner | epoch 023:    151 / 157 loss=8.283, ppl=311.51, wps=67923.6, ups=2.68, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.494, loss_scale=4, train_wall=37, gb_free=11.9, wall=2318
2022-03-23 12:19:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:19:13 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 12:19:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:19:17 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:19:17 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:19:21 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks.
2022-03-23 12:19:21 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:19:24 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz.
2022-03-23 12:19:24 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:19:28 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 12:19:28 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:19:32 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, the number of wild animals came back to the wild animals, and this is a foundation of natural protection.
2022-03-23 12:19:32 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:19:37 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught in the inner, but the supralegters may not be able to move when they're moving, because their movements need their movements, and so the sulant disorder.
2022-03-23 12:19:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:19:41 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face.
2022-03-23 12:19:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:19:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measured to me here at tedwomen, is that... "
2022-03-23 12:19:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:19:48 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of design work that we're using in our plane, was a result of it that we had to solve the unique problems that we had to solve in the ground, and it was connected to the ground, and it's all the way that we can use in a continuous refrigeration of a refrigeration of a refrigeration of a refrigeration of a refrigeration of a refrigeration, which is to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to refrightened by a refrightened by a refrightened to use the most sophisticated.
2022-03-23 12:19:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:19:48 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.809 | ppl 897.3 | bleu 24.99 | wps 4669.1 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 24.99
2022-03-23 12:19:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 12:19:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:19:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:19:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 24.99) (writing took 1.7592530706897378 seconds)
2022-03-23 12:19:50 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 12:19:50 | INFO | train | epoch 023 | loss 8.401 | ppl 337.95 | wps 39390 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.475 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2361
KL Stats: Epoch 23 Divergences: Uniform: 1.1138993814478684 Unigram: 1.2883644114219257
2022-03-23 12:19:50 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 12:19:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:20:26 | INFO | train_inner | epoch 024:     94 / 157 loss=8.422, ppl=343.08, wps=31591.7, ups=1.27, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.463, loss_scale=4, train_wall=37, gb_free=11.9, wall=2397
2022-03-23 12:20:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:20:53 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 12:20:53 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:20:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:20:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:21:01 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that create two new pigs.
2022-03-23 12:21:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:21:05 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and psuitcase.
2022-03-23 12:21:05 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:21:09 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 12:21:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:21:13 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people's responsibility for the wild, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 12:21:13 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:21:16 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines in the inside, but the superconductors don't like it when they're moving, because their movements need their energy, and so the superconductor disorders.
2022-03-23 12:21:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:21:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that gives the big configurations of the face and the basic form of the information that makes the whole portion and all the folds.
2022-03-23 12:21:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:21:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measured to me here at tedwomen, is that... tall, when dinner was the best, when someone said, "turn to the men on a table and tell you," if the revolution starts to support you. "
2022-03-23 12:21:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:21:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're in our airplane was a result that we had to solve the unique problems that were connected to surgery -- everything from a continually variable system and a refrigeration system that allows us to use in the way that we're going to be able to use in the aircraft, or the way that we're going to be able to be able to use in the united states.
2022-03-23 12:21:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:21:26 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.699 | ppl 830.94 | bleu 27.17 | wps 4971.4 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.17
2022-03-23 12:21:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 12:21:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:21:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:21:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 27.17) (writing took 1.7561039081774652 seconds)
2022-03-23 12:21:28 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 12:21:28 | INFO | train | epoch 024 | loss 8.338 | ppl 323.5 | wps 40349.5 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.439 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2459
KL Stats: Epoch 24 Divergences: Uniform: 1.1185241362152425 Unigram: 1.2934606874596783
2022-03-23 12:21:28 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 12:21:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:21:42 | INFO | train_inner | epoch 025:     37 / 157 loss=8.205, ppl=295, wps=33297.6, ups=1.31, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.412, loss_scale=4, train_wall=37, gb_free=12.1, wall=2473
2022-03-23 12:22:20 | INFO | train_inner | epoch 025:    137 / 157 loss=8.34, ppl=323.96, wps=66468.8, ups=2.65, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.49, loss_scale=4, train_wall=37, gb_free=12, wall=2511
2022-03-23 12:22:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:22:32 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 12:22:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:22:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:22:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:22:39 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that are two new pigs.
2022-03-23 12:22:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:22:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and psuitcase.
2022-03-23 12:22:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:22:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:22:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:22:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the makewise, people took responsibility for the wild animals, and that's a foundation for conservation in namibia.
2022-03-23 12:22:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:22:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some bands of magnetic field are caught in the inner, but the superconductor doesn't like you move because your movements need their movements, and so the superconductor disorders.
2022-03-23 12:22:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:22:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big constructions of the face and the basic form of the information that restores the whole portion.
2022-03-23 12:22:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:23:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and measured to me here at tedwomen is that... tyes, the dinner dinner was the best summarized when someone said, "turn you to the men on your desk and tell them," if the revolution starts to support you. "
2022-03-23 12:23:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:23:04 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a great part of design work that we're at our plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrigeration system that allows us to use a fluid, or if you can use the aircraft, or if you can use it in the air.
2022-03-23 12:23:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:23:04 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.691 | ppl 826.65 | bleu 26.33 | wps 5079.8 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 27.17
2022-03-23 12:23:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 12:23:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:23:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:23:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 26.33) (writing took 0.8001307062804699 seconds)
2022-03-23 12:23:05 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 12:23:05 | INFO | train | epoch 025 | loss 8.297 | ppl 314.58 | wps 40753.2 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.457 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2556
KL Stats: Epoch 25 Divergences: Uniform: 1.1182497407452123 Unigram: 1.2972303451410887
2022-03-23 12:23:05 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 12:23:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:23:35 | INFO | train_inner | epoch 026:     80 / 157 loss=8.167, ppl=287.38, wps=33693.2, ups=1.32, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.412, loss_scale=4, train_wall=37, gb_free=12.2, wall=2587
2022-03-23 12:24:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:24:08 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:24:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:24:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:24:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:24:16 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that make two new pigs.
2022-03-23 12:24:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:24:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:24:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:24:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of the thoughts are on the track.
2022-03-23 12:24:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:24:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the make-like people's responsibility for the wildlife, the number of wildlife animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 12:24:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:24:32 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are caught by magnetic field lines in the inside, but the superconductors don't like it, if they're moving, because their movements are using energy, and so the superconducting disorders.
2022-03-23 12:24:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:24:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can start with the grows of the face and the basic shape, and through the theft of information, which is all the ports of the whole structure and all the fits.
2022-03-23 12:24:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:24:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen, is that -- well, when dinner dinner was best summarized when someone said, "turn you to the men on your table and tell you," if the revolution starts to support you. "'" the truth is that we've already been supporting women, we've already been supporting them, we've already started to have a pride of silly, "
2022-03-23 12:24:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:24:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're in our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrigeration system that allows us to use a refrigerator of the refrigerator to the air, to be able to be able to be able to be able to use, or if we were able to solve the most propelled by the most propelled by the most propelled by the most prophecy of the most propelled by a mechanism that we had to be able to be able to be able to be able to be able to be able to do it.
2022-03-23 12:24:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:24:43 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.575 | ppl 762.57 | bleu 29.38 | wps 4667.2 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 29.38
2022-03-23 12:24:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 12:24:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:24:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:24:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 29.38) (writing took 1.7713334118016064 seconds)
2022-03-23 12:24:45 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 12:24:45 | INFO | train | epoch 026 | loss 8.23 | ppl 300.26 | wps 39445.9 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.435 | loss_scale 4 | train_wall 58 | gb_free 12.4 | wall 2656
KL Stats: Epoch 26 Divergences: Uniform: 1.120034844857806 Unigram: 1.3011040244096064
2022-03-23 12:24:45 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 12:24:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:24:54 | INFO | train_inner | epoch 027:     23 / 157 loss=8.266, ppl=307.83, wps=31654.6, ups=1.27, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.427, loss_scale=4, train_wall=37, gb_free=12.9, wall=2665
2022-03-23 12:25:32 | INFO | train_inner | epoch 027:    123 / 157 loss=8.192, ppl=292.5, wps=66710, ups=2.66, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.425, loss_scale=4, train_wall=37, gb_free=11.7, wall=2703
2022-03-23 12:25:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:25:48 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:25:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:25:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of you know here.
2022-03-23 12:25:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:25:56 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will become two new pigments.
2022-03-23 12:25:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:26:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:26:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:26:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a few electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:26:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:26:08 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people taking responsibility for wildlife, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 12:26:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:26:12 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught inside the inner, but the superconductor doesn't like moving, because their movements use energy, and so the superconductor disorder.
2022-03-23 12:26:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:26:16 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can begin to restore the grows of the face and the basic form of the information that recontains all the ports structure and all the floods.
2022-03-23 12:26:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:26:20 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it incredibly interesting and measured to me here at tedwomen is that... tyes, when dinner was best summarized when somebody said, "turn you to the men on your table and tell you," 'when the revolution begins, we support you. "the truth is that we've already been supporting you for a long time."
2022-03-23 12:26:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:26:21 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that we're at our airplane at the most staggering toes was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable and refrigeration system that allows us to use in the air, or if you can see the prophecy, or if you can see the propellism.
2022-03-23 12:26:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:26:21 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.573 | ppl 761.64 | bleu 29.12 | wps 5036.1 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.38
2022-03-23 12:26:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 12:26:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:26:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:26:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt (epoch 27 @ 4234 updates, score 29.12) (writing took 0.8014995008707047 seconds)
2022-03-23 12:26:22 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 12:26:22 | INFO | train | epoch 027 | loss 8.169 | ppl 287.91 | wps 40686.6 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.401 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 2753
KL Stats: Epoch 27 Divergences: Uniform: 1.123426997186406 Unigram: 1.3116547505822966
2022-03-23 12:26:22 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 12:26:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:26:47 | INFO | train_inner | epoch 028:     66 / 157 loss=8.193, ppl=292.57, wps=33014.5, ups=1.33, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.376, loss_scale=4, train_wall=37, gb_free=12.8, wall=2778
2022-03-23 12:27:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:27:25 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:27:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:27:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:27:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:27:33 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will be transformed two new pigs.
2022-03-23 12:27:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:27:37 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:27:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:27:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all his thoughts are on the track.
2022-03-23 12:27:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:27:45 | INFO | fairseq.tasks.translation | example hypothesis: and in the corn like people's responsibility for wildlife, the number of wildlife animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 12:27:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:27:49 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside the inner, but the superconductor doesn't like moving, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:27:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:27:53 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic form, and through the one that the whole portion structure and all the folds.
2022-03-23 12:27:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:27:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it highly interesting and measured to me here at tedwomen is that -- well, when dinner was striking, it was best summarized when someone said, "turn you to your desk and say," if the revolution starts supporting you. '"the truth is that we've already supported you for this long time, we've already started to help you with silver harbitors."
2022-03-23 12:27:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:28:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane on the stumber, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to use a refrigeration to the air system, or a refrigeration for the air system, or a refrigerator, to be able, if you can either see the air system that you can solve it, or if you can actually solve it's a specific, you can solve it, or if you can solve it, you can solve it, you can see the mere, you can actually solve it, it, you can actually solve it, it, you can't see the mold, you can actually get the most expensive for the mold old, you can actually solve the mere ere ere ere ere.
2022-03-23 12:28:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:28:00 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.528 | ppl 738.1 | bleu 30.07 | wps 4721.2 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.07
2022-03-23 12:28:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 12:28:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:28:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:28:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.07) (writing took 1.770162952132523 seconds)
2022-03-23 12:28:02 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 12:28:02 | INFO | train | epoch 028 | loss 8.13 | ppl 280.23 | wps 39629.7 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.411 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 2853
KL Stats: Epoch 28 Divergences: Uniform: 1.1235312413933676 Unigram: 1.3124323166582248
2022-03-23 12:28:02 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 12:28:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:28:05 | INFO | train_inner | epoch 029:      9 / 157 loss=8.092, ppl=272.79, wps=32310.8, ups=1.28, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.442, loss_scale=4, train_wall=37, gb_free=11.8, wall=2856
2022-03-23 12:28:43 | INFO | train_inner | epoch 029:    109 / 157 loss=8.103, ppl=274.98, wps=66659.5, ups=2.65, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.381, loss_scale=4, train_wall=37, gb_free=11.7, wall=2894
2022-03-23 12:29:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:29:05 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:29:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:29:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:29:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:29:13 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks.
2022-03-23 12:29:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:29:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:29:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:29:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:29:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:29:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wild animals grew back, and this is a foundation for conservation in namibia.
2022-03-23 12:29:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:29:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like moving, because their movements are using their energy, and so the superconductor disorders.
2022-03-23 12:29:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:29:32 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape, and through the information that pulls all the ports structure and all folds.
2022-03-23 12:29:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:29:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it high-interesting and measured to me here at tedwomen is that... tyes, when striped dinner, it was best summarized when somebody said, "turn to men on your table and say," if the revolution starts. "
2022-03-23 12:29:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:29:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrigeration system that allows us to use in the aircraft, or if you can see the aircraft.
2022-03-23 12:29:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:29:38 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.503 | ppl 725.81 | bleu 29.82 | wps 4937.2 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.07
2022-03-23 12:29:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 12:29:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:29:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:29:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt (epoch 29 @ 4548 updates, score 29.82) (writing took 0.7833112771622837 seconds)
2022-03-23 12:29:39 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 12:29:39 | INFO | train | epoch 029 | loss 8.082 | ppl 270.97 | wps 40649.6 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.393 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 2950
KL Stats: Epoch 29 Divergences: Uniform: 1.1214397367737947 Unigram: 1.3157597602173898
2022-03-23 12:29:39 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 12:29:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:29:59 | INFO | train_inner | epoch 030:     52 / 157 loss=8.098, ppl=273.96, wps=33075, ups=1.32, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.385, loss_scale=4, train_wall=37, gb_free=12.1, wall=2970
2022-03-23 12:30:36 | INFO | train_inner | epoch 030:    152 / 157 loss=8.008, ppl=257.37, wps=67691.3, ups=2.67, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.349, loss_scale=4, train_wall=37, gb_free=12.9, wall=3007
2022-03-23 12:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:30:42 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:30:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:30:46 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 12:30:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:30:50 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will make two new vibrations.
2022-03-23 12:30:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:30:54 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:30:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:30:58 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of your thoughts are on the track.
2022-03-23 12:30:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:31:02 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 12:31:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:31:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught in the inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:31:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:31:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial bar that gives the big constructions of the face and the basic form of information, and through the theast of this information, which pulls the whole portion structure and all the ffolds.
2022-03-23 12:31:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:31:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and measured to me here at tedwomen is that -- well, when dinner was best summarized, when someone said, "turn to the men on your table and say," if the revolution starts to support you for this long time. "
2022-03-23 12:31:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:31:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to use in the aircraft to an aircraft.
2022-03-23 12:31:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:31:17 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.453 | ppl 700.87 | bleu 30.68 | wps 4770.9 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.68
2022-03-23 12:31:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 12:31:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:31:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:31:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.68) (writing took 1.7855948470532894 seconds)
2022-03-23 12:31:18 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 12:31:18 | INFO | train | epoch 030 | loss 8.032 | ppl 261.77 | wps 39597.5 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.355 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3050
KL Stats: Epoch 30 Divergences: Uniform: 1.1221356800589155 Unigram: 1.3209590037215297
2022-03-23 12:31:19 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 12:31:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:31:55 | INFO | train_inner | epoch 031:     95 / 157 loss=7.951, ppl=247.49, wps=32439, ups=1.27, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.376, loss_scale=4, train_wall=37, gb_free=11.7, wall=3086
2022-03-23 12:32:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:32:21 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:32:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:32:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:32:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:32:29 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will create two new pigs.
2022-03-23 12:32:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:32:33 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 12:32:33 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:32:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:32:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:32:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 12:32:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:32:45 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor may not like moving, because their movements use energy, and so the superconducting.
2022-03-23 12:32:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:32:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial bar that restores the grove constructions of the face and the basic shape, and redeconstructs it through the information that refers the whole porter structure and all the fits.
2022-03-23 12:32:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:32:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it high-interesting and measured to me here at tedwomen is that... tyes, when dinner was best summarized, it was the best thing that someone said, "turn you to the men on your table and say," if the revolution begins to support you. "the truth is that we've already started to support you for a long time with silly, and then you've already been stumbled by the future of anxiety," in the future of the future of anxiety of anxiety, "anxiety," anxiety, "and then you know, and then you've already started to go down the future."
2022-03-23 12:32:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:32:56 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a big part of the design work that we are on our airplane on the stumber, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to use in our aircraft to stop, to use, or to use the aircraft, or when you can either drive the propelled, or if you see the propelled, or if you look at the unique problems that, or if you see it's the propellyfish, or if you look at the air conditioning, or if you can either drive, or if you can't see it's going to be able to fly, or you can see it's the same.
2022-03-23 12:32:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:32:56 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.426 | ppl 687.94 | bleu 31.46 | wps 4720.4 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.46
2022-03-23 12:32:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 12:32:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:32:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:32:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.46) (writing took 1.766521280631423 seconds)
2022-03-23 12:32:58 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 12:32:58 | INFO | train | epoch 031 | loss 8.006 | ppl 257.01 | wps 39693 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.363 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3149
KL Stats: Epoch 31 Divergences: Uniform: 1.1225420045020003 Unigram: 1.3236934906380473
2022-03-23 12:32:58 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 12:32:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:33:13 | INFO | train_inner | epoch 032:     38 / 157 loss=8.022, ppl=259.94, wps=31927, ups=1.28, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.328, loss_scale=4, train_wall=37, gb_free=12.5, wall=3164
2022-03-23 12:33:50 | INFO | train_inner | epoch 032:    138 / 157 loss=7.916, ppl=241.59, wps=67257.4, ups=2.66, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.375, loss_scale=4, train_wall=37, gb_free=12.5, wall=3202
2022-03-23 12:33:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:34:01 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:34:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:34:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:34:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:34:09 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will generate two new pigs.
2022-03-23 12:34:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:34:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:34:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:34:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:34:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:34:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife animals grew back, and that's become a foundation for conservation in namibia.
2022-03-23 12:34:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:34:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field are caught inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:34:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:34:29 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial bar that restores the grove constructions of the face and the basic shape, and refining it through the one of the information that pulls the whole porch structure, and all the fine folds.
2022-03-23 12:34:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:34:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that -- well, when dinner, it was best summarized, when someone said, "turn to the men on your table, and we tell them," 'if the revolution begins, then we support you.' '' '"the truth is that we've already been supporting you for a long time, we've already started with silly, and we've started with silly, and then, and then on the future,"
2022-03-23 12:34:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:34:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to use aircraft in the gogos, until you can either see that, until you see them, until you see them, until you're going to be the propelled, or if you're going to the ground, until you can see it, until you're going to a mechanism, until you see it, until you can see it, until you see it, until you can see it, until you can see it, until you can see it, until you're going to the most recently, until you're going to the most recently, until you can see it, until you can see it, until you can see it, or if you're going to a mechanism, until you can see it, until you can see it, until you
2022-03-23 12:34:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:34:36 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.431 | ppl 690.4 | bleu 31.09 | wps 4677.1 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.46
2022-03-23 12:34:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 12:34:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:34:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:34:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.09) (writing took 0.7888703038915992 seconds)
2022-03-23 12:34:37 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 12:34:37 | INFO | train | epoch 032 | loss 7.963 | ppl 249.54 | wps 39914.9 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.357 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 3248
KL Stats: Epoch 32 Divergences: Uniform: 1.124368566817302 Unigram: 1.3298258069714435
2022-03-23 12:34:37 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 12:34:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:35:08 | INFO | train_inner | epoch 033:     81 / 157 loss=7.947, ppl=246.84, wps=32360.1, ups=1.29, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.353, loss_scale=4, train_wall=37, gb_free=12.1, wall=3279
2022-03-23 12:35:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:35:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep beep in the clinic.
2022-03-23 12:35:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:35:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:35:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:35:49 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will make two new pigs.
2022-03-23 12:35:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:35:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:35:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:35:57 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:35:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:36:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the math of how people took responsibility for wildlife, the number of wild animals grew back, and that's become a foundation for conservation in namibia.
2022-03-23 12:36:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:36:05 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are captured inside, but the superconductor may not like moving, because their movements use energy, and so the superconducting disorders.
2022-03-23 12:36:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:36:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape, and redefeat it through the one of that information that pulls the whole porter structure and all the fits.
2022-03-23 12:36:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:36:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured to me here at tedwomen is that... well, when dinner was the best summarized, "turn to the men on your table and tell them," if the revolution starts to support you. "the truth is that we've already been supporting you for a long time,"
2022-03-23 12:36:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:36:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to use in the air to either drive the propelled, to see the most progressive, to the prophecy of a mechanism, to operate it -- all, to operate it on the ground -- from a continuous variable, to a refrigerator, to a refrigerator, to a refrigerator, to a refrigerator, to a refrigerator, to a refrigerator of a refrigerator, to the security system that allows us to the air, to the prophearsal system that allows us to the ground, if you can see, or if you can't see, to the mere ere ere ere ere ere ere ere ere ere ere ere, to the
2022-03-23 12:36:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:36:15 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.372 | ppl 662.8 | bleu 32.49 | wps 4649.8 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.49
2022-03-23 12:36:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 12:36:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:36:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:36:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.49) (writing took 1.8113769949413836 seconds)
2022-03-23 12:36:17 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 12:36:17 | INFO | train | epoch 033 | loss 7.938 | ppl 245.18 | wps 39329.8 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.357 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 3348
KL Stats: Epoch 33 Divergences: Uniform: 1.1220666736708076 Unigram: 1.3302359535560515
2022-03-23 12:36:18 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 12:36:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:36:27 | INFO | train_inner | epoch 034:     24 / 157 loss=7.962, ppl=249.36, wps=31781.1, ups=1.26, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.358, loss_scale=4, train_wall=37, gb_free=12, wall=3358
2022-03-23 12:37:05 | INFO | train_inner | epoch 034:    124 / 157 loss=7.911, ppl=240.62, wps=66722.1, ups=2.65, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.349, loss_scale=4, train_wall=37, gb_free=11.8, wall=3396
2022-03-23 12:37:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:37:21 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:37:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:37:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:37:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:37:29 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks, the two new pigs are going to cross.
2022-03-23 12:37:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:37:33 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:37:33 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:37:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of your thoughts are on the track.
2022-03-23 12:37:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:37:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife, the number of wildanimals grew again, and that's become a foundation for conservation in namibia.
2022-03-23 12:37:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:37:45 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are captured inside, but the superconductor may not, if they move, because their movements use energy, and so the superconducting disorders.
2022-03-23 12:37:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:37:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial bar that gives the big constructions of the face and the basic rehearsal of the information that pulls the whole porter structure and all the fine.
2022-03-23 12:37:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:37:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured, for me here at tedwomen, is that -- well, when dinner was stripped, it was best summarized when someone said, "turn you to the men in your desk and tell you," if the revolution begins, we support you. '"' the truth is that we've already been supporting you for a long time."
2022-03-23 12:37:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:37:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a large part of the design work that we're on our plane on the stumpy, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variable and a cooling system with a refrigeration system that allows us to use aircraft in the go-road to be a specialist, or if you're going to be able to see the propelled in the ground.
2022-03-23 12:37:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:37:56 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.393 | ppl 672.2 | bleu 32.24 | wps 4667.8 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.49
2022-03-23 12:37:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 12:37:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:37:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:37:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt (epoch 34 @ 5333 updates, score 32.24) (writing took 0.7736501302570105 seconds)
2022-03-23 12:37:57 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 12:37:57 | INFO | train | epoch 034 | loss 7.908 | ppl 240.24 | wps 39567 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.361 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 3448
KL Stats: Epoch 34 Divergences: Uniform: 1.1225228605412545 Unigram: 1.3333939881140024
2022-03-23 12:37:57 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 12:37:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:38:23 | INFO | train_inner | epoch 035:     67 / 157 loss=7.847, ppl=230.28, wps=32276.5, ups=1.29, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.374, loss_scale=4, train_wall=37, gb_free=12.9, wall=3474
2022-03-23 12:38:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:39:01 | INFO | fairseq.tasks.translation | example hypothesis: we put up these beep beep in the clinic.
2022-03-23 12:39:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:39:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:39:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:39:08 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will create two new pigs transcend.
2022-03-23 12:39:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:39:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pepper.
2022-03-23 12:39:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:39:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:39:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:39:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife animals grew back again, and that's become a foundation for conservation in namibia.
2022-03-23 12:39:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:39:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor may not like moving, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:39:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:39:28 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape of the information that includes all the porting structure and all the fine folds.
2022-03-23 12:39:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:39:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here for me at tedwomen is that -- well, when dinner was best summarized, when somebody said, "turn you to the men on your table and say," when the revolution begins, we support you. "'" the truth, women is that we've already been supporting you for a long time. "
2022-03-23 12:39:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:39:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane on the stumber, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variable and a refrigeration system that allows us to use aircraft on the go-road to use until you either see the propelled, or if you're on the ground, or if you're going to fly it to the aircraft, or if you're going to go to the aircraft that you're going to the aircraft that you're going to the air conditioning, you're going to the ground, you're going to the air conditioning, or if you're going to the ground, you're going to the air, you're going to see it, you're going to the ground, you're going to see it, or if you're going to see it, you're going to go to
2022-03-23 12:39:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:39:35 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.342 | ppl 648.79 | bleu 32.65 | wps 4780.8 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.65
2022-03-23 12:39:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 12:39:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:39:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:39:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 35 @ 5490 updates, score 32.65) (writing took 1.7591927372850478 seconds)
2022-03-23 12:39:37 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 12:39:37 | INFO | train | epoch 035 | loss 7.875 | ppl 234.71 | wps 39681 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.33 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3548
KL Stats: Epoch 35 Divergences: Uniform: 1.1222731411715998 Unigram: 1.3375448164855341
2022-03-23 12:39:37 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 12:39:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:39:41 | INFO | train_inner | epoch 036:     10 / 157 loss=7.969, ppl=250.56, wps=31673.2, ups=1.27, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.312, loss_scale=4, train_wall=37, gb_free=12.8, wall=3552
2022-03-23 12:40:19 | INFO | train_inner | epoch 036:    110 / 157 loss=7.838, ppl=228.88, wps=66840.2, ups=2.64, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.339, loss_scale=4, train_wall=37, gb_free=12.9, wall=3590
2022-03-23 12:40:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:40:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 12:40:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:40:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 12:40:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:40:48 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will create two new pigs transcend.
2022-03-23 12:40:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:40:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:40:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:40:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:40:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:41:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife, the number of wildanimals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 12:41:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:41:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconduction disturbs.
2022-03-23 12:41:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:41:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic form of the face, and reconcile it through the one of the things that refers the whole porter structure and all the fine folds.
2022-03-23 12:41:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:41:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate to be here for me at tedwomen is that... tyes, when dinner was the best summarized, when someone said, "turn you to the men on your table and tell them," 'if the revolution begins, we support you.' "] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 12:41:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:41:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on at our plane, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigerator system, and a refrigerator with liquid fluid, that allows us to see the fastest to the ground, or if you're going to be the propelled to the ground, or if you're going to run the ground, or you're going to the steady, or you're going to the steady, or you're going to the steady, you're going to the steady, and you're going to the steady, you're going to the steady, you're going to the bumped to the steady, you're going to the steady, you're going to the ground, and you're going to the burial it, or you're going to the
2022-03-23 12:41:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:41:16 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.364 | ppl 659.09 | bleu 32.67 | wps 4559 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.67
2022-03-23 12:41:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 12:41:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:41:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:41:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.67) (writing took 1.7890560911037028 seconds)
2022-03-23 12:41:18 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 12:41:18 | INFO | train | epoch 036 | loss 7.862 | ppl 232.72 | wps 38938.3 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.364 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 3649
KL Stats: Epoch 36 Divergences: Uniform: 1.1237319247144626 Unigram: 1.3369757964208484
2022-03-23 12:41:18 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 12:41:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:41:38 | INFO | train_inner | epoch 037:     53 / 157 loss=7.716, ppl=210.31, wps=32171.2, ups=1.26, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.372, loss_scale=4, train_wall=37, gb_free=12.8, wall=3670
2022-03-23 12:42:16 | INFO | train_inner | epoch 037:    153 / 157 loss=7.954, ppl=247.93, wps=66352.3, ups=2.67, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.323, loss_scale=4, train_wall=37, gb_free=11.7, wall=3707
2022-03-23 12:42:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:42:21 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:42:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:42:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:42:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:42:29 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:42:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:42:33 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pills.
2022-03-23 12:42:33 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:42:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all your thoughts are on the track.
2022-03-23 12:42:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:42:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility to the wildlife, the number of wild animals grew back, and this has become a basis for conservation in namibia.
2022-03-23 12:42:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:42:46 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the clubs of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and the superconductor disorders.
2022-03-23 12:42:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:42:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constructions of the face and repair it through the thief information that refers the whole pork structure and all the fine folds.
2022-03-23 12:42:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:42:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen is that -- well, in the dinner dinner dinner, it was best summarized when someone said, "turn you to the men on your table and say," if the revolution starts supporting you. "'" the truth, women is that we've been supporting you at this topic for a long time. at rachel, we've already been supporting you. at a time, and we've already started off with a time. "
2022-03-23 12:42:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:42:57 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on on our airplane is a result that we had to solve the unique problems that were connected to doing it on the ground -- all, from a continuous variation and a cooling system with fluid that allows us to use an aircraft on the top of the aircraft in the go-traffic, to a special transportation, to an aircraft, to a particular passage, to an aircraft where we're going, or an aircraft that's either when you're going to be in the storm, you're going.
2022-03-23 12:42:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:42:57 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.322 | ppl 640.12 | bleu 32.83 | wps 4618.2 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.83
2022-03-23 12:42:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 12:42:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:42:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:42:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 32.83) (writing took 1.7844326319172978 seconds)
2022-03-23 12:42:58 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 12:42:58 | INFO | train | epoch 037 | loss 7.834 | ppl 228.22 | wps 39345.3 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.325 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 3750
KL Stats: Epoch 37 Divergences: Uniform: 1.124442895892918 Unigram: 1.3404897812140262
2022-03-23 12:42:59 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 12:42:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:43:35 | INFO | train_inner | epoch 038:     96 / 157 loss=8.006, ppl=257.02, wps=31104.3, ups=1.26, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.348, loss_scale=4, train_wall=37, gb_free=12.6, wall=3786
2022-03-23 12:43:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:44:01 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:44:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:44:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:44:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:44:09 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:44:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:44:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pills.
2022-03-23 12:44:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:44:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:44:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:44:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew back, and that's become a foundation for conservation in namibia.
2022-03-23 12:44:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:44:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic fields are caught in the inside, but the superconductor doesn't like it when they move, because they use their movements, and so the superconductive disorder.
2022-03-23 12:44:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:44:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic form, and repair it through the last information that refers the whole porch structure and all the fine.
2022-03-23 12:44:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:44:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured to me here at tedwomen is that -- well, when dinner was stripped, it was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins, then we support you. "the truth, women, we've already been supporting you for a long time."
2022-03-23 12:44:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:44:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're on our airplane on the most staggering was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft in go-transportation to a specific traffic machine, either when you can see the prophecy, or an aircraft in a particular vehicle that you can see the propeller, or the prophecy system that you can see the prophecy of the most propelled the most propeller, or a mechanism of an aircraft that you can see the most sophisticated problems that you can see the most sophisticated problems that you can see the most sophisticated problems that you can see in the most sophisticated, or the ground, if you can see when you can see it's the earth, you can see it's the most sophisticated, the
2022-03-23 12:44:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:44:36 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.312 | ppl 635.74 | bleu 32.75 | wps 4713.1 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 32.83
2022-03-23 12:44:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 12:44:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:44:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:44:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 32.75) (writing took 0.8172164591960609 seconds)
2022-03-23 12:44:37 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 12:44:37 | INFO | train | epoch 038 | loss 7.825 | ppl 226.82 | wps 40019.9 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.351 | loss_scale 4 | train_wall 58 | gb_free 13.1 | wall 3848
KL Stats: Epoch 38 Divergences: Uniform: 1.1234787955236614 Unigram: 1.342841212555492
2022-03-23 12:44:37 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 12:44:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:44:53 | INFO | train_inner | epoch 039:     39 / 157 loss=7.555, ppl=188.01, wps=33637.4, ups=1.29, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.32, loss_scale=4, train_wall=37, gb_free=11.8, wall=3864
2022-03-23 12:45:30 | INFO | train_inner | epoch 039:    139 / 157 loss=7.858, ppl=231.93, wps=66271, ups=2.67, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.359, loss_scale=4, train_wall=37, gb_free=12.8, wall=3901
2022-03-23 12:45:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:45:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 12:45:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:45:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:45:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:45:48 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:45:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:45:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:45:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:45:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all of the thoughts are on the track.
2022-03-23 12:45:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:46:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the case like the people took responsibility for the wildlife, the number of wild animals grew back, and that's become a foundation for conservation in namibia.
2022-03-23 12:46:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:46:05 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic fields are trapped inside, but the superconductor doesn't like it when they move, because they use their movements, and that's how the superconduction boils.
2022-03-23 12:46:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:46:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial bar that will restore the big constructions of the face and recover the basic form, and repair it through that information that refers the whole porter structure and all the fine folds.
2022-03-23 12:46:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:46:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that -- well, when i was striking dinner, it was best summarized when someone said, "turn you to the men on your table and tell them," if the revolution begins, then we support you. "the truth, women, we've already been supporting you with this topic for a long time."
2022-03-23 12:46:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:46:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane is the most stumbling, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variable and a cooling system with liquid, that it allows us to use an aircraft in the gains and go-traffic to a specialized drive, or if you fly the most propelled, or if you see the most propelled or the ground, or the proper capita mechanism of a cerestate of a cerestate of a cerebellum, or a mechanism, or a storm, or a mechanism, or a storm, or a storage, or a car system that's going to the crashes in the earth, or a storm of a storm of a storm that's going to the earth.
2022-03-23 12:46:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:46:16 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.302 | ppl 631.14 | bleu 33.41 | wps 4606.2 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.41
2022-03-23 12:46:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 12:46:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:46:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:46:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 33.41) (writing took 1.7478889902122319 seconds)
2022-03-23 12:46:18 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 12:46:18 | INFO | train | epoch 039 | loss 7.795 | ppl 222.14 | wps 39267.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.331 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 3949
KL Stats: Epoch 39 Divergences: Uniform: 1.123273139818178 Unigram: 1.3450446777077634
2022-03-23 12:46:18 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 12:46:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:46:49 | INFO | train_inner | epoch 040:     82 / 157 loss=7.863, ppl=232.85, wps=31348.3, ups=1.26, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.298, loss_scale=4, train_wall=37, gb_free=12.2, wall=3980
2022-03-23 12:47:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:47:21 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep beep in the clinic.
2022-03-23 12:47:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:47:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:47:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:47:29 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:47:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:47:33 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pills.
2022-03-23 12:47:33 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:47:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:47:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:47:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew back, and that's become a foundation for conservation in namibia.
2022-03-23 12:47:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:47:45 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and the superconduction disturbs.
2022-03-23 12:47:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:47:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big constructions of the face and the basic form back, and reconstructs it through the information that refers the whole porter structure and all the fine folds.
2022-03-23 12:47:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:47:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn you to the men on your desk and tell them," when the revolution begins, we support you. '"'" '"the truth, women, we've already been supporting you with this topic for a long time."
2022-03-23 12:47:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:47:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems that were linked to operate on the ground -- everything, from a continuous variation and a cooling system, that allows us to use an aircraft in the go-traffic, to be a specific driver, either if you fly the propelled, to the ground, or if you see the propelled, the most progressively propelled, to the earth, to the earth, to be the degraded by which you can see it, from a mechanism that you can see it's the degraded, or if you can see it's the earth, to the ground, to the earth, to the degraded, to the earth.
2022-03-23 12:47:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:47:56 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.306 | ppl 633.17 | bleu 33.35 | wps 4686 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.41
2022-03-23 12:47:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 12:47:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:47:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:47:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 33.35) (writing took 0.8016685610637069 seconds)
2022-03-23 12:47:57 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 12:47:57 | INFO | train | epoch 040 | loss 7.767 | ppl 217.86 | wps 39839.4 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.307 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 4048
KL Stats: Epoch 40 Divergences: Uniform: 1.1246841234909144 Unigram: 1.3511820101299885
2022-03-23 12:47:57 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 12:47:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:48:07 | INFO | train_inner | epoch 041:     25 / 157 loss=7.725, ppl=211.57, wps=32841.8, ups=1.29, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.322, loss_scale=4, train_wall=37, gb_free=12.6, wall=4058
2022-03-23 12:48:44 | INFO | train_inner | epoch 041:    125 / 157 loss=7.77, ppl=218.21, wps=66036, ups=2.65, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.326, loss_scale=4, train_wall=37, gb_free=12, wall=4096
2022-03-23 12:48:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:49:00 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 12:49:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:49:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:49:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:49:08 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to transcend two new pigs.
2022-03-23 12:49:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:49:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:49:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:49:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:49:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:49:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent, as people took responsibility for wildlife, the number of wildlife grew up again, and that's become a foundation for conservation in namibia.
2022-03-23 12:49:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:49:25 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements are using energy, and so the superconducting disorders.
2022-03-23 12:49:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:49:29 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face that refers the big constructions of the face and the basic form, and reconcile it through the one that refers the whole porter structure and all the fine wrinkles.
2022-03-23 12:49:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:49:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, at dinner, it was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins, we support you. "'"' "the truth, women is that we've already been supporting you with this topic for a long time."
2022-03-23 12:49:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:49:35 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously varied variable system and a refrigeration system that allows us to use an aircraft in stop and go-traffic until a particular passenger, either when you fly the propelled ground, or you can see the propelled, all the way down to a mechanism.
2022-03-23 12:49:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:49:35 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.264 | ppl 614.94 | bleu 33.59 | wps 4737 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.59
2022-03-23 12:49:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 12:49:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:49:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:49:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 33.59) (writing took 1.7819238896481693 seconds)
2022-03-23 12:49:37 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 12:49:37 | INFO | train | epoch 041 | loss 7.758 | ppl 216.46 | wps 39565.2 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.325 | loss_scale 4 | train_wall 58 | gb_free 11.7 | wall 4148
KL Stats: Epoch 41 Divergences: Uniform: 1.1224507237664758 Unigram: 1.3477466271113963
2022-03-23 12:49:37 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 12:49:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:50:02 | INFO | train_inner | epoch 042:     68 / 157 loss=7.713, ppl=209.78, wps=32162.5, ups=1.28, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.32, loss_scale=4, train_wall=37, gb_free=22.3, wall=4174
2022-03-23 12:50:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:50:40 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 12:50:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:50:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 12:50:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:50:48 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-23 12:50:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:50:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-23 12:50:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:50:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:50:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:50:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent like people's responsibility for wildlife, the number of wild animals grew back. and this has become a foundation for conservation in namibia.
2022-03-23 12:50:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:51:04 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements are using energy, and so the superconducting disorder.
2022-03-23 12:51:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:51:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic form, and recover it through the information that refers the whole por-structure and all the fine folds.
2022-03-23 12:51:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:51:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when dinner was stripped, it was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins, we support you. "'" the truth, love, women, is that we have already supported you in this topic for a long time. rachel silly and then "
2022-03-23 12:51:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:51:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously varied variables and a cooling system with refrigeration that allows us to use an aircraft in stop and go-transport to a particular vehicle that is either when you fly the earth or when you see the propelled to the ground.
2022-03-23 12:51:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:51:14 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.291 | ppl 626.59 | bleu 33.28 | wps 4836.3 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.59
2022-03-23 12:51:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 12:51:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:51:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:51:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt (epoch 42 @ 6589 updates, score 33.28) (writing took 0.7822593138553202 seconds)
2022-03-23 12:51:15 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 12:51:15 | INFO | train | epoch 042 | loss 7.733 | ppl 212.7 | wps 40288.3 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.309 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 4246
KL Stats: Epoch 42 Divergences: Uniform: 1.1250855702444837 Unigram: 1.355949613131966
2022-03-23 12:51:15 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 12:51:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:51:19 | INFO | train_inner | epoch 043:     11 / 157 loss=7.691, ppl=206.7, wps=33213.1, ups=1.3, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.296, loss_scale=4, train_wall=37, gb_free=12.1, wall=4251
2022-03-23 12:51:57 | INFO | train_inner | epoch 043:    111 / 157 loss=7.767, ppl=217.87, wps=66374.5, ups=2.67, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.33, loss_scale=4, train_wall=37, gb_free=11.9, wall=4288
2022-03-23 12:52:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:52:18 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep beep in the clinic.
2022-03-23 12:52:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:52:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:52:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:52:26 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-23 12:52:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:52:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:52:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:52:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:52:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:52:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildanimals grew back, and it's become a basis for conservation in namibia.
2022-03-23 12:52:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:52:42 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and the superconduction boils.
2022-03-23 12:52:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:52:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial bar that restores the big constructions of the face and the basic form of the ground, and repair it through the information that attracts the whole porter structure and all the fine folds.
2022-03-23 12:52:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:52:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to be appropriate for me here at tedwomen is that... well, at dinner, the best time when someone said, "turn to the men on your table and tell them," when the revolution starts to support you. "'when the truth starts to support you.'" 'the truth is that we've already been supporting you with this topic for a long time, rachel siltheo's life, "to download the future of us."
2022-03-23 12:52:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:52:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable gear and a cooling system of refrigeration, that allows us to use an aircraft on stop and go-traffic to a particular vehicle vehicle that is either driving the propelled, or when you run the soil to a mechanism that's the ground, all the way down the way that you see the way that you see the way that you see the aircraft that's going to fly.
2022-03-23 12:52:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:52:52 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.273 | ppl 618.51 | bleu 33.77 | wps 4740.6 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.77
2022-03-23 12:52:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 12:52:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:52:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:52:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 43 @ 6746 updates, score 33.77) (writing took 1.80356217129156 seconds)
2022-03-23 12:52:54 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 12:52:54 | INFO | train | epoch 043 | loss 7.722 | ppl 211.1 | wps 39606.5 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.317 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 4345
KL Stats: Epoch 43 Divergences: Uniform: 1.1241106986355658 Unigram: 1.3553782918218733
2022-03-23 12:52:55 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 12:52:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:53:15 | INFO | train_inner | epoch 044:     54 / 157 loss=7.788, ppl=221.01, wps=31759.1, ups=1.28, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.334, loss_scale=4, train_wall=37, gb_free=12.3, wall=4366
2022-03-23 12:53:53 | INFO | train_inner | epoch 044:    154 / 157 loss=7.625, ppl=197.41, wps=68328.8, ups=2.67, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.3, loss_scale=4, train_wall=37, gb_free=12, wall=4404
2022-03-23 12:53:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:53:58 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 12:53:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:54:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:54:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:54:05 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-23 12:54:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:54:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:54:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:54:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:54:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:54:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent as people took responsibility for wildlife, the number of wildanimals grew back, and this has become a foundation for conservation in namibia.
2022-03-23 12:54:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:54:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because they use their movements, and they bother the superconduction.
2022-03-23 12:54:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:54:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructions of the face and reconcile the basic shape, and reconstruct it through the information that refers the whole por-structure and all the fine wrinkles.
2022-03-23 12:54:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:54:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when i'm striking dinner, it's best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins, let's support you. "the truth, women, we've been supporting you with this topic for a long time."
2022-03-23 12:54:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:54:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane is a pristine, a result that we had to solve the unique problems that were connected to operate on the ground -- all, from a continuously varied gear and a refrigerator system that allows us to use an aircraft on stop and go-transport to a particular driving, either when you fly, or you see the propeller, to the ground, all the way down to the ground, all the way down to the way down to the cables.
2022-03-23 12:54:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:54:32 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.273 | ppl 618.56 | bleu 33.77 | wps 4817.7 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.77
2022-03-23 12:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 12:54:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:54:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt
2022-03-23 12:54:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_best.pt (epoch 44 @ 6903 updates, score 33.77) (writing took 1.8713743290863931 seconds)
2022-03-23 12:54:33 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 12:54:33 | INFO | train | epoch 044 | loss 7.709 | ppl 209.19 | wps 39806.7 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.323 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 4445
KL Stats: Epoch 44 Divergences: Uniform: 1.1260137321426065 Unigram: 1.3585373561333334
2022-03-23 12:54:34 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 12:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:55:11 | INFO | train_inner | epoch 045:     97 / 157 loss=7.579, ppl=191.18, wps=32795.3, ups=1.28, wpb=25640.8, bsz=1040.4, num_updates=7000, lr=0.000377964, gnorm=0.31, loss_scale=4, train_wall=37, gb_free=12.7, wall=4482
2022-03-23 12:55:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:55:37 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 12:55:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:55:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:55:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:55:44 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-23 12:55:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:55:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:55:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:55:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 12:55:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:55:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people were responsible for the wildlife, the number of wildanimals grew back, and that's become a basis for conservation in namibia.
2022-03-23 12:55:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:56:01 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they're moving, because their movements are using energy, and the superconductions are disturbing.
2022-03-23 12:56:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:56:05 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big contents of the face and reconcile it through the information that refers the whole porter structure and all the fine wrinkles.
2022-03-23 12:56:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:56:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, at dinner, it was the best summarized when somebody said, "turn to the men on your table and tell them," when the revolution starts to support you. "the truth is that we've already been supporting women for a long time."
2022-03-23 12:56:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:56:11 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, we still need to solve the mother of invention, and a large part of the design work that we're on our plane on the stumbling, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously varied variable and a refrigeration system that allows us to use an aircraft in stop and transportation to a particular passage, to the ground, or when you're going to be the propelled, to the safety system, to the deployed, or when you're going to run the promoting mechanism, to the deploy, to the deploy, to the deployment of an aircraft that you're going to the deploy, to the deploy, to the deployment of one that you're going to the deployment of the depositing, to the deployment of the deployment of one that you're going to the deployment
2022-03-23 12:56:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:56:11 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.251 | ppl 609.43 | bleu 33.76 | wps 4781.1 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.77
2022-03-23 12:56:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 12:56:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:56:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:56:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt (epoch 45 @ 7060 updates, score 33.76) (writing took 0.8410919760353863 seconds)
2022-03-23 12:56:12 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 12:56:12 | INFO | train | epoch 045 | loss 7.699 | ppl 207.79 | wps 40173.1 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.335 | loss_scale 4 | train_wall 58 | gb_free 13.2 | wall 4543
KL Stats: Epoch 45 Divergences: Uniform: 1.1234704569074645 Unigram: 1.3570166164641373
2022-03-23 12:56:12 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 12:56:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:56:27 | INFO | train_inner | epoch 046:     40 / 157 loss=7.889, ppl=237.02, wps=31824.5, ups=1.31, wpb=24304.7, bsz=957.9, num_updates=7100, lr=0.000375293, gnorm=0.35, loss_scale=4, train_wall=36, gb_free=12.4, wall=4558
2022-03-23 12:57:05 | INFO | train_inner | epoch 046:    140 / 157 loss=7.612, ppl=195.63, wps=67379.3, ups=2.65, wpb=25441.7, bsz=1021.5, num_updates=7200, lr=0.000372678, gnorm=0.301, loss_scale=4, train_wall=37, gb_free=11.7, wall=4596
2022-03-23 12:57:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:57:16 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep beep in the clinic.
2022-03-23 12:57:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:57:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:57:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:57:23 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks revenues that will transcend two new pigs.
2022-03-23 12:57:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:57:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:57:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:57:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 12:57:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:57:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent, as people took responsibility for wildlife, the number of wild animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 12:57:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:57:39 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy and bother the superconduction.
2022-03-23 12:57:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:57:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big configurations of the face and the basic form, and reconstruct it through the information that refers the whole porter structure and all the fine folds.
2022-03-23 12:57:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:57:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here for me at tedwomen is that -- well, when stripped dinner, it was best summarized when somebody said, "turn to the men on your table and say," when the revolution starts to support you. "'the truth, women, we've already been supporting you with this topic for a long time." rachel carspring's "
2022-03-23 12:57:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:57:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- all, from a continuously varied, and a refrigeration system that allows us to use an aircraft machine in stop-go-traffic, to a specific driver, to either drive the propeller, to the ground, to the fall of the security system, to the security system that we're going to see.
2022-03-23 12:57:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:57:49 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.256 | ppl 611.21 | bleu 33.75 | wps 4952.9 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 33.77
2022-03-23 12:57:49 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 12:57:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-23 12:57:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:57:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt
2022-03-23 12:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#1/checkpoint_last.pt (epoch 46 @ 7217 updates, score 33.75) (writing took 0.8967759651131928 seconds)
2022-03-23 12:57:50 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 12:57:50 | INFO | train | epoch 046 | loss 7.675 | ppl 204.39 | wps 40400 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.308 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 4641
2022-03-23 12:57:50 | INFO | fairseq_cli.train | done training in 4640.3 seconds
