Sender: LSF System <lsfadmin@eu-g2-08>
Subject: Job 202287071: <w2_jelinek_0.11_-0.01_0.9> in cluster <euler> Exited

Job <w2_jelinek_0.11_-0.01_0.9> was submitted from host <eu-login-22> by user <andriusb> in cluster <euler> at Fri Jan 28 07:37:24 2022
Job was executed on host(s) <eu-g2-08>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Fri Jan 28 07:37:51 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Fri Jan 28 07:37:51 2022
Terminated at Sat Jan 29 03:37:58 2022
Results reported at Sat Jan 29 03:37:58 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.11, -0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72806.19 sec.
    Max Memory :                                 6068 MB
    Average Memory :                             3680.98 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13932.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72006 sec.
    Turnaround time :                            72034 sec.

The output (if any) follows:

2022-01-28 07:38:05 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.11, -0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-28 07:38:06 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-28 07:38:07 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▎         | 1367/36718 [00:00<00:02, 13667.34it/s]  7%|▋         | 2734/36718 [00:00<00:02, 13119.70it/s] 12%|█▏        | 4242/36718 [00:00<00:02, 13993.50it/s] 16%|█▌        | 5814/36718 [00:00<00:02, 14663.70it/s] 20%|█▉        | 7283/36718 [00:00<00:02, 13983.09it/s] 24%|██▎       | 8688/36718 [00:00<00:02, 13467.83it/s] 27%|██▋       | 10081/36718 [00:00<00:01, 13608.49it/s] 31%|███       | 11447/36718 [00:00<00:01, 13378.64it/s] 35%|███▍      | 12814/36718 [00:00<00:01, 13464.37it/s] 39%|███▊      | 14196/36718 [00:01<00:01, 13566.81it/s] 42%|████▏     | 15580/36718 [00:01<00:01, 13642.82it/s] 46%|████▌     | 16946/36718 [00:01<00:01, 13417.05it/s] 50%|████▉     | 18299/36718 [00:01<00:01, 13440.71it/s] 54%|█████▍    | 19823/36718 [00:01<00:01, 13970.76it/s] 58%|█████▊    | 21222/36718 [00:01<00:01, 13706.79it/s] 62%|██████▏   | 22595/36718 [00:01<00:01, 13582.89it/s] 66%|██████▌   | 24117/36718 [00:01<00:00, 14060.00it/s] 70%|██████▉   | 25651/36718 [00:01<00:00, 14435.57it/s] 74%|███████▍  | 27097/36718 [00:01<00:00, 13896.77it/s] 78%|███████▊  | 28562/36718 [00:02<00:00, 14114.51it/s] 82%|████████▏ | 29978/36718 [00:02<00:00, 13956.85it/s] 85%|████████▌ | 31377/36718 [00:02<00:00, 13473.59it/s] 89%|████████▉ | 32730/36718 [00:02<00:00, 13259.74it/s] 93%|█████████▎| 34060/36718 [00:02<00:00, 13005.13it/s] 97%|█████████▋| 35436/36718 [00:02<00:00, 13213.62it/s]100%|██████████| 36718/36718 [00:02<00:00, 13619.90it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  7%|▋         | 2710/36718 [00:00<00:01, 27096.34it/s] 16%|█▌        | 5729/36718 [00:00<00:01, 28912.97it/s] 23%|██▎       | 8621/36718 [00:00<00:01, 27396.16it/s] 31%|███       | 11370/36718 [00:00<00:00, 27423.17it/s] 39%|███▊      | 14183/36718 [00:00<00:00, 27667.39it/s] 46%|████▌     | 16954/36718 [00:00<00:00, 27628.54it/s] 54%|█████▍    | 19793/36718 [00:00<00:00, 27861.56it/s] 62%|██████▏   | 22582/36718 [00:00<00:00, 27600.58it/s] 70%|██████▉   | 25616/36718 [00:00<00:00, 28439.26it/s] 78%|███████▊  | 28463/36718 [00:01<00:00, 27803.35it/s] 85%|████████▌ | 31248/36718 [00:01<00:00, 27314.55it/s] 93%|█████████▎| 33984/36718 [00:01<00:00, 26970.10it/s]100%|██████████| 36718/36718 [00:01<00:00, 27532.79it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.08it/s]2022-01-28 07:38:29 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-28 07:38:29 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-28 07:38:29 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-28 07:38:29 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-28 07:38:29 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-28 07:38:29 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-28 07:38:29 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-28 07:38:29 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-28 07:38:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-28 07:38:29 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-01-28 07:38:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-28 07:38:29 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-28 07:38:29 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-28 07:38:29 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint_last.pt
2022-01-28 07:38:29 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint_last.pt
2022-01-28 07:38:29 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-28 07:38:29 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-28 07:38:29 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-28 07:38:29 | INFO | fairseq.trainer | begin training epoch 1
2022-01-28 07:38:29 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-28 07:43:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-28 07:44:24 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.719 | ppl 26972.1 | wps 7903.3 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-28 07:44:24 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-28 07:44:24 | INFO | train | epoch 001 | loss 16.136 | ppl 71992.6 | wps 5908.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.202 | train_wall 326 | gb_free 6.1 | wall 355
KL Stats: Epoch 1 Divergences: Uniform: 0.5171106382047024 Unigram: 3.6858789449895797
2022-01-28 07:44:24 | INFO | fairseq.trainer | begin training epoch 2
2022-01-28 07:44:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:47:28 | INFO | train_inner | epoch 002:     36 / 64 loss=15.602, ppl=49731.4, wps=6085, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.623, train_wall=509, gb_free=6.1, wall=539
2022-01-28 07:49:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:50:17 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.729 | ppl 13581.3 | wps 7907 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-28 07:50:17 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-28 07:50:17 | INFO | train | epoch 002 | loss 14.447 | ppl 22336.3 | wps 5916.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.477 | train_wall 324 | gb_free 6.1 | wall 708
KL Stats: Epoch 2 Divergences: Uniform: 0.533560633236072 Unigram: 2.4169236367086384
2022-01-28 07:50:17 | INFO | fairseq.trainer | begin training epoch 3
2022-01-28 07:50:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:55:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:56:10 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.917 | ppl 7734.78 | wps 7927.9 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-28 07:56:10 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-28 07:56:10 | INFO | train | epoch 003 | loss 13.555 | ppl 12038 | wps 5924.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.19 | train_wall 324 | gb_free 6.1 | wall 1061
KL Stats: Epoch 3 Divergences: Uniform: 0.5162869045801074 Unigram: 1.7356846949496483
2022-01-28 07:56:10 | INFO | fairseq.trainer | begin training epoch 4
2022-01-28 07:56:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:56:51 | INFO | train_inner | epoch 004:      8 / 64 loss=13.687, ppl=13186.1, wps=5793.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.219, train_wall=506, gb_free=6.1, wall=1101
2022-01-28 08:01:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:02:03 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.084 | ppl 4340.64 | wps 7911.9 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-28 08:02:03 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-28 08:02:03 | INFO | train | epoch 004 | loss 12.618 | ppl 6284.38 | wps 5920.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.947 | train_wall 324 | gb_free 6.1 | wall 1413
KL Stats: Epoch 4 Divergences: Uniform: 0.5977791940112988 Unigram: 1.1260147594738896
2022-01-28 08:02:03 | INFO | fairseq.trainer | begin training epoch 5
2022-01-28 08:02:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:05:47 | INFO | train_inner | epoch 005:     44 / 64 loss=12.274, ppl=4951.8, wps=6092.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.834, train_wall=507, gb_free=6.1, wall=1638
2022-01-28 08:07:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:07:56 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.571 | ppl 3042.87 | wps 7904.3 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-28 08:07:56 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-28 08:07:56 | INFO | train | epoch 005 | loss 11.834 | ppl 3651.25 | wps 5918 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.681 | train_wall 324 | gb_free 6.1 | wall 1766
KL Stats: Epoch 5 Divergences: Uniform: 0.8302719691463222 Unigram: 0.6766878780237157
2022-01-28 08:07:56 | INFO | fairseq.trainer | begin training epoch 6
2022-01-28 08:07:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:13:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:13:49 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.325 | ppl 2565.28 | wps 7899.8 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-28 08:13:49 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-28 08:13:49 | INFO | train | epoch 006 | loss 11.408 | ppl 2718.18 | wps 5913.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.581 | train_wall 325 | gb_free 6.1 | wall 2120
KL Stats: Epoch 6 Divergences: Uniform: 1.1180389069262155 Unigram: 0.4816152227226491
2022-01-28 08:13:49 | INFO | fairseq.trainer | begin training epoch 7
2022-01-28 08:13:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:15:11 | INFO | train_inner | epoch 007:     16 / 64 loss=11.431, ppl=2760.11, wps=5786.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.579, train_wall=507, gb_free=6.1, wall=2201
2022-01-28 08:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:19:42 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.179 | ppl 2318.3 | wps 7910.1 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-28 08:19:42 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-28 08:19:42 | INFO | train | epoch 007 | loss 11.209 | ppl 2366.67 | wps 5914 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.523 | train_wall 325 | gb_free 6.1 | wall 2473
KL Stats: Epoch 7 Divergences: Uniform: 1.3326223716701977 Unigram: 0.4965568794391444
2022-01-28 08:19:42 | INFO | fairseq.trainer | begin training epoch 8
2022-01-28 08:19:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:24:07 | INFO | train_inner | epoch 008:     52 / 64 loss=11.147, ppl=2267.25, wps=6091.9, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.517, train_wall=508, gb_free=6.1, wall=2738
2022-01-28 08:25:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:25:34 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.072 | ppl 2152.22 | wps 7932.6 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-28 08:25:34 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-28 08:25:34 | INFO | train | epoch 008 | loss 11.094 | ppl 2186.43 | wps 5924.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.512 | train_wall 324 | gb_free 6.1 | wall 2825
KL Stats: Epoch 8 Divergences: Uniform: 1.441088107761361 Unigram: 0.5781758444816125
2022-01-28 08:25:34 | INFO | fairseq.trainer | begin training epoch 9
2022-01-28 08:25:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:31:27 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.953 | ppl 1981.77 | wps 7907.1 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-28 08:31:27 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-28 08:31:27 | INFO | train | epoch 009 | loss 10.986 | ppl 2027.84 | wps 5932.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.485 | train_wall 324 | gb_free 6.1 | wall 3177
KL Stats: Epoch 9 Divergences: Uniform: 1.48232923694785 Unigram: 0.6909154184225449
2022-01-28 08:31:27 | INFO | fairseq.trainer | begin training epoch 10
2022-01-28 08:31:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:33:29 | INFO | train_inner | epoch 010:     24 / 64 loss=10.976, ppl=2014.52, wps=5800.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.487, train_wall=505, gb_free=6.1, wall=3300
2022-01-28 08:36:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:37:19 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.845 | ppl 1839.79 | wps 7884.3 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-28 08:37:19 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-28 08:37:19 | INFO | train | epoch 010 | loss 10.873 | ppl 1875.96 | wps 5918.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.483 | train_wall 324 | gb_free 6.1 | wall 3530
KL Stats: Epoch 10 Divergences: Uniform: 1.5051192626707617 Unigram: 0.815548152644212
2022-01-28 08:37:19 | INFO | fairseq.trainer | begin training epoch 11
2022-01-28 08:37:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:42:26 | INFO | train_inner | epoch 011:     60 / 64 loss=10.796, ppl=1777.34, wps=6090.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.494, train_wall=507, gb_free=6.1, wall=3836
2022-01-28 08:42:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:43:12 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.736 | ppl 1705.87 | wps 7911.4 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-28 08:43:12 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-28 08:43:12 | INFO | train | epoch 011 | loss 10.755 | ppl 1727.8 | wps 5918.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.498 | train_wall 324 | gb_free 6.1 | wall 3883
KL Stats: Epoch 11 Divergences: Uniform: 1.5223130737470618 Unigram: 0.9408259592847829
2022-01-28 08:43:12 | INFO | fairseq.trainer | begin training epoch 12
2022-01-28 08:43:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:49:05 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.625 | ppl 1579.34 | wps 7901.3 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-28 08:49:05 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-28 08:49:05 | INFO | train | epoch 012 | loss 10.636 | ppl 1591.2 | wps 5919.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.482 | train_wall 324 | gb_free 6.1 | wall 4236
KL Stats: Epoch 12 Divergences: Uniform: 1.5328654112733315 Unigram: 1.0622536844536299
2022-01-28 08:49:05 | INFO | fairseq.trainer | begin training epoch 13
2022-01-28 08:49:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:51:48 | INFO | train_inner | epoch 013:     32 / 64 loss=10.612, ppl=1564.61, wps=5794.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.496, train_wall=506, gb_free=6.1, wall=4399
2022-01-28 08:54:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:54:58 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.535 | ppl 1483.58 | wps 7943.8 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-28 08:54:58 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-28 08:54:58 | INFO | train | epoch 013 | loss 10.52 | ppl 1468.57 | wps 5926.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.517 | train_wall 324 | gb_free 6.1 | wall 4588
KL Stats: Epoch 13 Divergences: Uniform: 1.557062515511917 Unigram: 1.1693127984424936
2022-01-28 08:54:58 | INFO | fairseq.trainer | begin training epoch 14
2022-01-28 08:54:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:00:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:00:50 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.439 | ppl 1388.02 | wps 7943.1 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-28 09:00:50 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-28 09:00:50 | INFO | train | epoch 014 | loss 10.409 | ppl 1359.25 | wps 5931.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.56 | train_wall 324 | gb_free 6.1 | wall 4941
KL Stats: Epoch 14 Divergences: Uniform: 1.5836099849189593 Unigram: 1.2676935243543073
2022-01-28 09:00:50 | INFO | fairseq.trainer | begin training epoch 15
2022-01-28 09:00:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:01:10 | INFO | train_inner | epoch 015:      4 / 64 loss=10.431, ppl=1380.83, wps=5800.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.538, train_wall=506, gb_free=6.1, wall=4961
2022-01-28 09:06:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:06:42 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.369 | ppl 1322.21 | wps 7959.4 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-28 09:06:42 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-28 09:06:42 | INFO | train | epoch 015 | loss 10.296 | ppl 1257.56 | wps 5927 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.541 | train_wall 324 | gb_free 6.1 | wall 5293
KL Stats: Epoch 15 Divergences: Uniform: 1.604885217723347 Unigram: 1.3585080924798159
2022-01-28 09:06:42 | INFO | fairseq.trainer | begin training epoch 16
2022-01-28 09:06:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:10:06 | INFO | train_inner | epoch 016:     40 / 64 loss=10.255, ppl=1221.97, wps=6097.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.56, train_wall=507, gb_free=6.1, wall=5497
2022-01-28 09:12:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:12:35 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.289 | ppl 1250.83 | wps 7906.6 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-28 09:12:35 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-28 09:12:35 | INFO | train | epoch 016 | loss 10.19 | ppl 1167.96 | wps 5920.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.557 | train_wall 324 | gb_free 6.1 | wall 5646
KL Stats: Epoch 16 Divergences: Uniform: 1.6324820278276087 Unigram: 1.4446118608136946
2022-01-28 09:12:35 | INFO | fairseq.trainer | begin training epoch 17
2022-01-28 09:12:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:17:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:18:26 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.194 | ppl 1171.03 | wps 7971.2 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-28 09:18:26 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-28 09:18:26 | INFO | train | epoch 017 | loss 10.083 | ppl 1084.72 | wps 5946.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.548 | train_wall 323 | gb_free 6.1 | wall 5997
KL Stats: Epoch 17 Divergences: Uniform: 1.666492520836899 Unigram: 1.5197929693654648
2022-01-28 09:18:26 | INFO | fairseq.trainer | begin training epoch 18
2022-01-28 09:18:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:19:28 | INFO | train_inner | epoch 018:     12 / 64 loss=10.097, ppl=1095.43, wps=5807, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.551, train_wall=505, gb_free=6.1, wall=6058
2022-01-28 09:23:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:24:19 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.134 | ppl 1123.53 | wps 7939.4 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-28 09:24:19 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-28 09:24:19 | INFO | train | epoch 018 | loss 9.983 | ppl 1011.78 | wps 5918.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.569 | train_wall 324 | gb_free 6.1 | wall 6350
KL Stats: Epoch 18 Divergences: Uniform: 1.6990609249431612 Unigram: 1.594492043593805
2022-01-28 09:24:19 | INFO | fairseq.trainer | begin training epoch 19
2022-01-28 09:24:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:28:24 | INFO | train_inner | epoch 019:     48 / 64 loss=9.933, ppl=977.65, wps=6097, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.54, train_wall=507, gb_free=6.1, wall=6594
2022-01-28 09:29:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:30:11 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.057 | ppl 1065.24 | wps 7921.8 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-28 09:30:11 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-28 09:30:11 | INFO | train | epoch 019 | loss 9.879 | ppl 941.9 | wps 5930.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.528 | train_wall 324 | gb_free 6.1 | wall 6702
KL Stats: Epoch 19 Divergences: Uniform: 1.7271330018494322 Unigram: 1.6682365866592075
2022-01-28 09:30:11 | INFO | fairseq.trainer | begin training epoch 20
2022-01-28 09:30:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:35:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:36:03 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.973 | ppl 1004.87 | wps 7904.1 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-28 09:36:03 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-28 09:36:03 | INFO | train | epoch 020 | loss 9.783 | ppl 880.93 | wps 5935 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.548 | train_wall 323 | gb_free 6.1 | wall 7054
KL Stats: Epoch 20 Divergences: Uniform: 1.7575968569032996 Unigram: 1.7355260210888046
2022-01-28 09:36:03 | INFO | fairseq.trainer | begin training epoch 21
2022-01-28 09:36:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:37:45 | INFO | train_inner | epoch 021:     20 / 64 loss=9.778, ppl=877.87, wps=5803, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.545, train_wall=505, gb_free=6.1, wall=7156
2022-01-28 09:41:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:41:56 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.931 | ppl 976.06 | wps 7949.8 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-28 09:41:56 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-28 09:41:56 | INFO | train | epoch 021 | loss 9.689 | ppl 825.32 | wps 5926.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.53 | train_wall 324 | gb_free 6.1 | wall 7406
KL Stats: Epoch 21 Divergences: Uniform: 1.7872851899185553 Unigram: 1.8023461702925017
2022-01-28 09:41:56 | INFO | fairseq.trainer | begin training epoch 22
2022-01-28 09:41:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:46:41 | INFO | train_inner | epoch 022:     56 / 64 loss=9.636, ppl=795.86, wps=6098.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.541, train_wall=507, gb_free=6.1, wall=7692
2022-01-28 09:47:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:47:49 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.867 | ppl 933.84 | wps 7889.5 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-28 09:47:49 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-28 09:47:49 | INFO | train | epoch 022 | loss 9.6 | ppl 775.94 | wps 5913.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.55 | train_wall 325 | gb_free 6.1 | wall 7760
KL Stats: Epoch 22 Divergences: Uniform: 1.8113941170615828 Unigram: 1.8674924177854684
2022-01-28 09:47:49 | INFO | fairseq.trainer | begin training epoch 23
2022-01-28 09:47:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:53:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:53:41 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.803 | ppl 893.61 | wps 7914.9 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-28 09:53:41 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-28 09:53:41 | INFO | train | epoch 023 | loss 9.513 | ppl 730.66 | wps 5930.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.516 | train_wall 324 | gb_free 6.1 | wall 8112
KL Stats: Epoch 23 Divergences: Uniform: 1.839375828670175 Unigram: 1.9252475437142296
2022-01-28 09:53:41 | INFO | fairseq.trainer | begin training epoch 24
2022-01-28 09:53:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:56:04 | INFO | train_inner | epoch 024:     28 / 64 loss=9.498, ppl=723.12, wps=5794.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.531, train_wall=506, gb_free=6.1, wall=8255
2022-01-28 09:59:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:59:34 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.745 | ppl 857.85 | wps 7924.5 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-28 09:59:34 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-28 09:59:34 | INFO | train | epoch 024 | loss 9.43 | ppl 689.88 | wps 5923.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.564 | train_wall 324 | gb_free 6.1 | wall 8464
KL Stats: Epoch 24 Divergences: Uniform: 1.8600812712828954 Unigram: 1.978621486976207
2022-01-28 09:59:34 | INFO | fairseq.trainer | begin training epoch 25
2022-01-28 09:59:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:04:59 | INFO | train_inner | epoch 025:     64 / 64 loss=9.376, ppl=664.63, wps=6093.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.545, train_wall=506, gb_free=6.1, wall=8789
2022-01-28 10:04:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:05:26 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.715 | ppl 840.18 | wps 7912.7 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-28 10:05:26 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-28 10:05:26 | INFO | train | epoch 025 | loss 9.349 | ppl 651.95 | wps 5920.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.53 | train_wall 324 | gb_free 6.1 | wall 8817
KL Stats: Epoch 25 Divergences: Uniform: 1.88861118038125 Unigram: 2.0342098927952903
2022-01-28 10:05:26 | INFO | fairseq.trainer | begin training epoch 26
2022-01-28 10:05:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:11:18 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.664 | ppl 811.31 | wps 7985.5 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-28 10:11:18 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-28 10:11:18 | INFO | train | epoch 026 | loss 9.268 | ppl 616.35 | wps 5939.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.545 | train_wall 323 | gb_free 6.1 | wall 9169
KL Stats: Epoch 26 Divergences: Uniform: 1.9008871858722096 Unigram: 2.0835399930338516
2022-01-28 10:11:18 | INFO | fairseq.trainer | begin training epoch 27
2022-01-28 10:11:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:14:21 | INFO | train_inner | epoch 027:     36 / 64 loss=9.24, ppl=604.67, wps=5813.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.54, train_wall=506, gb_free=6.1, wall=9352
2022-01-28 10:16:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:17:10 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.631 | ppl 792.98 | wps 7935.3 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-28 10:17:10 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-28 10:17:10 | INFO | train | epoch 027 | loss 9.188 | ppl 583.25 | wps 5933.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.533 | train_wall 324 | gb_free 6.1 | wall 9521
KL Stats: Epoch 27 Divergences: Uniform: 1.9268720136236943 Unigram: 2.1285420285295604
2022-01-28 10:17:10 | INFO | fairseq.trainer | begin training epoch 28
2022-01-28 10:17:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:22:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:23:02 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.604 | ppl 778.42 | wps 7923.3 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-28 10:23:02 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-28 10:23:02 | INFO | train | epoch 028 | loss 9.11 | ppl 552.5 | wps 5934.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.527 | train_wall 323 | gb_free 6.1 | wall 9873
KL Stats: Epoch 28 Divergences: Uniform: 1.9558787386098861 Unigram: 2.1766612490600235
2022-01-28 10:23:02 | INFO | fairseq.trainer | begin training epoch 29
2022-01-28 10:23:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:23:43 | INFO | train_inner | epoch 029:      8 / 64 loss=9.125, ppl=558.51, wps=5802.5, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.532, train_wall=505, gb_free=6.1, wall=9913
2022-01-28 10:28:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:28:54 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.567 | ppl 758.66 | wps 7882.5 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-28 10:28:54 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-28 10:28:54 | INFO | train | epoch 029 | loss 9.031 | ppl 523.09 | wps 5931 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.525 | train_wall 324 | gb_free 6.1 | wall 10225
KL Stats: Epoch 29 Divergences: Uniform: 1.9760192409918353 Unigram: 2.2196457963808873
2022-01-28 10:28:54 | INFO | fairseq.trainer | begin training epoch 30
2022-01-28 10:28:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:32:38 | INFO | train_inner | epoch 030:     44 / 64 loss=8.998, ppl=511.29, wps=6101.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.516, train_wall=507, gb_free=6.1, wall=10449
2022-01-28 10:34:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:34:46 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.544 | ppl 746.67 | wps 7921.3 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-28 10:34:46 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-28 10:34:46 | INFO | train | epoch 030 | loss 8.954 | ppl 495.79 | wps 5929.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.523 | train_wall 324 | gb_free 6.1 | wall 10577
KL Stats: Epoch 30 Divergences: Uniform: 1.993195625183268 Unigram: 2.2669259936768267
2022-01-28 10:34:46 | INFO | fairseq.trainer | begin training epoch 31
2022-01-28 10:34:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:40:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:40:38 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.494 | ppl 720.96 | wps 7934.4 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-28 10:40:38 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-28 10:40:38 | INFO | train | epoch 031 | loss 8.874 | ppl 469.22 | wps 5931.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.5 | train_wall 324 | gb_free 6.1 | wall 10929
KL Stats: Epoch 31 Divergences: Uniform: 2.0115572472863126 Unigram: 2.3072716586599338
2022-01-28 10:40:38 | INFO | fairseq.trainer | begin training epoch 32
2022-01-28 10:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:42:00 | INFO | train_inner | epoch 032:     16 / 64 loss=8.875, ppl=469.65, wps=5805.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.508, train_wall=505, gb_free=6.1, wall=11011
2022-01-28 10:46:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:46:30 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.46 | ppl 704.15 | wps 7934.4 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-28 10:46:30 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-28 10:46:30 | INFO | train | epoch 032 | loss 8.801 | ppl 445.89 | wps 5936.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.512 | train_wall 323 | gb_free 6.1 | wall 11281
KL Stats: Epoch 32 Divergences: Uniform: 2.039364226489823 Unigram: 2.349113817485872
2022-01-28 10:46:30 | INFO | fairseq.trainer | begin training epoch 33
2022-01-28 10:46:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:50:55 | INFO | train_inner | epoch 033:     52 / 64 loss=8.764, ppl=434.62, wps=6110.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.515, train_wall=506, gb_free=6.1, wall=11545
2022-01-28 10:51:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:52:22 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.444 | ppl 696.27 | wps 7977.5 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-28 10:52:22 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-28 10:52:22 | INFO | train | epoch 033 | loss 8.726 | ppl 423.47 | wps 5942.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.514 | train_wall 323 | gb_free 6.1 | wall 11632
KL Stats: Epoch 33 Divergences: Uniform: 2.0618618398150814 Unigram: 2.397358807785163
2022-01-28 10:52:22 | INFO | fairseq.trainer | begin training epoch 34
2022-01-28 10:52:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:57:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:58:14 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.424 | ppl 686.89 | wps 7893.5 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-28 10:58:14 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-28 10:58:14 | INFO | train | epoch 034 | loss 8.65 | ppl 401.83 | wps 5924.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.516 | train_wall 324 | gb_free 6.1 | wall 11985
KL Stats: Epoch 34 Divergences: Uniform: 2.082294738509631 Unigram: 2.4387711432051034
2022-01-28 10:58:14 | INFO | fairseq.trainer | begin training epoch 35
2022-01-28 10:58:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:00:16 | INFO | train_inner | epoch 035:     24 / 64 loss=8.638, ppl=398.25, wps=5806.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.515, train_wall=505, gb_free=6.1, wall=12107
2022-01-28 11:03:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:04:06 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.396 | ppl 673.88 | wps 7922 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-28 11:04:06 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-28 11:04:06 | INFO | train | epoch 035 | loss 8.578 | ppl 382.13 | wps 5939 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.509 | train_wall 323 | gb_free 6.1 | wall 12337
KL Stats: Epoch 35 Divergences: Uniform: 2.103809158483506 Unigram: 2.475979529853614
2022-01-28 11:04:06 | INFO | fairseq.trainer | begin training epoch 36
2022-01-28 11:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:09:11 | INFO | train_inner | epoch 036:     60 / 64 loss=8.534, ppl=370.75, wps=6111, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.51, train_wall=506, gb_free=6.1, wall=12642
2022-01-28 11:09:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:09:57 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.37 | ppl 661.76 | wps 7954.4 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-28 11:09:57 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-28 11:09:57 | INFO | train | epoch 036 | loss 8.505 | ppl 363.21 | wps 5942.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.51 | train_wall 323 | gb_free 6.1 | wall 12688
KL Stats: Epoch 36 Divergences: Uniform: 2.1246713908365233 Unigram: 2.5216195951606557
2022-01-28 11:09:57 | INFO | fairseq.trainer | begin training epoch 37
2022-01-28 11:09:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:15:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:15:48 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.39 | ppl 670.9 | wps 7937.2 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-28 11:15:48 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-28 11:15:48 | INFO | train | epoch 037 | loss 8.435 | ppl 346.1 | wps 5949.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.513 | train_wall 323 | gb_free 6.1 | wall 13039
KL Stats: Epoch 37 Divergences: Uniform: 2.1425923121224177 Unigram: 2.564022273420494
2022-01-28 11:15:48 | INFO | fairseq.trainer | begin training epoch 38
2022-01-28 11:15:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:18:31 | INFO | train_inner | epoch 038:     32 / 64 loss=8.414, ppl=341.01, wps=5817.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.511, train_wall=504, gb_free=6.1, wall=13202
2022-01-28 11:21:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:21:40 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.369 | ppl 661.03 | wps 7950.1 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-28 11:21:40 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-28 11:21:40 | INFO | train | epoch 038 | loss 8.367 | ppl 330.06 | wps 5934.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.512 | train_wall 324 | gb_free 6.1 | wall 13391
KL Stats: Epoch 38 Divergences: Uniform: 2.171568709799728 Unigram: 2.5955388278258518
2022-01-28 11:21:40 | INFO | fairseq.trainer | begin training epoch 39
2022-01-28 11:21:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:27:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:27:32 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.347 | ppl 651.15 | wps 7852 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-28 11:27:32 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-28 11:27:32 | INFO | train | epoch 039 | loss 8.298 | ppl 314.65 | wps 5942.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.504 | train_wall 323 | gb_free 6.1 | wall 13743
KL Stats: Epoch 39 Divergences: Uniform: 2.1804200416663146 Unigram: 2.640163408085552
2022-01-28 11:27:32 | INFO | fairseq.trainer | begin training epoch 40
2022-01-28 11:27:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:27:52 | INFO | train_inner | epoch 040:      4 / 64 loss=8.319, ppl=319.43, wps=5807.2, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.508, train_wall=504, gb_free=6.1, wall=13763
2022-01-28 11:32:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:33:25 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.326 | ppl 641.68 | wps 7923 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-28 11:33:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-28 11:33:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint40.pt
2022-01-28 11:33:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint40.pt
2022-01-28 11:33:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.326) (writing took 5.5249195927754045 seconds)
2022-01-28 11:33:30 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-28 11:33:30 | INFO | train | epoch 040 | loss 8.229 | ppl 300.03 | wps 5827.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.508 | train_wall 324 | gb_free 6.1 | wall 14101
KL Stats: Epoch 40 Divergences: Uniform: 2.2076651354763066 Unigram: 2.67738658187128
2022-01-28 11:33:30 | INFO | fairseq.trainer | begin training epoch 41
2022-01-28 11:33:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:36:54 | INFO | train_inner | epoch 041:     40 / 64 loss=8.205, ppl=295.15, wps=6033.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.506, train_wall=507, gb_free=6.1, wall=14305
2022-01-28 11:38:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:39:23 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.317 | ppl 637.77 | wps 7920.9 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.317
2022-01-28 11:39:23 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-28 11:39:23 | INFO | train | epoch 041 | loss 8.165 | ppl 286.96 | wps 5925.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.505 | train_wall 324 | gb_free 6.1 | wall 14454
KL Stats: Epoch 41 Divergences: Uniform: 2.221443738611444 Unigram: 2.712206682521822
2022-01-28 11:39:23 | INFO | fairseq.trainer | begin training epoch 42
2022-01-28 11:39:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:44:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:45:15 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.294 | ppl 627.71 | wps 7919.5 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.294
2022-01-28 11:45:15 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-28 11:45:15 | INFO | train | epoch 042 | loss 8.101 | ppl 274.49 | wps 5925.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.515 | train_wall 324 | gb_free 6.1 | wall 14806
KL Stats: Epoch 42 Divergences: Uniform: 2.237935346230051 Unigram: 2.7540435213223597
2022-01-28 11:45:15 | INFO | fairseq.trainer | begin training epoch 43
2022-01-28 11:45:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:46:17 | INFO | train_inner | epoch 043:     12 / 64 loss=8.107, ppl=275.71, wps=5796.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.514, train_wall=506, gb_free=6.1, wall=14867
2022-01-28 11:50:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:51:07 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.327 | ppl 642.05 | wps 7941.4 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.326
2022-01-28 11:51:07 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-28 11:51:07 | INFO | train | epoch 043 | loss 8.036 | ppl 262.4 | wps 5935.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.507 | train_wall 323 | gb_free 6.1 | wall 15158
KL Stats: Epoch 43 Divergences: Uniform: 2.261333200701914 Unigram: 2.7913128920147487
2022-01-28 11:51:07 | INFO | fairseq.trainer | begin training epoch 44
2022-01-28 11:51:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:55:12 | INFO | train_inner | epoch 044:     48 / 64 loss=8.002, ppl=256.33, wps=6107.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.513, train_wall=506, gb_free=6.1, wall=15402
2022-01-28 11:56:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:57:00 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.34 | ppl 648.11 | wps 7905.3 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.326
2022-01-28 11:57:00 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-28 11:57:00 | INFO | train | epoch 044 | loss 7.976 | ppl 251.79 | wps 5925.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.513 | train_wall 324 | gb_free 6.1 | wall 15510
KL Stats: Epoch 44 Divergences: Uniform: 2.2775280908431363 Unigram: 2.826799115233034
2022-01-28 11:57:00 | INFO | fairseq.trainer | begin training epoch 45
2022-01-28 11:57:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:02:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:02:52 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.316 | ppl 637.33 | wps 7918.8 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.316
2022-01-28 12:02:52 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-28 12:02:52 | INFO | train | epoch 045 | loss 7.913 | ppl 241.04 | wps 5929.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.515 | train_wall 324 | gb_free 6.1 | wall 15863
KL Stats: Epoch 45 Divergences: Uniform: 2.294562090570219 Unigram: 2.869581372061677
2022-01-28 12:02:52 | INFO | fairseq.trainer | begin training epoch 46
2022-01-28 12:02:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:04:34 | INFO | train_inner | epoch 046:     20 / 64 loss=7.913, ppl=240.97, wps=5800.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.514, train_wall=505, gb_free=6.1, wall=15965
2022-01-28 12:08:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:08:44 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.313 | ppl 635.98 | wps 7941.4 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.313
2022-01-28 12:08:44 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-28 12:08:44 | INFO | train | epoch 046 | loss 7.854 | ppl 231.41 | wps 5935 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.523 | train_wall 323 | gb_free 6.1 | wall 16215
KL Stats: Epoch 46 Divergences: Uniform: 2.3092151561208794 Unigram: 2.894159442310697
2022-01-28 12:08:44 | INFO | fairseq.trainer | begin training epoch 47
2022-01-28 12:08:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:13:29 | INFO | train_inner | epoch 047:     56 / 64 loss=7.823, ppl=226.49, wps=6109.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.51, train_wall=506, gb_free=6.1, wall=16499
2022-01-28 12:14:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:14:35 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.302 | ppl 631.18 | wps 7937.9 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.302
2022-01-28 12:14:35 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-28 12:14:35 | INFO | train | epoch 047 | loss 7.796 | ppl 222.18 | wps 5940.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.506 | train_wall 323 | gb_free 6.1 | wall 16566
KL Stats: Epoch 47 Divergences: Uniform: 2.3318123438598524 Unigram: 2.925511145136698
2022-01-28 12:14:35 | INFO | fairseq.trainer | begin training epoch 48
2022-01-28 12:14:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:19:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:20:27 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.294 | ppl 627.78 | wps 7945.4 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.294
2022-01-28 12:20:27 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-28 12:20:27 | INFO | train | epoch 048 | loss 7.739 | ppl 213.6 | wps 5944.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.518 | train_wall 323 | gb_free 6.1 | wall 16917
KL Stats: Epoch 48 Divergences: Uniform: 2.347705015858914 Unigram: 2.963357710594926
2022-01-28 12:20:27 | INFO | fairseq.trainer | begin training epoch 49
2022-01-28 12:20:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:22:50 | INFO | train_inner | epoch 049:     28 / 64 loss=7.721, ppl=211.01, wps=5809.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.517, train_wall=505, gb_free=6.1, wall=17060
2022-01-28 12:25:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:26:20 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.333 | ppl 645.13 | wps 7949.6 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.326
2022-01-28 12:26:20 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-28 12:26:20 | INFO | train | epoch 049 | loss 7.682 | ppl 205.3 | wps 5918.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.518 | train_wall 324 | gb_free 6.1 | wall 17270
KL Stats: Epoch 49 Divergences: Uniform: 2.3515043399411204 Unigram: 2.9950348147804133
2022-01-28 12:26:20 | INFO | fairseq.trainer | begin training epoch 50
2022-01-28 12:26:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:31:46 | INFO | train_inner | epoch 050:     64 / 64 loss=7.657, ppl=201.84, wps=6082.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.529, train_wall=507, gb_free=6.1, wall=17596
2022-01-28 12:31:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:32:13 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.347 | ppl 651.01 | wps 7901.7 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.326
2022-01-28 12:32:13 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-28 12:32:13 | INFO | train | epoch 050 | loss 7.63 | ppl 198.14 | wps 5904.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.534 | train_wall 325 | gb_free 6.1 | wall 17624
KL Stats: Epoch 50 Divergences: Uniform: 2.3674361136453816 Unigram: 3.0203142879382803
2022-01-28 12:32:13 | INFO | fairseq.trainer | begin training epoch 51
2022-01-28 12:32:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:37:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:38:06 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.355 | ppl 654.97 | wps 7891.9 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.326
2022-01-28 12:38:06 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-28 12:38:06 | INFO | train | epoch 051 | loss 7.574 | ppl 190.59 | wps 5917.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.519 | train_wall 324 | gb_free 6.1 | wall 17977
KL Stats: Epoch 51 Divergences: Uniform: 2.394050767778345 Unigram: 3.0478396800905134
2022-01-28 12:38:06 | INFO | fairseq.trainer | begin training epoch 52
2022-01-28 12:38:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:41:10 | INFO | train_inner | epoch 052:     36 / 64 loss=7.55, ppl=187.46, wps=5793.1, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.52, train_wall=507, gb_free=6.1, wall=18161
2022-01-28 12:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:43:59 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.344 | ppl 650.08 | wps 7988.2 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.326
2022-01-28 12:43:59 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-28 12:43:59 | INFO | train | epoch 052 | loss 7.522 | ppl 183.8 | wps 5929.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.525 | train_wall 324 | gb_free 6.1 | wall 18329
KL Stats: Epoch 52 Divergences: Uniform: 2.407123674882871 Unigram: 3.0920985578908637
2022-01-28 12:43:59 | INFO | fairseq.trainer | begin training epoch 53
2022-01-28 12:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:49:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:49:52 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.331 | ppl 644.16 | wps 7884.3 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.326
2022-01-28 12:49:52 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-28 12:49:52 | INFO | train | epoch 053 | loss 7.471 | ppl 177.37 | wps 5916.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.518 | train_wall 324 | gb_free 6.1 | wall 18682
KL Stats: Epoch 53 Divergences: Uniform: 2.4222252122360075 Unigram: 3.1153657475525254
2022-01-28 12:49:52 | INFO | fairseq.trainer | begin training epoch 54
2022-01-28 12:49:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:50:32 | INFO | train_inner | epoch 054:      8 / 64 loss=7.483, ppl=178.96, wps=5793.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.525, train_wall=506, gb_free=6.1, wall=18723
2022-01-28 12:55:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:55:45 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.364 | ppl 658.91 | wps 7908.1 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.326
2022-01-28 12:55:45 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-28 12:55:45 | INFO | train | epoch 054 | loss 7.42 | ppl 171.3 | wps 5912.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.526 | train_wall 325 | gb_free 6.1 | wall 19036
KL Stats: Epoch 54 Divergences: Uniform: 2.431386707625916 Unigram: 3.1426068885666076
2022-01-28 12:55:45 | INFO | fairseq.trainer | begin training epoch 55
2022-01-28 12:55:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:59:29 | INFO | train_inner | epoch 055:     44 / 64 loss=7.393, ppl=168.11, wps=6086.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.527, train_wall=508, gb_free=6.1, wall=19260
2022-01-28 13:01:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:01:38 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.382 | ppl 667.26 | wps 7890.6 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.326
2022-01-28 13:01:38 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-28 13:01:38 | INFO | train | epoch 055 | loss 7.374 | ppl 165.85 | wps 5918.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.54 | train_wall 324 | gb_free 6.1 | wall 19388
KL Stats: Epoch 55 Divergences: Uniform: 2.4412968343911676 Unigram: 3.177885878313609
2022-01-28 13:01:38 | INFO | fairseq.trainer | begin training epoch 56
2022-01-28 13:01:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:07:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:07:31 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.465 | ppl 706.55 | wps 7891.1 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.326
2022-01-28 13:07:31 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-28 13:07:31 | INFO | train | epoch 056 | loss 7.324 | ppl 160.22 | wps 5913 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.529 | train_wall 325 | gb_free 6.1 | wall 19742
KL Stats: Epoch 56 Divergences: Uniform: 2.4449243932843365 Unigram: 3.1982874194093136
2022-01-28 13:07:31 | INFO | fairseq.trainer | begin training epoch 57
2022-01-28 13:07:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:08:52 | INFO | train_inner | epoch 057:     16 / 64 loss=7.328, ppl=160.69, wps=5789.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.537, train_wall=506, gb_free=6.1, wall=19823
2022-01-28 13:12:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:13:24 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.471 | ppl 709.45 | wps 7902.3 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.326
2022-01-28 13:13:24 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-28 13:13:24 | INFO | train | epoch 057 | loss 7.277 | ppl 155.09 | wps 5919.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.541 | train_wall 324 | gb_free 6.1 | wall 20095
KL Stats: Epoch 57 Divergences: Uniform: 2.4738395278632668 Unigram: 3.235402570953911
2022-01-28 13:13:24 | INFO | fairseq.trainer | begin training epoch 58
2022-01-28 13:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:17:49 | INFO | train_inner | epoch 058:     52 / 64 loss=7.252, ppl=152.45, wps=6085.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.536, train_wall=508, gb_free=6.1, wall=20360
2022-01-28 13:18:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:19:17 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.49 | ppl 719.27 | wps 7896.2 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.326
2022-01-28 13:19:17 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-28 13:19:17 | INFO | train | epoch 058 | loss 7.232 | ppl 150.32 | wps 5910.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.539 | train_wall 325 | gb_free 6.1 | wall 20448
KL Stats: Epoch 58 Divergences: Uniform: 2.482570292629034 Unigram: 3.261137688260474
2022-01-28 13:19:17 | INFO | fairseq.trainer | begin training epoch 59
2022-01-28 13:19:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:24:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:25:10 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.54 | ppl 744.53 | wps 7903.8 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.326
2022-01-28 13:25:10 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-28 13:25:10 | INFO | train | epoch 059 | loss 7.186 | ppl 145.64 | wps 5919.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.538 | train_wall 324 | gb_free 6.1 | wall 20801
KL Stats: Epoch 59 Divergences: Uniform: 2.4963397731052948 Unigram: 3.288185482177531
2022-01-28 13:25:10 | INFO | fairseq.trainer | begin training epoch 60
2022-01-28 13:25:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:27:13 | INFO | train_inner | epoch 060:     24 / 64 loss=7.18, ppl=145.01, wps=5787.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.541, train_wall=506, gb_free=6.1, wall=20923
2022-01-28 13:30:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:31:04 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.494 | ppl 720.97 | wps 7896.2 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.326
2022-01-28 13:31:04 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-28 13:31:04 | INFO | train | epoch 060 | loss 7.141 | ppl 141.18 | wps 5906.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.55 | train_wall 325 | gb_free 6.1 | wall 21154
KL Stats: Epoch 60 Divergences: Uniform: 2.5131464301878434 Unigram: 3.3220301948543978
2022-01-28 13:31:04 | INFO | fairseq.trainer | begin training epoch 61
2022-01-28 13:31:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:36:09 | INFO | train_inner | epoch 061:     60 / 64 loss=7.122, ppl=139.32, wps=6093.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.552, train_wall=507, gb_free=6.1, wall=21460
2022-01-28 13:36:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:36:56 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.549 | ppl 748.88 | wps 7896.1 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.326
2022-01-28 13:36:56 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-28 13:36:56 | INFO | train | epoch 061 | loss 7.099 | ppl 137.1 | wps 5927.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.553 | train_wall 324 | gb_free 6.1 | wall 21507
KL Stats: Epoch 61 Divergences: Uniform: 2.525891462538542 Unigram: 3.3346169889105512
2022-01-28 13:36:56 | INFO | fairseq.trainer | begin training epoch 62
2022-01-28 13:36:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:42:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:42:49 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.514 | ppl 731.26 | wps 7914.8 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.326
2022-01-28 13:42:49 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-28 13:42:49 | INFO | train | epoch 062 | loss 7.058 | ppl 133.27 | wps 5918.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.557 | train_wall 324 | gb_free 6.1 | wall 21860
KL Stats: Epoch 62 Divergences: Uniform: 2.528594754930607 Unigram: 3.373237554412178
2022-01-28 13:42:49 | INFO | fairseq.trainer | begin training epoch 63
2022-01-28 13:42:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:45:32 | INFO | train_inner | epoch 063:     32 / 64 loss=7.032, ppl=130.88, wps=5788.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.554, train_wall=506, gb_free=6.1, wall=22023
2022-01-28 13:48:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:48:42 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.547 | ppl 748.13 | wps 7902.7 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.326
2022-01-28 13:48:42 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-28 13:48:42 | INFO | train | epoch 063 | loss 7.014 | ppl 129.21 | wps 5921.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.551 | train_wall 324 | gb_free 6.1 | wall 22212
KL Stats: Epoch 63 Divergences: Uniform: 2.549045492901148 Unigram: 3.4021279169515246
2022-01-28 13:48:42 | INFO | fairseq.trainer | begin training epoch 64
2022-01-28 13:48:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:54:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:54:35 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.615 | ppl 784.25 | wps 7886.4 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.326
2022-01-28 13:54:35 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-28 13:54:35 | INFO | train | epoch 064 | loss 6.972 | ppl 125.53 | wps 5911.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.564 | train_wall 325 | gb_free 6.1 | wall 22566
KL Stats: Epoch 64 Divergences: Uniform: 2.5551295953489017 Unigram: 3.4205264833520586
2022-01-28 13:54:35 | INFO | fairseq.trainer | begin training epoch 65
2022-01-28 13:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:54:55 | INFO | train_inner | epoch 065:      4 / 64 loss=6.998, ppl=127.86, wps=5788.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.562, train_wall=506, gb_free=6.1, wall=22586
2022-01-28 14:00:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:00:28 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.627 | ppl 790.78 | wps 7958.9 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.326
2022-01-28 14:00:28 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-28 14:00:28 | INFO | train | epoch 065 | loss 6.928 | ppl 121.77 | wps 5920.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.562 | train_wall 324 | gb_free 6.1 | wall 22918
KL Stats: Epoch 65 Divergences: Uniform: 2.563942976226502 Unigram: 3.445737368680613
2022-01-28 14:00:28 | INFO | fairseq.trainer | begin training epoch 66
2022-01-28 14:00:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:03:51 | INFO | train_inner | epoch 066:     40 / 64 loss=6.904, ppl=119.75, wps=6096.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.567, train_wall=507, gb_free=6.1, wall=23122
2022-01-28 14:05:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:06:20 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.639 | ppl 797.29 | wps 7906.2 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.326
2022-01-28 14:06:20 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-28 14:06:20 | INFO | train | epoch 066 | loss 6.888 | ppl 118.46 | wps 5925.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.563 | train_wall 324 | gb_free 6.1 | wall 23271
KL Stats: Epoch 66 Divergences: Uniform: 2.5772898308287924 Unigram: 3.471961225872827
2022-01-28 14:06:20 | INFO | fairseq.trainer | begin training epoch 67
2022-01-28 14:06:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:11:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:12:13 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.638 | ppl 796.8 | wps 7861.8 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.326
2022-01-28 14:12:13 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-28 14:12:13 | INFO | train | epoch 067 | loss 6.847 | ppl 115.1 | wps 5918.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.569 | train_wall 324 | gb_free 6.1 | wall 23624
KL Stats: Epoch 67 Divergences: Uniform: 2.5950305911630087 Unigram: 3.507518799528248
2022-01-28 14:12:13 | INFO | fairseq.trainer | begin training epoch 68
2022-01-28 14:12:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:13:14 | INFO | train_inner | epoch 068:     12 / 64 loss=6.856, ppl=115.81, wps=5793.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.563, train_wall=506, gb_free=6.1, wall=23685
2022-01-28 14:17:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:18:06 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.681 | ppl 820.87 | wps 7935.9 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.326
2022-01-28 14:18:06 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-28 14:18:06 | INFO | train | epoch 068 | loss 6.81 | ppl 112.18 | wps 5920.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.582 | train_wall 324 | gb_free 6.1 | wall 23977
KL Stats: Epoch 68 Divergences: Uniform: 2.6060593442497813 Unigram: 3.5349998447665416
2022-01-28 14:18:06 | INFO | fairseq.trainer | begin training epoch 69
2022-01-28 14:18:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:22:10 | INFO | train_inner | epoch 069:     48 / 64 loss=6.792, ppl=110.8, wps=6092.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.581, train_wall=507, gb_free=6.1, wall=24221
2022-01-28 14:23:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:23:58 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.681 | ppl 820.85 | wps 7889 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.326
2022-01-28 14:23:58 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-28 14:23:58 | INFO | train | epoch 069 | loss 6.772 | ppl 109.27 | wps 5922.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.582 | train_wall 324 | gb_free 6.1 | wall 24329
KL Stats: Epoch 69 Divergences: Uniform: 2.618332367180402 Unigram: 3.5546142788288915
2022-01-28 14:23:58 | INFO | fairseq.trainer | begin training epoch 70
2022-01-28 14:23:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:29:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:29:51 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.785 | ppl 882.26 | wps 7923.1 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.326
2022-01-28 14:29:51 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-28 14:29:51 | INFO | train | epoch 070 | loss 6.736 | ppl 106.58 | wps 5922.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.575 | train_wall 324 | gb_free 6.1 | wall 24682
KL Stats: Epoch 70 Divergences: Uniform: 2.6226714181201594 Unigram: 3.571775430475295
2022-01-28 14:29:51 | INFO | fairseq.trainer | begin training epoch 71
2022-01-28 14:29:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:31:33 | INFO | train_inner | epoch 071:     20 / 64 loss=6.73, ppl=106.18, wps=5794.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.58, train_wall=506, gb_free=6.1, wall=24784
2022-01-28 14:35:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:35:44 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.776 | ppl 876.47 | wps 7889.8 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.326
2022-01-28 14:35:44 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-28 14:35:44 | INFO | train | epoch 071 | loss 6.701 | ppl 104.07 | wps 5924.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.588 | train_wall 324 | gb_free 6.1 | wall 25034
KL Stats: Epoch 71 Divergences: Uniform: 2.635696134088942 Unigram: 3.5959790520174897
2022-01-28 14:35:44 | INFO | fairseq.trainer | begin training epoch 72
2022-01-28 14:35:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:40:29 | INFO | train_inner | epoch 072:     56 / 64 loss=6.686, ppl=102.96, wps=6095.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.584, train_wall=507, gb_free=6.1, wall=25320
2022-01-28 14:41:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:41:36 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.668 | ppl 813.59 | wps 7907.4 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.326
2022-01-28 14:41:36 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-28 14:41:36 | INFO | train | epoch 072 | loss 6.666 | ppl 101.56 | wps 5923.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.583 | train_wall 324 | gb_free 6.1 | wall 25387
KL Stats: Epoch 72 Divergences: Uniform: 2.6509674567939228 Unigram: 3.627942886767364
2022-01-28 14:41:36 | INFO | fairseq.trainer | begin training epoch 73
2022-01-28 14:41:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:47:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:47:29 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.777 | ppl 877.34 | wps 7898.6 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.326
2022-01-28 14:47:29 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-28 14:47:29 | INFO | train | epoch 073 | loss 6.634 | ppl 99.29 | wps 5914.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.582 | train_wall 325 | gb_free 6.1 | wall 25740
KL Stats: Epoch 73 Divergences: Uniform: 2.6515154245954804 Unigram: 3.641509598538551
2022-01-28 14:47:29 | INFO | fairseq.trainer | begin training epoch 74
2022-01-28 14:47:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:49:52 | INFO | train_inner | epoch 074:     28 / 64 loss=6.622, ppl=98.52, wps=5789.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.584, train_wall=506, gb_free=6.1, wall=25883
2022-01-28 14:52:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:53:22 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.728 | ppl 847.88 | wps 7850.2 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.326
2022-01-28 14:53:22 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-28 14:53:22 | INFO | train | epoch 074 | loss 6.6 | ppl 97.02 | wps 5924 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.585 | train_wall 324 | gb_free 6.1 | wall 26093
KL Stats: Epoch 74 Divergences: Uniform: 2.6599145195931793 Unigram: 3.6727161269901174
2022-01-28 14:53:22 | INFO | fairseq.trainer | begin training epoch 75
2022-01-28 14:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:58:47 | INFO | train_inner | epoch 075:     64 / 64 loss=6.592, ppl=96.45, wps=6093.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.592, train_wall=506, gb_free=6.1, wall=26418
2022-01-28 14:58:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:59:15 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.859 | ppl 928.85 | wps 7924.9 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.326
2022-01-28 14:59:15 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-28 14:59:15 | INFO | train | epoch 075 | loss 6.572 | ppl 95.13 | wps 5919.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.597 | train_wall 324 | gb_free 6.1 | wall 26446
KL Stats: Epoch 75 Divergences: Uniform: 2.6677873147311764 Unigram: 3.6916189951416234
2022-01-28 14:59:15 | INFO | fairseq.trainer | begin training epoch 76
2022-01-28 14:59:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:04:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:05:08 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.804 | ppl 893.85 | wps 7906.2 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.326
2022-01-28 15:05:08 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-28 15:05:08 | INFO | train | epoch 076 | loss 6.541 | ppl 93.14 | wps 5916.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.607 | train_wall 324 | gb_free 6.1 | wall 26799
KL Stats: Epoch 76 Divergences: Uniform: 2.676770203705105 Unigram: 3.7220396256901878
2022-01-28 15:05:08 | INFO | fairseq.trainer | begin training epoch 77
2022-01-28 15:05:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:08:11 | INFO | train_inner | epoch 077:     36 / 64 loss=6.516, ppl=91.54, wps=5791.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.606, train_wall=508, gb_free=6.1, wall=26982
2022-01-28 15:10:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:11:01 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.758 | ppl 865.93 | wps 7905.4 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.326
2022-01-28 15:11:01 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-28 15:11:01 | INFO | train | epoch 077 | loss 6.511 | ppl 91.23 | wps 5918.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.616 | train_wall 324 | gb_free 6.1 | wall 27151
KL Stats: Epoch 77 Divergences: Uniform: 2.6854287922990836 Unigram: 3.751392547575252
2022-01-28 15:11:01 | INFO | fairseq.trainer | begin training epoch 78
2022-01-28 15:11:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:16:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:16:54 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.805 | ppl 894.51 | wps 7922.7 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.326
2022-01-28 15:16:54 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-28 15:16:54 | INFO | train | epoch 078 | loss 6.483 | ppl 89.43 | wps 5912.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.613 | train_wall 325 | gb_free 6.1 | wall 27505
KL Stats: Epoch 78 Divergences: Uniform: 2.691453206607939 Unigram: 3.766316553036266
2022-01-28 15:16:54 | INFO | fairseq.trainer | begin training epoch 79
2022-01-28 15:16:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:17:35 | INFO | train_inner | epoch 079:      8 / 64 loss=6.497, ppl=90.33, wps=5788.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.617, train_wall=506, gb_free=6.1, wall=27545
2022-01-28 15:22:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:22:46 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.889 | ppl 948.02 | wps 7918.7 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.326
2022-01-28 15:22:46 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-28 15:22:46 | INFO | train | epoch 079 | loss 6.451 | ppl 87.51 | wps 5931.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.601 | train_wall 324 | gb_free 6.1 | wall 27857
KL Stats: Epoch 79 Divergences: Uniform: 2.6939372343324948 Unigram: 3.78126672993646
2022-01-28 15:22:46 | INFO | fairseq.trainer | begin training epoch 80
2022-01-28 15:22:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:26:30 | INFO | train_inner | epoch 080:     44 / 64 loss=6.435, ppl=86.53, wps=6099.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.601, train_wall=507, gb_free=6.1, wall=28081
2022-01-28 15:28:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:28:39 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.808 | ppl 896.48 | wps 7924.5 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.326
2022-01-28 15:28:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-28 15:28:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint80.pt
2022-01-28 15:28:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint80.pt
2022-01-28 15:28:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.808) (writing took 3.8627134785056114 seconds)
2022-01-28 15:28:43 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-28 15:28:43 | INFO | train | epoch 080 | loss 6.427 | ppl 86.02 | wps 5856 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.609 | train_wall 324 | gb_free 6.1 | wall 28213
KL Stats: Epoch 80 Divergences: Uniform: 2.7024125311039207 Unigram: 3.807613960436276
2022-01-28 15:28:43 | INFO | fairseq.trainer | begin training epoch 81
2022-01-28 15:28:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:34:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:34:35 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.903 | ppl 957.55 | wps 7913.3 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.326
2022-01-28 15:34:35 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-28 15:34:35 | INFO | train | epoch 081 | loss 6.401 | ppl 84.53 | wps 5922.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.622 | train_wall 324 | gb_free 6.1 | wall 28566
KL Stats: Epoch 81 Divergences: Uniform: 2.7187858859645067 Unigram: 3.8318851558145184
2022-01-28 15:34:35 | INFO | fairseq.trainer | begin training epoch 82
2022-01-28 15:34:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:35:57 | INFO | train_inner | epoch 082:     16 / 64 loss=6.408, ppl=84.92, wps=5750.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.625, train_wall=506, gb_free=6.1, wall=28648
2022-01-28 15:40:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:40:28 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.839 | ppl 915.94 | wps 7924.9 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.326
2022-01-28 15:40:28 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-28 15:40:28 | INFO | train | epoch 082 | loss 6.374 | ppl 82.95 | wps 5919.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.617 | train_wall 324 | gb_free 6.1 | wall 28919
KL Stats: Epoch 82 Divergences: Uniform: 2.723287194768852 Unigram: 3.8658415518810205
2022-01-28 15:40:28 | INFO | fairseq.trainer | begin training epoch 83
2022-01-28 15:40:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:44:53 | INFO | train_inner | epoch 083:     52 / 64 loss=6.36, ppl=82.13, wps=6103.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.627, train_wall=506, gb_free=6.1, wall=29184
2022-01-28 15:45:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:46:20 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.775 | ppl 876.01 | wps 7902.5 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.326
2022-01-28 15:46:20 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-28 15:46:20 | INFO | train | epoch 083 | loss 6.35 | ppl 81.55 | wps 5929.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.639 | train_wall 324 | gb_free 6.1 | wall 29271
KL Stats: Epoch 83 Divergences: Uniform: 2.733066352271949 Unigram: 3.8812998243823773
2022-01-28 15:46:20 | INFO | fairseq.trainer | begin training epoch 84
2022-01-28 15:46:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:51:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:52:13 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.843 | ppl 918.37 | wps 7920.3 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.326
2022-01-28 15:52:13 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-28 15:52:13 | INFO | train | epoch 084 | loss 6.323 | ppl 80.07 | wps 5919.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.625 | train_wall 324 | gb_free 6.1 | wall 29624
KL Stats: Epoch 84 Divergences: Uniform: 2.7399716252387494 Unigram: 3.8974870511599766
2022-01-28 15:52:13 | INFO | fairseq.trainer | begin training epoch 85
2022-01-28 15:52:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:54:16 | INFO | train_inner | epoch 085:     24 / 64 loss=6.312, ppl=79.48, wps=5791.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.626, train_wall=506, gb_free=6.1, wall=29746
2022-01-28 15:57:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:58:06 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.882 | ppl 943.79 | wps 7921.1 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.326
2022-01-28 15:58:06 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-28 15:58:06 | INFO | train | epoch 085 | loss 6.3 | ppl 78.79 | wps 5924.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.635 | train_wall 324 | gb_free 6.1 | wall 29977
KL Stats: Epoch 85 Divergences: Uniform: 2.7499357247638323 Unigram: 3.920821769577209
2022-01-28 15:58:06 | INFO | fairseq.trainer | begin training epoch 86
2022-01-28 15:58:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:03:12 | INFO | train_inner | epoch 086:     60 / 64 loss=6.297, ppl=78.64, wps=6092.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.638, train_wall=507, gb_free=6.1, wall=30283
2022-01-28 16:03:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:03:59 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.933 | ppl 977.34 | wps 7894.4 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.326
2022-01-28 16:03:59 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-28 16:03:59 | INFO | train | epoch 086 | loss 6.276 | ppl 77.47 | wps 5915.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.639 | train_wall 324 | gb_free 6.1 | wall 30330
KL Stats: Epoch 86 Divergences: Uniform: 2.749816638440277 Unigram: 3.9447428747330355
2022-01-28 16:03:59 | INFO | fairseq.trainer | begin training epoch 87
2022-01-28 16:03:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:09:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:09:52 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.93 | ppl 975.62 | wps 7912.2 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.326
2022-01-28 16:09:52 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-28 16:09:52 | INFO | train | epoch 087 | loss 6.254 | ppl 76.3 | wps 5922.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.656 | train_wall 324 | gb_free 6.1 | wall 30682
KL Stats: Epoch 87 Divergences: Uniform: 2.7570176675909104 Unigram: 3.9567084475405947
2022-01-28 16:09:52 | INFO | fairseq.trainer | begin training epoch 88
2022-01-28 16:09:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:12:35 | INFO | train_inner | epoch 088:     32 / 64 loss=6.24, ppl=75.6, wps=5791.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.653, train_wall=506, gb_free=6.1, wall=30846
2022-01-28 16:15:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:15:44 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.901 | ppl 955.9 | wps 7914.2 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.326
2022-01-28 16:15:44 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-28 16:15:44 | INFO | train | epoch 088 | loss 6.231 | ppl 75.1 | wps 5923.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.651 | train_wall 324 | gb_free 6.1 | wall 31035
KL Stats: Epoch 88 Divergences: Uniform: 2.763481384587193 Unigram: 3.9818362478568616
2022-01-28 16:15:44 | INFO | fairseq.trainer | begin training epoch 89
2022-01-28 16:15:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:21:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:21:37 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.911 | ppl 962.89 | wps 7891.1 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.326
2022-01-28 16:21:37 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-28 16:21:37 | INFO | train | epoch 089 | loss 6.213 | ppl 74.2 | wps 5922 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.674 | train_wall 324 | gb_free 6.1 | wall 31388
KL Stats: Epoch 89 Divergences: Uniform: 2.772029917556553 Unigram: 3.9957191701788295
2022-01-28 16:21:37 | INFO | fairseq.trainer | begin training epoch 90
2022-01-28 16:21:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:21:57 | INFO | train_inner | epoch 090:      4 / 64 loss=6.224, ppl=74.73, wps=5796.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.667, train_wall=506, gb_free=6.1, wall=31408
2022-01-28 16:27:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:27:30 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.974 | ppl 1005.38 | wps 7878.7 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.326
2022-01-28 16:27:30 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-28 16:27:30 | INFO | train | epoch 090 | loss 6.188 | ppl 72.91 | wps 5920.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.655 | train_wall 324 | gb_free 6.1 | wall 31740
KL Stats: Epoch 90 Divergences: Uniform: 2.7743925227094532 Unigram: 4.011171219457905
2022-01-28 16:27:30 | INFO | fairseq.trainer | begin training epoch 91
2022-01-28 16:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:30:54 | INFO | train_inner | epoch 091:     40 / 64 loss=6.17, ppl=71.99, wps=6094.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.653, train_wall=507, gb_free=6.1, wall=31944
2022-01-28 16:32:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:33:22 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.945 | ppl 985.5 | wps 7902.6 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.326
2022-01-28 16:33:22 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-28 16:33:22 | INFO | train | epoch 091 | loss 6.166 | ppl 71.78 | wps 5922.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.657 | train_wall 324 | gb_free 6.1 | wall 32093
KL Stats: Epoch 91 Divergences: Uniform: 2.7827876296722778 Unigram: 4.044986030868144
2022-01-28 16:33:22 | INFO | fairseq.trainer | begin training epoch 92
2022-01-28 16:33:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:38:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:39:14 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.98 | ppl 1010.04 | wps 7926.3 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.326
2022-01-28 16:39:14 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-28 16:39:14 | INFO | train | epoch 092 | loss 6.147 | ppl 70.88 | wps 5930.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.681 | train_wall 324 | gb_free 6.1 | wall 32445
KL Stats: Epoch 92 Divergences: Uniform: 2.789062773022607 Unigram: 4.062267832792022
2022-01-28 16:39:14 | INFO | fairseq.trainer | begin training epoch 93
2022-01-28 16:39:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:40:16 | INFO | train_inner | epoch 093:     12 / 64 loss=6.156, ppl=71.32, wps=5799.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.674, train_wall=505, gb_free=6.1, wall=32506
2022-01-28 16:44:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:45:07 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.911 | ppl 962.51 | wps 7934.9 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.326
2022-01-28 16:45:07 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-28 16:45:07 | INFO | train | epoch 093 | loss 6.129 | ppl 70 | wps 5920.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.677 | train_wall 324 | gb_free 6.1 | wall 32798
KL Stats: Epoch 93 Divergences: Uniform: 2.7930974417456613 Unigram: 4.082826242518859
2022-01-28 16:45:07 | INFO | fairseq.trainer | begin training epoch 94
2022-01-28 16:45:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:49:12 | INFO | train_inner | epoch 094:     48 / 64 loss=6.115, ppl=69.29, wps=6088.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.68, train_wall=508, gb_free=6.1, wall=33043
2022-01-28 16:50:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:51:01 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 10.009 | ppl 1030.45 | wps 7912.3 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.326
2022-01-28 16:51:01 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-28 16:51:01 | INFO | train | epoch 094 | loss 6.108 | ppl 68.96 | wps 5911.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.679 | train_wall 325 | gb_free 6.1 | wall 33151
KL Stats: Epoch 94 Divergences: Uniform: 2.794718596335257 Unigram: 4.100380602911532
2022-01-28 16:51:01 | INFO | fairseq.trainer | begin training epoch 95
2022-01-28 16:51:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:56:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:56:53 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 10.034 | ppl 1048.51 | wps 7905.2 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.326
2022-01-28 16:56:53 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-28 16:56:53 | INFO | train | epoch 095 | loss 6.088 | ppl 68.01 | wps 5927.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.671 | train_wall 324 | gb_free 6.1 | wall 33504
KL Stats: Epoch 95 Divergences: Uniform: 2.798401115843311 Unigram: 4.116616116594432
2022-01-28 16:56:53 | INFO | fairseq.trainer | begin training epoch 96
2022-01-28 16:56:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:58:35 | INFO | train_inner | epoch 096:     20 / 64 loss=6.087, ppl=67.98, wps=5792.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.679, train_wall=506, gb_free=6.1, wall=33606
2022-01-28 17:02:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:02:46 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.938 | ppl 981.04 | wps 7904.9 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.326
2022-01-28 17:02:46 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-28 17:02:46 | INFO | train | epoch 096 | loss 6.071 | ppl 67.21 | wps 5918 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.698 | train_wall 324 | gb_free 6.1 | wall 33857
KL Stats: Epoch 96 Divergences: Uniform: 2.8145845751205765 Unigram: 4.132888318801318
2022-01-28 17:02:46 | INFO | fairseq.trainer | begin training epoch 97
2022-01-28 17:02:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:07:31 | INFO | train_inner | epoch 097:     56 / 64 loss=6.065, ppl=66.94, wps=6097.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.693, train_wall=507, gb_free=6.1, wall=34142
2022-01-28 17:08:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:08:38 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 10.029 | ppl 1044.88 | wps 7917.9 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.326
2022-01-28 17:08:38 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-28 17:08:38 | INFO | train | epoch 097 | loss 6.054 | ppl 66.42 | wps 5925.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.694 | train_wall 324 | gb_free 6.1 | wall 34209
KL Stats: Epoch 97 Divergences: Uniform: 2.8203055707285576 Unigram: 4.15749548320711
2022-01-28 17:08:38 | INFO | fairseq.trainer | begin training epoch 98
2022-01-28 17:08:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:14:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:14:31 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.983 | ppl 1012.16 | wps 7921.5 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.326
2022-01-28 17:14:31 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-28 17:14:31 | INFO | train | epoch 098 | loss 6.034 | ppl 65.54 | wps 5916.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.722 | train_wall 325 | gb_free 6.1 | wall 34562
KL Stats: Epoch 98 Divergences: Uniform: 2.8204585626503125 Unigram: 4.162579997613385
2022-01-28 17:14:31 | INFO | fairseq.trainer | begin training epoch 99
2022-01-28 17:14:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:16:54 | INFO | train_inner | epoch 099:     28 / 64 loss=6.025, ppl=65.13, wps=5791, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.724, train_wall=506, gb_free=6.1, wall=34705
2022-01-28 17:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:20:24 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 10.008 | ppl 1029.95 | wps 7889.3 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.326
2022-01-28 17:20:24 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-28 17:20:24 | INFO | train | epoch 099 | loss 6.016 | ppl 64.72 | wps 5921.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.722 | train_wall 324 | gb_free 6.1 | wall 34915
KL Stats: Epoch 99 Divergences: Uniform: 2.826178525640231 Unigram: 4.1873297947436185
2022-01-28 17:20:24 | INFO | fairseq.trainer | begin training epoch 100
2022-01-28 17:20:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:25:50 | INFO | train_inner | epoch 100:     64 / 64 loss=6.019, ppl=64.83, wps=6087.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.723, train_wall=506, gb_free=6.1, wall=35240
2022-01-28 17:25:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:26:17 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 10.007 | ppl 1028.75 | wps 7963.2 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.326
2022-01-28 17:26:17 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-28 17:26:17 | INFO | train | epoch 100 | loss 6.001 | ppl 64.04 | wps 5915.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.727 | train_wall 325 | gb_free 6.1 | wall 35268
KL Stats: Epoch 100 Divergences: Uniform: 2.824272446985833 Unigram: 4.195015192349328
2022-01-28 17:26:17 | INFO | fairseq.trainer | begin training epoch 101
2022-01-28 17:26:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:31:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:32:11 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 10.07 | ppl 1075.1 | wps 7938.4 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.326
2022-01-28 17:32:11 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-28 17:32:11 | INFO | train | epoch 101 | loss 5.983 | ppl 63.23 | wps 5905.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.731 | train_wall 325 | gb_free 6.1 | wall 35622
KL Stats: Epoch 101 Divergences: Uniform: 2.8393487423407042 Unigram: 4.218693767713537
2022-01-28 17:32:11 | INFO | fairseq.trainer | begin training epoch 102
2022-01-28 17:32:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:35:15 | INFO | train_inner | epoch 102:     36 / 64 loss=5.968, ppl=62.61, wps=5785.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.731, train_wall=508, gb_free=6.1, wall=35805
2022-01-28 17:37:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:38:04 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 10.079 | ppl 1081.82 | wps 7911.2 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.326
2022-01-28 17:38:04 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-28 17:38:04 | INFO | train | epoch 102 | loss 5.968 | ppl 62.57 | wps 5916.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.729 | train_wall 324 | gb_free 6.1 | wall 35975
KL Stats: Epoch 102 Divergences: Uniform: 2.839530661642631 Unigram: 4.2357347550203786
2022-01-28 17:38:04 | INFO | fairseq.trainer | begin training epoch 103
2022-01-28 17:38:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:43:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:43:57 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 10.091 | ppl 1090.82 | wps 7915.4 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.326
2022-01-28 17:43:57 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-28 17:43:57 | INFO | train | epoch 103 | loss 5.949 | ppl 61.78 | wps 5912.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.721 | train_wall 325 | gb_free 6.1 | wall 36328
KL Stats: Epoch 103 Divergences: Uniform: 2.8518920019897314 Unigram: 4.2535451524161365
2022-01-28 17:43:57 | INFO | fairseq.trainer | begin training epoch 104
2022-01-28 17:43:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:44:38 | INFO | train_inner | epoch 104:      8 / 64 loss=5.957, ppl=62.11, wps=5786.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.722, train_wall=507, gb_free=6.1, wall=36369
2022-01-28 17:49:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:49:50 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 10.078 | ppl 1080.67 | wps 7925.1 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.326
2022-01-28 17:49:50 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-28 17:49:50 | INFO | train | epoch 104 | loss 5.936 | ppl 61.23 | wps 5916 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.735 | train_wall 325 | gb_free 6.1 | wall 36681
KL Stats: Epoch 104 Divergences: Uniform: 2.846316067525878 Unigram: 4.271676171900059
2022-01-28 17:49:50 | INFO | fairseq.trainer | begin training epoch 105
2022-01-28 17:49:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:53:35 | INFO | train_inner | epoch 105:     44 / 64 loss=5.924, ppl=60.72, wps=6088.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.741, train_wall=508, gb_free=6.1, wall=36905
2022-01-28 17:55:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:55:43 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 10.029 | ppl 1044.78 | wps 7921.5 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.326
2022-01-28 17:55:43 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-28 17:55:43 | INFO | train | epoch 105 | loss 5.921 | ppl 60.57 | wps 5919.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.745 | train_wall 324 | gb_free 6.1 | wall 37034
KL Stats: Epoch 105 Divergences: Uniform: 2.853214934408744 Unigram: 4.285304926894688
2022-01-28 17:55:43 | INFO | fairseq.trainer | begin training epoch 106
2022-01-28 17:55:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:01:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:01:35 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 10.108 | ppl 1103.91 | wps 7953.9 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.326
2022-01-28 18:01:35 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-28 18:01:35 | INFO | train | epoch 106 | loss 5.903 | ppl 59.84 | wps 5928.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.729 | train_wall 324 | gb_free 6.1 | wall 37386
KL Stats: Epoch 106 Divergences: Uniform: 2.8544577686616277 Unigram: 4.292459220183567
2022-01-28 18:01:35 | INFO | fairseq.trainer | begin training epoch 107
2022-01-28 18:01:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:02:57 | INFO | train_inner | epoch 107:     16 / 64 loss=5.907, ppl=60, wps=5800.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.737, train_wall=505, gb_free=6.1, wall=37467
2022-01-28 18:07:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:07:27 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 10.11 | ppl 1105.39 | wps 7939.2 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.326
2022-01-28 18:07:27 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-28 18:07:27 | INFO | train | epoch 107 | loss 5.887 | ppl 59.19 | wps 5933.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.745 | train_wall 324 | gb_free 6.1 | wall 37738
KL Stats: Epoch 107 Divergences: Uniform: 2.8634388464797724 Unigram: 4.313897806964236
2022-01-28 18:07:27 | INFO | fairseq.trainer | begin training epoch 108
2022-01-28 18:07:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:11:52 | INFO | train_inner | epoch 108:     52 / 64 loss=5.883, ppl=59, wps=6099.7, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.756, train_wall=507, gb_free=6.1, wall=38003
2022-01-28 18:12:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:13:20 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 10.112 | ppl 1106.8 | wps 7923.8 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.326
2022-01-28 18:13:20 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-28 18:13:20 | INFO | train | epoch 108 | loss 5.876 | ppl 58.74 | wps 5917.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.777 | train_wall 324 | gb_free 6.1 | wall 38091
KL Stats: Epoch 108 Divergences: Uniform: 2.867727607078569 Unigram: 4.324856370171599
2022-01-28 18:13:20 | INFO | fairseq.trainer | begin training epoch 109
2022-01-28 18:13:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:18:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:19:13 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 10.121 | ppl 1113.86 | wps 7863.4 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.326
2022-01-28 18:19:13 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-28 18:19:13 | INFO | train | epoch 109 | loss 5.86 | ppl 58.09 | wps 5925.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.763 | train_wall 324 | gb_free 6.1 | wall 38443
KL Stats: Epoch 109 Divergences: Uniform: 2.8681110768544635 Unigram: 4.346300518147637
2022-01-28 18:19:13 | INFO | fairseq.trainer | begin training epoch 110
2022-01-28 18:19:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:21:15 | INFO | train_inner | epoch 110:     24 / 64 loss=5.854, ppl=57.86, wps=5790.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.769, train_wall=506, gb_free=6.1, wall=38566
2022-01-28 18:24:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:25:06 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.166 | ppl 1148.73 | wps 7779.4 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.326
2022-01-28 18:25:06 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-28 18:25:06 | INFO | train | epoch 110 | loss 5.847 | ppl 57.54 | wps 5911.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.769 | train_wall 324 | gb_free 6.1 | wall 38797
KL Stats: Epoch 110 Divergences: Uniform: 2.8757373250647222 Unigram: 4.360464246337592
2022-01-28 18:25:06 | INFO | fairseq.trainer | begin training epoch 111
2022-01-28 18:25:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:30:11 | INFO | train_inner | epoch 111:     60 / 64 loss=5.846, ppl=57.51, wps=6097, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.778, train_wall=507, gb_free=6.1, wall=39102
2022-01-28 18:30:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:30:58 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 10.132 | ppl 1121.93 | wps 7967.3 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.326
2022-01-28 18:30:58 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-28 18:30:58 | INFO | train | epoch 111 | loss 5.833 | ppl 57 | wps 5933.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.783 | train_wall 324 | gb_free 6.1 | wall 39149
KL Stats: Epoch 111 Divergences: Uniform: 2.8757006983412037 Unigram: 4.379962283666537
2022-01-28 18:30:58 | INFO | fairseq.trainer | begin training epoch 112
2022-01-28 18:30:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:36:50 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.18 | ppl 1159.82 | wps 7907.7 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.326
2022-01-28 18:36:50 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-28 18:36:50 | INFO | train | epoch 112 | loss 5.818 | ppl 56.42 | wps 5929.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.779 | train_wall 324 | gb_free 6.1 | wall 39501
KL Stats: Epoch 112 Divergences: Uniform: 2.879814677591912 Unigram: 4.395338171490341
2022-01-28 18:36:50 | INFO | fairseq.trainer | begin training epoch 113
2022-01-28 18:36:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:39:33 | INFO | train_inner | epoch 113:     32 / 64 loss=5.806, ppl=55.96, wps=5806.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.778, train_wall=505, gb_free=6.1, wall=39664
2022-01-28 18:42:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:42:42 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.134 | ppl 1123.32 | wps 7980.4 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.326
2022-01-28 18:42:42 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-28 18:42:42 | INFO | train | epoch 113 | loss 5.803 | ppl 55.84 | wps 5944.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.773 | train_wall 323 | gb_free 6.1 | wall 39852
KL Stats: Epoch 113 Divergences: Uniform: 2.887484484654345 Unigram: 4.408567771877758
2022-01-28 18:42:42 | INFO | fairseq.trainer | begin training epoch 114
2022-01-28 18:42:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:48:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:48:33 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 10.158 | ppl 1142.84 | wps 7909.4 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.326
2022-01-28 18:48:33 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-28 18:48:33 | INFO | train | epoch 114 | loss 5.791 | ppl 55.37 | wps 5935.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.791 | train_wall 323 | gb_free 6.1 | wall 40204
KL Stats: Epoch 114 Divergences: Uniform: 2.888618008486176 Unigram: 4.419617988774367
2022-01-28 18:48:33 | INFO | fairseq.trainer | begin training epoch 115
2022-01-28 18:48:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:48:54 | INFO | train_inner | epoch 115:      4 / 64 loss=5.803, ppl=55.84, wps=5810.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.789, train_wall=505, gb_free=6.1, wall=40225
2022-01-28 18:53:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:54:26 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.163 | ppl 1146.61 | wps 7906.4 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.326
2022-01-28 18:54:26 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-28 18:54:26 | INFO | train | epoch 115 | loss 5.779 | ppl 54.9 | wps 5925.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.8 | train_wall 324 | gb_free 6.1 | wall 40557
KL Stats: Epoch 115 Divergences: Uniform: 2.893427841725796 Unigram: 4.43073827533578
2022-01-28 18:54:26 | INFO | fairseq.trainer | begin training epoch 116
2022-01-28 18:54:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:57:50 | INFO | train_inner | epoch 116:     40 / 64 loss=5.764, ppl=54.35, wps=6096.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.791, train_wall=507, gb_free=6.1, wall=40761
2022-01-28 18:59:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:00:18 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.127 | ppl 1118.07 | wps 7912.6 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.326
2022-01-28 19:00:18 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-28 19:00:18 | INFO | train | epoch 116 | loss 5.765 | ppl 54.38 | wps 5928.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.788 | train_wall 324 | gb_free 6.1 | wall 40909
KL Stats: Epoch 116 Divergences: Uniform: 2.8974294330192256 Unigram: 4.437428403736695
2022-01-28 19:00:18 | INFO | fairseq.trainer | begin training epoch 117
2022-01-28 19:00:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:05:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:06:11 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.225 | ppl 1196.82 | wps 7907.8 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.326
2022-01-28 19:06:11 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-28 19:06:11 | INFO | train | epoch 117 | loss 5.754 | ppl 53.98 | wps 5920.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.801 | train_wall 324 | gb_free 6.1 | wall 41262
KL Stats: Epoch 117 Divergences: Uniform: 2.896982778298606 Unigram: 4.461594135032143
2022-01-28 19:06:11 | INFO | fairseq.trainer | begin training epoch 118
2022-01-28 19:06:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:07:12 | INFO | train_inner | epoch 118:     12 / 64 loss=5.76, ppl=54.18, wps=5799.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.808, train_wall=505, gb_free=6.1, wall=41323
2022-01-28 19:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:12:03 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.171 | ppl 1153.16 | wps 7913.3 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.326
2022-01-28 19:12:03 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-28 19:12:03 | INFO | train | epoch 118 | loss 5.742 | ppl 53.5 | wps 5934.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.812 | train_wall 323 | gb_free 6.1 | wall 41614
KL Stats: Epoch 118 Divergences: Uniform: 2.90852886467471 Unigram: 4.4740443212743655
2022-01-28 19:12:03 | INFO | fairseq.trainer | begin training epoch 119
2022-01-28 19:12:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:16:08 | INFO | train_inner | epoch 119:     48 / 64 loss=5.73, ppl=53.08, wps=6102.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.795, train_wall=507, gb_free=6.1, wall=41858
2022-01-28 19:17:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:17:55 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.157 | ppl 1141.33 | wps 7911.4 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.326
2022-01-28 19:17:55 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-28 19:17:55 | INFO | train | epoch 119 | loss 5.727 | ppl 52.97 | wps 5923.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.795 | train_wall 324 | gb_free 6.1 | wall 41966
KL Stats: Epoch 119 Divergences: Uniform: 2.9090011743138326 Unigram: 4.493895493027797
2022-01-28 19:17:56 | INFO | fairseq.trainer | begin training epoch 120
2022-01-28 19:17:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:23:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:23:48 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.224 | ppl 1196.03 | wps 7944.4 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.326
2022-01-28 19:23:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-28 19:23:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint120.pt
2022-01-28 19:23:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint120.pt
2022-01-28 19:23:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.224) (writing took 3.6825054604560137 seconds)
2022-01-28 19:23:52 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-28 19:23:52 | INFO | train | epoch 120 | loss 5.718 | ppl 52.65 | wps 5865.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.841 | train_wall 324 | gb_free 6.1 | wall 42322
KL Stats: Epoch 120 Divergences: Uniform: 2.913523930948785 Unigram: 4.500055369619682
2022-01-28 19:23:52 | INFO | fairseq.trainer | begin training epoch 121
2022-01-28 19:23:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:25:33 | INFO | train_inner | epoch 121:     20 / 64 loss=5.72, ppl=52.72, wps=5761.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.843, train_wall=505, gb_free=6.1, wall=42424
2022-01-28 19:29:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:29:43 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.202 | ppl 1178.1 | wps 7951.1 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.326
2022-01-28 19:29:43 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-28 19:29:43 | INFO | train | epoch 121 | loss 5.708 | ppl 52.27 | wps 5937.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.832 | train_wall 323 | gb_free 6.1 | wall 42674
KL Stats: Epoch 121 Divergences: Uniform: 2.9143809572728645 Unigram: 4.514382908834228
2022-01-28 19:29:43 | INFO | fairseq.trainer | begin training epoch 122
2022-01-28 19:29:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:34:29 | INFO | train_inner | epoch 122:     56 / 64 loss=5.704, ppl=52.12, wps=6107.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.825, train_wall=506, gb_free=6.1, wall=42959
2022-01-28 19:35:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:35:35 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.184 | ppl 1163.16 | wps 7936 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.326
2022-01-28 19:35:35 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-28 19:35:35 | INFO | train | epoch 122 | loss 5.696 | ppl 51.83 | wps 5932.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.833 | train_wall 324 | gb_free 6.1 | wall 43026
KL Stats: Epoch 122 Divergences: Uniform: 2.91664986985025 Unigram: 4.526332197218961
2022-01-28 19:35:35 | INFO | fairseq.trainer | begin training epoch 123
2022-01-28 19:35:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:41:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:41:27 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.226 | ppl 1197.87 | wps 7911.9 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.326
2022-01-28 19:41:27 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-28 19:41:27 | INFO | train | epoch 123 | loss 5.682 | ppl 51.35 | wps 5933.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.835 | train_wall 323 | gb_free 6.1 | wall 43378
KL Stats: Epoch 123 Divergences: Uniform: 2.9160364511221504 Unigram: 4.544041454553922
2022-01-28 19:41:27 | INFO | fairseq.trainer | begin training epoch 124
2022-01-28 19:41:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:43:50 | INFO | train_inner | epoch 124:     28 / 64 loss=5.675, ppl=51.1, wps=5808.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.827, train_wall=505, gb_free=6.1, wall=43521
2022-01-28 19:46:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:47:19 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.217 | ppl 1190.37 | wps 7932.1 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.326
2022-01-28 19:47:19 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-28 19:47:19 | INFO | train | epoch 124 | loss 5.67 | ppl 50.93 | wps 5933.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.824 | train_wall 324 | gb_free 6.1 | wall 43730
KL Stats: Epoch 124 Divergences: Uniform: 2.915198025362681 Unigram: 4.5475545003580296
2022-01-28 19:47:19 | INFO | fairseq.trainer | begin training epoch 125
2022-01-28 19:47:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:52:44 | INFO | train_inner | epoch 125:     64 / 64 loss=5.675, ppl=51.09, wps=6097, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.834, train_wall=506, gb_free=6.1, wall=44055
2022-01-28 19:52:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:53:12 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.261 | ppl 1227.09 | wps 7893.1 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.326
2022-01-28 19:53:12 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-28 19:53:12 | INFO | train | epoch 125 | loss 5.661 | ppl 50.59 | wps 5921.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.831 | train_wall 324 | gb_free 6.1 | wall 44083
KL Stats: Epoch 125 Divergences: Uniform: 2.9228282789627396 Unigram: 4.566401216859982
2022-01-28 19:53:12 | INFO | fairseq.trainer | begin training epoch 126
2022-01-28 19:53:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:59:04 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.196 | ppl 1173.32 | wps 7948.4 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.326
2022-01-28 19:59:04 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-28 19:59:04 | INFO | train | epoch 126 | loss 5.65 | ppl 50.21 | wps 5928.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.825 | train_wall 324 | gb_free 6.1 | wall 44435
KL Stats: Epoch 126 Divergences: Uniform: 2.931145260506506 Unigram: 4.583903470570598
2022-01-28 19:59:04 | INFO | fairseq.trainer | begin training epoch 127
2022-01-28 19:59:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:02:08 | INFO | train_inner | epoch 127:     36 / 64 loss=5.638, ppl=49.81, wps=5801.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.851, train_wall=507, gb_free=6.1, wall=44619
2022-01-28 20:04:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:04:56 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.195 | ppl 1172.5 | wps 7947.4 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.326
2022-01-28 20:04:56 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-28 20:04:56 | INFO | train | epoch 127 | loss 5.641 | ppl 49.91 | wps 5934.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.877 | train_wall 324 | gb_free 6.1 | wall 44787
KL Stats: Epoch 127 Divergences: Uniform: 2.9329548366748117 Unigram: 4.585434422617852
2022-01-28 20:04:56 | INFO | fairseq.trainer | begin training epoch 128
2022-01-28 20:04:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:10:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:10:49 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.228 | ppl 1198.91 | wps 7954.7 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.326
2022-01-28 20:10:49 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-28 20:10:49 | INFO | train | epoch 128 | loss 5.629 | ppl 49.48 | wps 5925.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.868 | train_wall 324 | gb_free 6.1 | wall 45140
KL Stats: Epoch 128 Divergences: Uniform: 2.923145826054424 Unigram: 4.595537100375836
2022-01-28 20:10:49 | INFO | fairseq.trainer | begin training epoch 129
2022-01-28 20:10:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:11:30 | INFO | train_inner | epoch 129:      8 / 64 loss=5.636, ppl=49.74, wps=5801.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.866, train_wall=505, gb_free=6.1, wall=45180
2022-01-28 20:16:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:16:41 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.189 | ppl 1167.42 | wps 7912 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.326
2022-01-28 20:16:41 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-28 20:16:41 | INFO | train | epoch 129 | loss 5.622 | ppl 49.25 | wps 5925.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.888 | train_wall 324 | gb_free 6.1 | wall 45492
KL Stats: Epoch 129 Divergences: Uniform: 2.929744821625501 Unigram: 4.607004362268021
2022-01-28 20:16:41 | INFO | fairseq.trainer | begin training epoch 130
2022-01-28 20:16:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:20:26 | INFO | train_inner | epoch 130:     44 / 64 loss=5.609, ppl=48.82, wps=6093.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.875, train_wall=507, gb_free=6.1, wall=45717
2022-01-28 20:22:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:22:34 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.288 | ppl 1250.45 | wps 7909 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.326
2022-01-28 20:22:34 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-28 20:22:34 | INFO | train | epoch 130 | loss 5.608 | ppl 48.79 | wps 5916.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.865 | train_wall 324 | gb_free 6.1 | wall 45845
KL Stats: Epoch 130 Divergences: Uniform: 2.9330096932659666 Unigram: 4.628320513647819
2022-01-28 20:22:34 | INFO | fairseq.trainer | begin training epoch 131
2022-01-28 20:22:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:28:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:28:27 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.251 | ppl 1218.75 | wps 7893 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.326
2022-01-28 20:28:27 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-28 20:28:27 | INFO | train | epoch 131 | loss 5.601 | ppl 48.52 | wps 5918.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.894 | train_wall 324 | gb_free 6.1 | wall 46198
KL Stats: Epoch 131 Divergences: Uniform: 2.934985056698084 Unigram: 4.629325769765611
2022-01-28 20:28:27 | INFO | fairseq.trainer | begin training epoch 132
2022-01-28 20:28:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:29:49 | INFO | train_inner | epoch 132:     16 / 64 loss=5.603, ppl=48.6, wps=5789.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.882, train_wall=506, gb_free=6.1, wall=46280
2022-01-28 20:33:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:34:21 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.265 | ppl 1230.66 | wps 7931.8 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.326
2022-01-28 20:34:21 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-28 20:34:21 | INFO | train | epoch 132 | loss 5.589 | ppl 48.14 | wps 5911.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.885 | train_wall 325 | gb_free 6.1 | wall 46551
KL Stats: Epoch 132 Divergences: Uniform: 2.9356706579473353 Unigram: 4.653152776304161
2022-01-28 20:34:21 | INFO | fairseq.trainer | begin training epoch 133
2022-01-28 20:34:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:38:46 | INFO | train_inner | epoch 133:     52 / 64 loss=5.584, ppl=47.97, wps=6085, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.904, train_wall=508, gb_free=6.1, wall=46817
2022-01-28 20:39:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:40:14 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.282 | ppl 1245.27 | wps 7929.6 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.326
2022-01-28 20:40:14 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-28 20:40:14 | INFO | train | epoch 133 | loss 5.58 | ppl 47.84 | wps 5913.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.912 | train_wall 325 | gb_free 6.1 | wall 46905
KL Stats: Epoch 133 Divergences: Uniform: 2.947139322413797 Unigram: 4.658479379644619
2022-01-28 20:40:14 | INFO | fairseq.trainer | begin training epoch 134
2022-01-28 20:40:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:45:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:46:07 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.317 | ppl 1275.84 | wps 7918.9 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.326
2022-01-28 20:46:07 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-28 20:46:07 | INFO | train | epoch 134 | loss 5.571 | ppl 47.55 | wps 5920 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.926 | train_wall 324 | gb_free 6.1 | wall 47257
KL Stats: Epoch 134 Divergences: Uniform: 2.9411135552673406 Unigram: 4.677324379702118
2022-01-28 20:46:07 | INFO | fairseq.trainer | begin training epoch 135
2022-01-28 20:46:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:48:09 | INFO | train_inner | epoch 135:     24 / 64 loss=5.571, ppl=47.53, wps=5792.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.924, train_wall=506, gb_free=6.1, wall=47380
2022-01-28 20:51:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:51:59 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.251 | ppl 1218.18 | wps 7937.5 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.326
2022-01-28 20:51:59 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-28 20:51:59 | INFO | train | epoch 135 | loss 5.56 | ppl 47.19 | wps 5924.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.884 | train_wall 324 | gb_free 6.1 | wall 47610
KL Stats: Epoch 135 Divergences: Uniform: 2.950843291657266 Unigram: 4.686307114280704
2022-01-28 20:51:59 | INFO | fairseq.trainer | begin training epoch 136
2022-01-28 20:51:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:57:05 | INFO | train_inner | epoch 136:     60 / 64 loss=5.562, ppl=47.24, wps=6097.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.901, train_wall=507, gb_free=6.1, wall=47916
2022-01-28 20:57:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:57:52 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.327 | ppl 1284.9 | wps 7918.6 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.326
2022-01-28 20:57:52 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-28 20:57:52 | INFO | train | epoch 136 | loss 5.554 | ppl 46.97 | wps 5922.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.924 | train_wall 324 | gb_free 6.1 | wall 47963
KL Stats: Epoch 136 Divergences: Uniform: 2.944617387616682 Unigram: 4.688226809884727
2022-01-28 20:57:52 | INFO | fairseq.trainer | begin training epoch 137
2022-01-28 20:57:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:03:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:03:44 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.411 | ppl 1361.73 | wps 7903.7 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.326
2022-01-28 21:03:44 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-28 21:03:44 | INFO | train | epoch 137 | loss 5.543 | ppl 46.62 | wps 5922.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.913 | train_wall 324 | gb_free 6.1 | wall 48315
KL Stats: Epoch 137 Divergences: Uniform: 2.946300688395223 Unigram: 4.705965392175802
2022-01-28 21:03:44 | INFO | fairseq.trainer | begin training epoch 138
2022-01-28 21:03:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:06:28 | INFO | train_inner | epoch 138:     32 / 64 loss=5.534, ppl=46.34, wps=5793.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.913, train_wall=506, gb_free=6.1, wall=48478
2022-01-28 21:09:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:09:37 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.385 | ppl 1337.12 | wps 7903.6 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.326
2022-01-28 21:09:37 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-28 21:09:37 | INFO | train | epoch 138 | loss 5.534 | ppl 46.32 | wps 5917.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.932 | train_wall 324 | gb_free 6.1 | wall 48668
KL Stats: Epoch 138 Divergences: Uniform: 2.9470303372917734 Unigram: 4.708562935610321
2022-01-28 21:09:37 | INFO | fairseq.trainer | begin training epoch 139
2022-01-28 21:09:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:15:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:15:30 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.315 | ppl 1274.14 | wps 7921.2 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.326
2022-01-28 21:15:30 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-28 21:15:30 | INFO | train | epoch 139 | loss 5.525 | ppl 46.04 | wps 5923.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.94 | train_wall 324 | gb_free 6.1 | wall 49021
KL Stats: Epoch 139 Divergences: Uniform: 2.951840734883938 Unigram: 4.724573653060703
2022-01-28 21:15:30 | INFO | fairseq.trainer | begin training epoch 140
2022-01-28 21:15:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:15:51 | INFO | train_inner | epoch 140:      4 / 64 loss=5.533, ppl=46.29, wps=5790.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.946, train_wall=506, gb_free=6.1, wall=49041
2022-01-28 21:20:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:21:23 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.317 | ppl 1275.93 | wps 7897.3 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.326
2022-01-28 21:21:23 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-28 21:21:23 | INFO | train | epoch 140 | loss 5.518 | ppl 45.83 | wps 5920.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.956 | train_wall 324 | gb_free 6.1 | wall 49374
KL Stats: Epoch 140 Divergences: Uniform: 2.951970174690379 Unigram: 4.729392544407343
2022-01-28 21:21:23 | INFO | fairseq.trainer | begin training epoch 141
2022-01-28 21:21:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:24:47 | INFO | train_inner | epoch 141:     40 / 64 loss=5.509, ppl=45.54, wps=6095.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.949, train_wall=507, gb_free=6.1, wall=49578
2022-01-28 21:26:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:27:16 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.319 | ppl 1277.59 | wps 7923.6 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.326
2022-01-28 21:27:16 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-28 21:27:16 | INFO | train | epoch 141 | loss 5.508 | ppl 45.5 | wps 5919.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.936 | train_wall 324 | gb_free 6.1 | wall 49726
KL Stats: Epoch 141 Divergences: Uniform: 2.9578667965350127 Unigram: 4.747178242992836
2022-01-28 21:27:16 | INFO | fairseq.trainer | begin training epoch 142
2022-01-28 21:27:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:32:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:33:08 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.308 | ppl 1267.72 | wps 7962.1 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.326
2022-01-28 21:33:08 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-28 21:33:08 | INFO | train | epoch 142 | loss 5.499 | ppl 45.22 | wps 5929.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.949 | train_wall 324 | gb_free 6.1 | wall 50079
KL Stats: Epoch 142 Divergences: Uniform: 2.9559981076917383 Unigram: 4.753810440652697
2022-01-28 21:33:08 | INFO | fairseq.trainer | begin training epoch 143
2022-01-28 21:33:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:34:09 | INFO | train_inner | epoch 143:     12 / 64 loss=5.501, ppl=45.28, wps=5798.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.945, train_wall=506, gb_free=6.1, wall=50140
2022-01-28 21:38:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:39:01 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.365 | ppl 1318.93 | wps 7896.1 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.326
2022-01-28 21:39:01 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-28 21:39:01 | INFO | train | epoch 143 | loss 5.494 | ppl 45.06 | wps 5922.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.967 | train_wall 324 | gb_free 6.1 | wall 50431
KL Stats: Epoch 143 Divergences: Uniform: 2.9670587138393114 Unigram: 4.763425698769235
2022-01-28 21:39:01 | INFO | fairseq.trainer | begin training epoch 144
2022-01-28 21:39:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:43:05 | INFO | train_inner | epoch 144:     48 / 64 loss=5.489, ppl=44.92, wps=6097.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.967, train_wall=507, gb_free=6.1, wall=50676
2022-01-28 21:44:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:44:53 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.39 | ppl 1342.29 | wps 7906.3 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.326
2022-01-28 21:44:53 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-28 21:44:53 | INFO | train | epoch 144 | loss 5.485 | ppl 44.8 | wps 5928 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.965 | train_wall 324 | gb_free 6.1 | wall 50784
KL Stats: Epoch 144 Divergences: Uniform: 2.9577879231609985 Unigram: 4.7651672522015325
2022-01-28 21:44:53 | INFO | fairseq.trainer | begin training epoch 145
2022-01-28 21:44:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:50:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:50:46 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.422 | ppl 1371.71 | wps 7907.7 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.326
2022-01-28 21:50:46 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-28 21:50:46 | INFO | train | epoch 145 | loss 5.476 | ppl 44.51 | wps 5918.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.951 | train_wall 324 | gb_free 6.1 | wall 51137
KL Stats: Epoch 145 Divergences: Uniform: 2.967391096111726 Unigram: 4.781376787889179
2022-01-28 21:50:46 | INFO | fairseq.trainer | begin training epoch 146
2022-01-28 21:50:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:52:28 | INFO | train_inner | epoch 146:     20 / 64 loss=5.473, ppl=44.43, wps=5793.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.961, train_wall=506, gb_free=6.1, wall=51238
2022-01-28 21:56:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:56:39 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.347 | ppl 1302.37 | wps 7881.5 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.326
2022-01-28 21:56:39 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-28 21:56:39 | INFO | train | epoch 146 | loss 5.468 | ppl 44.26 | wps 5919.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.988 | train_wall 324 | gb_free 6.1 | wall 51489
KL Stats: Epoch 146 Divergences: Uniform: 2.963370392600854 Unigram: 4.788961304699745
2022-01-28 21:56:39 | INFO | fairseq.trainer | begin training epoch 147
2022-01-28 21:56:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:01:24 | INFO | train_inner | epoch 147:     56 / 64 loss=5.47, ppl=44.31, wps=6089.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.992, train_wall=508, gb_free=6.1, wall=51775
2022-01-28 22:02:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:02:31 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.319 | ppl 1277.7 | wps 7934.7 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.326
2022-01-28 22:02:31 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-28 22:02:31 | INFO | train | epoch 147 | loss 5.461 | ppl 44.03 | wps 5923.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.998 | train_wall 324 | gb_free 6.1 | wall 51842
KL Stats: Epoch 147 Divergences: Uniform: 2.968024547503252 Unigram: 4.795234353395235
2022-01-28 22:02:31 | INFO | fairseq.trainer | begin training epoch 148
2022-01-28 22:02:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:07:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:08:24 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.344 | ppl 1300.1 | wps 8013.8 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.326
2022-01-28 22:08:24 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-28 22:08:24 | INFO | train | epoch 148 | loss 5.451 | ppl 43.74 | wps 5925.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.981 | train_wall 324 | gb_free 6.1 | wall 52194
KL Stats: Epoch 148 Divergences: Uniform: 2.970875453483355 Unigram: 4.814836934678458
2022-01-28 22:08:24 | INFO | fairseq.trainer | begin training epoch 149
2022-01-28 22:08:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:10:46 | INFO | train_inner | epoch 149:     28 / 64 loss=5.447, ppl=43.62, wps=5801, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.99, train_wall=506, gb_free=6.1, wall=52337
2022-01-28 22:13:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:14:16 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.364 | ppl 1317.92 | wps 7902.7 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.326
2022-01-28 22:14:16 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-28 22:14:16 | INFO | train | epoch 149 | loss 5.447 | ppl 43.63 | wps 5931.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 1.03 | train_wall 324 | gb_free 6.1 | wall 52547
KL Stats: Epoch 149 Divergences: Uniform: 2.9728071771089204 Unigram: 4.820278068674547
2022-01-28 22:14:16 | INFO | fairseq.trainer | begin training epoch 150
2022-01-28 22:14:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:19:39 | INFO | train_inner | epoch 150:     64 / 64 loss=5.449, ppl=43.67, wps=6115.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=1.017, train_wall=504, gb_free=6.1, wall=52870
2022-01-28 22:19:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:20:07 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.406 | ppl 1356.62 | wps 7947.3 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.326
2022-01-28 22:20:07 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-28 22:20:07 | INFO | train | epoch 150 | loss 5.437 | ppl 43.32 | wps 5950.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.999 | train_wall 323 | gb_free 6.1 | wall 52898
KL Stats: Epoch 150 Divergences: Uniform: 2.973089248087477 Unigram: 4.815940756613659
2022-01-28 22:20:07 | INFO | fairseq.trainer | begin training epoch 151
2022-01-28 22:20:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:25:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:25:58 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.395 | ppl 1346.83 | wps 7915.4 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.326
2022-01-28 22:25:58 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-28 22:25:58 | INFO | train | epoch 151 | loss 5.429 | ppl 43.07 | wps 5940.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 1.012 | train_wall 323 | gb_free 6.1 | wall 53249
KL Stats: Epoch 151 Divergences: Uniform: 2.9696210993696095 Unigram: 4.833747653182327
2022-01-28 22:25:58 | INFO | fairseq.trainer | begin training epoch 152
2022-01-28 22:25:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:29:02 | INFO | train_inner | epoch 152:     36 / 64 loss=5.416, ppl=42.7, wps=5805.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=1.018, train_wall=506, gb_free=6.1, wall=53433
2022-01-28 22:31:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:31:51 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.405 | ppl 1355.57 | wps 7906.7 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.326
2022-01-28 22:31:51 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-28 22:31:51 | INFO | train | epoch 152 | loss 5.422 | ppl 42.86 | wps 5918.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.016 | train_wall 324 | gb_free 6.1 | wall 53602
KL Stats: Epoch 152 Divergences: Uniform: 2.9755798518472494 Unigram: 4.846741600138211
2022-01-28 22:31:51 | INFO | fairseq.trainer | begin training epoch 153
2022-01-28 22:31:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:37:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:37:44 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.447 | ppl 1396.14 | wps 7902.4 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.326
2022-01-28 22:37:44 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-01-28 22:37:44 | INFO | train | epoch 153 | loss 5.413 | ppl 42.61 | wps 5920.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.992 | train_wall 324 | gb_free 6.1 | wall 53955
KL Stats: Epoch 153 Divergences: Uniform: 2.976073612597483 Unigram: 4.856112391695784
2022-01-28 22:37:44 | INFO | fairseq.trainer | begin training epoch 154
2022-01-28 22:37:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:38:25 | INFO | train_inner | epoch 154:      8 / 64 loss=5.421, ppl=42.85, wps=5792.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.998, train_wall=506, gb_free=6.1, wall=53996
2022-01-28 22:43:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:43:37 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.436 | ppl 1385.55 | wps 7925.4 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.326
2022-01-28 22:43:37 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-01-28 22:43:37 | INFO | train | epoch 154 | loss 5.408 | ppl 42.46 | wps 5919.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.035 | train_wall 324 | gb_free 6.1 | wall 54308
KL Stats: Epoch 154 Divergences: Uniform: 2.9810862469239283 Unigram: 4.857268663601933
2022-01-28 22:43:37 | INFO | fairseq.trainer | begin training epoch 155
2022-01-28 22:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:47:22 | INFO | train_inner | epoch 155:     44 / 64 loss=5.399, ppl=42.2, wps=6089.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=1.036, train_wall=508, gb_free=6.1, wall=54532
2022-01-28 22:49:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:49:30 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.385 | ppl 1336.99 | wps 7903.9 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.326
2022-01-28 22:49:30 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-01-28 22:49:30 | INFO | train | epoch 155 | loss 5.401 | ppl 42.25 | wps 5914.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.044 | train_wall 325 | gb_free 6.1 | wall 54661
KL Stats: Epoch 155 Divergences: Uniform: 2.9841395142974716 Unigram: 4.877648546174004
2022-01-28 22:49:30 | INFO | fairseq.trainer | begin training epoch 156
2022-01-28 22:49:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:54:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:55:23 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.458 | ppl 1406.57 | wps 7933.4 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.326
2022-01-28 22:55:23 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-01-28 22:55:23 | INFO | train | epoch 156 | loss 5.394 | ppl 42.05 | wps 5916.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.054 | train_wall 325 | gb_free 6.1 | wall 55014
KL Stats: Epoch 156 Divergences: Uniform: 2.9802092739702912 Unigram: 4.878030227757643
2022-01-28 22:55:23 | INFO | fairseq.trainer | begin training epoch 157
2022-01-28 22:55:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:56:45 | INFO | train_inner | epoch 157:     16 / 64 loss=5.399, ppl=42.21, wps=5789.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.046, train_wall=506, gb_free=6.1, wall=55096
2022-01-28 23:00:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:01:16 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.442 | ppl 1391.18 | wps 7891.5 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.326
2022-01-28 23:01:16 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-01-28 23:01:16 | INFO | train | epoch 157 | loss 5.386 | ppl 41.82 | wps 5923.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.024 | train_wall 324 | gb_free 6.1 | wall 55366
KL Stats: Epoch 157 Divergences: Uniform: 2.984939463234879 Unigram: 4.8915829757981655
2022-01-28 23:01:16 | INFO | fairseq.trainer | begin training epoch 158
2022-01-28 23:01:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:05:41 | INFO | train_inner | epoch 158:     52 / 64 loss=5.38, ppl=41.65, wps=6093.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.047, train_wall=507, gb_free=6.1, wall=55632
2022-01-28 23:06:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:07:09 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.44 | ppl 1389.46 | wps 7906 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.326
2022-01-28 23:07:09 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-01-28 23:07:09 | INFO | train | epoch 158 | loss 5.382 | ppl 41.69 | wps 5914 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.068 | train_wall 325 | gb_free 6.1 | wall 55720
KL Stats: Epoch 158 Divergences: Uniform: 2.981100016469909 Unigram: 4.895714819510672
2022-01-28 23:07:09 | INFO | fairseq.trainer | begin training epoch 159
2022-01-28 23:07:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:12:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:13:02 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.457 | ppl 1405.15 | wps 7915.7 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.326
2022-01-28 23:13:02 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-01-28 23:13:02 | INFO | train | epoch 159 | loss 5.373 | ppl 41.44 | wps 5915.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.075 | train_wall 325 | gb_free 6.1 | wall 56073
KL Stats: Epoch 159 Divergences: Uniform: 2.9847001847403876 Unigram: 4.912320133637599
2022-01-28 23:13:02 | INFO | fairseq.trainer | begin training epoch 160
2022-01-28 23:13:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:15:04 | INFO | train_inner | epoch 160:     24 / 64 loss=5.372, ppl=41.43, wps=5787.8, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.076, train_wall=506, gb_free=6.1, wall=56195
2022-01-28 23:18:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:18:55 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.473 | ppl 1421.17 | wps 7884.6 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.326
2022-01-28 23:18:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-01-28 23:18:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint160.pt
2022-01-28 23:18:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint160.pt
2022-01-28 23:18:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.473) (writing took 4.201987158507109 seconds)
2022-01-28 23:18:59 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-01-28 23:18:59 | INFO | train | epoch 160 | loss 5.367 | ppl 41.26 | wps 5852.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.041 | train_wall 324 | gb_free 6.1 | wall 56430
KL Stats: Epoch 160 Divergences: Uniform: 2.9856770664016987 Unigram: 4.922376669516735
2022-01-28 23:18:59 | INFO | fairseq.trainer | begin training epoch 161
2022-01-28 23:18:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:24:04 | INFO | train_inner | epoch 161:     60 / 64 loss=5.368, ppl=41.3, wps=6051.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.051, train_wall=507, gb_free=6.1, wall=56735
2022-01-28 23:24:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:24:51 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.374 | ppl 1327.43 | wps 7916.1 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.326
2022-01-28 23:24:51 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-01-28 23:24:51 | INFO | train | epoch 161 | loss 5.361 | ppl 41.09 | wps 5928.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.066 | train_wall 324 | gb_free 6.1 | wall 56782
KL Stats: Epoch 161 Divergences: Uniform: 2.988834571372759 Unigram: 4.92429793933948
2022-01-28 23:24:51 | INFO | fairseq.trainer | begin training epoch 162
2022-01-28 23:24:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:30:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:30:43 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.457 | ppl 1405.7 | wps 7900.8 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.326
2022-01-28 23:30:43 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-01-28 23:30:43 | INFO | train | epoch 162 | loss 5.352 | ppl 40.86 | wps 5927.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.046 | train_wall 324 | gb_free 6.1 | wall 57134
KL Stats: Epoch 162 Divergences: Uniform: 2.9962826371986604 Unigram: 4.934040904521307
2022-01-28 23:30:44 | INFO | fairseq.trainer | begin training epoch 163
2022-01-28 23:30:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:33:27 | INFO | train_inner | epoch 163:     32 / 64 loss=5.34, ppl=40.5, wps=5798.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.057, train_wall=505, gb_free=6.1, wall=57297
2022-01-28 23:36:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:36:36 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.522 | ppl 1470.1 | wps 7947.6 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.326
2022-01-28 23:36:36 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-01-28 23:36:36 | INFO | train | epoch 163 | loss 5.35 | ppl 40.78 | wps 5930.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.093 | train_wall 324 | gb_free 6.1 | wall 57486
KL Stats: Epoch 163 Divergences: Uniform: 2.9887244471750205 Unigram: 4.947805474506079
2022-01-28 23:36:36 | INFO | fairseq.trainer | begin training epoch 164
2022-01-28 23:36:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:42:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:42:28 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.417 | ppl 1367.5 | wps 7930.3 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.326
2022-01-28 23:42:28 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-01-28 23:42:28 | INFO | train | epoch 164 | loss 5.341 | ppl 40.54 | wps 5933.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.1 | train_wall 324 | gb_free 6.1 | wall 57838
KL Stats: Epoch 164 Divergences: Uniform: 2.9881662757355425 Unigram: 4.949558263771067
2022-01-28 23:42:28 | INFO | fairseq.trainer | begin training epoch 165
2022-01-28 23:42:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:42:48 | INFO | train_inner | epoch 165:      4 / 64 loss=5.356, ppl=40.97, wps=5805.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.1, train_wall=505, gb_free=6.1, wall=57859
2022-01-28 23:47:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:48:20 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.468 | ppl 1416.63 | wps 7905.5 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.326
2022-01-28 23:48:20 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-01-28 23:48:20 | INFO | train | epoch 165 | loss 5.333 | ppl 40.31 | wps 5927.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.079 | train_wall 324 | gb_free 6.1 | wall 58191
KL Stats: Epoch 165 Divergences: Uniform: 2.994881500628489 Unigram: 4.9666141733507345
2022-01-28 23:48:20 | INFO | fairseq.trainer | begin training epoch 166
2022-01-28 23:48:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:51:44 | INFO | train_inner | epoch 166:     40 / 64 loss=5.327, ppl=40.14, wps=6099.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.102, train_wall=507, gb_free=6.1, wall=58395
2022-01-28 23:53:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:54:12 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.363 | ppl 1317.33 | wps 7910 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.326
2022-01-28 23:54:12 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-01-28 23:54:12 | INFO | train | epoch 166 | loss 5.33 | ppl 40.23 | wps 5929.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.122 | train_wall 324 | gb_free 6.1 | wall 58543
KL Stats: Epoch 166 Divergences: Uniform: 2.9992728981504 Unigram: 4.971394016326823
2022-01-28 23:54:12 | INFO | fairseq.trainer | begin training epoch 167
2022-01-28 23:54:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:59:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:00:05 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.359 | ppl 1313.38 | wps 7900.7 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.326
2022-01-29 00:00:05 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-01-29 00:00:05 | INFO | train | epoch 167 | loss 5.323 | ppl 40.03 | wps 5926.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.121 | train_wall 324 | gb_free 6.1 | wall 58895
KL Stats: Epoch 167 Divergences: Uniform: 2.9950113051000087 Unigram: 4.9742442550947015
2022-01-29 00:00:05 | INFO | fairseq.trainer | begin training epoch 168
2022-01-29 00:00:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:01:06 | INFO | train_inner | epoch 168:     12 / 64 loss=5.325, ppl=40.09, wps=5802, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.117, train_wall=505, gb_free=6.1, wall=58956
2022-01-29 00:05:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:05:56 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.485 | ppl 1432.75 | wps 7984.5 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.326
2022-01-29 00:05:56 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-01-29 00:05:56 | INFO | train | epoch 168 | loss 5.318 | ppl 39.89 | wps 5940.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.128 | train_wall 323 | gb_free 6.1 | wall 59247
KL Stats: Epoch 168 Divergences: Uniform: 3.000312554799235 Unigram: 4.978208199639454
2022-01-29 00:05:56 | INFO | fairseq.trainer | begin training epoch 169
2022-01-29 00:05:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:10:01 | INFO | train_inner | epoch 169:     48 / 64 loss=5.317, ppl=39.86, wps=6107.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.124, train_wall=506, gb_free=6.1, wall=59492
2022-01-29 00:11:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:11:49 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.442 | ppl 1390.67 | wps 7929.3 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.326
2022-01-29 00:11:49 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-01-29 00:11:49 | INFO | train | epoch 169 | loss 5.312 | ppl 39.71 | wps 5927.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.118 | train_wall 324 | gb_free 6.1 | wall 59599
KL Stats: Epoch 169 Divergences: Uniform: 2.9983674913737386 Unigram: 4.990433999394714
2022-01-29 00:11:49 | INFO | fairseq.trainer | begin training epoch 170
2022-01-29 00:11:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:17:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:17:41 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.483 | ppl 1431.53 | wps 7999 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.326
2022-01-29 00:17:41 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-01-29 00:17:41 | INFO | train | epoch 170 | loss 5.306 | ppl 39.55 | wps 5924.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.128 | train_wall 324 | gb_free 6.1 | wall 59952
KL Stats: Epoch 170 Divergences: Uniform: 3.0005937742223963 Unigram: 4.998865152537638
2022-01-29 00:17:41 | INFO | fairseq.trainer | begin training epoch 171
2022-01-29 00:17:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:19:24 | INFO | train_inner | epoch 171:     20 / 64 loss=5.3, ppl=39.4, wps=5792.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.137, train_wall=506, gb_free=6.1, wall=60054
2022-01-29 00:23:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:23:34 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.471 | ppl 1419.8 | wps 7909.7 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.326
2022-01-29 00:23:34 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-01-29 00:23:34 | INFO | train | epoch 171 | loss 5.3 | ppl 39.4 | wps 5913.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.181 | train_wall 325 | gb_free 6.1 | wall 60305
KL Stats: Epoch 171 Divergences: Uniform: 3.000937250419241 Unigram: 5.008228403168469
2022-01-29 00:23:34 | INFO | fairseq.trainer | begin training epoch 172
2022-01-29 00:23:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:28:20 | INFO | train_inner | epoch 172:     56 / 64 loss=5.303, ppl=39.48, wps=6088.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.167, train_wall=508, gb_free=6.1, wall=60591
2022-01-29 00:29:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:29:27 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.458 | ppl 1406.26 | wps 7922.8 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.326
2022-01-29 00:29:27 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-01-29 00:29:27 | INFO | train | epoch 172 | loss 5.294 | ppl 39.23 | wps 5917.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.164 | train_wall 324 | gb_free 6.1 | wall 60658
KL Stats: Epoch 172 Divergences: Uniform: 3.0039760474887784 Unigram: 5.011681364315963
2022-01-29 00:29:27 | INFO | fairseq.trainer | begin training epoch 173
2022-01-29 00:29:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:34:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:35:20 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.395 | ppl 1346.09 | wps 7904 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.326
2022-01-29 00:35:20 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-01-29 00:35:20 | INFO | train | epoch 173 | loss 5.287 | ppl 39.05 | wps 5926.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.175 | train_wall 324 | gb_free 6.1 | wall 61011
KL Stats: Epoch 173 Divergences: Uniform: 3.00334954737982 Unigram: 5.0166818895606635
2022-01-29 00:35:20 | INFO | fairseq.trainer | begin training epoch 174
2022-01-29 00:35:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:37:42 | INFO | train_inner | epoch 174:     28 / 64 loss=5.281, ppl=38.88, wps=5798.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.163, train_wall=505, gb_free=6.1, wall=61153
2022-01-29 00:40:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:41:11 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.473 | ppl 1421.64 | wps 7952.2 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.326
2022-01-29 00:41:11 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-01-29 00:41:11 | INFO | train | epoch 174 | loss 5.283 | ppl 38.93 | wps 5938.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.165 | train_wall 323 | gb_free 6.1 | wall 61362
KL Stats: Epoch 174 Divergences: Uniform: 3.0051567015836254 Unigram: 5.029634433378922
2022-01-29 00:41:12 | INFO | fairseq.trainer | begin training epoch 175
2022-01-29 00:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:46:36 | INFO | train_inner | epoch 175:     64 / 64 loss=5.287, ppl=39.03, wps=6107.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.177, train_wall=505, gb_free=6.1, wall=61687
2022-01-29 00:46:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:47:04 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.534 | ppl 1482.38 | wps 7884.4 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.326
2022-01-29 00:47:04 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-01-29 00:47:04 | INFO | train | epoch 175 | loss 5.275 | ppl 38.73 | wps 5924.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.165 | train_wall 324 | gb_free 6.1 | wall 61715
KL Stats: Epoch 175 Divergences: Uniform: 3.015325232606118 Unigram: 5.039678662076189
2022-01-29 00:47:04 | INFO | fairseq.trainer | begin training epoch 176
2022-01-29 00:47:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:52:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:52:57 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.52 | ppl 1468.83 | wps 7903.7 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.326
2022-01-29 00:52:57 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-01-29 00:52:57 | INFO | train | epoch 176 | loss 5.271 | ppl 38.62 | wps 5922.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.18 | train_wall 324 | gb_free 6.1 | wall 62067
KL Stats: Epoch 176 Divergences: Uniform: 3.0099425586763084 Unigram: 5.046631055147024
2022-01-29 00:52:57 | INFO | fairseq.trainer | begin training epoch 177
2022-01-29 00:52:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:56:00 | INFO | train_inner | epoch 177:     36 / 64 loss=5.258, ppl=38.27, wps=5794.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.187, train_wall=507, gb_free=6.1, wall=62251
2022-01-29 00:58:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:58:49 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.424 | ppl 1373.76 | wps 7927.6 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.326
2022-01-29 00:58:49 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-01-29 00:58:49 | INFO | train | epoch 177 | loss 5.265 | ppl 38.45 | wps 5930.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.217 | train_wall 324 | gb_free 6.1 | wall 62420
KL Stats: Epoch 177 Divergences: Uniform: 3.0112642756156056 Unigram: 5.050980110777996
2022-01-29 00:58:49 | INFO | fairseq.trainer | begin training epoch 178
2022-01-29 00:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:04:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:04:41 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.498 | ppl 1446.53 | wps 7883.7 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.326
2022-01-29 01:04:41 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-01-29 01:04:41 | INFO | train | epoch 178 | loss 5.262 | ppl 38.38 | wps 5931 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.203 | train_wall 324 | gb_free 6.1 | wall 62772
KL Stats: Epoch 178 Divergences: Uniform: 3.0118346679914385 Unigram: 5.055410763553868
2022-01-29 01:04:41 | INFO | fairseq.trainer | begin training epoch 179
2022-01-29 01:04:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:05:22 | INFO | train_inner | epoch 179:      8 / 64 loss=5.269, ppl=38.57, wps=5804.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.21, train_wall=505, gb_free=6.1, wall=62813
2022-01-29 01:10:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:10:33 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.44 | ppl 1388.73 | wps 7931.5 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.326
2022-01-29 01:10:33 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-01-29 01:10:33 | INFO | train | epoch 179 | loss 5.255 | ppl 38.19 | wps 5943 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.198 | train_wall 323 | gb_free 6.1 | wall 63123
KL Stats: Epoch 179 Divergences: Uniform: 3.0139144278609695 Unigram: 5.063057981593525
2022-01-29 01:10:33 | INFO | fairseq.trainer | begin training epoch 180
2022-01-29 01:10:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:14:16 | INFO | train_inner | epoch 180:     44 / 64 loss=5.25, ppl=38.06, wps=6117.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.203, train_wall=505, gb_free=6.1, wall=63347
2022-01-29 01:15:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:16:24 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.422 | ppl 1372.27 | wps 7919.3 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.326
2022-01-29 01:16:24 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-01-29 01:16:24 | INFO | train | epoch 180 | loss 5.251 | ppl 38.09 | wps 5949.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.222 | train_wall 323 | gb_free 6.1 | wall 63474
KL Stats: Epoch 180 Divergences: Uniform: 3.015776991050507 Unigram: 5.070970856979377
2022-01-29 01:16:24 | INFO | fairseq.trainer | begin training epoch 181
2022-01-29 01:16:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:21:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:22:15 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.488 | ppl 1436.01 | wps 7880.1 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.326
2022-01-29 01:22:15 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-01-29 01:22:15 | INFO | train | epoch 181 | loss 5.243 | ppl 37.87 | wps 5937.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.216 | train_wall 323 | gb_free 6.1 | wall 63826
KL Stats: Epoch 181 Divergences: Uniform: 3.0187921644685747 Unigram: 5.081654839657489
2022-01-29 01:22:15 | INFO | fairseq.trainer | begin training epoch 182
2022-01-29 01:22:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:23:37 | INFO | train_inner | epoch 182:     16 / 64 loss=5.244, ppl=37.91, wps=5811.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.23, train_wall=504, gb_free=6.1, wall=63908
2022-01-29 01:27:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:28:08 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.41 | ppl 1360.67 | wps 7871.1 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.326
2022-01-29 01:28:08 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-01-29 01:28:08 | INFO | train | epoch 182 | loss 5.241 | ppl 37.82 | wps 5921.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.241 | train_wall 324 | gb_free 6.1 | wall 64179
KL Stats: Epoch 182 Divergences: Uniform: 3.019154154032112 Unigram: 5.0797379849701
2022-01-29 01:28:08 | INFO | fairseq.trainer | begin training epoch 183
2022-01-29 01:28:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:32:33 | INFO | train_inner | epoch 183:     52 / 64 loss=5.239, ppl=37.77, wps=6100.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.262, train_wall=507, gb_free=6.1, wall=64444
2022-01-29 01:33:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:34:00 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.437 | ppl 1386.39 | wps 7953.1 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.326
2022-01-29 01:34:00 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-01-29 01:34:00 | INFO | train | epoch 183 | loss 5.236 | ppl 37.68 | wps 5935 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.274 | train_wall 324 | gb_free 6.1 | wall 64531
KL Stats: Epoch 183 Divergences: Uniform: 3.019949897151495 Unigram: 5.095525725492096
2022-01-29 01:34:00 | INFO | fairseq.trainer | begin training epoch 184
2022-01-29 01:34:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:39:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:39:53 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.43 | ppl 1379.62 | wps 7913.8 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.326
2022-01-29 01:39:53 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-01-29 01:39:53 | INFO | train | epoch 184 | loss 5.231 | ppl 37.55 | wps 5918.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.235 | train_wall 324 | gb_free 6.1 | wall 64884
KL Stats: Epoch 184 Divergences: Uniform: 3.0190379417477002 Unigram: 5.096809579381083
2022-01-29 01:39:53 | INFO | fairseq.trainer | begin training epoch 185
2022-01-29 01:39:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:41:55 | INFO | train_inner | epoch 185:     24 / 64 loss=5.231, ppl=37.54, wps=5794.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.241, train_wall=506, gb_free=6.1, wall=65006
2022-01-29 01:45:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:45:45 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.48 | ppl 1427.78 | wps 7932.8 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.326
2022-01-29 01:45:45 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-01-29 01:45:45 | INFO | train | epoch 185 | loss 5.226 | ppl 37.44 | wps 5924.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.283 | train_wall 324 | gb_free 6.1 | wall 65236
KL Stats: Epoch 185 Divergences: Uniform: 3.016914206825253 Unigram: 5.106786464195065
2022-01-29 01:45:45 | INFO | fairseq.trainer | begin training epoch 186
2022-01-29 01:45:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:50:51 | INFO | train_inner | epoch 186:     60 / 64 loss=5.227, ppl=37.46, wps=6104.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.292, train_wall=506, gb_free=6.1, wall=65542
2022-01-29 01:51:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:51:38 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.411 | ppl 1361.39 | wps 7888.6 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.326
2022-01-29 01:51:38 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-01-29 01:51:38 | INFO | train | epoch 186 | loss 5.223 | ppl 37.34 | wps 5930.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.29 | train_wall 324 | gb_free 6.1 | wall 65588
KL Stats: Epoch 186 Divergences: Uniform: 3.017672078005219 Unigram: 5.110796530723995
2022-01-29 01:51:38 | INFO | fairseq.trainer | begin training epoch 187
2022-01-29 01:51:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:57:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:57:30 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.482 | ppl 1430.5 | wps 7957.3 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.326
2022-01-29 01:57:30 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-01-29 01:57:30 | INFO | train | epoch 187 | loss 5.217 | ppl 37.2 | wps 5931.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.263 | train_wall 324 | gb_free 6.1 | wall 65940
KL Stats: Epoch 187 Divergences: Uniform: 3.020967771358295 Unigram: 5.118241081542562
2022-01-29 01:57:30 | INFO | fairseq.trainer | begin training epoch 188
2022-01-29 01:57:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:00:13 | INFO | train_inner | epoch 188:     32 / 64 loss=5.21, ppl=37.01, wps=5802.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.272, train_wall=505, gb_free=6.1, wall=66103
2022-01-29 02:02:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:03:22 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.476 | ppl 1424.66 | wps 7917 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.326
2022-01-29 02:03:22 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-01-29 02:03:22 | INFO | train | epoch 188 | loss 5.209 | ppl 37 | wps 5934.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.279 | train_wall 323 | gb_free 6.1 | wall 66292
KL Stats: Epoch 188 Divergences: Uniform: 3.019819845583933 Unigram: 5.126205599260394
2022-01-29 02:03:22 | INFO | fairseq.trainer | begin training epoch 189
2022-01-29 02:03:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:08:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:09:15 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.441 | ppl 1390.09 | wps 7921.4 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.326
2022-01-29 02:09:15 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-01-29 02:09:15 | INFO | train | epoch 189 | loss 5.207 | ppl 36.95 | wps 5919 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.335 | train_wall 324 | gb_free 6.1 | wall 66645
KL Stats: Epoch 189 Divergences: Uniform: 3.0199039292451917 Unigram: 5.1277280512038095
2022-01-29 02:09:15 | INFO | fairseq.trainer | begin training epoch 190
2022-01-29 02:09:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:09:35 | INFO | train_inner | epoch 190:      4 / 64 loss=5.213, ppl=37.08, wps=5795.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.313, train_wall=506, gb_free=6.1, wall=66666
2022-01-29 02:14:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:15:08 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.454 | ppl 1403.15 | wps 7928.1 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.326
2022-01-29 02:15:08 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-01-29 02:15:08 | INFO | train | epoch 190 | loss 5.201 | ppl 36.78 | wps 5917.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.3 | train_wall 324 | gb_free 6.1 | wall 66998
KL Stats: Epoch 190 Divergences: Uniform: 3.0226450112466012 Unigram: 5.1327704773761935
2022-01-29 02:15:08 | INFO | fairseq.trainer | begin training epoch 191
2022-01-29 02:15:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:18:32 | INFO | train_inner | epoch 191:     40 / 64 loss=5.19, ppl=36.5, wps=6089.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.293, train_wall=508, gb_free=6.1, wall=67202
2022-01-29 02:20:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:21:01 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.454 | ppl 1402.27 | wps 7929.1 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.326
2022-01-29 02:21:01 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-01-29 02:21:01 | INFO | train | epoch 191 | loss 5.196 | ppl 36.66 | wps 5913.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.277 | train_wall 325 | gb_free 6.1 | wall 67351
KL Stats: Epoch 191 Divergences: Uniform: 3.023339571446987 Unigram: 5.142581513866657
2022-01-29 02:21:01 | INFO | fairseq.trainer | begin training epoch 192
2022-01-29 02:21:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:26:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:26:53 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.476 | ppl 1424.34 | wps 7952.5 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.326
2022-01-29 02:26:53 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-01-29 02:26:53 | INFO | train | epoch 192 | loss 5.193 | ppl 36.58 | wps 5931.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.338 | train_wall 324 | gb_free 6.1 | wall 67704
KL Stats: Epoch 192 Divergences: Uniform: 3.0228202068906227 Unigram: 5.143725730237356
2022-01-29 02:26:53 | INFO | fairseq.trainer | begin training epoch 193
2022-01-29 02:26:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:27:54 | INFO | train_inner | epoch 193:     12 / 64 loss=5.199, ppl=36.74, wps=5793.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.328, train_wall=506, gb_free=6.1, wall=67765
2022-01-29 02:32:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:32:46 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.466 | ppl 1414.78 | wps 7898.1 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.326
2022-01-29 02:32:46 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-01-29 02:32:46 | INFO | train | epoch 193 | loss 5.19 | ppl 36.5 | wps 5911 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.343 | train_wall 325 | gb_free 6.1 | wall 68057
KL Stats: Epoch 193 Divergences: Uniform: 3.026802161403407 Unigram: 5.153601186729461
2022-01-29 02:32:46 | INFO | fairseq.trainer | begin training epoch 194
2022-01-29 02:32:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:36:51 | INFO | train_inner | epoch 194:     48 / 64 loss=5.186, ppl=36.39, wps=6090.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.348, train_wall=508, gb_free=6.1, wall=68302
2022-01-29 02:38:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:38:39 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.435 | ppl 1384.71 | wps 7903.3 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.326
2022-01-29 02:38:39 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-01-29 02:38:39 | INFO | train | epoch 194 | loss 5.184 | ppl 36.36 | wps 5919 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.369 | train_wall 324 | gb_free 6.1 | wall 68410
KL Stats: Epoch 194 Divergences: Uniform: 3.0267364787251165 Unigram: 5.155686279005651
2022-01-29 02:38:39 | INFO | fairseq.trainer | begin training epoch 195
2022-01-29 02:38:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:44:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:44:33 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.464 | ppl 1412.64 | wps 7902.9 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.326
2022-01-29 02:44:33 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-01-29 02:44:33 | INFO | train | epoch 195 | loss 5.18 | ppl 36.25 | wps 5907.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.361 | train_wall 325 | gb_free 6.1 | wall 68763
KL Stats: Epoch 195 Divergences: Uniform: 3.0246999717742877 Unigram: 5.161739679955399
2022-01-29 02:44:33 | INFO | fairseq.trainer | begin training epoch 196
2022-01-29 02:44:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:46:15 | INFO | train_inner | epoch 196:     20 / 64 loss=5.178, ppl=36.2, wps=5782.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.356, train_wall=507, gb_free=6.1, wall=68865
2022-01-29 02:49:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:50:26 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.431 | ppl 1380.96 | wps 7890.7 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.326
2022-01-29 02:50:26 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-01-29 02:50:26 | INFO | train | epoch 196 | loss 5.176 | ppl 36.15 | wps 5915.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.352 | train_wall 324 | gb_free 6.1 | wall 69116
KL Stats: Epoch 196 Divergences: Uniform: 3.0263476945324257 Unigram: 5.169377428131848
2022-01-29 02:50:26 | INFO | fairseq.trainer | begin training epoch 197
2022-01-29 02:50:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:55:10 | INFO | train_inner | epoch 197:     56 / 64 loss=5.176, ppl=36.16, wps=6100.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.379, train_wall=507, gb_free=6.1, wall=69401
2022-01-29 02:55:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:56:18 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.515 | ppl 1462.97 | wps 7924.1 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.326
2022-01-29 02:56:18 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-01-29 02:56:18 | INFO | train | epoch 197 | loss 5.171 | ppl 36.04 | wps 5937.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.395 | train_wall 323 | gb_free 6.1 | wall 69468
KL Stats: Epoch 197 Divergences: Uniform: 3.0288804799675466 Unigram: 5.171969335448514
2022-01-29 02:56:18 | INFO | fairseq.trainer | begin training epoch 198
2022-01-29 02:56:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:01:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:02:11 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.461 | ppl 1409.24 | wps 7919.6 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.326
2022-01-29 03:02:11 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-01-29 03:02:11 | INFO | train | epoch 198 | loss 5.167 | ppl 35.94 | wps 5907.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.414 | train_wall 325 | gb_free 6.1 | wall 69822
KL Stats: Epoch 198 Divergences: Uniform: 3.030845318695624 Unigram: 5.185619835106468
2022-01-29 03:02:11 | INFO | fairseq.trainer | begin training epoch 199
2022-01-29 03:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:04:34 | INFO | train_inner | epoch 199:     28 / 64 loss=5.162, ppl=35.79, wps=5781.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.397, train_wall=507, gb_free=6.1, wall=69965
2022-01-29 03:07:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:08:05 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.437 | ppl 1386.43 | wps 7862.1 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.326
2022-01-29 03:08:05 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-01-29 03:08:05 | INFO | train | epoch 199 | loss 5.16 | ppl 35.76 | wps 5908.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.355 | train_wall 325 | gb_free 6.1 | wall 70175
KL Stats: Epoch 199 Divergences: Uniform: 3.0302740565628885 Unigram: 5.193646351813847
2022-01-29 03:08:05 | INFO | fairseq.trainer | begin training epoch 200
2022-01-29 03:08:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:13:30 | INFO | train_inner | epoch 200:     64 / 64 loss=5.17, ppl=35.99, wps=6091.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.39, train_wall=506, gb_free=6.1, wall=70500
2022-01-29 03:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:13:57 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.491 | ppl 1438.71 | wps 7882.8 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.326
2022-01-29 03:13:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-01-29 03:13:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint200.pt
2022-01-29 03:13:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint200.pt
2022-01-29 03:14:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.491) (writing took 3.7321818936616182 seconds)
2022-01-29 03:14:01 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-01-29 03:14:01 | INFO | train | epoch 200 | loss 5.158 | ppl 35.7 | wps 5859.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.404 | train_wall 324 | gb_free 6.1 | wall 70532
KL Stats: Epoch 200 Divergences: Uniform: 3.0285782648942443 Unigram: 5.1993120202370555
2022-01-29 03:14:01 | INFO | fairseq.trainer | begin training epoch 201
2022-01-29 03:14:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:19:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:19:53 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.494 | ppl 1441.79 | wps 7957.6 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.326
2022-01-29 03:19:53 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-01-29 03:19:53 | INFO | train | epoch 201 | loss 5.155 | ppl 35.63 | wps 5936 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.418 | train_wall 323 | gb_free 6.1 | wall 70884
KL Stats: Epoch 201 Divergences: Uniform: 3.027663156396804 Unigram: 5.1950693989773615
2022-01-29 03:19:53 | INFO | fairseq.trainer | begin training epoch 202
2022-01-29 03:19:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:22:56 | INFO | train_inner | epoch 202:     36 / 64 loss=5.14, ppl=35.27, wps=5767.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.419, train_wall=506, gb_free=6.1, wall=71067
2022-01-29 03:25:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:25:45 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.484 | ppl 1432.59 | wps 7922.5 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.326
2022-01-29 03:25:45 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-01-29 03:25:45 | INFO | train | epoch 202 | loss 5.148 | ppl 35.46 | wps 5929.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.405 | train_wall 324 | gb_free 6.1 | wall 71236
KL Stats: Epoch 202 Divergences: Uniform: 3.028541582190509 Unigram: 5.210616738014204
2022-01-29 03:25:45 | INFO | fairseq.trainer | begin training epoch 203
2022-01-29 03:25:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:31:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:31:38 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.443 | ppl 1391.83 | wps 7886 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.326
2022-01-29 03:31:38 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-01-29 03:31:38 | INFO | train | epoch 203 | loss 5.145 | ppl 35.37 | wps 5920.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.455 | train_wall 324 | gb_free 6.1 | wall 71589
KL Stats: Epoch 203 Divergences: Uniform: 3.0285699207730894 Unigram: 5.2168153046609245
2022-01-29 03:31:38 | INFO | fairseq.trainer | begin training epoch 204
2022-01-29 03:31:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:32:19 | INFO | train_inner | epoch 204:      8 / 64 loss=5.153, ppl=35.58, wps=5794.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.431, train_wall=506, gb_free=6.1, wall=71629
2022-01-29 03:37:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:37:30 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.483 | ppl 1431.1 | wps 7932 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.326
2022-01-29 03:37:30 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-01-29 03:37:30 | INFO | train | epoch 204 | loss 5.139 | ppl 35.25 | wps 5928 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.438 | train_wall 324 | gb_free 6.1 | wall 71941
KL Stats: Epoch 204 Divergences: Uniform: 3.035448135083059 Unigram: 5.221081664283911
2022-01-29 03:37:30 | INFO | fairseq.trainer | begin training epoch 205
2022-01-29 03:37:30 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
