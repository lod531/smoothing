Sender: LSF System <lsfadmin@eu-g3-031>
Subject: Job 202287102: <w2_jelinek_0.16_-0.06_0.9> in cluster <euler> Exited

Job <w2_jelinek_0.16_-0.06_0.9> was submitted from host <eu-login-22> by user <andriusb> in cluster <euler> at Fri Jan 28 07:41:33 2022
Job was executed on host(s) <eu-g3-031>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Fri Jan 28 07:47:20 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Fri Jan 28 07:47:20 2022
Terminated at Sat Jan 29 03:47:38 2022
Results reported at Sat Jan 29 03:47:38 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.16, -0.06, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   71960.00 sec.
    Max Memory :                                 6041 MB
    Average Memory :                             3625.97 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13959.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                16
    Run time :                                   72018 sec.
    Turnaround time :                            72365 sec.

The output (if any) follows:

2022-01-28 07:47:29 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.16, -0.06, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-28 07:47:30 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-28 07:47:30 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  3%|▎         | 1118/36718 [00:00<00:03, 11177.45it/s]  6%|▌         | 2236/36718 [00:00<00:03, 10140.76it/s]  9%|▉         | 3451/36718 [00:00<00:03, 11000.70it/s] 13%|█▎        | 4660/36718 [00:00<00:02, 11412.85it/s] 16%|█▌        | 5960/36718 [00:00<00:02, 11957.77it/s] 20%|█▉        | 7161/36718 [00:00<00:02, 11173.69it/s] 23%|██▎       | 8290/36718 [00:00<00:02, 11139.67it/s] 26%|██▌       | 9415/36718 [00:00<00:02, 11173.04it/s] 29%|██▊       | 10538/36718 [00:00<00:02, 11026.33it/s] 32%|███▏      | 11645/36718 [00:01<00:02, 10914.72it/s] 35%|███▍      | 12773/36718 [00:01<00:02, 11018.28it/s] 38%|███▊      | 13969/36718 [00:01<00:02, 11298.29it/s] 41%|████▏     | 15156/36718 [00:01<00:01, 11468.56it/s] 44%|████▍     | 16305/36718 [00:01<00:01, 11016.32it/s] 47%|████▋     | 17436/36718 [00:01<00:01, 11095.06it/s] 51%|█████     | 18549/36718 [00:01<00:01, 10891.63it/s] 54%|█████▍    | 19838/36718 [00:01<00:01, 11462.68it/s] 57%|█████▋    | 20988/36718 [00:01<00:01, 11220.00it/s] 60%|██████    | 22114/36718 [00:01<00:01, 11003.02it/s] 63%|██████▎   | 23294/36718 [00:02<00:01, 11226.47it/s] 67%|██████▋   | 24710/36718 [00:02<00:00, 12083.46it/s] 71%|███████   | 25923/36718 [00:02<00:00, 11770.47it/s] 74%|███████▍  | 27105/36718 [00:02<00:00, 11238.19it/s] 77%|███████▋  | 28236/36718 [00:02<00:00, 11128.46it/s] 80%|███████▉  | 29359/36718 [00:02<00:00, 11154.39it/s] 83%|████████▎ | 30494/36718 [00:02<00:00, 11207.84it/s] 86%|████████▌ | 31618/36718 [00:02<00:00, 10904.01it/s] 89%|████████▉ | 32712/36718 [00:02<00:00, 10704.30it/s] 92%|█████████▏| 33785/36718 [00:03<00:00, 10589.79it/s] 95%|█████████▌| 34969/36718 [00:03<00:00, 10947.77it/s] 98%|█████████▊| 36067/36718 [00:03<00:00, 10852.40it/s]100%|██████████| 36718/36718 [00:03<00:00, 11126.11it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  6%|▌         | 2023/36718 [00:00<00:01, 20227.75it/s] 12%|█▏        | 4263/36718 [00:00<00:01, 21500.25it/s] 18%|█▊        | 6460/36718 [00:00<00:01, 21709.12it/s] 24%|██▎       | 8631/36718 [00:00<00:01, 20908.37it/s] 29%|██▉       | 10760/36718 [00:00<00:01, 21035.89it/s] 35%|███▌      | 12867/36718 [00:00<00:01, 20947.16it/s] 41%|████      | 15075/36718 [00:00<00:01, 21309.85it/s] 47%|████▋     | 17208/36718 [00:00<00:00, 20943.34it/s] 53%|█████▎    | 19480/36718 [00:00<00:00, 21486.48it/s] 59%|█████▉    | 21632/36718 [00:01<00:00, 20841.10it/s] 65%|██████▌   | 23948/36718 [00:01<00:00, 21526.97it/s] 71%|███████▏  | 26183/36718 [00:01<00:00, 21765.59it/s] 77%|███████▋  | 28365/36718 [00:01<00:00, 21196.18it/s] 83%|████████▎ | 30491/36718 [00:01<00:00, 21155.31it/s] 89%|████████▉ | 32611/36718 [00:01<00:00, 20642.28it/s] 95%|█████████▍| 34769/36718 [00:01<00:00, 20914.74it/s]100%|██████████| 36718/36718 [00:01<00:00, 21049.20it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 71.54it/s]2022-01-28 07:47:44 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-28 07:47:44 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-28 07:47:44 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-28 07:47:44 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-28 07:47:44 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-28 07:47:44 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-28 07:47:44 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-28 07:47:44 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-28 07:47:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-28 07:47:44 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-01-28 07:47:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-28 07:47:44 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-28 07:47:44 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-28 07:47:44 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint_last.pt
2022-01-28 07:47:44 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint_last.pt
2022-01-28 07:47:44 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-28 07:47:44 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-28 07:47:44 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-28 07:47:45 | INFO | fairseq.trainer | begin training epoch 1
2022-01-28 07:47:45 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-28 07:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-28 07:53:43 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.87 | ppl 29935.6 | wps 7824.6 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-28 07:53:43 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-28 07:53:43 | INFO | train | epoch 001 | loss 16.197 | ppl 75138.8 | wps 5877.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.025 | train_wall 326 | gb_free 6.1 | wall 358
KL Stats: Epoch 1 Divergences: Uniform: 0.5165855417344711 Unigram: 3.687409058709278
2022-01-28 07:53:43 | INFO | fairseq.trainer | begin training epoch 2
2022-01-28 07:53:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:56:47 | INFO | train_inner | epoch 002:     36 / 64 loss=15.695, ppl=53042.1, wps=6054.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.477, train_wall=510, gb_free=6.1, wall=543
2022-01-28 07:59:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:59:37 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.934 | ppl 15649.6 | wps 7859.5 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-28 07:59:37 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-28 07:59:37 | INFO | train | epoch 002 | loss 14.608 | ppl 24978.5 | wps 5888.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.39 | train_wall 325 | gb_free 6.1 | wall 713
KL Stats: Epoch 2 Divergences: Uniform: 0.5281562582418964 Unigram: 2.422049620920851
2022-01-28 07:59:37 | INFO | fairseq.trainer | begin training epoch 3
2022-01-28 07:59:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:05:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:05:33 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.165 | ppl 9184.77 | wps 7855.6 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-28 08:05:33 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-28 08:05:33 | INFO | train | epoch 003 | loss 13.769 | ppl 13959.6 | wps 5875.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.117 | train_wall 326 | gb_free 6.1 | wall 1068
KL Stats: Epoch 3 Divergences: Uniform: 0.5011668501564835 Unigram: 1.7479525896056303
2022-01-28 08:05:33 | INFO | fairseq.trainer | begin training epoch 4
2022-01-28 08:05:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:06:14 | INFO | train_inner | epoch 004:      8 / 64 loss=13.893, ppl=15210.5, wps=5752.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.144, train_wall=508, gb_free=6.1, wall=1110
2022-01-28 08:11:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 08:11:29 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.387 | ppl 5355.92 | wps 7831.9 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-28 08:11:29 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-28 08:11:29 | INFO | train | epoch 004 | loss 12.878 | ppl 7529.28 | wps 5873.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.885 | train_wall 326 | gb_free 6.1 | wall 1424
KL Stats: Epoch 4 Divergences: Uniform: 0.5706734015737382 Unigram: 1.1598652379543475
2022-01-28 08:11:29 | INFO | fairseq.trainer | begin training epoch 5
2022-01-28 08:11:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:15:15 | INFO | train_inner | epoch 005:     44 / 64 loss=12.558, ppl=6029.29, wps=6044.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.785, train_wall=510, gb_free=6.1, wall=1650
2022-01-28 08:16:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:17:24 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.902 | ppl 3828.18 | wps 7847.6 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-28 08:17:24 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-28 08:17:24 | INFO | train | epoch 005 | loss 12.15 | ppl 4545.22 | wps 5876.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.651 | train_wall 326 | gb_free 6.1 | wall 1780
KL Stats: Epoch 5 Divergences: Uniform: 0.7727088982192242 Unigram: 0.7346960368338448
2022-01-28 08:17:24 | INFO | fairseq.trainer | begin training epoch 6
2022-01-28 08:17:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:22:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:23:19 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.652 | ppl 3219.18 | wps 7846.5 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-28 08:23:19 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-28 08:23:19 | INFO | train | epoch 006 | loss 11.75 | ppl 3444.72 | wps 5884.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.571 | train_wall 325 | gb_free 6.1 | wall 2134
KL Stats: Epoch 6 Divergences: Uniform: 1.017113371049887 Unigram: 0.574486156992525
2022-01-28 08:23:19 | INFO | fairseq.trainer | begin training epoch 7
2022-01-28 08:23:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:24:41 | INFO | train_inner | epoch 007:     16 / 64 loss=11.771, ppl=3493.62, wps=5758.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.567, train_wall=508, gb_free=6.1, wall=2216
2022-01-28 08:28:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:29:14 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.499 | ppl 2894.73 | wps 7852.4 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-28 08:29:14 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-28 08:29:14 | INFO | train | epoch 007 | loss 11.554 | ppl 3006.76 | wps 5889.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.529 | train_wall 325 | gb_free 6.1 | wall 2489
KL Stats: Epoch 7 Divergences: Uniform: 1.1898476593874319 Unigram: 0.624770568335686
2022-01-28 08:29:14 | INFO | fairseq.trainer | begin training epoch 8
2022-01-28 08:29:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:33:40 | INFO | train_inner | epoch 008:     52 / 64 loss=11.488, ppl=2872.86, wps=6060.9, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.523, train_wall=509, gb_free=6.1, wall=2756
2022-01-28 08:34:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 08:35:08 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.379 | ppl 2664.18 | wps 7854.4 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-28 08:35:08 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-28 08:35:08 | INFO | train | epoch 008 | loss 11.432 | ppl 2762.5 | wps 5890.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.516 | train_wall 325 | gb_free 6.1 | wall 2844
KL Stats: Epoch 8 Divergences: Uniform: 1.2693618784149752 Unigram: 0.7531461253782087
2022-01-28 08:35:08 | INFO | fairseq.trainer | begin training epoch 9
2022-01-28 08:35:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:40:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:41:04 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 11.246 | ppl 2428.49 | wps 7868.9 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-28 08:41:04 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-28 08:41:04 | INFO | train | epoch 009 | loss 11.309 | ppl 2536.63 | wps 5870.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.487 | train_wall 326 | gb_free 6.1 | wall 3199
KL Stats: Epoch 9 Divergences: Uniform: 1.293633937941516 Unigram: 0.9268775104788531
2022-01-28 08:41:04 | INFO | fairseq.trainer | begin training epoch 10
2022-01-28 08:41:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:43:07 | INFO | train_inner | epoch 010:     24 / 64 loss=11.298, ppl=2517.33, wps=5750, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.488, train_wall=509, gb_free=6.1, wall=3323
2022-01-28 08:46:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:46:59 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 11.124 | ppl 2231.39 | wps 7856.5 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-28 08:46:59 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-28 08:46:59 | INFO | train | epoch 010 | loss 11.181 | ppl 2322.25 | wps 5885.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.486 | train_wall 325 | gb_free 6.1 | wall 3554
KL Stats: Epoch 10 Divergences: Uniform: 1.3072914944931078 Unigram: 1.1255790588858918
2022-01-28 08:46:59 | INFO | fairseq.trainer | begin training epoch 11
2022-01-28 08:46:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:52:07 | INFO | train_inner | epoch 011:     60 / 64 loss=11.094, ppl=2186.41, wps=6055.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.498, train_wall=509, gb_free=6.1, wall=3862
2022-01-28 08:52:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 08:52:54 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 11.005 | ppl 2054.94 | wps 7843 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-28 08:52:54 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-28 08:52:54 | INFO | train | epoch 011 | loss 11.049 | ppl 2118.57 | wps 5884.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.499 | train_wall 325 | gb_free 6.1 | wall 3909
KL Stats: Epoch 11 Divergences: Uniform: 1.3204991859803452 Unigram: 1.3311761696498445
2022-01-28 08:52:54 | INFO | fairseq.trainer | begin training epoch 12
2022-01-28 08:52:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:58:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:58:49 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.878 | ppl 1881.98 | wps 7852.5 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-28 08:58:49 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-28 08:58:49 | INFO | train | epoch 012 | loss 10.92 | ppl 1937.85 | wps 5883.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.504 | train_wall 325 | gb_free 6.1 | wall 4264
KL Stats: Epoch 12 Divergences: Uniform: 1.3304115337527598 Unigram: 1.528798138254016
2022-01-28 08:58:49 | INFO | fairseq.trainer | begin training epoch 13
2022-01-28 08:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:01:33 | INFO | train_inner | epoch 013:     32 / 64 loss=10.894, ppl=1902.89, wps=5755.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.513, train_wall=508, gb_free=6.1, wall=4429
2022-01-28 09:04:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 09:04:44 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.782 | ppl 1760.24 | wps 7868 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-28 09:04:44 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-28 09:04:44 | INFO | train | epoch 013 | loss 10.797 | ppl 1778.62 | wps 5880.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.523 | train_wall 326 | gb_free 6.1 | wall 4619
KL Stats: Epoch 13 Divergences: Uniform: 1.3512645325446944 Unigram: 1.7090089108432815
2022-01-28 09:04:44 | INFO | fairseq.trainer | begin training epoch 14
2022-01-28 09:04:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:10:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 09:10:39 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.688 | ppl 1649.21 | wps 7860.2 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-28 09:10:39 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-28 09:10:39 | INFO | train | epoch 014 | loss 10.68 | ppl 1640.63 | wps 5888.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.587 | train_wall 325 | gb_free 6.1 | wall 4974
KL Stats: Epoch 14 Divergences: Uniform: 1.3761778110617593 Unigram: 1.8754429411898705
2022-01-28 09:10:39 | INFO | fairseq.trainer | begin training epoch 15
2022-01-28 09:10:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:10:59 | INFO | train_inner | epoch 015:      4 / 64 loss=10.704, ppl=1667.98, wps=5758.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.56, train_wall=508, gb_free=6.1, wall=4995
2022-01-28 09:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:16:34 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.602 | ppl 1553.82 | wps 7863.9 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-28 09:16:34 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-28 09:16:34 | INFO | train | epoch 015 | loss 10.564 | ppl 1514.18 | wps 5877.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.574 | train_wall 326 | gb_free 6.1 | wall 5330
KL Stats: Epoch 15 Divergences: Uniform: 1.3968676868884022 Unigram: 2.0283218083040904
2022-01-28 09:16:34 | INFO | fairseq.trainer | begin training epoch 16
2022-01-28 09:16:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:20:00 | INFO | train_inner | epoch 016:     40 / 64 loss=10.521, ppl=1469.33, wps=6049.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.576, train_wall=510, gb_free=6.1, wall=5535
2022-01-28 09:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:22:29 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.518 | ppl 1466.3 | wps 7849.4 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-28 09:22:29 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-28 09:22:29 | INFO | train | epoch 016 | loss 10.453 | ppl 1402.21 | wps 5878.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.572 | train_wall 326 | gb_free 6.1 | wall 5685
KL Stats: Epoch 16 Divergences: Uniform: 1.4198494831615165 Unigram: 2.1787623753824925
2022-01-28 09:22:29 | INFO | fairseq.trainer | begin training epoch 17
2022-01-28 09:22:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:27:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:28:25 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.436 | ppl 1385.63 | wps 7775 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-28 09:28:25 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-28 09:28:25 | INFO | train | epoch 017 | loss 10.344 | ppl 1299.81 | wps 5880.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.563 | train_wall 325 | gb_free 6.1 | wall 6040
KL Stats: Epoch 17 Divergences: Uniform: 1.4507947531584575 Unigram: 2.3116742207958496
2022-01-28 09:28:25 | INFO | fairseq.trainer | begin training epoch 18
2022-01-28 09:28:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:29:26 | INFO | train_inner | epoch 018:     12 / 64 loss=10.359, ppl=1313.22, wps=5753.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.576, train_wall=508, gb_free=6.1, wall=6102
2022-01-28 09:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:34:20 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.366 | ppl 1319.63 | wps 7856.2 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-28 09:34:20 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-28 09:34:20 | INFO | train | epoch 018 | loss 10.243 | ppl 1211.6 | wps 5879.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.606 | train_wall 326 | gb_free 6.1 | wall 6395
KL Stats: Epoch 18 Divergences: Uniform: 1.4761783062909055 Unigram: 2.4525288111148704
2022-01-28 09:34:20 | INFO | fairseq.trainer | begin training epoch 19
2022-01-28 09:34:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:38:26 | INFO | train_inner | epoch 019:     48 / 64 loss=10.192, ppl=1169.69, wps=6051.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.559, train_wall=510, gb_free=6.1, wall=6642
2022-01-28 09:39:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:40:15 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.28 | ppl 1243.05 | wps 7863.9 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-28 09:40:15 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-28 09:40:15 | INFO | train | epoch 019 | loss 10.137 | ppl 1125.79 | wps 5883 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.533 | train_wall 326 | gb_free 6.1 | wall 6750
KL Stats: Epoch 19 Divergences: Uniform: 1.5052891341622967 Unigram: 2.585896279724026
2022-01-28 09:40:15 | INFO | fairseq.trainer | begin training epoch 20
2022-01-28 09:40:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:45:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:46:10 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 10.197 | ppl 1173.54 | wps 7879.5 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-28 09:46:10 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-28 09:46:10 | INFO | train | epoch 020 | loss 10.037 | ppl 1050.3 | wps 5872.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.564 | train_wall 326 | gb_free 6.1 | wall 7106
KL Stats: Epoch 20 Divergences: Uniform: 1.5337911602448635 Unigram: 2.7214378792076603
2022-01-28 09:46:10 | INFO | fairseq.trainer | begin training epoch 21
2022-01-28 09:46:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:47:53 | INFO | train_inner | epoch 021:     20 / 64 loss=10.031, ppl=1046.5, wps=5748.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.565, train_wall=509, gb_free=6.1, wall=7209
2022-01-28 09:51:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:52:06 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 10.13 | ppl 1120.64 | wps 7861 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-28 09:52:06 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-28 09:52:06 | INFO | train | epoch 021 | loss 9.939 | ppl 981.35 | wps 5874.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.574 | train_wall 326 | gb_free 6.1 | wall 7461
KL Stats: Epoch 21 Divergences: Uniform: 1.5592282924237275 Unigram: 2.8541491162866897
2022-01-28 09:52:06 | INFO | fairseq.trainer | begin training epoch 22
2022-01-28 09:52:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:56:54 | INFO | train_inner | epoch 022:     56 / 64 loss=9.883, ppl=944.49, wps=6048.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.581, train_wall=510, gb_free=6.1, wall=7749
2022-01-28 09:57:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:58:01 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 10.074 | ppl 1077.8 | wps 7866.3 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-28 09:58:01 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-28 09:58:01 | INFO | train | epoch 022 | loss 9.845 | ppl 919.41 | wps 5880.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.586 | train_wall 326 | gb_free 6.1 | wall 7817
KL Stats: Epoch 22 Divergences: Uniform: 1.5876551897749074 Unigram: 2.9928127090718233
2022-01-28 09:58:01 | INFO | fairseq.trainer | begin training epoch 23
2022-01-28 09:58:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:03:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:03:56 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.994 | ppl 1020.06 | wps 7843.2 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-28 10:03:56 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-28 10:03:56 | INFO | train | epoch 023 | loss 9.754 | ppl 863.46 | wps 5884.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.557 | train_wall 325 | gb_free 6.1 | wall 8172
KL Stats: Epoch 23 Divergences: Uniform: 1.6093270946914124 Unigram: 3.1222851755774608
2022-01-28 10:03:56 | INFO | fairseq.trainer | begin training epoch 24
2022-01-28 10:03:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:06:20 | INFO | train_inner | epoch 024:     28 / 64 loss=9.739, ppl=854.37, wps=5759.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.571, train_wall=508, gb_free=6.1, wall=8315
2022-01-28 10:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 10:09:51 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.934 | ppl 978.2 | wps 7854.2 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-28 10:09:51 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-28 10:09:51 | INFO | train | epoch 024 | loss 9.667 | ppl 813.02 | wps 5887.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.594 | train_wall 325 | gb_free 6.1 | wall 8526
KL Stats: Epoch 24 Divergences: Uniform: 1.6336180502395867 Unigram: 3.245504954524745
2022-01-28 10:09:51 | INFO | fairseq.trainer | begin training epoch 25
2022-01-28 10:09:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:15:18 | INFO | train_inner | epoch 025:     64 / 64 loss=9.611, ppl=782.21, wps=6057.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.585, train_wall=508, gb_free=6.1, wall=8853
2022-01-28 10:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:15:46 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.89 | ppl 948.74 | wps 7858.3 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-28 10:15:46 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-28 10:15:46 | INFO | train | epoch 025 | loss 9.583 | ppl 767.2 | wps 5887.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.581 | train_wall 325 | gb_free 6.1 | wall 8881
KL Stats: Epoch 25 Divergences: Uniform: 1.6555213651496254 Unigram: 3.3757942564160466
2022-01-28 10:15:46 | INFO | fairseq.trainer | begin training epoch 26
2022-01-28 10:15:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:21:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:21:41 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.844 | ppl 918.81 | wps 7878.3 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-28 10:21:41 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-28 10:21:41 | INFO | train | epoch 026 | loss 9.499 | ppl 723.34 | wps 5882.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.583 | train_wall 326 | gb_free 6.1 | wall 9236
KL Stats: Epoch 26 Divergences: Uniform: 1.6734176829715226 Unigram: 3.501704314418544
2022-01-28 10:21:41 | INFO | fairseq.trainer | begin training epoch 27
2022-01-28 10:21:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:24:45 | INFO | train_inner | epoch 027:     36 / 64 loss=9.471, ppl=709.63, wps=5760.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.586, train_wall=509, gb_free=6.1, wall=9421
2022-01-28 10:27:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:27:36 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.805 | ppl 894.33 | wps 7868.6 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-28 10:27:36 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-28 10:27:36 | INFO | train | epoch 027 | loss 9.417 | ppl 683.59 | wps 5884.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.571 | train_wall 325 | gb_free 6.1 | wall 9591
KL Stats: Epoch 27 Divergences: Uniform: 1.696059632555305 Unigram: 3.6292677042064168
2022-01-28 10:27:36 | INFO | fairseq.trainer | begin training epoch 28
2022-01-28 10:27:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:33:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 10:33:31 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.758 | ppl 865.96 | wps 7852.2 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-28 10:33:31 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-28 10:33:31 | INFO | train | epoch 028 | loss 9.334 | ppl 645.52 | wps 5872.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.564 | train_wall 326 | gb_free 6.1 | wall 9947
KL Stats: Epoch 28 Divergences: Uniform: 1.718936688625913 Unigram: 3.7550746680258436
2022-01-28 10:33:31 | INFO | fairseq.trainer | begin training epoch 29
2022-01-28 10:33:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:34:12 | INFO | train_inner | epoch 029:      8 / 64 loss=9.351, ppl=652.86, wps=5748.1, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.563, train_wall=509, gb_free=6.1, wall=9988
2022-01-28 10:38:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 10:39:26 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.708 | ppl 836.1 | wps 7870.5 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-28 10:39:26 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-28 10:39:26 | INFO | train | epoch 029 | loss 9.254 | ppl 610.72 | wps 5887 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.572 | train_wall 325 | gb_free 6.1 | wall 10302
KL Stats: Epoch 29 Divergences: Uniform: 1.7403612924161826 Unigram: 3.879042522355921
2022-01-28 10:39:26 | INFO | fairseq.trainer | begin training epoch 30
2022-01-28 10:39:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:43:12 | INFO | train_inner | epoch 030:     44 / 64 loss=9.221, ppl=596.65, wps=6050.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.575, train_wall=510, gb_free=6.1, wall=10528
2022-01-28 10:44:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:45:22 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.678 | ppl 819.37 | wps 7863.1 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-28 10:45:22 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-28 10:45:22 | INFO | train | epoch 030 | loss 9.175 | ppl 578.05 | wps 5872.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.591 | train_wall 326 | gb_free 6.1 | wall 10657
KL Stats: Epoch 30 Divergences: Uniform: 1.7616181180998849 Unigram: 4.00939772619018
2022-01-28 10:45:22 | INFO | fairseq.trainer | begin training epoch 31
2022-01-28 10:45:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:50:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:51:17 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.64 | ppl 797.7 | wps 7856.5 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-28 10:51:17 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-28 10:51:17 | INFO | train | epoch 031 | loss 9.091 | ppl 545.44 | wps 5873.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.548 | train_wall 326 | gb_free 6.1 | wall 11013
KL Stats: Epoch 31 Divergences: Uniform: 1.7752112786715897 Unigram: 4.134832785598341
2022-01-28 10:51:17 | INFO | fairseq.trainer | begin training epoch 32
2022-01-28 10:51:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:52:39 | INFO | train_inner | epoch 032:     16 / 64 loss=9.093, ppl=545.99, wps=5751, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.562, train_wall=509, gb_free=6.1, wall=11095
2022-01-28 10:56:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:57:12 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.586 | ppl 768.8 | wps 7850.5 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-28 10:57:12 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-28 10:57:12 | INFO | train | epoch 032 | loss 9.016 | ppl 517.58 | wps 5879.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.583 | train_wall 326 | gb_free 6.1 | wall 11368
KL Stats: Epoch 32 Divergences: Uniform: 1.7979168199826177 Unigram: 4.260066907775174
2022-01-28 10:57:12 | INFO | fairseq.trainer | begin training epoch 33
2022-01-28 10:57:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:01:40 | INFO | train_inner | epoch 033:     52 / 64 loss=8.977, ppl=503.77, wps=6045, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.582, train_wall=510, gb_free=6.1, wall=11635
2022-01-28 11:02:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:03:08 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.56 | ppl 754.62 | wps 7865.1 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-28 11:03:08 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-28 11:03:08 | INFO | train | epoch 033 | loss 8.937 | ppl 490.06 | wps 5874 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.577 | train_wall 326 | gb_free 6.1 | wall 11724
KL Stats: Epoch 33 Divergences: Uniform: 1.818123962950082 Unigram: 4.404078794065391
2022-01-28 11:03:08 | INFO | fairseq.trainer | begin training epoch 34
2022-01-28 11:03:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:08:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:09:03 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.554 | ppl 751.88 | wps 7879.2 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-28 11:09:03 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-28 11:09:03 | INFO | train | epoch 034 | loss 8.857 | ppl 463.81 | wps 5888.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.574 | train_wall 325 | gb_free 6.1 | wall 12078
KL Stats: Epoch 34 Divergences: Uniform: 1.836636763385175 Unigram: 4.543286809061984
2022-01-28 11:09:03 | INFO | fairseq.trainer | begin training epoch 35
2022-01-28 11:09:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:11:06 | INFO | train_inner | epoch 035:     24 / 64 loss=8.844, ppl=459.68, wps=5761.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.582, train_wall=508, gb_free=6.1, wall=12201
2022-01-28 11:14:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:14:58 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.501 | ppl 724.44 | wps 7794.5 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-28 11:14:58 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-28 11:14:58 | INFO | train | epoch 035 | loss 8.781 | ppl 440.03 | wps 5886.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.581 | train_wall 325 | gb_free 6.1 | wall 12433
KL Stats: Epoch 35 Divergences: Uniform: 1.853434669034935 Unigram: 4.6848557671599
2022-01-28 11:14:58 | INFO | fairseq.trainer | begin training epoch 36
2022-01-28 11:14:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:20:05 | INFO | train_inner | epoch 036:     60 / 64 loss=8.734, ppl=425.76, wps=6056.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.578, train_wall=509, gb_free=6.1, wall=12741
2022-01-28 11:20:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:20:52 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.473 | ppl 710.45 | wps 7862.8 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-28 11:20:52 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-28 11:20:52 | INFO | train | epoch 036 | loss 8.703 | ppl 416.68 | wps 5887.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.585 | train_wall 325 | gb_free 6.1 | wall 12788
KL Stats: Epoch 36 Divergences: Uniform: 1.8723374086118412 Unigram: 4.846339029150436
2022-01-28 11:20:52 | INFO | fairseq.trainer | begin training epoch 37
2022-01-28 11:20:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:26:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 11:26:48 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.463 | ppl 705.95 | wps 7856.2 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-28 11:26:48 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-28 11:26:48 | INFO | train | epoch 037 | loss 8.626 | ppl 395.21 | wps 5875.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.594 | train_wall 326 | gb_free 6.1 | wall 13143
KL Stats: Epoch 37 Divergences: Uniform: 1.8873297035879313 Unigram: 4.999270206549619
2022-01-28 11:26:48 | INFO | fairseq.trainer | begin training epoch 38
2022-01-28 11:26:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:29:32 | INFO | train_inner | epoch 038:     32 / 64 loss=8.604, ppl=389.1, wps=5751.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.584, train_wall=509, gb_free=6.1, wall=13308
2022-01-28 11:32:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:32:44 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.437 | ppl 693.14 | wps 7698.6 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-28 11:32:44 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-28 11:32:44 | INFO | train | epoch 038 | loss 8.551 | ppl 375.12 | wps 5866.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.579 | train_wall 326 | gb_free 6.1 | wall 13499
KL Stats: Epoch 38 Divergences: Uniform: 1.9078948178187614 Unigram: 5.167193992689246
2022-01-28 11:32:44 | INFO | fairseq.trainer | begin training epoch 39
2022-01-28 11:32:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:38:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:38:39 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.414 | ppl 682.4 | wps 7855.5 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-28 11:38:39 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-28 11:38:39 | INFO | train | epoch 039 | loss 8.476 | ppl 356.18 | wps 5888 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.601 | train_wall 325 | gb_free 6.1 | wall 13854
KL Stats: Epoch 39 Divergences: Uniform: 1.92372861270422 Unigram: 5.350756800338738
2022-01-28 11:38:39 | INFO | fairseq.trainer | begin training epoch 40
2022-01-28 11:38:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:38:59 | INFO | train_inner | epoch 040:      4 / 64 loss=8.499, ppl=361.84, wps=5749.1, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.605, train_wall=508, gb_free=6.1, wall=13875
2022-01-28 11:44:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:44:33 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.393 | ppl 672.19 | wps 7875.6 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-28 11:44:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-28 11:44:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint40.pt
2022-01-28 11:44:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint40.pt
2022-01-28 11:44:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.393) (writing took 4.480983412824571 seconds)
2022-01-28 11:44:38 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-28 11:44:38 | INFO | train | epoch 040 | loss 8.4 | ppl 337.7 | wps 5812.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.61 | train_wall 325 | gb_free 6.1 | wall 14213
KL Stats: Epoch 40 Divergences: Uniform: 1.9415937355767872 Unigram: 5.53892923914693
2022-01-28 11:44:38 | INFO | fairseq.trainer | begin training epoch 41
2022-01-28 11:44:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:48:03 | INFO | train_inner | epoch 041:     40 / 64 loss=8.373, ppl=331.63, wps=6005.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.602, train_wall=509, gb_free=6.1, wall=14419
2022-01-28 11:50:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:50:33 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.374 | ppl 663.38 | wps 7853.5 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.374
2022-01-28 11:50:33 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-28 11:50:33 | INFO | train | epoch 041 | loss 8.328 | ppl 321.4 | wps 5882.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.608 | train_wall 326 | gb_free 6.1 | wall 14568
KL Stats: Epoch 41 Divergences: Uniform: 1.948356016868493 Unigram: 5.722181985815313
2022-01-28 11:50:33 | INFO | fairseq.trainer | begin training epoch 42
2022-01-28 11:50:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:56:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 11:56:28 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.353 | ppl 653.75 | wps 7879.5 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.353
2022-01-28 11:56:28 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-28 11:56:28 | INFO | train | epoch 042 | loss 8.254 | ppl 305.36 | wps 5887 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.623 | train_wall 325 | gb_free 6.1 | wall 14923
KL Stats: Epoch 42 Divergences: Uniform: 1.9641636351294587 Unigram: 5.935334637172478
2022-01-28 11:56:28 | INFO | fairseq.trainer | begin training epoch 43
2022-01-28 11:56:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:57:29 | INFO | train_inner | epoch 043:     12 / 64 loss=8.262, ppl=306.93, wps=5758.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.623, train_wall=508, gb_free=6.1, wall=14985
2022-01-28 12:01:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 12:02:22 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.326 | ppl 641.86 | wps 7859.8 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.326
2022-01-28 12:02:22 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-28 12:02:22 | INFO | train | epoch 043 | loss 8.182 | ppl 290.46 | wps 5887.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.639 | train_wall 325 | gb_free 6.1 | wall 15278
KL Stats: Epoch 43 Divergences: Uniform: 1.9844479077242239 Unigram: 6.158404778651116
2022-01-28 12:02:22 | INFO | fairseq.trainer | begin training epoch 44
2022-01-28 12:02:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:06:29 | INFO | train_inner | epoch 044:     48 / 64 loss=8.145, ppl=283.02, wps=6052.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.664, train_wall=510, gb_free=6.1, wall=15525
2022-01-28 12:07:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:08:18 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.352 | ppl 653.29 | wps 7871.8 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.352
2022-01-28 12:08:18 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-28 12:08:18 | INFO | train | epoch 044 | loss 8.112 | ppl 276.74 | wps 5876.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.673 | train_wall 326 | gb_free 6.1 | wall 15633
KL Stats: Epoch 44 Divergences: Uniform: 2.0002903327696386 Unigram: 6.376442382031952
2022-01-28 12:08:18 | INFO | fairseq.trainer | begin training epoch 45
2022-01-28 12:08:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:13:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 12:14:14 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.352 | ppl 653.45 | wps 7838.5 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.352
2022-01-28 12:14:14 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-28 12:14:14 | INFO | train | epoch 045 | loss 8.038 | ppl 262.85 | wps 5873.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.651 | train_wall 326 | gb_free 6.1 | wall 15989
KL Stats: Epoch 45 Divergences: Uniform: 2.0034445065474222 Unigram: 6.623822064914018
2022-01-28 12:14:14 | INFO | fairseq.trainer | begin training epoch 46
2022-01-28 12:14:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:15:56 | INFO | train_inner | epoch 046:     20 / 64 loss=8.036, ppl=262.52, wps=5749.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.648, train_wall=509, gb_free=6.1, wall=16092
2022-01-28 12:19:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:20:09 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.335 | ppl 646.02 | wps 7833.3 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.335
2022-01-28 12:20:09 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-28 12:20:09 | INFO | train | epoch 046 | loss 7.968 | ppl 250.4 | wps 5881 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.683 | train_wall 326 | gb_free 6.1 | wall 16344
KL Stats: Epoch 46 Divergences: Uniform: 2.0217959289279874 Unigram: 6.869225645933054
2022-01-28 12:20:09 | INFO | fairseq.trainer | begin training epoch 47
2022-01-28 12:20:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:24:56 | INFO | train_inner | epoch 047:     56 / 64 loss=7.931, ppl=244, wps=6052.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.691, train_wall=509, gb_free=6.1, wall=16632
2022-01-28 12:25:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 12:26:04 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.308 | ppl 633.93 | wps 7840.8 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.308
2022-01-28 12:26:04 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-28 12:26:04 | INFO | train | epoch 047 | loss 7.897 | ppl 238.38 | wps 5880.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.685 | train_wall 326 | gb_free 6.1 | wall 16699
KL Stats: Epoch 47 Divergences: Uniform: 2.033658074210921 Unigram: 7.1429876572176765
2022-01-28 12:26:04 | INFO | fairseq.trainer | begin training epoch 48
2022-01-28 12:26:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:31:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:31:59 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.34 | ppl 647.94 | wps 7865 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.34
2022-01-28 12:31:59 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-28 12:31:59 | INFO | train | epoch 048 | loss 7.825 | ppl 226.7 | wps 5882.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.719 | train_wall 326 | gb_free 6.1 | wall 17054
KL Stats: Epoch 48 Divergences: Uniform: 2.042977820276632 Unigram: 7.427230865437879
2022-01-28 12:31:59 | INFO | fairseq.trainer | begin training epoch 49
2022-01-28 12:31:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:34:23 | INFO | train_inner | epoch 049:     28 / 64 loss=7.806, ppl=223.84, wps=5754.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.718, train_wall=508, gb_free=6.1, wall=17198
2022-01-28 12:37:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:37:54 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.327 | ppl 642.46 | wps 7842.5 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.327
2022-01-28 12:37:54 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-28 12:37:54 | INFO | train | epoch 049 | loss 7.756 | ppl 216.24 | wps 5882.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.73 | train_wall 325 | gb_free 6.1 | wall 17409
KL Stats: Epoch 49 Divergences: Uniform: 2.0548426686950223 Unigram: 7.733301914484301
2022-01-28 12:37:54 | INFO | fairseq.trainer | begin training epoch 50
2022-01-28 12:37:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:43:21 | INFO | train_inner | epoch 050:     64 / 64 loss=7.719, ppl=210.63, wps=6056.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.74, train_wall=508, gb_free=6.1, wall=17737
2022-01-28 12:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:43:49 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.384 | ppl 668.08 | wps 7863.8 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.384
2022-01-28 12:43:49 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-28 12:43:49 | INFO | train | epoch 050 | loss 7.688 | ppl 206.16 | wps 5886.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.744 | train_wall 325 | gb_free 6.1 | wall 17764
KL Stats: Epoch 50 Divergences: Uniform: 2.060391117824854 Unigram: 8.032549794176342
2022-01-28 12:43:49 | INFO | fairseq.trainer | begin training epoch 51
2022-01-28 12:43:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:49:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:49:44 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.374 | ppl 663.49 | wps 7859.9 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.374
2022-01-28 12:49:44 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-28 12:49:44 | INFO | train | epoch 051 | loss 7.62 | ppl 196.78 | wps 5880 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.801 | train_wall 326 | gb_free 6.1 | wall 18120
KL Stats: Epoch 51 Divergences: Uniform: 2.0725636282233837 Unigram: 8.358545424405914
2022-01-28 12:49:44 | INFO | fairseq.trainer | begin training epoch 52
2022-01-28 12:49:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:52:49 | INFO | train_inner | epoch 052:     36 / 64 loss=7.59, ppl=192.74, wps=5753.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.768, train_wall=510, gb_free=6.1, wall=18305
2022-01-28 12:55:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:55:39 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.341 | ppl 648.5 | wps 7855.9 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.341
2022-01-28 12:55:39 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-28 12:55:39 | INFO | train | epoch 052 | loss 7.544 | ppl 186.66 | wps 5878.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.735 | train_wall 326 | gb_free 6.1 | wall 18475
KL Stats: Epoch 52 Divergences: Uniform: 2.0682614865537965 Unigram: 8.740811382671277
2022-01-28 12:55:39 | INFO | fairseq.trainer | begin training epoch 53
2022-01-28 12:55:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:01:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:01:34 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.344 | ppl 650.06 | wps 7867.2 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.344
2022-01-28 13:01:34 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-28 13:01:34 | INFO | train | epoch 053 | loss 7.48 | ppl 178.56 | wps 5883.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.841 | train_wall 326 | gb_free 6.1 | wall 18830
KL Stats: Epoch 53 Divergences: Uniform: 2.084298691853279 Unigram: 9.094165483687224
2022-01-28 13:01:34 | INFO | fairseq.trainer | begin training epoch 54
2022-01-28 13:01:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:02:15 | INFO | train_inner | epoch 054:      8 / 64 loss=7.493, ppl=180.15, wps=5755.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.828, train_wall=508, gb_free=6.1, wall=18871
2022-01-28 13:07:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:07:29 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.429 | ppl 689.08 | wps 7845.9 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.393
2022-01-28 13:07:29 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-28 13:07:29 | INFO | train | epoch 054 | loss 7.41 | ppl 170.04 | wps 5885.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.883 | train_wall 325 | gb_free 6.1 | wall 19185
KL Stats: Epoch 54 Divergences: Uniform: 2.1006904141510323 Unigram: 9.499562735881373
2022-01-28 13:07:29 | INFO | fairseq.trainer | begin training epoch 55
2022-01-28 13:07:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:11:15 | INFO | train_inner | epoch 055:     44 / 64 loss=7.377, ppl=166.18, wps=6058.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.888, train_wall=509, gb_free=6.1, wall=19410
2022-01-28 13:12:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:13:24 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.413 | ppl 681.83 | wps 7828.3 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.393
2022-01-28 13:13:24 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-28 13:13:24 | INFO | train | epoch 055 | loss 7.343 | ppl 162.41 | wps 5887.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.862 | train_wall 325 | gb_free 6.1 | wall 19539
KL Stats: Epoch 55 Divergences: Uniform: 2.093075303146694 Unigram: 9.906340698110121
2022-01-28 13:13:24 | INFO | fairseq.trainer | begin training epoch 56
2022-01-28 13:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:18:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:19:19 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.392 | ppl 671.98 | wps 7885 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.392
2022-01-28 13:19:19 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-28 13:19:19 | INFO | train | epoch 056 | loss 7.277 | ppl 155.07 | wps 5889.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.957 | train_wall 325 | gb_free 6.1 | wall 19894
KL Stats: Epoch 56 Divergences: Uniform: 2.1028322184080555 Unigram: 10.299870356844629
2022-01-28 13:19:19 | INFO | fairseq.trainer | begin training epoch 57
2022-01-28 13:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:20:41 | INFO | train_inner | epoch 057:     16 / 64 loss=7.279, ppl=155.26, wps=5759, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.923, train_wall=508, gb_free=6.1, wall=19976
2022-01-28 13:24:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:25:14 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.468 | ppl 708.12 | wps 7859.1 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.393
2022-01-28 13:25:14 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-28 13:25:14 | INFO | train | epoch 057 | loss 7.204 | ppl 147.48 | wps 5876.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.949 | train_wall 326 | gb_free 6.1 | wall 20250
KL Stats: Epoch 57 Divergences: Uniform: 2.117048842717529 Unigram: 10.765799830978942
2022-01-28 13:25:14 | INFO | fairseq.trainer | begin training epoch 58
2022-01-28 13:25:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:29:42 | INFO | train_inner | epoch 058:     52 / 64 loss=7.167, ppl=143.76, wps=6043.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=1.008, train_wall=510, gb_free=6.1, wall=20517
2022-01-28 13:30:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:31:10 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.572 | ppl 761.18 | wps 7864.7 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.393
2022-01-28 13:31:10 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-28 13:31:10 | INFO | train | epoch 058 | loss 7.138 | ppl 140.88 | wps 5867.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 1.031 | train_wall 326 | gb_free 6.1 | wall 20605
KL Stats: Epoch 58 Divergences: Uniform: 2.117249760265833 Unigram: 11.232498860602584
2022-01-28 13:31:10 | INFO | fairseq.trainer | begin training epoch 59
2022-01-28 13:31:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:36:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:37:05 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.444 | ppl 696.51 | wps 7742.5 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.393
2022-01-28 13:37:05 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-28 13:37:05 | INFO | train | epoch 059 | loss 7.074 | ppl 134.75 | wps 5878.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 1.078 | train_wall 325 | gb_free 6.1 | wall 20961
KL Stats: Epoch 59 Divergences: Uniform: 2.133565703445787 Unigram: 11.74489621231411
2022-01-28 13:37:05 | INFO | fairseq.trainer | begin training epoch 60
2022-01-28 13:37:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:39:08 | INFO | train_inner | epoch 060:     24 / 64 loss=7.068, ppl=134.17, wps=5752.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=1.088, train_wall=508, gb_free=6.1, wall=21084
2022-01-28 13:42:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 13:43:00 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.527 | ppl 737.57 | wps 7859.6 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.393
2022-01-28 13:43:00 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-28 13:43:00 | INFO | train | epoch 060 | loss 7.006 | ppl 128.5 | wps 5885.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 1.187 | train_wall 325 | gb_free 6.1 | wall 21316
KL Stats: Epoch 60 Divergences: Uniform: 2.1405887610109127 Unigram: 12.237001924476674
2022-01-28 13:43:00 | INFO | fairseq.trainer | begin training epoch 61
2022-01-28 13:43:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:48:09 | INFO | train_inner | epoch 061:     60 / 64 loss=6.966, ppl=124.98, wps=6049.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=1.115, train_wall=510, gb_free=6.1, wall=21624
2022-01-28 13:48:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:48:56 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.571 | ppl 760.38 | wps 7856.6 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.393
2022-01-28 13:48:56 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-28 13:48:56 | INFO | train | epoch 061 | loss 6.934 | ppl 122.27 | wps 5875.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 1.083 | train_wall 326 | gb_free 6.1 | wall 21671
KL Stats: Epoch 61 Divergences: Uniform: 2.138490926833138 Unigram: 12.779423248487422
2022-01-28 13:48:56 | INFO | fairseq.trainer | begin training epoch 62
2022-01-28 13:48:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:54:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:54:51 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.553 | ppl 751.31 | wps 7827.9 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.393
2022-01-28 13:54:51 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-28 13:54:51 | INFO | train | epoch 062 | loss 6.873 | ppl 117.19 | wps 5877.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 1.243 | train_wall 326 | gb_free 6.1 | wall 22026
KL Stats: Epoch 62 Divergences: Uniform: 2.1352961526888508 Unigram: 13.340774352424578
2022-01-28 13:54:51 | INFO | fairseq.trainer | begin training epoch 63
2022-01-28 13:54:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:57:35 | INFO | train_inner | epoch 063:     32 / 64 loss=6.843, ppl=114.8, wps=5750.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=1.265, train_wall=508, gb_free=6.1, wall=22191
2022-01-28 14:00:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:00:47 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.559 | ppl 754.38 | wps 7819.4 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.393
2022-01-28 14:00:47 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-28 14:00:47 | INFO | train | epoch 063 | loss 6.803 | ppl 111.66 | wps 5872.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 1.315 | train_wall 326 | gb_free 6.1 | wall 22382
KL Stats: Epoch 63 Divergences: Uniform: 2.1408255756351084 Unigram: 13.852666945442643
2022-01-28 14:00:47 | INFO | fairseq.trainer | begin training epoch 64
2022-01-28 14:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:06:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:06:41 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.596 | ppl 773.88 | wps 7856.8 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.393
2022-01-28 14:06:41 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-28 14:06:41 | INFO | train | epoch 064 | loss 6.731 | ppl 106.2 | wps 5889 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 1.34 | train_wall 325 | gb_free 6.1 | wall 22737
KL Stats: Epoch 64 Divergences: Uniform: 2.142300840382887 Unigram: 14.50246442480718
2022-01-28 14:06:41 | INFO | fairseq.trainer | begin training epoch 65
2022-01-28 14:06:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:07:02 | INFO | train_inner | epoch 065:      4 / 64 loss=6.762, ppl=108.55, wps=5755.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=1.318, train_wall=508, gb_free=6.1, wall=22757
2022-01-28 14:12:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:12:37 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.502 | ppl 725.27 | wps 7874.8 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.393
2022-01-28 14:12:37 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-28 14:12:37 | INFO | train | epoch 065 | loss 6.656 | ppl 100.81 | wps 5876.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 1.298 | train_wall 326 | gb_free 6.1 | wall 23092
KL Stats: Epoch 65 Divergences: Uniform: 2.1633298019277114 Unigram: 15.098216991026668
2022-01-28 14:12:37 | INFO | fairseq.trainer | begin training epoch 66
2022-01-28 14:12:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:16:02 | INFO | train_inner | epoch 066:     40 / 64 loss=6.623, ppl=98.59, wps=6049.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=1.326, train_wall=510, gb_free=6.1, wall=23298
2022-01-28 14:18:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:18:32 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.667 | ppl 813.09 | wps 7862.9 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.393
2022-01-28 14:18:32 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-28 14:18:32 | INFO | train | epoch 066 | loss 6.591 | ppl 96.42 | wps 5882 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 1.44 | train_wall 326 | gb_free 6.1 | wall 23447
KL Stats: Epoch 66 Divergences: Uniform: 2.1334095272126854 Unigram: 15.615349813191244
2022-01-28 14:18:32 | INFO | fairseq.trainer | begin training epoch 67
2022-01-28 14:18:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:23:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:24:27 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.512 | ppl 730.09 | wps 7858.8 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.393
2022-01-28 14:24:27 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-28 14:24:27 | INFO | train | epoch 067 | loss 6.523 | ppl 91.95 | wps 5883.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 1.547 | train_wall 325 | gb_free 6.1 | wall 23802
KL Stats: Epoch 67 Divergences: Uniform: 2.159255606409607 Unigram: 16.31895315472518
2022-01-28 14:24:27 | INFO | fairseq.trainer | begin training epoch 68
2022-01-28 14:24:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:25:29 | INFO | train_inner | epoch 068:     12 / 64 loss=6.534, ppl=92.64, wps=5755, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=1.531, train_wall=508, gb_free=6.1, wall=23864
2022-01-28 14:29:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:30:22 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.712 | ppl 838.77 | wps 7779.3 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.393
2022-01-28 14:30:22 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-28 14:30:22 | INFO | train | epoch 068 | loss 6.447 | ppl 87.22 | wps 5879 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 1.472 | train_wall 325 | gb_free 6.1 | wall 24158
KL Stats: Epoch 68 Divergences: Uniform: 2.162432155130812 Unigram: 16.9735259019265
2022-01-28 14:30:22 | INFO | fairseq.trainer | begin training epoch 69
2022-01-28 14:30:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:34:28 | INFO | train_inner | epoch 069:     48 / 64 loss=6.426, ppl=85.95, wps=6055.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=1.701, train_wall=509, gb_free=6.1, wall=24404
2022-01-28 14:35:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 14:36:17 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.684 | ppl 822.38 | wps 7852.8 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.393
2022-01-28 14:36:17 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-28 14:36:17 | INFO | train | epoch 069 | loss 6.399 | ppl 84.41 | wps 5888.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 1.789 | train_wall 325 | gb_free 6.1 | wall 24512
KL Stats: Epoch 69 Divergences: Uniform: 2.1572390068281084 Unigram: 17.663593280384184
2022-01-28 14:36:17 | INFO | fairseq.trainer | begin training epoch 70
2022-01-28 14:36:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:41:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:42:12 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.859 | ppl 928.54 | wps 7855.1 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.393
2022-01-28 14:42:12 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-28 14:42:12 | INFO | train | epoch 070 | loss 6.312 | ppl 79.48 | wps 5876.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 1.458 | train_wall 326 | gb_free 6.1 | wall 24868
KL Stats: Epoch 70 Divergences: Uniform: 2.1581350526331375 Unigram: 18.296631243723105
2022-01-28 14:42:12 | INFO | fairseq.trainer | begin training epoch 71
2022-01-28 14:42:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:43:55 | INFO | train_inner | epoch 071:     20 / 64 loss=6.306, ppl=79.12, wps=5752.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=1.446, train_wall=508, gb_free=6.1, wall=24970
2022-01-28 14:47:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:48:08 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 10.092 | ppl 1091.42 | wps 7867.2 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.393
2022-01-28 14:48:08 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-28 14:48:08 | INFO | train | epoch 071 | loss 6.251 | ppl 76.16 | wps 5873.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 1.621 | train_wall 326 | gb_free 6.1 | wall 25223
KL Stats: Epoch 71 Divergences: Uniform: 2.161084413316797 Unigram: 18.987443625106845
2022-01-28 14:48:08 | INFO | fairseq.trainer | begin training epoch 72
2022-01-28 14:48:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:52:56 | INFO | train_inner | epoch 072:     56 / 64 loss=6.217, ppl=74.41, wps=6040.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=1.743, train_wall=510, gb_free=6.1, wall=25511
2022-01-28 14:53:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:54:04 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 10.054 | ppl 1062.79 | wps 7828.9 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.393
2022-01-28 14:54:04 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-28 14:54:04 | INFO | train | epoch 072 | loss 6.18 | ppl 72.53 | wps 5867.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 1.81 | train_wall 326 | gb_free 6.1 | wall 25579
KL Stats: Epoch 72 Divergences: Uniform: 2.1451479459517913 Unigram: 19.709080392606406
2022-01-28 14:54:04 | INFO | fairseq.trainer | begin training epoch 73
2022-01-28 14:54:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:59:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:59:59 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.869 | ppl 935.06 | wps 7849.2 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.393
2022-01-28 14:59:59 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-28 14:59:59 | INFO | train | epoch 073 | loss 6.147 | ppl 70.88 | wps 5885.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 2.322 | train_wall 325 | gb_free 6.1 | wall 25934
KL Stats: Epoch 73 Divergences: Uniform: 2.154900312317883 Unigram: 20.302436385004455
2022-01-28 14:59:59 | INFO | fairseq.trainer | begin training epoch 74
2022-01-28 14:59:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:02:22 | INFO | train_inner | epoch 074:     28 / 64 loss=6.13, ppl=70.04, wps=5754.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=2.093, train_wall=508, gb_free=6.1, wall=26078
2022-01-28 15:05:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:05:53 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.972 | ppl 1004.65 | wps 7867.9 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.393
2022-01-28 15:05:53 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-28 15:05:53 | INFO | train | epoch 074 | loss 6.066 | ppl 67.01 | wps 5886.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 1.624 | train_wall 325 | gb_free 6.1 | wall 26289
KL Stats: Epoch 74 Divergences: Uniform: 2.1467720408255504 Unigram: 20.960355979624822
2022-01-28 15:05:53 | INFO | fairseq.trainer | begin training epoch 75
2022-01-28 15:05:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:11:21 | INFO | train_inner | epoch 075:     64 / 64 loss=6.022, ppl=64.99, wps=6057.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=1.873, train_wall=508, gb_free=6.1, wall=26616
2022-01-28 15:11:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:11:48 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.826 | ppl 907.72 | wps 7859.4 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.393
2022-01-28 15:11:48 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-28 15:11:48 | INFO | train | epoch 075 | loss 5.997 | ppl 63.88 | wps 5885.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 1.99 | train_wall 325 | gb_free 6.1 | wall 26644
KL Stats: Epoch 75 Divergences: Uniform: 2.158714741852037 Unigram: 21.69443325968885
2022-01-28 15:11:48 | INFO | fairseq.trainer | begin training epoch 76
2022-01-28 15:11:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:17:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:17:43 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.714 | ppl 839.87 | wps 7840.6 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.393
2022-01-28 15:17:43 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-28 15:17:43 | INFO | train | epoch 076 | loss 5.942 | ppl 61.47 | wps 5885.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 2.139 | train_wall 325 | gb_free 6.1 | wall 26999
KL Stats: Epoch 76 Divergences: Uniform: 2.1596720142466093 Unigram: 22.389145405409973
2022-01-28 15:17:43 | INFO | fairseq.trainer | begin training epoch 77
2022-01-28 15:17:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:20:49 | INFO | train_inner | epoch 077:     36 / 64 loss=5.913, ppl=60.26, wps=5753.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=2.225, train_wall=510, gb_free=6.1, wall=27184
2022-01-28 15:23:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:23:39 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.289 | ppl 1251.07 | wps 7826.3 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.393
2022-01-28 15:23:39 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-28 15:23:39 | INFO | train | epoch 077 | loss 5.886 | ppl 59.12 | wps 5869.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 2.221 | train_wall 326 | gb_free 6.1 | wall 27355
KL Stats: Epoch 77 Divergences: Uniform: 2.1409338559778437 Unigram: 23.076792971377788
2022-01-28 15:23:39 | INFO | fairseq.trainer | begin training epoch 78
2022-01-28 15:23:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:29:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:29:34 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.803 | ppl 893.45 | wps 7884.4 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.393
2022-01-28 15:29:34 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-28 15:29:34 | INFO | train | epoch 078 | loss 5.82 | ppl 56.48 | wps 5879.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 2.235 | train_wall 326 | gb_free 6.1 | wall 27710
KL Stats: Epoch 78 Divergences: Uniform: 2.1647888174916288 Unigram: 23.73872213791171
2022-01-28 15:29:34 | INFO | fairseq.trainer | begin training epoch 79
2022-01-28 15:29:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:30:15 | INFO | train_inner | epoch 079:      8 / 64 loss=5.84, ppl=57.27, wps=5751.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=2.228, train_wall=508, gb_free=6.1, wall=27751
2022-01-28 15:35:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:35:29 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 10.123 | ppl 1114.8 | wps 7852.8 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.393
2022-01-28 15:35:29 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-28 15:35:29 | INFO | train | epoch 079 | loss 5.757 | ppl 54.08 | wps 5882.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 2.273 | train_wall 325 | gb_free 6.1 | wall 28065
KL Stats: Epoch 79 Divergences: Uniform: 2.138842443228297 Unigram: 24.39278762942677
2022-01-28 15:35:29 | INFO | fairseq.trainer | begin training epoch 80
2022-01-28 15:35:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:39:15 | INFO | train_inner | epoch 080:     44 / 64 loss=5.732, ppl=53.16, wps=6054.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=2.267, train_wall=509, gb_free=6.1, wall=28291
2022-01-28 15:40:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:41:24 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 10.332 | ppl 1289.37 | wps 7853 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.393
2022-01-28 15:41:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-28 15:41:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint80.pt
2022-01-28 15:41:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint80.pt
2022-01-28 15:41:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint80.pt (epoch 80 @ 5120 updates, score 10.332) (writing took 3.0628067404031754 seconds)
2022-01-28 15:41:27 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-28 15:41:27 | INFO | train | epoch 080 | loss 5.706 | ppl 52.18 | wps 5836.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 2.373 | train_wall 325 | gb_free 6.1 | wall 28423
KL Stats: Epoch 80 Divergences: Uniform: 2.146604336371593 Unigram: 25.15197272201247
2022-01-28 15:41:27 | INFO | fairseq.trainer | begin training epoch 81
2022-01-28 15:41:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:46:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:47:23 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 10.303 | ppl 1263.49 | wps 7876.6 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.393
2022-01-28 15:47:23 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-28 15:47:23 | INFO | train | epoch 081 | loss 5.647 | ppl 50.11 | wps 5872.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 2.351 | train_wall 326 | gb_free 6.1 | wall 28778
KL Stats: Epoch 81 Divergences: Uniform: 2.146869491059887 Unigram: 25.83453842464469
2022-01-28 15:47:23 | INFO | fairseq.trainer | begin training epoch 82
2022-01-28 15:47:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:48:45 | INFO | train_inner | epoch 082:     16 / 64 loss=5.651, ppl=50.25, wps=5718.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=2.382, train_wall=509, gb_free=6.1, wall=28861
2022-01-28 15:52:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:53:18 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 10.154 | ppl 1139.23 | wps 7863 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.393
2022-01-28 15:53:18 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-28 15:53:18 | INFO | train | epoch 082 | loss 5.59 | ppl 48.18 | wps 5881.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 2.699 | train_wall 326 | gb_free 6.1 | wall 29133
KL Stats: Epoch 82 Divergences: Uniform: 2.1479526012672934 Unigram: 26.610990100154545
2022-01-28 15:53:18 | INFO | fairseq.trainer | begin training epoch 83
2022-01-28 15:53:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:57:44 | INFO | train_inner | epoch 083:     52 / 64 loss=5.554, ppl=46.98, wps=6061.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=2.636, train_wall=509, gb_free=6.1, wall=29400
2022-01-28 15:58:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:59:12 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 10.988 | ppl 2031.63 | wps 7865.6 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.393
2022-01-28 15:59:12 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-28 15:59:12 | INFO | train | epoch 083 | loss 5.523 | ppl 46 | wps 5893.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 2.521 | train_wall 325 | gb_free 6.1 | wall 29488
KL Stats: Epoch 83 Divergences: Uniform: 2.126613129735575 Unigram: 27.289997896616903
2022-01-28 15:59:12 | INFO | fairseq.trainer | begin training epoch 84
2022-01-28 15:59:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:04:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:05:08 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.068 | ppl 2147.11 | wps 7840.7 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.393
2022-01-28 16:05:08 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-28 16:05:08 | INFO | train | epoch 084 | loss 5.473 | ppl 44.42 | wps 5881.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 2.755 | train_wall 326 | gb_free 6.1 | wall 29843
KL Stats: Epoch 84 Divergences: Uniform: 2.1474407680078023 Unigram: 28.018408130657605
2022-01-28 16:05:08 | INFO | fairseq.trainer | begin training epoch 85
2022-01-28 16:05:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:07:11 | INFO | train_inner | epoch 085:     24 / 64 loss=5.46, ppl=44.01, wps=5756.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=2.73, train_wall=508, gb_free=6.1, wall=29966
2022-01-28 16:10:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 16:11:03 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 10.091 | ppl 1090.48 | wps 7855.6 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.393
2022-01-28 16:11:03 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-28 16:11:03 | INFO | train | epoch 085 | loss 5.41 | ppl 42.51 | wps 5883 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 2.829 | train_wall 325 | gb_free 6.1 | wall 30198
KL Stats: Epoch 85 Divergences: Uniform: 2.1308787355833565 Unigram: 28.678374715873627
2022-01-28 16:11:03 | INFO | fairseq.trainer | begin training epoch 86
2022-01-28 16:11:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:16:10 | INFO | train_inner | epoch 086:     60 / 64 loss=5.391, ppl=41.95, wps=6059.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=2.846, train_wall=509, gb_free=6.1, wall=30506
2022-01-28 16:16:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 16:16:57 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 10.578 | ppl 1528.13 | wps 7857.8 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.393
2022-01-28 16:16:57 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-28 16:16:57 | INFO | train | epoch 086 | loss 5.367 | ppl 41.26 | wps 5892.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 2.834 | train_wall 325 | gb_free 6.1 | wall 30553
KL Stats: Epoch 86 Divergences: Uniform: 2.1346954169190835 Unigram: 29.332599878628624
2022-01-28 16:16:57 | INFO | fairseq.trainer | begin training epoch 87
2022-01-28 16:16:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:22:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:22:52 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 10.531 | ppl 1479.88 | wps 7852.8 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.393
2022-01-28 16:22:52 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-28 16:22:52 | INFO | train | epoch 087 | loss 5.303 | ppl 39.48 | wps 5879.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 3.177 | train_wall 326 | gb_free 6.1 | wall 30908
KL Stats: Epoch 87 Divergences: Uniform: 2.131844943330598 Unigram: 30.054724417735986
2022-01-28 16:22:52 | INFO | fairseq.trainer | begin training epoch 88
2022-01-28 16:22:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:25:37 | INFO | train_inner | epoch 088:     32 / 64 loss=5.286, ppl=39.02, wps=5753.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=3.09, train_wall=508, gb_free=6.1, wall=31072
2022-01-28 16:28:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:28:48 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 10.528 | ppl 1476.34 | wps 7809.3 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.393
2022-01-28 16:28:48 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-28 16:28:48 | INFO | train | epoch 088 | loss 5.251 | ppl 38.08 | wps 5875.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 3.174 | train_wall 326 | gb_free 6.1 | wall 31263
KL Stats: Epoch 88 Divergences: Uniform: 2.132430261153938 Unigram: 30.79718313543097
2022-01-28 16:28:48 | INFO | fairseq.trainer | begin training epoch 89
2022-01-28 16:28:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:34:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 16:34:43 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 10.415 | ppl 1365.47 | wps 7849.2 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.393
2022-01-28 16:34:43 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-28 16:34:43 | INFO | train | epoch 089 | loss 5.202 | ppl 36.81 | wps 5883.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 3.037 | train_wall 325 | gb_free 6.1 | wall 31618
KL Stats: Epoch 89 Divergences: Uniform: 2.1348237886568517 Unigram: 31.38437863386741
2022-01-28 16:34:43 | INFO | fairseq.trainer | begin training epoch 90
2022-01-28 16:34:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:35:03 | INFO | train_inner | epoch 090:      4 / 64 loss=5.216, ppl=37.17, wps=5753, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=3.133, train_wall=508, gb_free=6.1, wall=31639
2022-01-28 16:40:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:40:38 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 10.867 | ppl 1867.5 | wps 7846.2 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.393
2022-01-28 16:40:38 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-28 16:40:38 | INFO | train | epoch 090 | loss 5.158 | ppl 35.71 | wps 5874.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 3.273 | train_wall 326 | gb_free 6.1 | wall 31974
KL Stats: Epoch 90 Divergences: Uniform: 2.1210099814787897 Unigram: 32.07870674217959
2022-01-28 16:40:38 | INFO | fairseq.trainer | begin training epoch 91
2022-01-28 16:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:44:03 | INFO | train_inner | epoch 091:     40 / 64 loss=5.132, ppl=35.06, wps=6049.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=3.308, train_wall=510, gb_free=6.1, wall=32179
2022-01-28 16:46:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:46:33 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 10.514 | ppl 1462.29 | wps 7860.4 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.393
2022-01-28 16:46:33 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-28 16:46:33 | INFO | train | epoch 091 | loss 5.108 | ppl 34.49 | wps 5889.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 3.552 | train_wall 325 | gb_free 6.1 | wall 32328
KL Stats: Epoch 91 Divergences: Uniform: 2.134336562141862 Unigram: 32.727545239160285
2022-01-28 16:46:33 | INFO | fairseq.trainer | begin training epoch 92
2022-01-28 16:46:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:52:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:52:28 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.396 | ppl 2694.19 | wps 7856.8 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.393
2022-01-28 16:52:28 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-28 16:52:28 | INFO | train | epoch 092 | loss 5.051 | ppl 33.16 | wps 5879.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 3.155 | train_wall 326 | gb_free 6.1 | wall 32684
KL Stats: Epoch 92 Divergences: Uniform: 2.1172572851075206 Unigram: 33.372370381700264
2022-01-28 16:52:28 | INFO | fairseq.trainer | begin training epoch 93
2022-01-28 16:52:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:53:30 | INFO | train_inner | epoch 093:     12 / 64 loss=5.066, ppl=33.49, wps=5756.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=3.431, train_wall=508, gb_free=6.1, wall=32745
2022-01-28 16:57:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:58:23 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 11.04 | ppl 2105.9 | wps 7839.6 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.393
2022-01-28 16:58:23 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-28 16:58:23 | INFO | train | epoch 093 | loss 5.006 | ppl 32.13 | wps 5882.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 3.669 | train_wall 325 | gb_free 6.1 | wall 33039
KL Stats: Epoch 93 Divergences: Uniform: 2.112545187188634 Unigram: 34.054589198316094
2022-01-28 16:58:23 | INFO | fairseq.trainer | begin training epoch 94
2022-01-28 16:58:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:02:30 | INFO | train_inner | epoch 094:     48 / 64 loss=4.976, ppl=31.47, wps=6053.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=3.43, train_wall=509, gb_free=6.1, wall=33285
2022-01-28 17:03:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:04:19 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.28 | ppl 2485.81 | wps 7832.7 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.393
2022-01-28 17:04:19 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-28 17:04:19 | INFO | train | epoch 094 | loss 4.948 | ppl 30.86 | wps 5876.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 3.262 | train_wall 326 | gb_free 6.1 | wall 33394
KL Stats: Epoch 94 Divergences: Uniform: 2.1221761101359955 Unigram: 34.73041230331671
2022-01-28 17:04:19 | INFO | fairseq.trainer | begin training epoch 95
2022-01-28 17:04:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:09:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:10:14 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 10.809 | ppl 1794.09 | wps 7860.7 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.393
2022-01-28 17:10:14 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-28 17:10:14 | INFO | train | epoch 095 | loss 4.899 | ppl 29.84 | wps 5878.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 3.666 | train_wall 326 | gb_free 6.1 | wall 33749
KL Stats: Epoch 95 Divergences: Uniform: 2.1300163535716212 Unigram: 35.42342618492726
2022-01-28 17:10:14 | INFO | fairseq.trainer | begin training epoch 96
2022-01-28 17:10:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:11:57 | INFO | train_inner | epoch 096:     20 / 64 loss=4.898, ppl=29.81, wps=5745.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=3.647, train_wall=509, gb_free=6.1, wall=33852
2022-01-28 17:15:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:16:09 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 11.507 | ppl 2909.49 | wps 7830.1 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.393
2022-01-28 17:16:09 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-28 17:16:09 | INFO | train | epoch 096 | loss 4.854 | ppl 28.93 | wps 5877.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 3.725 | train_wall 326 | gb_free 6.1 | wall 34105
KL Stats: Epoch 96 Divergences: Uniform: 2.128547966136331 Unigram: 36.152216540936415
2022-01-28 17:16:09 | INFO | fairseq.trainer | begin training epoch 97
2022-01-28 17:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:20:57 | INFO | train_inner | epoch 097:     56 / 64 loss=4.826, ppl=28.36, wps=6055.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=3.731, train_wall=509, gb_free=6.1, wall=34392
2022-01-28 17:21:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:22:04 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 10.83 | ppl 1820.71 | wps 7797.8 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.393
2022-01-28 17:22:04 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-28 17:22:04 | INFO | train | epoch 097 | loss 4.803 | ppl 27.92 | wps 5879.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 3.927 | train_wall 325 | gb_free 6.1 | wall 34460
KL Stats: Epoch 97 Divergences: Uniform: 2.120402396227908 Unigram: 36.80949385939732
2022-01-28 17:22:04 | INFO | fairseq.trainer | begin training epoch 98
2022-01-28 17:22:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:27:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:27:59 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 10.755 | ppl 1728.52 | wps 7832.2 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.393
2022-01-28 17:27:59 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-28 17:27:59 | INFO | train | epoch 098 | loss 4.767 | ppl 27.22 | wps 5888.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 4.282 | train_wall 325 | gb_free 6.1 | wall 34815
KL Stats: Epoch 98 Divergences: Uniform: 2.110565045755067 Unigram: 37.34493010106533
2022-01-28 17:27:59 | INFO | fairseq.trainer | begin training epoch 99
2022-01-28 17:27:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:30:23 | INFO | train_inner | epoch 099:     28 / 64 loss=4.757, ppl=27.04, wps=5753.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=4.279, train_wall=508, gb_free=6.1, wall=34959
2022-01-28 17:33:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:33:55 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 12.217 | ppl 4761.38 | wps 7828.1 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.393
2022-01-28 17:33:55 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-28 17:33:55 | INFO | train | epoch 099 | loss 4.712 | ppl 26.21 | wps 5869.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 3.803 | train_wall 326 | gb_free 6.1 | wall 35171
KL Stats: Epoch 99 Divergences: Uniform: 2.1095136511447534 Unigram: 38.01387024264414
2022-01-28 17:33:55 | INFO | fairseq.trainer | begin training epoch 100
2022-01-28 17:33:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:39:22 | INFO | train_inner | epoch 100:     64 / 64 loss=4.687, ppl=25.76, wps=6053, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=3.924, train_wall=508, gb_free=6.1, wall=35497
2022-01-28 17:39:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:39:50 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 10.949 | ppl 1977.52 | wps 7725 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.393
2022-01-28 17:39:50 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-28 17:39:50 | INFO | train | epoch 100 | loss 4.67 | ppl 25.46 | wps 5882 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 4.082 | train_wall 325 | gb_free 6.1 | wall 35526
KL Stats: Epoch 100 Divergences: Uniform: 2.0987871603282144 Unigram: 38.58530874205757
2022-01-28 17:39:50 | INFO | fairseq.trainer | begin training epoch 101
2022-01-28 17:39:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:45:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:45:46 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 11.731 | ppl 3399.05 | wps 7762 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.393
2022-01-28 17:45:46 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-28 17:45:46 | INFO | train | epoch 101 | loss 4.629 | ppl 24.74 | wps 5868 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 4.208 | train_wall 326 | gb_free 6.1 | wall 35882
KL Stats: Epoch 101 Divergences: Uniform: 2.1293441483141633 Unigram: 39.37344233702936
2022-01-28 17:45:46 | INFO | fairseq.trainer | begin training epoch 102
2022-01-28 17:45:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:48:51 | INFO | train_inner | epoch 102:     36 / 64 loss=4.605, ppl=24.33, wps=5740.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=4.193, train_wall=510, gb_free=6.1, wall=36067
2022-01-28 17:51:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:51:41 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 11.708 | ppl 3344.42 | wps 7878.1 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.393
2022-01-28 17:51:41 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-28 17:51:41 | INFO | train | epoch 102 | loss 4.575 | ppl 23.84 | wps 5875.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 4.29 | train_wall 326 | gb_free 6.1 | wall 36237
KL Stats: Epoch 102 Divergences: Uniform: 2.113531658716113 Unigram: 39.89658856889273
2022-01-28 17:51:41 | INFO | fairseq.trainer | begin training epoch 103
2022-01-28 17:51:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:57:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:57:37 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 11.301 | ppl 2522.48 | wps 7858.4 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.393
2022-01-28 17:57:37 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-28 17:57:37 | INFO | train | epoch 103 | loss 4.53 | ppl 23.1 | wps 5880.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 4.4 | train_wall 326 | gb_free 6.1 | wall 36592
KL Stats: Epoch 103 Divergences: Uniform: 2.126696789576856 Unigram: 40.48962410301618
2022-01-28 17:57:37 | INFO | fairseq.trainer | begin training epoch 104
2022-01-28 17:57:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:58:18 | INFO | train_inner | epoch 104:      8 / 64 loss=4.541, ppl=23.28, wps=5752.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=4.411, train_wall=508, gb_free=6.1, wall=36633
2022-01-28 18:03:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:03:32 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 11.248 | ppl 2432.42 | wps 7856.5 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.393
2022-01-28 18:03:32 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-28 18:03:32 | INFO | train | epoch 104 | loss 4.488 | ppl 22.44 | wps 5874.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 4.339 | train_wall 326 | gb_free 6.1 | wall 36948
KL Stats: Epoch 104 Divergences: Uniform: 2.1033934088637976 Unigram: 41.13796411743706
2022-01-28 18:03:32 | INFO | fairseq.trainer | begin training epoch 105
2022-01-28 18:03:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:07:17 | INFO | train_inner | epoch 105:     44 / 64 loss=4.469, ppl=22.15, wps=6056.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=4.824, train_wall=509, gb_free=6.1, wall=37173
2022-01-28 18:08:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:09:26 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 11.366 | ppl 2639.38 | wps 7875.2 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.393
2022-01-28 18:09:26 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-28 18:09:26 | INFO | train | epoch 105 | loss 4.446 | ppl 21.8 | wps 5899.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 5.191 | train_wall 325 | gb_free 6.1 | wall 37302
KL Stats: Epoch 105 Divergences: Uniform: 2.118493860052577 Unigram: 41.77816504263846
2022-01-28 18:09:26 | INFO | fairseq.trainer | begin training epoch 106
2022-01-28 18:09:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:14:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:15:21 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 11.083 | ppl 2169.1 | wps 7870.2 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.393
2022-01-28 18:15:22 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-28 18:15:22 | INFO | train | epoch 106 | loss 4.394 | ppl 21.03 | wps 5878.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 4.365 | train_wall 326 | gb_free 6.1 | wall 37657
KL Stats: Epoch 106 Divergences: Uniform: 2.0869926669784933 Unigram: 42.3913560317878
2022-01-28 18:15:22 | INFO | fairseq.trainer | begin training epoch 107
2022-01-28 18:15:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:16:43 | INFO | train_inner | epoch 107:     16 / 64 loss=4.401, ppl=21.13, wps=5759.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=4.533, train_wall=508, gb_free=6.1, wall=37739
2022-01-28 18:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:21:15 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 10.942 | ppl 1967.57 | wps 7857.6 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.393
2022-01-28 18:21:15 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-28 18:21:15 | INFO | train | epoch 107 | loss 4.358 | ppl 20.51 | wps 5904.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 5.222 | train_wall 324 | gb_free 6.1 | wall 38011
KL Stats: Epoch 107 Divergences: Uniform: 2.085518271987617 Unigram: 42.96734263914932
2022-01-28 18:21:15 | INFO | fairseq.trainer | begin training epoch 108
2022-01-28 18:21:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:25:41 | INFO | train_inner | epoch 108:     52 / 64 loss=4.335, ppl=20.18, wps=6080, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=5.015, train_wall=507, gb_free=6.1, wall=38277
2022-01-28 18:26:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:27:09 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.157 | ppl 4565.45 | wps 7897 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.393
2022-01-28 18:27:09 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-28 18:27:09 | INFO | train | epoch 108 | loss 4.314 | ppl 19.89 | wps 5909.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 4.806 | train_wall 324 | gb_free 6.1 | wall 38364
KL Stats: Epoch 108 Divergences: Uniform: 2.0914847361898614 Unigram: 43.55971768206086
2022-01-28 18:27:09 | INFO | fairseq.trainer | begin training epoch 109
2022-01-28 18:27:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:32:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:33:03 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.006 | ppl 4113.52 | wps 7871.5 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.393
2022-01-28 18:33:03 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-28 18:33:03 | INFO | train | epoch 109 | loss 4.271 | ppl 19.3 | wps 5894.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 4.898 | train_wall 325 | gb_free 6.1 | wall 38719
KL Stats: Epoch 109 Divergences: Uniform: 2.0827924413676797 Unigram: 44.177121148445956
2022-01-28 18:33:03 | INFO | fairseq.trainer | begin training epoch 110
2022-01-28 18:33:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:35:06 | INFO | train_inner | epoch 110:     24 / 64 loss=4.261, ppl=19.17, wps=5772.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=4.998, train_wall=507, gb_free=6.1, wall=38841
2022-01-28 18:38:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 18:38:57 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 11.423 | ppl 2744.98 | wps 7880.1 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.393
2022-01-28 18:38:57 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-28 18:38:57 | INFO | train | epoch 110 | loss 4.235 | ppl 18.83 | wps 5905.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 4.902 | train_wall 324 | gb_free 6.1 | wall 39072
KL Stats: Epoch 110 Divergences: Uniform: 2.111200121842751 Unigram: 44.70516948471374
2022-01-28 18:38:57 | INFO | fairseq.trainer | begin training epoch 111
2022-01-28 18:38:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:44:03 | INFO | train_inner | epoch 111:     60 / 64 loss=4.218, ppl=18.62, wps=6076.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=4.977, train_wall=507, gb_free=6.1, wall=39379
2022-01-28 18:44:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:44:50 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.088 | ppl 4352.23 | wps 7881.8 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.393
2022-01-28 18:44:50 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-28 18:44:50 | INFO | train | epoch 111 | loss 4.195 | ppl 18.32 | wps 5905.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 5.192 | train_wall 324 | gb_free 6.1 | wall 39426
KL Stats: Epoch 111 Divergences: Uniform: 2.082194986842867 Unigram: 45.31079082937702
2022-01-28 18:44:50 | INFO | fairseq.trainer | begin training epoch 112
2022-01-28 18:44:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:50:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:50:44 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 11.8 | ppl 3565.12 | wps 7872.1 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.393
2022-01-28 18:50:44 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-28 18:50:44 | INFO | train | epoch 112 | loss 4.146 | ppl 17.71 | wps 5905.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 5.406 | train_wall 324 | gb_free 6.1 | wall 39780
KL Stats: Epoch 112 Divergences: Uniform: 2.084780119071788 Unigram: 45.89700287752452
2022-01-28 18:50:44 | INFO | fairseq.trainer | begin training epoch 113
2022-01-28 18:50:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:53:28 | INFO | train_inner | epoch 113:     32 / 64 loss=4.138, ppl=17.6, wps=5773.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=5.177, train_wall=506, gb_free=6.1, wall=39944
2022-01-28 18:56:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:56:38 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 11.547 | ppl 2993.17 | wps 7879.4 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.393
2022-01-28 18:56:38 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-28 18:56:38 | INFO | train | epoch 113 | loss 4.121 | ppl 17.41 | wps 5895.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 4.998 | train_wall 325 | gb_free 6.1 | wall 40134
KL Stats: Epoch 113 Divergences: Uniform: 2.0744942905529307 Unigram: 46.27888720732925
2022-01-28 18:56:38 | INFO | fairseq.trainer | begin training epoch 114
2022-01-28 18:56:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:02:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:02:32 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 13.259 | ppl 9803.76 | wps 7867.2 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.393
2022-01-28 19:02:32 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-28 19:02:32 | INFO | train | epoch 114 | loss 4.072 | ppl 16.82 | wps 5905.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 5.232 | train_wall 324 | gb_free 6.1 | wall 40488
KL Stats: Epoch 114 Divergences: Uniform: 2.098231811180572 Unigram: 47.07896811074275
2022-01-28 19:02:32 | INFO | fairseq.trainer | begin training epoch 115
2022-01-28 19:02:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:02:53 | INFO | train_inner | epoch 115:      4 / 64 loss=4.09, ppl=17.03, wps=5774.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=5.26, train_wall=506, gb_free=6.1, wall=40508
2022-01-28 19:07:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:08:26 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 11.597 | ppl 3096.78 | wps 7883.4 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.393
2022-01-28 19:08:26 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-28 19:08:26 | INFO | train | epoch 115 | loss 4.04 | ppl 16.45 | wps 5901.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 5.745 | train_wall 324 | gb_free 6.1 | wall 40841
KL Stats: Epoch 115 Divergences: Uniform: 2.1010508799732817 Unigram: 47.61884449240477
2022-01-28 19:08:26 | INFO | fairseq.trainer | begin training epoch 116
2022-01-28 19:08:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:11:50 | INFO | train_inner | epoch 116:     40 / 64 loss=4.011, ppl=16.12, wps=6077.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=5.31, train_wall=507, gb_free=6.1, wall=41046
2022-01-28 19:13:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:14:19 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 11.639 | ppl 3188.29 | wps 7871.3 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.393
2022-01-28 19:14:19 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-28 19:14:19 | INFO | train | epoch 116 | loss 3.979 | ppl 15.76 | wps 5909.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 4.937 | train_wall 324 | gb_free 6.1 | wall 41195
KL Stats: Epoch 116 Divergences: Uniform: 2.081297128083068 Unigram: 48.1159865205361
2022-01-28 19:14:19 | INFO | fairseq.trainer | begin training epoch 117
2022-01-28 19:14:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:19:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:20:13 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 11.956 | ppl 3971.77 | wps 7885.3 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.393
2022-01-28 19:20:13 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-28 19:20:13 | INFO | train | epoch 117 | loss 3.965 | ppl 15.62 | wps 5908.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 5.655 | train_wall 324 | gb_free 6.1 | wall 41548
KL Stats: Epoch 117 Divergences: Uniform: 2.070653998687751 Unigram: 48.64233806489893
2022-01-28 19:20:13 | INFO | fairseq.trainer | begin training epoch 118
2022-01-28 19:20:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:21:14 | INFO | train_inner | epoch 118:     12 / 64 loss=3.967, ppl=15.63, wps=5781, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=5.637, train_wall=506, gb_free=6.1, wall=41610
2022-01-28 19:25:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 19:26:06 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 11.229 | ppl 2400.44 | wps 7888.3 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.393
2022-01-28 19:26:06 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-28 19:26:06 | INFO | train | epoch 118 | loss 3.927 | ppl 15.21 | wps 5906.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 5.869 | train_wall 324 | gb_free 6.1 | wall 41902
KL Stats: Epoch 118 Divergences: Uniform: 2.06362997347971 Unigram: 48.98484048788356
2022-01-28 19:26:06 | INFO | fairseq.trainer | begin training epoch 119
2022-01-28 19:26:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:30:13 | INFO | train_inner | epoch 119:     48 / 64 loss=3.899, ppl=14.92, wps=6067.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=5.695, train_wall=508, gb_free=6.1, wall=42148
2022-01-28 19:31:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 19:32:01 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 11.722 | ppl 3378.19 | wps 7865 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.393
2022-01-28 19:32:01 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-28 19:32:01 | INFO | train | epoch 119 | loss 3.88 | ppl 14.72 | wps 5887.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 5.805 | train_wall 325 | gb_free 6.1 | wall 42257
KL Stats: Epoch 119 Divergences: Uniform: 2.084495594593561 Unigram: 49.78994824459856
2022-01-28 19:32:01 | INFO | fairseq.trainer | begin training epoch 120
2022-01-28 19:32:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:37:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:37:55 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 11.752 | ppl 3448.49 | wps 7883 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.393
2022-01-28 19:37:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-28 19:37:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint120.pt
2022-01-28 19:37:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint120.pt
2022-01-28 19:37:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint120.pt (epoch 120 @ 7680 updates, score 11.752) (writing took 3.2266736272722483 seconds)
2022-01-28 19:37:58 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-28 19:37:58 | INFO | train | epoch 120 | loss 3.839 | ppl 14.31 | wps 5854.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 5.819 | train_wall 324 | gb_free 6.1 | wall 42613
KL Stats: Epoch 120 Divergences: Uniform: 2.0789138295097027 Unigram: 50.35425203935443
2022-01-28 19:37:58 | INFO | fairseq.trainer | begin training epoch 121
2022-01-28 19:37:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:39:41 | INFO | train_inner | epoch 121:     20 / 64 loss=3.843, ppl=14.35, wps=5741.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=6.147, train_wall=506, gb_free=6.1, wall=42716
2022-01-28 19:43:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:43:53 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 12.366 | ppl 5279.4 | wps 7862.3 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.393
2022-01-28 19:43:53 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-28 19:43:53 | INFO | train | epoch 121 | loss 3.81 | ppl 14.03 | wps 5884.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 6.011 | train_wall 325 | gb_free 6.1 | wall 42968
KL Stats: Epoch 121 Divergences: Uniform: 2.088972245435211 Unigram: 50.885959383121765
2022-01-28 19:43:53 | INFO | fairseq.trainer | begin training epoch 122
2022-01-28 19:43:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:48:39 | INFO | train_inner | epoch 122:     56 / 64 loss=3.783, ppl=13.77, wps=6067, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=5.83, train_wall=508, gb_free=6.1, wall=43255
2022-01-28 19:49:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:49:47 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 11.059 | ppl 2134.06 | wps 7873.4 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.393
2022-01-28 19:49:47 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-28 19:49:47 | INFO | train | epoch 122 | loss 3.764 | ppl 13.58 | wps 5903 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 6.099 | train_wall 324 | gb_free 6.1 | wall 43322
KL Stats: Epoch 122 Divergences: Uniform: 2.0752738013142644 Unigram: 51.1887469132953
2022-01-28 19:49:47 | INFO | fairseq.trainer | begin training epoch 123
2022-01-28 19:49:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:55:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 19:55:41 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 11.757 | ppl 3460.41 | wps 7860.1 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.393
2022-01-28 19:55:41 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-28 19:55:41 | INFO | train | epoch 123 | loss 3.747 | ppl 13.42 | wps 5890.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 6.288 | train_wall 325 | gb_free 6.1 | wall 43677
KL Stats: Epoch 123 Divergences: Uniform: 2.0960516449191333 Unigram: 51.74042594967236
2022-01-28 19:55:41 | INFO | fairseq.trainer | begin training epoch 124
2022-01-28 19:55:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:58:04 | INFO | train_inner | epoch 124:     28 / 64 loss=3.73, ppl=13.27, wps=5769.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=6.352, train_wall=507, gb_free=6.1, wall=43820
2022-01-28 20:01:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:01:35 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 11.739 | ppl 3418.97 | wps 7876.3 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.393
2022-01-28 20:01:35 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-28 20:01:35 | INFO | train | epoch 124 | loss 3.684 | ppl 12.85 | wps 5909.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 6.171 | train_wall 324 | gb_free 6.1 | wall 44030
KL Stats: Epoch 124 Divergences: Uniform: 2.0702576127202574 Unigram: 52.439827552859754
2022-01-28 20:01:35 | INFO | fairseq.trainer | begin training epoch 125
2022-01-28 20:01:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:07:01 | INFO | train_inner | epoch 125:     64 / 64 loss=3.685, ppl=12.86, wps=6078.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=6.781, train_wall=506, gb_free=6.1, wall=44356
2022-01-28 20:07:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 20:07:28 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 11.838 | ppl 3660.64 | wps 7876.8 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.393
2022-01-28 20:07:28 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-28 20:07:28 | INFO | train | epoch 125 | loss 3.679 | ppl 12.8 | wps 5905.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 7.182 | train_wall 324 | gb_free 6.1 | wall 44384
KL Stats: Epoch 125 Divergences: Uniform: 2.084529935228946 Unigram: 52.836055266291
2022-01-28 20:07:28 | INFO | fairseq.trainer | begin training epoch 126
2022-01-28 20:07:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:12:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:13:23 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 11.488 | ppl 2872.37 | wps 7883.6 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.393
2022-01-28 20:13:23 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-28 20:13:23 | INFO | train | epoch 126 | loss 3.629 | ppl 12.37 | wps 5890.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 5.755 | train_wall 325 | gb_free 6.1 | wall 44738
KL Stats: Epoch 126 Divergences: Uniform: 2.0641235047004725 Unigram: 53.28530404962437
2022-01-28 20:13:23 | INFO | fairseq.trainer | begin training epoch 127
2022-01-28 20:13:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:16:28 | INFO | train_inner | epoch 127:     36 / 64 loss=3.616, ppl=12.26, wps=5763.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=6.165, train_wall=509, gb_free=6.1, wall=44923
2022-01-28 20:18:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:19:17 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 12.183 | ppl 4651.53 | wps 7858.6 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.393
2022-01-28 20:19:17 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-28 20:19:17 | INFO | train | epoch 127 | loss 3.59 | ppl 12.04 | wps 5891.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 6.936 | train_wall 325 | gb_free 6.1 | wall 45093
KL Stats: Epoch 127 Divergences: Uniform: 2.0674527063932726 Unigram: 54.022629593511816
2022-01-28 20:19:17 | INFO | fairseq.trainer | begin training epoch 128
2022-01-28 20:19:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:24:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:25:12 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 11.888 | ppl 3790.67 | wps 7856.1 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.393
2022-01-28 20:25:12 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-28 20:25:12 | INFO | train | epoch 128 | loss 3.554 | ppl 11.75 | wps 5893.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 6.368 | train_wall 325 | gb_free 6.1 | wall 45447
KL Stats: Epoch 128 Divergences: Uniform: 2.064128553396429 Unigram: 54.47077969154463
2022-01-28 20:25:12 | INFO | fairseq.trainer | begin training epoch 129
2022-01-28 20:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:25:53 | INFO | train_inner | epoch 129:      8 / 64 loss=3.56, ppl=11.79, wps=5766.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=6.418, train_wall=507, gb_free=6.1, wall=45488
2022-01-28 20:30:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 20:31:07 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 11.378 | ppl 2661.69 | wps 7849.7 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.393
2022-01-28 20:31:07 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-28 20:31:07 | INFO | train | epoch 129 | loss 3.543 | ppl 11.66 | wps 5880.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 6.978 | train_wall 326 | gb_free 6.1 | wall 45803
KL Stats: Epoch 129 Divergences: Uniform: 2.0711980904148675 Unigram: 54.80663765857763
2022-01-28 20:31:07 | INFO | fairseq.trainer | begin training epoch 130
2022-01-28 20:31:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:34:52 | INFO | train_inner | epoch 130:     44 / 64 loss=3.512, ppl=11.41, wps=6058.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=7.044, train_wall=509, gb_free=6.1, wall=46028
2022-01-28 20:36:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:37:01 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 12.129 | ppl 4480.18 | wps 7899.5 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.393
2022-01-28 20:37:01 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-28 20:37:01 | INFO | train | epoch 130 | loss 3.493 | ppl 11.26 | wps 5898 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 6.842 | train_wall 325 | gb_free 6.1 | wall 46157
KL Stats: Epoch 130 Divergences: Uniform: 2.0693254214734225 Unigram: 55.403557993706414
2022-01-28 20:37:01 | INFO | fairseq.trainer | begin training epoch 131
2022-01-28 20:37:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:42:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:42:56 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 11.773 | ppl 3500.64 | wps 7859.8 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.393
2022-01-28 20:42:56 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-28 20:42:56 | INFO | train | epoch 131 | loss 3.464 | ppl 11.04 | wps 5891.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 7.074 | train_wall 325 | gb_free 6.1 | wall 46511
KL Stats: Epoch 131 Divergences: Uniform: 2.0886855389984036 Unigram: 55.785031104902664
2022-01-28 20:42:56 | INFO | fairseq.trainer | begin training epoch 132
2022-01-28 20:42:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:44:18 | INFO | train_inner | epoch 132:     16 / 64 loss=3.466, ppl=11.05, wps=5765.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=7.021, train_wall=507, gb_free=6.1, wall=46593
2022-01-28 20:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:48:50 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 11.637 | ppl 3185.92 | wps 7899.3 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.393
2022-01-28 20:48:50 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-28 20:48:50 | INFO | train | epoch 132 | loss 3.421 | ppl 10.71 | wps 5893.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 6.987 | train_wall 325 | gb_free 6.1 | wall 46866
KL Stats: Epoch 132 Divergences: Uniform: 2.0641543701178646 Unigram: 56.285383743441905
2022-01-28 20:48:50 | INFO | fairseq.trainer | begin training epoch 133
2022-01-28 20:48:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:53:16 | INFO | train_inner | epoch 133:     52 / 64 loss=3.404, ppl=10.59, wps=6070.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=6.836, train_wall=508, gb_free=6.1, wall=47132
2022-01-28 20:54:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:54:44 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 11.99 | ppl 4067.35 | wps 7871.1 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.393
2022-01-28 20:54:44 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-28 20:54:44 | INFO | train | epoch 133 | loss 3.392 | ppl 10.5 | wps 5898.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 7.343 | train_wall 325 | gb_free 6.1 | wall 47220
KL Stats: Epoch 133 Divergences: Uniform: 2.0892160937778694 Unigram: 56.87893254821479
2022-01-28 20:54:44 | INFO | fairseq.trainer | begin training epoch 134
2022-01-28 20:54:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:00:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:00:38 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 12.013 | ppl 4133.19 | wps 7883.4 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.393
2022-01-28 21:00:38 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-28 21:00:38 | INFO | train | epoch 134 | loss 3.358 | ppl 10.25 | wps 5900.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 6.912 | train_wall 325 | gb_free 6.1 | wall 47574
KL Stats: Epoch 134 Divergences: Uniform: 2.037601053370828 Unigram: 57.276527557169864
2022-01-28 21:00:38 | INFO | fairseq.trainer | begin training epoch 135
2022-01-28 21:00:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:02:41 | INFO | train_inner | epoch 135:     24 / 64 loss=3.37, ppl=10.34, wps=5769.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=7.283, train_wall=507, gb_free=6.1, wall=47697
2022-01-28 21:06:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 21:06:32 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 11.029 | ppl 2089.18 | wps 7871.1 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.393
2022-01-28 21:06:32 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-28 21:06:32 | INFO | train | epoch 135 | loss 3.352 | ppl 10.21 | wps 5899.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 7.91 | train_wall 325 | gb_free 6.1 | wall 47928
KL Stats: Epoch 135 Divergences: Uniform: 2.0652595912410163 Unigram: 57.64678610688678
2022-01-28 21:06:32 | INFO | fairseq.trainer | begin training epoch 136
2022-01-28 21:06:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:11:39 | INFO | train_inner | epoch 136:     60 / 64 loss=3.312, ppl=9.93, wps=6072, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=7.422, train_wall=508, gb_free=6.1, wall=48235
2022-01-28 21:11:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:12:26 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 11.396 | ppl 2693.97 | wps 7868.4 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.393
2022-01-28 21:12:26 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-28 21:12:26 | INFO | train | epoch 136 | loss 3.285 | ppl 9.75 | wps 5897.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 6.604 | train_wall 325 | gb_free 6.1 | wall 48282
KL Stats: Epoch 136 Divergences: Uniform: 2.056843513813857 Unigram: 58.27927608295276
2022-01-28 21:12:26 | INFO | fairseq.trainer | begin training epoch 137
2022-01-28 21:12:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:17:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:18:20 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.869 | ppl 1870.36 | wps 7888.1 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.393
2022-01-28 21:18:20 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-28 21:18:20 | INFO | train | epoch 137 | loss 3.27 | ppl 9.65 | wps 5897.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 7.607 | train_wall 325 | gb_free 6.1 | wall 48636
KL Stats: Epoch 137 Divergences: Uniform: 2.0263017071547424 Unigram: 58.58711824785377
2022-01-28 21:18:20 | INFO | fairseq.trainer | begin training epoch 138
2022-01-28 21:18:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:21:05 | INFO | train_inner | epoch 138:     32 / 64 loss=3.251, ppl=9.52, wps=5766.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=7.604, train_wall=507, gb_free=6.1, wall=48800
2022-01-28 21:23:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:24:15 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 12.298 | ppl 5034.68 | wps 7877.7 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.393
2022-01-28 21:24:15 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-28 21:24:15 | INFO | train | epoch 138 | loss 3.227 | ppl 9.36 | wps 5889.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 7.388 | train_wall 325 | gb_free 6.1 | wall 48991
KL Stats: Epoch 138 Divergences: Uniform: 2.045963727681837 Unigram: 59.23155609279858
2022-01-28 21:24:15 | INFO | fairseq.trainer | begin training epoch 139
2022-01-28 21:24:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:29:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:30:09 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 11.616 | ppl 3138.37 | wps 7853 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.393
2022-01-28 21:30:09 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-28 21:30:09 | INFO | train | epoch 139 | loss 3.19 | ppl 9.12 | wps 5895 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 8.266 | train_wall 325 | gb_free 6.1 | wall 49345
KL Stats: Epoch 139 Divergences: Uniform: 2.0601457638365925 Unigram: 59.797442399391954
2022-01-28 21:30:09 | INFO | fairseq.trainer | begin training epoch 140
2022-01-28 21:30:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:30:30 | INFO | train_inner | epoch 140:      4 / 64 loss=3.206, ppl=9.23, wps=5766.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=7.919, train_wall=507, gb_free=6.1, wall=49365
2022-01-28 21:35:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 21:36:04 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 11.514 | ppl 2924.93 | wps 7866 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.393
2022-01-28 21:36:04 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-28 21:36:04 | INFO | train | epoch 140 | loss 3.193 | ppl 9.15 | wps 5895.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 7.96 | train_wall 325 | gb_free 6.1 | wall 49699
KL Stats: Epoch 140 Divergences: Uniform: 2.0104094298744117 Unigram: 60.07395936413125
2022-01-28 21:36:04 | INFO | fairseq.trainer | begin training epoch 141
2022-01-28 21:36:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:39:28 | INFO | train_inner | epoch 141:     40 / 64 loss=3.177, ppl=9.04, wps=6068.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=7.915, train_wall=508, gb_free=6.1, wall=49904
2022-01-28 21:41:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 21:41:58 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 11.115 | ppl 2217.56 | wps 7872.7 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.393
2022-01-28 21:41:58 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-28 21:41:58 | INFO | train | epoch 141 | loss 3.152 | ppl 8.89 | wps 5902.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 7.538 | train_wall 324 | gb_free 6.1 | wall 50053
KL Stats: Epoch 141 Divergences: Uniform: 2.0369038612536734 Unigram: 60.45356106408903
2022-01-28 21:41:58 | INFO | fairseq.trainer | begin training epoch 142
2022-01-28 21:41:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:47:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:47:52 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 12.035 | ppl 4197.06 | wps 7881.1 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.393
2022-01-28 21:47:52 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-28 21:47:52 | INFO | train | epoch 142 | loss 3.111 | ppl 8.64 | wps 5897 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 8.253 | train_wall 325 | gb_free 6.1 | wall 50407
KL Stats: Epoch 142 Divergences: Uniform: 2.02289614918705 Unigram: 61.08004875200037
2022-01-28 21:47:52 | INFO | fairseq.trainer | begin training epoch 143
2022-01-28 21:47:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:48:53 | INFO | train_inner | epoch 143:     12 / 64 loss=3.115, ppl=8.66, wps=5773, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=7.642, train_wall=507, gb_free=6.1, wall=50469
2022-01-28 21:53:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:53:46 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 12.085 | ppl 4343.56 | wps 7876 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.393
2022-01-28 21:53:46 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-28 21:53:46 | INFO | train | epoch 143 | loss 3.091 | ppl 8.52 | wps 5892.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 7.858 | train_wall 325 | gb_free 6.1 | wall 50762
KL Stats: Epoch 143 Divergences: Uniform: 2.04392122206453 Unigram: 61.48634537833561
2022-01-28 21:53:46 | INFO | fairseq.trainer | begin training epoch 144
2022-01-28 21:53:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:57:52 | INFO | train_inner | epoch 144:     48 / 64 loss=3.076, ppl=8.43, wps=6068.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=8.019, train_wall=508, gb_free=6.1, wall=51007
2022-01-28 21:59:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:59:40 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 12.271 | ppl 4943.77 | wps 7855 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.393
2022-01-28 21:59:40 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-28 21:59:40 | INFO | train | epoch 144 | loss 3.051 | ppl 8.29 | wps 5903 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 8.502 | train_wall 324 | gb_free 6.1 | wall 51116
KL Stats: Epoch 144 Divergences: Uniform: 2.052024759190166 Unigram: 62.012897764054394
2022-01-28 21:59:40 | INFO | fairseq.trainer | begin training epoch 145
2022-01-28 21:59:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:05:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:05:35 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.643 | ppl 1599.33 | wps 7865.4 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.393
2022-01-28 22:05:35 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-28 22:05:35 | INFO | train | epoch 145 | loss 3.05 | ppl 8.28 | wps 5886.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 7.844 | train_wall 325 | gb_free 6.1 | wall 51470
KL Stats: Epoch 145 Divergences: Uniform: 2.0196294032146387 Unigram: 62.187409232893465
2022-01-28 22:05:35 | INFO | fairseq.trainer | begin training epoch 146
2022-01-28 22:05:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:07:17 | INFO | train_inner | epoch 146:     20 / 64 loss=3.034, ppl=8.19, wps=5762.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=8.499, train_wall=507, gb_free=6.1, wall=51573
2022-01-28 22:11:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:11:29 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 11.833 | ppl 3647.09 | wps 7874.8 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.393
2022-01-28 22:11:29 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-28 22:11:29 | INFO | train | epoch 146 | loss 2.989 | ppl 7.94 | wps 5901 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 8.276 | train_wall 325 | gb_free 6.1 | wall 51824
KL Stats: Epoch 146 Divergences: Uniform: 2.0577376420054496 Unigram: 62.92273401293393
2022-01-28 22:11:29 | INFO | fairseq.trainer | begin training epoch 147
2022-01-28 22:11:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:16:15 | INFO | train_inner | epoch 147:     56 / 64 loss=2.995, ppl=7.97, wps=6078.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=8.542, train_wall=507, gb_free=6.1, wall=52111
2022-01-28 22:16:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:17:22 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 11.935 | ppl 3914.47 | wps 7877.3 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.393
2022-01-28 22:17:22 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-28 22:17:22 | INFO | train | epoch 147 | loss 2.986 | ppl 7.92 | wps 5907.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 8.723 | train_wall 324 | gb_free 6.1 | wall 52178
KL Stats: Epoch 147 Divergences: Uniform: 2.0306442082325087 Unigram: 63.19390339519096
2022-01-28 22:17:22 | INFO | fairseq.trainer | begin training epoch 148
2022-01-28 22:17:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:22:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:23:16 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 11.636 | ppl 3182.51 | wps 7861.1 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.393
2022-01-28 22:23:16 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-28 22:23:16 | INFO | train | epoch 148 | loss 2.942 | ppl 7.69 | wps 5899.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 8.628 | train_wall 325 | gb_free 6.1 | wall 52532
KL Stats: Epoch 148 Divergences: Uniform: 2.0296187070650995 Unigram: 63.69854337080182
2022-01-28 22:23:16 | INFO | fairseq.trainer | begin training epoch 149
2022-01-28 22:23:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:25:40 | INFO | train_inner | epoch 149:     28 / 64 loss=2.947, ppl=7.71, wps=5771.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=8.622, train_wall=507, gb_free=6.1, wall=52675
2022-01-28 22:28:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:29:11 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 11.736 | ppl 3409.87 | wps 7859.4 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.393
2022-01-28 22:29:11 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-28 22:29:11 | INFO | train | epoch 149 | loss 2.939 | ppl 7.67 | wps 5892.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 8.519 | train_wall 325 | gb_free 6.1 | wall 52886
KL Stats: Epoch 149 Divergences: Uniform: 2.0063281440226914 Unigram: 63.81361263866061
2022-01-28 22:29:11 | INFO | fairseq.trainer | begin training epoch 150
2022-01-28 22:29:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:34:37 | INFO | train_inner | epoch 150:     64 / 64 loss=2.898, ppl=7.45, wps=6068.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=8.967, train_wall=507, gb_free=6.1, wall=53213
2022-01-28 22:34:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:35:05 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.904 | ppl 1916.53 | wps 7858.3 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.393
2022-01-28 22:35:05 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-28 22:35:05 | INFO | train | epoch 150 | loss 2.882 | ppl 7.37 | wps 5899.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 9.426 | train_wall 325 | gb_free 6.1 | wall 53240
KL Stats: Epoch 150 Divergences: Uniform: 2.047718772452194 Unigram: 64.54590057427228
2022-01-28 22:35:05 | INFO | fairseq.trainer | begin training epoch 151
2022-01-28 22:35:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:40:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:41:00 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 11.054 | ppl 2126.72 | wps 7859.4 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.393
2022-01-28 22:41:00 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-28 22:41:00 | INFO | train | epoch 151 | loss 2.85 | ppl 7.21 | wps 5875.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 8.234 | train_wall 326 | gb_free 6.1 | wall 53596
KL Stats: Epoch 151 Divergences: Uniform: 2.0045656338830127 Unigram: 64.79497279181143
2022-01-28 22:41:00 | INFO | fairseq.trainer | begin training epoch 152
2022-01-28 22:41:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:44:05 | INFO | train_inner | epoch 152:     36 / 64 loss=2.832, ppl=7.12, wps=5753.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=8.691, train_wall=510, gb_free=6.1, wall=53780
2022-01-28 22:46:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 22:46:55 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 11.853 | ppl 3700.02 | wps 7868.2 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.393
2022-01-28 22:46:55 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-28 22:46:55 | INFO | train | epoch 152 | loss 2.828 | ppl 7.1 | wps 5891.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 9.096 | train_wall 325 | gb_free 6.1 | wall 53950
KL Stats: Epoch 152 Divergences: Uniform: 2.0273300608792835 Unigram: 65.38442662319923
2022-01-28 22:46:55 | INFO | fairseq.trainer | begin training epoch 153
2022-01-28 22:46:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:52:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:52:49 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 12.428 | ppl 5511.09 | wps 7861.7 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.393
2022-01-28 22:52:49 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-01-28 22:52:49 | INFO | train | epoch 153 | loss 2.801 | ppl 6.97 | wps 5891.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 10.034 | train_wall 325 | gb_free 6.1 | wall 54305
KL Stats: Epoch 153 Divergences: Uniform: 2.036672811639399 Unigram: 65.77652247090684
2022-01-28 22:52:49 | INFO | fairseq.trainer | begin training epoch 154
2022-01-28 22:52:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:53:30 | INFO | train_inner | epoch 154:      8 / 64 loss=2.813, ppl=7.03, wps=5765.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=9.504, train_wall=507, gb_free=6.1, wall=54346
2022-01-28 22:58:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 22:58:44 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 11.589 | ppl 3081.37 | wps 7871.3 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.393
2022-01-28 22:58:44 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-01-28 22:58:44 | INFO | train | epoch 154 | loss 2.753 | ppl 6.74 | wps 5896.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 8.29 | train_wall 325 | gb_free 6.1 | wall 54659
KL Stats: Epoch 154 Divergences: Uniform: 2.003886676501339 Unigram: 66.37875457303132
2022-01-28 22:58:44 | INFO | fairseq.trainer | begin training epoch 155
2022-01-28 22:58:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:02:29 | INFO | train_inner | epoch 155:     44 / 64 loss=2.755, ppl=6.75, wps=6069.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=8.919, train_wall=508, gb_free=6.1, wall=54884
2022-01-28 23:04:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:04:38 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 11.29 | ppl 2503.89 | wps 7886.2 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.393
2022-01-28 23:04:38 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-01-28 23:04:38 | INFO | train | epoch 155 | loss 2.746 | ppl 6.71 | wps 5895 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 9.371 | train_wall 325 | gb_free 6.1 | wall 55013
KL Stats: Epoch 155 Divergences: Uniform: 2.0152400222504028 Unigram: 66.49397874164201
2022-01-28 23:04:38 | INFO | fairseq.trainer | begin training epoch 156
2022-01-28 23:04:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:10:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:10:32 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 11.74 | ppl 3421.2 | wps 7871 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.393
2022-01-28 23:10:32 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-01-28 23:10:32 | INFO | train | epoch 156 | loss 2.72 | ppl 6.59 | wps 5896.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 9.268 | train_wall 325 | gb_free 6.1 | wall 55368
KL Stats: Epoch 156 Divergences: Uniform: 1.9776531351549171 Unigram: 66.98756043306733
2022-01-28 23:10:32 | INFO | fairseq.trainer | begin training epoch 157
2022-01-28 23:10:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:11:54 | INFO | train_inner | epoch 157:     16 / 64 loss=2.72, ppl=6.59, wps=5770, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=9.579, train_wall=507, gb_free=6.1, wall=55449
2022-01-28 23:15:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:16:26 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.803 | ppl 1786.93 | wps 7887.7 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.393
2022-01-28 23:16:26 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-01-28 23:16:26 | INFO | train | epoch 157 | loss 2.716 | ppl 6.57 | wps 5897.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 10.01 | train_wall 325 | gb_free 6.1 | wall 55722
KL Stats: Epoch 157 Divergences: Uniform: 2.0077074516946563 Unigram: 67.19800136208904
2022-01-28 23:16:26 | INFO | fairseq.trainer | begin training epoch 158
2022-01-28 23:16:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:20:53 | INFO | train_inner | epoch 158:     52 / 64 loss=2.687, ppl=6.44, wps=6066, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=9.639, train_wall=508, gb_free=6.1, wall=55988
2022-01-28 23:21:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 23:22:21 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 12.094 | ppl 4370.45 | wps 7854.6 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.393
2022-01-28 23:22:21 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-01-28 23:22:21 | INFO | train | epoch 158 | loss 2.664 | ppl 6.34 | wps 5892.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 10.007 | train_wall 325 | gb_free 6.1 | wall 56076
KL Stats: Epoch 158 Divergences: Uniform: 2.0094398080747076 Unigram: 67.7838815146428
2022-01-28 23:22:21 | INFO | fairseq.trainer | begin training epoch 159
2022-01-28 23:22:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:27:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:28:16 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 11.746 | ppl 3434.55 | wps 7849.1 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.393
2022-01-28 23:28:16 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-01-28 23:28:16 | INFO | train | epoch 159 | loss 2.658 | ppl 6.31 | wps 5885.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 10.549 | train_wall 325 | gb_free 6.1 | wall 56431
KL Stats: Epoch 159 Divergences: Uniform: 1.9843028228758073 Unigram: 68.13382360642082
2022-01-28 23:28:16 | INFO | fairseq.trainer | begin training epoch 160
2022-01-28 23:28:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:30:18 | INFO | train_inner | epoch 160:     24 / 64 loss=2.651, ppl=6.28, wps=5761.6, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=10.508, train_wall=507, gb_free=6.1, wall=56554
2022-01-28 23:33:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:34:10 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 12.035 | ppl 4196.97 | wps 7869 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.393
2022-01-28 23:34:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-01-28 23:34:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint160.pt
2022-01-28 23:34:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint160.pt
2022-01-28 23:34:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint160.pt (epoch 160 @ 10240 updates, score 12.035) (writing took 3.0960931656882167 seconds)
2022-01-28 23:34:13 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-01-28 23:34:13 | INFO | train | epoch 160 | loss 2.644 | ppl 6.25 | wps 5842.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 9.973 | train_wall 325 | gb_free 6.1 | wall 56789
KL Stats: Epoch 160 Divergences: Uniform: 1.9823282556538047 Unigram: 68.29896419438795
2022-01-28 23:34:13 | INFO | fairseq.trainer | begin training epoch 161
2022-01-28 23:34:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:39:20 | INFO | train_inner | epoch 161:     60 / 64 loss=2.622, ppl=6.16, wps=6032.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=9.688, train_wall=508, gb_free=6.1, wall=57096
2022-01-28 23:39:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:40:07 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.885 | ppl 1891.04 | wps 7874.1 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.393
2022-01-28 23:40:07 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-01-28 23:40:07 | INFO | train | epoch 161 | loss 2.6 | ppl 6.06 | wps 5899.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 10.089 | train_wall 325 | gb_free 6.1 | wall 57143
KL Stats: Epoch 161 Divergences: Uniform: 1.9856394482251543 Unigram: 68.8146656813539
2022-01-28 23:40:07 | INFO | fairseq.trainer | begin training epoch 162
2022-01-28 23:40:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:45:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:46:02 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 11.646 | ppl 3204.18 | wps 7874.8 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.393
2022-01-28 23:46:02 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-01-28 23:46:02 | INFO | train | epoch 162 | loss 2.566 | ppl 5.92 | wps 5891.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 10.264 | train_wall 325 | gb_free 6.1 | wall 57497
KL Stats: Epoch 162 Divergences: Uniform: 1.9949077450853425 Unigram: 69.28372589598959
2022-01-28 23:46:02 | INFO | fairseq.trainer | begin training epoch 163
2022-01-28 23:46:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:48:45 | INFO | train_inner | epoch 163:     32 / 64 loss=2.548, ppl=5.85, wps=5768.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=10.597, train_wall=507, gb_free=6.1, wall=57661
2022-01-28 23:51:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-28 23:51:56 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 11.007 | ppl 2057.88 | wps 7887.7 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.393
2022-01-28 23:51:56 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-01-28 23:51:56 | INFO | train | epoch 163 | loss 2.52 | ppl 5.74 | wps 5898.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 10.288 | train_wall 325 | gb_free 6.1 | wall 57851
KL Stats: Epoch 163 Divergences: Uniform: 1.972651523322568 Unigram: 69.68555097922821
2022-01-28 23:51:56 | INFO | fairseq.trainer | begin training epoch 164
2022-01-28 23:51:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:57:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:57:50 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 11.801 | ppl 3567.4 | wps 7860.3 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.393
2022-01-28 23:57:50 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-01-28 23:57:50 | INFO | train | epoch 164 | loss 2.549 | ppl 5.85 | wps 5895.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 10.936 | train_wall 325 | gb_free 6.1 | wall 58205
KL Stats: Epoch 164 Divergences: Uniform: 1.9710736586896251 Unigram: 69.8773591117334
2022-01-28 23:57:50 | INFO | fairseq.trainer | begin training epoch 165
2022-01-28 23:57:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:58:10 | INFO | train_inner | epoch 165:      4 / 64 loss=2.544, ppl=5.83, wps=5768.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=10.519, train_wall=507, gb_free=6.1, wall=58226
2022-01-29 00:03:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:03:44 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 11.579 | ppl 3059.35 | wps 7879.8 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.393
2022-01-29 00:03:44 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-01-29 00:03:44 | INFO | train | epoch 165 | loss 2.509 | ppl 5.69 | wps 5890.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 10.449 | train_wall 325 | gb_free 6.1 | wall 58560
KL Stats: Epoch 165 Divergences: Uniform: 1.9863911850739202 Unigram: 70.20914588924836
2022-01-29 00:03:44 | INFO | fairseq.trainer | begin training epoch 166
2022-01-29 00:03:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:07:09 | INFO | train_inner | epoch 166:     40 / 64 loss=2.51, ppl=5.69, wps=6063.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=11.036, train_wall=509, gb_free=6.1, wall=58765
2022-01-29 00:09:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:09:39 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 11.565 | ppl 3030.07 | wps 7858.9 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.393
2022-01-29 00:09:39 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-01-29 00:09:39 | INFO | train | epoch 166 | loss 2.521 | ppl 5.74 | wps 5892.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 11.421 | train_wall 325 | gb_free 6.1 | wall 58914
KL Stats: Epoch 166 Divergences: Uniform: 2.010168293767964 Unigram: 70.45718612704762
2022-01-29 00:09:39 | INFO | fairseq.trainer | begin training epoch 167
2022-01-29 00:09:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:15:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:15:34 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.341 | ppl 1297.15 | wps 7861.5 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.393
2022-01-29 00:15:34 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-01-29 00:15:34 | INFO | train | epoch 167 | loss 2.484 | ppl 5.59 | wps 5886.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 10.624 | train_wall 325 | gb_free 6.1 | wall 59269
KL Stats: Epoch 167 Divergences: Uniform: 1.9847853656773877 Unigram: 70.74661921650582
2022-01-29 00:15:34 | INFO | fairseq.trainer | begin training epoch 168
2022-01-29 00:15:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:16:35 | INFO | train_inner | epoch 168:     12 / 64 loss=2.488, ppl=5.61, wps=5761.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=10.818, train_wall=508, gb_free=6.1, wall=59331
2022-01-29 00:21:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-29 00:21:28 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.922 | ppl 1940.86 | wps 7862.1 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.393
2022-01-29 00:21:28 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-01-29 00:21:28 | INFO | train | epoch 168 | loss 2.419 | ppl 5.35 | wps 5898.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 10.737 | train_wall 325 | gb_free 6.1 | wall 59623
KL Stats: Epoch 168 Divergences: Uniform: 1.9681552205676245 Unigram: 71.3572497750937
2022-01-29 00:21:28 | INFO | fairseq.trainer | begin training epoch 169
2022-01-29 00:21:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:25:34 | INFO | train_inner | epoch 169:     48 / 64 loss=2.417, ppl=5.34, wps=6067.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=10.726, train_wall=508, gb_free=6.1, wall=59869
2022-01-29 00:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-29 00:27:22 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 11.551 | ppl 3000.05 | wps 7871.5 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.393
2022-01-29 00:27:22 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-01-29 00:27:22 | INFO | train | epoch 169 | loss 2.42 | ppl 5.35 | wps 5893.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 11.264 | train_wall 325 | gb_free 6.1 | wall 59978
KL Stats: Epoch 169 Divergences: Uniform: 1.9819675458043722 Unigram: 71.6053230228077
2022-01-29 00:27:22 | INFO | fairseq.trainer | begin training epoch 170
2022-01-29 00:27:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:32:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:33:17 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 12.395 | ppl 5386.23 | wps 7865.2 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.393
2022-01-29 00:33:17 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-01-29 00:33:17 | INFO | train | epoch 170 | loss 2.405 | ppl 5.3 | wps 5890.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 11.163 | train_wall 325 | gb_free 6.1 | wall 60332
KL Stats: Epoch 170 Divergences: Uniform: 1.9955580287438945 Unigram: 71.86275793381178
2022-01-29 00:33:17 | INFO | fairseq.trainer | begin training epoch 171
2022-01-29 00:33:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:34:59 | INFO | train_inner | epoch 171:     20 / 64 loss=2.402, ppl=5.28, wps=5764.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=11.372, train_wall=507, gb_free=6.1, wall=60435
2022-01-29 00:38:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:39:11 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 11.744 | ppl 3429.55 | wps 7853.7 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.393
2022-01-29 00:39:11 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-01-29 00:39:11 | INFO | train | epoch 171 | loss 2.372 | ppl 5.18 | wps 5892.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 10.915 | train_wall 325 | gb_free 6.1 | wall 60687
KL Stats: Epoch 171 Divergences: Uniform: 1.9559668251211995 Unigram: 72.32631864518099
2022-01-29 00:39:11 | INFO | fairseq.trainer | begin training epoch 172
2022-01-29 00:39:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:43:58 | INFO | train_inner | epoch 172:     56 / 64 loss=2.354, ppl=5.11, wps=6067.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=11.021, train_wall=508, gb_free=6.1, wall=60974
2022-01-29 00:44:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:45:05 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 11.077 | ppl 2159.68 | wps 7893.9 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.393
2022-01-29 00:45:05 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-01-29 00:45:05 | INFO | train | epoch 172 | loss 2.337 | ppl 5.05 | wps 5900.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 11.891 | train_wall 325 | gb_free 6.1 | wall 61041
KL Stats: Epoch 172 Divergences: Uniform: 1.9801948146718478 Unigram: 72.75238255527461
2022-01-29 00:45:05 | INFO | fairseq.trainer | begin training epoch 173
2022-01-29 00:45:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:50:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:51:00 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 11.486 | ppl 2867.69 | wps 7855.6 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.393
2022-01-29 00:51:00 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-01-29 00:51:00 | INFO | train | epoch 173 | loss 2.324 | ppl 5.01 | wps 5892.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 12.46 | train_wall 325 | gb_free 6.1 | wall 61395
KL Stats: Epoch 173 Divergences: Uniform: 1.9667485203681603 Unigram: 73.00642724847772
2022-01-29 00:51:00 | INFO | fairseq.trainer | begin training epoch 174
2022-01-29 00:51:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:53:23 | INFO | train_inner | epoch 174:     28 / 64 loss=2.313, ppl=4.97, wps=5765.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=12.14, train_wall=507, gb_free=6.1, wall=61539
2022-01-29 00:56:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-29 00:56:55 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 12.371 | ppl 5298.26 | wps 7848.8 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.393
2022-01-29 00:56:55 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-01-29 00:56:55 | INFO | train | epoch 174 | loss 2.299 | ppl 4.92 | wps 5886.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 10.957 | train_wall 325 | gb_free 6.1 | wall 61750
KL Stats: Epoch 174 Divergences: Uniform: 1.951739440427798 Unigram: 73.42749375615499
2022-01-29 00:56:55 | INFO | fairseq.trainer | begin training epoch 175
2022-01-29 00:56:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:02:21 | INFO | train_inner | epoch 175:     64 / 64 loss=2.29, ppl=4.89, wps=6063.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=12.179, train_wall=507, gb_free=6.1, wall=62077
2022-01-29 01:02:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:02:49 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 11.338 | ppl 2588.85 | wps 7872.3 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.393
2022-01-29 01:02:49 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-01-29 01:02:49 | INFO | train | epoch 175 | loss 2.276 | ppl 4.84 | wps 5896.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 12.547 | train_wall 325 | gb_free 6.1 | wall 62104
KL Stats: Epoch 175 Divergences: Uniform: 1.9837242500865613 Unigram: 73.79170535883796
2022-01-29 01:02:49 | INFO | fairseq.trainer | begin training epoch 176
2022-01-29 01:02:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:08:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:08:43 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 11.673 | ppl 3265.34 | wps 7865.7 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.393
2022-01-29 01:08:43 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-01-29 01:08:43 | INFO | train | epoch 176 | loss 2.253 | ppl 4.77 | wps 5899.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 11.848 | train_wall 325 | gb_free 6.1 | wall 62458
KL Stats: Epoch 176 Divergences: Uniform: 1.946952893476829 Unigram: 74.177296187684
2022-01-29 01:08:43 | INFO | fairseq.trainer | begin training epoch 177
2022-01-29 01:08:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:11:47 | INFO | train_inner | epoch 177:     36 / 64 loss=2.249, ppl=4.75, wps=5771.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=11.603, train_wall=508, gb_free=6.1, wall=62643
2022-01-29 01:14:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-29 01:14:37 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 12.429 | ppl 5512.95 | wps 7848.8 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.393
2022-01-29 01:14:37 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-01-29 01:14:37 | INFO | train | epoch 177 | loss 2.26 | ppl 4.79 | wps 5891.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 12.154 | train_wall 325 | gb_free 6.1 | wall 62813
KL Stats: Epoch 177 Divergences: Uniform: 1.9706195015617334 Unigram: 74.30364506666892
2022-01-29 01:14:37 | INFO | fairseq.trainer | begin training epoch 178
2022-01-29 01:14:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:20:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-29 01:20:31 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.941 | ppl 1965.33 | wps 7900.7 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.393
2022-01-29 01:20:31 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-01-29 01:20:31 | INFO | train | epoch 178 | loss 2.206 | ppl 4.61 | wps 5900.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 11.758 | train_wall 325 | gb_free 6.1 | wall 63167
KL Stats: Epoch 178 Divergences: Uniform: 1.950628411965639 Unigram: 74.68993721059095
2022-01-29 01:20:31 | INFO | fairseq.trainer | begin training epoch 179
2022-01-29 01:20:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:21:12 | INFO | train_inner | epoch 179:      8 / 64 loss=2.222, ppl=4.67, wps=5769.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=11.909, train_wall=507, gb_free=6.1, wall=63208
2022-01-29 01:25:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:26:26 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 11.424 | ppl 2747.56 | wps 7856.1 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.393
2022-01-29 01:26:26 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-01-29 01:26:26 | INFO | train | epoch 179 | loss 2.215 | ppl 4.64 | wps 5893.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 12.739 | train_wall 325 | gb_free 6.1 | wall 63521
KL Stats: Epoch 179 Divergences: Uniform: 1.94090990262512 Unigram: 74.98453466531387
2022-01-29 01:26:26 | INFO | fairseq.trainer | begin training epoch 180
2022-01-29 01:26:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:30:11 | INFO | train_inner | epoch 180:     44 / 64 loss=2.197, ppl=4.58, wps=6065.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=12.841, train_wall=508, gb_free=6.1, wall=63747
2022-01-29 01:31:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-29 01:32:20 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 11.378 | ppl 2662.36 | wps 7876.7 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.393
2022-01-29 01:32:20 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-01-29 01:32:20 | INFO | train | epoch 180 | loss 2.174 | ppl 4.51 | wps 5894.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 12.75 | train_wall 325 | gb_free 6.1 | wall 63876
KL Stats: Epoch 180 Divergences: Uniform: 1.9718927025953716 Unigram: 75.28376275615803
2022-01-29 01:32:20 | INFO | fairseq.trainer | begin training epoch 181
2022-01-29 01:32:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:37:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:38:14 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 12.096 | ppl 4378.48 | wps 7854.1 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.393
2022-01-29 01:38:14 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-01-29 01:38:14 | INFO | train | epoch 181 | loss 2.14 | ppl 4.41 | wps 5892.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 11.999 | train_wall 325 | gb_free 6.1 | wall 64230
KL Stats: Epoch 181 Divergences: Uniform: 1.9028289239775906 Unigram: 75.65678710192508
2022-01-29 01:38:14 | INFO | fairseq.trainer | begin training epoch 182
2022-01-29 01:38:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:39:36 | INFO | train_inner | epoch 182:     16 / 64 loss=2.149, ppl=4.44, wps=5766.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=13.01, train_wall=507, gb_free=6.1, wall=64312
2022-01-29 01:43:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-29 01:44:08 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 11.17 | ppl 2304.88 | wps 7868.3 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.393
2022-01-29 01:44:08 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-01-29 01:44:08 | INFO | train | epoch 182 | loss 2.128 | ppl 4.37 | wps 5900 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 13.002 | train_wall 324 | gb_free 6.1 | wall 64584
KL Stats: Epoch 182 Divergences: Uniform: 1.946313292303987 Unigram: 76.0480534620831
2022-01-29 01:44:09 | INFO | fairseq.trainer | begin training epoch 183
2022-01-29 01:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:48:35 | INFO | train_inner | epoch 183:     52 / 64 loss=2.133, ppl=4.39, wps=6070.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=13.038, train_wall=508, gb_free=6.1, wall=64850
2022-01-29 01:49:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:50:03 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 11.672 | ppl 3262.19 | wps 7873.3 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.393
2022-01-29 01:50:03 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-01-29 01:50:03 | INFO | train | epoch 183 | loss 2.148 | ppl 4.43 | wps 5897.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 14.565 | train_wall 325 | gb_free 6.1 | wall 64938
KL Stats: Epoch 183 Divergences: Uniform: 1.9323944667684096 Unigram: 76.15155518959746
2022-01-29 01:50:03 | INFO | fairseq.trainer | begin training epoch 184
2022-01-29 01:50:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:55:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:55:56 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 12.137 | ppl 4504.48 | wps 7868.1 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.393
2022-01-29 01:55:56 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-01-29 01:55:56 | INFO | train | epoch 184 | loss 2.101 | ppl 4.29 | wps 5907.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 13.553 | train_wall 324 | gb_free 6.1 | wall 65292
KL Stats: Epoch 184 Divergences: Uniform: 1.9506297608877996 Unigram: 76.6279231315711
2022-01-29 01:55:56 | INFO | fairseq.trainer | begin training epoch 185
2022-01-29 01:55:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:57:59 | INFO | train_inner | epoch 185:     24 / 64 loss=2.112, ppl=4.32, wps=5776.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=13.801, train_wall=506, gb_free=6.1, wall=65415
2022-01-29 02:01:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:01:50 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 12.355 | ppl 5238.29 | wps 7874.9 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.393
2022-01-29 02:01:50 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-01-29 02:01:50 | INFO | train | epoch 185 | loss 2.068 | ppl 4.19 | wps 5897.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 13.486 | train_wall 325 | gb_free 6.1 | wall 65646
KL Stats: Epoch 185 Divergences: Uniform: 1.9203382506668965 Unigram: 77.20195267394125
2022-01-29 02:01:50 | INFO | fairseq.trainer | begin training epoch 186
2022-01-29 02:01:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:06:57 | INFO | train_inner | epoch 186:     60 / 64 loss=2.049, ppl=4.14, wps=6071.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=14.353, train_wall=508, gb_free=6.1, wall=65953
2022-01-29 02:07:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:07:44 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 12.452 | ppl 5603.96 | wps 7860 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.393
2022-01-29 02:07:44 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-01-29 02:07:44 | INFO | train | epoch 186 | loss 2.06 | ppl 4.17 | wps 5899.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 14.269 | train_wall 325 | gb_free 6.1 | wall 66000
KL Stats: Epoch 186 Divergences: Uniform: 1.9257142283468844 Unigram: 77.4435752668859
2022-01-29 02:07:44 | INFO | fairseq.trainer | begin training epoch 187
2022-01-29 02:07:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:13:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:13:38 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 12.485 | ppl 5733.05 | wps 7864.7 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.393
2022-01-29 02:13:38 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-01-29 02:13:38 | INFO | train | epoch 187 | loss 2.059 | ppl 4.17 | wps 5906 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 14.777 | train_wall 324 | gb_free 6.1 | wall 66354
KL Stats: Epoch 187 Divergences: Uniform: 1.9494802001524754 Unigram: 77.32168014262234
2022-01-29 02:13:38 | INFO | fairseq.trainer | begin training epoch 188
2022-01-29 02:13:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:16:23 | INFO | train_inner | epoch 188:     32 / 64 loss=2.06, ppl=4.17, wps=5768.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=13.654, train_wall=507, gb_free=6.1, wall=66518
2022-01-29 02:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:19:33 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 12.339 | ppl 5182.46 | wps 7875.5 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.393
2022-01-29 02:19:33 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-01-29 02:19:33 | INFO | train | epoch 188 | loss 2.036 | ppl 4.1 | wps 5877.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 12.483 | train_wall 326 | gb_free 6.1 | wall 66709
KL Stats: Epoch 188 Divergences: Uniform: 1.9288872870349165 Unigram: 77.62673019632678
2022-01-29 02:19:33 | INFO | fairseq.trainer | begin training epoch 189
2022-01-29 02:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:25:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:25:28 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 11.605 | ppl 3114.37 | wps 7858 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.393
2022-01-29 02:25:28 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-01-29 02:25:28 | INFO | train | epoch 189 | loss 2.044 | ppl 4.12 | wps 5890.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 16.394 | train_wall 325 | gb_free 6.1 | wall 67063
KL Stats: Epoch 189 Divergences: Uniform: 1.9328110400063168 Unigram: 77.87336434653426
2022-01-29 02:25:28 | INFO | fairseq.trainer | begin training epoch 190
2022-01-29 02:25:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:25:48 | INFO | train_inner | epoch 190:      4 / 64 loss=2.036, ppl=4.1, wps=5760.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=15.143, train_wall=508, gb_free=6.1, wall=67084
2022-01-29 02:30:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:31:23 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 11.031 | ppl 2091.84 | wps 7866.3 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.393
2022-01-29 02:31:23 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-01-29 02:31:23 | INFO | train | epoch 190 | loss 1.979 | ppl 3.94 | wps 5888.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 15.036 | train_wall 325 | gb_free 6.1 | wall 67418
KL Stats: Epoch 190 Divergences: Uniform: 1.9360914954174058 Unigram: 78.62574712869278
2022-01-29 02:31:23 | INFO | fairseq.trainer | begin training epoch 191
2022-01-29 02:31:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:34:48 | INFO | train_inner | epoch 191:     40 / 64 loss=1.974, ppl=3.93, wps=6058.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=15.028, train_wall=509, gb_free=6.1, wall=67623
2022-01-29 02:36:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:37:18 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 11.785 | ppl 3528.34 | wps 7849.7 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.393
2022-01-29 02:37:18 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-01-29 02:37:18 | INFO | train | epoch 191 | loss 1.997 | ppl 3.99 | wps 5883 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 14.9 | train_wall 325 | gb_free 6.1 | wall 67773
KL Stats: Epoch 191 Divergences: Uniform: 1.9021241545306806 Unigram: 78.49204678457153
2022-01-29 02:37:18 | INFO | fairseq.trainer | begin training epoch 192
2022-01-29 02:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:42:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:43:12 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 11.518 | ppl 2932.25 | wps 7857.9 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.393
2022-01-29 02:43:12 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-01-29 02:43:12 | INFO | train | epoch 192 | loss 1.975 | ppl 3.93 | wps 5887.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 14.13 | train_wall 325 | gb_free 6.1 | wall 68128
KL Stats: Epoch 192 Divergences: Uniform: 1.9024045334040087 Unigram: 78.81212780880918
2022-01-29 02:43:12 | INFO | fairseq.trainer | begin training epoch 193
2022-01-29 02:43:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:44:14 | INFO | train_inner | epoch 193:     12 / 64 loss=1.993, ppl=3.98, wps=5760.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=15.47, train_wall=508, gb_free=6.1, wall=68189
2022-01-29 02:48:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:49:07 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.466 | ppl 1414.14 | wps 7850 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.393
2022-01-29 02:49:07 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-01-29 02:49:07 | INFO | train | epoch 193 | loss 1.935 | ppl 3.82 | wps 5891.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 17.027 | train_wall 325 | gb_free 6.1 | wall 68482
KL Stats: Epoch 193 Divergences: Uniform: 1.9040043245037026 Unigram: 79.25308010475507
2022-01-29 02:49:07 | INFO | fairseq.trainer | begin training epoch 194
2022-01-29 02:49:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:53:14 | INFO | train_inner | epoch 194:     48 / 64 loss=1.939, ppl=3.84, wps=6056, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=16.069, train_wall=509, gb_free=6.1, wall=68729
2022-01-29 02:54:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:55:02 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 12.788 | ppl 7071.45 | wps 7871.5 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.393
2022-01-29 02:55:02 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-01-29 02:55:02 | INFO | train | epoch 194 | loss 1.949 | ppl 3.86 | wps 5882.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 16.582 | train_wall 326 | gb_free 6.1 | wall 68838
KL Stats: Epoch 194 Divergences: Uniform: 1.9102879884874773 Unigram: 79.51080419114575
2022-01-29 02:55:02 | INFO | fairseq.trainer | begin training epoch 195
2022-01-29 02:55:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:00:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:00:56 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 11.622 | ppl 3152.9 | wps 7873.5 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.393
2022-01-29 03:00:56 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-01-29 03:00:56 | INFO | train | epoch 195 | loss 1.916 | ppl 3.77 | wps 5894.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 16.675 | train_wall 325 | gb_free 6.1 | wall 69192
KL Stats: Epoch 195 Divergences: Uniform: 1.8818692881638772 Unigram: 79.6935018445458
2022-01-29 03:00:56 | INFO | fairseq.trainer | begin training epoch 196
2022-01-29 03:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:02:39 | INFO | train_inner | epoch 196:     20 / 64 loss=1.904, ppl=3.74, wps=5767.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=16.22, train_wall=507, gb_free=6.1, wall=69294
2022-01-29 03:06:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:06:51 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 11.831 | ppl 3642.45 | wps 7833.5 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.393
2022-01-29 03:06:51 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-01-29 03:06:51 | INFO | train | epoch 196 | loss 1.897 | ppl 3.72 | wps 5887 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 16.572 | train_wall 325 | gb_free 6.1 | wall 69547
KL Stats: Epoch 196 Divergences: Uniform: 1.8959185208313423 Unigram: 80.10119097591557
2022-01-29 03:06:51 | INFO | fairseq.trainer | begin training epoch 197
2022-01-29 03:06:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:11:38 | INFO | train_inner | epoch 197:     56 / 64 loss=1.915, ppl=3.77, wps=6061.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=17.542, train_wall=509, gb_free=6.1, wall=69833
2022-01-29 03:12:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-29 03:12:45 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 12.862 | ppl 7443.53 | wps 7865 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.393
2022-01-29 03:12:45 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-01-29 03:12:45 | INFO | train | epoch 197 | loss 1.912 | ppl 3.76 | wps 5893.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 17.196 | train_wall 325 | gb_free 6.1 | wall 69901
KL Stats: Epoch 197 Divergences: Uniform: 1.9136620466305951 Unigram: 80.33040075391015
2022-01-29 03:12:46 | INFO | fairseq.trainer | begin training epoch 198
2022-01-29 03:12:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:18:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:18:40 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 12.187 | ppl 4663.56 | wps 7898.2 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.393
2022-01-29 03:18:40 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-01-29 03:18:40 | INFO | train | epoch 198 | loss 1.879 | ppl 3.68 | wps 5889.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 17.857 | train_wall 325 | gb_free 6.1 | wall 70256
KL Stats: Epoch 198 Divergences: Uniform: 1.9021645247327768 Unigram: 80.67619944444192
2022-01-29 03:18:40 | INFO | fairseq.trainer | begin training epoch 199
2022-01-29 03:18:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:21:04 | INFO | train_inner | epoch 199:     28 / 64 loss=1.879, ppl=3.68, wps=5762.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=17.368, train_wall=508, gb_free=6.1, wall=70399
2022-01-29 03:24:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-29 03:24:35 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 11.734 | ppl 3407.29 | wps 7878.9 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.393
2022-01-29 03:24:35 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-01-29 03:24:35 | INFO | train | epoch 199 | loss 1.849 | ppl 3.6 | wps 5892.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 17.634 | train_wall 325 | gb_free 6.1 | wall 70610
KL Stats: Epoch 199 Divergences: Uniform: 1.9024023020262195 Unigram: 80.87893972722784
2022-01-29 03:24:35 | INFO | fairseq.trainer | begin training epoch 200
2022-01-29 03:24:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:30:01 | INFO | train_inner | epoch 200:     64 / 64 loss=1.839, ppl=3.58, wps=6069.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=18.976, train_wall=507, gb_free=6.1, wall=70936
2022-01-29 03:30:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-29 03:30:28 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 12.627 | ppl 6325.55 | wps 7880.4 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.393
2022-01-29 03:30:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-01-29 03:30:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint200.pt
2022-01-29 03:30:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint200.pt
2022-01-29 03:30:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.16_-0.06_0.9/checkpoint200.pt (epoch 200 @ 12800 updates, score 12.627) (writing took 3.951426347717643 seconds)
2022-01-29 03:30:32 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-01-29 03:30:32 | INFO | train | epoch 200 | loss 1.839 | ppl 3.58 | wps 5836.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 19.404 | train_wall 324 | gb_free 6.1 | wall 70968
KL Stats: Epoch 200 Divergences: Uniform: 1.8925875158665502 Unigram: 81.2811614001427
2022-01-29 03:30:32 | INFO | fairseq.trainer | begin training epoch 201
2022-01-29 03:30:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-01-29 03:36:26 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 13.396 | ppl 10776 | wps 7879.7 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.393
2022-01-29 03:36:26 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-01-29 03:36:26 | INFO | train | epoch 201 | loss 1.818 | ppl 3.53 | wps 5902.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 17.473 | train_wall 324 | gb_free 6.1 | wall 71322
KL Stats: Epoch 201 Divergences: Uniform: 1.90042992152482 Unigram: 81.6909316969193
2022-01-29 03:36:26 | INFO | fairseq.trainer | begin training epoch 202
2022-01-29 03:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:39:31 | INFO | train_inner | epoch 202:     36 / 64 loss=1.787, ppl=3.45, wps=5730.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=17.957, train_wall=508, gb_free=6.1, wall=71507
2022-01-29 03:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:42:21 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 12.265 | ppl 4922.79 | wps 7849.7 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.393
2022-01-29 03:42:21 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-01-29 03:42:21 | INFO | train | epoch 202 | loss 1.791 | ppl 3.46 | wps 5887.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 18.466 | train_wall 325 | gb_free 6.1 | wall 71677
KL Stats: Epoch 202 Divergences: Uniform: 1.890549687824935 Unigram: 81.88175875295072
2022-01-29 03:42:21 | INFO | fairseq.trainer | begin training epoch 203
2022-01-29 03:42:21 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
