Sender: LSF System <lsfadmin@eu-lo-g2-017>
Subject: Job 202286058: <w2_jelinek_0.06_0.04_0.9> in cluster <euler> Exited

Job <w2_jelinek_0.06_0.04_0.9> was submitted from host <eu-login-22> by user <andriusb> in cluster <euler> at Fri Jan 28 06:53:41 2022
Job was executed on host(s) <eu-lo-g2-017>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Fri Jan 28 07:00:48 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Fri Jan 28 07:00:48 2022
Terminated at Sat Jan 29 03:00:51 2022
Results reported at Sat Jan 29 03:00:51 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.06, 0.04, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72864.00 sec.
    Max Memory :                                 6041 MB
    Average Memory :                             3631.90 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13959.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72023 sec.
    Turnaround time :                            72430 sec.

The output (if any) follows:

2022-01-28 07:01:17 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.06, 0.04, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-28 07:01:17 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-28 07:01:18 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1446/36718 [00:00<00:02, 14434.13it/s]  8%|▊         | 2890/36718 [00:00<00:02, 13955.06it/s] 12%|█▏        | 4494/36718 [00:00<00:02, 14883.37it/s] 17%|█▋        | 6135/36718 [00:00<00:01, 15474.14it/s] 21%|██        | 7685/36718 [00:00<00:01, 14657.47it/s] 25%|██▍       | 9159/36718 [00:00<00:01, 14489.35it/s] 29%|██▉       | 10613/36718 [00:00<00:01, 14369.40it/s] 33%|███▎      | 12115/36718 [00:00<00:01, 14567.08it/s] 37%|███▋      | 13605/36718 [00:00<00:01, 14666.29it/s] 41%|████      | 15096/36718 [00:01<00:01, 14736.97it/s] 45%|████▌     | 16572/36718 [00:01<00:01, 14303.77it/s] 49%|████▉     | 18047/36718 [00:01<00:01, 14428.44it/s] 54%|█████▎    | 19658/36718 [00:01<00:01, 14921.35it/s] 58%|█████▊    | 21154/36718 [00:01<00:01, 14612.96it/s] 62%|██████▏   | 22619/36718 [00:01<00:00, 14494.37it/s] 66%|██████▌   | 24278/36718 [00:01<00:00, 15107.67it/s] 70%|███████   | 25874/36718 [00:01<00:00, 15354.62it/s] 75%|███████▍  | 27412/36718 [00:01<00:00, 14520.71it/s] 79%|███████▉  | 28932/36718 [00:01<00:00, 14713.95it/s] 83%|████████▎ | 30412/36718 [00:02<00:00, 14677.63it/s] 87%|████████▋ | 31886/36718 [00:02<00:00, 14217.61it/s] 91%|█████████ | 33314/36718 [00:02<00:00, 13972.42it/s] 95%|█████████▍| 34879/36718 [00:02<00:00, 14454.36it/s] 99%|█████████▉| 36330/36718 [00:02<00:00, 14276.93it/s]100%|██████████| 36718/36718 [00:02<00:00, 14560.10it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  8%|▊         | 2786/36718 [00:00<00:01, 27857.37it/s] 16%|█▋        | 6003/36718 [00:00<00:01, 30387.61it/s] 25%|██▍       | 9042/36718 [00:00<00:00, 29007.61it/s] 33%|███▎      | 11950/36718 [00:00<00:00, 28722.35it/s] 40%|████      | 14864/36718 [00:00<00:00, 28867.26it/s] 48%|████▊     | 17754/36718 [00:00<00:00, 28587.16it/s] 56%|█████▌    | 20615/36718 [00:00<00:00, 28389.84it/s] 64%|██████▍   | 23456/36718 [00:00<00:00, 28180.84it/s] 72%|███████▏  | 26534/36718 [00:00<00:00, 28974.92it/s] 80%|████████  | 29434/36718 [00:01<00:00, 28666.67it/s] 88%|████████▊ | 32303/36718 [00:01<00:00, 28202.15it/s] 96%|█████████▌| 35126/36718 [00:01<00:00, 28142.64it/s]100%|██████████| 36718/36718 [00:01<00:00, 28488.20it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 100.92it/s]2022-01-28 07:01:29 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-28 07:01:29 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-28 07:01:29 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-28 07:01:29 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-28 07:01:29 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-28 07:01:29 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-28 07:01:29 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-28 07:01:29 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-28 07:01:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-28 07:01:29 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-01-28 07:01:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-28 07:01:29 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-28 07:01:29 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-28 07:01:29 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint_last.pt
2022-01-28 07:01:29 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint_last.pt
2022-01-28 07:01:29 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-28 07:01:29 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-28 07:01:29 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-28 07:01:29 | INFO | fairseq.trainer | begin training epoch 1
2022-01-28 07:01:29 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-28 07:06:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-28 07:06:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.566 | ppl 24253.2 | wps 8622 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-28 07:06:59 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-28 07:06:59 | INFO | train | epoch 001 | loss 16.071 | ppl 68863.3 | wps 6351.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.379 | train_wall 303 | gb_free 6.1 | wall 330
KL Stats: Epoch 1 Divergences: Uniform: 0.5175912864357431 Unigram: 3.684556973864119
2022-01-28 07:06:59 | INFO | fairseq.trainer | begin training epoch 2
2022-01-28 07:06:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:09:50 | INFO | train_inner | epoch 002:     36 / 64 loss=15.506, ppl=46543.4, wps=6536.9, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.771, train_wall=474, gb_free=6.1, wall=501
2022-01-28 07:12:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:12:28 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.521 | ppl 11751.7 | wps 8642.5 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-28 07:12:28 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-28 07:12:28 | INFO | train | epoch 002 | loss 14.283 | ppl 19929.7 | wps 6355.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.565 | train_wall 302 | gb_free 6.1 | wall 659
KL Stats: Epoch 2 Divergences: Uniform: 0.5385688663428485 Unigram: 2.4125188923495853
2022-01-28 07:12:28 | INFO | fairseq.trainer | begin training epoch 3
2022-01-28 07:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:17:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:17:56 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.662 | ppl 6479.1 | wps 8625.6 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-28 07:17:56 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-28 07:17:56 | INFO | train | epoch 003 | loss 13.337 | ppl 10346.8 | wps 6354.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.264 | train_wall 302 | gb_free 6.1 | wall 987
KL Stats: Epoch 3 Divergences: Uniform: 0.5305613046532677 Unigram: 1.7251755745210915
2022-01-28 07:17:56 | INFO | fairseq.trainer | begin training epoch 4
2022-01-28 07:17:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:18:35 | INFO | train_inner | epoch 004:      8 / 64 loss=13.476, ppl=11395.2, wps=6218.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.294, train_wall=472, gb_free=6.1, wall=1026
2022-01-28 07:23:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:23:25 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.768 | ppl 3486.7 | wps 8639.2 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-28 07:23:25 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-28 07:23:25 | INFO | train | epoch 004 | loss 12.349 | ppl 5216.63 | wps 6352.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 1.011 | train_wall 303 | gb_free 6.1 | wall 1316
KL Stats: Epoch 4 Divergences: Uniform: 0.6245360046929378 Unigram: 1.097264054559148
2022-01-28 07:23:25 | INFO | fairseq.trainer | begin training epoch 5
2022-01-28 07:23:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:26:55 | INFO | train_inner | epoch 005:     44 / 64 loss=11.98, ppl=4040.29, wps=6535.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.885, train_wall=473, gb_free=6.1, wall=1526
2022-01-28 07:28:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:28:54 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.222 | ppl 2388.77 | wps 8614.7 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-28 07:28:54 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-28 07:28:54 | INFO | train | epoch 005 | loss 11.506 | ppl 2908.46 | wps 6352.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.714 | train_wall 303 | gb_free 6.1 | wall 1645
KL Stats: Epoch 5 Divergences: Uniform: 0.8894019182978129 Unigram: 0.6303576013008013
2022-01-28 07:28:54 | INFO | fairseq.trainer | begin training epoch 6
2022-01-28 07:28:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:33:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:34:23 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.971 | ppl 2007.78 | wps 8628.1 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-28 07:34:23 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-28 07:34:23 | INFO | train | epoch 006 | loss 11.048 | ppl 2116.74 | wps 6353 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.599 | train_wall 303 | gb_free 6.1 | wall 1974
KL Stats: Epoch 6 Divergences: Uniform: 1.2268012570001472 Unigram: 0.4120260111713113
2022-01-28 07:34:23 | INFO | fairseq.trainer | begin training epoch 7
2022-01-28 07:34:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:35:39 | INFO | train_inner | epoch 007:     16 / 64 loss=11.072, ppl=2152.29, wps=6218.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.598, train_wall=472, gb_free=6.1, wall=2050
2022-01-28 07:39:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:39:51 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.835 | ppl 1826.25 | wps 8619.5 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-28 07:39:51 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-28 07:39:51 | INFO | train | epoch 007 | loss 10.837 | ppl 1829.82 | wps 6360.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.529 | train_wall 302 | gb_free 6.1 | wall 2302
KL Stats: Epoch 7 Divergences: Uniform: 1.497940425813542 Unigram: 0.4047258567979375
2022-01-28 07:39:51 | INFO | fairseq.trainer | begin training epoch 8
2022-01-28 07:39:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:43:58 | INFO | train_inner | epoch 008:     52 / 64 loss=10.776, ppl=1753.37, wps=6541.3, ups=0.2, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.521, train_wall=473, gb_free=6.1, wall=2549
2022-01-28 07:44:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:45:20 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.737 | ppl 1706.68 | wps 8646.2 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-28 07:45:20 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-28 07:45:20 | INFO | train | epoch 008 | loss 10.725 | ppl 1692.2 | wps 6353.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.515 | train_wall 303 | gb_free 6.1 | wall 2631
KL Stats: Epoch 8 Divergences: Uniform: 1.651652586285506 Unigram: 0.4608756190821482
2022-01-28 07:45:20 | INFO | fairseq.trainer | begin training epoch 9
2022-01-28 07:45:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:50:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:50:49 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.625 | ppl 1578.97 | wps 8619.7 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-28 07:50:49 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-28 07:50:49 | INFO | train | epoch 009 | loss 10.624 | ppl 1578.34 | wps 6352.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.488 | train_wall 303 | gb_free 6.1 | wall 2960
KL Stats: Epoch 9 Divergences: Uniform: 1.7218610135068695 Unigram: 0.5383017691198688
2022-01-28 07:50:49 | INFO | fairseq.trainer | begin training epoch 10
2022-01-28 07:50:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:52:43 | INFO | train_inner | epoch 010:     24 / 64 loss=10.616, ppl=1569.08, wps=6216.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.491, train_wall=472, gb_free=6.1, wall=3074
2022-01-28 07:55:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:56:17 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.525 | ppl 1473.64 | wps 8619.8 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-28 07:56:17 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-28 07:56:17 | INFO | train | epoch 010 | loss 10.521 | ppl 1469.25 | wps 6351.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.484 | train_wall 303 | gb_free 6.1 | wall 3288
KL Stats: Epoch 10 Divergences: Uniform: 1.7605565963614744 Unigram: 0.6235153407347874
2022-01-28 07:56:17 | INFO | fairseq.trainer | begin training epoch 11
2022-01-28 07:56:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:01:03 | INFO | train_inner | epoch 011:     60 / 64 loss=10.448, ppl=1397.04, wps=6536.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.495, train_wall=473, gb_free=6.1, wall=3574
2022-01-28 08:01:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:01:46 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.421 | ppl 1370.58 | wps 8627.4 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-28 08:01:46 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-28 08:01:46 | INFO | train | epoch 011 | loss 10.41 | ppl 1360.74 | wps 6355.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.502 | train_wall 302 | gb_free 6.1 | wall 3617
KL Stats: Epoch 11 Divergences: Uniform: 1.7859838637467549 Unigram: 0.7074508409313874
2022-01-28 08:01:46 | INFO | fairseq.trainer | begin training epoch 12
2022-01-28 08:01:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:06:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:07:15 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.316 | ppl 1274.7 | wps 8616.7 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-28 08:07:15 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-28 08:07:15 | INFO | train | epoch 012 | loss 10.297 | ppl 1257.72 | wps 6355.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.474 | train_wall 302 | gb_free 6.1 | wall 3946
KL Stats: Epoch 12 Divergences: Uniform: 1.800697262161211 Unigram: 0.7914017363754422
2022-01-28 08:07:15 | INFO | fairseq.trainer | begin training epoch 13
2022-01-28 08:07:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:09:47 | INFO | train_inner | epoch 013:     32 / 64 loss=10.273, ppl=1237.4, wps=6218.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.488, train_wall=472, gb_free=6.1, wall=4098
2022-01-28 08:12:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:12:44 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.227 | ppl 1198.34 | wps 8619.9 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-28 08:12:44 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-28 08:12:44 | INFO | train | epoch 013 | loss 10.185 | ppl 1163.78 | wps 6349 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.517 | train_wall 303 | gb_free 6.1 | wall 4275
KL Stats: Epoch 13 Divergences: Uniform: 1.8321059769225343 Unigram: 0.8649601343733122
2022-01-28 08:12:44 | INFO | fairseq.trainer | begin training epoch 14
2022-01-28 08:12:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:17:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:18:13 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.135 | ppl 1124.72 | wps 8626.9 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-28 08:18:13 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-28 08:18:13 | INFO | train | epoch 014 | loss 10.075 | ppl 1078.37 | wps 6347.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.546 | train_wall 303 | gb_free 6.1 | wall 4604
KL Stats: Epoch 14 Divergences: Uniform: 1.8607154444382554 Unigram: 0.9353136820524363
2022-01-28 08:18:13 | INFO | fairseq.trainer | begin training epoch 15
2022-01-28 08:18:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:18:32 | INFO | train_inner | epoch 015:      4 / 64 loss=10.097, ppl=1095.34, wps=6213.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.531, train_wall=473, gb_free=6.1, wall=4623
2022-01-28 08:23:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:23:41 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.068 | ppl 1073.38 | wps 8624.4 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-28 08:23:41 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-28 08:23:41 | INFO | train | epoch 015 | loss 9.964 | ppl 998.43 | wps 6351.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.528 | train_wall 303 | gb_free 6.1 | wall 4932
KL Stats: Epoch 15 Divergences: Uniform: 1.891817131203331 Unigram: 0.9984735050468089
2022-01-28 08:23:41 | INFO | fairseq.trainer | begin training epoch 16
2022-01-28 08:23:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:26:52 | INFO | train_inner | epoch 016:     40 / 64 loss=9.923, ppl=970.46, wps=6532.9, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.551, train_wall=474, gb_free=6.1, wall=5123
2022-01-28 08:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:29:10 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.989 | ppl 1016.27 | wps 8631.9 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-28 08:29:10 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-28 08:29:10 | INFO | train | epoch 016 | loss 9.857 | ppl 927.52 | wps 6351.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.55 | train_wall 303 | gb_free 6.1 | wall 5261
KL Stats: Epoch 16 Divergences: Uniform: 1.925986605647189 Unigram: 1.0618843534920832
2022-01-28 08:29:10 | INFO | fairseq.trainer | begin training epoch 17
2022-01-28 08:29:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:34:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:34:39 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.896 | ppl 952.94 | wps 8639.7 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-28 08:34:39 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-28 08:34:39 | INFO | train | epoch 017 | loss 9.75 | ppl 861.16 | wps 6348.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.535 | train_wall 303 | gb_free 6.1 | wall 5590
KL Stats: Epoch 17 Divergences: Uniform: 1.9652242271094866 Unigram: 1.1163748707498278
2022-01-28 08:34:39 | INFO | fairseq.trainer | begin training epoch 18
2022-01-28 08:34:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:35:37 | INFO | train_inner | epoch 018:     12 / 64 loss=9.764, ppl=869.6, wps=6214.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.538, train_wall=473, gb_free=6.1, wall=5648
2022-01-28 08:39:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:40:08 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.826 | ppl 907.61 | wps 8607.5 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-28 08:40:08 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-28 08:40:08 | INFO | train | epoch 018 | loss 9.65 | ppl 803.36 | wps 6350.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.567 | train_wall 303 | gb_free 6.1 | wall 5919
KL Stats: Epoch 18 Divergences: Uniform: 2.0073210060781657 Unigram: 1.1705709641846456
2022-01-28 08:40:08 | INFO | fairseq.trainer | begin training epoch 19
2022-01-28 08:40:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:43:57 | INFO | train_inner | epoch 019:     48 / 64 loss=9.6, ppl=776.04, wps=6531.7, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.53, train_wall=474, gb_free=6.1, wall=6148
2022-01-28 08:45:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:45:37 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.759 | ppl 866.62 | wps 8613.1 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-28 08:45:37 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-28 08:45:37 | INFO | train | epoch 019 | loss 9.546 | ppl 747.55 | wps 6346.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.511 | train_wall 303 | gb_free 6.1 | wall 6248
KL Stats: Epoch 19 Divergences: Uniform: 2.044404940239017 Unigram: 1.2252306305351546
2022-01-28 08:45:37 | INFO | fairseq.trainer | begin training epoch 20
2022-01-28 08:45:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:50:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:51:06 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.67 | ppl 814.68 | wps 8605.2 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-28 08:51:06 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-28 08:51:06 | INFO | train | epoch 020 | loss 9.448 | ppl 698.37 | wps 6350 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.527 | train_wall 303 | gb_free 6.1 | wall 6577
KL Stats: Epoch 20 Divergences: Uniform: 2.0820162114280096 Unigram: 1.275277369561007
2022-01-28 08:51:06 | INFO | fairseq.trainer | begin training epoch 21
2022-01-28 08:51:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:52:42 | INFO | train_inner | epoch 021:     20 / 64 loss=9.444, ppl=696.32, wps=6213.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.537, train_wall=473, gb_free=6.1, wall=6673
2022-01-28 08:56:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:56:35 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.619 | ppl 786.39 | wps 8629.1 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-28 08:56:35 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-28 08:56:35 | INFO | train | epoch 021 | loss 9.355 | ppl 654.78 | wps 6349.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.542 | train_wall 303 | gb_free 6.1 | wall 6906
KL Stats: Epoch 21 Divergences: Uniform: 2.1150037374593817 Unigram: 1.3242022740380583
2022-01-28 08:56:35 | INFO | fairseq.trainer | begin training epoch 22
2022-01-28 08:56:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:01:02 | INFO | train_inner | epoch 022:     56 / 64 loss=9.302, ppl=631.1, wps=6534.9, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.531, train_wall=473, gb_free=6.1, wall=7173
2022-01-28 09:01:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:02:04 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.565 | ppl 757.22 | wps 8616.8 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-28 09:02:04 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-28 09:02:04 | INFO | train | epoch 022 | loss 9.265 | ppl 615.13 | wps 6354 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.53 | train_wall 302 | gb_free 6.1 | wall 7235
KL Stats: Epoch 22 Divergences: Uniform: 2.1481359460012044 Unigram: 1.3701439573666385
2022-01-28 09:02:04 | INFO | fairseq.trainer | begin training epoch 23
2022-01-28 09:02:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:07:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:07:33 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.503 | ppl 725.39 | wps 8595.8 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-28 09:07:33 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-28 09:07:33 | INFO | train | epoch 023 | loss 9.179 | ppl 579.64 | wps 6349.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.523 | train_wall 303 | gb_free 6.1 | wall 7564
KL Stats: Epoch 23 Divergences: Uniform: 2.1770848112533847 Unigram: 1.4112514592359926
2022-01-28 09:07:33 | INFO | fairseq.trainer | begin training epoch 24
2022-01-28 09:07:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:09:46 | INFO | train_inner | epoch 024:     28 / 64 loss=9.163, ppl=573.28, wps=6213.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.521, train_wall=472, gb_free=6.1, wall=7697
2022-01-28 09:12:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:13:02 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.452 | ppl 700.46 | wps 8632.5 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-28 09:13:02 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-28 09:13:02 | INFO | train | epoch 024 | loss 9.094 | ppl 546.6 | wps 6345.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.53 | train_wall 303 | gb_free 6.1 | wall 7893
KL Stats: Epoch 24 Divergences: Uniform: 2.206275937084193 Unigram: 1.4505942498002642
2022-01-28 09:13:02 | INFO | fairseq.trainer | begin training epoch 25
2022-01-28 09:13:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:18:06 | INFO | train_inner | epoch 025:     64 / 64 loss=9.041, ppl=526.67, wps=6527.1, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.526, train_wall=473, gb_free=6.1, wall=8197
2022-01-28 09:18:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:18:31 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.422 | ppl 686.14 | wps 8622.5 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-28 09:18:31 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-28 09:18:31 | INFO | train | epoch 025 | loss 9.013 | ppl 516.55 | wps 6346 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.518 | train_wall 303 | gb_free 6.1 | wall 8222
KL Stats: Epoch 25 Divergences: Uniform: 2.2394282090838518 Unigram: 1.4895723949682962
2022-01-28 09:18:31 | INFO | fairseq.trainer | begin training epoch 26
2022-01-28 09:18:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:23:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:24:00 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.376 | ppl 664.44 | wps 8620.1 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-28 09:24:00 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-28 09:24:00 | INFO | train | epoch 026 | loss 8.932 | ppl 488.28 | wps 6349.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.53 | train_wall 303 | gb_free 6.1 | wall 8551
KL Stats: Epoch 26 Divergences: Uniform: 2.2588343503895305 Unigram: 1.52462062875906
2022-01-28 09:24:00 | INFO | fairseq.trainer | begin training epoch 27
2022-01-28 09:24:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:26:52 | INFO | train_inner | epoch 027:     36 / 64 loss=8.903, ppl=478.82, wps=6215.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.519, train_wall=474, gb_free=6.1, wall=8722
2022-01-28 09:29:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:29:29 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.339 | ppl 647.5 | wps 8620.2 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-28 09:29:29 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-28 09:29:29 | INFO | train | epoch 027 | loss 8.851 | ppl 461.7 | wps 6348 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.508 | train_wall 303 | gb_free 6.1 | wall 8880
KL Stats: Epoch 27 Divergences: Uniform: 2.2859607821192363 Unigram: 1.5592749110339115
2022-01-28 09:29:29 | INFO | fairseq.trainer | begin training epoch 28
2022-01-28 09:29:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:34:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:34:58 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.306 | ppl 633.02 | wps 8620.2 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-28 09:34:58 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-28 09:34:58 | INFO | train | epoch 028 | loss 8.771 | ppl 436.95 | wps 6352.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.511 | train_wall 303 | gb_free 6.1 | wall 9209
KL Stats: Epoch 28 Divergences: Uniform: 2.318552810458993 Unigram: 1.5905123120988152
2022-01-28 09:34:58 | INFO | fairseq.trainer | begin training epoch 29
2022-01-28 09:34:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:35:36 | INFO | train_inner | epoch 029:      8 / 64 loss=8.788, ppl=441.9, wps=6214.1, ups=0.19, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.518, train_wall=472, gb_free=6.1, wall=9247
2022-01-28 09:40:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:40:27 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.279 | ppl 621.21 | wps 8609.4 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-28 09:40:27 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-28 09:40:27 | INFO | train | epoch 029 | loss 8.692 | ppl 413.7 | wps 6349.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.518 | train_wall 303 | gb_free 6.1 | wall 9538
KL Stats: Epoch 29 Divergences: Uniform: 2.3463293643617864 Unigram: 1.623594238659672
2022-01-28 09:40:27 | INFO | fairseq.trainer | begin training epoch 30
2022-01-28 09:40:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:43:56 | INFO | train_inner | epoch 030:     44 / 64 loss=8.659, ppl=404.24, wps=6533.8, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.512, train_wall=474, gb_free=6.1, wall=9747
2022-01-28 09:45:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:45:56 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.258 | ppl 612.46 | wps 8598.7 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-28 09:45:56 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-28 09:45:56 | INFO | train | epoch 030 | loss 8.614 | ppl 391.88 | wps 6349 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.52 | train_wall 303 | gb_free 6.1 | wall 9867
KL Stats: Epoch 30 Divergences: Uniform: 2.3685882625926933 Unigram: 1.6570130055923225
2022-01-28 09:45:56 | INFO | fairseq.trainer | begin training epoch 31
2022-01-28 09:45:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:50:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:51:25 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.209 | ppl 591.83 | wps 8616.3 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-28 09:51:25 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-28 09:51:25 | INFO | train | epoch 031 | loss 8.535 | ppl 370.82 | wps 6349.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.487 | train_wall 303 | gb_free 6.1 | wall 10196
KL Stats: Epoch 31 Divergences: Uniform: 2.3915633564782683 Unigram: 1.6849060082932974
2022-01-28 09:51:25 | INFO | fairseq.trainer | begin training epoch 32
2022-01-28 09:51:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:52:41 | INFO | train_inner | epoch 032:     16 / 64 loss=8.536, ppl=371.2, wps=6214.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.497, train_wall=472, gb_free=6.1, wall=10272
2022-01-28 09:56:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:56:53 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.181 | ppl 580.4 | wps 8628.2 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-28 09:56:53 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-28 09:56:53 | INFO | train | epoch 032 | loss 8.461 | ppl 352.34 | wps 6354.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.499 | train_wall 303 | gb_free 6.1 | wall 10524
KL Stats: Epoch 32 Divergences: Uniform: 2.420961222646504 Unigram: 1.7153773043243503
2022-01-28 09:56:53 | INFO | fairseq.trainer | begin training epoch 33
2022-01-28 09:56:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:01:01 | INFO | train_inner | epoch 033:     52 / 64 loss=8.424, ppl=343.45, wps=6535.4, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.504, train_wall=473, gb_free=6.1, wall=10772
2022-01-28 10:01:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:02:22 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.16 | ppl 572.2 | wps 8609.9 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-28 10:02:22 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-28 10:02:22 | INFO | train | epoch 033 | loss 8.386 | ppl 334.63 | wps 6350.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.5 | train_wall 303 | gb_free 6.1 | wall 10853
KL Stats: Epoch 33 Divergences: Uniform: 2.4504252565843605 Unigram: 1.7438149023627474
2022-01-28 10:02:22 | INFO | fairseq.trainer | begin training epoch 34
2022-01-28 10:02:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:07:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:07:51 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.145 | ppl 565.95 | wps 8626.6 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-28 10:07:51 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-28 10:07:51 | INFO | train | epoch 034 | loss 8.31 | ppl 317.28 | wps 6350.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.499 | train_wall 303 | gb_free 6.1 | wall 11182
KL Stats: Epoch 34 Divergences: Uniform: 2.4732176082905695 Unigram: 1.774379208730265
2022-01-28 10:07:51 | INFO | fairseq.trainer | begin training epoch 35
2022-01-28 10:07:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:09:45 | INFO | train_inner | epoch 035:     24 / 64 loss=8.297, ppl=314.54, wps=6214.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.497, train_wall=472, gb_free=6.1, wall=11296
2022-01-28 10:12:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:13:20 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.121 | ppl 556.87 | wps 8640.8 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-28 10:13:20 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-28 10:13:20 | INFO | train | epoch 035 | loss 8.238 | ppl 301.92 | wps 6353.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.498 | train_wall 303 | gb_free 6.1 | wall 11511
KL Stats: Epoch 35 Divergences: Uniform: 2.500692109240461 Unigram: 1.7976893828383986
2022-01-28 10:13:20 | INFO | fairseq.trainer | begin training epoch 36
2022-01-28 10:13:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:18:06 | INFO | train_inner | epoch 036:     60 / 64 loss=8.194, ppl=292.79, wps=6535.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.493, train_wall=473, gb_free=6.1, wall=11797
2022-01-28 10:18:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:18:49 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.097 | ppl 547.53 | wps 8611.4 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-28 10:18:49 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-28 10:18:49 | INFO | train | epoch 036 | loss 8.164 | ppl 286.79 | wps 6351.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.491 | train_wall 303 | gb_free 6.1 | wall 11840
KL Stats: Epoch 36 Divergences: Uniform: 2.5236070019586108 Unigram: 1.827256074863913
2022-01-28 10:18:49 | INFO | fairseq.trainer | begin training epoch 37
2022-01-28 10:18:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:23:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:24:18 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.099 | ppl 548.25 | wps 8616.4 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-28 10:24:18 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-28 10:24:18 | INFO | train | epoch 037 | loss 8.094 | ppl 273.23 | wps 6346.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.495 | train_wall 303 | gb_free 6.1 | wall 12169
KL Stats: Epoch 37 Divergences: Uniform: 2.5496526783538087 Unigram: 1.855081643943939
2022-01-28 10:24:18 | INFO | fairseq.trainer | begin training epoch 38
2022-01-28 10:24:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:26:50 | INFO | train_inner | epoch 038:     32 / 64 loss=8.072, ppl=269.18, wps=6214.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.493, train_wall=473, gb_free=6.1, wall=12321
2022-01-28 10:29:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:29:47 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.087 | ppl 543.97 | wps 8616.2 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-28 10:29:47 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-28 10:29:47 | INFO | train | epoch 038 | loss 8.025 | ppl 260.56 | wps 6352.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.497 | train_wall 303 | gb_free 6.1 | wall 12498
KL Stats: Epoch 38 Divergences: Uniform: 2.5838251414428113 Unigram: 1.8764074555620107
2022-01-28 10:29:47 | INFO | fairseq.trainer | begin training epoch 39
2022-01-28 10:29:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:34:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:35:15 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.062 | ppl 534.62 | wps 8631.2 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-28 10:35:15 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-28 10:35:15 | INFO | train | epoch 039 | loss 7.956 | ppl 248.36 | wps 6353.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.487 | train_wall 303 | gb_free 6.1 | wall 12826
KL Stats: Epoch 39 Divergences: Uniform: 2.594079828029519 Unigram: 1.90614641490535
2022-01-28 10:35:15 | INFO | fairseq.trainer | begin training epoch 40
2022-01-28 10:35:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:35:35 | INFO | train_inner | epoch 040:      4 / 64 loss=7.978, ppl=252.18, wps=6216.1, ups=0.19, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.494, train_wall=472, gb_free=6.1, wall=12845
2022-01-28 10:40:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:40:44 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.054 | ppl 531.46 | wps 8620.7 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-28 10:40:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-28 10:40:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint40.pt
2022-01-28 10:40:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint40.pt
2022-01-28 10:40:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.054) (writing took 5.290180908981711 seconds)
2022-01-28 10:40:49 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-28 10:40:49 | INFO | train | epoch 040 | loss 7.887 | ppl 236.66 | wps 6250.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.482 | train_wall 303 | gb_free 6.1 | wall 13160
KL Stats: Epoch 40 Divergences: Uniform: 2.6271658517284706 Unigram: 1.9304608485987595
2022-01-28 10:40:49 | INFO | fairseq.trainer | begin training epoch 41
2022-01-28 10:40:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:44:00 | INFO | train_inner | epoch 041:     40 / 64 loss=7.863, ppl=232.81, wps=6466.6, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.48, train_wall=473, gb_free=6.1, wall=13351
2022-01-28 10:45:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:46:18 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.045 | ppl 528.28 | wps 8616.7 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.045
2022-01-28 10:46:18 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-28 10:46:18 | INFO | train | epoch 041 | loss 7.823 | ppl 226.39 | wps 6350.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.488 | train_wall 303 | gb_free 6.1 | wall 13489
KL Stats: Epoch 41 Divergences: Uniform: 2.644218363552373 Unigram: 1.9504302586124995
2022-01-28 10:46:18 | INFO | fairseq.trainer | begin training epoch 42
2022-01-28 10:46:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:51:47 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.011 | ppl 515.86 | wps 8637 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.011
2022-01-28 10:51:47 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-28 10:51:47 | INFO | train | epoch 042 | loss 7.758 | ppl 216.52 | wps 6349.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.5 | train_wall 303 | gb_free 6.1 | wall 13818
KL Stats: Epoch 42 Divergences: Uniform: 2.6664332913865634 Unigram: 1.9795160698880103
2022-01-28 10:51:47 | INFO | fairseq.trainer | begin training epoch 43
2022-01-28 10:51:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:52:44 | INFO | train_inner | epoch 043:     12 / 64 loss=7.765, ppl=217.51, wps=6214.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.499, train_wall=472, gb_free=6.1, wall=13875
2022-01-28 10:56:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:57:16 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.03 | ppl 522.75 | wps 8606.6 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.03
2022-01-28 10:57:16 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-28 10:57:16 | INFO | train | epoch 043 | loss 7.693 | ppl 206.88 | wps 6351.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.486 | train_wall 303 | gb_free 6.1 | wall 14147
KL Stats: Epoch 43 Divergences: Uniform: 2.692256018473104 Unigram: 1.999858947843644
2022-01-28 10:57:16 | INFO | fairseq.trainer | begin training epoch 44
2022-01-28 10:57:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:01:05 | INFO | train_inner | epoch 044:     48 / 64 loss=7.658, ppl=202.03, wps=6534.1, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.494, train_wall=474, gb_free=6.1, wall=14376
2022-01-28 11:02:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:02:45 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.047 | ppl 529.12 | wps 8647.5 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.047
2022-01-28 11:02:45 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-28 11:02:45 | INFO | train | epoch 044 | loss 7.633 | ppl 198.47 | wps 6352.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.498 | train_wall 303 | gb_free 6.1 | wall 14476
KL Stats: Epoch 44 Divergences: Uniform: 2.716211758345643 Unigram: 2.0217801926668306
2022-01-28 11:02:45 | INFO | fairseq.trainer | begin training epoch 45
2022-01-28 11:02:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:07:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:08:14 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.047 | ppl 529.07 | wps 8625.4 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.047
2022-01-28 11:08:14 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-28 11:08:14 | INFO | train | epoch 045 | loss 7.57 | ppl 189.97 | wps 6351.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.499 | train_wall 303 | gb_free 6.1 | wall 14805
KL Stats: Epoch 45 Divergences: Uniform: 2.7335655796120446 Unigram: 2.0490713508934433
2022-01-28 11:08:14 | INFO | fairseq.trainer | begin training epoch 46
2022-01-28 11:08:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:09:49 | INFO | train_inner | epoch 046:     20 / 64 loss=7.569, ppl=189.86, wps=6215.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.495, train_wall=473, gb_free=6.1, wall=14900
2022-01-28 11:13:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:13:43 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.02 | ppl 519.25 | wps 8606.8 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.02
2022-01-28 11:13:43 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-28 11:13:43 | INFO | train | epoch 046 | loss 7.51 | ppl 182.25 | wps 6345.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.497 | train_wall 303 | gb_free 6.1 | wall 15134
KL Stats: Epoch 46 Divergences: Uniform: 2.751325859157869 Unigram: 2.0653022402294785
2022-01-28 11:13:43 | INFO | fairseq.trainer | begin training epoch 47
2022-01-28 11:13:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:18:10 | INFO | train_inner | epoch 047:     56 / 64 loss=7.479, ppl=178.39, wps=6526.7, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.491, train_wall=474, gb_free=6.1, wall=15401
2022-01-28 11:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:19:12 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.011 | ppl 516.03 | wps 8638.1 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.011
2022-01-28 11:19:12 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-28 11:19:12 | INFO | train | epoch 047 | loss 7.451 | ppl 174.93 | wps 6345.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.484 | train_wall 303 | gb_free 6.1 | wall 15463
KL Stats: Epoch 47 Divergences: Uniform: 2.7793866771091844 Unigram: 2.085815643555209
2022-01-28 11:19:12 | INFO | fairseq.trainer | begin training epoch 48
2022-01-28 11:19:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:24:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:24:41 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.006 | ppl 514.06 | wps 8640.8 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.006
2022-01-28 11:24:41 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-28 11:24:41 | INFO | train | epoch 048 | loss 7.394 | ppl 168.22 | wps 6348 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.499 | train_wall 303 | gb_free 6.1 | wall 15792
KL Stats: Epoch 48 Divergences: Uniform: 2.8041132926094336 Unigram: 2.1101701477607833
2022-01-28 11:24:41 | INFO | fairseq.trainer | begin training epoch 49
2022-01-28 11:24:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:26:55 | INFO | train_inner | epoch 049:     28 / 64 loss=7.376, ppl=166.15, wps=6213.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.494, train_wall=473, gb_free=6.1, wall=15926
2022-01-28 11:29:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:30:10 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.025 | ppl 521.05 | wps 8615.1 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.025
2022-01-28 11:30:10 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-28 11:30:10 | INFO | train | epoch 049 | loss 7.337 | ppl 161.64 | wps 6347 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.496 | train_wall 303 | gb_free 6.1 | wall 16121
KL Stats: Epoch 49 Divergences: Uniform: 2.8119355331671487 Unigram: 2.1264962930971394
2022-01-28 11:30:10 | INFO | fairseq.trainer | begin training epoch 50
2022-01-28 11:30:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:35:14 | INFO | train_inner | epoch 050:     64 / 64 loss=7.312, ppl=158.86, wps=6529.5, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.507, train_wall=473, gb_free=6.1, wall=16425
2022-01-28 11:35:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:35:39 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.061 | ppl 534.22 | wps 8649.9 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.054
2022-01-28 11:35:39 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-28 11:35:39 | INFO | train | epoch 050 | loss 7.285 | ppl 155.91 | wps 6351 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.508 | train_wall 303 | gb_free 6.1 | wall 16450
KL Stats: Epoch 50 Divergences: Uniform: 2.8313610618293312 Unigram: 2.140199126850167
2022-01-28 11:35:39 | INFO | fairseq.trainer | begin training epoch 51
2022-01-28 11:35:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:40:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:41:08 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.047 | ppl 528.96 | wps 8645.3 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.047
2022-01-28 11:41:08 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-28 11:41:08 | INFO | train | epoch 051 | loss 7.23 | ppl 150.08 | wps 6350.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.5 | train_wall 303 | gb_free 6.1 | wall 16779
KL Stats: Epoch 51 Divergences: Uniform: 2.864242681333133 Unigram: 2.1609118408062593
2022-01-28 11:41:08 | INFO | fairseq.trainer | begin training epoch 52
2022-01-28 11:41:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:43:59 | INFO | train_inner | epoch 052:     36 / 64 loss=7.205, ppl=147.56, wps=6218.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.498, train_wall=474, gb_free=6.1, wall=16950
2022-01-28 11:46:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:46:37 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.022 | ppl 519.99 | wps 8603.5 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.022
2022-01-28 11:46:37 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-28 11:46:37 | INFO | train | epoch 052 | loss 7.176 | ppl 144.6 | wps 6349.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.5 | train_wall 303 | gb_free 6.1 | wall 17108
KL Stats: Epoch 52 Divergences: Uniform: 2.875572701427495 Unigram: 2.1818842677291213
2022-01-28 11:46:37 | INFO | fairseq.trainer | begin training epoch 53
2022-01-28 11:46:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:51:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:52:06 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.032 | ppl 523.54 | wps 8625.8 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.032
2022-01-28 11:52:06 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-28 11:52:06 | INFO | train | epoch 053 | loss 7.124 | ppl 139.52 | wps 6356 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.494 | train_wall 302 | gb_free 6.1 | wall 17436
KL Stats: Epoch 53 Divergences: Uniform: 2.9003033650699215 Unigram: 2.1958572199965816
2022-01-28 11:52:06 | INFO | fairseq.trainer | begin training epoch 54
2022-01-28 11:52:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:52:44 | INFO | train_inner | epoch 054:      8 / 64 loss=7.137, ppl=140.79, wps=6217.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.501, train_wall=472, gb_free=6.1, wall=17475
2022-01-28 11:57:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:57:34 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.072 | ppl 538.07 | wps 8617.7 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.054
2022-01-28 11:57:34 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-28 11:57:34 | INFO | train | epoch 054 | loss 7.074 | ppl 134.78 | wps 6353.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.507 | train_wall 303 | gb_free 6.1 | wall 17765
KL Stats: Epoch 54 Divergences: Uniform: 2.911022878148214 Unigram: 2.2133835860479687
2022-01-28 11:57:34 | INFO | fairseq.trainer | begin training epoch 55
2022-01-28 11:57:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:01:04 | INFO | train_inner | epoch 055:     44 / 64 loss=7.047, ppl=132.23, wps=6535.7, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.505, train_wall=473, gb_free=6.1, wall=17975
2022-01-28 12:02:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:03:03 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.04 | ppl 526.24 | wps 8618.4 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.04
2022-01-28 12:03:03 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-28 12:03:03 | INFO | train | epoch 055 | loss 7.028 | ppl 130.47 | wps 6352.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.517 | train_wall 303 | gb_free 6.1 | wall 18094
KL Stats: Epoch 55 Divergences: Uniform: 2.9277075548675713 Unigram: 2.2338319793045915
2022-01-28 12:03:03 | INFO | fairseq.trainer | begin training epoch 56
2022-01-28 12:03:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:08:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:08:32 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.169 | ppl 575.61 | wps 8641.2 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.054
2022-01-28 12:08:32 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-28 12:08:32 | INFO | train | epoch 056 | loss 6.977 | ppl 125.96 | wps 6345.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.508 | train_wall 303 | gb_free 6.1 | wall 18423
KL Stats: Epoch 56 Divergences: Uniform: 2.9243998635466024 Unigram: 2.2449238628373904
2022-01-28 12:08:32 | INFO | fairseq.trainer | begin training epoch 57
2022-01-28 12:08:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:09:48 | INFO | train_inner | epoch 057:     16 / 64 loss=6.981, ppl=126.36, wps=6213, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.513, train_wall=473, gb_free=6.1, wall=18499
2022-01-28 12:13:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:14:01 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.124 | ppl 558.1 | wps 8620.3 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.054
2022-01-28 12:14:01 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-28 12:14:01 | INFO | train | epoch 057 | loss 6.93 | ppl 121.96 | wps 6349 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.516 | train_wall 303 | gb_free 6.1 | wall 18752
KL Stats: Epoch 57 Divergences: Uniform: 2.9634254654936405 Unigram: 2.2684449171734236
2022-01-28 12:14:01 | INFO | fairseq.trainer | begin training epoch 58
2022-01-28 12:14:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:18:09 | INFO | train_inner | epoch 058:     52 / 64 loss=6.906, ppl=119.92, wps=6529.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.514, train_wall=474, gb_free=6.1, wall=19000
2022-01-28 12:19:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:19:30 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.136 | ppl 562.75 | wps 8604.2 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.054
2022-01-28 12:19:30 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-28 12:19:30 | INFO | train | epoch 058 | loss 6.886 | ppl 118.23 | wps 6346.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.514 | train_wall 303 | gb_free 6.1 | wall 19081
KL Stats: Epoch 58 Divergences: Uniform: 2.9711913869902657 Unigram: 2.2799688822631565
2022-01-28 12:19:30 | INFO | fairseq.trainer | begin training epoch 59
2022-01-28 12:19:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:24:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:24:59 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.167 | ppl 574.68 | wps 8626 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.054
2022-01-28 12:24:59 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-28 12:24:59 | INFO | train | epoch 059 | loss 6.84 | ppl 114.56 | wps 6350.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.518 | train_wall 303 | gb_free 6.1 | wall 19410
KL Stats: Epoch 59 Divergences: Uniform: 2.9961776537626412 Unigram: 2.293097493069679
2022-01-28 12:24:59 | INFO | fairseq.trainer | begin training epoch 60
2022-01-28 12:24:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:26:53 | INFO | train_inner | epoch 060:     24 / 64 loss=6.834, ppl=114.08, wps=6215.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.521, train_wall=472, gb_free=6.1, wall=19524
2022-01-28 12:30:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:30:28 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.142 | ppl 564.87 | wps 8614 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.054
2022-01-28 12:30:28 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-28 12:30:28 | INFO | train | epoch 060 | loss 6.795 | ppl 111.05 | wps 6351.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.521 | train_wall 303 | gb_free 6.1 | wall 19739
KL Stats: Epoch 60 Divergences: Uniform: 3.006941084008824 Unigram: 2.313734006839385
2022-01-28 12:30:28 | INFO | fairseq.trainer | begin training epoch 61
2022-01-28 12:30:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:35:13 | INFO | train_inner | epoch 061:     60 / 64 loss=6.776, ppl=109.61, wps=6536.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.529, train_wall=473, gb_free=6.1, wall=20024
2022-01-28 12:35:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:35:57 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.177 | ppl 578.95 | wps 8630 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.054
2022-01-28 12:35:57 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-28 12:35:57 | INFO | train | epoch 061 | loss 6.754 | ppl 107.9 | wps 6356.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.536 | train_wall 302 | gb_free 6.1 | wall 20068
KL Stats: Epoch 61 Divergences: Uniform: 3.0371750566200633 Unigram: 2.327516758330811
2022-01-28 12:35:57 | INFO | fairseq.trainer | begin training epoch 62
2022-01-28 12:35:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:41:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:41:26 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.152 | ppl 568.78 | wps 8616.8 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.054
2022-01-28 12:41:26 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-28 12:41:26 | INFO | train | epoch 062 | loss 6.711 | ppl 104.75 | wps 6346.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.532 | train_wall 303 | gb_free 6.1 | wall 20397
KL Stats: Epoch 62 Divergences: Uniform: 3.047586219023981 Unigram: 2.343415291003529
2022-01-28 12:41:26 | INFO | fairseq.trainer | begin training epoch 63
2022-01-28 12:41:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:43:58 | INFO | train_inner | epoch 063:     32 / 64 loss=6.685, ppl=102.92, wps=6211.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.531, train_wall=473, gb_free=6.1, wall=20549
2022-01-28 12:46:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:46:55 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.187 | ppl 582.95 | wps 8621 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.054
2022-01-28 12:46:55 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-28 12:46:55 | INFO | train | epoch 063 | loss 6.668 | ppl 101.67 | wps 6348.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.53 | train_wall 303 | gb_free 6.1 | wall 20726
KL Stats: Epoch 63 Divergences: Uniform: 3.0603521658587973 Unigram: 2.357903686249145
2022-01-28 12:46:55 | INFO | fairseq.trainer | begin training epoch 64
2022-01-28 12:46:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:51:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:52:23 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.255 | ppl 610.87 | wps 8647 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.054
2022-01-28 12:52:23 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-28 12:52:23 | INFO | train | epoch 064 | loss 6.625 | ppl 98.68 | wps 6354.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.537 | train_wall 303 | gb_free 6.1 | wall 21054
KL Stats: Epoch 64 Divergences: Uniform: 3.064927783268481 Unigram: 2.369692410144391
2022-01-28 12:52:23 | INFO | fairseq.trainer | begin training epoch 65
2022-01-28 12:52:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:52:43 | INFO | train_inner | epoch 065:      4 / 64 loss=6.652, ppl=100.54, wps=6217.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.536, train_wall=472, gb_free=6.1, wall=21074
2022-01-28 12:57:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:57:52 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.162 | ppl 572.72 | wps 8648.3 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.054
2022-01-28 12:57:52 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-28 12:57:52 | INFO | train | epoch 065 | loss 6.581 | ppl 95.76 | wps 6354.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.535 | train_wall 303 | gb_free 6.1 | wall 21383
KL Stats: Epoch 65 Divergences: Uniform: 3.091940831143328 Unigram: 2.3879038842053504
2022-01-28 12:57:52 | INFO | fairseq.trainer | begin training epoch 66
2022-01-28 12:57:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:01:03 | INFO | train_inner | epoch 066:     40 / 64 loss=6.557, ppl=94.14, wps=6535.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.538, train_wall=473, gb_free=6.1, wall=21574
2022-01-28 13:02:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:03:21 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.183 | ppl 581.19 | wps 8632.3 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.054
2022-01-28 13:03:21 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-28 13:03:21 | INFO | train | epoch 066 | loss 6.54 | ppl 93.08 | wps 6349.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.536 | train_wall 303 | gb_free 6.1 | wall 21712
KL Stats: Epoch 66 Divergences: Uniform: 3.1034799953381116 Unigram: 2.400367095954038
2022-01-28 13:03:21 | INFO | fairseq.trainer | begin training epoch 67
2022-01-28 13:03:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:08:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:08:50 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.193 | ppl 585.13 | wps 8618.4 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.054
2022-01-28 13:08:50 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-28 13:08:50 | INFO | train | epoch 067 | loss 6.502 | ppl 90.64 | wps 6350.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.542 | train_wall 303 | gb_free 6.1 | wall 22041
KL Stats: Epoch 67 Divergences: Uniform: 3.1268125439663756 Unigram: 2.4196603842116016
2022-01-28 13:08:50 | INFO | fairseq.trainer | begin training epoch 68
2022-01-28 13:08:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:09:47 | INFO | train_inner | epoch 068:     12 / 64 loss=6.51, ppl=91.14, wps=6215, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.536, train_wall=472, gb_free=6.1, wall=22098
2022-01-28 13:13:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:14:19 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.258 | ppl 612.39 | wps 8636.6 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.054
2022-01-28 13:14:19 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-28 13:14:19 | INFO | train | epoch 068 | loss 6.463 | ppl 88.24 | wps 6346.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.553 | train_wall 303 | gb_free 6.1 | wall 22370
KL Stats: Epoch 68 Divergences: Uniform: 3.1368878758646783 Unigram: 2.431572824809163
2022-01-28 13:14:19 | INFO | fairseq.trainer | begin training epoch 69
2022-01-28 13:14:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:18:07 | INFO | train_inner | epoch 069:     48 / 64 loss=6.445, ppl=87.15, wps=6531.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.549, train_wall=474, gb_free=6.1, wall=22598
2022-01-28 13:19:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:19:48 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.297 | ppl 628.99 | wps 8614 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.054
2022-01-28 13:19:48 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-28 13:19:48 | INFO | train | epoch 069 | loss 6.425 | ppl 85.95 | wps 6350.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.548 | train_wall 303 | gb_free 6.1 | wall 22699
KL Stats: Epoch 69 Divergences: Uniform: 3.1512562808490996 Unigram: 2.4440256759848427
2022-01-28 13:19:48 | INFO | fairseq.trainer | begin training epoch 70
2022-01-28 13:19:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:24:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:25:17 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.282 | ppl 622.63 | wps 8619.9 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.054
2022-01-28 13:25:17 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-28 13:25:17 | INFO | train | epoch 070 | loss 6.39 | ppl 83.89 | wps 6351 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.54 | train_wall 303 | gb_free 6.1 | wall 23028
KL Stats: Epoch 70 Divergences: Uniform: 3.16593851526737 Unigram: 2.4553477885825763
2022-01-28 13:25:17 | INFO | fairseq.trainer | begin training epoch 71
2022-01-28 13:25:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:26:52 | INFO | train_inner | epoch 071:     20 / 64 loss=6.385, ppl=83.6, wps=6214.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.549, train_wall=472, gb_free=6.1, wall=23123
2022-01-28 13:30:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:30:46 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.305 | ppl 632.71 | wps 8642.2 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.054
2022-01-28 13:30:46 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-28 13:30:46 | INFO | train | epoch 071 | loss 6.358 | ppl 82.01 | wps 6351.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.56 | train_wall 303 | gb_free 6.1 | wall 23357
KL Stats: Epoch 71 Divergences: Uniform: 3.1700519918601775 Unigram: 2.4695109258584855
2022-01-28 13:30:46 | INFO | fairseq.trainer | begin training epoch 72
2022-01-28 13:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:35:12 | INFO | train_inner | epoch 072:     56 / 64 loss=6.343, ppl=81.17, wps=6535.9, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.56, train_wall=473, gb_free=6.1, wall=23623
2022-01-28 13:35:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:36:14 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.271 | ppl 617.97 | wps 8607.2 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.054
2022-01-28 13:36:14 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-28 13:36:14 | INFO | train | epoch 072 | loss 6.323 | ppl 80.07 | wps 6353.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.56 | train_wall 302 | gb_free 6.1 | wall 23685
KL Stats: Epoch 72 Divergences: Uniform: 3.199037539498625 Unigram: 2.4830519779491467
2022-01-28 13:36:14 | INFO | fairseq.trainer | begin training epoch 73
2022-01-28 13:36:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:41:43 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.354 | ppl 654.27 | wps 8632.2 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.054
2022-01-28 13:41:43 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-28 13:41:43 | INFO | train | epoch 073 | loss 6.291 | ppl 78.29 | wps 6354 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.558 | train_wall 303 | gb_free 6.1 | wall 24014
KL Stats: Epoch 73 Divergences: Uniform: 3.1921290611617574 Unigram: 2.4937979566537694
2022-01-28 13:41:43 | INFO | fairseq.trainer | begin training epoch 74
2022-01-28 13:41:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:43:56 | INFO | train_inner | epoch 074:     28 / 64 loss=6.28, ppl=77.71, wps=6216.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.557, train_wall=472, gb_free=6.1, wall=24147
2022-01-28 13:46:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:47:12 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.263 | ppl 614.42 | wps 8641.1 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.054
2022-01-28 13:47:12 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-28 13:47:12 | INFO | train | epoch 074 | loss 6.258 | ppl 76.54 | wps 6352.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.549 | train_wall 303 | gb_free 6.1 | wall 24343
KL Stats: Epoch 74 Divergences: Uniform: 3.2149301053575026 Unigram: 2.5127886900412895
2022-01-28 13:47:12 | INFO | fairseq.trainer | begin training epoch 75
2022-01-28 13:47:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:52:16 | INFO | train_inner | epoch 075:     64 / 64 loss=6.249, ppl=76.06, wps=6532.3, ups=0.2, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.559, train_wall=472, gb_free=6.1, wall=24647
2022-01-28 13:52:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:52:41 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.398 | ppl 674.83 | wps 8624.6 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.054
2022-01-28 13:52:41 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-28 13:52:41 | INFO | train | epoch 075 | loss 6.229 | ppl 75.03 | wps 6348.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.566 | train_wall 303 | gb_free 6.1 | wall 24672
KL Stats: Epoch 75 Divergences: Uniform: 3.2128140256503293 Unigram: 2.5224213933500246
2022-01-28 13:52:41 | INFO | fairseq.trainer | begin training epoch 76
2022-01-28 13:52:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:57:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:58:10 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.37 | ppl 661.75 | wps 8627.5 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.054
2022-01-28 13:58:10 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-28 13:58:10 | INFO | train | epoch 076 | loss 6.2 | ppl 73.5 | wps 6351.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.574 | train_wall 303 | gb_free 6.1 | wall 25001
KL Stats: Epoch 76 Divergences: Uniform: 3.2249903435501794 Unigram: 2.5373872521184997
2022-01-28 13:58:10 | INFO | fairseq.trainer | begin training epoch 77
2022-01-28 13:58:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:01:01 | INFO | train_inner | epoch 077:     36 / 64 loss=6.175, ppl=72.26, wps=6215.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.572, train_wall=474, gb_free=6.1, wall=25172
2022-01-28 14:03:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:03:39 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.413 | ppl 681.71 | wps 8596.2 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.054
2022-01-28 14:03:39 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-28 14:03:39 | INFO | train | epoch 077 | loss 6.171 | ppl 72.04 | wps 6343 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.577 | train_wall 303 | gb_free 6.1 | wall 25330
KL Stats: Epoch 77 Divergences: Uniform: 3.2301537026525127 Unigram: 2.55303778692822
2022-01-28 14:03:39 | INFO | fairseq.trainer | begin training epoch 78
2022-01-28 14:03:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:08:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:09:08 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.344 | ppl 649.68 | wps 8620.6 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.054
2022-01-28 14:09:08 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-28 14:09:08 | INFO | train | epoch 078 | loss 6.143 | ppl 70.65 | wps 6352.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.572 | train_wall 303 | gb_free 6.1 | wall 25659
KL Stats: Epoch 78 Divergences: Uniform: 3.248189051311068 Unigram: 2.5596691092225745
2022-01-28 14:09:08 | INFO | fairseq.trainer | begin training epoch 79
2022-01-28 14:09:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:09:46 | INFO | train_inner | epoch 079:      8 / 64 loss=6.157, ppl=71.38, wps=6213.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.579, train_wall=472, gb_free=6.1, wall=25697
2022-01-28 14:14:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:14:37 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.441 | ppl 695.14 | wps 8645.7 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.054
2022-01-28 14:14:37 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-28 14:14:37 | INFO | train | epoch 079 | loss 6.113 | ppl 69.2 | wps 6348.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.569 | train_wall 303 | gb_free 6.1 | wall 25988
KL Stats: Epoch 79 Divergences: Uniform: 3.2550991562489027 Unigram: 2.5673801770910814
2022-01-28 14:14:37 | INFO | fairseq.trainer | begin training epoch 80
2022-01-28 14:14:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:18:07 | INFO | train_inner | epoch 080:     44 / 64 loss=6.097, ppl=68.43, wps=6529.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.57, train_wall=474, gb_free=6.1, wall=26197
2022-01-28 14:19:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:20:06 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.359 | ppl 656.57 | wps 8632.8 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.054
2022-01-28 14:20:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-28 14:20:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint80.pt
2022-01-28 14:20:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint80.pt
2022-01-28 14:20:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.359) (writing took 4.718715514056385 seconds)
2022-01-28 14:20:11 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-28 14:20:11 | INFO | train | epoch 080 | loss 6.088 | ppl 68.03 | wps 6256 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.581 | train_wall 303 | gb_free 6.1 | wall 26322
KL Stats: Epoch 80 Divergences: Uniform: 3.2579121788607353 Unigram: 2.5801507086950677
2022-01-28 14:20:11 | INFO | fairseq.trainer | begin training epoch 81
2022-01-28 14:20:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:25:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:25:39 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.408 | ppl 679.16 | wps 8621.5 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.054
2022-01-28 14:25:39 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-28 14:25:39 | INFO | train | epoch 081 | loss 6.062 | ppl 66.8 | wps 6353.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.589 | train_wall 303 | gb_free 6.1 | wall 26650
KL Stats: Epoch 81 Divergences: Uniform: 3.2832917736415803 Unigram: 2.5978483332563282
2022-01-28 14:25:39 | INFO | fairseq.trainer | begin training epoch 82
2022-01-28 14:25:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:26:56 | INFO | train_inner | epoch 082:     16 / 64 loss=6.068, ppl=67.1, wps=6161.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.588, train_wall=472, gb_free=6.1, wall=26727
2022-01-28 14:30:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:31:08 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.433 | ppl 690.98 | wps 8615 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.054
2022-01-28 14:31:08 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-28 14:31:08 | INFO | train | epoch 082 | loss 6.037 | ppl 65.66 | wps 6351.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.583 | train_wall 303 | gb_free 6.1 | wall 26979
KL Stats: Epoch 82 Divergences: Uniform: 3.286159847452542 Unigram: 2.6096983101967965
2022-01-28 14:31:08 | INFO | fairseq.trainer | begin training epoch 83
2022-01-28 14:31:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:35:16 | INFO | train_inner | epoch 083:     52 / 64 loss=6.024, ppl=65.06, wps=6535.1, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.59, train_wall=473, gb_free=6.1, wall=27227
2022-01-28 14:36:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:36:37 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.34 | ppl 648.14 | wps 8620.4 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.054
2022-01-28 14:36:37 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-28 14:36:37 | INFO | train | epoch 083 | loss 6.014 | ppl 64.62 | wps 6354.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.6 | train_wall 302 | gb_free 6.1 | wall 27308
KL Stats: Epoch 83 Divergences: Uniform: 3.2894849492558573 Unigram: 2.6189630127884365
2022-01-28 14:36:37 | INFO | fairseq.trainer | begin training epoch 84
2022-01-28 14:36:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:41:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:42:06 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.372 | ppl 662.7 | wps 8644.1 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.054
2022-01-28 14:42:06 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-28 14:42:06 | INFO | train | epoch 084 | loss 5.988 | ppl 63.48 | wps 6351.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.589 | train_wall 303 | gb_free 6.1 | wall 27637
KL Stats: Epoch 84 Divergences: Uniform: 3.30183787172337 Unigram: 2.6331586386963783
2022-01-28 14:42:06 | INFO | fairseq.trainer | begin training epoch 85
2022-01-28 14:42:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:44:00 | INFO | train_inner | epoch 085:     24 / 64 loss=5.978, ppl=63.04, wps=6216.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.592, train_wall=472, gb_free=6.1, wall=27751
2022-01-28 14:47:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:47:35 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.439 | ppl 693.87 | wps 8622.8 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.054
2022-01-28 14:47:35 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-28 14:47:35 | INFO | train | epoch 085 | loss 5.963 | ppl 62.39 | wps 6349.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.585 | train_wall 303 | gb_free 6.1 | wall 27966
KL Stats: Epoch 85 Divergences: Uniform: 3.3158318365726056 Unigram: 2.636737504959953
2022-01-28 14:47:35 | INFO | fairseq.trainer | begin training epoch 86
2022-01-28 14:47:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:52:20 | INFO | train_inner | epoch 086:     60 / 64 loss=5.962, ppl=62.32, wps=6532.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.599, train_wall=474, gb_free=6.1, wall=28251
2022-01-28 14:52:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:53:04 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.435 | ppl 691.96 | wps 8616 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.054
2022-01-28 14:53:04 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-28 14:53:04 | INFO | train | epoch 086 | loss 5.942 | ppl 61.49 | wps 6349.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.612 | train_wall 303 | gb_free 6.1 | wall 28295
KL Stats: Epoch 86 Divergences: Uniform: 3.3088868928918616 Unigram: 2.6535470410553126
2022-01-28 14:53:04 | INFO | fairseq.trainer | begin training epoch 87
2022-01-28 14:53:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:58:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:58:32 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.423 | ppl 686.59 | wps 8641 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.054
2022-01-28 14:58:32 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-28 14:58:32 | INFO | train | epoch 087 | loss 5.92 | ppl 60.56 | wps 6353.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.622 | train_wall 303 | gb_free 6.1 | wall 28623
KL Stats: Epoch 87 Divergences: Uniform: 3.3201209414126978 Unigram: 2.6645423755400244
2022-01-28 14:58:32 | INFO | fairseq.trainer | begin training epoch 88
2022-01-28 14:58:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:01:05 | INFO | train_inner | epoch 088:     32 / 64 loss=5.907, ppl=60, wps=6217, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.62, train_wall=472, gb_free=6.1, wall=28776
2022-01-28 15:03:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:04:01 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.445 | ppl 696.97 | wps 8607.2 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.054
2022-01-28 15:04:01 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-28 15:04:01 | INFO | train | epoch 088 | loss 5.896 | ppl 59.57 | wps 6352 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.61 | train_wall 303 | gb_free 6.1 | wall 28952
KL Stats: Epoch 88 Divergences: Uniform: 3.328863018626803 Unigram: 2.6763409334344437
2022-01-28 15:04:01 | INFO | fairseq.trainer | begin training epoch 89
2022-01-28 15:04:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:09:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:09:30 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.461 | ppl 704.54 | wps 8637.9 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.054
2022-01-28 15:09:30 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-28 15:09:30 | INFO | train | epoch 089 | loss 5.879 | ppl 58.85 | wps 6351.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.624 | train_wall 303 | gb_free 6.1 | wall 29281
KL Stats: Epoch 89 Divergences: Uniform: 3.3391316200540797 Unigram: 2.682290320072606
2022-01-28 15:09:30 | INFO | fairseq.trainer | begin training epoch 90
2022-01-28 15:09:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:09:49 | INFO | train_inner | epoch 090:      4 / 64 loss=5.889, ppl=59.27, wps=6217.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.618, train_wall=472, gb_free=6.1, wall=29300
2022-01-28 15:14:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:14:59 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.477 | ppl 712.84 | wps 8643 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.054
2022-01-28 15:14:59 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-28 15:14:59 | INFO | train | epoch 090 | loss 5.857 | ppl 57.95 | wps 6356.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.61 | train_wall 302 | gb_free 6.1 | wall 29610
KL Stats: Epoch 90 Divergences: Uniform: 3.3420386864670215 Unigram: 2.6883023084665054
2022-01-28 15:14:59 | INFO | fairseq.trainer | begin training epoch 91
2022-01-28 15:14:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:18:09 | INFO | train_inner | epoch 091:     40 / 64 loss=5.839, ppl=57.25, wps=6534.9, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.616, train_wall=473, gb_free=6.1, wall=29800
2022-01-28 15:20:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:20:28 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.492 | ppl 720.29 | wps 8607.9 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.054
2022-01-28 15:20:28 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-28 15:20:28 | INFO | train | epoch 091 | loss 5.837 | ppl 57.15 | wps 6349.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.626 | train_wall 303 | gb_free 6.1 | wall 29939
KL Stats: Epoch 91 Divergences: Uniform: 3.346432030809439 Unigram: 2.705591104002037
2022-01-28 15:20:28 | INFO | fairseq.trainer | begin training epoch 92
2022-01-28 15:20:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:25:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:25:56 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.488 | ppl 718.24 | wps 8651.9 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.054
2022-01-28 15:25:56 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-28 15:25:56 | INFO | train | epoch 092 | loss 5.817 | ppl 56.37 | wps 6353.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.635 | train_wall 303 | gb_free 6.1 | wall 30267
KL Stats: Epoch 92 Divergences: Uniform: 3.359667861403437 Unigram: 2.7126769986726207
2022-01-28 15:25:56 | INFO | fairseq.trainer | begin training epoch 93
2022-01-28 15:25:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:26:54 | INFO | train_inner | epoch 093:     12 / 64 loss=5.826, ppl=56.75, wps=6217.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.631, train_wall=472, gb_free=6.1, wall=30324
2022-01-28 15:31:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:31:25 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.472 | ppl 710.14 | wps 8610.9 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.054
2022-01-28 15:31:25 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-28 15:31:25 | INFO | train | epoch 093 | loss 5.799 | ppl 55.68 | wps 6347.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.642 | train_wall 303 | gb_free 6.1 | wall 30596
KL Stats: Epoch 93 Divergences: Uniform: 3.366380650257461 Unigram: 2.722829256066205
2022-01-28 15:31:25 | INFO | fairseq.trainer | begin training epoch 94
2022-01-28 15:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:35:14 | INFO | train_inner | epoch 094:     48 / 64 loss=5.785, ppl=55.13, wps=6533.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.638, train_wall=474, gb_free=6.1, wall=30825
2022-01-28 15:36:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:36:54 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.551 | ppl 750.18 | wps 8644.4 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.054
2022-01-28 15:36:54 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-28 15:36:54 | INFO | train | epoch 094 | loss 5.777 | ppl 54.85 | wps 6356 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.631 | train_wall 302 | gb_free 6.1 | wall 30925
KL Stats: Epoch 94 Divergences: Uniform: 3.362543027558646 Unigram: 2.733604474010544
2022-01-28 15:36:54 | INFO | fairseq.trainer | begin training epoch 95
2022-01-28 15:36:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:41:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:42:23 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.585 | ppl 768.21 | wps 8623.6 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.054
2022-01-28 15:42:23 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-28 15:42:23 | INFO | train | epoch 095 | loss 5.761 | ppl 54.21 | wps 6351 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.644 | train_wall 303 | gb_free 6.1 | wall 31254
KL Stats: Epoch 95 Divergences: Uniform: 3.3648366972546127 Unigram: 2.7426107938269535
2022-01-28 15:42:23 | INFO | fairseq.trainer | begin training epoch 96
2022-01-28 15:42:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:43:58 | INFO | train_inner | epoch 096:     20 / 64 loss=5.759, ppl=54.16, wps=6217.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.642, train_wall=472, gb_free=6.1, wall=31349
2022-01-28 15:47:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:47:52 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.48 | ppl 713.87 | wps 8627.3 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.054
2022-01-28 15:47:52 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-28 15:47:52 | INFO | train | epoch 096 | loss 5.743 | ppl 53.54 | wps 6353.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.647 | train_wall 303 | gb_free 6.1 | wall 31583
KL Stats: Epoch 96 Divergences: Uniform: 3.3800437316014085 Unigram: 2.751162020619372
2022-01-28 15:47:52 | INFO | fairseq.trainer | begin training epoch 97
2022-01-28 15:47:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:52:18 | INFO | train_inner | epoch 097:     56 / 64 loss=5.737, ppl=53.35, wps=6533.7, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.656, train_wall=474, gb_free=6.1, wall=31849
2022-01-28 15:52:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:53:21 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.518 | ppl 732.94 | wps 8614.2 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.054
2022-01-28 15:53:21 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-28 15:53:21 | INFO | train | epoch 097 | loss 5.727 | ppl 52.97 | wps 6348 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.658 | train_wall 303 | gb_free 6.1 | wall 31912
KL Stats: Epoch 97 Divergences: Uniform: 3.391108665157306 Unigram: 2.764137367645582
2022-01-28 15:53:21 | INFO | fairseq.trainer | begin training epoch 98
2022-01-28 15:53:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:58:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:58:49 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.573 | ppl 761.52 | wps 8626.9 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.054
2022-01-28 15:58:49 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-28 15:58:49 | INFO | train | epoch 098 | loss 5.706 | ppl 52.2 | wps 6357.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.645 | train_wall 302 | gb_free 6.1 | wall 32240
KL Stats: Epoch 98 Divergences: Uniform: 3.3864385456283306 Unigram: 2.7681230419326557
2022-01-28 15:58:49 | INFO | fairseq.trainer | begin training epoch 99
2022-01-28 15:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:01:02 | INFO | train_inner | epoch 099:     28 / 64 loss=5.698, ppl=51.92, wps=6218.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.653, train_wall=472, gb_free=6.1, wall=32373
2022-01-28 16:03:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:04:18 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.532 | ppl 740.33 | wps 8622.6 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.054
2022-01-28 16:04:18 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-28 16:04:18 | INFO | train | epoch 099 | loss 5.691 | ppl 51.65 | wps 6348.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.679 | train_wall 303 | gb_free 6.1 | wall 32569
KL Stats: Epoch 99 Divergences: Uniform: 3.4005893149801323 Unigram: 2.7756335809396946
2022-01-28 16:04:18 | INFO | fairseq.trainer | begin training epoch 100
2022-01-28 16:04:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:09:22 | INFO | train_inner | epoch 100:     64 / 64 loss=5.693, ppl=51.75, wps=6532, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.685, train_wall=472, gb_free=6.1, wall=32873
2022-01-28 16:09:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:09:47 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.509 | ppl 728.75 | wps 8631.6 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.054
2022-01-28 16:09:47 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-28 16:09:47 | INFO | train | epoch 100 | loss 5.677 | ppl 51.15 | wps 6352.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.683 | train_wall 303 | gb_free 6.1 | wall 32898
KL Stats: Epoch 100 Divergences: Uniform: 3.396643983592894 Unigram: 2.7846126833652
2022-01-28 16:09:47 | INFO | fairseq.trainer | begin training epoch 101
2022-01-28 16:09:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:14:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:15:15 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.549 | ppl 748.97 | wps 8645.3 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.054
2022-01-28 16:15:15 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-28 16:15:15 | INFO | train | epoch 101 | loss 5.656 | ppl 50.43 | wps 6357.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.677 | train_wall 302 | gb_free 6.1 | wall 33226
KL Stats: Epoch 101 Divergences: Uniform: 3.411001627676973 Unigram: 2.796186556140952
2022-01-28 16:15:15 | INFO | fairseq.trainer | begin training epoch 102
2022-01-28 16:15:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:18:07 | INFO | train_inner | epoch 102:     36 / 64 loss=5.643, ppl=49.96, wps=6222.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.675, train_wall=473, gb_free=6.1, wall=33398
2022-01-28 16:20:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:20:44 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.601 | ppl 776.32 | wps 8645.3 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.054
2022-01-28 16:20:44 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-28 16:20:44 | INFO | train | epoch 102 | loss 5.643 | ppl 49.98 | wps 6352 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.682 | train_wall 303 | gb_free 6.1 | wall 33555
KL Stats: Epoch 102 Divergences: Uniform: 3.4017606511731917 Unigram: 2.7992471445416323
2022-01-28 16:20:44 | INFO | fairseq.trainer | begin training epoch 103
2022-01-28 16:20:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:25:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:26:13 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.585 | ppl 767.94 | wps 8618.7 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.054
2022-01-28 16:26:13 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-28 16:26:13 | INFO | train | epoch 103 | loss 5.626 | ppl 49.39 | wps 6347.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.672 | train_wall 303 | gb_free 6.1 | wall 33884
KL Stats: Epoch 103 Divergences: Uniform: 3.414574122883932 Unigram: 2.808914877391634
2022-01-28 16:26:13 | INFO | fairseq.trainer | begin training epoch 104
2022-01-28 16:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:26:51 | INFO | train_inner | epoch 104:      8 / 64 loss=5.634, ppl=49.66, wps=6214.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.68, train_wall=472, gb_free=6.1, wall=33922
2022-01-28 16:31:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:31:42 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.524 | ppl 736.17 | wps 8645.3 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.054
2022-01-28 16:31:42 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-28 16:31:42 | INFO | train | epoch 104 | loss 5.614 | ppl 48.96 | wps 6354.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.687 | train_wall 303 | gb_free 6.1 | wall 34213
KL Stats: Epoch 104 Divergences: Uniform: 3.412222233868365 Unigram: 2.82201469584777
2022-01-28 16:31:42 | INFO | fairseq.trainer | begin training epoch 105
2022-01-28 16:31:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:35:11 | INFO | train_inner | epoch 105:     44 / 64 loss=5.601, ppl=48.53, wps=6536.9, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.688, train_wall=473, gb_free=6.1, wall=34422
2022-01-28 16:36:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:37:10 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.586 | ppl 768.81 | wps 8630 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.054
2022-01-28 16:37:10 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-28 16:37:10 | INFO | train | epoch 105 | loss 5.597 | ppl 48.39 | wps 6356.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.694 | train_wall 302 | gb_free 6.1 | wall 34541
KL Stats: Epoch 105 Divergences: Uniform: 3.4141167492745876 Unigram: 2.8257277669030403
2022-01-28 16:37:10 | INFO | fairseq.trainer | begin training epoch 106
2022-01-28 16:37:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:42:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:42:39 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.574 | ppl 762.02 | wps 8610.8 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.054
2022-01-28 16:42:39 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-28 16:42:39 | INFO | train | epoch 106 | loss 5.581 | ppl 47.88 | wps 6352.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.693 | train_wall 303 | gb_free 6.1 | wall 34870
KL Stats: Epoch 106 Divergences: Uniform: 3.4199995878162883 Unigram: 2.835846505480452
2022-01-28 16:42:39 | INFO | fairseq.trainer | begin training epoch 107
2022-01-28 16:42:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:43:56 | INFO | train_inner | epoch 107:     16 / 64 loss=5.585, ppl=47.99, wps=6217.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.694, train_wall=472, gb_free=6.1, wall=34946
2022-01-28 16:47:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:48:08 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.602 | ppl 777.13 | wps 8616.2 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.054
2022-01-28 16:48:08 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-28 16:48:08 | INFO | train | epoch 107 | loss 5.566 | ppl 47.38 | wps 6355 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.691 | train_wall 302 | gb_free 6.1 | wall 35199
KL Stats: Epoch 107 Divergences: Uniform: 3.424786346941803 Unigram: 2.844889465142397
2022-01-28 16:48:08 | INFO | fairseq.trainer | begin training epoch 108
2022-01-28 16:48:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:52:16 | INFO | train_inner | epoch 108:     52 / 64 loss=5.562, ppl=47.23, wps=6536, ups=0.2, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.697, train_wall=473, gb_free=6.1, wall=35447
2022-01-28 16:53:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:53:37 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.604 | ppl 778.32 | wps 8608.4 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.054
2022-01-28 16:53:37 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-28 16:53:37 | INFO | train | epoch 108 | loss 5.554 | ppl 46.99 | wps 6348.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.7 | train_wall 303 | gb_free 6.1 | wall 35528
KL Stats: Epoch 108 Divergences: Uniform: 3.4277322708211155 Unigram: 2.8512926819162585
2022-01-28 16:53:37 | INFO | fairseq.trainer | begin training epoch 109
2022-01-28 16:53:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:58:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:59:06 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.646 | ppl 801.4 | wps 8615.5 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.054
2022-01-28 16:59:06 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-28 16:59:06 | INFO | train | epoch 109 | loss 5.54 | ppl 46.53 | wps 6355.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.713 | train_wall 302 | gb_free 6.1 | wall 35857
KL Stats: Epoch 109 Divergences: Uniform: 3.4337679430796104 Unigram: 2.861003841128394
2022-01-28 16:59:06 | INFO | fairseq.trainer | begin training epoch 110
2022-01-28 16:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:01:00 | INFO | train_inner | epoch 110:     24 / 64 loss=5.535, ppl=46.35, wps=6217.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.717, train_wall=472, gb_free=6.1, wall=35971
2022-01-28 17:04:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:04:34 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 9.671 | ppl 815.22 | wps 8649.7 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.054
2022-01-28 17:04:34 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-28 17:04:34 | INFO | train | epoch 110 | loss 5.527 | ppl 46.12 | wps 6350.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.716 | train_wall 303 | gb_free 6.1 | wall 36185
KL Stats: Epoch 110 Divergences: Uniform: 3.438870571371824 Unigram: 2.869542342845038
2022-01-28 17:04:34 | INFO | fairseq.trainer | begin training epoch 111
2022-01-28 17:04:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:09:20 | INFO | train_inner | epoch 111:     60 / 64 loss=5.525, ppl=46.05, wps=6533.7, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.71, train_wall=474, gb_free=6.1, wall=36471
2022-01-28 17:09:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:10:03 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.634 | ppl 794.4 | wps 8610.2 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.054
2022-01-28 17:10:03 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-28 17:10:03 | INFO | train | epoch 111 | loss 5.513 | ppl 45.66 | wps 6352.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.719 | train_wall 303 | gb_free 6.1 | wall 36514
KL Stats: Epoch 111 Divergences: Uniform: 3.440538400869289 Unigram: 2.879211999552016
2022-01-28 17:10:03 | INFO | fairseq.trainer | begin training epoch 112
2022-01-28 17:10:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:15:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:15:32 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 9.67 | ppl 814.4 | wps 8608.7 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.054
2022-01-28 17:15:32 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-28 17:15:32 | INFO | train | epoch 112 | loss 5.501 | ppl 45.27 | wps 6351.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.731 | train_wall 303 | gb_free 6.1 | wall 36843
KL Stats: Epoch 112 Divergences: Uniform: 3.4380914562816254 Unigram: 2.884078056718104
2022-01-28 17:15:32 | INFO | fairseq.trainer | begin training epoch 113
2022-01-28 17:15:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:18:04 | INFO | train_inner | epoch 113:     32 / 64 loss=5.489, ppl=44.91, wps=6217.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.728, train_wall=472, gb_free=6.1, wall=36995
2022-01-28 17:20:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:21:01 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 9.64 | ppl 797.82 | wps 8615.7 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.054
2022-01-28 17:21:01 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-28 17:21:01 | INFO | train | epoch 113 | loss 5.486 | ppl 44.81 | wps 6351.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.727 | train_wall 303 | gb_free 6.1 | wall 37172
KL Stats: Epoch 113 Divergences: Uniform: 3.4563702016314877 Unigram: 2.8934916781151605
2022-01-28 17:21:01 | INFO | fairseq.trainer | begin training epoch 114
2022-01-28 17:21:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:26:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:26:30 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 9.639 | ppl 797.18 | wps 8641.7 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.054
2022-01-28 17:26:30 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-28 17:26:30 | INFO | train | epoch 114 | loss 5.473 | ppl 44.43 | wps 6353.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.74 | train_wall 303 | gb_free 6.1 | wall 37501
KL Stats: Epoch 114 Divergences: Uniform: 3.445575002136095 Unigram: 2.8987134996118726
2022-01-28 17:26:30 | INFO | fairseq.trainer | begin training epoch 115
2022-01-28 17:26:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:26:49 | INFO | train_inner | epoch 115:      4 / 64 loss=5.485, ppl=44.8, wps=6215.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.736, train_wall=472, gb_free=6.1, wall=37520
2022-01-28 17:31:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:31:59 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 9.646 | ppl 801.18 | wps 8614.1 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.054
2022-01-28 17:31:59 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-28 17:31:59 | INFO | train | epoch 115 | loss 5.462 | ppl 44.08 | wps 6350 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.742 | train_wall 303 | gb_free 6.1 | wall 37830
KL Stats: Epoch 115 Divergences: Uniform: 3.4536051273980886 Unigram: 2.9068785034387945
2022-01-28 17:31:59 | INFO | fairseq.trainer | begin training epoch 116
2022-01-28 17:31:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:35:09 | INFO | train_inner | epoch 116:     40 / 64 loss=5.449, ppl=43.68, wps=6534.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.735, train_wall=473, gb_free=6.1, wall=38020
2022-01-28 17:37:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:37:27 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 9.631 | ppl 792.81 | wps 8615.2 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.054
2022-01-28 17:37:27 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-28 17:37:27 | INFO | train | epoch 116 | loss 5.45 | ppl 43.71 | wps 6352.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.734 | train_wall 303 | gb_free 6.1 | wall 38158
KL Stats: Epoch 116 Divergences: Uniform: 3.4554784752980794 Unigram: 2.9071345284839127
2022-01-28 17:37:27 | INFO | fairseq.trainer | begin training epoch 117
2022-01-28 17:37:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:42:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:42:57 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 9.667 | ppl 812.81 | wps 8623.6 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.054
2022-01-28 17:42:57 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-28 17:42:57 | INFO | train | epoch 117 | loss 5.439 | ppl 43.37 | wps 6346.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.739 | train_wall 303 | gb_free 6.1 | wall 38487
KL Stats: Epoch 117 Divergences: Uniform: 3.458256197250847 Unigram: 2.920300537144085
2022-01-28 17:42:57 | INFO | fairseq.trainer | begin training epoch 118
2022-01-28 17:42:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:43:54 | INFO | train_inner | epoch 118:     12 / 64 loss=5.444, ppl=43.52, wps=6213.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.746, train_wall=473, gb_free=6.1, wall=38545
2022-01-28 17:48:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:48:25 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 9.701 | ppl 832.27 | wps 8618.6 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.054
2022-01-28 17:48:25 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-28 17:48:25 | INFO | train | epoch 118 | loss 5.425 | ppl 42.97 | wps 6350.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.75 | train_wall 303 | gb_free 6.1 | wall 38816
KL Stats: Epoch 118 Divergences: Uniform: 3.460193843562181 Unigram: 2.927435041373431
2022-01-28 17:48:25 | INFO | fairseq.trainer | begin training epoch 119
2022-01-28 17:48:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:52:14 | INFO | train_inner | epoch 119:     48 / 64 loss=5.416, ppl=42.69, wps=6532, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.747, train_wall=474, gb_free=6.1, wall=39045
2022-01-28 17:53:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:53:54 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 9.658 | ppl 807.92 | wps 8622.3 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.054
2022-01-28 17:53:54 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-28 17:53:54 | INFO | train | epoch 119 | loss 5.413 | ppl 42.62 | wps 6350.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.753 | train_wall 303 | gb_free 6.1 | wall 39145
KL Stats: Epoch 119 Divergences: Uniform: 3.465879873651639 Unigram: 2.9347767605550863
2022-01-28 17:53:54 | INFO | fairseq.trainer | begin training epoch 120
2022-01-28 17:53:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:58:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:59:23 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 9.676 | ppl 818.01 | wps 8635 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.054
2022-01-28 17:59:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-28 17:59:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint120.pt
2022-01-28 17:59:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint120.pt
2022-01-28 17:59:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint120.pt (epoch 120 @ 7680 updates, score 9.676) (writing took 3.6587070969399065 seconds)
2022-01-28 17:59:27 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-28 17:59:27 | INFO | train | epoch 120 | loss 5.403 | ppl 42.31 | wps 6284 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.762 | train_wall 302 | gb_free 6.1 | wall 39478
KL Stats: Epoch 120 Divergences: Uniform: 3.4740810728686893 Unigram: 2.9424672732075954
2022-01-28 17:59:27 | INFO | fairseq.trainer | begin training epoch 121
2022-01-28 17:59:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:01:02 | INFO | train_inner | epoch 121:     20 / 64 loss=5.404, ppl=42.35, wps=6175.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.76, train_wall=472, gb_free=6.1, wall=39573
2022-01-28 18:04:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:04:55 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 9.726 | ppl 846.83 | wps 8622.1 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.054
2022-01-28 18:04:55 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-28 18:04:55 | INFO | train | epoch 121 | loss 5.391 | ppl 41.97 | wps 6356.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.756 | train_wall 302 | gb_free 6.1 | wall 39806
KL Stats: Epoch 121 Divergences: Uniform: 3.477432337327899 Unigram: 2.9480178274687163
2022-01-28 18:04:55 | INFO | fairseq.trainer | begin training epoch 122
2022-01-28 18:04:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:09:22 | INFO | train_inner | epoch 122:     56 / 64 loss=5.39, ppl=41.92, wps=6536, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.765, train_wall=473, gb_free=6.1, wall=40073
2022-01-28 18:09:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:10:24 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 9.678 | ppl 819.38 | wps 8611.7 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.054
2022-01-28 18:10:24 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-28 18:10:24 | INFO | train | epoch 122 | loss 5.383 | ppl 41.72 | wps 6349.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.77 | train_wall 303 | gb_free 6.1 | wall 40135
KL Stats: Epoch 122 Divergences: Uniform: 3.4769598961511403 Unigram: 2.953091500972675
2022-01-28 18:10:24 | INFO | fairseq.trainer | begin training epoch 123
2022-01-28 18:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:15:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:15:53 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 9.715 | ppl 840.37 | wps 8618 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.054
2022-01-28 18:15:53 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-28 18:15:53 | INFO | train | epoch 123 | loss 5.37 | ppl 41.37 | wps 6351.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.766 | train_wall 303 | gb_free 6.1 | wall 40464
KL Stats: Epoch 123 Divergences: Uniform: 3.4792353291009936 Unigram: 2.962483429771183
2022-01-28 18:15:53 | INFO | fairseq.trainer | begin training epoch 124
2022-01-28 18:15:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:18:06 | INFO | train_inner | epoch 124:     28 / 64 loss=5.364, ppl=41.18, wps=6216.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.769, train_wall=472, gb_free=6.1, wall=40597
2022-01-28 18:20:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:21:22 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 9.72 | ppl 843.13 | wps 8612.7 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.054
2022-01-28 18:21:22 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-28 18:21:22 | INFO | train | epoch 124 | loss 5.36 | ppl 41.07 | wps 6351.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.78 | train_wall 303 | gb_free 6.1 | wall 40793
KL Stats: Epoch 124 Divergences: Uniform: 3.4696693962222462 Unigram: 2.9602221621442677
2022-01-28 18:21:22 | INFO | fairseq.trainer | begin training epoch 125
2022-01-28 18:21:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:26:25 | INFO | train_inner | epoch 125:     64 / 64 loss=5.363, ppl=41.16, wps=6531.6, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.787, train_wall=472, gb_free=6.1, wall=41096
2022-01-28 18:26:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:26:51 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 9.722 | ppl 844.35 | wps 8615.5 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.054
2022-01-28 18:26:51 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-28 18:26:51 | INFO | train | epoch 125 | loss 5.35 | ppl 40.77 | wps 6350.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.788 | train_wall 303 | gb_free 6.1 | wall 41122
KL Stats: Epoch 125 Divergences: Uniform: 3.4827572259170663 Unigram: 2.9752094507534874
2022-01-28 18:26:51 | INFO | fairseq.trainer | begin training epoch 126
2022-01-28 18:26:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:31:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:32:19 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 9.665 | ppl 811.72 | wps 8627.3 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.054
2022-01-28 18:32:19 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-28 18:32:19 | INFO | train | epoch 126 | loss 5.34 | ppl 40.5 | wps 6354.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.782 | train_wall 303 | gb_free 6.1 | wall 41450
KL Stats: Epoch 126 Divergences: Uniform: 3.489414884099101 Unigram: 2.9765113613841483
2022-01-28 18:32:19 | INFO | fairseq.trainer | begin training epoch 127
2022-01-28 18:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:35:11 | INFO | train_inner | epoch 127:     36 / 64 loss=5.328, ppl=40.18, wps=6220.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.8, train_wall=473, gb_free=6.1, wall=41622
2022-01-28 18:37:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:37:48 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 9.667 | ppl 813.04 | wps 8624.3 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.054
2022-01-28 18:37:48 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-28 18:37:48 | INFO | train | epoch 127 | loss 5.332 | ppl 40.27 | wps 6355.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.827 | train_wall 302 | gb_free 6.1 | wall 41779
KL Stats: Epoch 127 Divergences: Uniform: 3.4854280147560956 Unigram: 2.9821031181430264
2022-01-28 18:37:48 | INFO | fairseq.trainer | begin training epoch 128
2022-01-28 18:37:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:42:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:43:17 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 9.686 | ppl 823.74 | wps 8608.1 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.054
2022-01-28 18:43:17 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-28 18:43:17 | INFO | train | epoch 128 | loss 5.319 | ppl 39.92 | wps 6352.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.807 | train_wall 303 | gb_free 6.1 | wall 42108
KL Stats: Epoch 128 Divergences: Uniform: 3.483565836443776 Unigram: 2.986792680585432
2022-01-28 18:43:17 | INFO | fairseq.trainer | begin training epoch 129
2022-01-28 18:43:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:43:55 | INFO | train_inner | epoch 129:      8 / 64 loss=5.327, ppl=40.14, wps=6217.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.814, train_wall=472, gb_free=6.1, wall=42146
2022-01-28 18:48:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:48:46 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 9.702 | ppl 832.75 | wps 8622.7 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.054
2022-01-28 18:48:46 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-28 18:48:46 | INFO | train | epoch 129 | loss 5.31 | ppl 39.68 | wps 6351.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.804 | train_wall 303 | gb_free 6.1 | wall 42437
KL Stats: Epoch 129 Divergences: Uniform: 3.48885055949198 Unigram: 2.995351141207069
2022-01-28 18:48:46 | INFO | fairseq.trainer | begin training epoch 130
2022-01-28 18:48:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:52:15 | INFO | train_inner | epoch 130:     44 / 64 loss=5.299, ppl=39.36, wps=6534.2, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.792, train_wall=474, gb_free=6.1, wall=42646
2022-01-28 18:53:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:54:15 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 9.751 | ppl 861.8 | wps 8615.9 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.054
2022-01-28 18:54:15 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-28 18:54:15 | INFO | train | epoch 130 | loss 5.3 | ppl 39.39 | wps 6351.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.795 | train_wall 303 | gb_free 6.1 | wall 42766
KL Stats: Epoch 130 Divergences: Uniform: 3.4883514233710655 Unigram: 3.000036638152372
2022-01-28 18:54:15 | INFO | fairseq.trainer | begin training epoch 131
2022-01-28 18:54:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:59:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:59:43 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 9.701 | ppl 832.52 | wps 8642.9 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.054
2022-01-28 18:59:43 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-28 18:59:43 | INFO | train | epoch 131 | loss 5.293 | ppl 39.21 | wps 6353.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.83 | train_wall 303 | gb_free 6.1 | wall 43094
KL Stats: Epoch 131 Divergences: Uniform: 3.4898214826994454 Unigram: 3.0037169947499334
2022-01-28 18:59:43 | INFO | fairseq.trainer | begin training epoch 132
2022-01-28 18:59:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:01:00 | INFO | train_inner | epoch 132:     16 / 64 loss=5.296, ppl=39.28, wps=6217.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.826, train_wall=472, gb_free=6.1, wall=43171
2022-01-28 19:04:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:05:12 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 9.713 | ppl 839.49 | wps 8635.3 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.054
2022-01-28 19:05:12 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-28 19:05:12 | INFO | train | epoch 132 | loss 5.281 | ppl 38.87 | wps 6352.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.824 | train_wall 303 | gb_free 6.1 | wall 43423
KL Stats: Epoch 132 Divergences: Uniform: 3.499473278330952 Unigram: 3.0128374187564297
2022-01-28 19:05:12 | INFO | fairseq.trainer | begin training epoch 133
2022-01-28 19:05:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:09:20 | INFO | train_inner | epoch 133:     52 / 64 loss=5.275, ppl=38.73, wps=6533.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.829, train_wall=474, gb_free=6.1, wall=43671
2022-01-28 19:10:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:10:41 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 9.746 | ppl 858.6 | wps 8616 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.054
2022-01-28 19:10:41 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-28 19:10:41 | INFO | train | epoch 133 | loss 5.272 | ppl 38.63 | wps 6350.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.828 | train_wall 303 | gb_free 6.1 | wall 43752
KL Stats: Epoch 133 Divergences: Uniform: 3.5064608852862253 Unigram: 3.020975193763594
2022-01-28 19:10:41 | INFO | fairseq.trainer | begin training epoch 134
2022-01-28 19:10:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:15:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:16:10 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 9.783 | ppl 881.12 | wps 8628.1 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.054
2022-01-28 19:16:10 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-28 19:16:10 | INFO | train | epoch 134 | loss 5.263 | ppl 38.41 | wps 6351.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.852 | train_wall 303 | gb_free 6.1 | wall 44081
KL Stats: Epoch 134 Divergences: Uniform: 3.4966177510728427 Unigram: 3.0247530619726675
2022-01-28 19:16:10 | INFO | fairseq.trainer | begin training epoch 135
2022-01-28 19:16:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:18:04 | INFO | train_inner | epoch 135:     24 / 64 loss=5.263, ppl=38.4, wps=6215.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.851, train_wall=472, gb_free=6.1, wall=44195
2022-01-28 19:21:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:21:39 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 9.744 | ppl 857.72 | wps 8619.4 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.054
2022-01-28 19:21:39 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-28 19:21:39 | INFO | train | epoch 135 | loss 5.254 | ppl 38.16 | wps 6352.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.833 | train_wall 303 | gb_free 6.1 | wall 44410
KL Stats: Epoch 135 Divergences: Uniform: 3.4988148996579187 Unigram: 3.0297441040204993
2022-01-28 19:21:39 | INFO | fairseq.trainer | begin training epoch 136
2022-01-28 19:21:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:26:24 | INFO | train_inner | epoch 136:     60 / 64 loss=5.254, ppl=38.16, wps=6536.5, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.835, train_wall=473, gb_free=6.1, wall=44695
2022-01-28 19:26:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:27:07 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 9.766 | ppl 870.45 | wps 8646.7 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.054
2022-01-28 19:27:07 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-28 19:27:07 | INFO | train | epoch 136 | loss 5.245 | ppl 37.93 | wps 6354.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.849 | train_wall 303 | gb_free 6.1 | wall 44738
KL Stats: Epoch 136 Divergences: Uniform: 3.499886201214272 Unigram: 3.028639030520037
2022-01-28 19:27:07 | INFO | fairseq.trainer | begin training epoch 137
2022-01-28 19:27:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:32:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:32:36 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 9.784 | ppl 881.53 | wps 8618.8 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.054
2022-01-28 19:32:36 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-28 19:32:36 | INFO | train | epoch 137 | loss 5.238 | ppl 37.75 | wps 6352.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.856 | train_wall 303 | gb_free 6.1 | wall 45067
KL Stats: Epoch 137 Divergences: Uniform: 3.505887587759371 Unigram: 3.0398865277323783
2022-01-28 19:32:36 | INFO | fairseq.trainer | begin training epoch 138
2022-01-28 19:32:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:35:09 | INFO | train_inner | epoch 138:     32 / 64 loss=5.23, ppl=37.52, wps=6217.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.845, train_wall=472, gb_free=6.1, wall=45220
2022-01-28 19:37:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:38:05 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 9.841 | ppl 917.07 | wps 8626.8 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.054
2022-01-28 19:38:05 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-28 19:38:05 | INFO | train | epoch 138 | loss 5.228 | ppl 37.47 | wps 6351.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.846 | train_wall 303 | gb_free 6.1 | wall 45396
KL Stats: Epoch 138 Divergences: Uniform: 3.505897939760739 Unigram: 3.0437710851338298
2022-01-28 19:38:05 | INFO | fairseq.trainer | begin training epoch 139
2022-01-28 19:38:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:43:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:43:34 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 9.757 | ppl 865.16 | wps 8615.9 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.054
2022-01-28 19:43:34 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-28 19:43:34 | INFO | train | epoch 139 | loss 5.219 | ppl 37.25 | wps 6355.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.856 | train_wall 302 | gb_free 6.1 | wall 45725
KL Stats: Epoch 139 Divergences: Uniform: 3.510375674756114 Unigram: 3.0521766159516464
2022-01-28 19:43:34 | INFO | fairseq.trainer | begin training epoch 140
2022-01-28 19:43:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:43:53 | INFO | train_inner | epoch 140:      4 / 64 loss=5.226, ppl=37.43, wps=6219.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.86, train_wall=472, gb_free=6.1, wall=45744
2022-01-28 19:48:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:49:03 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 9.762 | ppl 868.16 | wps 8639.2 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.054
2022-01-28 19:49:03 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-28 19:49:03 | INFO | train | epoch 140 | loss 5.213 | ppl 37.09 | wps 6349.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.887 | train_wall 303 | gb_free 6.1 | wall 46054
KL Stats: Epoch 140 Divergences: Uniform: 3.5067048642141154 Unigram: 3.0560036850568193
2022-01-28 19:49:03 | INFO | fairseq.trainer | begin training epoch 141
2022-01-28 19:49:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:52:13 | INFO | train_inner | epoch 141:     40 / 64 loss=5.204, ppl=36.87, wps=6530.9, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.879, train_wall=474, gb_free=6.1, wall=46244
2022-01-28 19:54:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:54:32 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 9.805 | ppl 894.58 | wps 8614.6 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.054
2022-01-28 19:54:32 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-28 19:54:32 | INFO | train | epoch 141 | loss 5.203 | ppl 36.82 | wps 6349.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.857 | train_wall 303 | gb_free 6.1 | wall 46383
KL Stats: Epoch 141 Divergences: Uniform: 3.5108370383051413 Unigram: 3.0646010664268117
2022-01-28 19:54:32 | INFO | fairseq.trainer | begin training epoch 142
2022-01-28 19:54:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:59:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:00:00 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 9.777 | ppl 877.1 | wps 8644.5 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.054
2022-01-28 20:00:00 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-28 20:00:00 | INFO | train | epoch 142 | loss 5.195 | ppl 36.62 | wps 6351.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.889 | train_wall 303 | gb_free 6.1 | wall 46711
KL Stats: Epoch 142 Divergences: Uniform: 3.5136118428314522 Unigram: 3.0630262311807592
2022-01-28 20:00:00 | INFO | fairseq.trainer | begin training epoch 143
2022-01-28 20:00:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:00:58 | INFO | train_inner | epoch 143:     12 / 64 loss=5.196, ppl=36.66, wps=6216.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.879, train_wall=472, gb_free=6.1, wall=46768
2022-01-28 20:05:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:05:29 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 9.791 | ppl 886.08 | wps 8648.5 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.054
2022-01-28 20:05:29 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-28 20:05:29 | INFO | train | epoch 143 | loss 5.188 | ppl 36.46 | wps 6353.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.882 | train_wall 303 | gb_free 6.1 | wall 47040
KL Stats: Epoch 143 Divergences: Uniform: 3.519487043936095 Unigram: 3.0682347577463718
2022-01-28 20:05:29 | INFO | fairseq.trainer | begin training epoch 144
2022-01-28 20:05:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:09:18 | INFO | train_inner | epoch 144:     48 / 64 loss=5.185, ppl=36.37, wps=6533.5, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.886, train_wall=474, gb_free=6.1, wall=47269
2022-01-28 20:10:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:10:58 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 9.839 | ppl 915.96 | wps 8626.4 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.054
2022-01-28 20:10:58 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-28 20:10:58 | INFO | train | epoch 144 | loss 5.182 | ppl 36.3 | wps 6349.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.893 | train_wall 303 | gb_free 6.1 | wall 47369
KL Stats: Epoch 144 Divergences: Uniform: 3.508259018103493 Unigram: 3.072096662631418
2022-01-28 20:10:58 | INFO | fairseq.trainer | begin training epoch 145
2022-01-28 20:10:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:16:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:16:27 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 9.767 | ppl 871.56 | wps 8615.2 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.054
2022-01-28 20:16:27 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-28 20:16:27 | INFO | train | epoch 145 | loss 5.175 | ppl 36.13 | wps 6352.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.925 | train_wall 303 | gb_free 6.1 | wall 47698
KL Stats: Epoch 145 Divergences: Uniform: 3.517567309812604 Unigram: 3.0765140805834936
2022-01-28 20:16:27 | INFO | fairseq.trainer | begin training epoch 146
2022-01-28 20:16:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:18:02 | INFO | train_inner | epoch 146:     20 / 64 loss=5.172, ppl=36.04, wps=6217.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.916, train_wall=472, gb_free=6.1, wall=47793
2022-01-28 20:21:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:21:56 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 9.814 | ppl 900 | wps 8628.6 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.054
2022-01-28 20:21:56 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-28 20:21:56 | INFO | train | epoch 146 | loss 5.163 | ppl 35.83 | wps 6352.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.887 | train_wall 303 | gb_free 6.1 | wall 48027
KL Stats: Epoch 146 Divergences: Uniform: 3.5160031876350266 Unigram: 3.0837482398634637
2022-01-28 20:21:56 | INFO | fairseq.trainer | begin training epoch 147
2022-01-28 20:21:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:26:22 | INFO | train_inner | epoch 147:     56 / 64 loss=5.165, ppl=35.87, wps=6534.7, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.89, train_wall=473, gb_free=6.1, wall=48293
2022-01-28 20:26:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:27:24 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 9.834 | ppl 912.5 | wps 8627.9 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.054
2022-01-28 20:27:24 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-28 20:27:24 | INFO | train | epoch 147 | loss 5.156 | ppl 35.65 | wps 6353.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.899 | train_wall 303 | gb_free 6.1 | wall 48355
KL Stats: Epoch 147 Divergences: Uniform: 3.5148577663668834 Unigram: 3.090142846689508
2022-01-28 20:27:24 | INFO | fairseq.trainer | begin training epoch 148
2022-01-28 20:27:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:32:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:32:53 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 9.794 | ppl 887.66 | wps 8622.3 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.054
2022-01-28 20:32:53 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-28 20:32:53 | INFO | train | epoch 148 | loss 5.149 | ppl 35.48 | wps 6354 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.915 | train_wall 303 | gb_free 6.1 | wall 48684
KL Stats: Epoch 148 Divergences: Uniform: 3.516777707373784 Unigram: 3.0937713812681182
2022-01-28 20:32:53 | INFO | fairseq.trainer | begin training epoch 149
2022-01-28 20:32:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:35:06 | INFO | train_inner | epoch 149:     28 / 64 loss=5.145, ppl=35.38, wps=6218.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.911, train_wall=472, gb_free=6.1, wall=48817
2022-01-28 20:37:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:38:22 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 9.834 | ppl 912.89 | wps 8616.9 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.054
2022-01-28 20:38:22 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-28 20:38:22 | INFO | train | epoch 149 | loss 5.144 | ppl 35.36 | wps 6353.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.934 | train_wall 303 | gb_free 6.1 | wall 49013
KL Stats: Epoch 149 Divergences: Uniform: 3.5262942743788175 Unigram: 3.0990534586426
2022-01-28 20:38:22 | INFO | fairseq.trainer | begin training epoch 150
2022-01-28 20:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:43:25 | INFO | train_inner | epoch 150:     64 / 64 loss=5.144, ppl=35.37, wps=6535.3, ups=0.2, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.933, train_wall=472, gb_free=6.1, wall=49316
2022-01-28 20:43:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:43:50 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 9.836 | ppl 913.65 | wps 8647.3 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.054
2022-01-28 20:43:50 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-28 20:43:50 | INFO | train | epoch 150 | loss 5.134 | ppl 35.11 | wps 6354.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.919 | train_wall 303 | gb_free 6.1 | wall 49341
KL Stats: Epoch 150 Divergences: Uniform: 3.5209956298232132 Unigram: 3.0999525057914994
2022-01-28 20:43:50 | INFO | fairseq.trainer | begin training epoch 151
2022-01-28 20:43:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:48:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:49:19 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 9.858 | ppl 928.17 | wps 8623 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.054
2022-01-28 20:49:19 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-28 20:49:19 | INFO | train | epoch 151 | loss 5.129 | ppl 35 | wps 6349.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.947 | train_wall 303 | gb_free 6.1 | wall 49670
KL Stats: Epoch 151 Divergences: Uniform: 3.5252197327425465 Unigram: 3.1058732176483126
2022-01-28 20:49:19 | INFO | fairseq.trainer | begin training epoch 152
2022-01-28 20:49:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:52:11 | INFO | train_inner | epoch 152:     36 / 64 loss=5.116, ppl=34.69, wps=6217.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.95, train_wall=474, gb_free=6.1, wall=49842
2022-01-28 20:54:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:54:48 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 9.809 | ppl 897.16 | wps 8616.6 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.054
2022-01-28 20:54:48 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-28 20:54:48 | INFO | train | epoch 152 | loss 5.122 | ppl 34.82 | wps 6350.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 0.956 | train_wall 303 | gb_free 6.1 | wall 49999
KL Stats: Epoch 152 Divergences: Uniform: 3.525567796989065 Unigram: 3.1087185055004243
2022-01-28 20:54:48 | INFO | fairseq.trainer | begin training epoch 153
2022-01-28 20:54:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:59:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:00:17 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 9.797 | ppl 889.8 | wps 8616.2 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.054
2022-01-28 21:00:17 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-01-28 21:00:17 | INFO | train | epoch 153 | loss 5.112 | ppl 34.59 | wps 6350.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.925 | train_wall 303 | gb_free 6.1 | wall 50328
KL Stats: Epoch 153 Divergences: Uniform: 3.530383210577967 Unigram: 3.1144793856900583
2022-01-28 21:00:17 | INFO | fairseq.trainer | begin training epoch 154
2022-01-28 21:00:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:00:55 | INFO | train_inner | epoch 154:      8 / 64 loss=5.121, ppl=34.8, wps=6215.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.934, train_wall=472, gb_free=6.1, wall=50366
2022-01-28 21:05:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:05:46 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 9.894 | ppl 951.26 | wps 8640.4 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.054
2022-01-28 21:05:46 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-01-28 21:05:46 | INFO | train | epoch 154 | loss 5.107 | ppl 34.47 | wps 6356.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 0.95 | train_wall 302 | gb_free 6.1 | wall 50657
KL Stats: Epoch 154 Divergences: Uniform: 3.537826505915832 Unigram: 3.1173730797096724
2022-01-28 21:05:46 | INFO | fairseq.trainer | begin training epoch 155
2022-01-28 21:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:09:15 | INFO | train_inner | epoch 155:     44 / 64 loss=5.099, ppl=34.27, wps=6536.3, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=0.955, train_wall=473, gb_free=6.1, wall=50866
2022-01-28 21:10:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:11:15 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 9.851 | ppl 923.51 | wps 8619.5 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.054
2022-01-28 21:11:15 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-01-28 21:11:15 | INFO | train | epoch 155 | loss 5.101 | ppl 34.32 | wps 6350.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 0.972 | train_wall 303 | gb_free 6.1 | wall 50986
KL Stats: Epoch 155 Divergences: Uniform: 3.53044395207618 Unigram: 3.1295151985649317
2022-01-28 21:11:15 | INFO | fairseq.trainer | begin training epoch 156
2022-01-28 21:11:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:16:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:16:43 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 9.842 | ppl 917.56 | wps 8631 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.054
2022-01-28 21:16:43 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-01-28 21:16:43 | INFO | train | epoch 156 | loss 5.094 | ppl 34.15 | wps 6354.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 0.985 | train_wall 303 | gb_free 6.1 | wall 51314
KL Stats: Epoch 156 Divergences: Uniform: 3.5351552859550575 Unigram: 3.125471056592343
2022-01-28 21:16:43 | INFO | fairseq.trainer | begin training epoch 157
2022-01-28 21:16:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:18:00 | INFO | train_inner | epoch 157:     16 / 64 loss=5.1, ppl=34.29, wps=6218.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=0.977, train_wall=472, gb_free=6.1, wall=51391
2022-01-28 21:21:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:22:12 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 9.825 | ppl 907.15 | wps 8628.6 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.054
2022-01-28 21:22:12 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-01-28 21:22:12 | INFO | train | epoch 157 | loss 5.085 | ppl 33.95 | wps 6353.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 0.948 | train_wall 303 | gb_free 6.1 | wall 51643
KL Stats: Epoch 157 Divergences: Uniform: 3.5318307376045466 Unigram: 3.1349269052743383
2022-01-28 21:22:12 | INFO | fairseq.trainer | begin training epoch 158
2022-01-28 21:22:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:26:20 | INFO | train_inner | epoch 158:     52 / 64 loss=5.079, ppl=33.8, wps=6536.7, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=0.955, train_wall=473, gb_free=6.1, wall=51891
2022-01-28 21:27:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:27:41 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 9.909 | ppl 961.6 | wps 8606.2 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.054
2022-01-28 21:27:41 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-01-28 21:27:41 | INFO | train | epoch 158 | loss 5.08 | ppl 33.84 | wps 6352.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 0.959 | train_wall 303 | gb_free 6.1 | wall 51972
KL Stats: Epoch 158 Divergences: Uniform: 3.529657059333825 Unigram: 3.1352189520545077
2022-01-28 21:27:41 | INFO | fairseq.trainer | begin training epoch 159
2022-01-28 21:27:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:32:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:33:10 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 9.893 | ppl 950.54 | wps 8621.7 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.054
2022-01-28 21:33:10 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-01-28 21:33:10 | INFO | train | epoch 159 | loss 5.074 | ppl 33.67 | wps 6354.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 0.974 | train_wall 302 | gb_free 6.1 | wall 52301
KL Stats: Epoch 159 Divergences: Uniform: 3.530142091720622 Unigram: 3.140611368870132
2022-01-28 21:33:10 | INFO | fairseq.trainer | begin training epoch 160
2022-01-28 21:33:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:35:04 | INFO | train_inner | epoch 160:     24 / 64 loss=5.074, ppl=33.68, wps=6217.6, ups=0.19, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=0.98, train_wall=472, gb_free=6.1, wall=52415
2022-01-28 21:38:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:38:38 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 9.889 | ppl 948.24 | wps 8622.6 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.054
2022-01-28 21:38:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-01-28 21:38:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint160.pt
2022-01-28 21:38:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint160.pt
2022-01-28 21:38:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint160.pt (epoch 160 @ 10240 updates, score 9.889) (writing took 3.656212853966281 seconds)
2022-01-28 21:38:42 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-01-28 21:38:42 | INFO | train | epoch 160 | loss 5.07 | ppl 33.6 | wps 6285 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.011 | train_wall 302 | gb_free 6.1 | wall 52633
KL Stats: Epoch 160 Divergences: Uniform: 3.5319030406577716 Unigram: 3.1439072085760245
2022-01-28 21:38:42 | INFO | fairseq.trainer | begin training epoch 161
2022-01-28 21:38:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:43:28 | INFO | train_inner | epoch 161:     60 / 64 loss=5.069, ppl=33.56, wps=6486.5, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=0.995, train_wall=474, gb_free=6.1, wall=52919
2022-01-28 21:43:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:44:11 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 9.881 | ppl 942.97 | wps 8642.3 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.054
2022-01-28 21:44:11 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-01-28 21:44:11 | INFO | train | epoch 161 | loss 5.06 | ppl 33.36 | wps 6349.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 0.976 | train_wall 303 | gb_free 6.1 | wall 52962
KL Stats: Epoch 161 Divergences: Uniform: 3.53806542620043 Unigram: 3.148803403416687
2022-01-28 21:44:11 | INFO | fairseq.trainer | begin training epoch 162
2022-01-28 21:44:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:49:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:49:40 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 9.899 | ppl 955.02 | wps 8618.8 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.054
2022-01-28 21:49:40 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-01-28 21:49:40 | INFO | train | epoch 162 | loss 5.056 | ppl 33.27 | wps 6352.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.005 | train_wall 303 | gb_free 6.1 | wall 53291
KL Stats: Epoch 162 Divergences: Uniform: 3.540734036678851 Unigram: 3.152095312655263
2022-01-28 21:49:40 | INFO | fairseq.trainer | begin training epoch 163
2022-01-28 21:49:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:52:12 | INFO | train_inner | epoch 163:     32 / 64 loss=5.043, ppl=32.98, wps=6218.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.006, train_wall=472, gb_free=6.1, wall=53443
2022-01-28 21:54:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:55:08 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 9.925 | ppl 972.14 | wps 8611.3 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.054
2022-01-28 21:55:08 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-01-28 21:55:08 | INFO | train | epoch 163 | loss 5.05 | ppl 33.13 | wps 6354.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 0.998 | train_wall 302 | gb_free 6.1 | wall 53619
KL Stats: Epoch 163 Divergences: Uniform: 3.535622940135436 Unigram: 3.15809767552074
2022-01-28 21:55:08 | INFO | fairseq.trainer | begin training epoch 164
2022-01-28 21:55:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:00:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:00:37 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 9.922 | ppl 969.93 | wps 8636.9 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.054
2022-01-28 22:00:37 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-01-28 22:00:37 | INFO | train | epoch 164 | loss 5.043 | ppl 32.98 | wps 6353.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.019 | train_wall 303 | gb_free 6.1 | wall 53948
KL Stats: Epoch 164 Divergences: Uniform: 3.5319293249039663 Unigram: 3.1592247893531957
2022-01-28 22:00:37 | INFO | fairseq.trainer | begin training epoch 165
2022-01-28 22:00:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:00:56 | INFO | train_inner | epoch 165:      4 / 64 loss=5.057, ppl=33.29, wps=6217.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.008, train_wall=472, gb_free=6.1, wall=53967
2022-01-28 22:05:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:06:06 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 9.921 | ppl 969.51 | wps 8645.1 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.054
2022-01-28 22:06:06 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-01-28 22:06:06 | INFO | train | epoch 165 | loss 5.036 | ppl 32.8 | wps 6353.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 0.998 | train_wall 303 | gb_free 6.1 | wall 54277
KL Stats: Epoch 165 Divergences: Uniform: 3.5421667129687613 Unigram: 3.1672956004864474
2022-01-28 22:06:06 | INFO | fairseq.trainer | begin training epoch 166
2022-01-28 22:06:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:09:16 | INFO | train_inner | epoch 166:     40 / 64 loss=5.03, ppl=32.66, wps=6538, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.01, train_wall=473, gb_free=6.1, wall=54467
2022-01-28 22:11:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:11:34 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 9.9 | ppl 955.34 | wps 8635.1 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.054
2022-01-28 22:11:34 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-01-28 22:11:34 | INFO | train | epoch 166 | loss 5.032 | ppl 32.73 | wps 6358.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.023 | train_wall 302 | gb_free 6.1 | wall 54605
KL Stats: Epoch 166 Divergences: Uniform: 3.5423891147506854 Unigram: 3.1696645558488883
2022-01-28 22:11:34 | INFO | fairseq.trainer | begin training epoch 167
2022-01-28 22:11:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:16:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:17:03 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 9.867 | ppl 933.58 | wps 8642.7 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.054
2022-01-28 22:17:03 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-01-28 22:17:03 | INFO | train | epoch 167 | loss 5.027 | ppl 32.6 | wps 6355.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.048 | train_wall 302 | gb_free 6.1 | wall 54934
KL Stats: Epoch 167 Divergences: Uniform: 3.538280323035337 Unigram: 3.1707663550886958
2022-01-28 22:17:03 | INFO | fairseq.trainer | begin training epoch 168
2022-01-28 22:17:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:18:00 | INFO | train_inner | epoch 168:     12 / 64 loss=5.028, ppl=32.64, wps=6221.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.039, train_wall=472, gb_free=6.1, wall=54991
2022-01-28 22:22:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:22:31 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 9.905 | ppl 958.47 | wps 8632.2 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.054
2022-01-28 22:22:31 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-01-28 22:22:31 | INFO | train | epoch 168 | loss 5.021 | ppl 32.48 | wps 6359 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.048 | train_wall 302 | gb_free 6.1 | wall 55262
KL Stats: Epoch 168 Divergences: Uniform: 3.5436228202069753 Unigram: 3.175871770645426
2022-01-28 22:22:31 | INFO | fairseq.trainer | begin training epoch 169
2022-01-28 22:22:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:26:19 | INFO | train_inner | epoch 169:     48 / 64 loss=5.02, ppl=32.45, wps=6543, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.053, train_wall=473, gb_free=6.1, wall=55490
2022-01-28 22:27:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:28:00 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 9.921 | ppl 969.71 | wps 8663 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.054
2022-01-28 22:28:00 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-01-28 22:28:00 | INFO | train | epoch 169 | loss 5.014 | ppl 32.31 | wps 6363.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.052 | train_wall 302 | gb_free 6.1 | wall 55591
KL Stats: Epoch 169 Divergences: Uniform: 3.5460322120165326 Unigram: 3.1802247999193822
2022-01-28 22:28:00 | INFO | fairseq.trainer | begin training epoch 170
2022-01-28 22:28:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:33:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:33:28 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 9.928 | ppl 974.06 | wps 8633.6 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.054
2022-01-28 22:33:28 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-01-28 22:33:28 | INFO | train | epoch 170 | loss 5.01 | ppl 32.21 | wps 6360.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.057 | train_wall 302 | gb_free 6.1 | wall 55919
KL Stats: Epoch 170 Divergences: Uniform: 3.5454271901093004 Unigram: 3.183169265561669
2022-01-28 22:33:28 | INFO | fairseq.trainer | begin training epoch 171
2022-01-28 22:33:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:35:03 | INFO | train_inner | epoch 171:     20 / 64 loss=5.003, ppl=32.07, wps=6226.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.058, train_wall=472, gb_free=6.1, wall=56014
2022-01-28 22:38:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:38:56 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 9.914 | ppl 964.52 | wps 8639.1 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.054
2022-01-28 22:38:56 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-01-28 22:38:56 | INFO | train | epoch 171 | loss 5.003 | ppl 32.08 | wps 6362.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.071 | train_wall 302 | gb_free 6.1 | wall 56247
KL Stats: Epoch 171 Divergences: Uniform: 3.545987313237129 Unigram: 3.1841568284388178
2022-01-28 22:38:56 | INFO | fairseq.trainer | begin training epoch 172
2022-01-28 22:38:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:43:22 | INFO | train_inner | epoch 172:     56 / 64 loss=5.007, ppl=32.15, wps=6546.7, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.061, train_wall=473, gb_free=6.1, wall=56513
2022-01-28 22:43:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:44:24 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 9.936 | ppl 979.46 | wps 8637.8 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.054
2022-01-28 22:44:24 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-01-28 22:44:24 | INFO | train | epoch 172 | loss 4.998 | ppl 31.95 | wps 6365.1 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.058 | train_wall 302 | gb_free 6.1 | wall 56575
KL Stats: Epoch 172 Divergences: Uniform: 3.5422259686102193 Unigram: 3.1858207073626494
2022-01-28 22:44:24 | INFO | fairseq.trainer | begin training epoch 173
2022-01-28 22:44:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:49:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:49:53 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 9.881 | ppl 943.02 | wps 8631.6 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.054
2022-01-28 22:49:53 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-01-28 22:49:53 | INFO | train | epoch 173 | loss 4.992 | ppl 31.83 | wps 6361.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.113 | train_wall 302 | gb_free 6.1 | wall 56904
KL Stats: Epoch 173 Divergences: Uniform: 3.5487302444905002 Unigram: 3.1891462794421144
2022-01-28 22:49:53 | INFO | fairseq.trainer | begin training epoch 174
2022-01-28 22:49:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:52:06 | INFO | train_inner | epoch 174:     28 / 64 loss=4.986, ppl=31.7, wps=6226.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.096, train_wall=471, gb_free=6.1, wall=57037
2022-01-28 22:54:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:55:21 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 9.947 | ppl 987.11 | wps 8618.9 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.054
2022-01-28 22:55:21 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-01-28 22:55:21 | INFO | train | epoch 174 | loss 4.987 | ppl 31.72 | wps 6363.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.083 | train_wall 302 | gb_free 6.1 | wall 57232
KL Stats: Epoch 174 Divergences: Uniform: 3.543449167458153 Unigram: 3.1946718170015322
2022-01-28 22:55:21 | INFO | fairseq.trainer | begin training epoch 175
2022-01-28 22:55:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:00:24 | INFO | train_inner | epoch 175:     64 / 64 loss=4.99, ppl=31.78, wps=6543.7, ups=0.2, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.088, train_wall=472, gb_free=6.1, wall=57535
2022-01-28 23:00:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:00:49 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 9.902 | ppl 957.06 | wps 8627.5 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.054
2022-01-28 23:00:49 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-01-28 23:00:49 | INFO | train | epoch 175 | loss 4.98 | ppl 31.56 | wps 6360 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.082 | train_wall 302 | gb_free 6.1 | wall 57560
KL Stats: Epoch 175 Divergences: Uniform: 3.5554966655668556 Unigram: 3.2009519200509144
2022-01-28 23:00:49 | INFO | fairseq.trainer | begin training epoch 176
2022-01-28 23:00:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:05:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:06:18 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 9.943 | ppl 984.37 | wps 8625.6 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.054
2022-01-28 23:06:18 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-01-28 23:06:18 | INFO | train | epoch 176 | loss 4.975 | ppl 31.45 | wps 6357.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.066 | train_wall 302 | gb_free 6.1 | wall 57889
KL Stats: Epoch 176 Divergences: Uniform: 3.552277224147473 Unigram: 3.2036347627322304
2022-01-28 23:06:18 | INFO | fairseq.trainer | begin training epoch 177
2022-01-28 23:06:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:09:09 | INFO | train_inner | epoch 177:     36 / 64 loss=4.964, ppl=31.2, wps=6224.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.075, train_wall=473, gb_free=6.1, wall=58060
2022-01-28 23:11:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:11:46 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 9.901 | ppl 955.97 | wps 8645.7 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.054
2022-01-28 23:11:46 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-01-28 23:11:46 | INFO | train | epoch 177 | loss 4.972 | ppl 31.39 | wps 6360.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.115 | train_wall 302 | gb_free 6.1 | wall 58217
KL Stats: Epoch 177 Divergences: Uniform: 3.5563388809436063 Unigram: 3.2081994670685057
2022-01-28 23:11:46 | INFO | fairseq.trainer | begin training epoch 178
2022-01-28 23:11:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:16:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:17:14 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 9.995 | ppl 1020.58 | wps 8632.3 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.054
2022-01-28 23:17:14 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-01-28 23:17:14 | INFO | train | epoch 178 | loss 4.967 | ppl 31.29 | wps 6364.3 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.091 | train_wall 302 | gb_free 6.1 | wall 58545
KL Stats: Epoch 178 Divergences: Uniform: 3.5599307323951908 Unigram: 3.212495178209111
2022-01-28 23:17:14 | INFO | fairseq.trainer | begin training epoch 179
2022-01-28 23:17:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:17:52 | INFO | train_inner | epoch 179:      8 / 64 loss=4.976, ppl=31.46, wps=6227.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.109, train_wall=471, gb_free=6.1, wall=58583
2022-01-28 23:22:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:22:43 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 9.96 | ppl 996 | wps 8663.2 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.054
2022-01-28 23:22:43 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-01-28 23:22:43 | INFO | train | epoch 179 | loss 4.962 | ppl 31.16 | wps 6364.4 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.134 | train_wall 302 | gb_free 6.1 | wall 58874
KL Stats: Epoch 179 Divergences: Uniform: 3.5599582543438717 Unigram: 3.214617366215096
2022-01-28 23:22:43 | INFO | fairseq.trainer | begin training epoch 180
2022-01-28 23:22:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:26:12 | INFO | train_inner | epoch 180:     44 / 64 loss=4.957, ppl=31.06, wps=6546, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.124, train_wall=473, gb_free=6.1, wall=59083
2022-01-28 23:27:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:28:11 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 9.932 | ppl 977.17 | wps 8635.6 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.054
2022-01-28 23:28:11 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-01-28 23:28:11 | INFO | train | epoch 180 | loss 4.957 | ppl 31.05 | wps 6362.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.112 | train_wall 302 | gb_free 6.1 | wall 59202
KL Stats: Epoch 180 Divergences: Uniform: 3.5604805186542996 Unigram: 3.2203032282580812
2022-01-28 23:28:11 | INFO | fairseq.trainer | begin training epoch 181
2022-01-28 23:28:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:33:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:33:39 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 9.958 | ppl 994.4 | wps 8648.9 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.054
2022-01-28 23:33:39 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-01-28 23:33:39 | INFO | train | epoch 181 | loss 4.95 | ppl 30.91 | wps 6359.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.136 | train_wall 302 | gb_free 6.1 | wall 59530
KL Stats: Epoch 181 Divergences: Uniform: 3.5618803983680736 Unigram: 3.222537978299713
2022-01-28 23:33:39 | INFO | fairseq.trainer | begin training epoch 182
2022-01-28 23:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:34:55 | INFO | train_inner | epoch 182:     16 / 64 loss=4.95, ppl=30.92, wps=6224.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.128, train_wall=472, gb_free=6.1, wall=59606
2022-01-28 23:38:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:39:08 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 9.953 | ppl 991.3 | wps 8623.3 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.054
2022-01-28 23:39:08 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-01-28 23:39:08 | INFO | train | epoch 182 | loss 4.947 | ppl 30.84 | wps 6358.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.16 | train_wall 302 | gb_free 6.1 | wall 59859
KL Stats: Epoch 182 Divergences: Uniform: 3.559098087942341 Unigram: 3.2225851276108175
2022-01-28 23:39:08 | INFO | fairseq.trainer | begin training epoch 183
2022-01-28 23:39:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:43:15 | INFO | train_inner | epoch 183:     52 / 64 loss=4.945, ppl=30.8, wps=6539.9, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.166, train_wall=473, gb_free=6.1, wall=60106
2022-01-28 23:44:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:44:36 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 9.95 | ppl 988.93 | wps 8632.8 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.054
2022-01-28 23:44:36 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-01-28 23:44:36 | INFO | train | epoch 183 | loss 4.942 | ppl 30.74 | wps 6355.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.169 | train_wall 302 | gb_free 6.1 | wall 60187
KL Stats: Epoch 183 Divergences: Uniform: 3.5650171079055712 Unigram: 3.227440629172632
2022-01-28 23:44:36 | INFO | fairseq.trainer | begin training epoch 184
2022-01-28 23:44:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:49:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:50:05 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 9.905 | ppl 958.91 | wps 8636.7 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.054
2022-01-28 23:50:05 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-01-28 23:50:05 | INFO | train | epoch 184 | loss 4.937 | ppl 30.64 | wps 6359.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.168 | train_wall 302 | gb_free 6.1 | wall 60516
KL Stats: Epoch 184 Divergences: Uniform: 3.5564075351237614 Unigram: 3.229882106323852
2022-01-28 23:50:05 | INFO | fairseq.trainer | begin training epoch 185
2022-01-28 23:50:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:51:59 | INFO | train_inner | epoch 185:     24 / 64 loss=4.938, ppl=30.65, wps=6224.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.172, train_wall=472, gb_free=6.1, wall=60630
2022-01-28 23:55:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:55:33 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 9.955 | ppl 992.22 | wps 8642.6 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.054
2022-01-28 23:55:33 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-01-28 23:55:33 | INFO | train | epoch 185 | loss 4.932 | ppl 30.53 | wps 6363 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.152 | train_wall 302 | gb_free 6.1 | wall 60844
KL Stats: Epoch 185 Divergences: Uniform: 3.558368353858504 Unigram: 3.23471626915828
2022-01-28 23:55:33 | INFO | fairseq.trainer | begin training epoch 186
2022-01-28 23:55:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:00:18 | INFO | train_inner | epoch 186:     60 / 64 loss=4.933, ppl=30.55, wps=6545.5, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.162, train_wall=473, gb_free=6.1, wall=61129
2022-01-29 00:00:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:01:01 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 9.892 | ppl 950.44 | wps 8642 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.054
2022-01-29 00:01:01 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-01-29 00:01:01 | INFO | train | epoch 186 | loss 4.929 | ppl 30.47 | wps 6362.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.173 | train_wall 302 | gb_free 6.1 | wall 61172
KL Stats: Epoch 186 Divergences: Uniform: 3.562134309921908 Unigram: 3.2340004872704315
2022-01-29 00:01:01 | INFO | fairseq.trainer | begin training epoch 187
2022-01-29 00:01:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:06:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:06:29 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 9.928 | ppl 974.29 | wps 8636.5 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.054
2022-01-29 00:06:29 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-01-29 00:06:29 | INFO | train | epoch 187 | loss 4.925 | ppl 30.38 | wps 6367.4 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.193 | train_wall 302 | gb_free 6.1 | wall 61500
KL Stats: Epoch 187 Divergences: Uniform: 3.5542009103261147 Unigram: 3.239137898325338
2022-01-29 00:06:29 | INFO | fairseq.trainer | begin training epoch 188
2022-01-29 00:06:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:09:01 | INFO | train_inner | epoch 188:     32 / 64 loss=4.918, ppl=30.24, wps=6229.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.178, train_wall=471, gb_free=6.1, wall=61652
2022-01-29 00:11:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:11:58 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 9.946 | ppl 986.65 | wps 8643.9 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.054
2022-01-29 00:11:58 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-01-29 00:11:58 | INFO | train | epoch 188 | loss 4.918 | ppl 30.24 | wps 6362.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.175 | train_wall 302 | gb_free 6.1 | wall 61829
KL Stats: Epoch 188 Divergences: Uniform: 3.5591641077718044 Unigram: 3.2430458885799025
2022-01-29 00:11:58 | INFO | fairseq.trainer | begin training epoch 189
2022-01-29 00:11:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:17:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:17:26 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 9.933 | ppl 977.8 | wps 8642.1 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.054
2022-01-29 00:17:26 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-01-29 00:17:26 | INFO | train | epoch 189 | loss 4.916 | ppl 30.19 | wps 6360.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.226 | train_wall 302 | gb_free 6.1 | wall 62157
KL Stats: Epoch 189 Divergences: Uniform: 3.564606897999221 Unigram: 3.2439877961510506
2022-01-29 00:17:26 | INFO | fairseq.trainer | begin training epoch 190
2022-01-29 00:17:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:17:45 | INFO | train_inner | epoch 190:      4 / 64 loss=4.921, ppl=30.29, wps=6225.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.215, train_wall=472, gb_free=6.1, wall=62176
2022-01-29 00:22:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:22:54 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 9.947 | ppl 987.2 | wps 8637.8 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.054
2022-01-29 00:22:54 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-01-29 00:22:54 | INFO | train | epoch 190 | loss 4.908 | ppl 30.03 | wps 6363.9 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.181 | train_wall 302 | gb_free 6.1 | wall 62485
KL Stats: Epoch 190 Divergences: Uniform: 3.5671085989639275 Unigram: 3.2476351890784074
2022-01-29 00:22:54 | INFO | fairseq.trainer | begin training epoch 191
2022-01-29 00:22:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:26:04 | INFO | train_inner | epoch 191:     40 / 64 loss=4.898, ppl=29.82, wps=6548.6, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.196, train_wall=472, gb_free=6.1, wall=62675
2022-01-29 00:27:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:28:22 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 9.939 | ppl 981.56 | wps 8639.3 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.054
2022-01-29 00:28:22 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-01-29 00:28:22 | INFO | train | epoch 191 | loss 4.906 | ppl 29.98 | wps 6366.3 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.233 | train_wall 302 | gb_free 6.1 | wall 62813
KL Stats: Epoch 191 Divergences: Uniform: 3.5666774056828716 Unigram: 3.2508570535205177
2022-01-29 00:28:22 | INFO | fairseq.trainer | begin training epoch 192
2022-01-29 00:28:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:33:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:33:51 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 9.964 | ppl 998.77 | wps 8639.8 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.054
2022-01-29 00:33:51 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-01-29 00:33:51 | INFO | train | epoch 192 | loss 4.901 | ppl 29.88 | wps 6360 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.229 | train_wall 302 | gb_free 6.1 | wall 63142
KL Stats: Epoch 192 Divergences: Uniform: 3.559478428540524 Unigram: 3.2498082297672655
2022-01-29 00:33:51 | INFO | fairseq.trainer | begin training epoch 193
2022-01-29 00:33:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:34:48 | INFO | train_inner | epoch 193:     12 / 64 loss=4.908, ppl=30.03, wps=6225.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.241, train_wall=472, gb_free=6.1, wall=63199
2022-01-29 00:38:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:39:19 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 9.91 | ppl 962.28 | wps 8644.3 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.054
2022-01-29 00:39:19 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-01-29 00:39:19 | INFO | train | epoch 193 | loss 4.896 | ppl 29.78 | wps 6358.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.23 | train_wall 302 | gb_free 6.1 | wall 63470
KL Stats: Epoch 193 Divergences: Uniform: 3.5653105667840626 Unigram: 3.254886568465658
2022-01-29 00:39:19 | INFO | fairseq.trainer | begin training epoch 194
2022-01-29 00:39:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:43:07 | INFO | train_inner | epoch 194:     48 / 64 loss=4.893, ppl=29.72, wps=6543.2, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.242, train_wall=473, gb_free=6.1, wall=63698
2022-01-29 00:44:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:44:47 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 9.924 | ppl 971.15 | wps 8657.5 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.054
2022-01-29 00:44:47 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-01-29 00:44:47 | INFO | train | epoch 194 | loss 4.893 | ppl 29.7 | wps 6362.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.27 | train_wall 302 | gb_free 6.1 | wall 63798
KL Stats: Epoch 194 Divergences: Uniform: 3.566525203198578 Unigram: 3.258395000610995
2022-01-29 00:44:47 | INFO | fairseq.trainer | begin training epoch 195
2022-01-29 00:44:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:49:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:50:16 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 9.975 | ppl 1006.75 | wps 8648.2 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.054
2022-01-29 00:50:16 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-01-29 00:50:16 | INFO | train | epoch 195 | loss 4.891 | ppl 29.67 | wps 6364.2 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.276 | train_wall 302 | gb_free 6.1 | wall 64127
KL Stats: Epoch 195 Divergences: Uniform: 3.563643153064049 Unigram: 3.259834338864167
2022-01-29 00:50:16 | INFO | fairseq.trainer | begin training epoch 196
2022-01-29 00:50:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:51:51 | INFO | train_inner | epoch 196:     20 / 64 loss=4.888, ppl=29.6, wps=6228.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.265, train_wall=471, gb_free=6.1, wall=64222
2022-01-29 00:55:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:55:44 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 9.942 | ppl 983.36 | wps 8636.4 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.054
2022-01-29 00:55:44 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-01-29 00:55:44 | INFO | train | epoch 196 | loss 4.887 | ppl 29.58 | wps 6360.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.249 | train_wall 302 | gb_free 6.1 | wall 64455
KL Stats: Epoch 196 Divergences: Uniform: 3.5645858769516283 Unigram: 3.261569309382771
2022-01-29 00:55:44 | INFO | fairseq.trainer | begin training epoch 197
2022-01-29 00:55:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:00:10 | INFO | train_inner | epoch 197:     56 / 64 loss=4.886, ppl=29.57, wps=6544.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.277, train_wall=473, gb_free=6.1, wall=64721
2022-01-29 01:00:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:01:12 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 9.915 | ppl 965.46 | wps 8652.5 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.054
2022-01-29 01:01:12 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-01-29 01:01:12 | INFO | train | epoch 197 | loss 4.881 | ppl 29.46 | wps 6364.8 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.295 | train_wall 302 | gb_free 6.1 | wall 64783
KL Stats: Epoch 197 Divergences: Uniform: 3.56484024036846 Unigram: 3.2629868993746456
2022-01-29 01:01:12 | INFO | fairseq.trainer | begin training epoch 198
2022-01-29 01:01:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:06:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:06:40 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 9.951 | ppl 989.53 | wps 8642.4 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.054
2022-01-29 01:06:40 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-01-29 01:06:40 | INFO | train | epoch 198 | loss 4.875 | ppl 29.35 | wps 6362.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.308 | train_wall 302 | gb_free 6.1 | wall 65111
KL Stats: Epoch 198 Divergences: Uniform: 3.5696204152045863 Unigram: 3.2672528128490628
2022-01-29 01:06:40 | INFO | fairseq.trainer | begin training epoch 199
2022-01-29 01:06:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:08:53 | INFO | train_inner | epoch 199:     28 / 64 loss=4.871, ppl=29.26, wps=6228.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.297, train_wall=471, gb_free=6.1, wall=65244
2022-01-29 01:11:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:12:08 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 9.931 | ppl 976.08 | wps 8638.6 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.054
2022-01-29 01:12:08 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-01-29 01:12:08 | INFO | train | epoch 199 | loss 4.873 | ppl 29.3 | wps 6364.5 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.297 | train_wall 302 | gb_free 6.1 | wall 65439
KL Stats: Epoch 199 Divergences: Uniform: 3.5701786092901253 Unigram: 3.272456158228678
2022-01-29 01:12:09 | INFO | fairseq.trainer | begin training epoch 200
2022-01-29 01:12:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:17:11 | INFO | train_inner | epoch 200:     64 / 64 loss=4.88, ppl=29.45, wps=6546.3, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.31, train_wall=471, gb_free=6.1, wall=65742
2022-01-29 01:17:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:17:37 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 9.988 | ppl 1015.8 | wps 8638.3 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.054
2022-01-29 01:17:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-01-29 01:17:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint200.pt
2022-01-29 01:17:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint200.pt
2022-01-29 01:17:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.06_0.04_0.9/checkpoint200.pt (epoch 200 @ 12800 updates, score 9.988) (writing took 4.473740265937522 seconds)
2022-01-29 01:17:41 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-01-29 01:17:41 | INFO | train | epoch 200 | loss 4.867 | ppl 29.19 | wps 6278.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.297 | train_wall 302 | gb_free 6.1 | wall 65772
KL Stats: Epoch 200 Divergences: Uniform: 3.566967493261277 Unigram: 3.275278771129969
2022-01-29 01:17:41 | INFO | fairseq.trainer | begin training epoch 201
2022-01-29 01:17:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:22:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:23:09 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 9.968 | ppl 1001.59 | wps 8628.9 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.054
2022-01-29 01:23:09 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-01-29 01:23:09 | INFO | train | epoch 201 | loss 4.865 | ppl 29.14 | wps 6366.6 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.322 | train_wall 302 | gb_free 6.1 | wall 66100
KL Stats: Epoch 201 Divergences: Uniform: 3.564037456228846 Unigram: 3.2731774840627943
2022-01-29 01:23:09 | INFO | fairseq.trainer | begin training epoch 202
2022-01-29 01:23:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:26:00 | INFO | train_inner | epoch 202:     36 / 64 loss=4.852, ppl=28.89, wps=6177.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.341, train_wall=472, gb_free=6.1, wall=66271
2022-01-29 01:28:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:28:38 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 9.997 | ppl 1021.93 | wps 8669.7 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.054
2022-01-29 01:28:38 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-01-29 01:28:38 | INFO | train | epoch 202 | loss 4.861 | ppl 29.05 | wps 6362.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.348 | train_wall 302 | gb_free 6.1 | wall 66428
KL Stats: Epoch 202 Divergences: Uniform: 3.564481053942847 Unigram: 3.2797304050582703
2022-01-29 01:28:38 | INFO | fairseq.trainer | begin training epoch 203
2022-01-29 01:28:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:33:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:34:06 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 9.959 | ppl 995.25 | wps 8647.7 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.054
2022-01-29 01:34:06 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-01-29 01:34:06 | INFO | train | epoch 203 | loss 4.854 | ppl 28.92 | wps 6359.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.301 | train_wall 302 | gb_free 6.1 | wall 66757
KL Stats: Epoch 203 Divergences: Uniform: 3.5639566656646866 Unigram: 3.2802345709328753
2022-01-29 01:34:06 | INFO | fairseq.trainer | begin training epoch 204
2022-01-29 01:34:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:34:44 | INFO | train_inner | epoch 204:      8 / 64 loss=4.863, ppl=29.1, wps=6226, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.309, train_wall=472, gb_free=6.1, wall=66795
2022-01-29 01:39:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:39:34 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 9.984 | ppl 1012.73 | wps 8657.6 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.054
2022-01-29 01:39:34 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-01-29 01:39:34 | INFO | train | epoch 204 | loss 4.851 | ppl 28.86 | wps 6363.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.331 | train_wall 302 | gb_free 6.1 | wall 67085
KL Stats: Epoch 204 Divergences: Uniform: 3.576495068685986 Unigram: 3.2855924816063866
2022-01-29 01:39:34 | INFO | fairseq.trainer | begin training epoch 205
2022-01-29 01:39:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:43:03 | INFO | train_inner | epoch 205:     44 / 64 loss=4.847, ppl=28.79, wps=6545.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.345, train_wall=473, gb_free=6.1, wall=67294
2022-01-29 01:44:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:45:02 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 9.955 | ppl 992.67 | wps 8646 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.054
2022-01-29 01:45:02 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-01-29 01:45:02 | INFO | train | epoch 205 | loss 4.848 | ppl 28.8 | wps 6363 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.361 | train_wall 302 | gb_free 6.1 | wall 67413
KL Stats: Epoch 205 Divergences: Uniform: 3.5741891920222635 Unigram: 3.288796953132721
2022-01-29 01:45:02 | INFO | fairseq.trainer | begin training epoch 206
2022-01-29 01:45:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:50:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:50:31 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 9.966 | ppl 999.8 | wps 8643.3 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.054
2022-01-29 01:50:31 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-01-29 01:50:31 | INFO | train | epoch 206 | loss 4.845 | ppl 28.73 | wps 6364.6 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.322 | train_wall 302 | gb_free 6.1 | wall 67742
KL Stats: Epoch 206 Divergences: Uniform: 3.570886467596292 Unigram: 3.2904157820564874
2022-01-29 01:50:31 | INFO | fairseq.trainer | begin training epoch 207
2022-01-29 01:50:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:51:47 | INFO | train_inner | epoch 207:     16 / 64 loss=4.846, ppl=28.76, wps=6228.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.337, train_wall=471, gb_free=6.1, wall=67818
2022-01-29 01:55:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:55:59 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 9.949 | ppl 988.25 | wps 8672.7 | wpb 2034.1 | bsz 4 | num_updates 13248 | best_loss 9.054
2022-01-29 01:55:59 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-01-29 01:55:59 | INFO | train | epoch 207 | loss 4.842 | ppl 28.68 | wps 6361 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13248 | lr 0.000274742 | gnorm 1.394 | train_wall 302 | gb_free 6.1 | wall 68070
KL Stats: Epoch 207 Divergences: Uniform: 3.5683486240469926 Unigram: 3.2868159620485673
2022-01-29 01:55:59 | INFO | fairseq.trainer | begin training epoch 208
2022-01-29 01:55:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:00:06 | INFO | train_inner | epoch 208:     52 / 64 loss=4.838, ppl=28.61, wps=6545.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=13300, lr=0.000274204, gnorm=1.374, train_wall=473, gb_free=6.1, wall=68317
2022-01-29 02:01:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:01:27 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 9.982 | ppl 1010.99 | wps 8668 | wpb 2034.1 | bsz 4 | num_updates 13312 | best_loss 9.054
2022-01-29 02:01:27 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-01-29 02:01:27 | INFO | train | epoch 208 | loss 4.836 | ppl 28.55 | wps 6366.5 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 13312 | lr 0.000274081 | gnorm 1.363 | train_wall 302 | gb_free 6.1 | wall 68398
KL Stats: Epoch 208 Divergences: Uniform: 3.570270902783512 Unigram: 3.2929987970903296
2022-01-29 02:01:27 | INFO | fairseq.trainer | begin training epoch 209
2022-01-29 02:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:06:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:06:55 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 9.997 | ppl 1021.93 | wps 8645.9 | wpb 2034.1 | bsz 4 | num_updates 13376 | best_loss 9.054
2022-01-29 02:06:55 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-01-29 02:06:55 | INFO | train | epoch 209 | loss 4.833 | ppl 28.49 | wps 6363.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13376 | lr 0.000273424 | gnorm 1.373 | train_wall 302 | gb_free 6.1 | wall 68726
KL Stats: Epoch 209 Divergences: Uniform: 3.572753376501484 Unigram: 3.2949410306047557
2022-01-29 02:06:55 | INFO | fairseq.trainer | begin training epoch 210
2022-01-29 02:06:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:08:49 | INFO | train_inner | epoch 210:     24 / 64 loss=4.83, ppl=28.44, wps=6229.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13400, lr=0.000273179, gnorm=1.386, train_wall=471, gb_free=6.1, wall=68840
2022-01-29 02:11:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:12:23 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 9.972 | ppl 1004.63 | wps 8690.7 | wpb 2034.1 | bsz 4 | num_updates 13440 | best_loss 9.054
2022-01-29 02:12:23 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-01-29 02:12:23 | INFO | train | epoch 210 | loss 4.828 | ppl 28.41 | wps 6372.3 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 13440 | lr 0.000272772 | gnorm 1.436 | train_wall 302 | gb_free 6.1 | wall 69054
KL Stats: Epoch 210 Divergences: Uniform: 3.5722373629272433 Unigram: 3.2994688129721355
2022-01-29 02:12:23 | INFO | fairseq.trainer | begin training epoch 211
2022-01-29 02:12:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:17:07 | INFO | train_inner | epoch 211:     60 / 64 loss=4.832, ppl=28.47, wps=6565.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=13500, lr=0.000272166, gnorm=1.418, train_wall=471, gb_free=6.1, wall=69338
2022-01-29 02:17:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:17:50 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 9.988 | ppl 1015.51 | wps 8722.3 | wpb 2034.1 | bsz 4 | num_updates 13504 | best_loss 9.054
2022-01-29 02:17:50 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-01-29 02:17:50 | INFO | train | epoch 211 | loss 4.826 | ppl 28.37 | wps 6390 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 13504 | lr 0.000272125 | gnorm 1.394 | train_wall 301 | gb_free 6.1 | wall 69381
KL Stats: Epoch 211 Divergences: Uniform: 3.5733452742754803 Unigram: 3.3038746469347835
2022-01-29 02:17:50 | INFO | fairseq.trainer | begin training epoch 212
2022-01-29 02:17:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:22:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:23:17 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 9.967 | ppl 1000.79 | wps 8669.8 | wpb 2034.1 | bsz 4 | num_updates 13568 | best_loss 9.054
2022-01-29 02:23:17 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-01-29 02:23:17 | INFO | train | epoch 212 | loss 4.823 | ppl 28.31 | wps 6382.7 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 13568 | lr 0.000271483 | gnorm 1.429 | train_wall 301 | gb_free 6.1 | wall 69708
KL Stats: Epoch 212 Divergences: Uniform: 3.578210672166048 Unigram: 3.300398525639317
2022-01-29 02:23:17 | INFO | fairseq.trainer | begin training epoch 213
2022-01-29 02:23:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:25:49 | INFO | train_inner | epoch 213:     32 / 64 loss=4.816, ppl=28.18, wps=6249.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13600, lr=0.000271163, gnorm=1.414, train_wall=470, gb_free=6.1, wall=69860
2022-01-29 02:28:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:28:44 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 9.99 | ppl 1017.07 | wps 8681.7 | wpb 2034.1 | bsz 4 | num_updates 13632 | best_loss 9.054
2022-01-29 02:28:44 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-01-29 02:28:44 | INFO | train | epoch 213 | loss 4.819 | ppl 28.23 | wps 6383.6 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 13632 | lr 0.000270845 | gnorm 1.43 | train_wall 301 | gb_free 6.1 | wall 70035
KL Stats: Epoch 213 Divergences: Uniform: 3.574905493817116 Unigram: 3.306957064551139
2022-01-29 02:28:44 | INFO | fairseq.trainer | begin training epoch 214
2022-01-29 02:28:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:33:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:34:12 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 9.933 | ppl 977.21 | wps 8674.4 | wpb 2034.1 | bsz 4 | num_updates 13696 | best_loss 9.054
2022-01-29 02:34:12 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-01-29 02:34:12 | INFO | train | epoch 214 | loss 4.816 | ppl 28.16 | wps 6379.5 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 13696 | lr 0.000270211 | gnorm 1.423 | train_wall 301 | gb_free 6.1 | wall 70363
KL Stats: Epoch 214 Divergences: Uniform: 3.575725514254885 Unigram: 3.305709146045866
2022-01-29 02:34:12 | INFO | fairseq.trainer | begin training epoch 215
2022-01-29 02:34:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:34:31 | INFO | train_inner | epoch 215:      4 / 64 loss=4.822, ppl=28.29, wps=6244.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=13700, lr=0.000270172, gnorm=1.443, train_wall=470, gb_free=6.1, wall=70382
2022-01-29 02:39:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:39:39 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 9.939 | ppl 981.8 | wps 8696.1 | wpb 2034.1 | bsz 4 | num_updates 13760 | best_loss 9.054
2022-01-29 02:39:39 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-01-29 02:39:39 | INFO | train | epoch 215 | loss 4.81 | ppl 28.06 | wps 6384.7 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 13760 | lr 0.000269582 | gnorm 1.461 | train_wall 301 | gb_free 6.1 | wall 70690
KL Stats: Epoch 215 Divergences: Uniform: 3.5768294455049516 Unigram: 3.3098759623670175
2022-01-29 02:39:39 | INFO | fairseq.trainer | begin training epoch 216
2022-01-29 02:39:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:42:48 | INFO | train_inner | epoch 216:     40 / 64 loss=4.805, ppl=27.95, wps=6566.5, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=13800, lr=0.000269191, gnorm=1.455, train_wall=471, gb_free=6.1, wall=70879
2022-01-29 02:44:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:45:06 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 9.971 | ppl 1003.63 | wps 8700.1 | wpb 2034.1 | bsz 4 | num_updates 13824 | best_loss 9.054
2022-01-29 02:45:06 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-01-29 02:45:06 | INFO | train | epoch 216 | loss 4.809 | ppl 28.03 | wps 6384 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 13824 | lr 0.000268957 | gnorm 1.47 | train_wall 301 | gb_free 6.1 | wall 71017
KL Stats: Epoch 216 Divergences: Uniform: 3.572816731291668 Unigram: 3.307494316744476
2022-01-29 02:45:06 | INFO | fairseq.trainer | begin training epoch 217
2022-01-29 02:45:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:50:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:50:33 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 9.966 | ppl 1000.42 | wps 8681.3 | wpb 2034.1 | bsz 4 | num_updates 13888 | best_loss 9.054
2022-01-29 02:50:33 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-01-29 02:50:33 | INFO | train | epoch 217 | loss 4.805 | ppl 27.95 | wps 6382.6 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 13888 | lr 0.000268337 | gnorm 1.511 | train_wall 301 | gb_free 6.1 | wall 71344
KL Stats: Epoch 217 Divergences: Uniform: 3.568784003039757 Unigram: 3.309900403393146
2022-01-29 02:50:33 | INFO | fairseq.trainer | begin training epoch 218
2022-01-29 02:50:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:51:30 | INFO | train_inner | epoch 218:     12 / 64 loss=4.809, ppl=28.04, wps=6248.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13900, lr=0.000268221, gnorm=1.498, train_wall=470, gb_free=6.1, wall=71401
2022-01-29 02:55:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:56:00 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 9.936 | ppl 979.4 | wps 8687.9 | wpb 2034.1 | bsz 4 | num_updates 13952 | best_loss 9.054
2022-01-29 02:56:00 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-01-29 02:56:00 | INFO | train | epoch 218 | loss 4.801 | ppl 27.88 | wps 6382.4 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 13952 | lr 0.000267721 | gnorm 1.433 | train_wall 301 | gb_free 6.1 | wall 71671
KL Stats: Epoch 218 Divergences: Uniform: 3.5730633475332856 Unigram: 3.3134285238547903
2022-01-29 02:56:00 | INFO | fairseq.trainer | begin training epoch 219
2022-01-29 02:56:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:59:48 | INFO | train_inner | epoch 219:     48 / 64 loss=4.797, ppl=27.79, wps=6565.1, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=14000, lr=0.000267261, gnorm=1.455, train_wall=471, gb_free=6.1, wall=71899
User defined signal 2
