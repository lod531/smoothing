Sender: LSF System <lsfadmin@eu-g3-075>
Subject: Job 208123450: <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.065_0.01_0.925_#1> in cluster <euler> Exited

Job <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.065_0.01_0.925_#1> was submitted from host <eu-login-20> by user <andriusb> in cluster <euler> at Mon Mar 14 10:12:18 2022
Job was executed on host(s) <eu-g3-075>, in queue <gpuhe.120h>, as user <andriusb> in cluster <euler> at Mon Mar 14 10:12:52 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Mar 14 10:12:52 2022
Terminated at Mon Mar 14 10:13:00 2022
Results reported at Mon Mar 14 10:13:00 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-cleaned-bpe-size0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.065, 0.1, 0.925)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 32 --no-epoch-checkpoints --seed 1321671 --no-epoch-checkpoints --fp16 --max-update 50000
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   4.97 sec.
    Max Memory :                                 582 MB
    Average Memory :                             343.00 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               19418.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                5
    Run time :                                   8 sec.
    Turnaround time :                            42 sec.

The output (if any) follows:

2022-03-14 10:12:59 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1321671, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-cleaned-bpe-size0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1321671, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.065, 0.1, 0.925)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-14 10:12:59 | INFO | fairseq.tasks.language_modeling | dictionary: 39136 types
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 99, in main
    criterion = task.build_criterion(cfg.criterion)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 668, in build_criterion
    return criterions.build_criterion(args, self)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/__init__.py", line 29, in build_criterion
    return build_criterion_(cfg, task)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/registry.py", line 61, in build_x
    return builder(cfg, *extra_args, **extra_kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/fairseq_criterion.py", line 60, in build_criterion
    return cls(**init_args)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/jelinek_mercer.py", line 46, in __init__
    assert sum(self.alphas) == 1
AssertionError
Sender: LSF System <lsfadmin@eu-g3-073>
Subject: Job 208123525: <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.065_0.01_0.925_#1> in cluster <euler> Exited

Job <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.065_0.01_0.925_#1> was submitted from host <eu-login-20> by user <andriusb> in cluster <euler> at Mon Mar 14 10:14:10 2022
Job was executed on host(s) <eu-g3-073>, in queue <gpuhe.120h>, as user <andriusb> in cluster <euler> at Mon Mar 14 10:14:22 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Mar 14 10:14:22 2022
Terminated at Tue Mar 15 06:20:20 2022
Results reported at Tue Mar 15 06:20:20 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-cleaned-bpe-size0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.065, 0.01, 0.925)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 32 --no-epoch-checkpoints --seed 1321671 --no-epoch-checkpoints --fp16 --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   72312.13 sec.
    Max Memory :                                 4949 MB
    Average Memory :                             3342.02 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15051.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72356 sec.
    Turnaround time :                            72370 sec.

The output (if any) follows:

2022-03-14 10:14:31 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1321671, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-cleaned-bpe-size0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1321671, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.065, 0.01, 0.925)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-14 10:14:31 | INFO | fairseq.tasks.language_modeling | dictionary: 39136 types
2022-03-14 10:14:32 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
Calculating frequency stats:
  0%|          | 0/112584 [00:00<?, ?it/s]  1%|          | 625/112584 [00:00<00:18, 6218.93it/s]  1%|          | 1247/112584 [00:00<00:19, 5650.28it/s]  2%|▏         | 1816/112584 [00:00<00:20, 5361.02it/s]  2%|▏         | 2355/112584 [00:00<00:20, 5252.03it/s]  3%|▎         | 3060/112584 [00:00<00:18, 5862.65it/s]  3%|▎         | 3651/112584 [00:00<00:18, 5759.06it/s]  4%|▍         | 4274/112584 [00:00<00:18, 5901.48it/s]  4%|▍         | 4977/112584 [00:00<00:17, 6248.57it/s]  5%|▍         | 5605/112584 [00:00<00:17, 6146.74it/s]  6%|▌         | 6233/112584 [00:01<00:17, 6160.54it/s]  6%|▌         | 6851/112584 [00:01<00:18, 5687.80it/s]  7%|▋         | 7465/112584 [00:01<00:18, 5814.80it/s]  7%|▋         | 8053/112584 [00:01<00:18, 5659.42it/s]  8%|▊         | 8624/112584 [00:01<00:18, 5572.10it/s]  8%|▊         | 9233/112584 [00:01<00:18, 5719.79it/s]  9%|▉         | 9852/112584 [00:01<00:17, 5852.85it/s]  9%|▉         | 10440/112584 [00:01<00:17, 5815.03it/s] 10%|▉         | 11024/112584 [00:01<00:17, 5769.60it/s] 10%|█         | 11603/112584 [00:02<00:17, 5631.79it/s] 11%|█         | 12215/112584 [00:02<00:17, 5767.19it/s] 11%|█▏        | 12794/112584 [00:02<00:17, 5729.51it/s] 12%|█▏        | 13382/112584 [00:02<00:17, 5770.41it/s] 12%|█▏        | 14015/112584 [00:02<00:16, 5929.93it/s] 13%|█▎        | 14609/112584 [00:02<00:16, 5887.49it/s] 14%|█▎        | 15258/112584 [00:02<00:16, 6050.75it/s] 14%|█▍        | 15864/112584 [00:02<00:16, 5784.10it/s] 15%|█▍        | 16446/112584 [00:02<00:17, 5594.37it/s] 15%|█▌        | 17018/112584 [00:02<00:16, 5624.92it/s] 16%|█▌        | 17595/112584 [00:03<00:16, 5663.92it/s] 16%|█▌        | 18186/112584 [00:03<00:16, 5726.67it/s] 17%|█▋        | 18790/112584 [00:03<00:16, 5809.14it/s] 17%|█▋        | 19522/112584 [00:03<00:14, 6255.29it/s] 18%|█▊        | 20149/112584 [00:03<00:15, 5932.77it/s] 18%|█▊        | 20747/112584 [00:03<00:15, 5867.24it/s] 19%|█▉        | 21337/112584 [00:03<00:16, 5556.30it/s] 19%|█▉        | 21932/112584 [00:03<00:16, 5664.34it/s] 20%|██        | 22540/112584 [00:03<00:15, 5781.23it/s] 21%|██        | 23161/112584 [00:03<00:15, 5903.28it/s] 21%|██        | 23826/112584 [00:04<00:14, 6121.48it/s] 22%|██▏       | 24537/112584 [00:04<00:13, 6406.49it/s] 22%|██▏       | 25200/112584 [00:04<00:13, 6469.15it/s] 23%|██▎       | 25849/112584 [00:04<00:13, 6247.79it/s] 24%|██▎       | 26477/112584 [00:04<00:14, 5853.94it/s] 24%|██▍       | 27069/112584 [00:04<00:14, 5709.80it/s] 25%|██▍       | 27645/112584 [00:04<00:15, 5552.75it/s] 25%|██▌       | 28258/112584 [00:04<00:14, 5712.74it/s] 26%|██▌       | 28904/112584 [00:04<00:14, 5920.05it/s] 26%|██▌       | 29500/112584 [00:05<00:14, 5706.77it/s] 27%|██▋       | 30111/112584 [00:05<00:14, 5817.26it/s] 27%|██▋       | 30696/112584 [00:05<00:14, 5540.99it/s] 28%|██▊       | 31255/112584 [00:05<00:15, 5420.99it/s] 28%|██▊       | 31844/112584 [00:05<00:14, 5548.34it/s] 29%|██▉       | 32402/112584 [00:05<00:14, 5443.84it/s] 29%|██▉       | 32949/112584 [00:05<00:14, 5433.81it/s] 30%|██▉       | 33494/112584 [00:05<00:14, 5392.20it/s] 30%|███       | 34073/112584 [00:05<00:14, 5507.04it/s] 31%|███       | 34729/112584 [00:06<00:13, 5812.26it/s] 31%|███▏      | 35312/112584 [00:06<00:13, 5625.51it/s] 32%|███▏      | 35877/112584 [00:06<00:13, 5587.25it/s] 32%|███▏      | 36465/112584 [00:06<00:13, 5666.73it/s] 33%|███▎      | 37033/112584 [00:06<00:13, 5527.40it/s] 33%|███▎      | 37588/112584 [00:06<00:14, 5299.88it/s] 34%|███▍      | 38180/112584 [00:06<00:13, 5475.62it/s] 34%|███▍      | 38731/112584 [00:06<00:13, 5471.83it/s] 35%|███▍      | 39309/112584 [00:06<00:13, 5560.71it/s] 35%|███▌      | 39867/112584 [00:06<00:13, 5545.60it/s] 36%|███▌      | 40505/112584 [00:07<00:12, 5787.95it/s] 36%|███▋      | 41085/112584 [00:07<00:12, 5696.45it/s] 37%|███▋      | 41656/112584 [00:07<00:12, 5606.46it/s] 37%|███▋      | 42218/112584 [00:07<00:13, 5363.64it/s] 38%|███▊      | 42757/112584 [00:07<00:13, 5361.20it/s] 38%|███▊      | 43295/112584 [00:07<00:12, 5346.02it/s] 39%|███▉      | 43938/112584 [00:07<00:12, 5659.87it/s] 40%|███▉      | 44530/112584 [00:07<00:11, 5734.85it/s] 40%|████      | 45105/112584 [00:07<00:11, 5643.07it/s] 41%|████      | 45718/112584 [00:07<00:11, 5779.76it/s] 41%|████      | 46420/112584 [00:08<00:10, 6143.21it/s] 42%|████▏     | 47036/112584 [00:08<00:10, 6019.94it/s] 43%|████▎     | 47953/112584 [00:08<00:09, 6934.05it/s] 43%|████▎     | 48650/112584 [00:08<00:09, 6782.70it/s] 44%|████▍     | 49331/112584 [00:08<00:09, 6784.88it/s] 44%|████▍     | 50012/112584 [00:08<00:09, 6507.22it/s] 45%|████▌     | 50666/112584 [00:08<00:10, 6037.76it/s] 46%|████▌     | 51278/112584 [00:08<00:10, 5936.51it/s] 46%|████▌     | 51903/112584 [00:08<00:10, 6018.20it/s] 47%|████▋     | 52662/112584 [00:09<00:09, 6460.53it/s] 47%|████▋     | 53314/112584 [00:09<00:09, 6151.75it/s] 48%|████▊     | 53936/112584 [00:09<00:09, 6119.26it/s] 48%|████▊     | 54553/112584 [00:09<00:10, 5688.62it/s] 49%|████▉     | 55137/112584 [00:09<00:10, 5722.68it/s] 50%|████▉     | 55778/112584 [00:09<00:09, 5914.40it/s] 50%|█████     | 56375/112584 [00:09<00:09, 5884.58it/s] 51%|█████     | 56968/112584 [00:09<00:10, 5553.85it/s] 51%|█████     | 57529/112584 [00:09<00:10, 5493.39it/s] 52%|█████▏    | 58114/112584 [00:10<00:09, 5591.59it/s] 52%|█████▏    | 58826/112584 [00:10<00:08, 6030.33it/s] 53%|█████▎    | 59434/112584 [00:10<00:09, 5752.68it/s] 53%|█████▎    | 60015/112584 [00:10<00:09, 5727.10it/s] 54%|█████▍    | 60600/112584 [00:10<00:09, 5756.27it/s] 55%|█████▍    | 61368/112584 [00:10<00:08, 6310.46it/s] 55%|█████▌    | 62003/112584 [00:10<00:08, 5915.18it/s] 56%|█████▌    | 62606/112584 [00:10<00:08, 5942.98it/s] 56%|█████▌    | 63206/112584 [00:10<00:08, 5750.15it/s] 57%|█████▋    | 63812/112584 [00:10<00:08, 5831.73it/s] 57%|█████▋    | 64399/112584 [00:11<00:08, 5763.31it/s] 58%|█████▊    | 64984/112584 [00:11<00:08, 5782.00it/s] 58%|█████▊    | 65564/112584 [00:11<00:08, 5582.52it/s] 59%|█████▉    | 66156/112584 [00:11<00:08, 5676.78it/s] 59%|█████▉    | 66882/112584 [00:11<00:07, 6135.36it/s] 60%|█████▉    | 67499/112584 [00:11<00:07, 5694.41it/s] 60%|██████    | 68077/112584 [00:11<00:08, 5517.24it/s] 61%|██████    | 68778/112584 [00:11<00:07, 5931.63it/s] 62%|██████▏   | 69379/112584 [00:11<00:07, 5880.90it/s] 62%|██████▏   | 70051/112584 [00:12<00:06, 6119.21it/s] 63%|██████▎   | 70668/112584 [00:12<00:07, 5886.99it/s] 63%|██████▎   | 71262/112584 [00:12<00:07, 5812.94it/s] 64%|██████▍   | 71847/112584 [00:12<00:07, 5817.02it/s] 64%|██████▍   | 72486/112584 [00:12<00:06, 5969.58it/s] 65%|██████▌   | 73199/112584 [00:12<00:06, 6308.63it/s] 66%|██████▌   | 73878/112584 [00:12<00:06, 6450.38it/s] 66%|██████▋   | 74595/112584 [00:12<00:05, 6658.66it/s] 67%|██████▋   | 75263/112584 [00:12<00:05, 6353.98it/s] 67%|██████▋   | 75903/112584 [00:12<00:05, 6196.73it/s] 68%|██████▊   | 76526/112584 [00:13<00:05, 6200.66it/s] 69%|██████▊   | 77149/112584 [00:13<00:05, 5937.88it/s] 69%|██████▉   | 77806/112584 [00:13<00:05, 6114.12it/s] 70%|██████▉   | 78421/112584 [00:13<00:05, 5861.69it/s] 70%|███████   | 79011/112584 [00:13<00:06, 5544.27it/s] 71%|███████   | 79571/112584 [00:13<00:06, 5430.35it/s] 71%|███████   | 80118/112584 [00:13<00:06, 5388.88it/s] 72%|███████▏  | 80709/112584 [00:13<00:05, 5533.60it/s] 72%|███████▏  | 81378/112584 [00:13<00:05, 5861.19it/s] 73%|███████▎  | 81968/112584 [00:14<00:05, 5728.64it/s] 73%|███████▎  | 82562/112584 [00:14<00:05, 5786.37it/s] 74%|███████▍  | 83247/112584 [00:14<00:04, 6093.63it/s] 74%|███████▍  | 83859/112584 [00:14<00:04, 5972.24it/s] 75%|███████▌  | 84459/112584 [00:14<00:04, 5791.54it/s] 76%|███████▌  | 85065/112584 [00:14<00:04, 5868.44it/s] 76%|███████▌  | 85665/112584 [00:14<00:04, 5905.05it/s] 77%|███████▋  | 86257/112584 [00:14<00:04, 5721.25it/s] 77%|███████▋  | 86964/112584 [00:14<00:04, 6110.37it/s] 78%|███████▊  | 87578/112584 [00:14<00:04, 6091.77it/s] 78%|███████▊  | 88228/112584 [00:15<00:03, 6211.36it/s] 79%|███████▉  | 88851/112584 [00:15<00:04, 5643.43it/s] 79%|███████▉  | 89427/112584 [00:15<00:04, 5546.86it/s] 80%|███████▉  | 89989/112584 [00:15<00:04, 5495.70it/s] 80%|████████  | 90553/112584 [00:15<00:03, 5531.00it/s] 81%|████████  | 91118/112584 [00:15<00:03, 5563.46it/s] 81%|████████▏ | 91747/112584 [00:15<00:03, 5769.99it/s] 82%|████████▏ | 92403/112584 [00:15<00:03, 5998.54it/s] 83%|████████▎ | 93006/112584 [00:15<00:03, 5843.00it/s] 83%|████████▎ | 93593/112584 [00:16<00:03, 5834.17it/s] 84%|████████▎ | 94178/112584 [00:16<00:03, 5700.39it/s] 84%|████████▍ | 94860/112584 [00:16<00:02, 6024.81it/s] 85%|████████▍ | 95465/112584 [00:16<00:02, 5860.88it/s] 85%|████████▌ | 96054/112584 [00:16<00:02, 5847.18it/s] 86%|████████▌ | 96884/112584 [00:16<00:02, 6551.47it/s] 87%|████████▋ | 97542/112584 [00:16<00:02, 6047.43it/s] 87%|████████▋ | 98162/112584 [00:16<00:02, 6088.29it/s] 88%|████████▊ | 98778/112584 [00:16<00:02, 5853.81it/s] 88%|████████▊ | 99370/112584 [00:17<00:02, 5724.55it/s] 89%|████████▉ | 99947/112584 [00:17<00:02, 5720.83it/s] 89%|████████▉ | 100522/112584 [00:17<00:02, 5479.53it/s] 90%|████████▉ | 101158/112584 [00:17<00:01, 5726.06it/s] 90%|█████████ | 101740/112584 [00:17<00:01, 5752.76it/s] 91%|█████████ | 102357/112584 [00:17<00:01, 5866.31it/s] 91%|█████████▏| 102954/112584 [00:17<00:01, 5894.17it/s] 92%|█████████▏| 103546/112584 [00:17<00:01, 5690.78it/s] 92%|█████████▏| 104118/112584 [00:17<00:01, 5513.78it/s] 93%|█████████▎| 104762/112584 [00:17<00:01, 5777.86it/s] 94%|█████████▎| 105343/112584 [00:18<00:01, 5546.63it/s] 94%|█████████▍| 105981/112584 [00:18<00:01, 5781.96it/s] 95%|█████████▍| 106563/112584 [00:18<00:01, 5689.72it/s] 95%|█████████▌| 107135/112584 [00:18<00:00, 5587.61it/s] 96%|█████████▌| 107719/112584 [00:18<00:00, 5659.90it/s] 96%|█████████▌| 108287/112584 [00:18<00:00, 5541.03it/s] 97%|█████████▋| 108843/112584 [00:18<00:00, 5339.67it/s] 97%|█████████▋| 109417/112584 [00:18<00:00, 5452.30it/s] 98%|█████████▊| 110017/112584 [00:18<00:00, 5601.47it/s] 98%|█████████▊| 110648/112584 [00:19<00:00, 5802.92it/s] 99%|█████████▉| 111292/112584 [00:19<00:00, 5989.72it/s] 99%|█████████▉| 111893/112584 [00:19<00:00, 5853.74it/s]100%|█████████▉| 112534/112584 [00:19<00:00, 6014.06it/s]100%|██████████| 112584/112584 [00:19<00:00, 5821.38it/s]

gathering stats for n=1
  0%|          | 0/112584 [00:00<?, ?it/s]  2%|▏         | 1795/112584 [00:00<00:06, 17943.56it/s]  3%|▎         | 3697/112584 [00:00<00:05, 18570.32it/s]  5%|▌         | 5817/112584 [00:00<00:05, 19769.29it/s]  7%|▋         | 7794/112584 [00:00<00:05, 18874.59it/s]  9%|▊         | 9688/112584 [00:00<00:05, 18742.08it/s] 10%|█         | 11566/112584 [00:00<00:05, 18712.18it/s] 12%|█▏        | 13508/112584 [00:00<00:05, 18938.92it/s] 14%|█▎        | 15417/112584 [00:00<00:05, 18984.11it/s] 15%|█▌        | 17317/112584 [00:00<00:05, 18747.96it/s] 17%|█▋        | 19399/112584 [00:01<00:04, 19373.93it/s] 19%|█▉        | 21339/112584 [00:01<00:04, 18749.36it/s] 21%|██        | 23290/112584 [00:01<00:04, 18969.48it/s] 23%|██▎       | 25499/112584 [00:01<00:04, 19890.93it/s] 24%|██▍       | 27493/112584 [00:01<00:04, 18926.02it/s] 26%|██▌       | 29403/112584 [00:01<00:04, 18975.67it/s] 28%|██▊       | 31310/112584 [00:01<00:04, 18621.34it/s] 29%|██▉       | 33179/112584 [00:01<00:04, 18289.67it/s] 31%|███       | 35101/112584 [00:01<00:04, 18557.84it/s] 33%|███▎      | 36962/112584 [00:01<00:04, 18405.69it/s] 34%|███▍      | 38806/112584 [00:02<00:04, 18276.01it/s] 36%|███▌      | 40727/112584 [00:02<00:03, 18546.15it/s] 38%|███▊      | 42584/112584 [00:02<00:03, 18186.62it/s] 39%|███▉      | 44469/112584 [00:02<00:03, 18379.83it/s] 41%|████▏     | 46479/112584 [00:02<00:03, 18882.24it/s] 43%|████▎     | 48748/112584 [00:02<00:03, 20003.15it/s] 45%|████▌     | 50752/112584 [00:02<00:03, 19735.50it/s] 47%|████▋     | 52865/112584 [00:02<00:02, 20136.62it/s] 49%|████▊     | 54882/112584 [00:02<00:02, 19440.84it/s] 50%|█████     | 56833/112584 [00:02<00:02, 19233.36it/s] 52%|█████▏    | 58807/112584 [00:03<00:02, 19375.70it/s] 54%|█████▍    | 60749/112584 [00:03<00:02, 19055.86it/s] 56%|█████▌    | 62722/112584 [00:03<00:02, 19252.33it/s] 57%|█████▋    | 64650/112584 [00:03<00:02, 19045.39it/s] 59%|█████▉    | 66616/112584 [00:03<00:02, 19221.58it/s] 61%|██████    | 68540/112584 [00:03<00:02, 18899.11it/s] 63%|██████▎   | 70567/112584 [00:03<00:02, 19294.40it/s] 64%|██████▍   | 72509/112584 [00:03<00:02, 19328.02it/s] 66%|██████▋   | 74768/112584 [00:03<00:01, 20290.72it/s] 68%|██████▊   | 76800/112584 [00:04<00:01, 20052.30it/s] 70%|██████▉   | 78808/112584 [00:04<00:01, 19477.49it/s] 72%|███████▏  | 80761/112584 [00:04<00:01, 19042.60it/s] 73%|███████▎  | 82747/112584 [00:04<00:01, 19278.15it/s] 75%|███████▌  | 84775/112584 [00:04<00:01, 19567.59it/s] 77%|███████▋  | 86736/112584 [00:04<00:01, 19351.15it/s] 79%|███████▉  | 88674/112584 [00:04<00:01, 19227.52it/s] 80%|████████  | 90599/112584 [00:04<00:01, 18841.85it/s] 82%|████████▏ | 92624/112584 [00:04<00:01, 19248.55it/s] 84%|████████▍ | 94552/112584 [00:04<00:00, 19074.98it/s] 86%|████████▌ | 96652/112584 [00:05<00:00, 19639.94it/s] 88%|████████▊ | 98619/112584 [00:05<00:00, 19325.32it/s] 89%|████████▉ | 100555/112584 [00:05<00:00, 18917.51it/s] 91%|█████████ | 102511/112584 [00:05<00:00, 19099.32it/s] 93%|█████████▎| 104424/112584 [00:05<00:00, 19097.88it/s] 94%|█████████▍| 106336/112584 [00:05<00:00, 18942.39it/s] 96%|█████████▌| 108232/112584 [00:05<00:00, 18761.41it/s] 98%|█████████▊| 110110/112584 [00:05<00:00, 18533.28it/s]100%|█████████▉| 112110/112584 [00:05<00:00, 18960.70it/s]100%|██████████| 112584/112584 [00:05<00:00, 19091.24it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 597.65it/s]2022-03-14 10:15:00 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=39136, bias=False)
  )
)
2022-03-14 10:15:00 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-14 10:15:00 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-14 10:15:00 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-14 10:15:00 | INFO | fairseq_cli.train | num. shared model params: 38,951,936 (num. trained: 38,951,936)
2022-03-14 10:15:00 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-14 10:15:00 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/valid
2022-03-14 10:15:00 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-14 10:15:00 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 10:15:00 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = NVIDIA TITAN RTX                        
2022-03-14 10:15:00 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 10:15:00 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-14 10:15:00 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-03-14 10:15:00 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 10:15:00 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 10:15:00 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-14 10:15:00 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
2022-03-14 10:15:00 | INFO | fairseq.trainer | begin training epoch 1
2022-03-14 10:15:00 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-14 10:15:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-14 10:15:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 10:15:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 10:15:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 10:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:17:52 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 13.106 | ppl 8818.43 | wps 66416.4 | wpb 2040.3 | bsz 4 | num_updates 99
2022-03-14 10:17:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 99 updates
2022-03-14 10:17:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:17:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:17:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 1 @ 99 updates, score 13.106) (writing took 1.848866418004036 seconds)
2022-03-14 10:17:54 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-14 10:17:54 | INFO | train | epoch 001 | loss 14.379 | ppl 21302 | wps 40017.3 | ups 0.61 | wpb 65303.3 | bsz 127.6 | num_updates 99 | lr 1.24725e-05 | gnorm 2.848 | loss_scale 8 | train_wall 162 | gb_free 20.8 | wall 173
KL Stats: Epoch 1 Divergences: Uniform: 0.5634753499411624 Unigram: 2.4863806962353117
2022-03-14 10:17:54 | INFO | fairseq.trainer | begin training epoch 2
2022-03-14 10:17:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:17:55 | INFO | train_inner | epoch 002:      1 / 103 loss=14.367, ppl=21125.4, wps=40009.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=100, lr=1.25975e-05, gnorm=2.832, loss_scale=8, train_wall=164, gb_free=20.8, wall=175
2022-03-14 10:20:33 | INFO | train_inner | epoch 002:    101 / 103 loss=12.579, ppl=6118.28, wps=41422.5, ups=0.63, wpb=65530.9, bsz=128, num_updates=200, lr=2.5095e-05, gnorm=1.059, loss_scale=8, train_wall=153, gb_free=20.8, wall=333
2022-03-14 10:20:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:20:40 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.828 | ppl 3636.61 | wps 66511.8 | wpb 2040.3 | bsz 4 | num_updates 202 | best_loss 11.828
2022-03-14 10:20:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 202 updates
2022-03-14 10:20:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:20:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 2 @ 202 updates, score 11.828) (writing took 1.9644834697246552 seconds)
2022-03-14 10:20:42 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-14 10:20:42 | INFO | train | epoch 002 | loss 12.574 | ppl 6096.88 | wps 40035.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 202 | lr 2.5345e-05 | gnorm 1.056 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 341
KL Stats: Epoch 2 Divergences: Uniform: 0.5328058026213118 Unigram: 1.1961788042628971
2022-03-14 10:20:42 | INFO | fairseq.trainer | begin training epoch 3
2022-03-14 10:20:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:23:17 | INFO | train_inner | epoch 003:     98 / 103 loss=11.398, ppl=2698.31, wps=39950.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=300, lr=3.75925e-05, gnorm=0.633, loss_scale=8, train_wall=153, gb_free=20.8, wall=496
2022-03-14 10:23:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:23:28 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.932 | ppl 1953.65 | wps 66078.9 | wpb 2040.3 | bsz 4 | num_updates 305 | best_loss 10.932
2022-03-14 10:23:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 305 updates
2022-03-14 10:23:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:23:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:23:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 3 @ 305 updates, score 10.932) (writing took 1.9631240414455533 seconds)
2022-03-14 10:23:30 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-14 10:23:30 | INFO | train | epoch 003 | loss 11.371 | ppl 2648.7 | wps 39991.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 305 | lr 3.82174e-05 | gnorm 0.621 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 509
KL Stats: Epoch 3 Divergences: Uniform: 0.7327769108667406 Unigram: 0.5861517569474237
2022-03-14 10:23:30 | INFO | fairseq.trainer | begin training epoch 4
2022-03-14 10:23:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:26:00 | INFO | train_inner | epoch 004:     95 / 103 loss=10.783, ppl=1762.56, wps=39952.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=400, lr=5.009e-05, gnorm=0.409, loss_scale=8, train_wall=153, gb_free=20.8, wall=660
2022-03-14 10:26:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:26:16 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.574 | ppl 1523.96 | wps 66158.6 | wpb 2040.3 | bsz 4 | num_updates 408 | best_loss 10.574
2022-03-14 10:26:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 408 updates
2022-03-14 10:26:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:26:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:26:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 4 @ 408 updates, score 10.574) (writing took 1.9538718396797776 seconds)
2022-03-14 10:26:18 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-14 10:26:18 | INFO | train | epoch 004 | loss 10.761 | ppl 1735.9 | wps 39987.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 408 | lr 5.10898e-05 | gnorm 0.408 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 678
KL Stats: Epoch 4 Divergences: Uniform: 1.1221427191088593 Unigram: 0.473093665352022
2022-03-14 10:26:18 | INFO | fairseq.trainer | begin training epoch 5
2022-03-14 10:26:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:28:44 | INFO | train_inner | epoch 005:     92 / 103 loss=10.475, ppl=1423.61, wps=39940.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=500, lr=6.25875e-05, gnorm=0.458, loss_scale=8, train_wall=153, gb_free=20.8, wall=823
2022-03-14 10:29:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:29:04 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.275 | ppl 1238.65 | wps 66018.9 | wpb 2040.3 | bsz 4 | num_updates 511 | best_loss 10.275
2022-03-14 10:29:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 511 updates
2022-03-14 10:29:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:29:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:29:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 5 @ 511 updates, score 10.275) (writing took 1.9639654168859124 seconds)
2022-03-14 10:29:06 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-14 10:29:06 | INFO | train | epoch 005 | loss 10.446 | ppl 1395.3 | wps 39986.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 511 | lr 6.39622e-05 | gnorm 0.463 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 846
KL Stats: Epoch 5 Divergences: Uniform: 1.3302371788305498 Unigram: 0.6612461189173214
2022-03-14 10:29:06 | INFO | fairseq.trainer | begin training epoch 6
2022-03-14 10:29:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:31:27 | INFO | train_inner | epoch 006:     89 / 103 loss=10.192, ppl=1169.8, wps=39931.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=600, lr=7.5085e-05, gnorm=0.552, loss_scale=16, train_wall=153, gb_free=20.8, wall=987
2022-03-14 10:31:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:31:53 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10 | ppl 1024.12 | wps 66022.1 | wpb 2040.3 | bsz 4 | num_updates 614 | best_loss 10
2022-03-14 10:31:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 614 updates
2022-03-14 10:31:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:31:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:31:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 6 @ 614 updates, score 10.0) (writing took 1.981885484419763 seconds)
2022-03-14 10:31:55 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-14 10:31:55 | INFO | train | epoch 006 | loss 10.163 | ppl 1146.79 | wps 39965.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 614 | lr 7.68347e-05 | gnorm 0.558 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 1014
KL Stats: Epoch 6 Divergences: Uniform: 1.4272402987141695 Unigram: 0.8823406241754698
2022-03-14 10:31:55 | INFO | fairseq.trainer | begin training epoch 7
2022-03-14 10:31:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:34:11 | INFO | train_inner | epoch 007:     86 / 103 loss=9.935, ppl=978.87, wps=39951.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=700, lr=8.75825e-05, gnorm=0.61, loss_scale=16, train_wall=153, gb_free=20.8, wall=1150
2022-03-14 10:34:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:34:41 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.756 | ppl 864.89 | wps 65612.1 | wpb 2040.3 | bsz 4 | num_updates 717 | best_loss 9.756
2022-03-14 10:34:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 717 updates
2022-03-14 10:34:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:34:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:34:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 7 @ 717 updates, score 9.756) (writing took 2.0773100052028894 seconds)
2022-03-14 10:34:43 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-14 10:34:43 | INFO | train | epoch 007 | loss 9.897 | ppl 953.49 | wps 39957.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 717 | lr 8.97071e-05 | gnorm 0.657 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 1182
KL Stats: Epoch 7 Divergences: Uniform: 1.5338757652094717 Unigram: 1.0698493774781643
2022-03-14 10:34:43 | INFO | fairseq.trainer | begin training epoch 8
2022-03-14 10:34:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:36:55 | INFO | train_inner | epoch 008:     83 / 103 loss=9.684, ppl=822.38, wps=39895.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=800, lr=0.00010008, gnorm=0.732, loss_scale=16, train_wall=153, gb_free=20.8, wall=1314
2022-03-14 10:37:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:37:29 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.511 | ppl 729.8 | wps 65982.8 | wpb 2040.3 | bsz 4 | num_updates 820 | best_loss 9.511
2022-03-14 10:37:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 820 updates
2022-03-14 10:37:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:37:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:37:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 8 @ 820 updates, score 9.511) (writing took 2.081004912033677 seconds)
2022-03-14 10:37:31 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-14 10:37:31 | INFO | train | epoch 008 | loss 9.641 | ppl 798.35 | wps 39944.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 820 | lr 0.00010258 | gnorm 0.711 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 1351
KL Stats: Epoch 8 Divergences: Uniform: 1.6567799067313111 Unigram: 1.2418059074777854
2022-03-14 10:37:31 | INFO | fairseq.trainer | begin training epoch 9
2022-03-14 10:37:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:39:38 | INFO | train_inner | epoch 009:     80 / 103 loss=9.46, ppl=704.42, wps=39914.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=900, lr=0.000112578, gnorm=0.746, loss_scale=16, train_wall=153, gb_free=20.8, wall=1478
2022-03-14 10:40:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:40:18 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.306 | ppl 632.88 | wps 66556.2 | wpb 2040.3 | bsz 4 | num_updates 923 | best_loss 9.306
2022-03-14 10:40:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 923 updates
2022-03-14 10:40:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:40:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:40:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 9 @ 923 updates, score 9.306) (writing took 2.085583357140422 seconds)
2022-03-14 10:40:20 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-14 10:40:20 | INFO | train | epoch 009 | loss 9.414 | ppl 682.35 | wps 39956.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 923 | lr 0.000115452 | gnorm 0.772 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 1519
KL Stats: Epoch 9 Divergences: Uniform: 1.753031221967096 Unigram: 1.403749544930046
2022-03-14 10:40:20 | INFO | fairseq.trainer | begin training epoch 10
2022-03-14 10:40:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:42:22 | INFO | train_inner | epoch 010:     77 / 103 loss=9.26, ppl=613.12, wps=39890, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1000, lr=0.000125075, gnorm=0.766, loss_scale=16, train_wall=153, gb_free=20.8, wall=1641
2022-03-14 10:43:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:43:06 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.144 | ppl 565.62 | wps 66006.5 | wpb 2040.3 | bsz 4 | num_updates 1026 | best_loss 9.144
2022-03-14 10:43:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1026 updates
2022-03-14 10:43:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:43:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:43:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 10 @ 1026 updates, score 9.144) (writing took 2.099578677676618 seconds)
2022-03-14 10:43:08 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-14 10:43:08 | INFO | train | epoch 010 | loss 9.221 | ppl 596.68 | wps 39909.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1026 | lr 0.000128324 | gnorm 0.775 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 1688
KL Stats: Epoch 10 Divergences: Uniform: 1.84062502490286 Unigram: 1.548596724257306
2022-03-14 10:43:08 | INFO | fairseq.trainer | begin training epoch 11
2022-03-14 10:43:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:45:06 | INFO | train_inner | epoch 011:     74 / 103 loss=9.092, ppl=545.72, wps=39870.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1100, lr=0.000137573, gnorm=0.793, loss_scale=32, train_wall=153, gb_free=20.8, wall=1805
2022-03-14 10:45:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:45:55 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.994 | ppl 509.85 | wps 66288.4 | wpb 2040.3 | bsz 4 | num_updates 1129 | best_loss 8.994
2022-03-14 10:45:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1129 updates
2022-03-14 10:45:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:45:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:45:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 11 @ 1129 updates, score 8.994) (writing took 2.091752126812935 seconds)
2022-03-14 10:45:57 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-14 10:45:57 | INFO | train | epoch 011 | loss 9.051 | ppl 530.5 | wps 39927.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1129 | lr 0.000141197 | gnorm 0.791 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 1856
KL Stats: Epoch 11 Divergences: Uniform: 1.9270852341815012 Unigram: 1.6704871667663417
2022-03-14 10:45:57 | INFO | fairseq.trainer | begin training epoch 12
2022-03-14 10:45:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:47:49 | INFO | train_inner | epoch 012:     71 / 103 loss=8.944, ppl=492.55, wps=39893, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1200, lr=0.00015007, gnorm=0.805, loss_scale=32, train_wall=153, gb_free=20.8, wall=1969
2022-03-14 10:48:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:48:43 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.858 | ppl 464.06 | wps 66318.8 | wpb 2040.3 | bsz 4 | num_updates 1232 | best_loss 8.858
2022-03-14 10:48:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1232 updates
2022-03-14 10:48:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:48:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:48:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 12 @ 1232 updates, score 8.858) (writing took 2.0731195490807295 seconds)
2022-03-14 10:48:45 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-14 10:48:45 | INFO | train | epoch 012 | loss 8.895 | ppl 476.02 | wps 39925.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1232 | lr 0.000154069 | gnorm 0.792 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 2025
KL Stats: Epoch 12 Divergences: Uniform: 2.0098115106241017 Unigram: 1.7739136393169306
2022-03-14 10:48:45 | INFO | fairseq.trainer | begin training epoch 13
2022-03-14 10:48:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:50:33 | INFO | train_inner | epoch 013:     68 / 103 loss=8.79, ppl=442.64, wps=39882.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1300, lr=0.000162568, gnorm=0.805, loss_scale=32, train_wall=153, gb_free=20.8, wall=2133
2022-03-14 10:51:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:51:32 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.743 | ppl 428.49 | wps 66440.8 | wpb 2040.3 | bsz 4 | num_updates 1335 | best_loss 8.743
2022-03-14 10:51:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1335 updates
2022-03-14 10:51:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:51:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:51:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 13 @ 1335 updates, score 8.743) (writing took 2.115653377957642 seconds)
2022-03-14 10:51:34 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-14 10:51:34 | INFO | train | epoch 013 | loss 8.747 | ppl 429.7 | wps 39906.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1335 | lr 0.000166942 | gnorm 0.824 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 2193
KL Stats: Epoch 13 Divergences: Uniform: 2.0893915453830507 Unigram: 1.8696813088824267
2022-03-14 10:51:34 | INFO | fairseq.trainer | begin training epoch 14
2022-03-14 10:51:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:53:17 | INFO | train_inner | epoch 014:     65 / 103 loss=8.653, ppl=402.41, wps=39881.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1400, lr=0.000175065, gnorm=0.827, loss_scale=32, train_wall=153, gb_free=20.8, wall=2296
2022-03-14 10:54:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:54:20 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.645 | ppl 400.35 | wps 66509.1 | wpb 2040.3 | bsz 4 | num_updates 1438 | best_loss 8.645
2022-03-14 10:54:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1438 updates
2022-03-14 10:54:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:54:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:54:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 14 @ 1438 updates, score 8.645) (writing took 2.092961410060525 seconds)
2022-03-14 10:54:22 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-14 10:54:22 | INFO | train | epoch 014 | loss 8.603 | ppl 388.88 | wps 39939.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1438 | lr 0.000179814 | gnorm 0.838 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 2362
KL Stats: Epoch 14 Divergences: Uniform: 2.1664416684960566 Unigram: 1.955083764831386
2022-03-14 10:54:22 | INFO | fairseq.trainer | begin training epoch 15
2022-03-14 10:54:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:56:01 | INFO | train_inner | epoch 015:     62 / 103 loss=8.516, ppl=365.99, wps=39904.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1500, lr=0.000187563, gnorm=0.858, loss_scale=32, train_wall=153, gb_free=20.8, wall=2460
2022-03-14 10:57:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:57:09 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.518 | ppl 366.49 | wps 66302 | wpb 2040.3 | bsz 4 | num_updates 1541 | best_loss 8.518
2022-03-14 10:57:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1541 updates
2022-03-14 10:57:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:57:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:57:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 15 @ 1541 updates, score 8.518) (writing took 2.066425814293325 seconds)
2022-03-14 10:57:11 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-14 10:57:11 | INFO | train | epoch 015 | loss 8.462 | ppl 352.6 | wps 39953.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1541 | lr 0.000192686 | gnorm 0.858 | loss_scale 64 | train_wall 158 | gb_free 20.8 | wall 2530
KL Stats: Epoch 15 Divergences: Uniform: 2.237480836056663 Unigram: 2.0368747023020917
2022-03-14 10:57:11 | INFO | fairseq.trainer | begin training epoch 16
2022-03-14 10:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:57:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 10:58:46 | INFO | train_inner | epoch 016:     60 / 103 loss=8.376, ppl=332.17, wps=39522.1, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1600, lr=0.00020006, gnorm=0.837, loss_scale=32, train_wall=155, gb_free=20.8, wall=2625
2022-03-14 10:59:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:59:57 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.408 | ppl 339.78 | wps 65761.1 | wpb 2040.3 | bsz 4 | num_updates 1643 | best_loss 8.408
2022-03-14 10:59:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1643 updates
2022-03-14 10:59:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:59:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 10:59:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 16 @ 1643 updates, score 8.408) (writing took 2.05720098875463 seconds)
2022-03-14 10:59:59 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-14 10:59:59 | INFO | train | epoch 016 | loss 8.318 | ppl 319.06 | wps 39548 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 1643 | lr 0.000205434 | gnorm 0.832 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 2699
KL Stats: Epoch 16 Divergences: Uniform: 2.3076049184921956 Unigram: 2.112014713301383
2022-03-14 10:59:59 | INFO | fairseq.trainer | begin training epoch 17
2022-03-14 10:59:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:01:29 | INFO | train_inner | epoch 017:     57 / 103 loss=8.24, ppl=302.32, wps=39908, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1700, lr=0.000212558, gnorm=0.863, loss_scale=32, train_wall=153, gb_free=20.8, wall=2789
2022-03-14 11:02:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:02:45 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.314 | ppl 318.31 | wps 66122.6 | wpb 2040.3 | bsz 4 | num_updates 1746 | best_loss 8.314
2022-03-14 11:02:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1746 updates
2022-03-14 11:02:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:02:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:02:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 17 @ 1746 updates, score 8.314) (writing took 2.08294471539557 seconds)
2022-03-14 11:02:47 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-14 11:02:47 | INFO | train | epoch 017 | loss 8.181 | ppl 290.15 | wps 39947.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1746 | lr 0.000218306 | gnorm 0.882 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 2867
KL Stats: Epoch 17 Divergences: Uniform: 2.3802210390063583 Unigram: 2.185547634396934
2022-03-14 11:02:47 | INFO | fairseq.trainer | begin training epoch 18
2022-03-14 11:02:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:04:13 | INFO | train_inner | epoch 018:     54 / 103 loss=8.103, ppl=275.01, wps=39891, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1800, lr=0.000225055, gnorm=0.874, loss_scale=32, train_wall=153, gb_free=20.8, wall=2953
2022-03-14 11:05:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:05:34 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.221 | ppl 298.44 | wps 66302.6 | wpb 2040.3 | bsz 4 | num_updates 1849 | best_loss 8.221
2022-03-14 11:05:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1849 updates
2022-03-14 11:05:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:05:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:05:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 18 @ 1849 updates, score 8.221) (writing took 2.0541336219757795 seconds)
2022-03-14 11:05:36 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-14 11:05:36 | INFO | train | epoch 018 | loss 8.042 | ppl 263.65 | wps 39941.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1849 | lr 0.000231179 | gnorm 0.853 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3035
KL Stats: Epoch 18 Divergences: Uniform: 2.4477501154033607 Unigram: 2.254876117944805
2022-03-14 11:05:36 | INFO | fairseq.trainer | begin training epoch 19
2022-03-14 11:05:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:06:57 | INFO | train_inner | epoch 019:     51 / 103 loss=7.975, ppl=251.53, wps=39896.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1900, lr=0.000237553, gnorm=0.863, loss_scale=32, train_wall=153, gb_free=20.8, wall=3116
2022-03-14 11:08:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:08:22 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.13 | ppl 280.19 | wps 66306.8 | wpb 2040.3 | bsz 4 | num_updates 1952 | best_loss 8.13
2022-03-14 11:08:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1952 updates
2022-03-14 11:08:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:08:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:08:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 19 @ 1952 updates, score 8.13) (writing took 2.25525361020118 seconds)
2022-03-14 11:08:25 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-14 11:08:25 | INFO | train | epoch 019 | loss 7.909 | ppl 240.38 | wps 39872.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1952 | lr 0.000244051 | gnorm 0.862 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3204
KL Stats: Epoch 19 Divergences: Uniform: 2.5169772213721546 Unigram: 2.3213130424109485
2022-03-14 11:08:25 | INFO | fairseq.trainer | begin training epoch 20
2022-03-14 11:08:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:09:41 | INFO | train_inner | epoch 020:     48 / 103 loss=7.85, ppl=230.65, wps=39833.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2000, lr=0.00025005, gnorm=0.849, loss_scale=32, train_wall=153, gb_free=20.8, wall=3280
2022-03-14 11:11:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:11:11 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.054 | ppl 265.81 | wps 66283.4 | wpb 2040.3 | bsz 4 | num_updates 2055 | best_loss 8.054
2022-03-14 11:11:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 2055 updates
2022-03-14 11:11:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:11:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:11:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 20 @ 2055 updates, score 8.054) (writing took 2.0158108407631516 seconds)
2022-03-14 11:11:13 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-14 11:11:13 | INFO | train | epoch 020 | loss 7.781 | ppl 219.89 | wps 39951.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2055 | lr 0.000256924 | gnorm 0.845 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3373
KL Stats: Epoch 20 Divergences: Uniform: 2.5841463028661202 Unigram: 2.383825945880493
2022-03-14 11:11:13 | INFO | fairseq.trainer | begin training epoch 21
2022-03-14 11:11:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:11:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 11:12:26 | INFO | train_inner | epoch 021:     46 / 103 loss=7.719, ppl=210.75, wps=39538.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2100, lr=0.000262548, gnorm=0.867, loss_scale=32, train_wall=155, gb_free=20.8, wall=3445
2022-03-14 11:13:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:13:59 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.992 | ppl 254.53 | wps 65779.1 | wpb 2040.3 | bsz 4 | num_updates 2157 | best_loss 7.992
2022-03-14 11:13:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2157 updates
2022-03-14 11:13:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:14:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:14:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 21 @ 2157 updates, score 7.992) (writing took 2.075790314003825 seconds)
2022-03-14 11:14:01 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-14 11:14:01 | INFO | train | epoch 021 | loss 7.661 | ppl 202.43 | wps 39533.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 2157 | lr 0.000269671 | gnorm 0.86 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3541
KL Stats: Epoch 21 Divergences: Uniform: 2.6530499349231444 Unigram: 2.4447258304260635
2022-03-14 11:14:01 | INFO | fairseq.trainer | begin training epoch 22
2022-03-14 11:14:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:15:10 | INFO | train_inner | epoch 022:     43 / 103 loss=7.612, ppl=195.67, wps=39868.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2200, lr=0.000275045, gnorm=0.843, loss_scale=32, train_wall=153, gb_free=20.8, wall=3609
2022-03-14 11:16:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:16:48 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.924 | ppl 242.85 | wps 66106.8 | wpb 2040.3 | bsz 4 | num_updates 2260 | best_loss 7.924
2022-03-14 11:16:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2260 updates
2022-03-14 11:16:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:16:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:16:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 22 @ 2260 updates, score 7.924) (writing took 2.139235978014767 seconds)
2022-03-14 11:16:50 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-14 11:16:50 | INFO | train | epoch 022 | loss 7.55 | ppl 187.41 | wps 39907.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2260 | lr 0.000282544 | gnorm 0.846 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3710
KL Stats: Epoch 22 Divergences: Uniform: 2.7134354264826492 Unigram: 2.5003557887047516
2022-03-14 11:16:50 | INFO | fairseq.trainer | begin training epoch 23
2022-03-14 11:16:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:17:54 | INFO | train_inner | epoch 023:     40 / 103 loss=7.504, ppl=181.53, wps=39846.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2300, lr=0.000287543, gnorm=0.849, loss_scale=32, train_wall=153, gb_free=20.8, wall=3773
2022-03-14 11:19:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:19:37 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.868 | ppl 233.55 | wps 66500.7 | wpb 2040.3 | bsz 4 | num_updates 2363 | best_loss 7.868
2022-03-14 11:19:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2363 updates
2022-03-14 11:19:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:19:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:19:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 23 @ 2363 updates, score 7.868) (writing took 2.1224648086354136 seconds)
2022-03-14 11:19:39 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-14 11:19:39 | INFO | train | epoch 023 | loss 7.444 | ppl 174.1 | wps 39881.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2363 | lr 0.000295416 | gnorm 0.855 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3878
KL Stats: Epoch 23 Divergences: Uniform: 2.7749807152251806 Unigram: 2.5541044896032146
2022-03-14 11:19:39 | INFO | fairseq.trainer | begin training epoch 24
2022-03-14 11:19:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:20:37 | INFO | train_inner | epoch 024:     37 / 103 loss=7.404, ppl=169.34, wps=39863.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2400, lr=0.00030004, gnorm=0.832, loss_scale=32, train_wall=153, gb_free=20.8, wall=3937
2022-03-14 11:22:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:22:25 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.821 | ppl 226.13 | wps 66341.6 | wpb 2040.3 | bsz 4 | num_updates 2466 | best_loss 7.821
2022-03-14 11:22:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2466 updates
2022-03-14 11:22:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:22:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:22:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 24 @ 2466 updates, score 7.821) (writing took 2.0469191409647465 seconds)
2022-03-14 11:22:27 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-14 11:22:27 | INFO | train | epoch 024 | loss 7.342 | ppl 162.23 | wps 39941.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2466 | lr 0.000308288 | gnorm 0.815 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4047
KL Stats: Epoch 24 Divergences: Uniform: 2.831898989717765 Unigram: 2.6056163240680363
2022-03-14 11:22:27 | INFO | fairseq.trainer | begin training epoch 25
2022-03-14 11:22:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:23:21 | INFO | train_inner | epoch 025:     34 / 103 loss=7.304, ppl=158.05, wps=39898, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2500, lr=0.000312538, gnorm=0.845, loss_scale=32, train_wall=153, gb_free=20.8, wall=4101
2022-03-14 11:25:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:25:14 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.783 | ppl 220.25 | wps 65863.3 | wpb 2040.3 | bsz 4 | num_updates 2569 | best_loss 7.783
2022-03-14 11:25:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2569 updates
2022-03-14 11:25:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:25:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:25:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 25 @ 2569 updates, score 7.783) (writing took 2.0571153992787004 seconds)
2022-03-14 11:25:16 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-14 11:25:16 | INFO | train | epoch 025 | loss 7.247 | ppl 151.91 | wps 39943.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2569 | lr 0.000321161 | gnorm 0.835 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4215
KL Stats: Epoch 25 Divergences: Uniform: 2.883855289306304 Unigram: 2.6543584811683085
2022-03-14 11:25:16 | INFO | fairseq.trainer | begin training epoch 26
2022-03-14 11:25:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:25:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 11:26:06 | INFO | train_inner | epoch 026:     32 / 103 loss=7.224, ppl=149.54, wps=39526.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2600, lr=0.000325035, gnorm=0.832, loss_scale=32, train_wall=155, gb_free=20.8, wall=4266
2022-03-14 11:27:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:28:02 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.74 | ppl 213.76 | wps 66022.2 | wpb 2040.3 | bsz 4 | num_updates 2671 | best_loss 7.74
2022-03-14 11:28:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2671 updates
2022-03-14 11:28:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:28:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:28:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 26 @ 2671 updates, score 7.74) (writing took 2.0375416204333305 seconds)
2022-03-14 11:28:04 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-14 11:28:04 | INFO | train | epoch 026 | loss 7.156 | ppl 142.58 | wps 39569.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 2671 | lr 0.000333908 | gnorm 0.833 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4383
KL Stats: Epoch 26 Divergences: Uniform: 2.935108348541989 Unigram: 2.7008015755740717
2022-03-14 11:28:04 | INFO | fairseq.trainer | begin training epoch 27
2022-03-14 11:28:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:28:50 | INFO | train_inner | epoch 027:     29 / 103 loss=7.128, ppl=139.83, wps=39904.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2700, lr=0.000337533, gnorm=0.826, loss_scale=32, train_wall=153, gb_free=20.8, wall=4430
2022-03-14 11:30:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:30:50 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.71 | ppl 209.31 | wps 65849.3 | wpb 2040.3 | bsz 4 | num_updates 2774 | best_loss 7.71
2022-03-14 11:30:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2774 updates
2022-03-14 11:30:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:30:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:30:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 27 @ 2774 updates, score 7.71) (writing took 2.094908807426691 seconds)
2022-03-14 11:30:52 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-14 11:30:52 | INFO | train | epoch 027 | loss 7.069 | ppl 134.28 | wps 39929.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2774 | lr 0.000346781 | gnorm 0.818 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4552
KL Stats: Epoch 27 Divergences: Uniform: 2.9806515432359895 Unigram: 2.7453002144721292
2022-03-14 11:30:52 | INFO | fairseq.trainer | begin training epoch 28
2022-03-14 11:30:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:31:34 | INFO | train_inner | epoch 028:     26 / 103 loss=7.045, ppl=132.03, wps=39895.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2800, lr=0.00035003, gnorm=0.794, loss_scale=32, train_wall=153, gb_free=20.8, wall=4593
2022-03-14 11:33:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:33:39 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.681 | ppl 205.19 | wps 66361.7 | wpb 2040.3 | bsz 4 | num_updates 2877 | best_loss 7.681
2022-03-14 11:33:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2877 updates
2022-03-14 11:33:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:33:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:33:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 28 @ 2877 updates, score 7.681) (writing took 2.0879431003704667 seconds)
2022-03-14 11:33:41 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-14 11:33:41 | INFO | train | epoch 028 | loss 6.986 | ppl 126.78 | wps 39944.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2877 | lr 0.000359653 | gnorm 0.826 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4720
KL Stats: Epoch 28 Divergences: Uniform: 3.025864175050826 Unigram: 2.789480141586747
2022-03-14 11:33:41 | INFO | fairseq.trainer | begin training epoch 29
2022-03-14 11:33:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:34:17 | INFO | train_inner | epoch 029:     23 / 103 loss=6.971, ppl=125.42, wps=39903.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=2900, lr=0.000362528, gnorm=0.828, loss_scale=32, train_wall=153, gb_free=20.8, wall=4757
2022-03-14 11:36:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:36:27 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.655 | ppl 201.6 | wps 66120.4 | wpb 2040.3 | bsz 4 | num_updates 2980 | best_loss 7.655
2022-03-14 11:36:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2980 updates
2022-03-14 11:36:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:36:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:36:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 29 @ 2980 updates, score 7.655) (writing took 2.0554158044978976 seconds)
2022-03-14 11:36:29 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-14 11:36:29 | INFO | train | epoch 029 | loss 6.905 | ppl 119.83 | wps 39952.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2980 | lr 0.000372526 | gnorm 0.804 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4889
KL Stats: Epoch 29 Divergences: Uniform: 3.0714157447520316 Unigram: 2.8343986848646687
2022-03-14 11:36:29 | INFO | fairseq.trainer | begin training epoch 30
2022-03-14 11:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:37:01 | INFO | train_inner | epoch 030:     20 / 103 loss=6.89, ppl=118.62, wps=39913.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=3000, lr=0.000375025, gnorm=0.846, loss_scale=32, train_wall=153, gb_free=20.8, wall=4921
2022-03-14 11:38:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 11:39:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:39:16 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.629 | ppl 197.99 | wps 66170.2 | wpb 2040.3 | bsz 4 | num_updates 3082 | best_loss 7.629
2022-03-14 11:39:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 3082 updates
2022-03-14 11:39:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:39:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:39:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 30 @ 3082 updates, score 7.629) (writing took 2.0404653986915946 seconds)
2022-03-14 11:39:18 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-14 11:39:18 | INFO | train | epoch 030 | loss 6.829 | ppl 113.73 | wps 39536.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 3082 | lr 0.000385273 | gnorm 0.838 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5057
KL Stats: Epoch 30 Divergences: Uniform: 3.112055114614214 Unigram: 2.8768030240282325
2022-03-14 11:39:18 | INFO | fairseq.trainer | begin training epoch 31
2022-03-14 11:39:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:39:46 | INFO | train_inner | epoch 031:     18 / 103 loss=6.814, ppl=112.53, wps=39491.2, ups=0.6, wpb=65300.5, bsz=127.6, num_updates=3100, lr=0.000387523, gnorm=0.797, loss_scale=16, train_wall=155, gb_free=20.8, wall=5086
2022-03-14 11:42:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:42:04 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.627 | ppl 197.71 | wps 66044.3 | wpb 2040.3 | bsz 4 | num_updates 3185 | best_loss 7.627
2022-03-14 11:42:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 3185 updates
2022-03-14 11:42:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:42:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:42:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 31 @ 3185 updates, score 7.627) (writing took 2.057184847071767 seconds)
2022-03-14 11:42:06 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-14 11:42:06 | INFO | train | epoch 031 | loss 6.752 | ppl 107.81 | wps 39936.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3185 | lr 0.000398145 | gnorm 0.803 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5226
KL Stats: Epoch 31 Divergences: Uniform: 3.1592881897522624 Unigram: 2.9164790921283146
2022-03-14 11:42:06 | INFO | fairseq.trainer | begin training epoch 32
2022-03-14 11:42:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:42:30 | INFO | train_inner | epoch 032:     15 / 103 loss=6.742, ppl=107, wps=39903.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=3200, lr=0.00040002, gnorm=0.815, loss_scale=16, train_wall=153, gb_free=20.8, wall=5250
2022-03-14 11:44:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:44:53 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.606 | ppl 194.85 | wps 66312.4 | wpb 2040.3 | bsz 4 | num_updates 3288 | best_loss 7.606
2022-03-14 11:44:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3288 updates
2022-03-14 11:44:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:44:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:44:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 32 @ 3288 updates, score 7.606) (writing took 2.0275375805795193 seconds)
2022-03-14 11:44:55 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-14 11:44:55 | INFO | train | epoch 032 | loss 6.681 | ppl 102.6 | wps 39937.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3288 | lr 0.000411018 | gnorm 0.817 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5394
KL Stats: Epoch 32 Divergences: Uniform: 3.1977675534381986 Unigram: 2.95737584911317
2022-03-14 11:44:55 | INFO | fairseq.trainer | begin training epoch 33
2022-03-14 11:44:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:45:14 | INFO | train_inner | epoch 033:     12 / 103 loss=6.675, ppl=102.2, wps=39893.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3300, lr=0.000412518, gnorm=0.826, loss_scale=16, train_wall=153, gb_free=20.8, wall=5413
2022-03-14 11:47:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:47:41 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.607 | ppl 194.91 | wps 66074.9 | wpb 2040.3 | bsz 4 | num_updates 3391 | best_loss 7.606
2022-03-14 11:47:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3391 updates
2022-03-14 11:47:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 11:47:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 11:47:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 33 @ 3391 updates, score 7.607) (writing took 0.8629506453871727 seconds)
2022-03-14 11:47:42 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-14 11:47:42 | INFO | train | epoch 033 | loss 6.612 | ppl 97.81 | wps 40225.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3391 | lr 0.00042389 | gnorm 0.84 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5561
KL Stats: Epoch 33 Divergences: Uniform: 3.2377740781418582 Unigram: 3.000491740432633
2022-03-14 11:47:42 | INFO | fairseq.trainer | begin training epoch 34
2022-03-14 11:47:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:47:56 | INFO | train_inner | epoch 034:      9 / 103 loss=6.604, ppl=97.3, wps=40198, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=3400, lr=0.000425015, gnorm=0.831, loss_scale=16, train_wall=153, gb_free=20.8, wall=5576
2022-03-14 11:50:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:50:28 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.59 | ppl 192.61 | wps 66082.5 | wpb 2040.3 | bsz 4 | num_updates 3494 | best_loss 7.59
2022-03-14 11:50:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3494 updates
2022-03-14 11:50:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:50:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt
2022-03-14 11:50:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_best.pt (epoch 34 @ 3494 updates, score 7.59) (writing took 1.9986505433917046 seconds)
2022-03-14 11:50:30 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-14 11:50:30 | INFO | train | epoch 034 | loss 6.54 | ppl 93.08 | wps 39970 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3494 | lr 0.000436763 | gnorm 0.807 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5730
KL Stats: Epoch 34 Divergences: Uniform: 3.2771726451142826 Unigram: 3.041726401238899
2022-03-14 11:50:30 | INFO | fairseq.trainer | begin training epoch 35
2022-03-14 11:50:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:50:40 | INFO | train_inner | epoch 035:      6 / 103 loss=6.54, ppl=93.04, wps=39931.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3500, lr=0.000437513, gnorm=0.807, loss_scale=16, train_wall=153, gb_free=20.8, wall=5739
2022-03-14 11:53:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:53:16 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 7.593 | ppl 193.03 | wps 66123.2 | wpb 2040.3 | bsz 4 | num_updates 3597 | best_loss 7.59
2022-03-14 11:53:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3597 updates
2022-03-14 11:53:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 11:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 11:53:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 35 @ 3597 updates, score 7.593) (writing took 0.9403759082779288 seconds)
2022-03-14 11:53:17 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-14 11:53:17 | INFO | train | epoch 035 | loss 6.477 | ppl 89.09 | wps 40211.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3597 | lr 0.000449635 | gnorm 0.832 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 5897
KL Stats: Epoch 35 Divergences: Uniform: 3.3125425761742995 Unigram: 3.08240082576986
2022-03-14 11:53:17 | INFO | fairseq.trainer | begin training epoch 36
2022-03-14 11:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:53:22 | INFO | train_inner | epoch 036:      3 / 103 loss=6.475, ppl=88.97, wps=40176.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=3600, lr=0.00045001, gnorm=0.832, loss_scale=32, train_wall=153, gb_free=20.8, wall=5902
2022-03-14 11:53:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 11:56:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:56:04 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 7.595 | ppl 193.4 | wps 66378.8 | wpb 2040.3 | bsz 4 | num_updates 3699 | best_loss 7.59
2022-03-14 11:56:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3699 updates
2022-03-14 11:56:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 11:56:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 11:56:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 36 @ 3699 updates, score 7.595) (writing took 0.8809063723310828 seconds)
2022-03-14 11:56:05 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-14 11:56:05 | INFO | train | epoch 036 | loss 6.409 | ppl 84.98 | wps 39841.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 3699 | lr 0.000462383 | gnorm 0.821 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6064
KL Stats: Epoch 36 Divergences: Uniform: 3.3538515252986345 Unigram: 3.1257417010313975
2022-03-14 11:56:05 | INFO | fairseq.trainer | begin training epoch 37
2022-03-14 11:56:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:56:06 | INFO | train_inner | epoch 037:      1 / 103 loss=6.41, ppl=85.02, wps=39812.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3700, lr=0.000462508, gnorm=0.822, loss_scale=16, train_wall=155, gb_free=20.8, wall=6066
2022-03-14 11:58:45 | INFO | train_inner | epoch 037:    101 / 103 loss=6.348, ppl=81.44, wps=41337.4, ups=0.63, wpb=65530.9, bsz=128, num_updates=3800, lr=0.000475005, gnorm=0.824, loss_scale=16, train_wall=154, gb_free=20.8, wall=6224
2022-03-14 11:58:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:58:51 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 7.61 | ppl 195.34 | wps 65830.9 | wpb 2040.3 | bsz 4 | num_updates 3802 | best_loss 7.59
2022-03-14 11:58:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3802 updates
2022-03-14 11:58:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 11:58:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 11:58:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 37 @ 3802 updates, score 7.61) (writing took 0.8627854790538549 seconds)
2022-03-14 11:58:52 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-14 11:58:52 | INFO | train | epoch 037 | loss 6.347 | ppl 81.42 | wps 40220.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3802 | lr 0.000475255 | gnorm 0.823 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6231
KL Stats: Epoch 37 Divergences: Uniform: 3.396529372363636 Unigram: 3.167130994358322
2022-03-14 11:58:52 | INFO | fairseq.trainer | begin training epoch 38
2022-03-14 11:58:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:01:27 | INFO | train_inner | epoch 038:     98 / 103 loss=6.287, ppl=78.09, wps=40197.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=3900, lr=0.000487503, gnorm=0.838, loss_scale=16, train_wall=153, gb_free=20.8, wall=6387
2022-03-14 12:01:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:01:38 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 7.618 | ppl 196.41 | wps 65878.2 | wpb 2040.3 | bsz 4 | num_updates 3905 | best_loss 7.59
2022-03-14 12:01:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3905 updates
2022-03-14 12:01:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:01:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:01:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 38 @ 3905 updates, score 7.618) (writing took 0.9468612531200051 seconds)
2022-03-14 12:01:39 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-14 12:01:39 | INFO | train | epoch 038 | loss 6.287 | ppl 78.11 | wps 40209.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3905 | lr 0.000488127 | gnorm 0.836 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6399
KL Stats: Epoch 38 Divergences: Uniform: 3.4363281525685183 Unigram: 3.204847642576576
2022-03-14 12:01:39 | INFO | fairseq.trainer | begin training epoch 39
2022-03-14 12:01:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:04:10 | INFO | train_inner | epoch 039:     95 / 103 loss=6.229, ppl=74.99, wps=40157.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=4000, lr=0.0005, gnorm=0.843, loss_scale=16, train_wall=153, gb_free=20.8, wall=6549
2022-03-14 12:04:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:04:26 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 7.635 | ppl 198.72 | wps 65084.1 | wpb 2040.3 | bsz 4 | num_updates 4008 | best_loss 7.59
2022-03-14 12:04:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 4008 updates
2022-03-14 12:04:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:04:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:04:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 39 @ 4008 updates, score 7.635) (writing took 0.9439441477879882 seconds)
2022-03-14 12:04:27 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-14 12:04:27 | INFO | train | epoch 039 | loss 6.228 | ppl 74.98 | wps 40181.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4008 | lr 0.000499501 | gnorm 0.843 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6566
KL Stats: Epoch 39 Divergences: Uniform: 3.4711959855702923 Unigram: 3.246461835386298
2022-03-14 12:04:27 | INFO | fairseq.trainer | begin training epoch 40
2022-03-14 12:04:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:06:52 | INFO | train_inner | epoch 040:     92 / 103 loss=6.169, ppl=71.94, wps=40182, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=4100, lr=0.000493865, gnorm=0.819, loss_scale=16, train_wall=153, gb_free=20.8, wall=6712
2022-03-14 12:07:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:07:13 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 7.624 | ppl 197.31 | wps 66045.3 | wpb 2040.3 | bsz 4 | num_updates 4111 | best_loss 7.59
2022-03-14 12:07:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 4111 updates
2022-03-14 12:07:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:07:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:07:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 40 @ 4111 updates, score 7.624) (writing took 0.9344914369285107 seconds)
2022-03-14 12:07:14 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-14 12:07:14 | INFO | train | epoch 040 | loss 6.167 | ppl 71.83 | wps 40226.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4111 | lr 0.000493204 | gnorm 0.818 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6733
KL Stats: Epoch 40 Divergences: Uniform: 3.5122379694409385 Unigram: 3.2859607490996923
2022-03-14 12:07:14 | INFO | fairseq.trainer | begin training epoch 41
2022-03-14 12:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:08:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 12:09:36 | INFO | train_inner | epoch 041:     90 / 103 loss=6.109, ppl=69.02, wps=39803.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=4200, lr=0.00048795, gnorm=0.821, loss_scale=16, train_wall=155, gb_free=20.8, wall=6876
2022-03-14 12:09:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:10:00 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 7.639 | ppl 199.33 | wps 66024.9 | wpb 2040.3 | bsz 4 | num_updates 4213 | best_loss 7.59
2022-03-14 12:10:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 4213 updates
2022-03-14 12:10:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:10:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:10:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 41 @ 4213 updates, score 7.639) (writing took 0.9081993447616696 seconds)
2022-03-14 12:10:01 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-14 12:10:01 | INFO | train | epoch 041 | loss 6.103 | ppl 68.74 | wps 39842.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 4213 | lr 0.000487197 | gnorm 0.816 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6901
KL Stats: Epoch 41 Divergences: Uniform: 3.555881307825704 Unigram: 3.330340647443159
2022-03-14 12:10:01 | INFO | fairseq.trainer | begin training epoch 42
2022-03-14 12:10:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:12:19 | INFO | train_inner | epoch 042:     87 / 103 loss=6.048, ppl=66.17, wps=40196.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=4300, lr=0.000482243, gnorm=0.81, loss_scale=16, train_wall=153, gb_free=20.8, wall=7039
2022-03-14 12:12:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:12:47 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 7.643 | ppl 199.89 | wps 65897.4 | wpb 2040.3 | bsz 4 | num_updates 4316 | best_loss 7.59
2022-03-14 12:12:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4316 updates
2022-03-14 12:12:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:12:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:12:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 42 @ 4316 updates, score 7.643) (writing took 0.92365828063339 seconds)
2022-03-14 12:12:48 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-14 12:12:48 | INFO | train | epoch 042 | loss 6.043 | ppl 65.93 | wps 40226.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4316 | lr 0.000481348 | gnorm 0.819 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7068
KL Stats: Epoch 42 Divergences: Uniform: 3.5923109770084225 Unigram: 3.373769386168042
2022-03-14 12:12:48 | INFO | fairseq.trainer | begin training epoch 43
2022-03-14 12:12:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:15:01 | INFO | train_inner | epoch 043:     84 / 103 loss=5.994, ppl=63.75, wps=40197.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=4400, lr=0.000476731, gnorm=0.809, loss_scale=16, train_wall=153, gb_free=20.8, wall=7201
2022-03-14 12:15:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:15:35 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 7.67 | ppl 203.72 | wps 65888.9 | wpb 2040.3 | bsz 4 | num_updates 4419 | best_loss 7.59
2022-03-14 12:15:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4419 updates
2022-03-14 12:15:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:15:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:15:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 43 @ 4419 updates, score 7.67) (writing took 0.8924309816211462 seconds)
2022-03-14 12:15:35 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-14 12:15:35 | INFO | train | epoch 043 | loss 5.984 | ppl 63.28 | wps 40237.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4419 | lr 0.000475705 | gnorm 0.802 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7235
KL Stats: Epoch 43 Divergences: Uniform: 3.634018670026324 Unigram: 3.4137947422741703
2022-03-14 12:15:35 | INFO | fairseq.trainer | begin training epoch 44
2022-03-14 12:15:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:17:44 | INFO | train_inner | epoch 044:     81 / 103 loss=5.934, ppl=61.14, wps=40186.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4500, lr=0.000471405, gnorm=0.795, loss_scale=16, train_wall=153, gb_free=20.8, wall=7363
2022-03-14 12:18:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:18:22 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 7.677 | ppl 204.7 | wps 66002.1 | wpb 2040.3 | bsz 4 | num_updates 4522 | best_loss 7.59
2022-03-14 12:18:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4522 updates
2022-03-14 12:18:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:18:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 44 @ 4522 updates, score 7.677) (writing took 0.9097393546253443 seconds)
2022-03-14 12:18:23 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-14 12:18:23 | INFO | train | epoch 044 | loss 5.93 | ppl 60.95 | wps 40217.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4522 | lr 0.000470256 | gnorm 0.807 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7402
KL Stats: Epoch 44 Divergences: Uniform: 3.671920633333577 Unigram: 3.4556828577757845
2022-03-14 12:18:23 | INFO | fairseq.trainer | begin training epoch 45
2022-03-14 12:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:20:26 | INFO | train_inner | epoch 045:     78 / 103 loss=5.888, ppl=59.21, wps=40197.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4600, lr=0.000466252, gnorm=0.814, loss_scale=16, train_wall=153, gb_free=20.8, wall=7526
2022-03-14 12:21:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:21:09 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 7.711 | ppl 209.56 | wps 66076.7 | wpb 2040.3 | bsz 4 | num_updates 4625 | best_loss 7.59
2022-03-14 12:21:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4625 updates
2022-03-14 12:21:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:21:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:21:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 45 @ 4625 updates, score 7.711) (writing took 0.8976881494745612 seconds)
2022-03-14 12:21:10 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-14 12:21:10 | INFO | train | epoch 045 | loss 5.874 | ppl 58.67 | wps 40234.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4625 | lr 0.000464991 | gnorm 0.794 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7569
KL Stats: Epoch 45 Divergences: Uniform: 3.709390371027305 Unigram: 3.4978923780771685
2022-03-14 12:21:10 | INFO | fairseq.trainer | begin training epoch 46
2022-03-14 12:21:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:22:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 12:23:10 | INFO | train_inner | epoch 046:     76 / 103 loss=5.833, ppl=57, wps=39807.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=4700, lr=0.000461266, gnorm=0.787, loss_scale=16, train_wall=155, gb_free=20.8, wall=7690
2022-03-14 12:23:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:23:56 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 7.732 | ppl 212.58 | wps 66189 | wpb 2040.3 | bsz 4 | num_updates 4727 | best_loss 7.59
2022-03-14 12:23:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4727 updates
2022-03-14 12:23:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:23:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:23:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 46 @ 4727 updates, score 7.732) (writing took 0.8751092199236155 seconds)
2022-03-14 12:23:57 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-14 12:23:57 | INFO | train | epoch 046 | loss 5.821 | ppl 56.54 | wps 39837.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 4727 | lr 0.000459946 | gnorm 0.803 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7737
KL Stats: Epoch 46 Divergences: Uniform: 3.7475804114613562 Unigram: 3.5379454321263246
2022-03-14 12:23:57 | INFO | fairseq.trainer | begin training epoch 47
2022-03-14 12:23:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:25:53 | INFO | train_inner | epoch 047:     73 / 103 loss=5.782, ppl=55.03, wps=40199.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4800, lr=0.000456435, gnorm=0.815, loss_scale=16, train_wall=153, gb_free=20.8, wall=7852
2022-03-14 12:26:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:26:43 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 7.76 | ppl 216.82 | wps 66284.8 | wpb 2040.3 | bsz 4 | num_updates 4830 | best_loss 7.59
2022-03-14 12:26:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4830 updates
2022-03-14 12:26:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:26:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:26:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 47 @ 4830 updates, score 7.76) (writing took 0.8592113666236401 seconds)
2022-03-14 12:26:44 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-14 12:26:44 | INFO | train | epoch 047 | loss 5.773 | ppl 54.69 | wps 40236.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4830 | lr 0.000455016 | gnorm 0.81 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7904
KL Stats: Epoch 47 Divergences: Uniform: 3.784047412907389 Unigram: 3.578321506504453
2022-03-14 12:26:44 | INFO | fairseq.trainer | begin training epoch 48
2022-03-14 12:26:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:28:35 | INFO | train_inner | epoch 048:     70 / 103 loss=5.739, ppl=53.41, wps=40209.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4900, lr=0.000451754, gnorm=0.801, loss_scale=16, train_wall=153, gb_free=20.8, wall=8015
2022-03-14 12:29:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:29:31 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 7.776 | ppl 219.16 | wps 65998.2 | wpb 2040.3 | bsz 4 | num_updates 4933 | best_loss 7.59
2022-03-14 12:29:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4933 updates
2022-03-14 12:29:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:29:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:29:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 48 @ 4933 updates, score 7.776) (writing took 0.8843450313434005 seconds)
2022-03-14 12:29:32 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-14 12:29:32 | INFO | train | epoch 048 | loss 5.722 | ppl 52.8 | wps 40230.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4933 | lr 0.00045024 | gnorm 0.796 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8071
KL Stats: Epoch 48 Divergences: Uniform: 3.820594751260525 Unigram: 3.6165337375614213
2022-03-14 12:29:32 | INFO | fairseq.trainer | begin training epoch 49
2022-03-14 12:29:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:31:18 | INFO | train_inner | epoch 049:     67 / 103 loss=5.691, ppl=51.66, wps=40190.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=5000, lr=0.000447214, gnorm=0.799, loss_scale=16, train_wall=153, gb_free=20.8, wall=8177
2022-03-14 12:32:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:32:18 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 7.802 | ppl 223.18 | wps 66011.3 | wpb 2040.3 | bsz 4 | num_updates 5036 | best_loss 7.59
2022-03-14 12:32:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 5036 updates
2022-03-14 12:32:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:32:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:32:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 49 @ 5036 updates, score 7.802) (writing took 0.8711348632350564 seconds)
2022-03-14 12:32:19 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-14 12:32:19 | INFO | train | epoch 049 | loss 5.678 | ppl 51.21 | wps 40225.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5036 | lr 0.000445612 | gnorm 0.8 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8238
KL Stats: Epoch 49 Divergences: Uniform: 3.856137009691166 Unigram: 3.6556559159677664
2022-03-14 12:32:19 | INFO | fairseq.trainer | begin training epoch 50
2022-03-14 12:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:34:00 | INFO | train_inner | epoch 050:     64 / 103 loss=5.651, ppl=50.26, wps=40203.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5100, lr=0.000442807, gnorm=0.807, loss_scale=16, train_wall=153, gb_free=20.8, wall=8340
2022-03-14 12:35:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:35:05 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 7.834 | ppl 228.16 | wps 66230.7 | wpb 2040.3 | bsz 4 | num_updates 5139 | best_loss 7.59
2022-03-14 12:35:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 5139 updates
2022-03-14 12:35:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:35:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:35:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 50 @ 5139 updates, score 7.834) (writing took 0.8648563288152218 seconds)
2022-03-14 12:35:06 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-14 12:35:06 | INFO | train | epoch 050 | loss 5.636 | ppl 49.72 | wps 40243.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5139 | lr 0.000441124 | gnorm 0.815 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8406
KL Stats: Epoch 50 Divergences: Uniform: 3.892585443845344 Unigram: 3.688213546910063
2022-03-14 12:35:06 | INFO | fairseq.trainer | begin training epoch 51
2022-03-14 12:35:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:36:43 | INFO | train_inner | epoch 051:     61 / 103 loss=5.604, ppl=48.63, wps=40208.5, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=5200, lr=0.000438529, gnorm=0.809, loss_scale=32, train_wall=153, gb_free=20.8, wall=8502
2022-03-14 12:36:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 12:37:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:37:52 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 7.861 | ppl 232.46 | wps 65958.7 | wpb 2040.3 | bsz 4 | num_updates 5241 | best_loss 7.59
2022-03-14 12:37:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 5241 updates
2022-03-14 12:37:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:37:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:37:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 51 @ 5241 updates, score 7.861) (writing took 0.8746518986299634 seconds)
2022-03-14 12:37:53 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-14 12:37:53 | INFO | train | epoch 051 | loss 5.59 | ppl 48.16 | wps 39842.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 5241 | lr 0.00043681 | gnorm 0.798 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8573
KL Stats: Epoch 51 Divergences: Uniform: 3.930643742818436 Unigram: 3.727753380091149
2022-03-14 12:37:53 | INFO | fairseq.trainer | begin training epoch 52
2022-03-14 12:37:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:39:27 | INFO | train_inner | epoch 052:     59 / 103 loss=5.569, ppl=47.46, wps=39806.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=5300, lr=0.000434372, gnorm=0.797, loss_scale=16, train_wall=155, gb_free=20.8, wall=8666
2022-03-14 12:40:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:40:39 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 7.868 | ppl 233.59 | wps 65900.7 | wpb 2040.3 | bsz 4 | num_updates 5344 | best_loss 7.59
2022-03-14 12:40:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5344 updates
2022-03-14 12:40:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:40:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:40:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 52 @ 5344 updates, score 7.868) (writing took 0.8645218834280968 seconds)
2022-03-14 12:40:40 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-14 12:40:40 | INFO | train | epoch 052 | loss 5.553 | ppl 46.95 | wps 40232.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5344 | lr 0.00043258 | gnorm 0.804 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8740
KL Stats: Epoch 52 Divergences: Uniform: 3.9581514707862038 Unigram: 3.760887300604273
2022-03-14 12:40:40 | INFO | fairseq.trainer | begin training epoch 53
2022-03-14 12:40:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:42:09 | INFO | train_inner | epoch 053:     56 / 103 loss=5.529, ppl=46.17, wps=40204.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5400, lr=0.000430331, gnorm=0.81, loss_scale=16, train_wall=153, gb_free=20.8, wall=8829
2022-03-14 12:43:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:43:27 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 7.885 | ppl 236.36 | wps 66330.9 | wpb 2040.3 | bsz 4 | num_updates 5447 | best_loss 7.59
2022-03-14 12:43:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5447 updates
2022-03-14 12:43:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:43:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:43:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 53 @ 5447 updates, score 7.885) (writing took 0.8531951736658812 seconds)
2022-03-14 12:43:28 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-14 12:43:28 | INFO | train | epoch 053 | loss 5.514 | ppl 45.69 | wps 40229.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5447 | lr 0.000428471 | gnorm 0.809 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8907
KL Stats: Epoch 53 Divergences: Uniform: 3.9925213778356543 Unigram: 3.793610315929664
2022-03-14 12:43:28 | INFO | fairseq.trainer | begin training epoch 54
2022-03-14 12:43:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:44:52 | INFO | train_inner | epoch 054:     53 / 103 loss=5.492, ppl=45.02, wps=40190.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5500, lr=0.000426401, gnorm=0.798, loss_scale=16, train_wall=153, gb_free=20.8, wall=8991
2022-03-14 12:46:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:46:14 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 7.914 | ppl 241.23 | wps 66143.8 | wpb 2040.3 | bsz 4 | num_updates 5550 | best_loss 7.59
2022-03-14 12:46:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5550 updates
2022-03-14 12:46:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:46:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:46:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 54 @ 5550 updates, score 7.914) (writing took 0.9032010808587074 seconds)
2022-03-14 12:46:15 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-14 12:46:15 | INFO | train | epoch 054 | loss 5.475 | ppl 44.49 | wps 40210.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5550 | lr 0.000424476 | gnorm 0.813 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 9074
KL Stats: Epoch 54 Divergences: Uniform: 4.024768120701499 Unigram: 3.827966840182126
2022-03-14 12:46:15 | INFO | fairseq.trainer | begin training epoch 55
2022-03-14 12:46:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:47:34 | INFO | train_inner | epoch 055:     50 / 103 loss=5.46, ppl=44.02, wps=40187.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=5600, lr=0.000422577, gnorm=0.822, loss_scale=16, train_wall=153, gb_free=20.8, wall=9154
2022-03-14 12:48:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:49:01 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 7.926 | ppl 243.16 | wps 66014.2 | wpb 2040.3 | bsz 4 | num_updates 5653 | best_loss 7.59
2022-03-14 12:49:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5653 updates
2022-03-14 12:49:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:49:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:49:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 55 @ 5653 updates, score 7.926) (writing took 0.84782893396914 seconds)
2022-03-14 12:49:02 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-14 12:49:02 | INFO | train | epoch 055 | loss 5.438 | ppl 43.35 | wps 40233 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5653 | lr 0.000420592 | gnorm 0.817 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 9242
KL Stats: Epoch 55 Divergences: Uniform: 4.05413456847011 Unigram: 3.8591680714732455
2022-03-14 12:49:02 | INFO | fairseq.trainer | begin training epoch 56
2022-03-14 12:49:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:50:17 | INFO | train_inner | epoch 056:     47 / 103 loss=5.417, ppl=42.72, wps=40191.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=5700, lr=0.000418854, gnorm=0.826, loss_scale=16, train_wall=153, gb_free=20.8, wall=9316
2022-03-14 12:50:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 12:51:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:51:48 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 7.941 | ppl 245.69 | wps 66476.1 | wpb 2040.3 | bsz 4 | num_updates 5755 | best_loss 7.59
2022-03-14 12:51:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5755 updates
2022-03-14 12:51:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:51:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:51:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 56 @ 5755 updates, score 7.941) (writing took 0.8668419755995274 seconds)
2022-03-14 12:51:49 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-14 12:51:49 | INFO | train | epoch 056 | loss 5.4 | ppl 42.22 | wps 39844.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 5755 | lr 0.000416848 | gnorm 0.818 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 9409
KL Stats: Epoch 56 Divergences: Uniform: 4.083658801742054 Unigram: 3.8903315298958008
2022-03-14 12:51:49 | INFO | fairseq.trainer | begin training epoch 57
2022-03-14 12:51:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:53:01 | INFO | train_inner | epoch 057:     45 / 103 loss=5.386, ppl=41.81, wps=39823.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=5800, lr=0.000415227, gnorm=0.812, loss_scale=16, train_wall=155, gb_free=20.8, wall=9480
2022-03-14 12:54:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:54:36 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 7.988 | ppl 253.79 | wps 66160.1 | wpb 2040.3 | bsz 4 | num_updates 5858 | best_loss 7.59
2022-03-14 12:54:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5858 updates
2022-03-14 12:54:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:54:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:54:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 57 @ 5858 updates, score 7.988) (writing took 0.8668278157711029 seconds)
2022-03-14 12:54:36 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-14 12:54:36 | INFO | train | epoch 057 | loss 5.367 | ppl 41.28 | wps 40231.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5858 | lr 0.000413167 | gnorm 0.811 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 9576
KL Stats: Epoch 57 Divergences: Uniform: 4.114106373718531 Unigram: 3.9235523036579387
2022-03-14 12:54:36 | INFO | fairseq.trainer | begin training epoch 58
2022-03-14 12:54:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:55:43 | INFO | train_inner | epoch 058:     42 / 103 loss=5.355, ppl=40.92, wps=40175.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=5900, lr=0.000411693, gnorm=0.817, loss_scale=16, train_wall=153, gb_free=20.8, wall=9643
2022-03-14 12:57:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:57:23 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 7.999 | ppl 255.82 | wps 66129.7 | wpb 2040.3 | bsz 4 | num_updates 5961 | best_loss 7.59
2022-03-14 12:57:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5961 updates
2022-03-14 12:57:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:57:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 12:57:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 58 @ 5961 updates, score 7.999) (writing took 0.9717080174013972 seconds)
2022-03-14 12:57:24 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-14 12:57:24 | INFO | train | epoch 058 | loss 5.335 | ppl 40.35 | wps 40168.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.824 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 9744
KL Stats: Epoch 58 Divergences: Uniform: 4.143951360948737 Unigram: 3.952831370657794
2022-03-14 12:57:24 | INFO | fairseq.trainer | begin training epoch 59
2022-03-14 12:57:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:58:26 | INFO | train_inner | epoch 059:     39 / 103 loss=5.322, ppl=40.01, wps=40164.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6000, lr=0.000408248, gnorm=0.828, loss_scale=16, train_wall=153, gb_free=20.8, wall=9805
2022-03-14 12:59:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 13:00:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:00:10 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 8.026 | ppl 260.59 | wps 65918.8 | wpb 2040.3 | bsz 4 | num_updates 6063 | best_loss 7.59
2022-03-14 13:00:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 6063 updates
2022-03-14 13:00:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:00:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:00:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 59 @ 6063 updates, score 8.026) (writing took 0.9427634291350842 seconds)
2022-03-14 13:00:11 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-14 13:00:11 | INFO | train | epoch 059 | loss 5.303 | ppl 39.48 | wps 39841 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 6063 | lr 0.000406122 | gnorm 0.833 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 9911
KL Stats: Epoch 59 Divergences: Uniform: 4.169352792316871 Unigram: 3.982864129591532
2022-03-14 13:00:11 | INFO | fairseq.trainer | begin training epoch 60
2022-03-14 13:00:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:01:10 | INFO | train_inner | epoch 060:     37 / 103 loss=5.294, ppl=39.22, wps=39808, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=6100, lr=0.000404888, gnorm=0.832, loss_scale=8, train_wall=155, gb_free=20.8, wall=9969
2022-03-14 13:02:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:02:57 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 8.053 | ppl 265.57 | wps 66489.4 | wpb 2040.3 | bsz 4 | num_updates 6166 | best_loss 7.59
2022-03-14 13:02:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 6166 updates
2022-03-14 13:02:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:02:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 60 @ 6166 updates, score 8.053) (writing took 0.9138145903125405 seconds)
2022-03-14 13:02:58 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-14 13:02:58 | INFO | train | epoch 060 | loss 5.272 | ppl 38.65 | wps 40239.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6166 | lr 0.000402715 | gnorm 0.837 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 10078
KL Stats: Epoch 60 Divergences: Uniform: 4.1984639945386215 Unigram: 4.008181719132844
2022-03-14 13:02:58 | INFO | fairseq.trainer | begin training epoch 61
2022-03-14 13:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:03:52 | INFO | train_inner | epoch 061:     34 / 103 loss=5.263, ppl=38.4, wps=40198.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6200, lr=0.00040161, gnorm=0.831, loss_scale=8, train_wall=153, gb_free=20.8, wall=10132
2022-03-14 13:05:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:05:45 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 8.081 | ppl 270.7 | wps 66147 | wpb 2040.3 | bsz 4 | num_updates 6269 | best_loss 7.59
2022-03-14 13:05:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 6269 updates
2022-03-14 13:05:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:05:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:05:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 61 @ 6269 updates, score 8.081) (writing took 0.9298830470070243 seconds)
2022-03-14 13:05:46 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-14 13:05:46 | INFO | train | epoch 061 | loss 5.243 | ppl 37.87 | wps 40209.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6269 | lr 0.000399393 | gnorm 0.833 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 10245
KL Stats: Epoch 61 Divergences: Uniform: 4.224368752903604 Unigram: 4.040621999310588
2022-03-14 13:05:46 | INFO | fairseq.trainer | begin training epoch 62
2022-03-14 13:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:06:35 | INFO | train_inner | epoch 062:     31 / 103 loss=5.23, ppl=37.53, wps=40173.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6300, lr=0.00039841, gnorm=0.831, loss_scale=8, train_wall=153, gb_free=20.8, wall=10294
2022-03-14 13:08:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:08:32 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 8.11 | ppl 276.32 | wps 66483.9 | wpb 2040.3 | bsz 4 | num_updates 6372 | best_loss 7.59
2022-03-14 13:08:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 6372 updates
2022-03-14 13:08:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:08:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:08:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 62 @ 6372 updates, score 8.11) (writing took 0.8927211072295904 seconds)
2022-03-14 13:08:33 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-14 13:08:33 | INFO | train | epoch 062 | loss 5.214 | ppl 37.11 | wps 40245.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6372 | lr 0.000396152 | gnorm 0.829 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 10412
KL Stats: Epoch 62 Divergences: Uniform: 4.249006250668379 Unigram: 4.066533895186003
2022-03-14 13:08:33 | INFO | fairseq.trainer | begin training epoch 63
2022-03-14 13:08:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:09:17 | INFO | train_inner | epoch 063:     28 / 103 loss=5.21, ppl=37.01, wps=40225.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=6400, lr=0.000395285, gnorm=0.845, loss_scale=8, train_wall=153, gb_free=20.8, wall=10457
2022-03-14 13:11:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:11:19 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 8.114 | ppl 277 | wps 66081 | wpb 2040.3 | bsz 4 | num_updates 6475 | best_loss 7.59
2022-03-14 13:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6475 updates
2022-03-14 13:11:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:11:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:11:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 63 @ 6475 updates, score 8.114) (writing took 0.9443537872284651 seconds)
2022-03-14 13:11:20 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-14 13:11:20 | INFO | train | epoch 063 | loss 5.187 | ppl 36.42 | wps 40230.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6475 | lr 0.000392989 | gnorm 0.852 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 10580
KL Stats: Epoch 63 Divergences: Uniform: 4.271869344806005 Unigram: 4.091405834718503
2022-03-14 13:11:20 | INFO | fairseq.trainer | begin training epoch 64
2022-03-14 13:11:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:12:00 | INFO | train_inner | epoch 064:     25 / 103 loss=5.182, ppl=36.3, wps=40181.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=6500, lr=0.000392232, gnorm=0.838, loss_scale=8, train_wall=153, gb_free=20.8, wall=10619
2022-03-14 13:14:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:14:06 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 8.126 | ppl 279.29 | wps 65925.6 | wpb 2040.3 | bsz 4 | num_updates 6578 | best_loss 7.59
2022-03-14 13:14:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6578 updates
2022-03-14 13:14:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:14:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:14:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 64 @ 6578 updates, score 8.126) (writing took 0.867544767446816 seconds)
2022-03-14 13:14:07 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-14 13:14:07 | INFO | train | epoch 064 | loss 5.159 | ppl 35.72 | wps 40219.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6578 | lr 0.0003899 | gnorm 0.831 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 10747
KL Stats: Epoch 64 Divergences: Uniform: 4.299573527578485 Unigram: 4.118651335429689
2022-03-14 13:14:07 | INFO | fairseq.trainer | begin training epoch 65
2022-03-14 13:14:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:14:42 | INFO | train_inner | epoch 065:     22 / 103 loss=5.155, ppl=35.62, wps=40173.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6600, lr=0.000389249, gnorm=0.83, loss_scale=16, train_wall=153, gb_free=20.8, wall=10782
2022-03-14 13:16:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:16:54 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 8.186 | ppl 291.18 | wps 65762.3 | wpb 2040.3 | bsz 4 | num_updates 6681 | best_loss 7.59
2022-03-14 13:16:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 6681 updates
2022-03-14 13:16:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:16:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:16:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 65 @ 6681 updates, score 8.186) (writing took 1.116864299401641 seconds)
2022-03-14 13:16:55 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-14 13:16:55 | INFO | train | epoch 065 | loss 5.133 | ppl 35.08 | wps 40076.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6681 | lr 0.000386883 | gnorm 0.841 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 10915
KL Stats: Epoch 65 Divergences: Uniform: 4.3216256261266475 Unigram: 4.145485816680583
2022-03-14 13:16:55 | INFO | fairseq.trainer | begin training epoch 66
2022-03-14 13:16:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:17:25 | INFO | train_inner | epoch 066:     19 / 103 loss=5.129, ppl=34.99, wps=40048.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=6700, lr=0.000386334, gnorm=0.847, loss_scale=16, train_wall=153, gb_free=20.8, wall=10945
2022-03-14 13:19:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:19:42 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 8.167 | ppl 287.5 | wps 66141 | wpb 2040.3 | bsz 4 | num_updates 6784 | best_loss 7.59
2022-03-14 13:19:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 6784 updates
2022-03-14 13:19:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:19:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:19:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 66 @ 6784 updates, score 8.167) (writing took 0.9072327297180891 seconds)
2022-03-14 13:19:43 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-14 13:19:43 | INFO | train | epoch 066 | loss 5.108 | ppl 34.48 | wps 40154.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6784 | lr 0.000383934 | gnorm 0.849 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 11082
KL Stats: Epoch 66 Divergences: Uniform: 4.346246423402136 Unigram: 4.167736420766445
2022-03-14 13:19:43 | INFO | fairseq.trainer | begin training epoch 67
2022-03-14 13:19:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:20:08 | INFO | train_inner | epoch 067:     16 / 103 loss=5.105, ppl=34.4, wps=40111.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6800, lr=0.000383482, gnorm=0.847, loss_scale=16, train_wall=153, gb_free=20.8, wall=11108
2022-03-14 13:22:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:22:29 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 8.196 | ppl 293.32 | wps 66102.2 | wpb 2040.3 | bsz 4 | num_updates 6887 | best_loss 7.59
2022-03-14 13:22:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 6887 updates
2022-03-14 13:22:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:22:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:22:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 67 @ 6887 updates, score 8.196) (writing took 0.9102077670395374 seconds)
2022-03-14 13:22:30 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-14 13:22:30 | INFO | train | epoch 067 | loss 5.082 | ppl 33.88 | wps 40180.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6887 | lr 0.000381053 | gnorm 0.849 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 11250
KL Stats: Epoch 67 Divergences: Uniform: 4.368750624184926 Unigram: 4.191152229814154
2022-03-14 13:22:30 | INFO | fairseq.trainer | begin training epoch 68
2022-03-14 13:22:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:22:51 | INFO | train_inner | epoch 068:     13 / 103 loss=5.084, ppl=33.93, wps=40156.2, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=6900, lr=0.000380693, gnorm=0.856, loss_scale=16, train_wall=153, gb_free=20.8, wall=11270
2022-03-14 13:25:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:25:17 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 8.22 | ppl 298.22 | wps 66114 | wpb 2040.3 | bsz 4 | num_updates 6990 | best_loss 7.59
2022-03-14 13:25:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 6990 updates
2022-03-14 13:25:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:25:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:25:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 68 @ 6990 updates, score 8.22) (writing took 0.8969958163797855 seconds)
2022-03-14 13:25:17 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-14 13:25:17 | INFO | train | epoch 068 | loss 5.059 | ppl 33.32 | wps 40194.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6990 | lr 0.000378235 | gnorm 0.849 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 11417
KL Stats: Epoch 68 Divergences: Uniform: 4.39010427733825 Unigram: 4.21697823768944
2022-03-14 13:25:17 | INFO | fairseq.trainer | begin training epoch 69
2022-03-14 13:25:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:25:33 | INFO | train_inner | epoch 069:     10 / 103 loss=5.056, ppl=33.26, wps=40158.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=7000, lr=0.000377964, gnorm=0.844, loss_scale=16, train_wall=153, gb_free=20.8, wall=11433
2022-03-14 13:27:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 13:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:28:04 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 8.267 | ppl 307.99 | wps 66123.6 | wpb 2040.3 | bsz 4 | num_updates 7092 | best_loss 7.59
2022-03-14 13:28:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 7092 updates
2022-03-14 13:28:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:28:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:28:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 69 @ 7092 updates, score 8.267) (writing took 0.9129361566156149 seconds)
2022-03-14 13:28:05 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-14 13:28:05 | INFO | train | epoch 069 | loss 5.035 | ppl 32.79 | wps 39736.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 7092 | lr 0.000375505 | gnorm 0.857 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 11585
KL Stats: Epoch 69 Divergences: Uniform: 4.412722148102581 Unigram: 4.239743660775648
2022-03-14 13:28:05 | INFO | fairseq.trainer | begin training epoch 70
2022-03-14 13:28:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:28:18 | INFO | train_inner | epoch 070:      8 / 103 loss=5.036, ppl=32.8, wps=39706.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7100, lr=0.000375293, gnorm=0.86, loss_scale=16, train_wall=155, gb_free=20.8, wall=11597
2022-03-14 13:30:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:30:52 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 8.252 | ppl 304.88 | wps 65933.9 | wpb 2040.3 | bsz 4 | num_updates 7195 | best_loss 7.59
2022-03-14 13:30:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 7195 updates
2022-03-14 13:30:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:30:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:30:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 70 @ 7195 updates, score 8.252) (writing took 0.8888220442458987 seconds)
2022-03-14 13:30:53 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-14 13:30:53 | INFO | train | epoch 070 | loss 5.014 | ppl 32.31 | wps 40098.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 7195 | lr 0.000372807 | gnorm 0.865 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 11752
KL Stats: Epoch 70 Divergences: Uniform: 4.430905649424388 Unigram: 4.260544699752712
2022-03-14 13:30:53 | INFO | fairseq.trainer | begin training epoch 71
2022-03-14 13:30:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:31:01 | INFO | train_inner | epoch 071:      5 / 103 loss=5.018, ppl=32.41, wps=40062.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=7200, lr=0.000372678, gnorm=0.861, loss_scale=16, train_wall=154, gb_free=20.8, wall=11760
2022-03-14 13:33:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:33:39 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 8.289 | ppl 312.71 | wps 66354.4 | wpb 2040.3 | bsz 4 | num_updates 7298 | best_loss 7.59
2022-03-14 13:33:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 7298 updates
2022-03-14 13:33:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:33:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:33:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 71 @ 7298 updates, score 8.289) (writing took 0.888036722317338 seconds)
2022-03-14 13:33:40 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-14 13:33:40 | INFO | train | epoch 071 | loss 4.992 | ppl 31.82 | wps 40170.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7298 | lr 0.000370167 | gnorm 0.858 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 11920
KL Stats: Epoch 71 Divergences: Uniform: 4.4531289582920675 Unigram: 4.282677735331831
2022-03-14 13:33:40 | INFO | fairseq.trainer | begin training epoch 72
2022-03-14 13:33:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:33:44 | INFO | train_inner | epoch 072:      2 / 103 loss=4.993, ppl=31.84, wps=40145.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=7300, lr=0.000370117, gnorm=0.858, loss_scale=16, train_wall=153, gb_free=20.8, wall=11923
2022-03-14 13:36:22 | INFO | train_inner | epoch 072:    102 / 103 loss=4.97, ppl=31.34, wps=41258.9, ups=0.63, wpb=65530.9, bsz=128, num_updates=7400, lr=0.000367607, gnorm=0.872, loss_scale=16, train_wall=154, gb_free=20.8, wall=12082
2022-03-14 13:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:36:27 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 8.288 | ppl 312.51 | wps 66500.1 | wpb 2040.3 | bsz 4 | num_updates 7401 | best_loss 7.59
2022-03-14 13:36:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 7401 updates
2022-03-14 13:36:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:36:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:36:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 72 @ 7401 updates, score 8.288) (writing took 0.8989949626848102 seconds)
2022-03-14 13:36:28 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-14 13:36:28 | INFO | train | epoch 072 | loss 4.969 | ppl 31.32 | wps 40142.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 7401 | lr 0.000367582 | gnorm 0.873 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 12087
KL Stats: Epoch 72 Divergences: Uniform: 4.472554271034389 Unigram: 4.30419519935824
2022-03-14 13:36:28 | INFO | fairseq.trainer | begin training epoch 73
2022-03-14 13:36:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:37:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 13:39:07 | INFO | train_inner | epoch 073:    100 / 103 loss=4.946, ppl=30.82, wps=39721.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7500, lr=0.000365148, gnorm=0.876, loss_scale=8, train_wall=155, gb_free=20.8, wall=12246
2022-03-14 13:39:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:39:15 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 8.334 | ppl 322.76 | wps 65928.3 | wpb 2040.3 | bsz 4 | num_updates 7503 | best_loss 7.59
2022-03-14 13:39:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 7503 updates
2022-03-14 13:39:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:39:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:39:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 73 @ 7503 updates, score 8.334) (writing took 0.9189912341535091 seconds)
2022-03-14 13:39:16 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-14 13:39:16 | INFO | train | epoch 073 | loss 4.948 | ppl 30.87 | wps 39742.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 7503 | lr 0.000365075 | gnorm 0.876 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12255
KL Stats: Epoch 73 Divergences: Uniform: 4.490686558467056 Unigram: 4.326317604222075
2022-03-14 13:39:16 | INFO | fairseq.trainer | begin training epoch 74
2022-03-14 13:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:41:49 | INFO | train_inner | epoch 074:     97 / 103 loss=4.927, ppl=30.42, wps=40151.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7600, lr=0.000362738, gnorm=0.88, loss_scale=8, train_wall=153, gb_free=20.8, wall=12409
2022-03-14 13:41:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:42:02 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 8.339 | ppl 323.8 | wps 66135.1 | wpb 2040.3 | bsz 4 | num_updates 7606 | best_loss 7.59
2022-03-14 13:42:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 7606 updates
2022-03-14 13:42:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:42:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:42:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 74 @ 7606 updates, score 8.339) (writing took 0.9169695442542434 seconds)
2022-03-14 13:42:03 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-14 13:42:03 | INFO | train | epoch 074 | loss 4.928 | ppl 30.45 | wps 40174.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7606 | lr 0.000362595 | gnorm 0.879 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12423
KL Stats: Epoch 74 Divergences: Uniform: 4.508244836729386 Unigram: 4.347384082924666
2022-03-14 13:42:03 | INFO | fairseq.trainer | begin training epoch 75
2022-03-14 13:42:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:44:32 | INFO | train_inner | epoch 075:     94 / 103 loss=4.907, ppl=30, wps=40147.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7700, lr=0.000360375, gnorm=0.877, loss_scale=8, train_wall=153, gb_free=20.8, wall=12572
2022-03-14 13:44:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:44:49 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 8.355 | ppl 327.37 | wps 66125.3 | wpb 2040.3 | bsz 4 | num_updates 7709 | best_loss 7.59
2022-03-14 13:44:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 7709 updates
2022-03-14 13:44:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:44:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:44:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 75 @ 7709 updates, score 8.355) (writing took 0.8897724514827132 seconds)
2022-03-14 13:44:50 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-14 13:44:50 | INFO | train | epoch 075 | loss 4.907 | ppl 30.01 | wps 40195.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7709 | lr 0.000360165 | gnorm 0.873 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12590
KL Stats: Epoch 75 Divergences: Uniform: 4.526996437667616 Unigram: 4.3674660166031565
2022-03-14 13:44:50 | INFO | fairseq.trainer | begin training epoch 76
2022-03-14 13:44:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:47:15 | INFO | train_inner | epoch 076:     91 / 103 loss=4.888, ppl=29.6, wps=40164, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7800, lr=0.000358057, gnorm=0.868, loss_scale=8, train_wall=153, gb_free=20.8, wall=12734
2022-03-14 13:47:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:47:37 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 8.382 | ppl 333.55 | wps 66287.4 | wpb 2040.3 | bsz 4 | num_updates 7812 | best_loss 7.59
2022-03-14 13:47:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 7812 updates
2022-03-14 13:47:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:47:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:47:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 76 @ 7812 updates, score 8.382) (writing took 0.9004593528807163 seconds)
2022-03-14 13:47:38 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-14 13:47:38 | INFO | train | epoch 076 | loss 4.89 | ppl 29.64 | wps 40202.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7812 | lr 0.000357782 | gnorm 0.872 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12757
KL Stats: Epoch 76 Divergences: Uniform: 4.545841626430005 Unigram: 4.3855870368595555
2022-03-14 13:47:38 | INFO | fairseq.trainer | begin training epoch 77
2022-03-14 13:47:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:49:57 | INFO | train_inner | epoch 077:     88 / 103 loss=4.872, ppl=29.29, wps=40173.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7900, lr=0.000355784, gnorm=0.884, loss_scale=8, train_wall=153, gb_free=20.8, wall=12897
2022-03-14 13:50:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:50:24 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 8.387 | ppl 334.66 | wps 66037.7 | wpb 2040.3 | bsz 4 | num_updates 7915 | best_loss 7.59
2022-03-14 13:50:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 7915 updates
2022-03-14 13:50:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:50:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:50:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 77 @ 7915 updates, score 8.387) (writing took 0.903616433031857 seconds)
2022-03-14 13:50:25 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-14 13:50:25 | INFO | train | epoch 077 | loss 4.871 | ppl 29.26 | wps 40198.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7915 | lr 0.000355447 | gnorm 0.888 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12925
KL Stats: Epoch 77 Divergences: Uniform: 4.562407863556615 Unigram: 4.403337774876507
2022-03-14 13:50:25 | INFO | fairseq.trainer | begin training epoch 78
2022-03-14 13:50:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:52:40 | INFO | train_inner | epoch 078:     85 / 103 loss=4.851, ppl=28.86, wps=40130.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8000, lr=0.000353553, gnorm=0.893, loss_scale=16, train_wall=153, gb_free=20.8, wall=13060
2022-03-14 13:53:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:53:12 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 8.417 | ppl 341.89 | wps 66275.6 | wpb 2040.3 | bsz 4 | num_updates 8018 | best_loss 7.59
2022-03-14 13:53:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 8018 updates
2022-03-14 13:53:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:53:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:53:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 78 @ 8018 updates, score 8.417) (writing took 0.9198249438777566 seconds)
2022-03-14 13:53:13 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-14 13:53:13 | INFO | train | epoch 078 | loss 4.851 | ppl 28.85 | wps 40151.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8018 | lr 0.000353156 | gnorm 0.894 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 13092
KL Stats: Epoch 78 Divergences: Uniform: 4.581966785334103 Unigram: 4.423220899623297
2022-03-14 13:53:13 | INFO | fairseq.trainer | begin training epoch 79
2022-03-14 13:53:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:55:23 | INFO | train_inner | epoch 079:     82 / 103 loss=4.835, ppl=28.55, wps=40107.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8100, lr=0.000351364, gnorm=0.881, loss_scale=16, train_wall=153, gb_free=20.8, wall=13222
2022-03-14 13:55:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:55:59 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 8.443 | ppl 347.91 | wps 66330.7 | wpb 2040.3 | bsz 4 | num_updates 8121 | best_loss 7.59
2022-03-14 13:55:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 8121 updates
2022-03-14 13:55:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:56:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:56:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 79 @ 8121 updates, score 8.443) (writing took 0.9207513276487589 seconds)
2022-03-14 13:56:00 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-14 13:56:00 | INFO | train | epoch 079 | loss 4.834 | ppl 28.52 | wps 40145.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8121 | lr 0.00035091 | gnorm 0.88 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 13260
KL Stats: Epoch 79 Divergences: Uniform: 4.597745010667796 Unigram: 4.442604170445354
2022-03-14 13:56:00 | INFO | fairseq.trainer | begin training epoch 80
2022-03-14 13:56:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:58:06 | INFO | train_inner | epoch 080:     79 / 103 loss=4.818, ppl=28.21, wps=40126.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8200, lr=0.000349215, gnorm=0.892, loss_scale=16, train_wall=153, gb_free=20.8, wall=13385
2022-03-14 13:58:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:58:47 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 8.447 | ppl 348.93 | wps 65949.8 | wpb 2040.3 | bsz 4 | num_updates 8224 | best_loss 7.59
2022-03-14 13:58:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 8224 updates
2022-03-14 13:58:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 13:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 80 @ 8224 updates, score 8.447) (writing took 0.90679513476789 seconds)
2022-03-14 13:58:48 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-14 13:58:48 | INFO | train | epoch 080 | loss 4.818 | ppl 28.2 | wps 40156.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8224 | lr 0.000348705 | gnorm 0.898 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 13427
KL Stats: Epoch 80 Divergences: Uniform: 4.611610257779031 Unigram: 4.4602415213211355
2022-03-14 13:58:48 | INFO | fairseq.trainer | begin training epoch 81
2022-03-14 13:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:00:48 | INFO | train_inner | epoch 081:     76 / 103 loss=4.805, ppl=27.95, wps=40105, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8300, lr=0.000347105, gnorm=0.887, loss_scale=16, train_wall=153, gb_free=20.8, wall=13548
2022-03-14 14:01:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:01:34 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 8.461 | ppl 352.49 | wps 66307.3 | wpb 2040.3 | bsz 4 | num_updates 8327 | best_loss 7.59
2022-03-14 14:01:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 8327 updates
2022-03-14 14:01:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:01:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:01:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 81 @ 8327 updates, score 8.461) (writing took 0.9658048572018743 seconds)
2022-03-14 14:01:35 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-14 14:01:35 | INFO | train | epoch 081 | loss 4.798 | ppl 27.83 | wps 40152.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8327 | lr 0.000346542 | gnorm 0.88 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 13595
KL Stats: Epoch 81 Divergences: Uniform: 4.627882296305099 Unigram: 4.477353673403909
2022-03-14 14:01:35 | INFO | fairseq.trainer | begin training epoch 82
2022-03-14 14:01:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:03:31 | INFO | train_inner | epoch 082:     73 / 103 loss=4.786, ppl=27.59, wps=40190.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=8400, lr=0.000345033, gnorm=0.894, loss_scale=16, train_wall=153, gb_free=20.8, wall=13710
2022-03-14 14:04:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:04:22 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 8.483 | ppl 357.74 | wps 66304.2 | wpb 2040.3 | bsz 4 | num_updates 8430 | best_loss 7.59
2022-03-14 14:04:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 8430 updates
2022-03-14 14:04:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:04:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:04:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 82 @ 8430 updates, score 8.483) (writing took 1.0102020064368844 seconds)
2022-03-14 14:04:23 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-14 14:04:23 | INFO | train | epoch 082 | loss 4.784 | ppl 27.55 | wps 40202.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8430 | lr 0.000344418 | gnorm 0.899 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 13762
KL Stats: Epoch 82 Divergences: Uniform: 4.64364481642212 Unigram: 4.49598378009242
2022-03-14 14:04:23 | INFO | fairseq.trainer | begin training epoch 83
2022-03-14 14:04:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:05:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 14:06:15 | INFO | train_inner | epoch 083:     71 / 103 loss=4.769, ppl=27.27, wps=39774.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8500, lr=0.000342997, gnorm=0.895, loss_scale=16, train_wall=155, gb_free=20.8, wall=13875
2022-03-14 14:07:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:07:09 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 8.501 | ppl 362.28 | wps 66138.5 | wpb 2040.3 | bsz 4 | num_updates 8532 | best_loss 7.59
2022-03-14 14:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 8532 updates
2022-03-14 14:07:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:07:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:07:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 83 @ 8532 updates, score 8.501) (writing took 1.102969012223184 seconds)
2022-03-14 14:07:10 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-14 14:07:10 | INFO | train | epoch 083 | loss 4.767 | ppl 27.23 | wps 39781.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 8532 | lr 0.000342353 | gnorm 0.895 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 13930
KL Stats: Epoch 83 Divergences: Uniform: 4.659220507566698 Unigram: 4.513700094991153
2022-03-14 14:07:10 | INFO | fairseq.trainer | begin training epoch 84
2022-03-14 14:07:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:08:58 | INFO | train_inner | epoch 084:     68 / 103 loss=4.756, ppl=27.03, wps=40116, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8600, lr=0.000340997, gnorm=0.891, loss_scale=16, train_wall=153, gb_free=20.8, wall=14037
2022-03-14 14:09:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:09:56 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 8.526 | ppl 368.72 | wps 65854.1 | wpb 2040.3 | bsz 4 | num_updates 8635 | best_loss 7.59
2022-03-14 14:09:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 8635 updates
2022-03-14 14:09:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:09:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:09:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 84 @ 8635 updates, score 8.526) (writing took 1.0829272009432316 seconds)
2022-03-14 14:09:58 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-14 14:09:58 | INFO | train | epoch 084 | loss 4.752 | ppl 26.94 | wps 40143.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8635 | lr 0.000340305 | gnorm 0.898 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 14097
KL Stats: Epoch 84 Divergences: Uniform: 4.67320915480316 Unigram: 4.532138629448944
2022-03-14 14:09:58 | INFO | fairseq.trainer | begin training epoch 85
2022-03-14 14:09:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:11:41 | INFO | train_inner | epoch 085:     65 / 103 loss=4.741, ppl=26.75, wps=40118.2, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=8700, lr=0.000339032, gnorm=0.908, loss_scale=16, train_wall=153, gb_free=20.8, wall=14200
2022-03-14 14:12:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:12:44 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 8.519 | ppl 366.95 | wps 65579.4 | wpb 2040.3 | bsz 4 | num_updates 8738 | best_loss 7.59
2022-03-14 14:12:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 8738 updates
2022-03-14 14:12:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:12:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:12:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 85 @ 8738 updates, score 8.519) (writing took 0.9905870463699102 seconds)
2022-03-14 14:12:45 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-14 14:12:45 | INFO | train | epoch 085 | loss 4.735 | ppl 26.64 | wps 40156.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8738 | lr 0.000338294 | gnorm 0.897 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 14265
KL Stats: Epoch 85 Divergences: Uniform: 4.68574541056143 Unigram: 4.5457902404656085
2022-03-14 14:12:45 | INFO | fairseq.trainer | begin training epoch 86
2022-03-14 14:12:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:14:23 | INFO | train_inner | epoch 086:     62 / 103 loss=4.727, ppl=26.49, wps=40143.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8800, lr=0.0003371, gnorm=0.904, loss_scale=16, train_wall=153, gb_free=20.8, wall=14363
2022-03-14 14:15:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:15:31 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 8.541 | ppl 372.53 | wps 65944.4 | wpb 2040.3 | bsz 4 | num_updates 8841 | best_loss 7.59
2022-03-14 14:15:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 8841 updates
2022-03-14 14:15:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:15:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:15:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 86 @ 8841 updates, score 8.541) (writing took 1.0723423641175032 seconds)
2022-03-14 14:15:33 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-14 14:15:33 | INFO | train | epoch 086 | loss 4.721 | ppl 26.37 | wps 40182 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8841 | lr 0.000336317 | gnorm 0.906 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 14432
KL Stats: Epoch 86 Divergences: Uniform: 4.6997520759641445 Unigram: 4.560935655925676
2022-03-14 14:15:33 | INFO | fairseq.trainer | begin training epoch 87
2022-03-14 14:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:17:06 | INFO | train_inner | epoch 087:     59 / 103 loss=4.709, ppl=26.15, wps=40143.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=8900, lr=0.000335201, gnorm=0.888, loss_scale=16, train_wall=153, gb_free=20.8, wall=14526
2022-03-14 14:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:18:19 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 8.556 | ppl 376.47 | wps 65301 | wpb 2040.3 | bsz 4 | num_updates 8944 | best_loss 7.59
2022-03-14 14:18:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 8944 updates
2022-03-14 14:18:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:18:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:18:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 87 @ 8944 updates, score 8.556) (writing took 1.0283921165391803 seconds)
2022-03-14 14:18:20 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-14 14:18:20 | INFO | train | epoch 087 | loss 4.706 | ppl 26.11 | wps 40187.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8944 | lr 0.000334375 | gnorm 0.896 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 14599
KL Stats: Epoch 87 Divergences: Uniform: 4.713098903331918 Unigram: 4.5778884445757235
2022-03-14 14:18:20 | INFO | fairseq.trainer | begin training epoch 88
2022-03-14 14:18:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:19:49 | INFO | train_inner | epoch 088:     56 / 103 loss=4.696, ppl=25.93, wps=40144.1, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=9000, lr=0.000333333, gnorm=0.902, loss_scale=32, train_wall=153, gb_free=20.8, wall=14688
2022-03-14 14:20:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 14:21:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:21:06 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 8.569 | ppl 379.84 | wps 66337 | wpb 2040.3 | bsz 4 | num_updates 9046 | best_loss 7.59
2022-03-14 14:21:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 9046 updates
2022-03-14 14:21:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:21:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:21:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 88 @ 9046 updates, score 8.569) (writing took 1.04257389344275 seconds)
2022-03-14 14:21:07 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-14 14:21:07 | INFO | train | epoch 088 | loss 4.691 | ppl 25.84 | wps 39802.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 9046 | lr 0.000332485 | gnorm 0.909 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 14767
KL Stats: Epoch 88 Divergences: Uniform: 4.727699517519784 Unigram: 4.593170905595494
2022-03-14 14:21:07 | INFO | fairseq.trainer | begin training epoch 89
2022-03-14 14:21:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:22:33 | INFO | train_inner | epoch 089:     54 / 103 loss=4.687, ppl=25.77, wps=39777.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=9100, lr=0.000331497, gnorm=0.92, loss_scale=16, train_wall=155, gb_free=20.8, wall=14852
2022-03-14 14:23:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:23:54 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 8.59 | ppl 385.37 | wps 65938.4 | wpb 2040.3 | bsz 4 | num_updates 9149 | best_loss 7.59
2022-03-14 14:23:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 9149 updates
2022-03-14 14:23:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:23:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:23:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 89 @ 9149 updates, score 8.59) (writing took 1.0627302285283804 seconds)
2022-03-14 14:23:55 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-14 14:23:55 | INFO | train | epoch 089 | loss 4.678 | ppl 25.6 | wps 40196.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9149 | lr 0.000330608 | gnorm 0.912 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 14934
KL Stats: Epoch 89 Divergences: Uniform: 4.73922940205458 Unigram: 4.607618183894997
2022-03-14 14:23:55 | INFO | fairseq.trainer | begin training epoch 90
2022-03-14 14:23:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:25:15 | INFO | train_inner | epoch 090:     51 / 103 loss=4.67, ppl=25.46, wps=40167.2, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=9200, lr=0.00032969, gnorm=0.919, loss_scale=16, train_wall=153, gb_free=20.8, wall=15015
2022-03-14 14:26:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:26:41 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 8.607 | ppl 389.91 | wps 65692.1 | wpb 2040.3 | bsz 4 | num_updates 9252 | best_loss 7.59
2022-03-14 14:26:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 9252 updates
2022-03-14 14:26:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:26:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:26:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 90 @ 9252 updates, score 8.607) (writing took 1.0322782583534718 seconds)
2022-03-14 14:26:42 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-14 14:26:42 | INFO | train | epoch 090 | loss 4.664 | ppl 25.36 | wps 40186.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9252 | lr 0.000328762 | gnorm 0.917 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15102
KL Stats: Epoch 90 Divergences: Uniform: 4.749422576612478 Unigram: 4.621009835779513
2022-03-14 14:26:42 | INFO | fairseq.trainer | begin training epoch 91
2022-03-14 14:26:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:27:58 | INFO | train_inner | epoch 091:     48 / 103 loss=4.658, ppl=25.24, wps=40162, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=9300, lr=0.000327913, gnorm=0.921, loss_scale=16, train_wall=153, gb_free=20.8, wall=15178
2022-03-14 14:29:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:29:28 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 8.612 | ppl 391.4 | wps 66103.7 | wpb 2040.3 | bsz 4 | num_updates 9355 | best_loss 7.59
2022-03-14 14:29:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 9355 updates
2022-03-14 14:29:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:29:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:29:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 91 @ 9355 updates, score 8.612) (writing took 1.0174943311139941 seconds)
2022-03-14 14:29:29 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-14 14:29:29 | INFO | train | epoch 091 | loss 4.651 | ppl 25.13 | wps 40214.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9355 | lr 0.000326948 | gnorm 0.929 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15269
KL Stats: Epoch 91 Divergences: Uniform: 4.762293771418985 Unigram: 4.636092244688752
2022-03-14 14:29:29 | INFO | fairseq.trainer | begin training epoch 92
2022-03-14 14:29:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:30:41 | INFO | train_inner | epoch 092:     45 / 103 loss=4.646, ppl=25.04, wps=40170.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=9400, lr=0.000326164, gnorm=0.915, loss_scale=16, train_wall=153, gb_free=20.8, wall=15340
2022-03-14 14:32:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:32:16 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 8.647 | ppl 400.84 | wps 65895.3 | wpb 2040.3 | bsz 4 | num_updates 9458 | best_loss 7.59
2022-03-14 14:32:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 9458 updates
2022-03-14 14:32:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:32:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:32:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 92 @ 9458 updates, score 8.647) (writing took 1.0602828729897738 seconds)
2022-03-14 14:32:17 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-14 14:32:17 | INFO | train | epoch 092 | loss 4.637 | ppl 24.88 | wps 40189.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9458 | lr 0.000325162 | gnorm 0.91 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15436
KL Stats: Epoch 92 Divergences: Uniform: 4.776848612045619 Unigram: 4.652887105854086
2022-03-14 14:32:17 | INFO | fairseq.trainer | begin training epoch 93
2022-03-14 14:32:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:33:23 | INFO | train_inner | epoch 093:     42 / 103 loss=4.629, ppl=24.74, wps=40154.2, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=9500, lr=0.000324443, gnorm=0.909, loss_scale=16, train_wall=153, gb_free=20.8, wall=15503
2022-03-14 14:34:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 14:34:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:35:03 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 8.656 | ppl 403.35 | wps 66346.4 | wpb 2040.3 | bsz 4 | num_updates 9560 | best_loss 7.59
2022-03-14 14:35:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 9560 updates
2022-03-14 14:35:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:35:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:35:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 93 @ 9560 updates, score 8.656) (writing took 0.9865765376016498 seconds)
2022-03-14 14:35:04 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-14 14:35:04 | INFO | train | epoch 093 | loss 4.623 | ppl 24.64 | wps 39817.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 9560 | lr 0.000323423 | gnorm 0.918 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15604
KL Stats: Epoch 93 Divergences: Uniform: 4.786295911081138 Unigram: 4.66597965657163
2022-03-14 14:35:04 | INFO | fairseq.trainer | begin training epoch 94
2022-03-14 14:35:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:36:07 | INFO | train_inner | epoch 094:     40 / 103 loss=4.614, ppl=24.49, wps=39785.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=9600, lr=0.000322749, gnorm=0.923, loss_scale=16, train_wall=155, gb_free=20.8, wall=15667
2022-03-14 14:37:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:37:50 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 8.657 | ppl 403.72 | wps 66313.5 | wpb 2040.3 | bsz 4 | num_updates 9663 | best_loss 7.59
2022-03-14 14:37:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 9663 updates
2022-03-14 14:37:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:37:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:37:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 94 @ 9663 updates, score 8.657) (writing took 1.0097200656309724 seconds)
2022-03-14 14:37:51 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-14 14:37:51 | INFO | train | epoch 094 | loss 4.612 | ppl 24.45 | wps 40177.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9663 | lr 0.000321695 | gnorm 0.916 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15771
KL Stats: Epoch 94 Divergences: Uniform: 4.795869366672821 Unigram: 4.678288286930939
2022-03-14 14:37:51 | INFO | fairseq.trainer | begin training epoch 95
2022-03-14 14:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:38:50 | INFO | train_inner | epoch 095:     37 / 103 loss=4.612, ppl=24.46, wps=40140.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=9700, lr=0.000321081, gnorm=0.92, loss_scale=16, train_wall=153, gb_free=20.8, wall=15830
2022-03-14 14:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:40:38 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 8.673 | ppl 408.23 | wps 65836.9 | wpb 2040.3 | bsz 4 | num_updates 9766 | best_loss 7.59
2022-03-14 14:40:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 9766 updates
2022-03-14 14:40:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:40:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:40:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 95 @ 9766 updates, score 8.673) (writing took 0.9926977781578898 seconds)
2022-03-14 14:40:39 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-14 14:40:39 | INFO | train | epoch 095 | loss 4.599 | ppl 24.23 | wps 40119.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9766 | lr 0.000319994 | gnorm 0.917 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15939
KL Stats: Epoch 95 Divergences: Uniform: 4.8071750500571335 Unigram: 4.694292774810735
2022-03-14 14:40:39 | INFO | fairseq.trainer | begin training epoch 96
2022-03-14 14:40:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:41:33 | INFO | train_inner | epoch 096:     34 / 103 loss=4.597, ppl=24.21, wps=40029.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=9800, lr=0.000319438, gnorm=0.918, loss_scale=16, train_wall=154, gb_free=20.8, wall=15993
2022-03-14 14:43:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:43:26 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 8.687 | ppl 412.12 | wps 65933.3 | wpb 2040.3 | bsz 4 | num_updates 9869 | best_loss 7.59
2022-03-14 14:43:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 9869 updates
2022-03-14 14:43:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:43:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:43:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 96 @ 9869 updates, score 8.687) (writing took 0.9730802746489644 seconds)
2022-03-14 14:43:27 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-14 14:43:27 | INFO | train | epoch 096 | loss 4.587 | ppl 24.04 | wps 40051.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9869 | lr 0.00031832 | gnorm 0.929 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 16107
KL Stats: Epoch 96 Divergences: Uniform: 4.817900281304952 Unigram: 4.704591201762585
2022-03-14 14:43:27 | INFO | fairseq.trainer | begin training epoch 97
2022-03-14 14:43:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:44:16 | INFO | train_inner | epoch 097:     31 / 103 loss=4.584, ppl=23.98, wps=40027.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=9900, lr=0.000317821, gnorm=0.929, loss_scale=16, train_wall=154, gb_free=20.8, wall=16156
2022-03-14 14:46:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:46:14 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 8.682 | ppl 410.58 | wps 65232.5 | wpb 2040.3 | bsz 4 | num_updates 9972 | best_loss 7.59
2022-03-14 14:46:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 9972 updates
2022-03-14 14:46:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:46:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:46:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 97 @ 9972 updates, score 8.682) (writing took 0.9384982259944081 seconds)
2022-03-14 14:46:15 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-14 14:46:15 | INFO | train | epoch 097 | loss 4.575 | ppl 23.83 | wps 40082.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9972 | lr 0.000316671 | gnorm 0.924 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 16274
KL Stats: Epoch 97 Divergences: Uniform: 4.829184858147473 Unigram: 4.719517289807403
2022-03-14 14:46:15 | INFO | fairseq.trainer | begin training epoch 98
2022-03-14 14:46:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:46:59 | INFO | train_inner | epoch 098:     28 / 103 loss=4.573, ppl=23.79, wps=40054.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10000, lr=0.000316228, gnorm=0.926, loss_scale=16, train_wall=153, gb_free=20.8, wall=16319
2022-03-14 14:48:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:49:02 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 8.722 | ppl 422.41 | wps 66277.4 | wpb 2040.3 | bsz 4 | num_updates 10075 | best_loss 7.59
2022-03-14 14:49:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 10075 updates
2022-03-14 14:49:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:49:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:49:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 98 @ 10075 updates, score 8.722) (writing took 0.9855579603463411 seconds)
2022-03-14 14:49:03 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-14 14:49:03 | INFO | train | epoch 098 | loss 4.564 | ppl 23.65 | wps 40075.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 10075 | lr 0.000315049 | gnorm 0.918 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 16442
KL Stats: Epoch 98 Divergences: Uniform: 4.839944625242794 Unigram: 4.732756262467424
2022-03-14 14:49:03 | INFO | fairseq.trainer | begin training epoch 99
2022-03-14 14:49:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:49:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 14:49:44 | INFO | train_inner | epoch 099:     26 / 103 loss=4.562, ppl=23.62, wps=39657.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10100, lr=0.000314658, gnorm=0.911, loss_scale=16, train_wall=155, gb_free=20.8, wall=16484
2022-03-14 14:51:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:51:50 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 8.726 | ppl 423.34 | wps 65391.2 | wpb 2040.3 | bsz 4 | num_updates 10177 | best_loss 7.59
2022-03-14 14:51:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 10177 updates
2022-03-14 14:51:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:51:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:51:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 99 @ 10177 updates, score 8.726) (writing took 0.9648259487003088 seconds)
2022-03-14 14:51:51 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-14 14:51:51 | INFO | train | epoch 099 | loss 4.551 | ppl 23.44 | wps 39681.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 10177 | lr 0.000313466 | gnorm 0.932 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 16610
KL Stats: Epoch 99 Divergences: Uniform: 4.847643453577679 Unigram: 4.744075523732821
2022-03-14 14:51:51 | INFO | fairseq.trainer | begin training epoch 100
2022-03-14 14:51:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:52:27 | INFO | train_inner | epoch 100:     23 / 103 loss=4.548, ppl=23.4, wps=40017.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10200, lr=0.000313112, gnorm=0.941, loss_scale=16, train_wall=154, gb_free=20.8, wall=16647
2022-03-14 14:54:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:54:38 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 8.724 | ppl 422.84 | wps 65651.3 | wpb 2040.3 | bsz 4 | num_updates 10280 | best_loss 7.59
2022-03-14 14:54:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 10280 updates
2022-03-14 14:54:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:54:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:54:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 100 @ 10280 updates, score 8.724) (writing took 0.9831382678821683 seconds)
2022-03-14 14:54:39 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-14 14:54:39 | INFO | train | epoch 100 | loss 4.54 | ppl 23.26 | wps 40072.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 10280 | lr 0.000311891 | gnorm 0.93 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 16778
KL Stats: Epoch 100 Divergences: Uniform: 4.856538736947366 Unigram: 4.755345353873261
2022-03-14 14:54:39 | INFO | fairseq.trainer | begin training epoch 101
2022-03-14 14:54:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:55:10 | INFO | train_inner | epoch 101:     20 / 103 loss=4.54, ppl=23.26, wps=40056.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10300, lr=0.000311588, gnorm=0.926, loss_scale=16, train_wall=153, gb_free=20.8, wall=16810
2022-03-14 14:57:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:57:25 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 8.745 | ppl 429.13 | wps 66051.3 | wpb 2040.3 | bsz 4 | num_updates 10383 | best_loss 7.59
2022-03-14 14:57:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 10383 updates
2022-03-14 14:57:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:57:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 14:57:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 101 @ 10383 updates, score 8.745) (writing took 0.9023045459762216 seconds)
2022-03-14 14:57:26 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-14 14:57:26 | INFO | train | epoch 101 | loss 4.53 | ppl 23.1 | wps 40101.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 10383 | lr 0.000310341 | gnorm 0.936 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 16946
KL Stats: Epoch 101 Divergences: Uniform: 4.86856843808768 Unigram: 4.767224404074419
2022-03-14 14:57:26 | INFO | fairseq.trainer | begin training epoch 102
2022-03-14 14:57:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:57:53 | INFO | train_inner | epoch 102:     17 / 103 loss=4.53, ppl=23.1, wps=40054, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10400, lr=0.000310087, gnorm=0.939, loss_scale=16, train_wall=154, gb_free=20.8, wall=16973
2022-03-14 15:00:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:00:13 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 8.755 | ppl 431.93 | wps 65642.6 | wpb 2040.3 | bsz 4 | num_updates 10486 | best_loss 7.59
2022-03-14 15:00:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 10486 updates
2022-03-14 15:00:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:00:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:00:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 102 @ 10486 updates, score 8.755) (writing took 1.0130263920873404 seconds)
2022-03-14 15:00:14 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-14 15:00:14 | INFO | train | epoch 102 | loss 4.518 | ppl 22.91 | wps 40079.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 10486 | lr 0.000308813 | gnorm 0.94 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17114
KL Stats: Epoch 102 Divergences: Uniform: 4.878493231225864 Unigram: 4.779777311849085
2022-03-14 15:00:14 | INFO | fairseq.trainer | begin training epoch 103
2022-03-14 15:00:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:00:36 | INFO | train_inner | epoch 103:     14 / 103 loss=4.519, ppl=22.93, wps=40064.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10500, lr=0.000308607, gnorm=0.941, loss_scale=16, train_wall=153, gb_free=20.8, wall=17136
2022-03-14 15:02:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:03:01 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 8.77 | ppl 436.65 | wps 66110.5 | wpb 2040.3 | bsz 4 | num_updates 10589 | best_loss 7.59
2022-03-14 15:03:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 10589 updates
2022-03-14 15:03:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:03:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:03:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 103 @ 10589 updates, score 8.77) (writing took 1.0218545021489263 seconds)
2022-03-14 15:03:02 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-14 15:03:02 | INFO | train | epoch 103 | loss 4.508 | ppl 22.75 | wps 40178.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10589 | lr 0.000307307 | gnorm 0.948 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17281
KL Stats: Epoch 103 Divergences: Uniform: 4.886124640994757 Unigram: 4.789507242141729
2022-03-14 15:03:02 | INFO | fairseq.trainer | begin training epoch 104
2022-03-14 15:03:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:03:19 | INFO | train_inner | epoch 104:     11 / 103 loss=4.509, ppl=22.77, wps=40155.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10600, lr=0.000307148, gnorm=0.947, loss_scale=16, train_wall=153, gb_free=20.8, wall=17299
2022-03-14 15:03:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 15:05:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:05:48 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 8.789 | ppl 442.32 | wps 65815.5 | wpb 2040.3 | bsz 4 | num_updates 10691 | best_loss 7.59
2022-03-14 15:05:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 10691 updates
2022-03-14 15:05:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:05:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:05:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 104 @ 10691 updates, score 8.789) (writing took 1.1162580763921142 seconds)
2022-03-14 15:05:49 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-14 15:05:49 | INFO | train | epoch 104 | loss 4.495 | ppl 22.55 | wps 39787.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 10691 | lr 0.000305838 | gnorm 0.931 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17449
KL Stats: Epoch 104 Divergences: Uniform: 4.8962862137531085 Unigram: 4.805371989411175
2022-03-14 15:05:49 | INFO | fairseq.trainer | begin training epoch 105
2022-03-14 15:05:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:06:03 | INFO | train_inner | epoch 105:      9 / 103 loss=4.494, ppl=22.53, wps=39761.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10700, lr=0.000305709, gnorm=0.93, loss_scale=16, train_wall=155, gb_free=20.8, wall=17463
2022-03-14 15:08:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:08:35 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 8.813 | ppl 449.85 | wps 66114 | wpb 2040.3 | bsz 4 | num_updates 10794 | best_loss 7.59
2022-03-14 15:08:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 10794 updates
2022-03-14 15:08:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:08:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:08:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 105 @ 10794 updates, score 8.813) (writing took 1.0378858083859086 seconds)
2022-03-14 15:08:36 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-14 15:08:36 | INFO | train | epoch 105 | loss 4.488 | ppl 22.43 | wps 40195.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10794 | lr 0.000304375 | gnorm 0.952 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17616
KL Stats: Epoch 105 Divergences: Uniform: 4.903365605120363 Unigram: 4.813595618233605
2022-03-14 15:08:36 | INFO | fairseq.trainer | begin training epoch 106
2022-03-14 15:08:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:08:46 | INFO | train_inner | epoch 106:      6 / 103 loss=4.491, ppl=22.49, wps=40157.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10800, lr=0.00030429, gnorm=0.955, loss_scale=16, train_wall=153, gb_free=20.8, wall=17626
2022-03-14 15:11:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:11:23 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 8.822 | ppl 452.62 | wps 66140.5 | wpb 2040.3 | bsz 4 | num_updates 10897 | best_loss 7.59
2022-03-14 15:11:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 10897 updates
2022-03-14 15:11:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:11:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:11:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 106 @ 10897 updates, score 8.822) (writing took 1.0205627782270312 seconds)
2022-03-14 15:11:24 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-14 15:11:24 | INFO | train | epoch 106 | loss 4.476 | ppl 22.26 | wps 40190.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10897 | lr 0.000302933 | gnorm 0.94 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17783
KL Stats: Epoch 106 Divergences: Uniform: 4.9142588853573 Unigram: 4.82585434277034
2022-03-14 15:11:24 | INFO | fairseq.trainer | begin training epoch 107
2022-03-14 15:11:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:11:29 | INFO | train_inner | epoch 107:      3 / 103 loss=4.478, ppl=22.29, wps=40155.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10900, lr=0.000302891, gnorm=0.938, loss_scale=16, train_wall=153, gb_free=20.8, wall=17788
2022-03-14 15:14:07 | INFO | train_inner | epoch 107:    103 / 103 loss=4.47, ppl=22.16, wps=41341.2, ups=0.63, wpb=65305.6, bsz=127.6, num_updates=11000, lr=0.000301511, gnorm=0.939, loss_scale=16, train_wall=153, gb_free=20.8, wall=17946
2022-03-14 15:14:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:14:10 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 8.823 | ppl 452.82 | wps 66250.7 | wpb 2040.3 | bsz 4 | num_updates 11000 | best_loss 7.59
2022-03-14 15:14:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 11000 updates
2022-03-14 15:14:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:14:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:14:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 107 @ 11000 updates, score 8.823) (writing took 1.0108625311404467 seconds)
2022-03-14 15:14:11 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-14 15:14:11 | INFO | train | epoch 107 | loss 4.467 | ppl 22.11 | wps 40190.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11000 | lr 0.000301511 | gnorm 0.94 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17951
KL Stats: Epoch 107 Divergences: Uniform: 4.920830924092693 Unigram: 4.835301340095433
2022-03-14 15:14:11 | INFO | fairseq.trainer | begin training epoch 108
2022-03-14 15:14:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:16:50 | INFO | train_inner | epoch 108:    100 / 103 loss=4.456, ppl=21.95, wps=40177.3, ups=0.61, wpb=65530.9, bsz=128, num_updates=11100, lr=0.00030015, gnorm=0.957, loss_scale=16, train_wall=154, gb_free=20.8, wall=18109
2022-03-14 15:16:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:16:57 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 8.837 | ppl 457.2 | wps 66200.5 | wpb 2040.3 | bsz 4 | num_updates 11103 | best_loss 7.59
2022-03-14 15:16:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 11103 updates
2022-03-14 15:16:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:16:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:16:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 108 @ 11103 updates, score 8.837) (writing took 0.9534772718325257 seconds)
2022-03-14 15:16:58 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-14 15:16:58 | INFO | train | epoch 108 | loss 4.458 | ppl 21.98 | wps 40215.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11103 | lr 0.00030011 | gnorm 0.961 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 18118
KL Stats: Epoch 108 Divergences: Uniform: 4.9284922405830764 Unigram: 4.845588138042982
2022-03-14 15:16:58 | INFO | fairseq.trainer | begin training epoch 109
2022-03-14 15:16:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:17:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 15:19:34 | INFO | train_inner | epoch 109:     98 / 103 loss=4.444, ppl=21.76, wps=39790.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=11200, lr=0.000298807, gnorm=0.943, loss_scale=16, train_wall=155, gb_free=20.8, wall=18273
2022-03-14 15:19:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:19:45 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 8.84 | ppl 458.33 | wps 66541.6 | wpb 2040.3 | bsz 4 | num_updates 11205 | best_loss 7.59
2022-03-14 15:19:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 11205 updates
2022-03-14 15:19:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:19:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:19:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 109 @ 11205 updates, score 8.84) (writing took 0.9749775826931 seconds)
2022-03-14 15:19:46 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-14 15:19:46 | INFO | train | epoch 109 | loss 4.445 | ppl 21.78 | wps 39820.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 11205 | lr 0.00029874 | gnorm 0.939 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 18285
KL Stats: Epoch 109 Divergences: Uniform: 4.937551476807224 Unigram: 4.858881602369717
2022-03-14 15:19:46 | INFO | fairseq.trainer | begin training epoch 110
2022-03-14 15:19:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:20:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 15:22:18 | INFO | train_inner | epoch 110:     96 / 103 loss=4.434, ppl=21.62, wps=39804.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=11300, lr=0.000297482, gnorm=0.942, loss_scale=8, train_wall=155, gb_free=20.8, wall=18437
2022-03-14 15:22:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:22:32 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 8.853 | ppl 462.35 | wps 66261.1 | wpb 2040.3 | bsz 4 | num_updates 11307 | best_loss 7.59
2022-03-14 15:22:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 11307 updates
2022-03-14 15:22:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:22:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:22:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 110 @ 11307 updates, score 8.853) (writing took 1.018637984059751 seconds)
2022-03-14 15:22:33 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-14 15:22:33 | INFO | train | epoch 110 | loss 4.437 | ppl 21.66 | wps 39823.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 11307 | lr 0.00029739 | gnorm 0.945 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 18453
KL Stats: Epoch 110 Divergences: Uniform: 4.9468192294486615 Unigram: 4.8690157403135705
2022-03-14 15:22:33 | INFO | fairseq.trainer | begin training epoch 111
2022-03-14 15:22:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:25:00 | INFO | train_inner | epoch 111:     93 / 103 loss=4.428, ppl=21.53, wps=40178.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11400, lr=0.000296174, gnorm=0.959, loss_scale=8, train_wall=153, gb_free=20.8, wall=18600
2022-03-14 15:25:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:25:19 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 8.839 | ppl 457.87 | wps 66143.9 | wpb 2040.3 | bsz 4 | num_updates 11410 | best_loss 7.59
2022-03-14 15:25:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 11410 updates
2022-03-14 15:25:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:25:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:25:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 111 @ 11410 updates, score 8.839) (writing took 0.9941966393962502 seconds)
2022-03-14 15:25:20 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-14 15:25:20 | INFO | train | epoch 111 | loss 4.429 | ppl 21.54 | wps 40211.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11410 | lr 0.000296045 | gnorm 0.959 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 18620
KL Stats: Epoch 111 Divergences: Uniform: 4.951620439906119 Unigram: 4.876474153280872
2022-03-14 15:25:20 | INFO | fairseq.trainer | begin training epoch 112
2022-03-14 15:25:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:27:43 | INFO | train_inner | epoch 112:     90 / 103 loss=4.421, ppl=21.43, wps=40163.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11500, lr=0.000294884, gnorm=0.959, loss_scale=8, train_wall=153, gb_free=20.8, wall=18763
2022-03-14 15:28:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:28:07 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 8.865 | ppl 466.11 | wps 66121.7 | wpb 2040.3 | bsz 4 | num_updates 11513 | best_loss 7.59
2022-03-14 15:28:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 11513 updates
2022-03-14 15:28:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:28:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:28:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 112 @ 11513 updates, score 8.865) (writing took 1.007631791755557 seconds)
2022-03-14 15:28:08 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-14 15:28:08 | INFO | train | epoch 112 | loss 4.421 | ppl 21.42 | wps 40199.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11513 | lr 0.000294717 | gnorm 0.958 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 18787
KL Stats: Epoch 112 Divergences: Uniform: 4.959759166811529 Unigram: 4.885749758881389
2022-03-14 15:28:08 | INFO | fairseq.trainer | begin training epoch 113
2022-03-14 15:28:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:30:26 | INFO | train_inner | epoch 113:     87 / 103 loss=4.408, ppl=21.23, wps=40167.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11600, lr=0.00029361, gnorm=0.958, loss_scale=8, train_wall=153, gb_free=20.8, wall=18925
2022-03-14 15:30:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:30:54 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 8.897 | ppl 476.85 | wps 66604.4 | wpb 2040.3 | bsz 4 | num_updates 11616 | best_loss 7.59
2022-03-14 15:30:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 11616 updates
2022-03-14 15:30:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:30:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:30:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 113 @ 11616 updates, score 8.897) (writing took 0.9801598889753222 seconds)
2022-03-14 15:30:55 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-14 15:30:55 | INFO | train | epoch 113 | loss 4.41 | ppl 21.27 | wps 40212.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11616 | lr 0.000293408 | gnorm 0.963 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 18954
KL Stats: Epoch 113 Divergences: Uniform: 4.966954476081874 Unigram: 4.898508923717525
2022-03-14 15:30:55 | INFO | fairseq.trainer | begin training epoch 114
2022-03-14 15:30:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:33:08 | INFO | train_inner | epoch 114:     84 / 103 loss=4.402, ppl=21.14, wps=40191.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11700, lr=0.000292353, gnorm=0.973, loss_scale=8, train_wall=153, gb_free=20.8, wall=19088
2022-03-14 15:33:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:33:41 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 8.911 | ppl 481.5 | wps 66298.8 | wpb 2040.3 | bsz 4 | num_updates 11719 | best_loss 7.59
2022-03-14 15:33:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 11719 updates
2022-03-14 15:33:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:33:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:33:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 114 @ 11719 updates, score 8.911) (writing took 0.9459133604541421 seconds)
2022-03-14 15:33:42 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-14 15:33:42 | INFO | train | epoch 114 | loss 4.401 | ppl 21.13 | wps 40230.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11719 | lr 0.000292116 | gnorm 0.965 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 19122
KL Stats: Epoch 114 Divergences: Uniform: 4.976181800788972 Unigram: 4.911318703862226
2022-03-14 15:33:42 | INFO | fairseq.trainer | begin training epoch 115
2022-03-14 15:33:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:35:51 | INFO | train_inner | epoch 115:     81 / 103 loss=4.392, ppl=21, wps=40197.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=11800, lr=0.000291111, gnorm=0.961, loss_scale=16, train_wall=153, gb_free=20.8, wall=19250
2022-03-14 15:36:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:36:28 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 8.903 | ppl 478.87 | wps 66119.4 | wpb 2040.3 | bsz 4 | num_updates 11822 | best_loss 7.59
2022-03-14 15:36:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 11822 updates
2022-03-14 15:36:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:36:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:36:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 115 @ 11822 updates, score 8.903) (writing took 0.9614679664373398 seconds)
2022-03-14 15:36:29 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-14 15:36:29 | INFO | train | epoch 115 | loss 4.393 | ppl 21.01 | wps 40223.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11822 | lr 0.00029084 | gnorm 0.971 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19289
KL Stats: Epoch 115 Divergences: Uniform: 4.980247734030541 Unigram: 4.918564914157611
2022-03-14 15:36:29 | INFO | fairseq.trainer | begin training epoch 116
2022-03-14 15:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:38:33 | INFO | train_inner | epoch 116:     78 / 103 loss=4.384, ppl=20.89, wps=40182.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=11900, lr=0.000289886, gnorm=0.964, loss_scale=16, train_wall=153, gb_free=20.8, wall=19413
2022-03-14 15:39:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:39:16 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 8.92 | ppl 484.23 | wps 66406.7 | wpb 2040.3 | bsz 4 | num_updates 11925 | best_loss 7.59
2022-03-14 15:39:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 11925 updates
2022-03-14 15:39:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:39:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:39:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 116 @ 11925 updates, score 8.92) (writing took 0.9519912907853723 seconds)
2022-03-14 15:39:17 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-14 15:39:17 | INFO | train | epoch 116 | loss 4.383 | ppl 20.86 | wps 40215.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11925 | lr 0.000289581 | gnorm 0.958 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19456
KL Stats: Epoch 116 Divergences: Uniform: 4.991095529088382 Unigram: 4.929883691746332
2022-03-14 15:39:17 | INFO | fairseq.trainer | begin training epoch 117
2022-03-14 15:39:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:41:15 | INFO | train_inner | epoch 117:     75 / 103 loss=4.374, ppl=20.74, wps=40194.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12000, lr=0.000288675, gnorm=0.954, loss_scale=16, train_wall=153, gb_free=20.8, wall=19575
2022-03-14 15:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:42:03 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 8.901 | ppl 477.94 | wps 66226.2 | wpb 2040.3 | bsz 4 | num_updates 12028 | best_loss 7.59
2022-03-14 15:42:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 12028 updates
2022-03-14 15:42:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:42:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:42:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 117 @ 12028 updates, score 8.901) (writing took 0.9564192723482847 seconds)
2022-03-14 15:42:04 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-14 15:42:04 | INFO | train | epoch 117 | loss 4.375 | ppl 20.76 | wps 40233.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12028 | lr 0.000288339 | gnorm 0.954 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19623
KL Stats: Epoch 117 Divergences: Uniform: 4.994848951428811 Unigram: 4.935159387970812
2022-03-14 15:42:04 | INFO | fairseq.trainer | begin training epoch 118
2022-03-14 15:42:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:43:58 | INFO | train_inner | epoch 118:     72 / 103 loss=4.367, ppl=20.63, wps=40198.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=12100, lr=0.00028748, gnorm=0.96, loss_scale=16, train_wall=153, gb_free=20.8, wall=19738
2022-03-14 15:44:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:44:50 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 8.92 | ppl 484.44 | wps 65986 | wpb 2040.3 | bsz 4 | num_updates 12131 | best_loss 7.59
2022-03-14 15:44:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 12131 updates
2022-03-14 15:44:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:44:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:44:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 118 @ 12131 updates, score 8.92) (writing took 0.9446092629805207 seconds)
2022-03-14 15:44:51 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-14 15:44:51 | INFO | train | epoch 118 | loss 4.368 | ppl 20.64 | wps 40221.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12131 | lr 0.000287112 | gnorm 0.965 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19791
KL Stats: Epoch 118 Divergences: Uniform: 5.001998745776924 Unigram: 4.944719131697009
2022-03-14 15:44:51 | INFO | fairseq.trainer | begin training epoch 119
2022-03-14 15:44:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:46:40 | INFO | train_inner | epoch 119:     69 / 103 loss=4.363, ppl=20.58, wps=40195.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=12200, lr=0.000286299, gnorm=0.97, loss_scale=16, train_wall=153, gb_free=20.8, wall=19900
2022-03-14 15:47:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:47:37 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 8.948 | ppl 493.81 | wps 66290.5 | wpb 2040.3 | bsz 4 | num_updates 12234 | best_loss 7.59
2022-03-14 15:47:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 12234 updates
2022-03-14 15:47:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:47:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:47:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 119 @ 12234 updates, score 8.948) (writing took 0.9420549804344773 seconds)
2022-03-14 15:47:38 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-14 15:47:38 | INFO | train | epoch 119 | loss 4.359 | ppl 20.53 | wps 40226.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12234 | lr 0.000285901 | gnorm 0.956 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19958
KL Stats: Epoch 119 Divergences: Uniform: 5.00943390150726 Unigram: 4.954709147740568
2022-03-14 15:47:38 | INFO | fairseq.trainer | begin training epoch 120
2022-03-14 15:47:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:47:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 15:49:25 | INFO | train_inner | epoch 120:     67 / 103 loss=4.352, ppl=20.42, wps=39801.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=12300, lr=0.000285133, gnorm=0.948, loss_scale=16, train_wall=155, gb_free=20.8, wall=20064
2022-03-14 15:50:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:50:25 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 8.963 | ppl 499.06 | wps 66154.5 | wpb 2040.3 | bsz 4 | num_updates 12336 | best_loss 7.59
2022-03-14 15:50:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 12336 updates
2022-03-14 15:50:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:50:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:50:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 120 @ 12336 updates, score 8.963) (writing took 0.9513522107154131 seconds)
2022-03-14 15:50:26 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-14 15:50:26 | INFO | train | epoch 120 | loss 4.351 | ppl 20.4 | wps 39835.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 12336 | lr 0.000284717 | gnorm 0.965 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20125
KL Stats: Epoch 120 Divergences: Uniform: 5.0168765240269755 Unigram: 4.966736513904545
2022-03-14 15:50:26 | INFO | fairseq.trainer | begin training epoch 121
2022-03-14 15:50:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:52:07 | INFO | train_inner | epoch 121:     64 / 103 loss=4.347, ppl=20.36, wps=40183.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12400, lr=0.000283981, gnorm=0.977, loss_scale=16, train_wall=153, gb_free=20.8, wall=20227
2022-03-14 15:53:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:53:12 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 8.961 | ppl 498.27 | wps 65985.8 | wpb 2040.3 | bsz 4 | num_updates 12439 | best_loss 7.59
2022-03-14 15:53:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 12439 updates
2022-03-14 15:53:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:53:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:53:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 121 @ 12439 updates, score 8.961) (writing took 0.9503099340945482 seconds)
2022-03-14 15:53:13 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-14 15:53:13 | INFO | train | epoch 121 | loss 4.343 | ppl 20.3 | wps 40213.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12439 | lr 0.000283535 | gnorm 0.979 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20292
KL Stats: Epoch 121 Divergences: Uniform: 5.022121648027337 Unigram: 4.973137521480716
2022-03-14 15:53:13 | INFO | fairseq.trainer | begin training epoch 122
2022-03-14 15:53:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:54:50 | INFO | train_inner | epoch 122:     61 / 103 loss=4.34, ppl=20.25, wps=40191.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12500, lr=0.000282843, gnorm=0.97, loss_scale=16, train_wall=153, gb_free=20.8, wall=20389
2022-03-14 15:55:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:55:59 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 8.958 | ppl 497.15 | wps 65927.6 | wpb 2040.3 | bsz 4 | num_updates 12542 | best_loss 7.59
2022-03-14 15:55:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 12542 updates
2022-03-14 15:55:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:56:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:56:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 122 @ 12542 updates, score 8.958) (writing took 0.9381632339209318 seconds)
2022-03-14 15:56:00 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-14 15:56:00 | INFO | train | epoch 122 | loss 4.335 | ppl 20.18 | wps 40209.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12542 | lr 0.000282369 | gnorm 0.972 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20460
KL Stats: Epoch 122 Divergences: Uniform: 5.028343110191511 Unigram: 4.982031627681686
2022-03-14 15:56:00 | INFO | fairseq.trainer | begin training epoch 123
2022-03-14 15:56:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:57:32 | INFO | train_inner | epoch 123:     58 / 103 loss=4.327, ppl=20.07, wps=40170.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=12600, lr=0.000281718, gnorm=0.989, loss_scale=16, train_wall=153, gb_free=20.8, wall=20552
2022-03-14 15:58:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:58:46 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 8.984 | ppl 506.19 | wps 65901.1 | wpb 2040.3 | bsz 4 | num_updates 12645 | best_loss 7.59
2022-03-14 15:58:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 12645 updates
2022-03-14 15:58:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:58:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 15:58:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 123 @ 12645 updates, score 8.984) (writing took 0.926080284640193 seconds)
2022-03-14 15:58:47 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-14 15:58:47 | INFO | train | epoch 123 | loss 4.328 | ppl 20.08 | wps 40217.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12645 | lr 0.000281216 | gnorm 0.977 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20627
KL Stats: Epoch 123 Divergences: Uniform: 5.033558640685227 Unigram: 4.990151065322747
2022-03-14 15:58:47 | INFO | fairseq.trainer | begin training epoch 124
2022-03-14 15:58:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:00:15 | INFO | train_inner | epoch 124:     55 / 103 loss=4.323, ppl=20.01, wps=40196.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=12700, lr=0.000280607, gnorm=0.974, loss_scale=16, train_wall=153, gb_free=20.8, wall=20714
2022-03-14 16:01:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:01:34 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 8.973 | ppl 502.65 | wps 66289 | wpb 2040.3 | bsz 4 | num_updates 12748 | best_loss 7.59
2022-03-14 16:01:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 12748 updates
2022-03-14 16:01:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:01:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:01:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 124 @ 12748 updates, score 8.973) (writing took 0.9381589172407985 seconds)
2022-03-14 16:01:35 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-14 16:01:35 | INFO | train | epoch 124 | loss 4.32 | ppl 19.97 | wps 40235.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12748 | lr 0.000280078 | gnorm 0.98 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20794
KL Stats: Epoch 124 Divergences: Uniform: 5.039262423527596 Unigram: 4.99864777063087
2022-03-14 16:01:35 | INFO | fairseq.trainer | begin training epoch 125
2022-03-14 16:01:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:01:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 16:02:59 | INFO | train_inner | epoch 125:     53 / 103 loss=4.317, ppl=19.94, wps=39810.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=12800, lr=0.000279508, gnorm=0.971, loss_scale=16, train_wall=155, gb_free=20.8, wall=20878
2022-03-14 16:04:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:04:21 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 8.998 | ppl 511.23 | wps 66116.7 | wpb 2040.3 | bsz 4 | num_updates 12850 | best_loss 7.59
2022-03-14 16:04:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 12850 updates
2022-03-14 16:04:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:04:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:04:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 125 @ 12850 updates, score 8.998) (writing took 0.9410999361425638 seconds)
2022-03-14 16:04:22 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-14 16:04:22 | INFO | train | epoch 125 | loss 4.312 | ppl 19.86 | wps 39827.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 12850 | lr 0.000278964 | gnorm 0.973 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20961
KL Stats: Epoch 125 Divergences: Uniform: 5.046863785014516 Unigram: 5.009896078036085
2022-03-14 16:04:22 | INFO | fairseq.trainer | begin training epoch 126
2022-03-14 16:04:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:05:41 | INFO | train_inner | epoch 126:     50 / 103 loss=4.309, ppl=19.83, wps=40193.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12900, lr=0.000278423, gnorm=0.98, loss_scale=16, train_wall=153, gb_free=20.8, wall=21041
2022-03-14 16:07:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:07:08 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 9.017 | ppl 518.21 | wps 66287.2 | wpb 2040.3 | bsz 4 | num_updates 12953 | best_loss 7.59
2022-03-14 16:07:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 12953 updates
2022-03-14 16:07:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:07:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:07:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 126 @ 12953 updates, score 9.017) (writing took 0.9387662373483181 seconds)
2022-03-14 16:07:09 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-14 16:07:09 | INFO | train | epoch 126 | loss 4.305 | ppl 19.77 | wps 40251.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12953 | lr 0.000277853 | gnorm 0.974 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21129
KL Stats: Epoch 126 Divergences: Uniform: 5.052823912286285 Unigram: 5.016945633181495
2022-03-14 16:07:09 | INFO | fairseq.trainer | begin training epoch 127
2022-03-14 16:07:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:08:24 | INFO | train_inner | epoch 127:     47 / 103 loss=4.297, ppl=19.66, wps=40202.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13000, lr=0.00027735, gnorm=0.979, loss_scale=16, train_wall=153, gb_free=20.8, wall=21203
2022-03-14 16:09:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:09:55 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 9.016 | ppl 517.83 | wps 66092.2 | wpb 2040.3 | bsz 4 | num_updates 13056 | best_loss 7.59
2022-03-14 16:09:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 13056 updates
2022-03-14 16:09:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:09:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:09:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 127 @ 13056 updates, score 9.016) (writing took 0.9440368292853236 seconds)
2022-03-14 16:09:56 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-14 16:09:56 | INFO | train | epoch 127 | loss 4.298 | ppl 19.68 | wps 40221 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13056 | lr 0.000276755 | gnorm 0.988 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21296
KL Stats: Epoch 127 Divergences: Uniform: 5.057262548886489 Unigram: 5.023660168888026
2022-03-14 16:09:56 | INFO | fairseq.trainer | begin training epoch 128
2022-03-14 16:09:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:11:06 | INFO | train_inner | epoch 128:     44 / 103 loss=4.3, ppl=19.69, wps=40199.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=13100, lr=0.000276289, gnorm=0.982, loss_scale=16, train_wall=153, gb_free=20.8, wall=21366
2022-03-14 16:12:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:12:42 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 9.035 | ppl 524.7 | wps 66111.6 | wpb 2040.3 | bsz 4 | num_updates 13159 | best_loss 7.59
2022-03-14 16:12:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 13159 updates
2022-03-14 16:12:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:12:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:12:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 128 @ 13159 updates, score 9.035) (writing took 1.177854334935546 seconds)
2022-03-14 16:12:44 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-14 16:12:44 | INFO | train | epoch 128 | loss 4.29 | ppl 19.56 | wps 40181.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13159 | lr 0.000275669 | gnorm 0.975 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21463
KL Stats: Epoch 128 Divergences: Uniform: 5.061534756586454 Unigram: 5.033110349079229
2022-03-14 16:12:44 | INFO | fairseq.trainer | begin training epoch 129
2022-03-14 16:12:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:13:49 | INFO | train_inner | epoch 129:     41 / 103 loss=4.286, ppl=19.51, wps=40145.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=13200, lr=0.000275241, gnorm=0.974, loss_scale=16, train_wall=153, gb_free=20.8, wall=21528
2022-03-14 16:15:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:15:30 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 9.025 | ppl 521.01 | wps 66302.7 | wpb 2040.3 | bsz 4 | num_updates 13262 | best_loss 7.59
2022-03-14 16:15:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 13262 updates
2022-03-14 16:15:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:15:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:15:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 129 @ 13262 updates, score 9.025) (writing took 0.9286958873271942 seconds)
2022-03-14 16:15:31 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-14 16:15:31 | INFO | train | epoch 129 | loss 4.284 | ppl 19.48 | wps 40211.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13262 | lr 0.000274597 | gnorm 0.972 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21631
KL Stats: Epoch 129 Divergences: Uniform: 5.068028506622371 Unigram: 5.037372400410783
2022-03-14 16:15:31 | INFO | fairseq.trainer | begin training epoch 130
2022-03-14 16:15:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:15:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 16:16:33 | INFO | train_inner | epoch 130:     39 / 103 loss=4.279, ppl=19.41, wps=39768.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13300, lr=0.000274204, gnorm=0.97, loss_scale=16, train_wall=155, gb_free=20.8, wall=21692
2022-03-14 16:18:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:18:17 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 9.046 | ppl 528.62 | wps 66214.9 | wpb 2040.3 | bsz 4 | num_updates 13364 | best_loss 7.59
2022-03-14 16:18:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 13364 updates
2022-03-14 16:18:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:18:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:18:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 130 @ 13364 updates, score 9.046) (writing took 0.9014281583949924 seconds)
2022-03-14 16:18:18 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-14 16:18:18 | INFO | train | epoch 130 | loss 4.276 | ppl 19.38 | wps 39805.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 13364 | lr 0.000273547 | gnorm 0.978 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21798
KL Stats: Epoch 130 Divergences: Uniform: 5.0748216680938505 Unigram: 5.047429033218389
2022-03-14 16:18:18 | INFO | fairseq.trainer | begin training epoch 131
2022-03-14 16:18:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:19:15 | INFO | train_inner | epoch 131:     36 / 103 loss=4.276, ppl=19.37, wps=40172.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13400, lr=0.000273179, gnorm=0.976, loss_scale=16, train_wall=153, gb_free=20.8, wall=21855
2022-03-14 16:21:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:21:05 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 9.039 | ppl 526.11 | wps 66465.5 | wpb 2040.3 | bsz 4 | num_updates 13467 | best_loss 7.59
2022-03-14 16:21:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 13467 updates
2022-03-14 16:21:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:21:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:21:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 131 @ 13467 updates, score 9.039) (writing took 1.3802784364670515 seconds)
2022-03-14 16:21:06 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-14 16:21:06 | INFO | train | epoch 131 | loss 4.271 | ppl 19.3 | wps 40116.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 13467 | lr 0.000272499 | gnorm 0.986 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21966
KL Stats: Epoch 131 Divergences: Uniform: 5.07874427871171 Unigram: 5.055364625460087
2022-03-14 16:21:06 | INFO | fairseq.trainer | begin training epoch 132
2022-03-14 16:21:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:21:58 | INFO | train_inner | epoch 132:     33 / 103 loss=4.269, ppl=19.28, wps=40094.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13500, lr=0.000272166, gnorm=0.992, loss_scale=16, train_wall=153, gb_free=20.8, wall=22018
2022-03-14 16:23:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:23:52 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 9.05 | ppl 530.15 | wps 65926 | wpb 2040.3 | bsz 4 | num_updates 13570 | best_loss 7.59
2022-03-14 16:23:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 13570 updates
2022-03-14 16:23:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:23:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:23:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 132 @ 13570 updates, score 9.05) (writing took 0.8896545702591538 seconds)
2022-03-14 16:23:53 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-14 16:23:53 | INFO | train | epoch 132 | loss 4.264 | ppl 19.21 | wps 40232.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13570 | lr 0.000271463 | gnorm 0.991 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22133
KL Stats: Epoch 132 Divergences: Uniform: 5.0828030259699535 Unigram: 5.061980452683096
2022-03-14 16:23:53 | INFO | fairseq.trainer | begin training epoch 133
2022-03-14 16:23:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:24:41 | INFO | train_inner | epoch 133:     30 / 103 loss=4.264, ppl=19.21, wps=40193.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=13600, lr=0.000271163, gnorm=0.994, loss_scale=16, train_wall=153, gb_free=20.8, wall=22180
2022-03-14 16:26:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:26:39 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 9.063 | ppl 534.83 | wps 66538.6 | wpb 2040.3 | bsz 4 | num_updates 13673 | best_loss 7.59
2022-03-14 16:26:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 13673 updates
2022-03-14 16:26:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:26:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:26:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 133 @ 13673 updates, score 9.063) (writing took 0.8393286969512701 seconds)
2022-03-14 16:26:40 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-14 16:26:40 | INFO | train | epoch 133 | loss 4.255 | ppl 19.1 | wps 40261.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13673 | lr 0.000270438 | gnorm 0.987 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22300
KL Stats: Epoch 133 Divergences: Uniform: 5.089374229091631 Unigram: 5.07174676458114
2022-03-14 16:26:40 | INFO | fairseq.trainer | begin training epoch 134
2022-03-14 16:26:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:27:23 | INFO | train_inner | epoch 134:     27 / 103 loss=4.255, ppl=19.09, wps=40217.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13700, lr=0.000270172, gnorm=0.984, loss_scale=16, train_wall=153, gb_free=20.8, wall=22343
2022-03-14 16:29:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:29:27 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 9.083 | ppl 542.44 | wps 66063.8 | wpb 2040.3 | bsz 4 | num_updates 13776 | best_loss 7.59
2022-03-14 16:29:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 13776 updates
2022-03-14 16:29:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:29:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:29:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 134 @ 13776 updates, score 9.083) (writing took 0.9116757027804852 seconds)
2022-03-14 16:29:28 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-14 16:29:28 | INFO | train | epoch 134 | loss 4.25 | ppl 19.02 | wps 40155.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 13776 | lr 0.000269425 | gnorm 0.99 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22467
KL Stats: Epoch 134 Divergences: Uniform: 5.094865423653572 Unigram: 5.07955349981456
2022-03-14 16:29:28 | INFO | fairseq.trainer | begin training epoch 135
2022-03-14 16:29:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:29:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 16:30:08 | INFO | train_inner | epoch 135:     25 / 103 loss=4.249, ppl=19.01, wps=39702.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13800, lr=0.000269191, gnorm=0.988, loss_scale=16, train_wall=155, gb_free=20.8, wall=22507
2022-03-14 16:32:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:32:15 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 9.081 | ppl 541.5 | wps 65845 | wpb 2040.3 | bsz 4 | num_updates 13878 | best_loss 7.59
2022-03-14 16:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 13878 updates
2022-03-14 16:32:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:32:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:32:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 135 @ 13878 updates, score 9.081) (writing took 0.8937097694724798 seconds)
2022-03-14 16:32:16 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-14 16:32:16 | INFO | train | epoch 135 | loss 4.243 | ppl 18.94 | wps 39676.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 13878 | lr 0.000268433 | gnorm 0.992 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22635
KL Stats: Epoch 135 Divergences: Uniform: 5.09880338334213 Unigram: 5.0860581646688106
2022-03-14 16:32:16 | INFO | fairseq.trainer | begin training epoch 136
2022-03-14 16:32:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:32:51 | INFO | train_inner | epoch 136:     22 / 103 loss=4.243, ppl=18.94, wps=40056, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13900, lr=0.000268221, gnorm=0.997, loss_scale=16, train_wall=154, gb_free=20.8, wall=22670
2022-03-14 16:34:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:35:02 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 9.083 | ppl 542.43 | wps 66349.9 | wpb 2040.3 | bsz 4 | num_updates 13981 | best_loss 7.59
2022-03-14 16:35:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 13981 updates
2022-03-14 16:35:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:35:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:35:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 136 @ 13981 updates, score 9.083) (writing took 0.9072256917133927 seconds)
2022-03-14 16:35:03 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-14 16:35:03 | INFO | train | epoch 136 | loss 4.238 | ppl 18.86 | wps 40168.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13981 | lr 0.000267443 | gnorm 0.991 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22803
KL Stats: Epoch 136 Divergences: Uniform: 5.103491367790443 Unigram: 5.092212570796516
2022-03-14 16:35:03 | INFO | fairseq.trainer | begin training epoch 137
2022-03-14 16:35:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:35:33 | INFO | train_inner | epoch 137:     19 / 103 loss=4.239, ppl=18.88, wps=40143.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14000, lr=0.000267261, gnorm=0.991, loss_scale=16, train_wall=153, gb_free=20.8, wall=22833
2022-03-14 16:37:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:37:50 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 9.077 | ppl 540.04 | wps 66113.2 | wpb 2040.3 | bsz 4 | num_updates 14084 | best_loss 7.59
2022-03-14 16:37:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 14084 updates
2022-03-14 16:37:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:37:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:37:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 137 @ 14084 updates, score 9.077) (writing took 0.9162619030103087 seconds)
2022-03-14 16:37:50 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-14 16:37:50 | INFO | train | epoch 137 | loss 4.231 | ppl 18.77 | wps 40208.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14084 | lr 0.000266463 | gnorm 0.989 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22970
KL Stats: Epoch 137 Divergences: Uniform: 5.107913178545274 Unigram: 5.097898751385469
2022-03-14 16:37:51 | INFO | fairseq.trainer | begin training epoch 138
2022-03-14 16:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:38:16 | INFO | train_inner | epoch 138:     16 / 103 loss=4.231, ppl=18.78, wps=40177.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14100, lr=0.000266312, gnorm=0.992, loss_scale=16, train_wall=153, gb_free=20.8, wall=22996
2022-03-14 16:40:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:40:37 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 9.116 | ppl 554.75 | wps 66126.9 | wpb 2040.3 | bsz 4 | num_updates 14187 | best_loss 7.59
2022-03-14 16:40:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 14187 updates
2022-03-14 16:40:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:40:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:40:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 138 @ 14187 updates, score 9.116) (writing took 0.9304486708715558 seconds)
2022-03-14 16:40:38 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-14 16:40:38 | INFO | train | epoch 138 | loss 4.224 | ppl 18.68 | wps 40223.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14187 | lr 0.000265494 | gnorm 0.994 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23137
KL Stats: Epoch 138 Divergences: Uniform: 5.114887906979796 Unigram: 5.108119114675518
2022-03-14 16:40:38 | INFO | fairseq.trainer | begin training epoch 139
2022-03-14 16:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:40:58 | INFO | train_inner | epoch 139:     13 / 103 loss=4.226, ppl=18.71, wps=40188.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14200, lr=0.000265372, gnorm=0.99, loss_scale=16, train_wall=153, gb_free=20.8, wall=23158
2022-03-14 16:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:43:24 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 9.107 | ppl 551.38 | wps 65809 | wpb 2040.3 | bsz 4 | num_updates 14290 | best_loss 7.59
2022-03-14 16:43:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 14290 updates
2022-03-14 16:43:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:43:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:43:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 139 @ 14290 updates, score 9.107) (writing took 0.952113532461226 seconds)
2022-03-14 16:43:25 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-14 16:43:25 | INFO | train | epoch 139 | loss 4.219 | ppl 18.63 | wps 40188.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14290 | lr 0.000264535 | gnorm 1 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23305
KL Stats: Epoch 139 Divergences: Uniform: 5.116365600886175 Unigram: 5.112132698106783
2022-03-14 16:43:25 | INFO | fairseq.trainer | begin training epoch 140
2022-03-14 16:43:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:43:41 | INFO | train_inner | epoch 140:     10 / 103 loss=4.222, ppl=18.66, wps=40162.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14300, lr=0.000264443, gnorm=1.006, loss_scale=16, train_wall=153, gb_free=20.8, wall=23321
2022-03-14 16:43:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 16:46:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:46:11 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 9.096 | ppl 547.15 | wps 66468.2 | wpb 2040.3 | bsz 4 | num_updates 14392 | best_loss 7.59
2022-03-14 16:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 14392 updates
2022-03-14 16:46:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:46:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 140 @ 14392 updates, score 9.096) (writing took 0.9577215909957886 seconds)
2022-03-14 16:46:12 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-14 16:46:12 | INFO | train | epoch 140 | loss 4.212 | ppl 18.53 | wps 39821.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 14392 | lr 0.000263596 | gnorm 0.993 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23472
KL Stats: Epoch 140 Divergences: Uniform: 5.1228228811395216 Unigram: 5.12075826835001
2022-03-14 16:46:12 | INFO | fairseq.trainer | begin training epoch 141
2022-03-14 16:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:46:25 | INFO | train_inner | epoch 141:      8 / 103 loss=4.21, ppl=18.51, wps=39785.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14400, lr=0.000263523, gnorm=0.99, loss_scale=16, train_wall=155, gb_free=20.8, wall=23485
2022-03-14 16:48:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:48:59 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 9.12 | ppl 556.25 | wps 66331.4 | wpb 2040.3 | bsz 4 | num_updates 14495 | best_loss 7.59
2022-03-14 16:48:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 14495 updates
2022-03-14 16:48:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:49:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:49:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 141 @ 14495 updates, score 9.12) (writing took 0.9478492476046085 seconds)
2022-03-14 16:49:00 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-14 16:49:00 | INFO | train | epoch 141 | loss 4.206 | ppl 18.46 | wps 40205.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14495 | lr 0.000262658 | gnorm 0.992 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23639
KL Stats: Epoch 141 Divergences: Uniform: 5.127594776230728 Unigram: 5.127069027961374
2022-03-14 16:49:00 | INFO | fairseq.trainer | begin training epoch 142
2022-03-14 16:49:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:49:08 | INFO | train_inner | epoch 142:      5 / 103 loss=4.209, ppl=18.49, wps=40173.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14500, lr=0.000262613, gnorm=0.993, loss_scale=16, train_wall=153, gb_free=20.8, wall=23647
2022-03-14 16:51:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:51:46 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 9.134 | ppl 562.01 | wps 66449.7 | wpb 2040.3 | bsz 4 | num_updates 14598 | best_loss 7.59
2022-03-14 16:51:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 14598 updates
2022-03-14 16:51:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:51:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:51:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 142 @ 14598 updates, score 9.134) (writing took 0.906676490791142 seconds)
2022-03-14 16:51:47 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-14 16:51:47 | INFO | train | epoch 142 | loss 4.2 | ppl 18.38 | wps 40212.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14598 | lr 0.00026173 | gnorm 0.988 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23807
KL Stats: Epoch 142 Divergences: Uniform: 5.1317237477304305 Unigram: 5.134864130262155
2022-03-14 16:51:47 | INFO | fairseq.trainer | begin training epoch 143
2022-03-14 16:51:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:51:50 | INFO | train_inner | epoch 143:      2 / 103 loss=4.202, ppl=18.4, wps=40177, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14600, lr=0.000261712, gnorm=0.989, loss_scale=16, train_wall=153, gb_free=20.8, wall=23810
2022-03-14 16:54:29 | INFO | train_inner | epoch 143:    102 / 103 loss=4.197, ppl=18.34, wps=41348.5, ups=0.63, wpb=65530.9, bsz=128, num_updates=14700, lr=0.00026082, gnorm=0.989, loss_scale=16, train_wall=154, gb_free=20.8, wall=23968
2022-03-14 16:54:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:54:33 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 9.135 | ppl 562.19 | wps 66110.7 | wpb 2040.3 | bsz 4 | num_updates 14701 | best_loss 7.59
2022-03-14 16:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 14701 updates
2022-03-14 16:54:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:54:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:54:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 143 @ 14701 updates, score 9.135) (writing took 0.9339961837977171 seconds)
2022-03-14 16:54:34 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-14 16:54:34 | INFO | train | epoch 143 | loss 4.195 | ppl 18.31 | wps 40211.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14701 | lr 0.000260811 | gnorm 0.991 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23974
KL Stats: Epoch 143 Divergences: Uniform: 5.1340489467832695 Unigram: 5.138944156347894
2022-03-14 16:54:34 | INFO | fairseq.trainer | begin training epoch 144
2022-03-14 16:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:57:11 | INFO | train_inner | epoch 144:     99 / 103 loss=4.186, ppl=18.21, wps=40172.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14800, lr=0.000259938, gnorm=0.987, loss_scale=16, train_wall=153, gb_free=20.8, wall=24131
2022-03-14 16:57:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:57:21 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 9.14 | ppl 564.26 | wps 66192.3 | wpb 2040.3 | bsz 4 | num_updates 14804 | best_loss 7.59
2022-03-14 16:57:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 14804 updates
2022-03-14 16:57:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:57:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 16:57:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 144 @ 14804 updates, score 9.14) (writing took 1.0202805325388908 seconds)
2022-03-14 16:57:22 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-14 16:57:22 | INFO | train | epoch 144 | loss 4.189 | ppl 18.24 | wps 40185.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14804 | lr 0.000259903 | gnorm 0.987 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24141
KL Stats: Epoch 144 Divergences: Uniform: 5.140706787446089 Unigram: 5.148830889287614
2022-03-14 16:57:22 | INFO | fairseq.trainer | begin training epoch 145
2022-03-14 16:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:57:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 16:59:55 | INFO | train_inner | epoch 145:     97 / 103 loss=4.184, ppl=18.18, wps=39796.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14900, lr=0.000259064, gnorm=1.005, loss_scale=16, train_wall=154, gb_free=20.8, wall=24295
2022-03-14 17:00:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:00:08 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 9.19 | ppl 584.15 | wps 66496.3 | wpb 2040.3 | bsz 4 | num_updates 14906 | best_loss 7.59
2022-03-14 17:00:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 14906 updates
2022-03-14 17:00:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:00:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:00:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 145 @ 14906 updates, score 9.19) (writing took 0.8811831614002585 seconds)
2022-03-14 17:00:09 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-14 17:00:09 | INFO | train | epoch 145 | loss 4.183 | ppl 18.17 | wps 39860.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 14906 | lr 0.000259012 | gnorm 1.007 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24308
KL Stats: Epoch 145 Divergences: Uniform: 5.143913845526642 Unigram: 5.154775645742525
2022-03-14 17:00:09 | INFO | fairseq.trainer | begin training epoch 146
2022-03-14 17:00:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:02:38 | INFO | train_inner | epoch 146:     94 / 103 loss=4.175, ppl=18.06, wps=40219.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15000, lr=0.000258199, gnorm=1.006, loss_scale=16, train_wall=153, gb_free=20.8, wall=24457
2022-03-14 17:02:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:02:55 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 9.177 | ppl 578.77 | wps 66280.6 | wpb 2040.3 | bsz 4 | num_updates 15009 | best_loss 7.59
2022-03-14 17:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 15009 updates
2022-03-14 17:02:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:02:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:02:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 146 @ 15009 updates, score 9.177) (writing took 0.909725982695818 seconds)
2022-03-14 17:02:56 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-14 17:02:56 | INFO | train | epoch 146 | loss 4.178 | ppl 18.1 | wps 40246.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15009 | lr 0.000258121 | gnorm 1.007 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24476
KL Stats: Epoch 146 Divergences: Uniform: 5.146901764611893 Unigram: 5.161301183612875
2022-03-14 17:02:56 | INFO | fairseq.trainer | begin training epoch 147
2022-03-14 17:02:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:05:20 | INFO | train_inner | epoch 147:     91 / 103 loss=4.169, ppl=17.99, wps=40199.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=15100, lr=0.000257343, gnorm=1, loss_scale=16, train_wall=153, gb_free=20.8, wall=24620
2022-03-14 17:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:05:42 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 9.159 | ppl 571.74 | wps 66323.2 | wpb 2040.3 | bsz 4 | num_updates 15112 | best_loss 7.59
2022-03-14 17:05:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 15112 updates
2022-03-14 17:05:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:05:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:05:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 147 @ 15112 updates, score 9.159) (writing took 0.873512695543468 seconds)
2022-03-14 17:05:43 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-14 17:05:43 | INFO | train | epoch 147 | loss 4.171 | ppl 18.02 | wps 40236 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15112 | lr 0.00025724 | gnorm 0.997 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24643
KL Stats: Epoch 147 Divergences: Uniform: 5.151155623884576 Unigram: 5.165327368312217
2022-03-14 17:05:43 | INFO | fairseq.trainer | begin training epoch 148
2022-03-14 17:05:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:08:03 | INFO | train_inner | epoch 148:     88 / 103 loss=4.165, ppl=17.94, wps=40210, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=15200, lr=0.000256495, gnorm=1.006, loss_scale=16, train_wall=153, gb_free=20.8, wall=24782
2022-03-14 17:08:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:08:29 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 9.18 | ppl 579.85 | wps 66197 | wpb 2040.3 | bsz 4 | num_updates 15215 | best_loss 7.59
2022-03-14 17:08:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 15215 updates
2022-03-14 17:08:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:08:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:08:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 148 @ 15215 updates, score 9.18) (writing took 0.8560517523437738 seconds)
2022-03-14 17:08:30 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-14 17:08:30 | INFO | train | epoch 148 | loss 4.167 | ppl 17.97 | wps 40252.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15215 | lr 0.000256368 | gnorm 1.009 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24810
KL Stats: Epoch 148 Divergences: Uniform: 5.154815914579155 Unigram: 5.172349891578419
2022-03-14 17:08:30 | INFO | fairseq.trainer | begin training epoch 149
2022-03-14 17:08:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:10:45 | INFO | train_inner | epoch 149:     85 / 103 loss=4.161, ppl=17.89, wps=40215.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=15300, lr=0.000255655, gnorm=1.006, loss_scale=16, train_wall=153, gb_free=20.8, wall=24945
2022-03-14 17:11:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:11:17 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 9.172 | ppl 576.75 | wps 66112.6 | wpb 2040.3 | bsz 4 | num_updates 15318 | best_loss 7.59
2022-03-14 17:11:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 15318 updates
2022-03-14 17:11:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:11:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:11:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 149 @ 15318 updates, score 9.172) (writing took 0.8972179321572185 seconds)
2022-03-14 17:11:18 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-14 17:11:18 | INFO | train | epoch 149 | loss 4.161 | ppl 17.89 | wps 40232.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15318 | lr 0.000255505 | gnorm 1.006 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24977
KL Stats: Epoch 149 Divergences: Uniform: 5.159026624280418 Unigram: 5.1785823387098295
2022-03-14 17:11:18 | INFO | fairseq.trainer | begin training epoch 150
2022-03-14 17:11:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:11:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 17:13:29 | INFO | train_inner | epoch 150:     83 / 103 loss=4.153, ppl=17.79, wps=39797.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=15400, lr=0.000254824, gnorm=1.008, loss_scale=16, train_wall=155, gb_free=20.8, wall=25109
2022-03-14 17:14:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:14:04 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 9.202 | ppl 588.93 | wps 66425.1 | wpb 2040.3 | bsz 4 | num_updates 15420 | best_loss 7.59
2022-03-14 17:14:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 15420 updates
2022-03-14 17:14:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:14:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:14:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 150 @ 15420 updates, score 9.202) (writing took 0.922127977013588 seconds)
2022-03-14 17:14:05 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-14 17:14:05 | INFO | train | epoch 150 | loss 4.155 | ppl 17.81 | wps 39833.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 15420 | lr 0.000254658 | gnorm 1.005 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25144
KL Stats: Epoch 150 Divergences: Uniform: 5.16317951690629 Unigram: 5.185903383432482
2022-03-14 17:14:05 | INFO | fairseq.trainer | begin training epoch 151
2022-03-14 17:14:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:16:12 | INFO | train_inner | epoch 151:     80 / 103 loss=4.155, ppl=17.82, wps=40207.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15500, lr=0.000254, gnorm=1.01, loss_scale=16, train_wall=153, gb_free=20.8, wall=25271
2022-03-14 17:16:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:16:51 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 9.198 | ppl 587.3 | wps 66111.3 | wpb 2040.3 | bsz 4 | num_updates 15523 | best_loss 7.59
2022-03-14 17:16:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 15523 updates
2022-03-14 17:16:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:16:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:16:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 151 @ 15523 updates, score 9.198) (writing took 0.890720060095191 seconds)
2022-03-14 17:16:52 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-14 17:16:52 | INFO | train | epoch 151 | loss 4.151 | ppl 17.76 | wps 40235.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15523 | lr 0.000253812 | gnorm 1.021 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25312
KL Stats: Epoch 151 Divergences: Uniform: 5.166988392584725 Unigram: 5.191722520391219
2022-03-14 17:16:52 | INFO | fairseq.trainer | begin training epoch 152
2022-03-14 17:16:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:18:54 | INFO | train_inner | epoch 152:     77 / 103 loss=4.141, ppl=17.65, wps=40193.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=15600, lr=0.000253185, gnorm=1.02, loss_scale=16, train_wall=153, gb_free=20.8, wall=25434
2022-03-14 17:19:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:19:38 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 9.206 | ppl 590.67 | wps 66005.1 | wpb 2040.3 | bsz 4 | num_updates 15626 | best_loss 7.59
2022-03-14 17:19:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 15626 updates
2022-03-14 17:19:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:19:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:19:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 152 @ 15626 updates, score 9.206) (writing took 0.9563972493633628 seconds)
2022-03-14 17:19:39 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-14 17:19:39 | INFO | train | epoch 152 | loss 4.144 | ppl 17.68 | wps 40207 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15626 | lr 0.000252974 | gnorm 1.005 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25479
KL Stats: Epoch 152 Divergences: Uniform: 5.172536964177998 Unigram: 5.198897438919163
2022-03-14 17:19:39 | INFO | fairseq.trainer | begin training epoch 153
2022-03-14 17:19:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:21:37 | INFO | train_inner | epoch 153:     74 / 103 loss=4.141, ppl=17.64, wps=40186, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=15700, lr=0.000252377, gnorm=1.01, loss_scale=16, train_wall=153, gb_free=20.8, wall=25596
2022-03-14 17:22:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:22:26 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 9.224 | ppl 598.05 | wps 66122.1 | wpb 2040.3 | bsz 4 | num_updates 15729 | best_loss 7.59
2022-03-14 17:22:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 15729 updates
2022-03-14 17:22:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:22:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:22:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 153 @ 15729 updates, score 9.224) (writing took 0.9137142477557063 seconds)
2022-03-14 17:22:27 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-14 17:22:27 | INFO | train | epoch 153 | loss 4.14 | ppl 17.63 | wps 40227 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15729 | lr 0.000252144 | gnorm 1.018 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25646
KL Stats: Epoch 153 Divergences: Uniform: 5.174382738630401 Unigram: 5.203432186669661
2022-03-14 17:22:27 | INFO | fairseq.trainer | begin training epoch 154
2022-03-14 17:22:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:24:19 | INFO | train_inner | epoch 154:     71 / 103 loss=4.132, ppl=17.53, wps=40179.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15800, lr=0.000251577, gnorm=1.011, loss_scale=16, train_wall=153, gb_free=20.8, wall=25759
2022-03-14 17:25:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:25:13 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 9.223 | ppl 597.72 | wps 66017.5 | wpb 2040.3 | bsz 4 | num_updates 15832 | best_loss 7.59
2022-03-14 17:25:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 15832 updates
2022-03-14 17:25:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:25:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:25:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 154 @ 15832 updates, score 9.223) (writing took 0.8744189385324717 seconds)
2022-03-14 17:25:14 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-14 17:25:14 | INFO | train | epoch 154 | loss 4.134 | ppl 17.55 | wps 40234 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15832 | lr 0.000251323 | gnorm 1.006 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25813
KL Stats: Epoch 154 Divergences: Uniform: 5.178168224490447 Unigram: 5.209939283656477
2022-03-14 17:25:14 | INFO | fairseq.trainer | begin training epoch 155
2022-03-14 17:25:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:25:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 17:27:03 | INFO | train_inner | epoch 155:     69 / 103 loss=4.13, ppl=17.51, wps=39831, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=15900, lr=0.000250785, gnorm=1.009, loss_scale=16, train_wall=155, gb_free=20.8, wall=25923
2022-03-14 17:27:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:28:00 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 9.215 | ppl 594.23 | wps 66120.2 | wpb 2040.3 | bsz 4 | num_updates 15934 | best_loss 7.59
2022-03-14 17:28:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 15934 updates
2022-03-14 17:28:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:28:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:28:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 155 @ 15934 updates, score 9.215) (writing took 0.8614481138065457 seconds)
2022-03-14 17:28:01 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-14 17:28:01 | INFO | train | epoch 155 | loss 4.129 | ppl 17.5 | wps 39862 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 15934 | lr 0.000250517 | gnorm 1.018 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25980
KL Stats: Epoch 155 Divergences: Uniform: 5.18091481655299 Unigram: 5.215869230976785
2022-03-14 17:28:01 | INFO | fairseq.trainer | begin training epoch 156
2022-03-14 17:28:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:29:45 | INFO | train_inner | epoch 156:     66 / 103 loss=4.127, ppl=17.47, wps=40220.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=16000, lr=0.00025, gnorm=1.018, loss_scale=16, train_wall=153, gb_free=20.8, wall=26085
2022-03-14 17:30:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:30:47 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 9.25 | ppl 608.92 | wps 66467.8 | wpb 2040.3 | bsz 4 | num_updates 16037 | best_loss 7.59
2022-03-14 17:30:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 16037 updates
2022-03-14 17:30:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:30:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:30:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 156 @ 16037 updates, score 9.25) (writing took 0.9041531682014465 seconds)
2022-03-14 17:30:48 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-14 17:30:48 | INFO | train | epoch 156 | loss 4.124 | ppl 17.44 | wps 40212.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16037 | lr 0.000249711 | gnorm 1.009 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26148
KL Stats: Epoch 156 Divergences: Uniform: 5.184799284828021 Unigram: 5.2215276138008235
2022-03-14 17:30:48 | INFO | fairseq.trainer | begin training epoch 157
2022-03-14 17:30:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:32:28 | INFO | train_inner | epoch 157:     63 / 103 loss=4.12, ppl=17.39, wps=40184.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16100, lr=0.000249222, gnorm=1.004, loss_scale=16, train_wall=153, gb_free=20.8, wall=26248
2022-03-14 17:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:33:34 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 9.232 | ppl 601.5 | wps 66451 | wpb 2040.3 | bsz 4 | num_updates 16140 | best_loss 7.59
2022-03-14 17:33:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 16140 updates
2022-03-14 17:33:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:33:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:33:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 157 @ 16140 updates, score 9.232) (writing took 0.8600676208734512 seconds)
2022-03-14 17:33:35 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-14 17:33:35 | INFO | train | epoch 157 | loss 4.119 | ppl 17.38 | wps 40242.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16140 | lr 0.000248913 | gnorm 1.012 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26315
KL Stats: Epoch 157 Divergences: Uniform: 5.189976321743358 Unigram: 5.227379507280176
2022-03-14 17:33:35 | INFO | fairseq.trainer | begin training epoch 158
2022-03-14 17:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:35:10 | INFO | train_inner | epoch 158:     60 / 103 loss=4.117, ppl=17.35, wps=40198.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16200, lr=0.000248452, gnorm=1.017, loss_scale=16, train_wall=153, gb_free=20.8, wall=26410
2022-03-14 17:36:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:36:22 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 9.24 | ppl 604.69 | wps 66253.3 | wpb 2040.3 | bsz 4 | num_updates 16243 | best_loss 7.59
2022-03-14 17:36:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 16243 updates
2022-03-14 17:36:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:36:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:36:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 158 @ 16243 updates, score 9.24) (writing took 0.8376084230840206 seconds)
2022-03-14 17:36:22 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-14 17:36:22 | INFO | train | epoch 158 | loss 4.115 | ppl 17.33 | wps 40237.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16243 | lr 0.000248123 | gnorm 1.019 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26482
KL Stats: Epoch 158 Divergences: Uniform: 5.192404929747166 Unigram: 5.233147057999403
2022-03-14 17:36:22 | INFO | fairseq.trainer | begin training epoch 159
2022-03-14 17:36:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:37:53 | INFO | train_inner | epoch 159:     57 / 103 loss=4.112, ppl=17.29, wps=40215.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=16300, lr=0.000247689, gnorm=1.018, loss_scale=16, train_wall=153, gb_free=20.8, wall=26572
2022-03-14 17:39:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:39:09 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 9.253 | ppl 610 | wps 66122.7 | wpb 2040.3 | bsz 4 | num_updates 16346 | best_loss 7.59
2022-03-14 17:39:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 16346 updates
2022-03-14 17:39:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:39:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:39:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 159 @ 16346 updates, score 9.253) (writing took 0.9131153132766485 seconds)
2022-03-14 17:39:10 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-14 17:39:10 | INFO | train | epoch 159 | loss 4.11 | ppl 17.27 | wps 40222.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16346 | lr 0.00024734 | gnorm 1.019 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26649
KL Stats: Epoch 159 Divergences: Uniform: 5.195324512087453 Unigram: 5.238393345559595
2022-03-14 17:39:10 | INFO | fairseq.trainer | begin training epoch 160
2022-03-14 17:39:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:39:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 17:40:37 | INFO | train_inner | epoch 160:     55 / 103 loss=4.107, ppl=17.23, wps=39796.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=16400, lr=0.000246932, gnorm=1.028, loss_scale=16, train_wall=155, gb_free=20.8, wall=26736
2022-03-14 17:41:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:41:56 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 9.27 | ppl 617.3 | wps 66337.2 | wpb 2040.3 | bsz 4 | num_updates 16448 | best_loss 7.59
2022-03-14 17:41:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 16448 updates
2022-03-14 17:41:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:41:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:41:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 160 @ 16448 updates, score 9.27) (writing took 0.8678021701052785 seconds)
2022-03-14 17:41:57 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-14 17:41:57 | INFO | train | epoch 160 | loss 4.103 | ppl 17.18 | wps 39851.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 16448 | lr 0.000246572 | gnorm 1.019 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26816
KL Stats: Epoch 160 Divergences: Uniform: 5.200247585216661 Unigram: 5.246244881318834
2022-03-14 17:41:57 | INFO | fairseq.trainer | begin training epoch 161
2022-03-14 17:41:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:43:19 | INFO | train_inner | epoch 161:     52 / 103 loss=4.098, ppl=17.13, wps=40224.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16500, lr=0.000246183, gnorm=1.012, loss_scale=16, train_wall=153, gb_free=20.8, wall=26899
2022-03-14 17:44:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:44:43 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 9.254 | ppl 610.57 | wps 66143 | wpb 2040.3 | bsz 4 | num_updates 16551 | best_loss 7.59
2022-03-14 17:44:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 16551 updates
2022-03-14 17:44:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:44:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:44:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 161 @ 16551 updates, score 9.254) (writing took 0.8432959765195847 seconds)
2022-03-14 17:44:44 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-14 17:44:44 | INFO | train | epoch 161 | loss 4.1 | ppl 17.15 | wps 40261 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16551 | lr 0.000245803 | gnorm 1.024 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26984
KL Stats: Epoch 161 Divergences: Uniform: 5.201818919348427 Unigram: 5.249408763451978
2022-03-14 17:44:44 | INFO | fairseq.trainer | begin training epoch 162
2022-03-14 17:44:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:46:02 | INFO | train_inner | epoch 162:     49 / 103 loss=4.098, ppl=17.13, wps=40210.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=16600, lr=0.00024544, gnorm=1.014, loss_scale=16, train_wall=153, gb_free=20.8, wall=27061
2022-03-14 17:47:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:47:30 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 9.246 | ppl 607.27 | wps 66150 | wpb 2040.3 | bsz 4 | num_updates 16654 | best_loss 7.59
2022-03-14 17:47:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 16654 updates
2022-03-14 17:47:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:47:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:47:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 162 @ 16654 updates, score 9.246) (writing took 0.9258638005703688 seconds)
2022-03-14 17:47:31 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-14 17:47:31 | INFO | train | epoch 162 | loss 4.095 | ppl 17.09 | wps 40234.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16654 | lr 0.000245042 | gnorm 1.006 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27151
KL Stats: Epoch 162 Divergences: Uniform: 5.204388626115469 Unigram: 5.2538673299864485
2022-03-14 17:47:31 | INFO | fairseq.trainer | begin training epoch 163
2022-03-14 17:47:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:48:44 | INFO | train_inner | epoch 163:     46 / 103 loss=4.093, ppl=17.06, wps=40208.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=16700, lr=0.000244704, gnorm=1.021, loss_scale=16, train_wall=153, gb_free=20.8, wall=27224
2022-03-14 17:50:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:50:17 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 9.265 | ppl 615.24 | wps 66503.5 | wpb 2040.3 | bsz 4 | num_updates 16757 | best_loss 7.59
2022-03-14 17:50:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 16757 updates
2022-03-14 17:50:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:50:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:50:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 163 @ 16757 updates, score 9.265) (writing took 0.9675581902265549 seconds)
2022-03-14 17:50:18 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-14 17:50:18 | INFO | train | epoch 163 | loss 4.091 | ppl 17.04 | wps 40213.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16757 | lr 0.000244288 | gnorm 1.02 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27318
KL Stats: Epoch 163 Divergences: Uniform: 5.208020633053543 Unigram: 5.2603763117339515
2022-03-14 17:50:18 | INFO | fairseq.trainer | begin training epoch 164
2022-03-14 17:50:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:51:27 | INFO | train_inner | epoch 164:     43 / 103 loss=4.09, ppl=17.03, wps=40182.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=16800, lr=0.000243975, gnorm=1.023, loss_scale=16, train_wall=153, gb_free=20.8, wall=27386
2022-03-14 17:53:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:53:05 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 9.273 | ppl 618.82 | wps 66324.7 | wpb 2040.3 | bsz 4 | num_updates 16860 | best_loss 7.59
2022-03-14 17:53:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 16860 updates
2022-03-14 17:53:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:53:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:53:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 164 @ 16860 updates, score 9.273) (writing took 0.9232807625085115 seconds)
2022-03-14 17:53:06 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-14 17:53:06 | INFO | train | epoch 164 | loss 4.086 | ppl 16.98 | wps 40250.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16860 | lr 0.000243541 | gnorm 1.021 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27485
KL Stats: Epoch 164 Divergences: Uniform: 5.211889848923061 Unigram: 5.265245300130223
2022-03-14 17:53:06 | INFO | fairseq.trainer | begin training epoch 165
2022-03-14 17:53:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:53:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 17:54:11 | INFO | train_inner | epoch 165:     41 / 103 loss=4.084, ppl=16.96, wps=39822.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=16900, lr=0.000243252, gnorm=1.019, loss_scale=16, train_wall=155, gb_free=20.8, wall=27550
2022-03-14 17:55:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:55:52 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 9.261 | ppl 613.73 | wps 66292.6 | wpb 2040.3 | bsz 4 | num_updates 16962 | best_loss 7.59
2022-03-14 17:55:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 16962 updates
2022-03-14 17:55:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:55:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:55:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 165 @ 16962 updates, score 9.261) (writing took 0.9174612667411566 seconds)
2022-03-14 17:55:53 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-14 17:55:53 | INFO | train | epoch 165 | loss 4.08 | ppl 16.91 | wps 39847.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 16962 | lr 0.000242807 | gnorm 1.011 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27652
KL Stats: Epoch 165 Divergences: Uniform: 5.215437047242154 Unigram: 5.27252017305633
2022-03-14 17:55:53 | INFO | fairseq.trainer | begin training epoch 166
2022-03-14 17:55:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:56:53 | INFO | train_inner | epoch 166:     38 / 103 loss=4.08, ppl=16.91, wps=40197.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=17000, lr=0.000242536, gnorm=1.014, loss_scale=16, train_wall=153, gb_free=20.8, wall=27713
2022-03-14 17:58:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:58:39 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 9.265 | ppl 615.23 | wps 66139 | wpb 2040.3 | bsz 4 | num_updates 17065 | best_loss 7.59
2022-03-14 17:58:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 17065 updates
2022-03-14 17:58:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:58:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 17:58:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 166 @ 17065 updates, score 9.265) (writing took 0.9438213929533958 seconds)
2022-03-14 17:58:40 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-14 17:58:40 | INFO | train | epoch 166 | loss 4.077 | ppl 16.88 | wps 40219.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17065 | lr 0.000242073 | gnorm 1.022 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27820
KL Stats: Epoch 166 Divergences: Uniform: 5.218491081386508 Unigram: 5.274449858432221
2022-03-14 17:58:40 | INFO | fairseq.trainer | begin training epoch 167
2022-03-14 17:58:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:59:36 | INFO | train_inner | epoch 167:     35 / 103 loss=4.075, ppl=16.85, wps=40194, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17100, lr=0.000241825, gnorm=1.019, loss_scale=16, train_wall=153, gb_free=20.8, wall=27875
2022-03-14 18:01:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:01:26 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 9.273 | ppl 618.57 | wps 66107.8 | wpb 2040.3 | bsz 4 | num_updates 17168 | best_loss 7.59
2022-03-14 18:01:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 17168 updates
2022-03-14 18:01:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:01:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:01:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 167 @ 17168 updates, score 9.273) (writing took 0.9083099775016308 seconds)
2022-03-14 18:01:27 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-14 18:01:27 | INFO | train | epoch 167 | loss 4.073 | ppl 16.83 | wps 40232.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17168 | lr 0.000241346 | gnorm 1.028 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27987
KL Stats: Epoch 167 Divergences: Uniform: 5.2200792916604115 Unigram: 5.279421624018454
2022-03-14 18:01:27 | INFO | fairseq.trainer | begin training epoch 168
2022-03-14 18:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:02:18 | INFO | train_inner | epoch 168:     32 / 103 loss=4.074, ppl=16.84, wps=40183.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=17200, lr=0.000241121, gnorm=1.033, loss_scale=16, train_wall=153, gb_free=20.8, wall=28038
2022-03-14 18:04:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:04:14 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 9.29 | ppl 626 | wps 66129.6 | wpb 2040.3 | bsz 4 | num_updates 17271 | best_loss 7.59
2022-03-14 18:04:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 17271 updates
2022-03-14 18:04:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:04:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:04:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 168 @ 17271 updates, score 9.29) (writing took 0.9052891433238983 seconds)
2022-03-14 18:04:15 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-14 18:04:15 | INFO | train | epoch 168 | loss 4.067 | ppl 16.76 | wps 40216.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17271 | lr 0.000240625 | gnorm 1.025 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28154
KL Stats: Epoch 168 Divergences: Uniform: 5.224666197574415 Unigram: 5.286841675848503
2022-03-14 18:04:15 | INFO | fairseq.trainer | begin training epoch 169
2022-03-14 18:04:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:05:01 | INFO | train_inner | epoch 169:     29 / 103 loss=4.066, ppl=16.75, wps=40183.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17300, lr=0.000240424, gnorm=1.024, loss_scale=16, train_wall=153, gb_free=20.8, wall=28200
2022-03-14 18:06:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:07:01 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 9.307 | ppl 633.24 | wps 66320.1 | wpb 2040.3 | bsz 4 | num_updates 17374 | best_loss 7.59
2022-03-14 18:07:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 17374 updates
2022-03-14 18:07:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:07:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:07:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 169 @ 17374 updates, score 9.307) (writing took 0.9449525596573949 seconds)
2022-03-14 18:07:02 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-14 18:07:02 | INFO | train | epoch 169 | loss 4.065 | ppl 16.73 | wps 40208.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17374 | lr 0.000239911 | gnorm 1.033 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28321
KL Stats: Epoch 169 Divergences: Uniform: 5.224130359578107 Unigram: 5.290775005288666
2022-03-14 18:07:02 | INFO | fairseq.trainer | begin training epoch 170
2022-03-14 18:07:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:07:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:07:45 | INFO | train_inner | epoch 170:     27 / 103 loss=4.065, ppl=16.73, wps=39797.5, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=17400, lr=0.000239732, gnorm=1.028, loss_scale=16, train_wall=155, gb_free=20.8, wall=28364
2022-03-14 18:09:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:09:48 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 9.314 | ppl 636.53 | wps 65969.5 | wpb 2040.3 | bsz 4 | num_updates 17476 | best_loss 7.59
2022-03-14 18:09:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 17476 updates
2022-03-14 18:09:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:09:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:09:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 170 @ 17476 updates, score 9.314) (writing took 0.9184580463916063 seconds)
2022-03-14 18:09:49 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-14 18:09:49 | INFO | train | epoch 170 | loss 4.059 | ppl 16.66 | wps 39839.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 17476 | lr 0.00023921 | gnorm 1.021 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28489
KL Stats: Epoch 170 Divergences: Uniform: 5.230412691066527 Unigram: 5.298312289121178
2022-03-14 18:09:49 | INFO | fairseq.trainer | begin training epoch 171
2022-03-14 18:09:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:10:27 | INFO | train_inner | epoch 171:     24 / 103 loss=4.062, ppl=16.7, wps=40191.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17500, lr=0.000239046, gnorm=1.03, loss_scale=16, train_wall=153, gb_free=20.8, wall=28527
2022-03-14 18:12:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:12:35 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 9.325 | ppl 641.33 | wps 66337.1 | wpb 2040.3 | bsz 4 | num_updates 17579 | best_loss 7.59
2022-03-14 18:12:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 17579 updates
2022-03-14 18:12:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:12:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 171 @ 17579 updates, score 9.325) (writing took 0.8522858852520585 seconds)
2022-03-14 18:12:36 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-14 18:12:36 | INFO | train | epoch 171 | loss 4.055 | ppl 16.62 | wps 40223.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17579 | lr 0.000238508 | gnorm 1.027 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28656
KL Stats: Epoch 171 Divergences: Uniform: 5.233991960691766 Unigram: 5.303125571152356
2022-03-14 18:12:36 | INFO | fairseq.trainer | begin training epoch 172
2022-03-14 18:12:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:13:10 | INFO | train_inner | epoch 172:     21 / 103 loss=4.052, ppl=16.58, wps=40192.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=17600, lr=0.000238366, gnorm=1.014, loss_scale=16, train_wall=153, gb_free=20.8, wall=28689
2022-03-14 18:15:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:15:23 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 9.335 | ppl 645.65 | wps 66134.2 | wpb 2040.3 | bsz 4 | num_updates 17682 | best_loss 7.59
2022-03-14 18:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 17682 updates
2022-03-14 18:15:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:15:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:15:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 172 @ 17682 updates, score 9.335) (writing took 0.8537129899486899 seconds)
2022-03-14 18:15:24 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-14 18:15:24 | INFO | train | epoch 172 | loss 4.051 | ppl 16.58 | wps 40222.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17682 | lr 0.000237812 | gnorm 1.019 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28823
KL Stats: Epoch 172 Divergences: Uniform: 5.234297299358765 Unigram: 5.305630482080536
2022-03-14 18:15:24 | INFO | fairseq.trainer | begin training epoch 173
2022-03-14 18:15:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:15:52 | INFO | train_inner | epoch 173:     18 / 103 loss=4.055, ppl=16.62, wps=40184.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=17700, lr=0.000237691, gnorm=1.024, loss_scale=16, train_wall=153, gb_free=20.8, wall=28852
2022-03-14 18:18:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:18:10 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 9.302 | ppl 631.34 | wps 66086.1 | wpb 2040.3 | bsz 4 | num_updates 17785 | best_loss 7.59
2022-03-14 18:18:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 17785 updates
2022-03-14 18:18:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:18:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:18:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 173 @ 17785 updates, score 9.302) (writing took 0.8588837757706642 seconds)
2022-03-14 18:18:11 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-14 18:18:11 | INFO | train | epoch 173 | loss 4.047 | ppl 16.53 | wps 40211.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17785 | lr 0.000237123 | gnorm 1.037 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28990
KL Stats: Epoch 173 Divergences: Uniform: 5.238537332844147 Unigram: 5.308699532298754
2022-03-14 18:18:11 | INFO | fairseq.trainer | begin training epoch 174
2022-03-14 18:18:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:18:35 | INFO | train_inner | epoch 174:     15 / 103 loss=4.045, ppl=16.51, wps=40185.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17800, lr=0.000237023, gnorm=1.041, loss_scale=16, train_wall=153, gb_free=20.8, wall=29014
2022-03-14 18:20:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:20:57 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 9.341 | ppl 648.55 | wps 66105.9 | wpb 2040.3 | bsz 4 | num_updates 17888 | best_loss 7.59
2022-03-14 18:20:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 17888 updates
2022-03-14 18:20:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:20:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:20:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 174 @ 17888 updates, score 9.341) (writing took 0.8509833626449108 seconds)
2022-03-14 18:20:58 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-14 18:20:58 | INFO | train | epoch 174 | loss 4.042 | ppl 16.47 | wps 40243.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17888 | lr 0.000236439 | gnorm 1.024 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29158
KL Stats: Epoch 174 Divergences: Uniform: 5.241708422566477 Unigram: 5.316520504462188
2022-03-14 18:20:58 | INFO | fairseq.trainer | begin training epoch 175
2022-03-14 18:20:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:21:17 | INFO | train_inner | epoch 175:     12 / 103 loss=4.043, ppl=16.48, wps=40207.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=17900, lr=0.00023636, gnorm=1.025, loss_scale=16, train_wall=153, gb_free=20.8, wall=29177
2022-03-14 18:21:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:23:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:23:44 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 9.369 | ppl 661.35 | wps 66367.1 | wpb 2040.3 | bsz 4 | num_updates 17990 | best_loss 7.59
2022-03-14 18:23:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 17990 updates
2022-03-14 18:23:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:23:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:23:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 175 @ 17990 updates, score 9.369) (writing took 0.8465965921059251 seconds)
2022-03-14 18:23:45 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-14 18:23:45 | INFO | train | epoch 175 | loss 4.037 | ppl 16.41 | wps 39856.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 17990 | lr 0.000235768 | gnorm 1.029 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29325
KL Stats: Epoch 175 Divergences: Uniform: 5.245801363205287 Unigram: 5.323328048983845
2022-03-14 18:23:45 | INFO | fairseq.trainer | begin training epoch 176
2022-03-14 18:23:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:24:01 | INFO | train_inner | epoch 176:     10 / 103 loss=4.038, ppl=16.43, wps=39833.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18000, lr=0.000235702, gnorm=1.029, loss_scale=16, train_wall=155, gb_free=20.8, wall=29341
2022-03-14 18:26:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:26:31 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 9.351 | ppl 653.07 | wps 65932.8 | wpb 2040.3 | bsz 4 | num_updates 18093 | best_loss 7.59
2022-03-14 18:26:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 18093 updates
2022-03-14 18:26:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:26:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:26:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 176 @ 18093 updates, score 9.351) (writing took 0.8706672228872776 seconds)
2022-03-14 18:26:32 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-14 18:26:32 | INFO | train | epoch 176 | loss 4.035 | ppl 16.39 | wps 40239.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18093 | lr 0.000235096 | gnorm 1.033 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29492
KL Stats: Epoch 176 Divergences: Uniform: 5.245307865402373 Unigram: 5.325519492250017
2022-03-14 18:26:32 | INFO | fairseq.trainer | begin training epoch 177
2022-03-14 18:26:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:26:43 | INFO | train_inner | epoch 177:      7 / 103 loss=4.036, ppl=16.41, wps=40201.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18100, lr=0.00023505, gnorm=1.032, loss_scale=16, train_wall=153, gb_free=20.8, wall=29503
2022-03-14 18:29:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:29:19 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 9.341 | ppl 648.72 | wps 66591.4 | wpb 2040.3 | bsz 4 | num_updates 18196 | best_loss 7.59
2022-03-14 18:29:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 18196 updates
2022-03-14 18:29:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:29:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:29:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 177 @ 18196 updates, score 9.341) (writing took 0.8468978935852647 seconds)
2022-03-14 18:29:19 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-14 18:29:19 | INFO | train | epoch 177 | loss 4.031 | ppl 16.35 | wps 40237.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18196 | lr 0.000234429 | gnorm 1.033 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29659
KL Stats: Epoch 177 Divergences: Uniform: 5.248330251589204 Unigram: 5.328728513237132
2022-03-14 18:29:19 | INFO | fairseq.trainer | begin training epoch 178
2022-03-14 18:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:29:26 | INFO | train_inner | epoch 178:      4 / 103 loss=4.034, ppl=16.38, wps=40208.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18200, lr=0.000234404, gnorm=1.034, loss_scale=16, train_wall=153, gb_free=20.8, wall=29665
2022-03-14 18:32:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:32:06 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 9.328 | ppl 642.57 | wps 66201.4 | wpb 2040.3 | bsz 4 | num_updates 18299 | best_loss 7.59
2022-03-14 18:32:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 18299 updates
2022-03-14 18:32:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:32:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:32:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 178 @ 18299 updates, score 9.328) (writing took 0.8434347892180085 seconds)
2022-03-14 18:32:07 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-14 18:32:07 | INFO | train | epoch 178 | loss 4.026 | ppl 16.3 | wps 40259 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18299 | lr 0.000233769 | gnorm 1.045 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29826
KL Stats: Epoch 178 Divergences: Uniform: 5.248386381162621 Unigram: 5.330797217321027
2022-03-14 18:32:07 | INFO | fairseq.trainer | begin training epoch 179
2022-03-14 18:32:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:32:08 | INFO | train_inner | epoch 179:      1 / 103 loss=4.028, ppl=16.32, wps=40227.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18300, lr=0.000233762, gnorm=1.046, loss_scale=16, train_wall=153, gb_free=20.8, wall=29828
2022-03-14 18:34:47 | INFO | train_inner | epoch 179:    101 / 103 loss=4.021, ppl=16.24, wps=41363.3, ups=0.63, wpb=65530.9, bsz=128, num_updates=18400, lr=0.000233126, gnorm=1.028, loss_scale=16, train_wall=154, gb_free=20.8, wall=29986
2022-03-14 18:34:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:34:53 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 9.348 | ppl 651.55 | wps 65980.6 | wpb 2040.3 | bsz 4 | num_updates 18402 | best_loss 7.59
2022-03-14 18:34:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 18402 updates
2022-03-14 18:34:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:34:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:34:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 179 @ 18402 updates, score 9.348) (writing took 0.8314163945615292 seconds)
2022-03-14 18:34:54 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-14 18:34:54 | INFO | train | epoch 179 | loss 4.022 | ppl 16.24 | wps 40254 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18402 | lr 0.000233114 | gnorm 1.031 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29993
KL Stats: Epoch 179 Divergences: Uniform: 5.254354108226084 Unigram: 5.339457017001355
2022-03-14 18:34:54 | INFO | fairseq.trainer | begin training epoch 180
2022-03-14 18:34:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:35:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:37:31 | INFO | train_inner | epoch 180:     99 / 103 loss=4.018, ppl=16.2, wps=39843.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18500, lr=0.000232495, gnorm=1.04, loss_scale=16, train_wall=154, gb_free=20.8, wall=30150
2022-03-14 18:37:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:37:40 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 9.358 | ppl 656.24 | wps 66205.3 | wpb 2040.3 | bsz 4 | num_updates 18504 | best_loss 7.59
2022-03-14 18:37:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 18504 updates
2022-03-14 18:37:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:37:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:37:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 180 @ 18504 updates, score 9.358) (writing took 0.8429537136107683 seconds)
2022-03-14 18:37:41 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-14 18:37:41 | INFO | train | epoch 180 | loss 4.019 | ppl 16.21 | wps 39877 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 18504 | lr 0.00023247 | gnorm 1.04 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30160
KL Stats: Epoch 180 Divergences: Uniform: 5.257559373581309 Unigram: 5.342990743364206
2022-03-14 18:37:41 | INFO | fairseq.trainer | begin training epoch 181
2022-03-14 18:37:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:40:13 | INFO | train_inner | epoch 181:     96 / 103 loss=4.013, ppl=16.15, wps=40237.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18600, lr=0.000231869, gnorm=1.034, loss_scale=16, train_wall=153, gb_free=20.8, wall=30312
2022-03-14 18:40:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:40:27 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 9.36 | ppl 657.01 | wps 66098.4 | wpb 2040.3 | bsz 4 | num_updates 18607 | best_loss 7.59
2022-03-14 18:40:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 18607 updates
2022-03-14 18:40:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:40:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:40:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 181 @ 18607 updates, score 9.36) (writing took 0.8566527795046568 seconds)
2022-03-14 18:40:28 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-14 18:40:28 | INFO | train | epoch 181 | loss 4.016 | ppl 16.17 | wps 40258.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18607 | lr 0.000231826 | gnorm 1.038 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30327
KL Stats: Epoch 181 Divergences: Uniform: 5.257787513803059 Unigram: 5.346895821316359
2022-03-14 18:40:28 | INFO | fairseq.trainer | begin training epoch 182
2022-03-14 18:40:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:42:55 | INFO | train_inner | epoch 182:     93 / 103 loss=4.008, ppl=16.09, wps=40218.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18700, lr=0.000231249, gnorm=1.036, loss_scale=16, train_wall=153, gb_free=20.8, wall=30475
2022-03-14 18:43:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:43:14 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 9.373 | ppl 663.07 | wps 66119 | wpb 2040.3 | bsz 4 | num_updates 18710 | best_loss 7.59
2022-03-14 18:43:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 18710 updates
2022-03-14 18:43:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:43:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:43:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 182 @ 18710 updates, score 9.373) (writing took 0.8604525607079268 seconds)
2022-03-14 18:43:15 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-14 18:43:15 | INFO | train | epoch 182 | loss 4.011 | ppl 16.12 | wps 40245.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18710 | lr 0.000231187 | gnorm 1.033 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30495
KL Stats: Epoch 182 Divergences: Uniform: 5.261354518033161 Unigram: 5.352517794826181
2022-03-14 18:43:15 | INFO | fairseq.trainer | begin training epoch 183
2022-03-14 18:43:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:45:38 | INFO | train_inner | epoch 183:     90 / 103 loss=4.007, ppl=16.08, wps=40209.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18800, lr=0.000230633, gnorm=1.026, loss_scale=16, train_wall=153, gb_free=20.8, wall=30637
2022-03-14 18:45:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:46:01 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 9.404 | ppl 677.68 | wps 65801.6 | wpb 2040.3 | bsz 4 | num_updates 18813 | best_loss 7.59
2022-03-14 18:46:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 18813 updates
2022-03-14 18:46:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:46:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:46:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 183 @ 18813 updates, score 9.404) (writing took 1.0176461162045598 seconds)
2022-03-14 18:46:02 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-14 18:46:02 | INFO | train | epoch 183 | loss 4.007 | ppl 16.08 | wps 40206.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18813 | lr 0.000230553 | gnorm 1.025 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30662
KL Stats: Epoch 183 Divergences: Uniform: 5.265146806442637 Unigram: 5.358085421737217
2022-03-14 18:46:02 | INFO | fairseq.trainer | begin training epoch 184
2022-03-14 18:46:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:48:20 | INFO | train_inner | epoch 184:     87 / 103 loss=4.002, ppl=16.02, wps=40184.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18900, lr=0.000230022, gnorm=1.028, loss_scale=16, train_wall=153, gb_free=20.8, wall=30800
2022-03-14 18:48:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:48:49 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 9.383 | ppl 667.88 | wps 65974.3 | wpb 2040.3 | bsz 4 | num_updates 18916 | best_loss 7.59
2022-03-14 18:48:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 18916 updates
2022-03-14 18:48:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:48:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:48:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 184 @ 18916 updates, score 9.383) (writing took 0.8369152788072824 seconds)
2022-03-14 18:48:49 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-14 18:48:49 | INFO | train | epoch 184 | loss 4.003 | ppl 16.04 | wps 40266.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18916 | lr 0.000229925 | gnorm 1.033 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30829
KL Stats: Epoch 184 Divergences: Uniform: 5.266680893261409 Unigram: 5.363093978387988
2022-03-14 18:48:49 | INFO | fairseq.trainer | begin training epoch 185
2022-03-14 18:48:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:49:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:51:04 | INFO | train_inner | epoch 185:     85 / 103 loss=3.998, ppl=15.98, wps=39832.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=19000, lr=0.000229416, gnorm=1.051, loss_scale=16, train_wall=155, gb_free=20.8, wall=30964
2022-03-14 18:51:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:51:36 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 9.357 | ppl 655.92 | wps 66191.2 | wpb 2040.3 | bsz 4 | num_updates 19018 | best_loss 7.59
2022-03-14 18:51:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 19018 updates
2022-03-14 18:51:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:51:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:51:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 185 @ 19018 updates, score 9.357) (writing took 0.8527736207470298 seconds)
2022-03-14 18:51:37 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-14 18:51:37 | INFO | train | epoch 185 | loss 3.998 | ppl 15.98 | wps 39856.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 19018 | lr 0.000229307 | gnorm 1.049 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30996
KL Stats: Epoch 185 Divergences: Uniform: 5.268338965457693 Unigram: 5.364836438379993
2022-03-14 18:51:37 | INFO | fairseq.trainer | begin training epoch 186
2022-03-14 18:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:53:46 | INFO | train_inner | epoch 186:     82 / 103 loss=3.994, ppl=15.93, wps=40226.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=19100, lr=0.000228814, gnorm=1.03, loss_scale=16, train_wall=153, gb_free=20.8, wall=31126
2022-03-14 18:54:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:54:23 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 9.392 | ppl 671.93 | wps 65830.4 | wpb 2040.3 | bsz 4 | num_updates 19121 | best_loss 7.59
2022-03-14 18:54:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 19121 updates
2022-03-14 18:54:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:54:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:54:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 186 @ 19121 updates, score 9.392) (writing took 0.8353780889883637 seconds)
2022-03-14 18:54:24 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-14 18:54:24 | INFO | train | epoch 186 | loss 3.995 | ppl 15.94 | wps 40257.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19121 | lr 0.000228689 | gnorm 1.027 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31163
KL Stats: Epoch 186 Divergences: Uniform: 5.270630628284876 Unigram: 5.3704186852340445
2022-03-14 18:54:24 | INFO | fairseq.trainer | begin training epoch 187
2022-03-14 18:54:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:56:29 | INFO | train_inner | epoch 187:     79 / 103 loss=3.988, ppl=15.87, wps=40219, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=19200, lr=0.000228218, gnorm=1.036, loss_scale=16, train_wall=153, gb_free=20.8, wall=31288
2022-03-14 18:57:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:57:10 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 9.383 | ppl 667.48 | wps 66078.4 | wpb 2040.3 | bsz 4 | num_updates 19224 | best_loss 7.59
2022-03-14 18:57:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 19224 updates
2022-03-14 18:57:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:57:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:57:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 187 @ 19224 updates, score 9.383) (writing took 0.9764114515855908 seconds)
2022-03-14 18:57:11 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-14 18:57:11 | INFO | train | epoch 187 | loss 3.99 | ppl 15.89 | wps 40212.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19224 | lr 0.000228075 | gnorm 1.034 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31331
KL Stats: Epoch 187 Divergences: Uniform: 5.274843413060796 Unigram: 5.37540584562806
2022-03-14 18:57:11 | INFO | fairseq.trainer | begin training epoch 188
2022-03-14 18:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:59:11 | INFO | train_inner | epoch 188:     76 / 103 loss=3.989, ppl=15.88, wps=40172.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=19300, lr=0.000227626, gnorm=1.028, loss_scale=16, train_wall=153, gb_free=20.8, wall=31451
2022-03-14 18:59:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:59:57 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 9.382 | ppl 667.3 | wps 65923.3 | wpb 2040.3 | bsz 4 | num_updates 19327 | best_loss 7.59
2022-03-14 18:59:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 19327 updates
2022-03-14 18:59:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:59:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 18:59:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 188 @ 19327 updates, score 9.382) (writing took 0.9147206237539649 seconds)
2022-03-14 18:59:58 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-14 18:59:58 | INFO | train | epoch 188 | loss 3.988 | ppl 15.87 | wps 40219.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19327 | lr 0.000227467 | gnorm 1.032 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31498
KL Stats: Epoch 188 Divergences: Uniform: 5.275430514892264 Unigram: 5.379752496745316
2022-03-14 18:59:58 | INFO | fairseq.trainer | begin training epoch 189
2022-03-14 18:59:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:01:54 | INFO | train_inner | epoch 189:     73 / 103 loss=3.983, ppl=15.81, wps=40181.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=19400, lr=0.000227038, gnorm=1.042, loss_scale=16, train_wall=153, gb_free=20.8, wall=31614
2022-03-14 19:02:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:02:45 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 9.389 | ppl 670.56 | wps 65859.1 | wpb 2040.3 | bsz 4 | num_updates 19430 | best_loss 7.59
2022-03-14 19:02:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 19430 updates
2022-03-14 19:02:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:02:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:02:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 189 @ 19430 updates, score 9.389) (writing took 0.9834817098453641 seconds)
2022-03-14 19:02:46 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-14 19:02:46 | INFO | train | epoch 189 | loss 3.983 | ppl 15.82 | wps 40184.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19430 | lr 0.000226863 | gnorm 1.041 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31665
KL Stats: Epoch 189 Divergences: Uniform: 5.27888888681404 Unigram: 5.384520410325169
2022-03-14 19:02:46 | INFO | fairseq.trainer | begin training epoch 190
2022-03-14 19:02:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:03:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 19:04:38 | INFO | train_inner | epoch 190:     71 / 103 loss=3.98, ppl=15.78, wps=39785.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=19500, lr=0.000226455, gnorm=1.048, loss_scale=16, train_wall=154, gb_free=20.8, wall=31778
2022-03-14 19:05:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:05:32 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 9.401 | ppl 676.01 | wps 65958.4 | wpb 2040.3 | bsz 4 | num_updates 19532 | best_loss 7.59
2022-03-14 19:05:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 19532 updates
2022-03-14 19:05:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:05:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:05:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 190 @ 19532 updates, score 9.401) (writing took 0.9427494145929813 seconds)
2022-03-14 19:05:33 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-14 19:05:33 | INFO | train | epoch 190 | loss 3.98 | ppl 15.79 | wps 39844.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 19532 | lr 0.00022627 | gnorm 1.05 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31832
KL Stats: Epoch 190 Divergences: Uniform: 5.2795682795567735 Unigram: 5.387812305294709
2022-03-14 19:05:33 | INFO | fairseq.trainer | begin training epoch 191
2022-03-14 19:05:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:07:21 | INFO | train_inner | epoch 191:     68 / 103 loss=3.978, ppl=15.76, wps=40205.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=19600, lr=0.000225877, gnorm=1.042, loss_scale=16, train_wall=153, gb_free=20.8, wall=31940
2022-03-14 19:07:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 19:08:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:08:19 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 9.401 | ppl 676.19 | wps 66240.5 | wpb 2040.3 | bsz 4 | num_updates 19634 | best_loss 7.59
2022-03-14 19:08:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 19634 updates
2022-03-14 19:08:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:08:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:08:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 191 @ 19634 updates, score 9.401) (writing took 0.9861272750422359 seconds)
2022-03-14 19:08:20 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-14 19:08:20 | INFO | train | epoch 191 | loss 3.976 | ppl 15.73 | wps 39842.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 19634 | lr 0.000225681 | gnorm 1.041 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 32000
KL Stats: Epoch 191 Divergences: Uniform: 5.282315197040071 Unigram: 5.390687675798759
2022-03-14 19:08:20 | INFO | fairseq.trainer | begin training epoch 192
2022-03-14 19:08:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:10:05 | INFO | train_inner | epoch 192:     66 / 103 loss=3.973, ppl=15.7, wps=39807.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=19700, lr=0.000225303, gnorm=1.047, loss_scale=8, train_wall=154, gb_free=20.8, wall=32104
2022-03-14 19:11:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:11:06 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 9.417 | ppl 683.77 | wps 66112.5 | wpb 2040.3 | bsz 4 | num_updates 19737 | best_loss 7.59
2022-03-14 19:11:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 19737 updates
2022-03-14 19:11:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:11:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:11:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 192 @ 19737 updates, score 9.417) (writing took 0.939982402138412 seconds)
2022-03-14 19:11:07 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-14 19:11:07 | INFO | train | epoch 192 | loss 3.975 | ppl 15.72 | wps 40228.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19737 | lr 0.000225092 | gnorm 1.044 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 32167
KL Stats: Epoch 192 Divergences: Uniform: 5.284822998804483 Unigram: 5.3941016953059
2022-03-14 19:11:07 | INFO | fairseq.trainer | begin training epoch 193
2022-03-14 19:11:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:12:47 | INFO | train_inner | epoch 193:     63 / 103 loss=3.972, ppl=15.69, wps=40184.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=19800, lr=0.000224733, gnorm=1.046, loss_scale=8, train_wall=153, gb_free=20.8, wall=32267
2022-03-14 19:13:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:13:54 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 9.414 | ppl 682.25 | wps 66085.4 | wpb 2040.3 | bsz 4 | num_updates 19840 | best_loss 7.59
2022-03-14 19:13:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 19840 updates
2022-03-14 19:13:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:13:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:13:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 193 @ 19840 updates, score 9.414) (writing took 0.9685932649299502 seconds)
2022-03-14 19:13:55 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-14 19:13:55 | INFO | train | epoch 193 | loss 3.97 | ppl 15.68 | wps 40201.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19840 | lr 0.000224507 | gnorm 1.05 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 32334
KL Stats: Epoch 193 Divergences: Uniform: 5.287094724542212 Unigram: 5.398104202786803
2022-03-14 19:13:55 | INFO | fairseq.trainer | begin training epoch 194
2022-03-14 19:13:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:15:30 | INFO | train_inner | epoch 194:     60 / 103 loss=3.968, ppl=15.65, wps=40169.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=19900, lr=0.000224168, gnorm=1.045, loss_scale=8, train_wall=153, gb_free=20.8, wall=32429
2022-03-14 19:16:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:16:41 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 9.421 | ppl 685.53 | wps 66101.9 | wpb 2040.3 | bsz 4 | num_updates 19943 | best_loss 7.59
2022-03-14 19:16:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 19943 updates
2022-03-14 19:16:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:16:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:16:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 194 @ 19943 updates, score 9.421) (writing took 0.9371274197474122 seconds)
2022-03-14 19:16:42 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-14 19:16:42 | INFO | train | epoch 194 | loss 3.967 | ppl 15.64 | wps 40213 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19943 | lr 0.000223926 | gnorm 1.042 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 32501
KL Stats: Epoch 194 Divergences: Uniform: 5.289033321003214 Unigram: 5.403689478530127
2022-03-14 19:16:42 | INFO | fairseq.trainer | begin training epoch 195
2022-03-14 19:16:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:18:12 | INFO | train_inner | epoch 195:     57 / 103 loss=3.964, ppl=15.6, wps=40165.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20000, lr=0.000223607, gnorm=1.041, loss_scale=8, train_wall=153, gb_free=20.8, wall=32592
2022-03-14 19:19:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:19:28 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 9.442 | ppl 695.5 | wps 66217.6 | wpb 2040.3 | bsz 4 | num_updates 20046 | best_loss 7.59
2022-03-14 19:19:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 20046 updates
2022-03-14 19:19:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:19:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:19:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 195 @ 20046 updates, score 9.442) (writing took 0.9629715094342828 seconds)
2022-03-14 19:19:29 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-14 19:19:29 | INFO | train | epoch 195 | loss 3.964 | ppl 15.61 | wps 40187 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20046 | lr 0.00022335 | gnorm 1.044 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 32669
KL Stats: Epoch 195 Divergences: Uniform: 5.2902805288384265 Unigram: 5.407517089787631
2022-03-14 19:19:29 | INFO | fairseq.trainer | begin training epoch 196
2022-03-14 19:19:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:20:55 | INFO | train_inner | epoch 196:     54 / 103 loss=3.964, ppl=15.6, wps=40169.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20100, lr=0.00022305, gnorm=1.054, loss_scale=8, train_wall=153, gb_free=20.8, wall=32754
2022-03-14 19:22:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:22:16 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 9.435 | ppl 692.28 | wps 65989.6 | wpb 2040.3 | bsz 4 | num_updates 20149 | best_loss 7.59
2022-03-14 19:22:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 20149 updates
2022-03-14 19:22:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:22:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:22:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 196 @ 20149 updates, score 9.435) (writing took 0.9943734472617507 seconds)
2022-03-14 19:22:17 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-14 19:22:17 | INFO | train | epoch 196 | loss 3.96 | ppl 15.56 | wps 40200.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20149 | lr 0.000222778 | gnorm 1.048 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32836
KL Stats: Epoch 196 Divergences: Uniform: 5.292665439057148 Unigram: 5.410093480762904
2022-03-14 19:22:17 | INFO | fairseq.trainer | begin training epoch 197
2022-03-14 19:22:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:23:37 | INFO | train_inner | epoch 197:     51 / 103 loss=3.956, ppl=15.52, wps=40157.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=20200, lr=0.000222497, gnorm=1.033, loss_scale=16, train_wall=153, gb_free=20.8, wall=32917
2022-03-14 19:24:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:25:03 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 9.433 | ppl 691.37 | wps 66071.8 | wpb 2040.3 | bsz 4 | num_updates 20252 | best_loss 7.59
2022-03-14 19:25:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 20252 updates
2022-03-14 19:25:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:25:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:25:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 197 @ 20252 updates, score 9.433) (writing took 0.918992729857564 seconds)
2022-03-14 19:25:04 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-14 19:25:04 | INFO | train | epoch 197 | loss 3.956 | ppl 15.52 | wps 40218.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20252 | lr 0.000222211 | gnorm 1.04 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33003
KL Stats: Epoch 197 Divergences: Uniform: 5.296978231263801 Unigram: 5.415102285460192
2022-03-14 19:25:04 | INFO | fairseq.trainer | begin training epoch 198
2022-03-14 19:25:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:26:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 19:26:22 | INFO | train_inner | epoch 198:     49 / 103 loss=3.955, ppl=15.5, wps=39814.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=20300, lr=0.000221948, gnorm=1.049, loss_scale=8, train_wall=155, gb_free=20.8, wall=33081
2022-03-14 19:27:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:27:50 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 9.434 | ppl 691.63 | wps 66301.7 | wpb 2040.3 | bsz 4 | num_updates 20354 | best_loss 7.59
2022-03-14 19:27:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 20354 updates
2022-03-14 19:27:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:27:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:27:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 198 @ 20354 updates, score 9.434) (writing took 0.9991700993850827 seconds)
2022-03-14 19:27:51 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-14 19:27:51 | INFO | train | epoch 198 | loss 3.952 | ppl 15.48 | wps 39827.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 20354 | lr 0.000221654 | gnorm 1.048 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 33171
KL Stats: Epoch 198 Divergences: Uniform: 5.297871259890658 Unigram: 5.421151337197442
2022-03-14 19:27:51 | INFO | fairseq.trainer | begin training epoch 199
2022-03-14 19:27:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:29:04 | INFO | train_inner | epoch 199:     46 / 103 loss=3.953, ppl=15.49, wps=40180.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20400, lr=0.000221404, gnorm=1.048, loss_scale=8, train_wall=153, gb_free=20.8, wall=33244
2022-03-14 19:30:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:30:37 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 9.462 | ppl 705.29 | wps 66258.3 | wpb 2040.3 | bsz 4 | num_updates 20457 | best_loss 7.59
2022-03-14 19:30:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 20457 updates
2022-03-14 19:30:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:30:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:30:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 199 @ 20457 updates, score 9.462) (writing took 0.9276893055066466 seconds)
2022-03-14 19:30:38 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-14 19:30:38 | INFO | train | epoch 199 | loss 3.949 | ppl 15.45 | wps 40235.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20457 | lr 0.000221095 | gnorm 1.047 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 33338
KL Stats: Epoch 199 Divergences: Uniform: 5.300549485956145 Unigram: 5.425045624284369
2022-03-14 19:30:38 | INFO | fairseq.trainer | begin training epoch 200
2022-03-14 19:30:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:31:46 | INFO | train_inner | epoch 200:     43 / 103 loss=3.949, ppl=15.44, wps=40209.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=20500, lr=0.000220863, gnorm=1.048, loss_scale=8, train_wall=153, gb_free=20.8, wall=33406
2022-03-14 19:33:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:33:25 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 9.444 | ppl 696.54 | wps 66105.7 | wpb 2040.3 | bsz 4 | num_updates 20560 | best_loss 7.59
2022-03-14 19:33:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 20560 updates
2022-03-14 19:33:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:33:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:33:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 200 @ 20560 updates, score 9.444) (writing took 0.8850526809692383 seconds)
2022-03-14 19:33:25 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-14 19:33:25 | INFO | train | epoch 200 | loss 3.946 | ppl 15.42 | wps 40257.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20560 | lr 0.000220541 | gnorm 1.049 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 33505
KL Stats: Epoch 200 Divergences: Uniform: 5.301569197536523 Unigram: 5.428407728132758
2022-03-14 19:33:25 | INFO | fairseq.trainer | begin training epoch 201
2022-03-14 19:33:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:34:29 | INFO | train_inner | epoch 201:     40 / 103 loss=3.942, ppl=15.37, wps=40217.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=20600, lr=0.000220326, gnorm=1.037, loss_scale=8, train_wall=153, gb_free=20.8, wall=33568
2022-03-14 19:36:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:36:12 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 9.479 | ppl 713.62 | wps 66105.1 | wpb 2040.3 | bsz 4 | num_updates 20663 | best_loss 7.59
2022-03-14 19:36:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 20663 updates
2022-03-14 19:36:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:36:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:36:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 201 @ 20663 updates, score 9.479) (writing took 0.9336449289694428 seconds)
2022-03-14 19:36:13 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-14 19:36:13 | INFO | train | epoch 201 | loss 3.943 | ppl 15.38 | wps 40229.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20663 | lr 0.00021999 | gnorm 1.05 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 33672
KL Stats: Epoch 201 Divergences: Uniform: 5.303995344436269 Unigram: 5.433557101407881
2022-03-14 19:36:13 | INFO | fairseq.trainer | begin training epoch 202
2022-03-14 19:36:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:37:11 | INFO | train_inner | epoch 202:     37 / 103 loss=3.944, ppl=15.39, wps=40204.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20700, lr=0.000219793, gnorm=1.057, loss_scale=8, train_wall=153, gb_free=20.8, wall=33731
2022-03-14 19:38:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:38:59 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 9.447 | ppl 697.8 | wps 66455.1 | wpb 2040.3 | bsz 4 | num_updates 20766 | best_loss 7.59
2022-03-14 19:38:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 20766 updates
2022-03-14 19:38:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:39:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:39:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 202 @ 20766 updates, score 9.447) (writing took 0.9879371337592602 seconds)
2022-03-14 19:39:00 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-14 19:39:00 | INFO | train | epoch 202 | loss 3.939 | ppl 15.34 | wps 40223.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20766 | lr 0.000219444 | gnorm 1.038 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 33839
KL Stats: Epoch 202 Divergences: Uniform: 5.306697880954329 Unigram: 5.437304034273429
2022-03-14 19:39:00 | INFO | fairseq.trainer | begin training epoch 203
2022-03-14 19:39:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:39:54 | INFO | train_inner | epoch 203:     34 / 103 loss=3.938, ppl=15.33, wps=40176.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=20800, lr=0.000219265, gnorm=1.038, loss_scale=8, train_wall=153, gb_free=20.8, wall=33893
2022-03-14 19:40:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 19:41:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:41:46 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 9.438 | ppl 693.74 | wps 65927.7 | wpb 2040.3 | bsz 4 | num_updates 20868 | best_loss 7.59
2022-03-14 19:41:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 20868 updates
2022-03-14 19:41:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:41:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:41:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 203 @ 20868 updates, score 9.438) (writing took 0.9473003381863236 seconds)
2022-03-14 19:41:47 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-14 19:41:47 | INFO | train | epoch 203 | loss 3.936 | ppl 15.31 | wps 39840.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 20868 | lr 0.000218907 | gnorm 1.049 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 34007
KL Stats: Epoch 203 Divergences: Uniform: 5.307090148420709 Unigram: 5.438505218747172
2022-03-14 19:41:47 | INFO | fairseq.trainer | begin training epoch 204
2022-03-14 19:41:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:42:38 | INFO | train_inner | epoch 204:     32 / 103 loss=3.938, ppl=15.33, wps=39808.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=20900, lr=0.000218739, gnorm=1.058, loss_scale=8, train_wall=155, gb_free=20.8, wall=34057
2022-03-14 19:44:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:44:33 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 9.484 | ppl 716.15 | wps 66172.6 | wpb 2040.3 | bsz 4 | num_updates 20971 | best_loss 7.59
2022-03-14 19:44:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 20971 updates
2022-03-14 19:44:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:44:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:44:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 204 @ 20971 updates, score 9.484) (writing took 0.9491679146885872 seconds)
2022-03-14 19:44:34 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-14 19:44:34 | INFO | train | epoch 204 | loss 3.934 | ppl 15.28 | wps 40216.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20971 | lr 0.000218369 | gnorm 1.065 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 34174
KL Stats: Epoch 204 Divergences: Uniform: 5.308637984424183 Unigram: 5.444360999457754
2022-03-14 19:44:34 | INFO | fairseq.trainer | begin training epoch 205
2022-03-14 19:44:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:45:20 | INFO | train_inner | epoch 205:     29 / 103 loss=3.931, ppl=15.25, wps=40182.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=21000, lr=0.000218218, gnorm=1.066, loss_scale=8, train_wall=153, gb_free=20.8, wall=34220
2022-03-14 19:47:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:47:21 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 9.479 | ppl 713.48 | wps 66511.9 | wpb 2040.3 | bsz 4 | num_updates 21074 | best_loss 7.59
2022-03-14 19:47:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 21074 updates
2022-03-14 19:47:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:47:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:47:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 205 @ 21074 updates, score 9.479) (writing took 0.9394169962033629 seconds)
2022-03-14 19:47:22 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-14 19:47:22 | INFO | train | epoch 205 | loss 3.931 | ppl 15.25 | wps 40224.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21074 | lr 0.000217834 | gnorm 1.057 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 34341
KL Stats: Epoch 205 Divergences: Uniform: 5.313774779650515 Unigram: 5.448357969103775
2022-03-14 19:47:22 | INFO | fairseq.trainer | begin training epoch 206
2022-03-14 19:47:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:48:03 | INFO | train_inner | epoch 206:     26 / 103 loss=3.933, ppl=15.27, wps=40190.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=21100, lr=0.0002177, gnorm=1.055, loss_scale=8, train_wall=153, gb_free=20.8, wall=34382
2022-03-14 19:50:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:50:08 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 9.464 | ppl 706.01 | wps 66057.5 | wpb 2040.3 | bsz 4 | num_updates 21177 | best_loss 7.59
2022-03-14 19:50:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 21177 updates
2022-03-14 19:50:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:50:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:50:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 206 @ 21177 updates, score 9.464) (writing took 0.9120129402726889 seconds)
2022-03-14 19:50:09 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-14 19:50:09 | INFO | train | epoch 206 | loss 3.927 | ppl 15.21 | wps 40214.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21177 | lr 0.000217304 | gnorm 1.052 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 34508
KL Stats: Epoch 206 Divergences: Uniform: 5.3140298034566955 Unigram: 5.450130693857264
2022-03-14 19:50:09 | INFO | fairseq.trainer | begin training epoch 207
2022-03-14 19:50:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:50:45 | INFO | train_inner | epoch 207:     23 / 103 loss=3.927, ppl=15.21, wps=40188.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=21200, lr=0.000217186, gnorm=1.045, loss_scale=8, train_wall=153, gb_free=20.8, wall=34545
2022-03-14 19:52:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:52:55 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 9.461 | ppl 704.54 | wps 66499.7 | wpb 2040.3 | bsz 4 | num_updates 21280 | best_loss 7.59
2022-03-14 19:52:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 21280 updates
2022-03-14 19:52:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:52:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:52:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 207 @ 21280 updates, score 9.461) (writing took 0.9201690703630447 seconds)
2022-03-14 19:52:56 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-14 19:52:56 | INFO | train | epoch 207 | loss 3.925 | ppl 15.19 | wps 40213.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21280 | lr 0.000216777 | gnorm 1.049 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 34676
KL Stats: Epoch 207 Divergences: Uniform: 5.3147794856092165 Unigram: 5.4525818060495785
2022-03-14 19:52:56 | INFO | fairseq.trainer | begin training epoch 208
2022-03-14 19:52:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:53:28 | INFO | train_inner | epoch 208:     20 / 103 loss=3.927, ppl=15.21, wps=40177.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21300, lr=0.000216676, gnorm=1.054, loss_scale=8, train_wall=153, gb_free=20.8, wall=34708
2022-03-14 19:55:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:55:42 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 9.465 | ppl 706.51 | wps 66499.7 | wpb 2040.3 | bsz 4 | num_updates 21383 | best_loss 7.59
2022-03-14 19:55:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 21383 updates
2022-03-14 19:55:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:55:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:55:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 208 @ 21383 updates, score 9.465) (writing took 0.8964150361716747 seconds)
2022-03-14 19:55:43 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-14 19:55:43 | INFO | train | epoch 208 | loss 3.922 | ppl 15.15 | wps 40254.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21383 | lr 0.000216255 | gnorm 1.045 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34843
KL Stats: Epoch 208 Divergences: Uniform: 5.314549639085585 Unigram: 5.456145393817729
2022-03-14 19:55:43 | INFO | fairseq.trainer | begin training epoch 209
2022-03-14 19:55:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:56:10 | INFO | train_inner | epoch 209:     17 / 103 loss=3.924, ppl=15.18, wps=40225, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21400, lr=0.000216169, gnorm=1.045, loss_scale=16, train_wall=153, gb_free=20.8, wall=34870
2022-03-14 19:58:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:58:30 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 9.477 | ppl 712.79 | wps 66481 | wpb 2040.3 | bsz 4 | num_updates 21486 | best_loss 7.59
2022-03-14 19:58:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 21486 updates
2022-03-14 19:58:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:58:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 19:58:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 209 @ 21486 updates, score 9.477) (writing took 0.9572415659204125 seconds)
2022-03-14 19:58:31 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-14 19:58:31 | INFO | train | epoch 209 | loss 3.918 | ppl 15.12 | wps 40224.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21486 | lr 0.000215736 | gnorm 1.066 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35010
KL Stats: Epoch 209 Divergences: Uniform: 5.319004338661859 Unigram: 5.45975745910667
2022-03-14 19:58:31 | INFO | fairseq.trainer | begin training epoch 210
2022-03-14 19:58:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:58:53 | INFO | train_inner | epoch 210:     14 / 103 loss=3.919, ppl=15.12, wps=40193, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21500, lr=0.000215666, gnorm=1.067, loss_scale=16, train_wall=153, gb_free=20.8, wall=35032
2022-03-14 20:01:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:01:17 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 9.479 | ppl 713.43 | wps 66227.6 | wpb 2040.3 | bsz 4 | num_updates 21589 | best_loss 7.59
2022-03-14 20:01:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 21589 updates
2022-03-14 20:01:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:01:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:01:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 210 @ 21589 updates, score 9.479) (writing took 0.8821370098739862 seconds)
2022-03-14 20:01:18 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-14 20:01:18 | INFO | train | epoch 210 | loss 3.914 | ppl 15.08 | wps 40251.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21589 | lr 0.000215221 | gnorm 1.053 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35177
KL Stats: Epoch 210 Divergences: Uniform: 5.322739213843168 Unigram: 5.4673213680950585
2022-03-14 20:01:18 | INFO | fairseq.trainer | begin training epoch 211
2022-03-14 20:01:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:01:35 | INFO | train_inner | epoch 211:     11 / 103 loss=3.915, ppl=15.09, wps=40212.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21600, lr=0.000215166, gnorm=1.051, loss_scale=16, train_wall=153, gb_free=20.8, wall=35195
2022-03-14 20:04:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:04:04 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 9.481 | ppl 714.83 | wps 66268.6 | wpb 2040.3 | bsz 4 | num_updates 21692 | best_loss 7.59
2022-03-14 20:04:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 21692 updates
2022-03-14 20:04:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:04:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:04:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 211 @ 21692 updates, score 9.481) (writing took 0.9285395331680775 seconds)
2022-03-14 20:04:05 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-14 20:04:05 | INFO | train | epoch 211 | loss 3.913 | ppl 15.06 | wps 40235.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21692 | lr 0.000214709 | gnorm 1.056 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35344
KL Stats: Epoch 211 Divergences: Uniform: 5.3215385793368135 Unigram: 5.468350104682364
2022-03-14 20:04:05 | INFO | fairseq.trainer | begin training epoch 212
2022-03-14 20:04:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:04:18 | INFO | train_inner | epoch 212:      8 / 103 loss=3.916, ppl=15.09, wps=40204.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21700, lr=0.000214669, gnorm=1.058, loss_scale=16, train_wall=153, gb_free=20.8, wall=35357
2022-03-14 20:06:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:06:51 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 9.483 | ppl 715.4 | wps 66146.5 | wpb 2040.3 | bsz 4 | num_updates 21795 | best_loss 7.59
2022-03-14 20:06:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 21795 updates
2022-03-14 20:06:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:06:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:06:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 212 @ 21795 updates, score 9.483) (writing took 0.8761979760602117 seconds)
2022-03-14 20:06:52 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-14 20:06:52 | INFO | train | epoch 212 | loss 3.91 | ppl 15.03 | wps 40242.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21795 | lr 0.000214201 | gnorm 1.058 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35512
KL Stats: Epoch 212 Divergences: Uniform: 5.3238954093711435 Unigram: 5.4720886561571564
2022-03-14 20:06:52 | INFO | fairseq.trainer | begin training epoch 213
2022-03-14 20:06:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:07:00 | INFO | train_inner | epoch 213:      5 / 103 loss=3.91, ppl=15.04, wps=40211, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21800, lr=0.000214176, gnorm=1.06, loss_scale=16, train_wall=153, gb_free=20.8, wall=35520
2022-03-14 20:08:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 20:09:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:09:38 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 9.494 | ppl 721.19 | wps 66122.1 | wpb 2040.3 | bsz 4 | num_updates 21897 | best_loss 7.59
2022-03-14 20:09:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 21897 updates
2022-03-14 20:09:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:09:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:09:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 213 @ 21897 updates, score 9.494) (writing took 0.8606478348374367 seconds)
2022-03-14 20:09:39 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-14 20:09:39 | INFO | train | epoch 213 | loss 3.905 | ppl 14.98 | wps 39846.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 21897 | lr 0.000213702 | gnorm 1.072 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35679
KL Stats: Epoch 213 Divergences: Uniform: 5.326416129336369 Unigram: 5.476978630719706
2022-03-14 20:09:39 | INFO | fairseq.trainer | begin training epoch 214
2022-03-14 20:09:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:09:44 | INFO | train_inner | epoch 214:      3 / 103 loss=3.907, ppl=15, wps=39814, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=21900, lr=0.000213687, gnorm=1.07, loss_scale=16, train_wall=155, gb_free=20.8, wall=35684
2022-03-14 20:12:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 20:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:12:26 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 9.51 | ppl 728.98 | wps 66510.5 | wpb 2040.3 | bsz 4 | num_updates 21999 | best_loss 7.59
2022-03-14 20:12:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 21999 updates
2022-03-14 20:12:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:12:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:12:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 214 @ 21999 updates, score 9.51) (writing took 0.8795942524448037 seconds)
2022-03-14 20:12:26 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-14 20:12:26 | INFO | train | epoch 214 | loss 3.902 | ppl 14.95 | wps 39835.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 21999 | lr 0.000213206 | gnorm 1.07 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 35846
KL Stats: Epoch 214 Divergences: Uniform: 5.326806429687253 Unigram: 5.478555334048396
2022-03-14 20:12:26 | INFO | fairseq.trainer | begin training epoch 215
2022-03-14 20:12:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:12:28 | INFO | train_inner | epoch 215:      1 / 103 loss=3.903, ppl=14.96, wps=39806.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=22000, lr=0.000213201, gnorm=1.071, loss_scale=8, train_wall=155, gb_free=20.8, wall=35848
2022-03-14 20:15:07 | INFO | train_inner | epoch 215:    101 / 103 loss=3.899, ppl=14.92, wps=41346.4, ups=0.63, wpb=65530.9, bsz=128, num_updates=22100, lr=0.000212718, gnorm=1.053, loss_scale=8, train_wall=154, gb_free=20.8, wall=36006
2022-03-14 20:15:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:15:13 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 9.504 | ppl 726.24 | wps 66318 | wpb 2040.3 | bsz 4 | num_updates 22102 | best_loss 7.59
2022-03-14 20:15:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 22102 updates
2022-03-14 20:15:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:15:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:15:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 215 @ 22102 updates, score 9.504) (writing took 0.8813245994970202 seconds)
2022-03-14 20:15:14 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-14 20:15:14 | INFO | train | epoch 215 | loss 3.899 | ppl 14.92 | wps 40221.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22102 | lr 0.000212708 | gnorm 1.054 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 36013
KL Stats: Epoch 215 Divergences: Uniform: 5.330591632706929 Unigram: 5.483043934554464
2022-03-14 20:15:14 | INFO | fairseq.trainer | begin training epoch 216
2022-03-14 20:15:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:17:49 | INFO | train_inner | epoch 216:     98 / 103 loss=3.896, ppl=14.89, wps=40225.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22200, lr=0.000212238, gnorm=1.069, loss_scale=8, train_wall=153, gb_free=20.8, wall=36169
2022-03-14 20:17:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:18:00 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 9.505 | ppl 726.81 | wps 66255 | wpb 2040.3 | bsz 4 | num_updates 22205 | best_loss 7.59
2022-03-14 20:18:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 22205 updates
2022-03-14 20:18:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:18:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:18:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 216 @ 22205 updates, score 9.505) (writing took 0.8787071276456118 seconds)
2022-03-14 20:18:01 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-14 20:18:01 | INFO | train | epoch 216 | loss 3.897 | ppl 14.9 | wps 40260.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22205 | lr 0.000212214 | gnorm 1.069 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 36180
KL Stats: Epoch 216 Divergences: Uniform: 5.3324282497112785 Unigram: 5.486729645387089
2022-03-14 20:18:01 | INFO | fairseq.trainer | begin training epoch 217
2022-03-14 20:18:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:20:31 | INFO | train_inner | epoch 217:     95 / 103 loss=3.894, ppl=14.86, wps=40217.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=22300, lr=0.000211762, gnorm=1.055, loss_scale=8, train_wall=153, gb_free=20.8, wall=36331
2022-03-14 20:20:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:20:47 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 9.522 | ppl 734.99 | wps 66115.1 | wpb 2040.3 | bsz 4 | num_updates 22308 | best_loss 7.59
2022-03-14 20:20:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 22308 updates
2022-03-14 20:20:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:20:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:20:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 217 @ 22308 updates, score 9.522) (writing took 0.911662700586021 seconds)
2022-03-14 20:20:48 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-14 20:20:48 | INFO | train | epoch 217 | loss 3.895 | ppl 14.88 | wps 40241.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22308 | lr 0.000211724 | gnorm 1.051 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 36348
KL Stats: Epoch 217 Divergences: Uniform: 5.33274339856186 Unigram: 5.490022842670986
2022-03-14 20:20:48 | INFO | fairseq.trainer | begin training epoch 218
2022-03-14 20:20:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:23:14 | INFO | train_inner | epoch 218:     92 / 103 loss=3.889, ppl=14.82, wps=40209.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=22400, lr=0.000211289, gnorm=1.065, loss_scale=8, train_wall=153, gb_free=20.8, wall=36493
2022-03-14 20:23:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:23:34 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 9.511 | ppl 729.68 | wps 66116.7 | wpb 2040.3 | bsz 4 | num_updates 22411 | best_loss 7.59
2022-03-14 20:23:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 22411 updates
2022-03-14 20:23:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:23:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:23:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 218 @ 22411 updates, score 9.511) (writing took 0.8668604791164398 seconds)
2022-03-14 20:23:35 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-14 20:23:35 | INFO | train | epoch 218 | loss 3.893 | ppl 14.86 | wps 40254.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22411 | lr 0.000211237 | gnorm 1.07 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 36515
KL Stats: Epoch 218 Divergences: Uniform: 5.33369893098237 Unigram: 5.492226994673352
2022-03-14 20:23:35 | INFO | fairseq.trainer | begin training epoch 219
2022-03-14 20:23:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:25:56 | INFO | train_inner | epoch 219:     89 / 103 loss=3.89, ppl=14.82, wps=40232.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=22500, lr=0.000210819, gnorm=1.061, loss_scale=8, train_wall=153, gb_free=20.8, wall=36656
2022-03-14 20:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:26:21 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 9.524 | ppl 736.06 | wps 66265.1 | wpb 2040.3 | bsz 4 | num_updates 22514 | best_loss 7.59
2022-03-14 20:26:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 22514 updates
2022-03-14 20:26:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:26:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:26:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 219 @ 22514 updates, score 9.524) (writing took 0.8693230655044317 seconds)
2022-03-14 20:26:22 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-14 20:26:22 | INFO | train | epoch 219 | loss 3.889 | ppl 14.81 | wps 40248.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22514 | lr 0.000210753 | gnorm 1.061 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36682
KL Stats: Epoch 219 Divergences: Uniform: 5.33607464026072 Unigram: 5.495188697991717
2022-03-14 20:26:22 | INFO | fairseq.trainer | begin training epoch 220
2022-03-14 20:26:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:28:39 | INFO | train_inner | epoch 220:     86 / 103 loss=3.883, ppl=14.76, wps=40197.5, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=22600, lr=0.000210352, gnorm=1.06, loss_scale=16, train_wall=153, gb_free=20.8, wall=36818
2022-03-14 20:29:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:29:08 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 9.525 | ppl 736.53 | wps 66246.7 | wpb 2040.3 | bsz 4 | num_updates 22617 | best_loss 7.59
2022-03-14 20:29:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 22617 updates
2022-03-14 20:29:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:29:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:29:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 220 @ 22617 updates, score 9.525) (writing took 0.855782057158649 seconds)
2022-03-14 20:29:09 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-14 20:29:09 | INFO | train | epoch 220 | loss 3.886 | ppl 14.78 | wps 40248.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22617 | lr 0.000210273 | gnorm 1.057 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36849
KL Stats: Epoch 220 Divergences: Uniform: 5.3386251007646885 Unigram: 5.500261695948801
2022-03-14 20:29:09 | INFO | fairseq.trainer | begin training epoch 221
2022-03-14 20:29:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:31:21 | INFO | train_inner | epoch 221:     83 / 103 loss=3.884, ppl=14.76, wps=40220.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22700, lr=0.000209888, gnorm=1.062, loss_scale=16, train_wall=153, gb_free=20.8, wall=36980
2022-03-14 20:31:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 20:31:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:31:56 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 9.52 | ppl 734.4 | wps 66006 | wpb 2040.3 | bsz 4 | num_updates 22719 | best_loss 7.59
2022-03-14 20:31:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 22719 updates
2022-03-14 20:31:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:31:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:31:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 221 @ 22719 updates, score 9.52) (writing took 0.8779788240790367 seconds)
2022-03-14 20:31:56 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-14 20:31:56 | INFO | train | epoch 221 | loss 3.882 | ppl 14.75 | wps 39864 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 22719 | lr 0.0002098 | gnorm 1.064 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 37016
KL Stats: Epoch 221 Divergences: Uniform: 5.338862454623762 Unigram: 5.502751632471565
2022-03-14 20:31:56 | INFO | fairseq.trainer | begin training epoch 222
2022-03-14 20:31:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:34:05 | INFO | train_inner | epoch 222:     81 / 103 loss=3.879, ppl=14.71, wps=39840, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=22800, lr=0.000209427, gnorm=1.047, loss_scale=8, train_wall=154, gb_free=20.8, wall=37144
2022-03-14 20:34:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:34:43 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 9.53 | ppl 739.05 | wps 65884.8 | wpb 2040.3 | bsz 4 | num_updates 22822 | best_loss 7.59
2022-03-14 20:34:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 22822 updates
2022-03-14 20:34:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:34:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:34:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 222 @ 22822 updates, score 9.53) (writing took 0.8612008215859532 seconds)
2022-03-14 20:34:44 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-14 20:34:44 | INFO | train | epoch 222 | loss 3.882 | ppl 14.74 | wps 40263.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22822 | lr 0.000209326 | gnorm 1.047 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 37183
KL Stats: Epoch 222 Divergences: Uniform: 5.340713401996463 Unigram: 5.504321240098567
2022-03-14 20:34:44 | INFO | fairseq.trainer | begin training epoch 223
2022-03-14 20:34:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:36:47 | INFO | train_inner | epoch 223:     78 / 103 loss=3.878, ppl=14.7, wps=40219.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22900, lr=0.000208969, gnorm=1.068, loss_scale=8, train_wall=153, gb_free=20.8, wall=37307
2022-03-14 20:37:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:37:30 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 9.523 | ppl 735.5 | wps 66309.7 | wpb 2040.3 | bsz 4 | num_updates 22925 | best_loss 7.59
2022-03-14 20:37:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 22925 updates
2022-03-14 20:37:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:37:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:37:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 223 @ 22925 updates, score 9.523) (writing took 0.8836210891604424 seconds)
2022-03-14 20:37:31 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-14 20:37:31 | INFO | train | epoch 223 | loss 3.878 | ppl 14.71 | wps 40242.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22925 | lr 0.000208855 | gnorm 1.063 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 37350
KL Stats: Epoch 223 Divergences: Uniform: 5.341631508294428 Unigram: 5.508379629878009
2022-03-14 20:37:31 | INFO | fairseq.trainer | begin training epoch 224
2022-03-14 20:37:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:39:30 | INFO | train_inner | epoch 224:     75 / 103 loss=3.875, ppl=14.67, wps=40208.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23000, lr=0.000208514, gnorm=1.061, loss_scale=8, train_wall=153, gb_free=20.8, wall=37469
2022-03-14 20:40:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:40:17 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 9.533 | ppl 740.86 | wps 65666.5 | wpb 2040.3 | bsz 4 | num_updates 23028 | best_loss 7.59
2022-03-14 20:40:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 23028 updates
2022-03-14 20:40:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:40:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:40:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 224 @ 23028 updates, score 9.533) (writing took 0.9459213642403483 seconds)
2022-03-14 20:40:18 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-14 20:40:18 | INFO | train | epoch 224 | loss 3.874 | ppl 14.67 | wps 40221.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23028 | lr 0.000208388 | gnorm 1.066 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 37518
KL Stats: Epoch 224 Divergences: Uniform: 5.343963914726007 Unigram: 5.513373266418614
2022-03-14 20:40:18 | INFO | fairseq.trainer | begin training epoch 225
2022-03-14 20:40:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:42:12 | INFO | train_inner | epoch 225:     72 / 103 loss=3.873, ppl=14.65, wps=40196.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23100, lr=0.000208063, gnorm=1.061, loss_scale=8, train_wall=153, gb_free=20.8, wall=37632
2022-03-14 20:43:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:43:04 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 9.559 | ppl 754.15 | wps 66242.2 | wpb 2040.3 | bsz 4 | num_updates 23131 | best_loss 7.59
2022-03-14 20:43:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 23131 updates
2022-03-14 20:43:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:43:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:43:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 225 @ 23131 updates, score 9.559) (writing took 0.8933630883693695 seconds)
2022-03-14 20:43:05 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-14 20:43:05 | INFO | train | epoch 225 | loss 3.873 | ppl 14.65 | wps 40262 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23131 | lr 0.000207923 | gnorm 1.065 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 37685
KL Stats: Epoch 225 Divergences: Uniform: 5.34498578969851 Unigram: 5.515446299882266
2022-03-14 20:43:05 | INFO | fairseq.trainer | begin training epoch 226
2022-03-14 20:43:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:44:54 | INFO | train_inner | epoch 226:     69 / 103 loss=3.869, ppl=14.61, wps=40221.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23200, lr=0.000207614, gnorm=1.069, loss_scale=8, train_wall=153, gb_free=20.8, wall=37794
2022-03-14 20:45:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:45:51 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 9.556 | ppl 752.78 | wps 66175 | wpb 2040.3 | bsz 4 | num_updates 23234 | best_loss 7.59
2022-03-14 20:45:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 23234 updates
2022-03-14 20:45:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:45:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:45:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 226 @ 23234 updates, score 9.556) (writing took 0.8625407759100199 seconds)
2022-03-14 20:45:52 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-14 20:45:52 | INFO | train | epoch 226 | loss 3.869 | ppl 14.61 | wps 40241.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23234 | lr 0.000207462 | gnorm 1.067 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37852
KL Stats: Epoch 226 Divergences: Uniform: 5.348958707039915 Unigram: 5.521579918505384
2022-03-14 20:45:52 | INFO | fairseq.trainer | begin training epoch 227
2022-03-14 20:45:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:47:37 | INFO | train_inner | epoch 227:     66 / 103 loss=3.868, ppl=14.6, wps=40216.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23300, lr=0.000207168, gnorm=1.061, loss_scale=16, train_wall=153, gb_free=20.8, wall=37956
2022-03-14 20:48:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:48:38 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 9.554 | ppl 751.46 | wps 66198.2 | wpb 2040.3 | bsz 4 | num_updates 23337 | best_loss 7.59
2022-03-14 20:48:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 23337 updates
2022-03-14 20:48:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:48:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:48:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 227 @ 23337 updates, score 9.554) (writing took 0.8507722904905677 seconds)
2022-03-14 20:48:39 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-14 20:48:39 | INFO | train | epoch 227 | loss 3.867 | ppl 14.59 | wps 40249.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23337 | lr 0.000207003 | gnorm 1.063 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38019
KL Stats: Epoch 227 Divergences: Uniform: 5.348805769457016 Unigram: 5.5222065186579465
2022-03-14 20:48:39 | INFO | fairseq.trainer | begin training epoch 228
2022-03-14 20:48:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:50:19 | INFO | train_inner | epoch 228:     63 / 103 loss=3.862, ppl=14.55, wps=40226.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23400, lr=0.000206725, gnorm=1.056, loss_scale=16, train_wall=153, gb_free=20.8, wall=38119
2022-03-14 20:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:51:26 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 9.567 | ppl 758.64 | wps 66228.2 | wpb 2040.3 | bsz 4 | num_updates 23440 | best_loss 7.59
2022-03-14 20:51:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 23440 updates
2022-03-14 20:51:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:51:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:51:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 228 @ 23440 updates, score 9.567) (writing took 0.8543034009635448 seconds)
2022-03-14 20:51:26 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-14 20:51:26 | INFO | train | epoch 228 | loss 3.864 | ppl 14.56 | wps 40261.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23440 | lr 0.000206548 | gnorm 1.055 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38186
KL Stats: Epoch 228 Divergences: Uniform: 5.351261651564188 Unigram: 5.526379840397668
2022-03-14 20:51:26 | INFO | fairseq.trainer | begin training epoch 229
2022-03-14 20:51:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:53:02 | INFO | train_inner | epoch 229:     60 / 103 loss=3.863, ppl=14.55, wps=40221, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23500, lr=0.000206284, gnorm=1.071, loss_scale=16, train_wall=153, gb_free=20.8, wall=38281
2022-03-14 20:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:54:13 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 9.562 | ppl 755.91 | wps 66299.4 | wpb 2040.3 | bsz 4 | num_updates 23543 | best_loss 7.59
2022-03-14 20:54:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 23543 updates
2022-03-14 20:54:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:54:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:54:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 229 @ 23543 updates, score 9.562) (writing took 0.8447283208370209 seconds)
2022-03-14 20:54:14 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-14 20:54:14 | INFO | train | epoch 229 | loss 3.861 | ppl 14.53 | wps 40243.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23543 | lr 0.000206096 | gnorm 1.078 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38353
KL Stats: Epoch 229 Divergences: Uniform: 5.35221548329473 Unigram: 5.528940220587654
2022-03-14 20:54:14 | INFO | fairseq.trainer | begin training epoch 230
2022-03-14 20:54:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:55:44 | INFO | train_inner | epoch 230:     57 / 103 loss=3.86, ppl=14.52, wps=40222.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=23600, lr=0.000205847, gnorm=1.074, loss_scale=16, train_wall=153, gb_free=20.8, wall=38443
2022-03-14 20:56:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:57:00 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 9.586 | ppl 768.49 | wps 66095.7 | wpb 2040.3 | bsz 4 | num_updates 23646 | best_loss 7.59
2022-03-14 20:57:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 23646 updates
2022-03-14 20:57:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:57:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:57:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 230 @ 23646 updates, score 9.586) (writing took 0.8700773315504193 seconds)
2022-03-14 20:57:01 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-14 20:57:01 | INFO | train | epoch 230 | loss 3.859 | ppl 14.51 | wps 40248.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23646 | lr 0.000205646 | gnorm 1.064 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38520
KL Stats: Epoch 230 Divergences: Uniform: 5.354291544384973 Unigram: 5.532057543912764
2022-03-14 20:57:01 | INFO | fairseq.trainer | begin training epoch 231
2022-03-14 20:57:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:58:26 | INFO | train_inner | epoch 231:     54 / 103 loss=3.856, ppl=14.48, wps=40206, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23700, lr=0.000205412, gnorm=1.06, loss_scale=16, train_wall=153, gb_free=20.8, wall=38606
2022-03-14 20:59:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 20:59:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:59:47 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 9.587 | ppl 768.95 | wps 66320.6 | wpb 2040.3 | bsz 4 | num_updates 23748 | best_loss 7.59
2022-03-14 20:59:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 23748 updates
2022-03-14 20:59:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:59:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 20:59:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 231 @ 23748 updates, score 9.587) (writing took 0.9031870132312179 seconds)
2022-03-14 20:59:48 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-14 20:59:48 | INFO | train | epoch 231 | loss 3.856 | ppl 14.48 | wps 39821.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 23748 | lr 0.000205204 | gnorm 1.064 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38688
KL Stats: Epoch 231 Divergences: Uniform: 5.356475604759853 Unigram: 5.537261666020473
2022-03-14 20:59:48 | INFO | fairseq.trainer | begin training epoch 232
2022-03-14 20:59:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:01:10 | INFO | train_inner | epoch 232:     52 / 103 loss=3.856, ppl=14.48, wps=39796.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=23800, lr=0.00020498, gnorm=1.058, loss_scale=16, train_wall=154, gb_free=20.8, wall=38770
2022-03-14 21:01:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 21:02:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:02:34 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 9.576 | ppl 763.29 | wps 66319.9 | wpb 2040.3 | bsz 4 | num_updates 23850 | best_loss 7.59
2022-03-14 21:02:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 23850 updates
2022-03-14 21:02:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:02:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:02:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 232 @ 23850 updates, score 9.576) (writing took 0.8964789789170027 seconds)
2022-03-14 21:02:35 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-14 21:02:35 | INFO | train | epoch 232 | loss 3.854 | ppl 14.46 | wps 39866.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 23850 | lr 0.000204765 | gnorm 1.069 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 38855
KL Stats: Epoch 232 Divergences: Uniform: 5.354671006029079 Unigram: 5.535683911580643
2022-03-14 21:02:35 | INFO | fairseq.trainer | begin training epoch 233
2022-03-14 21:02:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:03:54 | INFO | train_inner | epoch 233:     50 / 103 loss=3.854, ppl=14.46, wps=39827.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=23900, lr=0.000204551, gnorm=1.076, loss_scale=8, train_wall=154, gb_free=20.8, wall=38934
2022-03-14 21:05:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:05:21 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 9.57 | ppl 760.07 | wps 66304 | wpb 2040.3 | bsz 4 | num_updates 23953 | best_loss 7.59
2022-03-14 21:05:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 23953 updates
2022-03-14 21:05:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:05:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:05:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 233 @ 23953 updates, score 9.57) (writing took 1.2153481571003795 seconds)
2022-03-14 21:05:23 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-14 21:05:23 | INFO | train | epoch 233 | loss 3.851 | ppl 14.43 | wps 40154.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 23953 | lr 0.000204324 | gnorm 1.062 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 39022
KL Stats: Epoch 233 Divergences: Uniform: 5.357491313012569 Unigram: 5.540017191194883
2022-03-14 21:05:23 | INFO | fairseq.trainer | begin training epoch 234
2022-03-14 21:05:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:06:37 | INFO | train_inner | epoch 234:     47 / 103 loss=3.847, ppl=14.39, wps=40123.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=24000, lr=0.000204124, gnorm=1.064, loss_scale=8, train_wall=153, gb_free=20.8, wall=39097
2022-03-14 21:08:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:08:09 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 9.578 | ppl 764.09 | wps 66114.8 | wpb 2040.3 | bsz 4 | num_updates 24056 | best_loss 7.59
2022-03-14 21:08:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 24056 updates
2022-03-14 21:08:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:08:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:08:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 234 @ 24056 updates, score 9.578) (writing took 0.8538526939228177 seconds)
2022-03-14 21:08:10 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-14 21:08:10 | INFO | train | epoch 234 | loss 3.85 | ppl 14.42 | wps 40252.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24056 | lr 0.000203886 | gnorm 1.067 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 39189
KL Stats: Epoch 234 Divergences: Uniform: 5.357277117129764 Unigram: 5.541590123318627
2022-03-14 21:08:10 | INFO | fairseq.trainer | begin training epoch 235
2022-03-14 21:08:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:09:20 | INFO | train_inner | epoch 235:     44 / 103 loss=3.85, ppl=14.42, wps=40212.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=24100, lr=0.0002037, gnorm=1.064, loss_scale=8, train_wall=153, gb_free=20.8, wall=39259
2022-03-14 21:10:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:10:56 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 9.579 | ppl 764.97 | wps 66327.8 | wpb 2040.3 | bsz 4 | num_updates 24159 | best_loss 7.59
2022-03-14 21:10:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 24159 updates
2022-03-14 21:10:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:10:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:10:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 235 @ 24159 updates, score 9.579) (writing took 0.8774468479678035 seconds)
2022-03-14 21:10:57 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-14 21:10:57 | INFO | train | epoch 235 | loss 3.846 | ppl 14.38 | wps 40243.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24159 | lr 0.000203451 | gnorm 1.063 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 39357
KL Stats: Epoch 235 Divergences: Uniform: 5.361177878258815 Unigram: 5.546198869952826
2022-03-14 21:10:57 | INFO | fairseq.trainer | begin training epoch 236
2022-03-14 21:10:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:12:02 | INFO | train_inner | epoch 236:     41 / 103 loss=3.845, ppl=14.37, wps=40217.2, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=24200, lr=0.000203279, gnorm=1.072, loss_scale=8, train_wall=153, gb_free=20.8, wall=39422
2022-03-14 21:13:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:13:43 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 9.592 | ppl 771.95 | wps 66118.9 | wpb 2040.3 | bsz 4 | num_updates 24262 | best_loss 7.59
2022-03-14 21:13:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 24262 updates
2022-03-14 21:13:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:13:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:13:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 236 @ 24262 updates, score 9.592) (writing took 0.9039615662768483 seconds)
2022-03-14 21:13:44 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-14 21:13:44 | INFO | train | epoch 236 | loss 3.844 | ppl 14.36 | wps 40227.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24262 | lr 0.000203019 | gnorm 1.065 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 39524
KL Stats: Epoch 236 Divergences: Uniform: 5.361221792383113 Unigram: 5.549095461902569
2022-03-14 21:13:44 | INFO | fairseq.trainer | begin training epoch 237
2022-03-14 21:13:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:14:44 | INFO | train_inner | epoch 237:     38 / 103 loss=3.842, ppl=14.34, wps=40192.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=24300, lr=0.00020286, gnorm=1.059, loss_scale=8, train_wall=153, gb_free=20.8, wall=39584
2022-03-14 21:16:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:16:30 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 9.599 | ppl 775.24 | wps 66113 | wpb 2040.3 | bsz 4 | num_updates 24365 | best_loss 7.59
2022-03-14 21:16:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 24365 updates
2022-03-14 21:16:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:16:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:16:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 237 @ 24365 updates, score 9.599) (writing took 0.8981808675453067 seconds)
2022-03-14 21:16:31 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-14 21:16:31 | INFO | train | epoch 237 | loss 3.843 | ppl 14.35 | wps 40245.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24365 | lr 0.000202589 | gnorm 1.066 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39691
KL Stats: Epoch 237 Divergences: Uniform: 5.363817397493262 Unigram: 5.552054402055702
2022-03-14 21:16:31 | INFO | fairseq.trainer | begin training epoch 238
2022-03-14 21:16:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:17:27 | INFO | train_inner | epoch 238:     35 / 103 loss=3.845, ppl=14.37, wps=40217.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=24400, lr=0.000202444, gnorm=1.065, loss_scale=16, train_wall=153, gb_free=20.8, wall=39746
2022-03-14 21:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:19:18 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 9.594 | ppl 772.76 | wps 66144.9 | wpb 2040.3 | bsz 4 | num_updates 24468 | best_loss 7.59
2022-03-14 21:19:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 24468 updates
2022-03-14 21:19:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:19:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:19:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 238 @ 24468 updates, score 9.594) (writing took 0.9936489202082157 seconds)
2022-03-14 21:19:19 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-14 21:19:19 | INFO | train | epoch 238 | loss 3.839 | ppl 14.31 | wps 40216.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24468 | lr 0.000202163 | gnorm 1.059 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39858
KL Stats: Epoch 238 Divergences: Uniform: 5.365022263942548 Unigram: 5.55619052565681
2022-03-14 21:19:19 | INFO | fairseq.trainer | begin training epoch 239
2022-03-14 21:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:20:09 | INFO | train_inner | epoch 239:     32 / 103 loss=3.837, ppl=14.29, wps=40190.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24500, lr=0.000202031, gnorm=1.068, loss_scale=16, train_wall=153, gb_free=20.8, wall=39909
2022-03-14 21:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:22:05 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 9.58 | ppl 765.41 | wps 66122.8 | wpb 2040.3 | bsz 4 | num_updates 24571 | best_loss 7.59
2022-03-14 21:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 24571 updates
2022-03-14 21:22:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:22:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:22:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 239 @ 24571 updates, score 9.58) (writing took 0.9994866326451302 seconds)
2022-03-14 21:22:06 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-14 21:22:06 | INFO | train | epoch 239 | loss 3.837 | ppl 14.29 | wps 40210.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24571 | lr 0.000201738 | gnorm 1.082 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40025
KL Stats: Epoch 239 Divergences: Uniform: 5.3666435052998676 Unigram: 5.558136631417423
2022-03-14 21:22:06 | INFO | fairseq.trainer | begin training epoch 240
2022-03-14 21:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:22:52 | INFO | train_inner | epoch 240:     29 / 103 loss=3.838, ppl=14.3, wps=40163.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24600, lr=0.000201619, gnorm=1.071, loss_scale=16, train_wall=153, gb_free=20.8, wall=40071
2022-03-14 21:24:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:24:52 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 9.575 | ppl 762.78 | wps 65917.8 | wpb 2040.3 | bsz 4 | num_updates 24674 | best_loss 7.59
2022-03-14 21:24:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 24674 updates
2022-03-14 21:24:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:24:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:24:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 240 @ 24674 updates, score 9.575) (writing took 0.8714299062266946 seconds)
2022-03-14 21:24:53 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-14 21:24:53 | INFO | train | epoch 240 | loss 3.833 | ppl 14.25 | wps 40211.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24674 | lr 0.000201317 | gnorm 1.059 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40193
KL Stats: Epoch 240 Divergences: Uniform: 5.365333899665992 Unigram: 5.5587625491614725
2022-03-14 21:24:53 | INFO | fairseq.trainer | begin training epoch 241
2022-03-14 21:24:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:25:34 | INFO | train_inner | epoch 241:     26 / 103 loss=3.834, ppl=14.26, wps=40168.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24700, lr=0.000201211, gnorm=1.073, loss_scale=16, train_wall=153, gb_free=20.8, wall=40234
2022-03-14 21:27:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:27:40 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 9.614 | ppl 783.35 | wps 66277.1 | wpb 2040.3 | bsz 4 | num_updates 24777 | best_loss 7.59
2022-03-14 21:27:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 24777 updates
2022-03-14 21:27:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:27:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:27:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 241 @ 24777 updates, score 9.614) (writing took 1.1152902329340577 seconds)
2022-03-14 21:27:41 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-14 21:27:41 | INFO | train | epoch 241 | loss 3.833 | ppl 14.25 | wps 40125.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 24777 | lr 0.000200898 | gnorm 1.082 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40360
KL Stats: Epoch 241 Divergences: Uniform: 5.3682226749937865 Unigram: 5.565636934713214
2022-03-14 21:27:41 | INFO | fairseq.trainer | begin training epoch 242
2022-03-14 21:27:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:28:17 | INFO | train_inner | epoch 242:     23 / 103 loss=3.832, ppl=14.24, wps=40090.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=24800, lr=0.000200805, gnorm=1.074, loss_scale=16, train_wall=153, gb_free=20.8, wall=40397
2022-03-14 21:29:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 21:30:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:30:27 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 9.597 | ppl 774.47 | wps 66497.8 | wpb 2040.3 | bsz 4 | num_updates 24879 | best_loss 7.59
2022-03-14 21:30:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 24879 updates
2022-03-14 21:30:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:30:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:30:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 242 @ 24879 updates, score 9.597) (writing took 1.061378396116197 seconds)
2022-03-14 21:30:28 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-14 21:30:28 | INFO | train | epoch 242 | loss 3.828 | ppl 14.2 | wps 39767 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 24879 | lr 0.000200486 | gnorm 1.063 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40528
KL Stats: Epoch 242 Divergences: Uniform: 5.36876501951116 Unigram: 5.566650947887874
2022-03-14 21:30:28 | INFO | fairseq.trainer | begin training epoch 243
2022-03-14 21:30:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:31:02 | INFO | train_inner | epoch 243:     21 / 103 loss=3.83, ppl=14.22, wps=39739.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=24900, lr=0.000200401, gnorm=1.064, loss_scale=16, train_wall=155, gb_free=20.8, wall=40561
2022-03-14 21:33:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:33:15 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 9.597 | ppl 774.59 | wps 66304.6 | wpb 2040.3 | bsz 4 | num_updates 24982 | best_loss 7.59
2022-03-14 21:33:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 24982 updates
2022-03-14 21:33:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:33:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:33:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 243 @ 24982 updates, score 9.597) (writing took 0.881978421472013 seconds)
2022-03-14 21:33:16 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-14 21:33:16 | INFO | train | epoch 243 | loss 3.826 | ppl 14.18 | wps 40214.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24982 | lr 0.000200072 | gnorm 1.077 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40695
KL Stats: Epoch 243 Divergences: Uniform: 5.372873495115257 Unigram: 5.57059719300349
2022-03-14 21:33:16 | INFO | fairseq.trainer | begin training epoch 244
2022-03-14 21:33:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:33:44 | INFO | train_inner | epoch 244:     18 / 103 loss=3.826, ppl=14.18, wps=40182.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=25000, lr=0.0002, gnorm=1.081, loss_scale=16, train_wall=153, gb_free=20.8, wall=40724
2022-03-14 21:35:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:36:02 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 9.595 | ppl 773.57 | wps 65940 | wpb 2040.3 | bsz 4 | num_updates 25085 | best_loss 7.59
2022-03-14 21:36:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 25085 updates
2022-03-14 21:36:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:36:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:36:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 244 @ 25085 updates, score 9.595) (writing took 0.8776573687791824 seconds)
2022-03-14 21:36:03 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-14 21:36:03 | INFO | train | epoch 244 | loss 3.824 | ppl 14.16 | wps 40194.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25085 | lr 0.000199661 | gnorm 1.068 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40863
KL Stats: Epoch 244 Divergences: Uniform: 5.3709525286164865 Unigram: 5.5701622056978595
2022-03-14 21:36:03 | INFO | fairseq.trainer | begin training epoch 245
2022-03-14 21:36:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:36:27 | INFO | train_inner | epoch 245:     15 / 103 loss=3.824, ppl=14.17, wps=40149.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25100, lr=0.000199601, gnorm=1.06, loss_scale=16, train_wall=153, gb_free=20.8, wall=40886
2022-03-14 21:38:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:38:50 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 9.611 | ppl 781.79 | wps 66016.2 | wpb 2040.3 | bsz 4 | num_updates 25188 | best_loss 7.59
2022-03-14 21:38:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 25188 updates
2022-03-14 21:38:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:38:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:38:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 245 @ 25188 updates, score 9.611) (writing took 0.9308068715035915 seconds)
2022-03-14 21:38:51 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-14 21:38:51 | INFO | train | epoch 245 | loss 3.822 | ppl 14.14 | wps 40142.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25188 | lr 0.000199252 | gnorm 1.067 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41030
KL Stats: Epoch 245 Divergences: Uniform: 5.3738932363686205 Unigram: 5.575837238924869
2022-03-14 21:38:51 | INFO | fairseq.trainer | begin training epoch 246
2022-03-14 21:38:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:39:10 | INFO | train_inner | epoch 246:     12 / 103 loss=3.825, ppl=14.17, wps=40112.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=25200, lr=0.000199205, gnorm=1.077, loss_scale=16, train_wall=153, gb_free=20.8, wall=41049
2022-03-14 21:41:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:41:37 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 9.6 | ppl 776.11 | wps 65568.1 | wpb 2040.3 | bsz 4 | num_updates 25291 | best_loss 7.59
2022-03-14 21:41:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 25291 updates
2022-03-14 21:41:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:41:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:41:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 246 @ 25291 updates, score 9.6) (writing took 0.976639999076724 seconds)
2022-03-14 21:41:38 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-14 21:41:38 | INFO | train | epoch 246 | loss 3.82 | ppl 14.12 | wps 40091.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25291 | lr 0.000198846 | gnorm 1.079 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41198
KL Stats: Epoch 246 Divergences: Uniform: 5.3748587175869424 Unigram: 5.577281825215381
2022-03-14 21:41:38 | INFO | fairseq.trainer | begin training epoch 247
2022-03-14 21:41:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:41:53 | INFO | train_inner | epoch 247:      9 / 103 loss=3.822, ppl=14.14, wps=40049.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25300, lr=0.000198811, gnorm=1.076, loss_scale=16, train_wall=153, gb_free=20.8, wall=41212
2022-03-14 21:43:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 21:44:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:44:25 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 9.615 | ppl 784.32 | wps 65567.6 | wpb 2040.3 | bsz 4 | num_updates 25393 | best_loss 7.59
2022-03-14 21:44:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 25393 updates
2022-03-14 21:44:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:44:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:44:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 247 @ 25393 updates, score 9.615) (writing took 1.0306127285584807 seconds)
2022-03-14 21:44:26 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-14 21:44:26 | INFO | train | epoch 247 | loss 3.816 | ppl 14.08 | wps 39683.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 25393 | lr 0.000198446 | gnorm 1.063 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41366
KL Stats: Epoch 247 Divergences: Uniform: 5.376957564794127 Unigram: 5.581973059381707
2022-03-14 21:44:26 | INFO | fairseq.trainer | begin training epoch 248
2022-03-14 21:44:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:44:37 | INFO | train_inner | epoch 248:      7 / 103 loss=3.816, ppl=14.08, wps=39661.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25400, lr=0.000198419, gnorm=1.062, loss_scale=16, train_wall=155, gb_free=20.8, wall=41377
2022-03-14 21:47:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:47:13 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 9.638 | ppl 796.48 | wps 66299.8 | wpb 2040.3 | bsz 4 | num_updates 25496 | best_loss 7.59
2022-03-14 21:47:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 25496 updates
2022-03-14 21:47:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:47:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:47:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 248 @ 25496 updates, score 9.638) (writing took 0.9319632304832339 seconds)
2022-03-14 21:47:14 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-14 21:47:14 | INFO | train | epoch 248 | loss 3.816 | ppl 14.09 | wps 40143 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25496 | lr 0.000198045 | gnorm 1.071 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41533
KL Stats: Epoch 248 Divergences: Uniform: 5.375856434400137 Unigram: 5.5820179158162
2022-03-14 21:47:14 | INFO | fairseq.trainer | begin training epoch 249
2022-03-14 21:47:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:47:20 | INFO | train_inner | epoch 249:      4 / 103 loss=3.818, ppl=14.1, wps=40109.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25500, lr=0.00019803, gnorm=1.072, loss_scale=16, train_wall=153, gb_free=20.8, wall=41540
2022-03-14 21:48:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 21:49:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:50:00 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 9.621 | ppl 787.68 | wps 66036.1 | wpb 2040.3 | bsz 4 | num_updates 25598 | best_loss 7.59
2022-03-14 21:50:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 25598 updates
2022-03-14 21:50:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:50:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:50:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 249 @ 25598 updates, score 9.621) (writing took 0.9052184512838721 seconds)
2022-03-14 21:50:01 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-14 21:50:01 | INFO | train | epoch 249 | loss 3.812 | ppl 14.05 | wps 39787.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 25598 | lr 0.00019765 | gnorm 1.073 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 41701
KL Stats: Epoch 249 Divergences: Uniform: 5.379136227982673 Unigram: 5.586157429854016
2022-03-14 21:50:01 | INFO | fairseq.trainer | begin training epoch 250
2022-03-14 21:50:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:50:04 | INFO | train_inner | epoch 250:      2 / 103 loss=3.813, ppl=14.06, wps=39757.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25600, lr=0.000197642, gnorm=1.073, loss_scale=8, train_wall=155, gb_free=20.8, wall=41704
2022-03-14 21:52:43 | INFO | train_inner | epoch 250:    102 / 103 loss=3.813, ppl=14.05, wps=41281.8, ups=0.63, wpb=65530.9, bsz=128, num_updates=25700, lr=0.000197257, gnorm=1.065, loss_scale=8, train_wall=154, gb_free=20.8, wall=41863
2022-03-14 21:52:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:52:48 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 9.631 | ppl 792.66 | wps 66089.1 | wpb 2040.3 | bsz 4 | num_updates 25701 | best_loss 7.59
2022-03-14 21:52:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 25701 updates
2022-03-14 21:52:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:52:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:52:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 250 @ 25701 updates, score 9.631) (writing took 0.9166410025209188 seconds)
2022-03-14 21:52:49 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-14 21:52:49 | INFO | train | epoch 250 | loss 3.812 | ppl 14.04 | wps 40151 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25701 | lr 0.000197254 | gnorm 1.066 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 41868
KL Stats: Epoch 250 Divergences: Uniform: 5.3783971659529515 Unigram: 5.586296207951289
2022-03-14 21:52:49 | INFO | fairseq.trainer | begin training epoch 251
2022-03-14 21:52:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:55:26 | INFO | train_inner | epoch 251:     99 / 103 loss=3.808, ppl=14, wps=40116.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25800, lr=0.000196875, gnorm=1.072, loss_scale=8, train_wall=153, gb_free=20.8, wall=42026
2022-03-14 21:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:55:35 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 9.628 | ppl 791.15 | wps 65719.3 | wpb 2040.3 | bsz 4 | num_updates 25804 | best_loss 7.59
2022-03-14 21:55:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 25804 updates
2022-03-14 21:55:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:55:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:55:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 251 @ 25804 updates, score 9.628) (writing took 0.8698051664978266 seconds)
2022-03-14 21:55:36 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-14 21:55:36 | INFO | train | epoch 251 | loss 3.809 | ppl 14.02 | wps 40155 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25804 | lr 0.00019686 | gnorm 1.072 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 42036
KL Stats: Epoch 251 Divergences: Uniform: 5.380687393954503 Unigram: 5.589749317232323
2022-03-14 21:55:36 | INFO | fairseq.trainer | begin training epoch 252
2022-03-14 21:55:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:58:09 | INFO | train_inner | epoch 252:     96 / 103 loss=3.805, ppl=13.98, wps=40153.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25900, lr=0.000196494, gnorm=1.06, loss_scale=8, train_wall=153, gb_free=20.8, wall=42188
2022-03-14 21:58:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:58:23 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 9.627 | ppl 790.43 | wps 66259 | wpb 2040.3 | bsz 4 | num_updates 25907 | best_loss 7.59
2022-03-14 21:58:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 25907 updates
2022-03-14 21:58:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:58:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 21:58:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 252 @ 25907 updates, score 9.627) (writing took 0.8857192872092128 seconds)
2022-03-14 21:58:24 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-14 21:58:24 | INFO | train | epoch 252 | loss 3.806 | ppl 13.99 | wps 40191.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25907 | lr 0.000196468 | gnorm 1.063 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 42203
KL Stats: Epoch 252 Divergences: Uniform: 5.380601327425419 Unigram: 5.594272922180558
2022-03-14 21:58:24 | INFO | fairseq.trainer | begin training epoch 253
2022-03-14 21:58:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:00:51 | INFO | train_inner | epoch 253:     93 / 103 loss=3.801, ppl=13.94, wps=40166.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26000, lr=0.000196116, gnorm=1.071, loss_scale=8, train_wall=153, gb_free=20.8, wall=42351
2022-03-14 22:01:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:01:10 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 9.63 | ppl 792.25 | wps 66304.3 | wpb 2040.3 | bsz 4 | num_updates 26010 | best_loss 7.59
2022-03-14 22:01:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 26010 updates
2022-03-14 22:01:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:01:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:01:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 253 @ 26010 updates, score 9.63) (writing took 0.9380506426095963 seconds)
2022-03-14 22:01:11 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-14 22:01:11 | INFO | train | epoch 253 | loss 3.804 | ppl 13.97 | wps 40190 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26010 | lr 0.000196078 | gnorm 1.068 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 42371
KL Stats: Epoch 253 Divergences: Uniform: 5.3832172146173205 Unigram: 5.597565920241575
2022-03-14 22:01:11 | INFO | fairseq.trainer | begin training epoch 254
2022-03-14 22:01:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:03:34 | INFO | train_inner | epoch 254:     90 / 103 loss=3.801, ppl=13.94, wps=40142.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26100, lr=0.00019574, gnorm=1.073, loss_scale=16, train_wall=153, gb_free=20.8, wall=42514
2022-03-14 22:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:03:58 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 9.62 | ppl 787.01 | wps 66079.5 | wpb 2040.3 | bsz 4 | num_updates 26113 | best_loss 7.59
2022-03-14 22:03:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 26113 updates
2022-03-14 22:03:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:03:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:03:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 254 @ 26113 updates, score 9.62) (writing took 0.8695984538644552 seconds)
2022-03-14 22:03:58 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-14 22:03:58 | INFO | train | epoch 254 | loss 3.803 | ppl 13.95 | wps 40187 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26113 | lr 0.000195691 | gnorm 1.071 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42538
KL Stats: Epoch 254 Divergences: Uniform: 5.383192971507694 Unigram: 5.597913140187854
2022-03-14 22:03:58 | INFO | fairseq.trainer | begin training epoch 255
2022-03-14 22:03:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:06:17 | INFO | train_inner | epoch 255:     87 / 103 loss=3.802, ppl=13.95, wps=40142.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26200, lr=0.000195366, gnorm=1.091, loss_scale=16, train_wall=153, gb_free=20.8, wall=42676
2022-03-14 22:06:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:06:45 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 9.665 | ppl 811.69 | wps 65812.3 | wpb 2040.3 | bsz 4 | num_updates 26216 | best_loss 7.59
2022-03-14 22:06:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 26216 updates
2022-03-14 22:06:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:06:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:06:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 255 @ 26216 updates, score 9.665) (writing took 0.8886401997879148 seconds)
2022-03-14 22:06:46 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-14 22:06:46 | INFO | train | epoch 255 | loss 3.8 | ppl 13.93 | wps 40159.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 26216 | lr 0.000195307 | gnorm 1.093 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42706
KL Stats: Epoch 255 Divergences: Uniform: 5.385407378157082 Unigram: 5.603609638277245
2022-03-14 22:06:46 | INFO | fairseq.trainer | begin training epoch 256
2022-03-14 22:06:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:07:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 22:09:01 | INFO | train_inner | epoch 256:     85 / 103 loss=3.792, ppl=13.85, wps=39717.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26300, lr=0.000194994, gnorm=1.07, loss_scale=8, train_wall=155, gb_free=20.8, wall=42841
2022-03-14 22:09:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:09:33 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 9.66 | ppl 809.18 | wps 65864.2 | wpb 2040.3 | bsz 4 | num_updates 26318 | best_loss 7.59
2022-03-14 22:09:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 26318 updates
2022-03-14 22:09:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:09:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:09:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 256 @ 26318 updates, score 9.66) (writing took 0.9990245578810573 seconds)
2022-03-14 22:09:34 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-14 22:09:34 | INFO | train | epoch 256 | loss 3.796 | ppl 13.89 | wps 39727.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 26318 | lr 0.000194928 | gnorm 1.074 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 42873
KL Stats: Epoch 256 Divergences: Uniform: 5.387718019980023 Unigram: 5.607024856629113
2022-03-14 22:09:34 | INFO | fairseq.trainer | begin training epoch 257
2022-03-14 22:09:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:11:44 | INFO | train_inner | epoch 257:     82 / 103 loss=3.795, ppl=13.88, wps=40116.3, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=26400, lr=0.000194625, gnorm=1.084, loss_scale=8, train_wall=153, gb_free=20.8, wall=43003
2022-03-14 22:12:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:12:20 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 9.648 | ppl 802.37 | wps 66169.5 | wpb 2040.3 | bsz 4 | num_updates 26421 | best_loss 7.59
2022-03-14 22:12:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 26421 updates
2022-03-14 22:12:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:12:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:12:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 257 @ 26421 updates, score 9.648) (writing took 0.8662021895870566 seconds)
2022-03-14 22:12:21 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-14 22:12:21 | INFO | train | epoch 257 | loss 3.796 | ppl 13.89 | wps 40184.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26421 | lr 0.000194547 | gnorm 1.08 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 43041
KL Stats: Epoch 257 Divergences: Uniform: 5.387967872970373 Unigram: 5.608730729900331
2022-03-14 22:12:21 | INFO | fairseq.trainer | begin training epoch 258
2022-03-14 22:12:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:14:27 | INFO | train_inner | epoch 258:     79 / 103 loss=3.791, ppl=13.84, wps=40147.5, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=26500, lr=0.000194257, gnorm=1.065, loss_scale=8, train_wall=153, gb_free=20.8, wall=43166
2022-03-14 22:15:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:15:08 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 9.673 | ppl 816.31 | wps 66384.9 | wpb 2040.3 | bsz 4 | num_updates 26524 | best_loss 7.59
2022-03-14 22:15:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 26524 updates
2022-03-14 22:15:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:15:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:15:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 258 @ 26524 updates, score 9.673) (writing took 0.887697639875114 seconds)
2022-03-14 22:15:08 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-14 22:15:08 | INFO | train | epoch 258 | loss 3.792 | ppl 13.86 | wps 40186.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26524 | lr 0.000194169 | gnorm 1.066 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 43208
KL Stats: Epoch 258 Divergences: Uniform: 5.390331547783771 Unigram: 5.612574069383347
2022-03-14 22:15:08 | INFO | fairseq.trainer | begin training epoch 259
2022-03-14 22:15:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:17:09 | INFO | train_inner | epoch 259:     76 / 103 loss=3.792, ppl=13.85, wps=40180.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26600, lr=0.000193892, gnorm=1.079, loss_scale=8, train_wall=153, gb_free=20.8, wall=43329
2022-03-14 22:17:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:17:55 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 9.643 | ppl 799.73 | wps 66198 | wpb 2040.3 | bsz 4 | num_updates 26627 | best_loss 7.59
2022-03-14 22:17:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 26627 updates
2022-03-14 22:17:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:17:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:17:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 259 @ 26627 updates, score 9.643) (writing took 0.9543240442872047 seconds)
2022-03-14 22:17:56 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-14 22:17:56 | INFO | train | epoch 259 | loss 3.792 | ppl 13.85 | wps 40194 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26627 | lr 0.000193793 | gnorm 1.077 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 43375
KL Stats: Epoch 259 Divergences: Uniform: 5.38916562526881 Unigram: 5.611579613161245
2022-03-14 22:17:56 | INFO | fairseq.trainer | begin training epoch 260
2022-03-14 22:17:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:19:52 | INFO | train_inner | epoch 260:     73 / 103 loss=3.787, ppl=13.81, wps=40134.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=26700, lr=0.000193528, gnorm=1.065, loss_scale=8, train_wall=153, gb_free=20.8, wall=43491
2022-03-14 22:20:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:20:42 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 9.658 | ppl 807.95 | wps 65851.2 | wpb 2040.3 | bsz 4 | num_updates 26730 | best_loss 7.59
2022-03-14 22:20:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 26730 updates
2022-03-14 22:20:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:20:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:20:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 260 @ 26730 updates, score 9.658) (writing took 0.8693837244063616 seconds)
2022-03-14 22:20:43 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-14 22:20:43 | INFO | train | epoch 260 | loss 3.789 | ppl 13.83 | wps 40171.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26730 | lr 0.00019342 | gnorm 1.068 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 43543
KL Stats: Epoch 260 Divergences: Uniform: 5.38971366131731 Unigram: 5.614737206585664
2022-03-14 22:20:43 | INFO | fairseq.trainer | begin training epoch 261
2022-03-14 22:20:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:21:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 22:22:36 | INFO | train_inner | epoch 261:     71 / 103 loss=3.788, ppl=13.82, wps=39736.5, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=26800, lr=0.000193167, gnorm=1.089, loss_scale=8, train_wall=155, gb_free=20.8, wall=43656
2022-03-14 22:23:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:23:30 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 9.643 | ppl 799.77 | wps 66284.8 | wpb 2040.3 | bsz 4 | num_updates 26832 | best_loss 7.59
2022-03-14 22:23:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 26832 updates
2022-03-14 22:23:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:23:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:23:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 261 @ 26832 updates, score 9.643) (writing took 0.9169566286727786 seconds)
2022-03-14 22:23:31 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-14 22:23:31 | INFO | train | epoch 261 | loss 3.786 | ppl 13.8 | wps 39779.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 26832 | lr 0.000193052 | gnorm 1.096 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 43710
KL Stats: Epoch 261 Divergences: Uniform: 5.392950157033647 Unigram: 5.617886721943178
2022-03-14 22:23:31 | INFO | fairseq.trainer | begin training epoch 262
2022-03-14 22:23:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:25:19 | INFO | train_inner | epoch 262:     68 / 103 loss=3.785, ppl=13.78, wps=40185.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26900, lr=0.000192807, gnorm=1.078, loss_scale=8, train_wall=153, gb_free=20.8, wall=43818
2022-03-14 22:26:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:26:17 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 9.661 | ppl 809.53 | wps 66463.4 | wpb 2040.3 | bsz 4 | num_updates 26935 | best_loss 7.59
2022-03-14 22:26:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 26935 updates
2022-03-14 22:26:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:26:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:26:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 262 @ 26935 updates, score 9.661) (writing took 0.874388076364994 seconds)
2022-03-14 22:26:18 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-14 22:26:18 | INFO | train | epoch 262 | loss 3.785 | ppl 13.78 | wps 40210.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26935 | lr 0.000192682 | gnorm 1.073 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 43878
KL Stats: Epoch 262 Divergences: Uniform: 5.392744887738861 Unigram: 5.618491210460488
2022-03-14 22:26:18 | INFO | fairseq.trainer | begin training epoch 263
2022-03-14 22:26:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:28:01 | INFO | train_inner | epoch 263:     65 / 103 loss=3.783, ppl=13.76, wps=40155.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=27000, lr=0.00019245, gnorm=1.086, loss_scale=8, train_wall=153, gb_free=20.8, wall=43981
2022-03-14 22:29:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:29:05 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 9.672 | ppl 815.81 | wps 65897.2 | wpb 2040.3 | bsz 4 | num_updates 27038 | best_loss 7.59
2022-03-14 22:29:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 27038 updates
2022-03-14 22:29:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:29:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:29:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 263 @ 27038 updates, score 9.672) (writing took 0.9067376451566815 seconds)
2022-03-14 22:29:06 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-14 22:29:06 | INFO | train | epoch 263 | loss 3.783 | ppl 13.77 | wps 40160.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27038 | lr 0.000192315 | gnorm 1.081 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 44045
KL Stats: Epoch 263 Divergences: Uniform: 5.393613165307896 Unigram: 5.620923532708334
2022-03-14 22:29:06 | INFO | fairseq.trainer | begin training epoch 264
2022-03-14 22:29:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:30:44 | INFO | train_inner | epoch 264:     62 / 103 loss=3.781, ppl=13.75, wps=40122.3, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=27100, lr=0.000192095, gnorm=1.078, loss_scale=8, train_wall=153, gb_free=20.8, wall=44144
2022-03-14 22:31:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:31:52 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 9.684 | ppl 822.81 | wps 65911.3 | wpb 2040.3 | bsz 4 | num_updates 27141 | best_loss 7.59
2022-03-14 22:31:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 27141 updates
2022-03-14 22:31:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:31:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:31:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 264 @ 27141 updates, score 9.684) (writing took 0.9735198589041829 seconds)
2022-03-14 22:31:53 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-14 22:31:53 | INFO | train | epoch 264 | loss 3.782 | ppl 13.76 | wps 40138 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27141 | lr 0.00019195 | gnorm 1.087 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 44213
KL Stats: Epoch 264 Divergences: Uniform: 5.396162533383021 Unigram: 5.624881294730307
2022-03-14 22:31:53 | INFO | fairseq.trainer | begin training epoch 265
2022-03-14 22:31:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:33:27 | INFO | train_inner | epoch 265:     59 / 103 loss=3.78, ppl=13.74, wps=40116.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=27200, lr=0.000191741, gnorm=1.083, loss_scale=8, train_wall=153, gb_free=20.8, wall=44306
2022-03-14 22:34:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:34:40 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 9.641 | ppl 798.5 | wps 66092.1 | wpb 2040.3 | bsz 4 | num_updates 27244 | best_loss 7.59
2022-03-14 22:34:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 27244 updates
2022-03-14 22:34:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:34:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:34:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 265 @ 27244 updates, score 9.641) (writing took 0.9045367352664471 seconds)
2022-03-14 22:34:41 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-14 22:34:41 | INFO | train | epoch 265 | loss 3.778 | ppl 13.72 | wps 40169.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27244 | lr 0.000191586 | gnorm 1.082 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 44380
KL Stats: Epoch 265 Divergences: Uniform: 5.395319948901408 Unigram: 5.625971800511968
2022-03-14 22:34:41 | INFO | fairseq.trainer | begin training epoch 266
2022-03-14 22:34:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:36:10 | INFO | train_inner | epoch 266:     56 / 103 loss=3.775, ppl=13.69, wps=40131.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=27300, lr=0.00019139, gnorm=1.08, loss_scale=16, train_wall=153, gb_free=20.8, wall=44469
2022-03-14 22:36:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 22:37:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:37:27 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 9.679 | ppl 819.64 | wps 66254.3 | wpb 2040.3 | bsz 4 | num_updates 27346 | best_loss 7.59
2022-03-14 22:37:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 27346 updates
2022-03-14 22:37:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:37:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:37:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 266 @ 27346 updates, score 9.679) (writing took 0.9102070005610585 seconds)
2022-03-14 22:37:28 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-14 22:37:28 | INFO | train | epoch 266 | loss 3.776 | ppl 13.7 | wps 39793.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 27346 | lr 0.000191229 | gnorm 1.079 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 44548
KL Stats: Epoch 266 Divergences: Uniform: 5.397238438652911 Unigram: 5.627963183319888
2022-03-14 22:37:28 | INFO | fairseq.trainer | begin training epoch 267
2022-03-14 22:37:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:38:54 | INFO | train_inner | epoch 267:     54 / 103 loss=3.779, ppl=13.72, wps=39775.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=27400, lr=0.00019104, gnorm=1.092, loss_scale=8, train_wall=155, gb_free=20.8, wall=44633
2022-03-14 22:40:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:40:14 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 9.68 | ppl 820.4 | wps 65902.9 | wpb 2040.3 | bsz 4 | num_updates 27449 | best_loss 7.59
2022-03-14 22:40:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 27449 updates
2022-03-14 22:40:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:40:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:40:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 267 @ 27449 updates, score 9.68) (writing took 0.939404864795506 seconds)
2022-03-14 22:40:15 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-14 22:40:15 | INFO | train | epoch 267 | loss 3.774 | ppl 13.68 | wps 40189.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27449 | lr 0.00019087 | gnorm 1.091 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 44715
KL Stats: Epoch 267 Divergences: Uniform: 5.399868264852442 Unigram: 5.633703206557919
2022-03-14 22:40:15 | INFO | fairseq.trainer | begin training epoch 268
2022-03-14 22:40:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:41:36 | INFO | train_inner | epoch 268:     51 / 103 loss=3.768, ppl=13.63, wps=40143.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=27500, lr=0.000190693, gnorm=1.067, loss_scale=8, train_wall=153, gb_free=20.8, wall=44796
2022-03-14 22:42:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:43:02 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 9.695 | ppl 828.64 | wps 66282.9 | wpb 2040.3 | bsz 4 | num_updates 27552 | best_loss 7.59
2022-03-14 22:43:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 27552 updates
2022-03-14 22:43:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:43:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:43:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 268 @ 27552 updates, score 9.695) (writing took 0.9324834672734141 seconds)
2022-03-14 22:43:03 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-14 22:43:03 | INFO | train | epoch 268 | loss 3.771 | ppl 13.65 | wps 40178.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27552 | lr 0.000190512 | gnorm 1.065 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 44882
KL Stats: Epoch 268 Divergences: Uniform: 5.401196002925131 Unigram: 5.635108920957026
2022-03-14 22:43:03 | INFO | fairseq.trainer | begin training epoch 269
2022-03-14 22:43:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:44:19 | INFO | train_inner | epoch 269:     48 / 103 loss=3.772, ppl=13.66, wps=40150.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=27600, lr=0.000190347, gnorm=1.084, loss_scale=8, train_wall=153, gb_free=20.8, wall=44959
2022-03-14 22:45:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:45:49 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 9.675 | ppl 817.68 | wps 66105.2 | wpb 2040.3 | bsz 4 | num_updates 27655 | best_loss 7.59
2022-03-14 22:45:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 27655 updates
2022-03-14 22:45:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:45:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:45:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 269 @ 27655 updates, score 9.675) (writing took 0.9128882018849254 seconds)
2022-03-14 22:45:50 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-14 22:45:50 | INFO | train | epoch 269 | loss 3.77 | ppl 13.64 | wps 40199.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27655 | lr 0.000190157 | gnorm 1.087 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 45050
KL Stats: Epoch 269 Divergences: Uniform: 5.402154149725052 Unigram: 5.636786030512954
2022-03-14 22:45:50 | INFO | fairseq.trainer | begin training epoch 270
2022-03-14 22:45:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:47:02 | INFO | train_inner | epoch 270:     45 / 103 loss=3.77, ppl=13.64, wps=40166.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=27700, lr=0.000190003, gnorm=1.078, loss_scale=8, train_wall=153, gb_free=20.8, wall=45121
2022-03-14 22:48:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:48:37 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 9.687 | ppl 824.56 | wps 65830.8 | wpb 2040.3 | bsz 4 | num_updates 27758 | best_loss 7.59
2022-03-14 22:48:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 27758 updates
2022-03-14 22:48:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:48:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:48:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 270 @ 27758 updates, score 9.687) (writing took 0.9392317216843367 seconds)
2022-03-14 22:48:38 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-14 22:48:38 | INFO | train | epoch 270 | loss 3.768 | ppl 13.63 | wps 40143.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27758 | lr 0.000189804 | gnorm 1.081 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 45217
KL Stats: Epoch 270 Divergences: Uniform: 5.402621055762967 Unigram: 5.63865223457025
2022-03-14 22:48:38 | INFO | fairseq.trainer | begin training epoch 271
2022-03-14 22:48:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:49:45 | INFO | train_inner | epoch 271:     42 / 103 loss=3.767, ppl=13.61, wps=40095.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=27800, lr=0.000189661, gnorm=1.086, loss_scale=8, train_wall=153, gb_free=20.8, wall=45284
2022-03-14 22:51:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:51:24 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 9.681 | ppl 820.6 | wps 65698.6 | wpb 2040.3 | bsz 4 | num_updates 27861 | best_loss 7.59
2022-03-14 22:51:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 27861 updates
2022-03-14 22:51:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:51:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:51:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 271 @ 27861 updates, score 9.681) (writing took 0.8735097507014871 seconds)
2022-03-14 22:51:25 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-14 22:51:25 | INFO | train | epoch 271 | loss 3.766 | ppl 13.6 | wps 40149.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27861 | lr 0.000189453 | gnorm 1.075 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45385
KL Stats: Epoch 271 Divergences: Uniform: 5.404097716586473 Unigram: 5.6426259777746735
2022-03-14 22:51:25 | INFO | fairseq.trainer | begin training epoch 272
2022-03-14 22:51:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:52:27 | INFO | train_inner | epoch 272:     39 / 103 loss=3.767, ppl=13.61, wps=40110, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=27900, lr=0.000189321, gnorm=1.068, loss_scale=16, train_wall=153, gb_free=20.8, wall=45447
2022-03-14 22:54:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:54:12 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 9.68 | ppl 820.29 | wps 65866.2 | wpb 2040.3 | bsz 4 | num_updates 27964 | best_loss 7.59
2022-03-14 22:54:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 27964 updates
2022-03-14 22:54:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:54:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:54:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 272 @ 27964 updates, score 9.68) (writing took 0.8706405246630311 seconds)
2022-03-14 22:54:13 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-14 22:54:13 | INFO | train | epoch 272 | loss 3.764 | ppl 13.58 | wps 40165.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27964 | lr 0.000189104 | gnorm 1.07 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45552
KL Stats: Epoch 272 Divergences: Uniform: 5.404498106734461 Unigram: 5.643107316107292
2022-03-14 22:54:13 | INFO | fairseq.trainer | begin training epoch 273
2022-03-14 22:54:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:54:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 22:55:12 | INFO | train_inner | epoch 273:     37 / 103 loss=3.762, ppl=13.56, wps=39753.3, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=28000, lr=0.000188982, gnorm=1.082, loss_scale=8, train_wall=155, gb_free=20.8, wall=45611
2022-03-14 22:56:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:56:59 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 9.702 | ppl 832.98 | wps 66248 | wpb 2040.3 | bsz 4 | num_updates 28066 | best_loss 7.59
2022-03-14 22:56:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 28066 updates
2022-03-14 22:56:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:57:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:57:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 273 @ 28066 updates, score 9.702) (writing took 0.8714148113504052 seconds)
2022-03-14 22:57:00 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-14 22:57:00 | INFO | train | epoch 273 | loss 3.763 | ppl 13.58 | wps 39768.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 28066 | lr 0.00018876 | gnorm 1.086 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 45720
KL Stats: Epoch 273 Divergences: Uniform: 5.40551824355748 Unigram: 5.644732448413732
2022-03-14 22:57:00 | INFO | fairseq.trainer | begin training epoch 274
2022-03-14 22:57:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:57:54 | INFO | train_inner | epoch 274:     34 / 103 loss=3.763, ppl=13.58, wps=40130.6, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=28100, lr=0.000188646, gnorm=1.081, loss_scale=8, train_wall=153, gb_free=20.8, wall=45774
2022-03-14 22:59:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:59:47 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 9.698 | ppl 830.5 | wps 65900.2 | wpb 2040.3 | bsz 4 | num_updates 28169 | best_loss 7.59
2022-03-14 22:59:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 28169 updates
2022-03-14 22:59:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:59:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 22:59:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 274 @ 28169 updates, score 9.698) (writing took 0.8673845576122403 seconds)
2022-03-14 22:59:48 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-14 22:59:48 | INFO | train | epoch 274 | loss 3.761 | ppl 13.56 | wps 40184.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28169 | lr 0.000188414 | gnorm 1.089 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 45887
KL Stats: Epoch 274 Divergences: Uniform: 5.405932159255471 Unigram: 5.648386170224874
2022-03-14 22:59:48 | INFO | fairseq.trainer | begin training epoch 275
2022-03-14 22:59:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:00:37 | INFO | train_inner | epoch 275:     31 / 103 loss=3.763, ppl=13.57, wps=40152.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=28200, lr=0.000188311, gnorm=1.089, loss_scale=8, train_wall=153, gb_free=20.8, wall=45937
2022-03-14 23:02:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:02:34 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 9.679 | ppl 819.56 | wps 66032.5 | wpb 2040.3 | bsz 4 | num_updates 28272 | best_loss 7.59
2022-03-14 23:02:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 28272 updates
2022-03-14 23:02:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:02:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:02:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 275 @ 28272 updates, score 9.679) (writing took 0.9443414397537708 seconds)
2022-03-14 23:02:35 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-14 23:02:35 | INFO | train | epoch 275 | loss 3.759 | ppl 13.54 | wps 40163 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 28272 | lr 0.000188071 | gnorm 1.085 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 46055
KL Stats: Epoch 275 Divergences: Uniform: 5.405691002133402 Unigram: 5.648778527481848
2022-03-14 23:02:35 | INFO | fairseq.trainer | begin training epoch 276
2022-03-14 23:02:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:03:20 | INFO | train_inner | epoch 276:     28 / 103 loss=3.757, ppl=13.52, wps=40133.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=28300, lr=0.000187978, gnorm=1.08, loss_scale=8, train_wall=153, gb_free=20.8, wall=46099
2022-03-14 23:05:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:05:22 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 9.698 | ppl 830.72 | wps 65907.2 | wpb 2040.3 | bsz 4 | num_updates 28375 | best_loss 7.59
2022-03-14 23:05:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 28375 updates
2022-03-14 23:05:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:05:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:05:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 276 @ 28375 updates, score 9.698) (writing took 0.9105666503310204 seconds)
2022-03-14 23:05:23 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-14 23:05:23 | INFO | train | epoch 276 | loss 3.756 | ppl 13.51 | wps 40187.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28375 | lr 0.000187729 | gnorm 1.073 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 46222
KL Stats: Epoch 276 Divergences: Uniform: 5.407763994068905 Unigram: 5.652318301241202
2022-03-14 23:05:23 | INFO | fairseq.trainer | begin training epoch 277
2022-03-14 23:05:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:06:02 | INFO | train_inner | epoch 277:     25 / 103 loss=3.757, ppl=13.52, wps=40154.6, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=28400, lr=0.000187647, gnorm=1.077, loss_scale=8, train_wall=153, gb_free=20.8, wall=46262
2022-03-14 23:08:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:08:09 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 9.702 | ppl 832.97 | wps 66092 | wpb 2040.3 | bsz 4 | num_updates 28478 | best_loss 7.59
2022-03-14 23:08:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 28478 updates
2022-03-14 23:08:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:08:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:08:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 277 @ 28478 updates, score 9.702) (writing took 0.8851789040490985 seconds)
2022-03-14 23:08:10 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-14 23:08:10 | INFO | train | epoch 277 | loss 3.755 | ppl 13.5 | wps 40187.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28478 | lr 0.00018739 | gnorm 1.08 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 46390
KL Stats: Epoch 277 Divergences: Uniform: 5.410340336851882 Unigram: 5.655910110613931
2022-03-14 23:08:10 | INFO | fairseq.trainer | begin training epoch 278
2022-03-14 23:08:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:08:45 | INFO | train_inner | epoch 278:     22 / 103 loss=3.756, ppl=13.51, wps=40140.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=28500, lr=0.000187317, gnorm=1.079, loss_scale=16, train_wall=153, gb_free=20.8, wall=46425
2022-03-14 23:10:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 23:10:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:10:57 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 9.71 | ppl 837.61 | wps 65849.1 | wpb 2040.3 | bsz 4 | num_updates 28580 | best_loss 7.59
2022-03-14 23:10:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 28580 updates
2022-03-14 23:10:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:10:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:10:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 278 @ 28580 updates, score 9.71) (writing took 0.9138282090425491 seconds)
2022-03-14 23:10:58 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-14 23:10:58 | INFO | train | epoch 278 | loss 3.751 | ppl 13.47 | wps 39761.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 28580 | lr 0.000187055 | gnorm 1.085 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 46557
KL Stats: Epoch 278 Divergences: Uniform: 5.41007273127902 Unigram: 5.657598682360073
2022-03-14 23:10:58 | INFO | fairseq.trainer | begin training epoch 279
2022-03-14 23:10:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:11:29 | INFO | train_inner | epoch 279:     20 / 103 loss=3.75, ppl=13.46, wps=39739.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=28600, lr=0.000186989, gnorm=1.091, loss_scale=8, train_wall=155, gb_free=20.8, wall=46589
2022-03-14 23:13:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:13:44 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 9.693 | ppl 827.84 | wps 65858.3 | wpb 2040.3 | bsz 4 | num_updates 28683 | best_loss 7.59
2022-03-14 23:13:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 28683 updates
2022-03-14 23:13:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:13:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:13:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 279 @ 28683 updates, score 9.693) (writing took 0.8861657483503222 seconds)
2022-03-14 23:13:45 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-14 23:13:45 | INFO | train | epoch 279 | loss 3.752 | ppl 13.47 | wps 40146.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 28683 | lr 0.000186719 | gnorm 1.081 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 46725
KL Stats: Epoch 279 Divergences: Uniform: 5.4100694133762754 Unigram: 5.656870097068795
2022-03-14 23:13:45 | INFO | fairseq.trainer | begin training epoch 280
2022-03-14 23:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:14:12 | INFO | train_inner | epoch 280:     17 / 103 loss=3.755, ppl=13.5, wps=40107.5, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=28700, lr=0.000186663, gnorm=1.084, loss_scale=8, train_wall=153, gb_free=20.8, wall=46752
2022-03-14 23:16:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:16:32 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 9.715 | ppl 840.4 | wps 66009.5 | wpb 2040.3 | bsz 4 | num_updates 28786 | best_loss 7.59
2022-03-14 23:16:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 28786 updates
2022-03-14 23:16:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:16:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:16:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 280 @ 28786 updates, score 9.715) (writing took 0.8804744593799114 seconds)
2022-03-14 23:16:33 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-14 23:16:33 | INFO | train | epoch 280 | loss 3.75 | ppl 13.45 | wps 40160 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 28786 | lr 0.000186384 | gnorm 1.09 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 46892
KL Stats: Epoch 280 Divergences: Uniform: 5.411532405546019 Unigram: 5.662772777651373
2022-03-14 23:16:33 | INFO | fairseq.trainer | begin training epoch 281
2022-03-14 23:16:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:16:55 | INFO | train_inner | epoch 281:     14 / 103 loss=3.75, ppl=13.45, wps=40135.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=28800, lr=0.000186339, gnorm=1.085, loss_scale=8, train_wall=153, gb_free=20.8, wall=46915
2022-03-14 23:19:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:19:19 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 9.711 | ppl 838.2 | wps 66088 | wpb 2040.3 | bsz 4 | num_updates 28889 | best_loss 7.59
2022-03-14 23:19:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 28889 updates
2022-03-14 23:19:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:19:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:19:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 281 @ 28889 updates, score 9.711) (writing took 0.9666785206645727 seconds)
2022-03-14 23:19:20 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-14 23:19:20 | INFO | train | epoch 281 | loss 3.746 | ppl 13.42 | wps 40172.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28889 | lr 0.000186052 | gnorm 1.084 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 47060
KL Stats: Epoch 281 Divergences: Uniform: 5.413532402288304 Unigram: 5.6660344194339975
2022-03-14 23:19:20 | INFO | fairseq.trainer | begin training epoch 282
2022-03-14 23:19:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:19:38 | INFO | train_inner | epoch 282:     11 / 103 loss=3.747, ppl=13.43, wps=40137.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=28900, lr=0.000186016, gnorm=1.085, loss_scale=8, train_wall=153, gb_free=20.8, wall=47077
2022-03-14 23:22:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:22:07 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 9.698 | ppl 830.67 | wps 66058.6 | wpb 2040.3 | bsz 4 | num_updates 28992 | best_loss 7.59
2022-03-14 23:22:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 28992 updates
2022-03-14 23:22:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:22:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:22:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 282 @ 28992 updates, score 9.698) (writing took 0.8560112528502941 seconds)
2022-03-14 23:22:07 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-14 23:22:07 | INFO | train | epoch 282 | loss 3.745 | ppl 13.41 | wps 40207.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28992 | lr 0.000185721 | gnorm 1.079 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 47227
KL Stats: Epoch 282 Divergences: Uniform: 5.413991316612611 Unigram: 5.667676903492127
2022-03-14 23:22:07 | INFO | fairseq.trainer | begin training epoch 283
2022-03-14 23:22:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:22:20 | INFO | train_inner | epoch 283:      8 / 103 loss=3.747, ppl=13.42, wps=40174.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29000, lr=0.000185695, gnorm=1.082, loss_scale=8, train_wall=153, gb_free=20.8, wall=47240
2022-03-14 23:24:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:24:54 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 9.719 | ppl 842.72 | wps 66231.8 | wpb 2040.3 | bsz 4 | num_updates 29095 | best_loss 7.59
2022-03-14 23:24:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 29095 updates
2022-03-14 23:24:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:24:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:24:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 283 @ 29095 updates, score 9.719) (writing took 0.8819881249219179 seconds)
2022-03-14 23:24:55 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-14 23:24:55 | INFO | train | epoch 283 | loss 3.743 | ppl 13.39 | wps 40168.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29095 | lr 0.000185392 | gnorm 1.075 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47394
KL Stats: Epoch 283 Divergences: Uniform: 5.4137777012821156 Unigram: 5.669040502454919
2022-03-14 23:24:55 | INFO | fairseq.trainer | begin training epoch 284
2022-03-14 23:24:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:25:03 | INFO | train_inner | epoch 284:      5 / 103 loss=3.746, ppl=13.42, wps=40136.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29100, lr=0.000185376, gnorm=1.074, loss_scale=16, train_wall=153, gb_free=20.8, wall=47402
2022-03-14 23:27:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:27:42 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 9.746 | ppl 858.41 | wps 66189.1 | wpb 2040.3 | bsz 4 | num_updates 29198 | best_loss 7.59
2022-03-14 23:27:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 29198 updates
2022-03-14 23:27:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:27:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:27:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 284 @ 29198 updates, score 9.746) (writing took 0.9423349453136325 seconds)
2022-03-14 23:27:42 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-14 23:27:42 | INFO | train | epoch 284 | loss 3.741 | ppl 13.37 | wps 40148.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 29198 | lr 0.000185065 | gnorm 1.081 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47562
KL Stats: Epoch 284 Divergences: Uniform: 5.41777081729823 Unigram: 5.674777542821359
2022-03-14 23:27:42 | INFO | fairseq.trainer | begin training epoch 285
2022-03-14 23:27:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:27:46 | INFO | train_inner | epoch 285:      2 / 103 loss=3.741, ppl=13.37, wps=40112.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29200, lr=0.000185058, gnorm=1.08, loss_scale=16, train_wall=153, gb_free=20.8, wall=47565
2022-03-14 23:30:24 | INFO | train_inner | epoch 285:    102 / 103 loss=3.741, ppl=13.37, wps=41302.2, ups=0.63, wpb=65530.9, bsz=128, num_updates=29300, lr=0.000184742, gnorm=1.089, loss_scale=16, train_wall=154, gb_free=20.8, wall=47724
2022-03-14 23:30:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:30:29 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 9.714 | ppl 839.85 | wps 66267.5 | wpb 2040.3 | bsz 4 | num_updates 29301 | best_loss 7.59
2022-03-14 23:30:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 29301 updates
2022-03-14 23:30:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:30:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:30:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 285 @ 29301 updates, score 9.714) (writing took 0.9093007920309901 seconds)
2022-03-14 23:30:30 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-14 23:30:30 | INFO | train | epoch 285 | loss 3.74 | ppl 13.36 | wps 40173.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29301 | lr 0.000184739 | gnorm 1.09 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47729
KL Stats: Epoch 285 Divergences: Uniform: 5.416098891886423 Unigram: 5.672489241038495
2022-03-14 23:30:30 | INFO | fairseq.trainer | begin training epoch 286
2022-03-14 23:30:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:33:07 | INFO | train_inner | epoch 286:     99 / 103 loss=3.736, ppl=13.32, wps=40136.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29400, lr=0.000184428, gnorm=1.081, loss_scale=16, train_wall=153, gb_free=20.8, wall=47887
2022-03-14 23:33:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:33:16 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 9.722 | ppl 844.77 | wps 66269.6 | wpb 2040.3 | bsz 4 | num_updates 29404 | best_loss 7.59
2022-03-14 23:33:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 29404 updates
2022-03-14 23:33:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:33:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:33:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 286 @ 29404 updates, score 9.722) (writing took 0.9018520666286349 seconds)
2022-03-14 23:33:17 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-14 23:33:17 | INFO | train | epoch 286 | loss 3.738 | ppl 13.34 | wps 40173.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29404 | lr 0.000184415 | gnorm 1.083 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47897
KL Stats: Epoch 286 Divergences: Uniform: 5.416549003225076 Unigram: 5.675753607404456
2022-03-14 23:33:17 | INFO | fairseq.trainer | begin training epoch 287
2022-03-14 23:33:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:35:50 | INFO | train_inner | epoch 287:     96 / 103 loss=3.736, ppl=13.32, wps=40146.3, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=29500, lr=0.000184115, gnorm=1.081, loss_scale=16, train_wall=153, gb_free=20.8, wall=48049
2022-03-14 23:36:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:36:04 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 9.734 | ppl 851.61 | wps 66480.9 | wpb 2040.3 | bsz 4 | num_updates 29507 | best_loss 7.59
2022-03-14 23:36:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 29507 updates
2022-03-14 23:36:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:36:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:36:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 287 @ 29507 updates, score 9.734) (writing took 0.872016116976738 seconds)
2022-03-14 23:36:05 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-14 23:36:05 | INFO | train | epoch 287 | loss 3.736 | ppl 13.32 | wps 40186.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29507 | lr 0.000184093 | gnorm 1.079 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48064
KL Stats: Epoch 287 Divergences: Uniform: 5.418313230912271 Unigram: 5.676790935268031
2022-03-14 23:36:05 | INFO | fairseq.trainer | begin training epoch 288
2022-03-14 23:36:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:37:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 23:38:34 | INFO | train_inner | epoch 288:     94 / 103 loss=3.732, ppl=13.29, wps=39782.6, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=29600, lr=0.000183804, gnorm=1.085, loss_scale=8, train_wall=155, gb_free=20.8, wall=48213
2022-03-14 23:38:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:38:51 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 9.731 | ppl 849.66 | wps 66263.1 | wpb 2040.3 | bsz 4 | num_updates 29609 | best_loss 7.59
2022-03-14 23:38:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 29609 updates
2022-03-14 23:38:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:38:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:38:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 288 @ 29609 updates, score 9.731) (writing took 0.9332716651260853 seconds)
2022-03-14 23:38:52 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-14 23:38:52 | INFO | train | epoch 288 | loss 3.733 | ppl 13.3 | wps 39798.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 29609 | lr 0.000183776 | gnorm 1.086 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 48232
KL Stats: Epoch 288 Divergences: Uniform: 5.422107916520158 Unigram: 5.682601969958491
2022-03-14 23:38:52 | INFO | fairseq.trainer | begin training epoch 289
2022-03-14 23:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:41:16 | INFO | train_inner | epoch 289:     91 / 103 loss=3.73, ppl=13.27, wps=40197, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29700, lr=0.000183494, gnorm=1.082, loss_scale=8, train_wall=153, gb_free=20.8, wall=48376
2022-03-14 23:41:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:41:38 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 9.731 | ppl 849.58 | wps 65932.4 | wpb 2040.3 | bsz 4 | num_updates 29712 | best_loss 7.59
2022-03-14 23:41:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 29712 updates
2022-03-14 23:41:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:41:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:41:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 289 @ 29712 updates, score 9.731) (writing took 0.8437924776226282 seconds)
2022-03-14 23:41:39 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-14 23:41:39 | INFO | train | epoch 289 | loss 3.732 | ppl 13.29 | wps 40236.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29712 | lr 0.000183457 | gnorm 1.086 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 48399
KL Stats: Epoch 289 Divergences: Uniform: 5.421303165585909 Unigram: 5.682375237484897
2022-03-14 23:41:39 | INFO | fairseq.trainer | begin training epoch 290
2022-03-14 23:41:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:43:59 | INFO | train_inner | epoch 290:     88 / 103 loss=3.727, ppl=13.24, wps=40180.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29800, lr=0.000183186, gnorm=1.085, loss_scale=8, train_wall=153, gb_free=20.8, wall=48538
2022-03-14 23:44:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:44:26 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 9.733 | ppl 851.07 | wps 66126.4 | wpb 2040.3 | bsz 4 | num_updates 29815 | best_loss 7.59
2022-03-14 23:44:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 29815 updates
2022-03-14 23:44:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:44:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:44:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 290 @ 29815 updates, score 9.733) (writing took 0.879734467715025 seconds)
2022-03-14 23:44:27 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-14 23:44:27 | INFO | train | epoch 290 | loss 3.729 | ppl 13.26 | wps 40216.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29815 | lr 0.00018314 | gnorm 1.085 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 48566
KL Stats: Epoch 290 Divergences: Uniform: 5.422885896318666 Unigram: 5.68549771352742
2022-03-14 23:44:27 | INFO | fairseq.trainer | begin training epoch 291
2022-03-14 23:44:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:46:41 | INFO | train_inner | epoch 291:     85 / 103 loss=3.729, ppl=13.26, wps=40184.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29900, lr=0.000182879, gnorm=1.082, loss_scale=8, train_wall=153, gb_free=20.8, wall=48701
2022-03-14 23:47:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:47:13 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 9.708 | ppl 836.46 | wps 66295.2 | wpb 2040.3 | bsz 4 | num_updates 29918 | best_loss 7.59
2022-03-14 23:47:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 29918 updates
2022-03-14 23:47:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:47:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:47:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 291 @ 29918 updates, score 9.708) (writing took 0.9448375878855586 seconds)
2022-03-14 23:47:14 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-14 23:47:14 | INFO | train | epoch 291 | loss 3.729 | ppl 13.26 | wps 40212.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29918 | lr 0.000182824 | gnorm 1.08 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 48733
KL Stats: Epoch 291 Divergences: Uniform: 5.421055066949438 Unigram: 5.683976916909086
2022-03-14 23:47:14 | INFO | fairseq.trainer | begin training epoch 292
2022-03-14 23:47:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:49:24 | INFO | train_inner | epoch 292:     82 / 103 loss=3.725, ppl=13.23, wps=40171.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=30000, lr=0.000182574, gnorm=1.083, loss_scale=8, train_wall=153, gb_free=20.8, wall=48864
2022-03-14 23:49:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:50:00 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 9.755 | ppl 863.87 | wps 65921.6 | wpb 2040.3 | bsz 4 | num_updates 30021 | best_loss 7.59
2022-03-14 23:50:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 30021 updates
2022-03-14 23:50:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:50:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:50:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 292 @ 30021 updates, score 9.755) (writing took 0.9452952453866601 seconds)
2022-03-14 23:50:01 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-14 23:50:01 | INFO | train | epoch 292 | loss 3.726 | ppl 13.23 | wps 40195.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30021 | lr 0.00018251 | gnorm 1.082 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 48901
KL Stats: Epoch 292 Divergences: Uniform: 5.423778681949729 Unigram: 5.688084855242747
2022-03-14 23:50:01 | INFO | fairseq.trainer | begin training epoch 293
2022-03-14 23:50:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:52:07 | INFO | train_inner | epoch 293:     79 / 103 loss=3.725, ppl=13.23, wps=40148.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=30100, lr=0.000182271, gnorm=1.087, loss_scale=16, train_wall=153, gb_free=20.8, wall=49026
2022-03-14 23:52:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:52:48 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 9.735 | ppl 851.98 | wps 66106.5 | wpb 2040.3 | bsz 4 | num_updates 30124 | best_loss 7.59
2022-03-14 23:52:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 30124 updates
2022-03-14 23:52:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:52:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:52:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 293 @ 30124 updates, score 9.735) (writing took 0.9062621286138892 seconds)
2022-03-14 23:52:49 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-14 23:52:49 | INFO | train | epoch 293 | loss 3.725 | ppl 13.22 | wps 40188.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30124 | lr 0.000182198 | gnorm 1.09 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 49068
KL Stats: Epoch 293 Divergences: Uniform: 5.424046989151904 Unigram: 5.690573379527826
2022-03-14 23:52:49 | INFO | fairseq.trainer | begin training epoch 294
2022-03-14 23:52:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:54:49 | INFO | train_inner | epoch 294:     76 / 103 loss=3.721, ppl=13.19, wps=40162.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=30200, lr=0.000181969, gnorm=1.095, loss_scale=16, train_wall=153, gb_free=20.8, wall=49189
2022-03-14 23:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:55:35 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 9.743 | ppl 856.64 | wps 66518.3 | wpb 2040.3 | bsz 4 | num_updates 30227 | best_loss 7.59
2022-03-14 23:55:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 30227 updates
2022-03-14 23:55:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:55:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:55:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 294 @ 30227 updates, score 9.743) (writing took 0.8820878909900784 seconds)
2022-03-14 23:55:36 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-14 23:55:36 | INFO | train | epoch 294 | loss 3.723 | ppl 13.21 | wps 40208.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30227 | lr 0.000181887 | gnorm 1.091 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 49236
KL Stats: Epoch 294 Divergences: Uniform: 5.425124186845157 Unigram: 5.692353095180544
2022-03-14 23:55:36 | INFO | fairseq.trainer | begin training epoch 295
2022-03-14 23:55:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:57:32 | INFO | train_inner | epoch 295:     73 / 103 loss=3.72, ppl=13.18, wps=40172.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=30300, lr=0.000181668, gnorm=1.079, loss_scale=16, train_wall=153, gb_free=20.8, wall=49351
2022-03-14 23:58:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:58:22 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 9.774 | ppl 875.62 | wps 66134.6 | wpb 2040.3 | bsz 4 | num_updates 30330 | best_loss 7.59
2022-03-14 23:58:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 30330 updates
2022-03-14 23:58:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:58:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-14 23:58:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 295 @ 30330 updates, score 9.774) (writing took 0.8734372202306986 seconds)
2022-03-14 23:58:23 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-14 23:58:23 | INFO | train | epoch 295 | loss 3.721 | ppl 13.19 | wps 40193.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30330 | lr 0.000181578 | gnorm 1.079 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 49403
KL Stats: Epoch 295 Divergences: Uniform: 5.426629486098014 Unigram: 5.696828718841317
2022-03-14 23:58:23 | INFO | fairseq.trainer | begin training epoch 296
2022-03-14 23:58:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:59:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 00:00:16 | INFO | train_inner | epoch 296:     71 / 103 loss=3.721, ppl=13.19, wps=39786.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=30400, lr=0.000181369, gnorm=1.079, loss_scale=8, train_wall=155, gb_free=20.8, wall=49516
2022-03-15 00:01:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:01:10 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 9.762 | ppl 868.54 | wps 65923 | wpb 2040.3 | bsz 4 | num_updates 30432 | best_loss 7.59
2022-03-15 00:01:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 30432 updates
2022-03-15 00:01:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:01:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:01:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 296 @ 30432 updates, score 9.762) (writing took 0.9218663349747658 seconds)
2022-03-15 00:01:11 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-15 00:01:11 | INFO | train | epoch 296 | loss 3.72 | ppl 13.17 | wps 39783.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 30432 | lr 0.000181274 | gnorm 1.081 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 49570
KL Stats: Epoch 296 Divergences: Uniform: 5.428686948609992 Unigram: 5.69745588032539
2022-03-15 00:01:11 | INFO | fairseq.trainer | begin training epoch 297
2022-03-15 00:01:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:02:59 | INFO | train_inner | epoch 297:     68 / 103 loss=3.716, ppl=13.14, wps=40099.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=30500, lr=0.000181071, gnorm=1.084, loss_scale=8, train_wall=153, gb_free=20.8, wall=49678
2022-03-15 00:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:03:57 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 9.732 | ppl 850.52 | wps 65878.3 | wpb 2040.3 | bsz 4 | num_updates 30535 | best_loss 7.59
2022-03-15 00:03:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 30535 updates
2022-03-15 00:03:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:03:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:03:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 297 @ 30535 updates, score 9.732) (writing took 0.8770331731066108 seconds)
2022-03-15 00:03:58 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-15 00:03:58 | INFO | train | epoch 297 | loss 3.717 | ppl 13.15 | wps 40148 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 30535 | lr 0.000180968 | gnorm 1.089 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 49738
KL Stats: Epoch 297 Divergences: Uniform: 5.427651620902047 Unigram: 5.699292234622104
2022-03-15 00:03:58 | INFO | fairseq.trainer | begin training epoch 298
2022-03-15 00:03:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:05:42 | INFO | train_inner | epoch 298:     65 / 103 loss=3.717, ppl=13.15, wps=40113.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=30600, lr=0.000180775, gnorm=1.094, loss_scale=8, train_wall=153, gb_free=20.8, wall=49841
2022-03-15 00:06:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:06:45 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 9.757 | ppl 865.01 | wps 65934.5 | wpb 2040.3 | bsz 4 | num_updates 30638 | best_loss 7.59
2022-03-15 00:06:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 30638 updates
2022-03-15 00:06:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:06:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:06:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 298 @ 30638 updates, score 9.757) (writing took 0.9064427288249135 seconds)
2022-03-15 00:06:46 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-15 00:06:46 | INFO | train | epoch 298 | loss 3.716 | ppl 13.15 | wps 40140.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 30638 | lr 0.000180663 | gnorm 1.093 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 49906
KL Stats: Epoch 298 Divergences: Uniform: 5.428008172967146 Unigram: 5.700400294043992
2022-03-15 00:06:46 | INFO | fairseq.trainer | begin training epoch 299
2022-03-15 00:06:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:08:24 | INFO | train_inner | epoch 299:     62 / 103 loss=3.714, ppl=13.13, wps=40099.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=30700, lr=0.000180481, gnorm=1.088, loss_scale=8, train_wall=153, gb_free=20.8, wall=50004
2022-03-15 00:09:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:09:33 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 9.773 | ppl 874.62 | wps 66060.1 | wpb 2040.3 | bsz 4 | num_updates 30741 | best_loss 7.59
2022-03-15 00:09:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 30741 updates
2022-03-15 00:09:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:09:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:09:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 299 @ 30741 updates, score 9.773) (writing took 0.9262025058269501 seconds)
2022-03-15 00:09:34 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-15 00:09:34 | INFO | train | epoch 299 | loss 3.715 | ppl 13.13 | wps 40120.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 30741 | lr 0.00018036 | gnorm 1.087 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 50073
KL Stats: Epoch 299 Divergences: Uniform: 5.4298378833912455 Unigram: 5.704190898669384
2022-03-15 00:09:34 | INFO | fairseq.trainer | begin training epoch 300
2022-03-15 00:09:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:11:07 | INFO | train_inner | epoch 300:     59 / 103 loss=3.714, ppl=13.12, wps=40114.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=30800, lr=0.000180187, gnorm=1.084, loss_scale=8, train_wall=153, gb_free=20.8, wall=50167
2022-03-15 00:12:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:12:20 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 9.768 | ppl 871.67 | wps 66195.2 | wpb 2040.3 | bsz 4 | num_updates 30844 | best_loss 7.59
2022-03-15 00:12:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 30844 updates
2022-03-15 00:12:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:12:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:12:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 300 @ 30844 updates, score 9.768) (writing took 0.9157698797062039 seconds)
2022-03-15 00:12:21 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-15 00:12:21 | INFO | train | epoch 300 | loss 3.713 | ppl 13.12 | wps 40153.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 30844 | lr 0.000180059 | gnorm 1.087 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 50241
KL Stats: Epoch 300 Divergences: Uniform: 5.430010084634144 Unigram: 5.703991255456799
2022-03-15 00:12:21 | INFO | fairseq.trainer | begin training epoch 301
2022-03-15 00:12:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:13:50 | INFO | train_inner | epoch 301:     56 / 103 loss=3.713, ppl=13.12, wps=40118.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=30900, lr=0.000179896, gnorm=1.098, loss_scale=16, train_wall=153, gb_free=20.8, wall=50330
2022-03-15 00:15:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:15:08 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 9.776 | ppl 876.68 | wps 66086.1 | wpb 2040.3 | bsz 4 | num_updates 30947 | best_loss 7.59
2022-03-15 00:15:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 30947 updates
2022-03-15 00:15:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:15:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:15:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 301 @ 30947 updates, score 9.776) (writing took 0.8964097704738379 seconds)
2022-03-15 00:15:09 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-15 00:15:09 | INFO | train | epoch 301 | loss 3.712 | ppl 13.1 | wps 40163.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 30947 | lr 0.000179759 | gnorm 1.098 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 50408
KL Stats: Epoch 301 Divergences: Uniform: 5.4311023430159615 Unigram: 5.707697563830786
2022-03-15 00:15:09 | INFO | fairseq.trainer | begin training epoch 302
2022-03-15 00:15:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:16:33 | INFO | train_inner | epoch 302:     53 / 103 loss=3.708, ppl=13.07, wps=40141.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=31000, lr=0.000179605, gnorm=1.086, loss_scale=16, train_wall=153, gb_free=20.8, wall=50492
2022-03-15 00:17:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:17:55 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 9.758 | ppl 866.05 | wps 66231.6 | wpb 2040.3 | bsz 4 | num_updates 31050 | best_loss 7.59
2022-03-15 00:17:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 31050 updates
2022-03-15 00:17:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:17:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:17:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 302 @ 31050 updates, score 9.758) (writing took 0.9758381778374314 seconds)
2022-03-15 00:17:56 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-15 00:17:56 | INFO | train | epoch 302 | loss 3.709 | ppl 13.08 | wps 40154.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 31050 | lr 0.000179461 | gnorm 1.078 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 50576
KL Stats: Epoch 302 Divergences: Uniform: 5.433024901754499 Unigram: 5.710366439117847
2022-03-15 00:17:56 | INFO | fairseq.trainer | begin training epoch 303
2022-03-15 00:17:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:18:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 00:19:17 | INFO | train_inner | epoch 303:     51 / 103 loss=3.71, ppl=13.09, wps=39738.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=31100, lr=0.000179316, gnorm=1.085, loss_scale=8, train_wall=155, gb_free=20.8, wall=50657
2022-03-15 00:20:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:20:43 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 9.771 | ppl 873.76 | wps 66293.8 | wpb 2040.3 | bsz 4 | num_updates 31152 | best_loss 7.59
2022-03-15 00:20:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 31152 updates
2022-03-15 00:20:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:20:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:20:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 303 @ 31152 updates, score 9.771) (writing took 0.925518237054348 seconds)
2022-03-15 00:20:44 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-15 00:20:44 | INFO | train | epoch 303 | loss 3.708 | ppl 13.07 | wps 39788.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 31152 | lr 0.000179167 | gnorm 1.085 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 50743
KL Stats: Epoch 303 Divergences: Uniform: 5.433103694263386 Unigram: 5.712003809601649
2022-03-15 00:20:44 | INFO | fairseq.trainer | begin training epoch 304
2022-03-15 00:20:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:22:00 | INFO | train_inner | epoch 304:     48 / 103 loss=3.705, ppl=13.04, wps=40139.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=31200, lr=0.000179029, gnorm=1.075, loss_scale=8, train_wall=153, gb_free=20.8, wall=50819
2022-03-15 00:23:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:23:30 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 9.784 | ppl 881.46 | wps 66291.4 | wpb 2040.3 | bsz 4 | num_updates 31255 | best_loss 7.59
2022-03-15 00:23:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 31255 updates
2022-03-15 00:23:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:23:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:23:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 304 @ 31255 updates, score 9.784) (writing took 0.8810455230996013 seconds)
2022-03-15 00:23:31 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-15 00:23:31 | INFO | train | epoch 304 | loss 3.706 | ppl 13.05 | wps 40189.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 31255 | lr 0.000178871 | gnorm 1.076 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 50911
KL Stats: Epoch 304 Divergences: Uniform: 5.432983261506844 Unigram: 5.713438122585531
2022-03-15 00:23:31 | INFO | fairseq.trainer | begin training epoch 305
2022-03-15 00:23:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:24:42 | INFO | train_inner | epoch 305:     45 / 103 loss=3.708, ppl=13.07, wps=40139.1, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=31300, lr=0.000178743, gnorm=1.09, loss_scale=8, train_wall=153, gb_free=20.8, wall=50982
2022-03-15 00:26:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:26:18 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 9.774 | ppl 875.72 | wps 66110.2 | wpb 2040.3 | bsz 4 | num_updates 31358 | best_loss 7.59
2022-03-15 00:26:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 31358 updates
2022-03-15 00:26:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:26:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:26:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 305 @ 31358 updates, score 9.774) (writing took 0.8859108602628112 seconds)
2022-03-15 00:26:18 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-15 00:26:18 | INFO | train | epoch 305 | loss 3.705 | ppl 13.04 | wps 40166.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 31358 | lr 0.000178577 | gnorm 1.093 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 51078
KL Stats: Epoch 305 Divergences: Uniform: 5.433636540549342 Unigram: 5.715414018059268
2022-03-15 00:26:18 | INFO | fairseq.trainer | begin training epoch 306
2022-03-15 00:26:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:27:25 | INFO | train_inner | epoch 306:     42 / 103 loss=3.703, ppl=13.02, wps=40135.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=31400, lr=0.000178458, gnorm=1.091, loss_scale=8, train_wall=153, gb_free=20.8, wall=51145
2022-03-15 00:29:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:29:05 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 9.793 | ppl 886.87 | wps 66089.1 | wpb 2040.3 | bsz 4 | num_updates 31461 | best_loss 7.59
2022-03-15 00:29:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 31461 updates
2022-03-15 00:29:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:29:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:29:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 306 @ 31461 updates, score 9.793) (writing took 0.8954917602241039 seconds)
2022-03-15 00:29:06 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-15 00:29:06 | INFO | train | epoch 306 | loss 3.703 | ppl 13.03 | wps 40142.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 31461 | lr 0.000178285 | gnorm 1.101 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 51246
KL Stats: Epoch 306 Divergences: Uniform: 5.434942136682452 Unigram: 5.718373788073905
2022-03-15 00:29:06 | INFO | fairseq.trainer | begin training epoch 307
2022-03-15 00:29:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:30:08 | INFO | train_inner | epoch 307:     39 / 103 loss=3.703, ppl=13.02, wps=40088.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=31500, lr=0.000178174, gnorm=1.086, loss_scale=8, train_wall=153, gb_free=20.8, wall=51308
2022-03-15 00:31:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:31:53 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 9.791 | ppl 886.05 | wps 65719.3 | wpb 2040.3 | bsz 4 | num_updates 31564 | best_loss 7.59
2022-03-15 00:31:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 31564 updates
2022-03-15 00:31:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:31:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:31:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 307 @ 31564 updates, score 9.791) (writing took 0.9280539788305759 seconds)
2022-03-15 00:31:54 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-15 00:31:54 | INFO | train | epoch 307 | loss 3.7 | ppl 13 | wps 40083 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 31564 | lr 0.000177993 | gnorm 1.075 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 51413
KL Stats: Epoch 307 Divergences: Uniform: 5.4362398601446404 Unigram: 5.718817525893812
2022-03-15 00:31:54 | INFO | fairseq.trainer | begin training epoch 308
2022-03-15 00:31:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:32:51 | INFO | train_inner | epoch 308:     36 / 103 loss=3.701, ppl=13.01, wps=40046.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=31600, lr=0.000177892, gnorm=1.086, loss_scale=16, train_wall=154, gb_free=20.8, wall=51471
2022-03-15 00:34:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:34:41 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 9.818 | ppl 902.69 | wps 66103.5 | wpb 2040.3 | bsz 4 | num_updates 31667 | best_loss 7.59
2022-03-15 00:34:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 31667 updates
2022-03-15 00:34:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:34:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:34:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 308 @ 31667 updates, score 9.818) (writing took 0.8761056214570999 seconds)
2022-03-15 00:34:42 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-15 00:34:42 | INFO | train | epoch 308 | loss 3.7 | ppl 13 | wps 40110.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 31667 | lr 0.000177704 | gnorm 1.085 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 51581
KL Stats: Epoch 308 Divergences: Uniform: 5.436133879184196 Unigram: 5.7204678354828005
2022-03-15 00:34:42 | INFO | fairseq.trainer | begin training epoch 309
2022-03-15 00:34:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:35:34 | INFO | train_inner | epoch 309:     33 / 103 loss=3.699, ppl=12.98, wps=40086.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=31700, lr=0.000177611, gnorm=1.08, loss_scale=16, train_wall=153, gb_free=20.8, wall=51634
2022-03-15 00:37:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:37:28 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 9.771 | ppl 873.77 | wps 66296.1 | wpb 2040.3 | bsz 4 | num_updates 31770 | best_loss 7.59
2022-03-15 00:37:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 31770 updates
2022-03-15 00:37:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:37:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:37:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 309 @ 31770 updates, score 9.771) (writing took 0.8980901129543781 seconds)
2022-03-15 00:37:29 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-15 00:37:29 | INFO | train | epoch 309 | loss 3.698 | ppl 12.98 | wps 40125.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 31770 | lr 0.000177415 | gnorm 1.085 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 51749
KL Stats: Epoch 309 Divergences: Uniform: 5.436390233153848 Unigram: 5.722307651066614
2022-03-15 00:37:29 | INFO | fairseq.trainer | begin training epoch 310
2022-03-15 00:37:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:38:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 00:38:19 | INFO | train_inner | epoch 310:     31 / 103 loss=3.7, ppl=13, wps=39721.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=31800, lr=0.000177332, gnorm=1.09, loss_scale=8, train_wall=155, gb_free=20.8, wall=51798
2022-03-15 00:40:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:40:16 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 9.792 | ppl 886.26 | wps 66359.1 | wpb 2040.3 | bsz 4 | num_updates 31872 | best_loss 7.59
2022-03-15 00:40:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 31872 updates
2022-03-15 00:40:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:40:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:40:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 310 @ 31872 updates, score 9.792) (writing took 0.8985035913065076 seconds)
2022-03-15 00:40:17 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-15 00:40:17 | INFO | train | epoch 310 | loss 3.697 | ppl 12.97 | wps 39763 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 31872 | lr 0.000177131 | gnorm 1.091 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 51916
KL Stats: Epoch 310 Divergences: Uniform: 5.437623097432716 Unigram: 5.724158483816009
2022-03-15 00:40:17 | INFO | fairseq.trainer | begin training epoch 311
2022-03-15 00:40:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:41:01 | INFO | train_inner | epoch 311:     28 / 103 loss=3.697, ppl=12.97, wps=40116.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=31900, lr=0.000177054, gnorm=1.091, loss_scale=8, train_wall=153, gb_free=20.8, wall=51961
2022-03-15 00:43:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:43:03 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 9.786 | ppl 882.68 | wps 66251.8 | wpb 2040.3 | bsz 4 | num_updates 31975 | best_loss 7.59
2022-03-15 00:43:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 31975 updates
2022-03-15 00:43:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:43:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:43:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 311 @ 31975 updates, score 9.786) (writing took 0.9028007220476866 seconds)
2022-03-15 00:43:04 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-15 00:43:04 | INFO | train | epoch 311 | loss 3.695 | ppl 12.95 | wps 40137.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 31975 | lr 0.000176846 | gnorm 1.093 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 52084
KL Stats: Epoch 311 Divergences: Uniform: 5.437075514546121 Unigram: 5.725998421599209
2022-03-15 00:43:04 | INFO | fairseq.trainer | begin training epoch 312
2022-03-15 00:43:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:43:44 | INFO | train_inner | epoch 312:     25 / 103 loss=3.696, ppl=12.96, wps=40090.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32000, lr=0.000176777, gnorm=1.091, loss_scale=8, train_wall=153, gb_free=20.8, wall=52124
2022-03-15 00:45:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:45:51 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 9.794 | ppl 887.94 | wps 65917.7 | wpb 2040.3 | bsz 4 | num_updates 32078 | best_loss 7.59
2022-03-15 00:45:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 32078 updates
2022-03-15 00:45:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:45:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:45:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 312 @ 32078 updates, score 9.794) (writing took 0.8893568199127913 seconds)
2022-03-15 00:45:52 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-15 00:45:52 | INFO | train | epoch 312 | loss 3.694 | ppl 12.94 | wps 40120.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32078 | lr 0.000176562 | gnorm 1.08 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 52252
KL Stats: Epoch 312 Divergences: Uniform: 5.440368327554336 Unigram: 5.73052342012552
2022-03-15 00:45:52 | INFO | fairseq.trainer | begin training epoch 313
2022-03-15 00:45:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:46:27 | INFO | train_inner | epoch 313:     22 / 103 loss=3.693, ppl=12.94, wps=40099.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32100, lr=0.000176501, gnorm=1.084, loss_scale=8, train_wall=153, gb_free=20.8, wall=52287
2022-03-15 00:48:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:48:39 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 9.798 | ppl 890.06 | wps 65743.8 | wpb 2040.3 | bsz 4 | num_updates 32181 | best_loss 7.59
2022-03-15 00:48:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 32181 updates
2022-03-15 00:48:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:48:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:48:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 313 @ 32181 updates, score 9.798) (writing took 0.9280700022354722 seconds)
2022-03-15 00:48:40 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-15 00:48:40 | INFO | train | epoch 313 | loss 3.693 | ppl 12.93 | wps 40123.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32181 | lr 0.000176279 | gnorm 1.097 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 52419
KL Stats: Epoch 313 Divergences: Uniform: 5.4406032385480625 Unigram: 5.731298840611505
2022-03-15 00:48:40 | INFO | fairseq.trainer | begin training epoch 314
2022-03-15 00:48:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:49:10 | INFO | train_inner | epoch 314:     19 / 103 loss=3.693, ppl=12.93, wps=40091.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32200, lr=0.000176227, gnorm=1.099, loss_scale=8, train_wall=153, gb_free=20.8, wall=52450
2022-03-15 00:51:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:51:26 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 9.801 | ppl 892.22 | wps 66191.4 | wpb 2040.3 | bsz 4 | num_updates 32284 | best_loss 7.59
2022-03-15 00:51:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 32284 updates
2022-03-15 00:51:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:51:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:51:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 314 @ 32284 updates, score 9.801) (writing took 0.910210408270359 seconds)
2022-03-15 00:51:27 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-15 00:51:27 | INFO | train | epoch 314 | loss 3.69 | ppl 12.91 | wps 40143 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32284 | lr 0.000175997 | gnorm 1.094 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 52587
KL Stats: Epoch 314 Divergences: Uniform: 5.441103511051292 Unigram: 5.733702413454438
2022-03-15 00:51:27 | INFO | fairseq.trainer | begin training epoch 315
2022-03-15 00:51:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:51:53 | INFO | train_inner | epoch 315:     16 / 103 loss=3.694, ppl=12.94, wps=40105.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32300, lr=0.000175954, gnorm=1.098, loss_scale=8, train_wall=153, gb_free=20.8, wall=52612
2022-03-15 00:54:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:54:14 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 9.804 | ppl 894.01 | wps 66092.5 | wpb 2040.3 | bsz 4 | num_updates 32387 | best_loss 7.59
2022-03-15 00:54:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 32387 updates
2022-03-15 00:54:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:54:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:54:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 315 @ 32387 updates, score 9.804) (writing took 0.9261322934180498 seconds)
2022-03-15 00:54:15 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-15 00:54:15 | INFO | train | epoch 315 | loss 3.689 | ppl 12.9 | wps 40093.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32387 | lr 0.000175717 | gnorm 1.097 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 52755
KL Stats: Epoch 315 Divergences: Uniform: 5.442414479397728 Unigram: 5.734662050988666
2022-03-15 00:54:15 | INFO | fairseq.trainer | begin training epoch 316
2022-03-15 00:54:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:54:36 | INFO | train_inner | epoch 316:     13 / 103 loss=3.689, ppl=12.9, wps=40061.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32400, lr=0.000175682, gnorm=1.095, loss_scale=16, train_wall=154, gb_free=20.8, wall=52775
2022-03-15 00:55:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 00:56:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:57:02 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 9.806 | ppl 895.36 | wps 65997.2 | wpb 2040.3 | bsz 4 | num_updates 32489 | best_loss 7.59
2022-03-15 00:57:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 32489 updates
2022-03-15 00:57:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:57:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:57:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 316 @ 32489 updates, score 9.806) (writing took 0.9132965309545398 seconds)
2022-03-15 00:57:03 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-15 00:57:03 | INFO | train | epoch 316 | loss 3.687 | ppl 12.88 | wps 39712 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 32489 | lr 0.000175441 | gnorm 1.099 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 52922
KL Stats: Epoch 316 Divergences: Uniform: 5.442826375999886 Unigram: 5.736166599718426
2022-03-15 00:57:03 | INFO | fairseq.trainer | begin training epoch 317
2022-03-15 00:57:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:57:20 | INFO | train_inner | epoch 317:     11 / 103 loss=3.688, ppl=12.88, wps=39676.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32500, lr=0.000175412, gnorm=1.097, loss_scale=8, train_wall=155, gb_free=20.8, wall=52940
2022-03-15 00:59:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:59:50 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 9.804 | ppl 893.97 | wps 65686.1 | wpb 2040.3 | bsz 4 | num_updates 32592 | best_loss 7.59
2022-03-15 00:59:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 32592 updates
2022-03-15 00:59:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:59:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 00:59:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 317 @ 32592 updates, score 9.804) (writing took 0.8806689595803618 seconds)
2022-03-15 00:59:51 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-15 00:59:51 | INFO | train | epoch 317 | loss 3.686 | ppl 12.87 | wps 40108.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32592 | lr 0.000175164 | gnorm 1.101 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 53090
KL Stats: Epoch 317 Divergences: Uniform: 5.443871478536367 Unigram: 5.737252792044131
2022-03-15 00:59:51 | INFO | fairseq.trainer | begin training epoch 318
2022-03-15 00:59:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:00:03 | INFO | train_inner | epoch 318:      8 / 103 loss=3.688, ppl=12.89, wps=40078.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32600, lr=0.000175142, gnorm=1.1, loss_scale=8, train_wall=153, gb_free=20.8, wall=53103
2022-03-15 01:02:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:02:37 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 9.809 | ppl 897.25 | wps 66051.9 | wpb 2040.3 | bsz 4 | num_updates 32695 | best_loss 7.59
2022-03-15 01:02:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 32695 updates
2022-03-15 01:02:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:02:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:02:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 318 @ 32695 updates, score 9.809) (writing took 0.900234017521143 seconds)
2022-03-15 01:02:38 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-15 01:02:38 | INFO | train | epoch 318 | loss 3.685 | ppl 12.86 | wps 40138.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32695 | lr 0.000174888 | gnorm 1.095 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 53258
KL Stats: Epoch 318 Divergences: Uniform: 5.443517158819762 Unigram: 5.738164625627322
2022-03-15 01:02:38 | INFO | fairseq.trainer | begin training epoch 319
2022-03-15 01:02:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:02:46 | INFO | train_inner | epoch 319:      5 / 103 loss=3.686, ppl=12.87, wps=40107.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32700, lr=0.000174874, gnorm=1.1, loss_scale=8, train_wall=153, gb_free=20.8, wall=53266
2022-03-15 01:05:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:05:25 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 9.82 | ppl 903.75 | wps 65950 | wpb 2040.3 | bsz 4 | num_updates 32798 | best_loss 7.59
2022-03-15 01:05:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 32798 updates
2022-03-15 01:05:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:05:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:05:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 319 @ 32798 updates, score 9.82) (writing took 0.8964058291167021 seconds)
2022-03-15 01:05:26 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-15 01:05:26 | INFO | train | epoch 319 | loss 3.683 | ppl 12.84 | wps 40101.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32798 | lr 0.000174613 | gnorm 1.11 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 53425
KL Stats: Epoch 319 Divergences: Uniform: 5.444970525788577 Unigram: 5.742309553336466
2022-03-15 01:05:26 | INFO | fairseq.trainer | begin training epoch 320
2022-03-15 01:05:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:05:29 | INFO | train_inner | epoch 320:      2 / 103 loss=3.686, ppl=12.87, wps=40065.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32800, lr=0.000174608, gnorm=1.109, loss_scale=8, train_wall=153, gb_free=20.8, wall=53429
2022-03-15 01:08:08 | INFO | train_inner | epoch 320:    102 / 103 loss=3.681, ppl=12.83, wps=41288.1, ups=0.63, wpb=65530.9, bsz=128, num_updates=32900, lr=0.000174342, gnorm=1.081, loss_scale=8, train_wall=154, gb_free=20.8, wall=53587
2022-03-15 01:08:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:08:13 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 9.826 | ppl 907.42 | wps 65826.2 | wpb 2040.3 | bsz 4 | num_updates 32901 | best_loss 7.59
2022-03-15 01:08:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 32901 updates
2022-03-15 01:08:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:08:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:08:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 320 @ 32901 updates, score 9.826) (writing took 0.9092727489769459 seconds)
2022-03-15 01:08:13 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-15 01:08:13 | INFO | train | epoch 320 | loss 3.681 | ppl 12.83 | wps 40156.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32901 | lr 0.000174339 | gnorm 1.084 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 53593
KL Stats: Epoch 320 Divergences: Uniform: 5.445913344352023 Unigram: 5.744542266744689
2022-03-15 01:08:13 | INFO | fairseq.trainer | begin training epoch 321
2022-03-15 01:08:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:10:51 | INFO | train_inner | epoch 321:     99 / 103 loss=3.678, ppl=12.8, wps=40075.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=33000, lr=0.000174078, gnorm=1.094, loss_scale=16, train_wall=153, gb_free=20.8, wall=53750
2022-03-15 01:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:11:00 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 9.792 | ppl 886.65 | wps 66289.5 | wpb 2040.3 | bsz 4 | num_updates 33004 | best_loss 7.59
2022-03-15 01:11:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 33004 updates
2022-03-15 01:11:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:11:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:11:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 321 @ 33004 updates, score 9.792) (writing took 0.9083588672801852 seconds)
2022-03-15 01:11:01 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-15 01:11:01 | INFO | train | epoch 321 | loss 3.68 | ppl 12.81 | wps 40112.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 33004 | lr 0.000174067 | gnorm 1.094 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 53761
KL Stats: Epoch 321 Divergences: Uniform: 5.446901351013969 Unigram: 5.744245159209498
2022-03-15 01:11:01 | INFO | fairseq.trainer | begin training epoch 322
2022-03-15 01:11:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:13:34 | INFO | train_inner | epoch 322:     96 / 103 loss=3.678, ppl=12.8, wps=40120.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=33100, lr=0.000173814, gnorm=1.099, loss_scale=16, train_wall=153, gb_free=20.8, wall=53913
2022-03-15 01:13:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:13:48 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 9.829 | ppl 909.41 | wps 66278.4 | wpb 2040.3 | bsz 4 | num_updates 33107 | best_loss 7.59
2022-03-15 01:13:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 33107 updates
2022-03-15 01:13:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:13:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:13:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 322 @ 33107 updates, score 9.829) (writing took 0.9111925000324845 seconds)
2022-03-15 01:13:49 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-15 01:13:49 | INFO | train | epoch 322 | loss 3.679 | ppl 12.81 | wps 40156.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 33107 | lr 0.000173796 | gnorm 1.097 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 53928
KL Stats: Epoch 322 Divergences: Uniform: 5.446509811833485 Unigram: 5.74776301859231
2022-03-15 01:13:49 | INFO | fairseq.trainer | begin training epoch 323
2022-03-15 01:13:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:16:16 | INFO | train_inner | epoch 323:     93 / 103 loss=3.675, ppl=12.77, wps=40157.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=33200, lr=0.000173553, gnorm=1.094, loss_scale=16, train_wall=153, gb_free=20.8, wall=54076
2022-03-15 01:16:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 01:16:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:16:35 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 9.826 | ppl 907.9 | wps 66292.7 | wpb 2040.3 | bsz 4 | num_updates 33209 | best_loss 7.59
2022-03-15 01:16:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 33209 updates
2022-03-15 01:16:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:16:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:16:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 323 @ 33209 updates, score 9.826) (writing took 0.9437971590086818 seconds)
2022-03-15 01:16:36 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-15 01:16:36 | INFO | train | epoch 323 | loss 3.675 | ppl 12.78 | wps 39796.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 33209 | lr 0.000173529 | gnorm 1.098 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 54096
KL Stats: Epoch 323 Divergences: Uniform: 5.44746504633161 Unigram: 5.74986534651784
2022-03-15 01:16:36 | INFO | fairseq.trainer | begin training epoch 324
2022-03-15 01:16:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:19:00 | INFO | train_inner | epoch 324:     91 / 103 loss=3.674, ppl=12.76, wps=39797.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=33300, lr=0.000173292, gnorm=1.104, loss_scale=8, train_wall=155, gb_free=20.8, wall=54240
2022-03-15 01:19:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:19:22 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 9.795 | ppl 888.12 | wps 66293.2 | wpb 2040.3 | bsz 4 | num_updates 33312 | best_loss 7.59
2022-03-15 01:19:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 33312 updates
2022-03-15 01:19:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:19:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:19:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 324 @ 33312 updates, score 9.795) (writing took 0.9691788330674171 seconds)
2022-03-15 01:19:23 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-15 01:19:23 | INFO | train | epoch 324 | loss 3.675 | ppl 12.78 | wps 40208.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 33312 | lr 0.000173261 | gnorm 1.106 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 54263
KL Stats: Epoch 324 Divergences: Uniform: 5.448434510885156 Unigram: 5.750907622404333
2022-03-15 01:19:23 | INFO | fairseq.trainer | begin training epoch 325
2022-03-15 01:19:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:21:43 | INFO | train_inner | epoch 325:     88 / 103 loss=3.671, ppl=12.74, wps=40151.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=33400, lr=0.000173032, gnorm=1.093, loss_scale=8, train_wall=153, gb_free=20.8, wall=54403
2022-03-15 01:22:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:22:10 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 9.811 | ppl 898.5 | wps 65823.3 | wpb 2040.3 | bsz 4 | num_updates 33415 | best_loss 7.59
2022-03-15 01:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 33415 updates
2022-03-15 01:22:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:22:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:22:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 325 @ 33415 updates, score 9.811) (writing took 1.0454898197203875 seconds)
2022-03-15 01:22:11 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-15 01:22:11 | INFO | train | epoch 325 | loss 3.673 | ppl 12.75 | wps 40167.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 33415 | lr 0.000172993 | gnorm 1.091 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 54430
KL Stats: Epoch 325 Divergences: Uniform: 5.450349973922005 Unigram: 5.754533125697448
2022-03-15 01:22:11 | INFO | fairseq.trainer | begin training epoch 326
2022-03-15 01:22:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:24:26 | INFO | train_inner | epoch 326:     85 / 103 loss=3.671, ppl=12.74, wps=40157.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=33500, lr=0.000172774, gnorm=1.101, loss_scale=8, train_wall=153, gb_free=20.8, wall=54565
2022-03-15 01:24:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:24:57 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 9.819 | ppl 903.43 | wps 65597.4 | wpb 2040.3 | bsz 4 | num_updates 33518 | best_loss 7.59
2022-03-15 01:24:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 33518 updates
2022-03-15 01:24:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:24:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:24:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 326 @ 33518 updates, score 9.819) (writing took 1.0862863706424832 seconds)
2022-03-15 01:24:58 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-15 01:24:58 | INFO | train | epoch 326 | loss 3.673 | ppl 12.75 | wps 40178.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 33518 | lr 0.000172727 | gnorm 1.099 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 54598
KL Stats: Epoch 326 Divergences: Uniform: 5.449460342045258 Unigram: 5.75500318731355
2022-03-15 01:24:58 | INFO | fairseq.trainer | begin training epoch 327
2022-03-15 01:24:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:27:08 | INFO | train_inner | epoch 327:     82 / 103 loss=3.669, ppl=12.72, wps=40121.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=33600, lr=0.000172516, gnorm=1.093, loss_scale=8, train_wall=153, gb_free=20.8, wall=54728
2022-03-15 01:27:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:27:45 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 9.837 | ppl 914.53 | wps 66204.1 | wpb 2040.3 | bsz 4 | num_updates 33621 | best_loss 7.59
2022-03-15 01:27:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 33621 updates
2022-03-15 01:27:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:27:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:27:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 327 @ 33621 updates, score 9.837) (writing took 1.0048671597614884 seconds)
2022-03-15 01:27:46 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-15 01:27:46 | INFO | train | epoch 327 | loss 3.67 | ppl 12.73 | wps 40177.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 33621 | lr 0.000172463 | gnorm 1.092 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 54765
KL Stats: Epoch 327 Divergences: Uniform: 5.450899814550997 Unigram: 5.758104335424346
2022-03-15 01:27:46 | INFO | fairseq.trainer | begin training epoch 328
2022-03-15 01:27:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:29:51 | INFO | train_inner | epoch 328:     79 / 103 loss=3.67, ppl=12.73, wps=40154.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=33700, lr=0.00017226, gnorm=1.101, loss_scale=8, train_wall=153, gb_free=20.8, wall=54891
2022-03-15 01:30:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:30:32 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 9.839 | ppl 915.82 | wps 66035.7 | wpb 2040.3 | bsz 4 | num_updates 33724 | best_loss 7.59
2022-03-15 01:30:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 33724 updates
2022-03-15 01:30:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:30:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:30:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 328 @ 33724 updates, score 9.839) (writing took 1.0323065100237727 seconds)
2022-03-15 01:30:33 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-15 01:30:33 | INFO | train | epoch 328 | loss 3.669 | ppl 12.72 | wps 40184 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 33724 | lr 0.000172199 | gnorm 1.099 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 54933
KL Stats: Epoch 328 Divergences: Uniform: 5.450941062946888 Unigram: 5.759127618355451
2022-03-15 01:30:33 | INFO | fairseq.trainer | begin training epoch 329
2022-03-15 01:30:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:31:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 01:32:35 | INFO | train_inner | epoch 329:     77 / 103 loss=3.666, ppl=12.69, wps=39765.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=33800, lr=0.000172005, gnorm=1.09, loss_scale=8, train_wall=155, gb_free=20.8, wall=55055
2022-03-15 01:33:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:33:19 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 9.809 | ppl 896.94 | wps 66419.9 | wpb 2040.3 | bsz 4 | num_updates 33826 | best_loss 7.59
2022-03-15 01:33:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 33826 updates
2022-03-15 01:33:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:33:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:33:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 329 @ 33826 updates, score 9.809) (writing took 1.035269981250167 seconds)
2022-03-15 01:33:21 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-15 01:33:21 | INFO | train | epoch 329 | loss 3.668 | ppl 12.71 | wps 39796.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 33826 | lr 0.000171939 | gnorm 1.092 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 55100
KL Stats: Epoch 329 Divergences: Uniform: 5.4511472422833736 Unigram: 5.760012943229942
2022-03-15 01:33:21 | INFO | fairseq.trainer | begin training epoch 330
2022-03-15 01:33:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:35:18 | INFO | train_inner | epoch 330:     74 / 103 loss=3.669, ppl=12.72, wps=40149.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=33900, lr=0.000171751, gnorm=1.098, loss_scale=8, train_wall=153, gb_free=20.8, wall=55217
2022-03-15 01:36:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:36:07 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 9.834 | ppl 912.69 | wps 66408.7 | wpb 2040.3 | bsz 4 | num_updates 33929 | best_loss 7.59
2022-03-15 01:36:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 33929 updates
2022-03-15 01:36:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:36:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:36:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 330 @ 33929 updates, score 9.834) (writing took 1.0028252582997084 seconds)
2022-03-15 01:36:08 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-15 01:36:08 | INFO | train | epoch 330 | loss 3.667 | ppl 12.7 | wps 40188.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 33929 | lr 0.000171678 | gnorm 1.092 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 55267
KL Stats: Epoch 330 Divergences: Uniform: 5.452848451003383 Unigram: 5.762005909859761
2022-03-15 01:36:08 | INFO | fairseq.trainer | begin training epoch 331
2022-03-15 01:36:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:38:00 | INFO | train_inner | epoch 331:     71 / 103 loss=3.662, ppl=12.66, wps=40173, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=34000, lr=0.000171499, gnorm=1.094, loss_scale=8, train_wall=153, gb_free=20.8, wall=55380
2022-03-15 01:38:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:38:54 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 9.842 | ppl 917.52 | wps 65903.9 | wpb 2040.3 | bsz 4 | num_updates 34032 | best_loss 7.59
2022-03-15 01:38:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 34032 updates
2022-03-15 01:38:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:38:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:38:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 331 @ 34032 updates, score 9.842) (writing took 0.9857778316363692 seconds)
2022-03-15 01:38:55 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-15 01:38:55 | INFO | train | epoch 331 | loss 3.666 | ppl 12.69 | wps 40207.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34032 | lr 0.000171418 | gnorm 1.108 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 55435
KL Stats: Epoch 331 Divergences: Uniform: 5.4510441530710985 Unigram: 5.760426276551752
2022-03-15 01:38:55 | INFO | fairseq.trainer | begin training epoch 332
2022-03-15 01:38:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:40:43 | INFO | train_inner | epoch 332:     68 / 103 loss=3.667, ppl=12.71, wps=40170.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=34100, lr=0.000171247, gnorm=1.108, loss_scale=8, train_wall=153, gb_free=20.8, wall=55543
2022-03-15 01:41:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:41:41 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 9.837 | ppl 914.77 | wps 66460.1 | wpb 2040.3 | bsz 4 | num_updates 34135 | best_loss 7.59
2022-03-15 01:41:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 34135 updates
2022-03-15 01:41:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:41:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:41:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 332 @ 34135 updates, score 9.837) (writing took 0.9914690461009741 seconds)
2022-03-15 01:41:42 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-15 01:41:42 | INFO | train | epoch 332 | loss 3.663 | ppl 12.67 | wps 40216.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34135 | lr 0.000171159 | gnorm 1.106 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 55602
KL Stats: Epoch 332 Divergences: Uniform: 5.454802069571054 Unigram: 5.763610234879623
2022-03-15 01:41:43 | INFO | fairseq.trainer | begin training epoch 333
2022-03-15 01:41:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:43:26 | INFO | train_inner | epoch 333:     65 / 103 loss=3.66, ppl=12.64, wps=40189, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=34200, lr=0.000170996, gnorm=1.107, loss_scale=8, train_wall=153, gb_free=20.8, wall=55705
2022-03-15 01:44:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:44:29 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 9.823 | ppl 905.73 | wps 65773.1 | wpb 2040.3 | bsz 4 | num_updates 34238 | best_loss 7.59
2022-03-15 01:44:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 34238 updates
2022-03-15 01:44:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:44:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:44:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 333 @ 34238 updates, score 9.823) (writing took 0.9837375683709979 seconds)
2022-03-15 01:44:30 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-15 01:44:30 | INFO | train | epoch 333 | loss 3.662 | ppl 12.66 | wps 40207.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34238 | lr 0.000170901 | gnorm 1.096 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 55769
KL Stats: Epoch 333 Divergences: Uniform: 5.453518991656232 Unigram: 5.766162246866847
2022-03-15 01:44:30 | INFO | fairseq.trainer | begin training epoch 334
2022-03-15 01:44:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:46:08 | INFO | train_inner | epoch 334:     62 / 103 loss=3.661, ppl=12.65, wps=40186.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=34300, lr=0.000170747, gnorm=1.094, loss_scale=16, train_wall=153, gb_free=20.8, wall=55868
2022-03-15 01:46:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 01:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:47:16 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 9.844 | ppl 919.31 | wps 66112.9 | wpb 2040.3 | bsz 4 | num_updates 34340 | best_loss 7.59
2022-03-15 01:47:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 34340 updates
2022-03-15 01:47:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:47:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:47:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 334 @ 34340 updates, score 9.844) (writing took 0.9625819372013211 seconds)
2022-03-15 01:47:17 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-15 01:47:17 | INFO | train | epoch 334 | loss 3.661 | ppl 12.65 | wps 39820.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 34340 | lr 0.000170647 | gnorm 1.098 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 55937
KL Stats: Epoch 334 Divergences: Uniform: 5.4555037160005675 Unigram: 5.768574327087964
2022-03-15 01:47:17 | INFO | fairseq.trainer | begin training epoch 335
2022-03-15 01:47:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:48:52 | INFO | train_inner | epoch 335:     60 / 103 loss=3.66, ppl=12.64, wps=39793.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=34400, lr=0.000170499, gnorm=1.092, loss_scale=8, train_wall=155, gb_free=20.8, wall=56032
2022-03-15 01:50:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:50:03 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 9.848 | ppl 921.61 | wps 66296.4 | wpb 2040.3 | bsz 4 | num_updates 34443 | best_loss 7.59
2022-03-15 01:50:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 34443 updates
2022-03-15 01:50:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:50:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:50:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 335 @ 34443 updates, score 9.848) (writing took 0.9743692902848125 seconds)
2022-03-15 01:50:04 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-15 01:50:04 | INFO | train | epoch 335 | loss 3.659 | ppl 12.63 | wps 40219.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34443 | lr 0.000170392 | gnorm 1.089 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 56104
KL Stats: Epoch 335 Divergences: Uniform: 5.45464274493067 Unigram: 5.769390715374233
2022-03-15 01:50:04 | INFO | fairseq.trainer | begin training epoch 336
2022-03-15 01:50:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:51:35 | INFO | train_inner | epoch 336:     57 / 103 loss=3.658, ppl=12.62, wps=40167.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=34500, lr=0.000170251, gnorm=1.094, loss_scale=8, train_wall=153, gb_free=20.8, wall=56194
2022-03-15 01:52:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:52:51 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 9.846 | ppl 920.4 | wps 66080.6 | wpb 2040.3 | bsz 4 | num_updates 34546 | best_loss 7.59
2022-03-15 01:52:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 34546 updates
2022-03-15 01:52:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:52:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:52:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 336 @ 34546 updates, score 9.846) (writing took 0.9676903700456023 seconds)
2022-03-15 01:52:52 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-15 01:52:52 | INFO | train | epoch 336 | loss 3.658 | ppl 12.63 | wps 40197.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34546 | lr 0.000170138 | gnorm 1.11 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 56271
KL Stats: Epoch 336 Divergences: Uniform: 5.455112340126725 Unigram: 5.771246319511612
2022-03-15 01:52:52 | INFO | fairseq.trainer | begin training epoch 337
2022-03-15 01:52:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:54:17 | INFO | train_inner | epoch 337:     54 / 103 loss=3.656, ppl=12.61, wps=40147.1, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=34600, lr=0.000170005, gnorm=1.107, loss_scale=8, train_wall=153, gb_free=20.8, wall=56357
2022-03-15 01:55:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:55:38 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 9.828 | ppl 908.78 | wps 66006.1 | wpb 2040.3 | bsz 4 | num_updates 34649 | best_loss 7.59
2022-03-15 01:55:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 34649 updates
2022-03-15 01:55:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:55:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:55:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 337 @ 34649 updates, score 9.828) (writing took 0.9854817809537053 seconds)
2022-03-15 01:55:39 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-15 01:55:39 | INFO | train | epoch 337 | loss 3.657 | ppl 12.62 | wps 40160.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 34649 | lr 0.000169885 | gnorm 1.097 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 56439
KL Stats: Epoch 337 Divergences: Uniform: 5.455250756676559 Unigram: 5.77232308396525
2022-03-15 01:55:39 | INFO | fairseq.trainer | begin training epoch 338
2022-03-15 01:55:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:57:00 | INFO | train_inner | epoch 338:     51 / 103 loss=3.658, ppl=12.62, wps=40148.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=34700, lr=0.00016976, gnorm=1.094, loss_scale=8, train_wall=153, gb_free=20.8, wall=56520
2022-03-15 01:58:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:58:26 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 9.852 | ppl 924.05 | wps 66021 | wpb 2040.3 | bsz 4 | num_updates 34752 | best_loss 7.59
2022-03-15 01:58:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 34752 updates
2022-03-15 01:58:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:58:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 01:58:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 338 @ 34752 updates, score 9.852) (writing took 0.9934974918141961 seconds)
2022-03-15 01:58:27 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-15 01:58:27 | INFO | train | epoch 338 | loss 3.654 | ppl 12.59 | wps 40203.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34752 | lr 0.000169633 | gnorm 1.08 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 56606
KL Stats: Epoch 338 Divergences: Uniform: 5.456601986073097 Unigram: 5.774818312521146
2022-03-15 01:58:27 | INFO | fairseq.trainer | begin training epoch 339
2022-03-15 01:58:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:59:43 | INFO | train_inner | epoch 339:     48 / 103 loss=3.652, ppl=12.57, wps=40172.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=34800, lr=0.000169516, gnorm=1.077, loss_scale=8, train_wall=153, gb_free=20.8, wall=56682
2022-03-15 02:01:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:01:13 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 9.847 | ppl 921.18 | wps 65815.3 | wpb 2040.3 | bsz 4 | num_updates 34855 | best_loss 7.59
2022-03-15 02:01:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 34855 updates
2022-03-15 02:01:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:01:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:01:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 339 @ 34855 updates, score 9.847) (writing took 0.9551910609006882 seconds)
2022-03-15 02:01:14 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-15 02:01:14 | INFO | train | epoch 339 | loss 3.654 | ppl 12.59 | wps 40207.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34855 | lr 0.000169382 | gnorm 1.092 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 56773
KL Stats: Epoch 339 Divergences: Uniform: 5.45782553212263 Unigram: 5.776310862982786
2022-03-15 02:01:14 | INFO | fairseq.trainer | begin training epoch 340
2022-03-15 02:01:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:01:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 02:02:27 | INFO | train_inner | epoch 340:     46 / 103 loss=3.654, ppl=12.58, wps=39791, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=34900, lr=0.000169273, gnorm=1.103, loss_scale=8, train_wall=155, gb_free=20.8, wall=56846
2022-03-15 02:03:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:04:00 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 9.819 | ppl 903.43 | wps 65849.6 | wpb 2040.3 | bsz 4 | num_updates 34957 | best_loss 7.59
2022-03-15 02:04:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 34957 updates
2022-03-15 02:04:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:04:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:04:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 340 @ 34957 updates, score 9.819) (writing took 0.9568032352253795 seconds)
2022-03-15 02:04:01 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-15 02:04:01 | INFO | train | epoch 340 | loss 3.651 | ppl 12.56 | wps 39828.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 34957 | lr 0.000169135 | gnorm 1.097 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 56941
KL Stats: Epoch 340 Divergences: Uniform: 5.460951517363952 Unigram: 5.780368998121715
2022-03-15 02:04:01 | INFO | fairseq.trainer | begin training epoch 341
2022-03-15 02:04:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:05:09 | INFO | train_inner | epoch 341:     43 / 103 loss=3.651, ppl=12.56, wps=40169.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=35000, lr=0.000169031, gnorm=1.092, loss_scale=8, train_wall=153, gb_free=20.8, wall=57009
2022-03-15 02:06:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:06:47 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 9.865 | ppl 932.73 | wps 66155.3 | wpb 2040.3 | bsz 4 | num_updates 35060 | best_loss 7.59
2022-03-15 02:06:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 35060 updates
2022-03-15 02:06:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:06:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:06:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 341 @ 35060 updates, score 9.865) (writing took 0.9972446598112583 seconds)
2022-03-15 02:06:48 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-15 02:06:48 | INFO | train | epoch 341 | loss 3.65 | ppl 12.56 | wps 40190.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35060 | lr 0.000168886 | gnorm 1.102 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 57108
KL Stats: Epoch 341 Divergences: Uniform: 5.459266683922922 Unigram: 5.779000258928013
2022-03-15 02:06:49 | INFO | fairseq.trainer | begin training epoch 342
2022-03-15 02:06:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:07:52 | INFO | train_inner | epoch 342:     40 / 103 loss=3.652, ppl=12.57, wps=40160.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=35100, lr=0.00016879, gnorm=1.101, loss_scale=8, train_wall=153, gb_free=20.8, wall=57172
2022-03-15 02:09:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:09:35 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 9.85 | ppl 922.67 | wps 66075.8 | wpb 2040.3 | bsz 4 | num_updates 35163 | best_loss 7.59
2022-03-15 02:09:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 35163 updates
2022-03-15 02:09:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:09:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:09:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 342 @ 35163 updates, score 9.85) (writing took 0.9482789766043425 seconds)
2022-03-15 02:09:36 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-15 02:09:36 | INFO | train | epoch 342 | loss 3.649 | ppl 12.55 | wps 40219.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35163 | lr 0.000168639 | gnorm 1.089 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 57275
KL Stats: Epoch 342 Divergences: Uniform: 5.461662228083777 Unigram: 5.782215641438413
2022-03-15 02:09:36 | INFO | fairseq.trainer | begin training epoch 343
2022-03-15 02:09:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:10:34 | INFO | train_inner | epoch 343:     37 / 103 loss=3.646, ppl=12.52, wps=40183.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=35200, lr=0.00016855, gnorm=1.098, loss_scale=8, train_wall=153, gb_free=20.8, wall=57334
2022-03-15 02:12:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:12:22 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 9.864 | ppl 931.93 | wps 65923.2 | wpb 2040.3 | bsz 4 | num_updates 35266 | best_loss 7.59
2022-03-15 02:12:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 35266 updates
2022-03-15 02:12:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:12:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:12:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 343 @ 35266 updates, score 9.864) (writing took 0.9857656173408031 seconds)
2022-03-15 02:12:23 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-15 02:12:23 | INFO | train | epoch 343 | loss 3.649 | ppl 12.54 | wps 40193.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35266 | lr 0.000168392 | gnorm 1.11 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 57443
KL Stats: Epoch 343 Divergences: Uniform: 5.46015376967514 Unigram: 5.783042744267903
2022-03-15 02:12:23 | INFO | fairseq.trainer | begin training epoch 344
2022-03-15 02:12:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:13:17 | INFO | train_inner | epoch 344:     34 / 103 loss=3.651, ppl=12.56, wps=40158.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=35300, lr=0.000168311, gnorm=1.102, loss_scale=8, train_wall=153, gb_free=20.8, wall=57497
2022-03-15 02:15:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:15:09 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 9.841 | ppl 916.85 | wps 66471.4 | wpb 2040.3 | bsz 4 | num_updates 35369 | best_loss 7.59
2022-03-15 02:15:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 35369 updates
2022-03-15 02:15:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:15:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:15:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 344 @ 35369 updates, score 9.841) (writing took 0.9891340993344784 seconds)
2022-03-15 02:15:10 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-15 02:15:10 | INFO | train | epoch 344 | loss 3.648 | ppl 12.53 | wps 40204.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35369 | lr 0.000168147 | gnorm 1.097 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 57610
KL Stats: Epoch 344 Divergences: Uniform: 5.46031695299615 Unigram: 5.783578225066005
2022-03-15 02:15:10 | INFO | fairseq.trainer | begin training epoch 345
2022-03-15 02:15:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:16:00 | INFO | train_inner | epoch 345:     31 / 103 loss=3.648, ppl=12.54, wps=40172.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=35400, lr=0.000168073, gnorm=1.095, loss_scale=16, train_wall=153, gb_free=20.8, wall=57659
2022-03-15 02:16:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 02:17:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:17:57 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 9.865 | ppl 932.34 | wps 66274.8 | wpb 2040.3 | bsz 4 | num_updates 35471 | best_loss 7.59
2022-03-15 02:17:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 35471 updates
2022-03-15 02:17:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:17:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:17:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 345 @ 35471 updates, score 9.865) (writing took 0.9491883674636483 seconds)
2022-03-15 02:17:58 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-15 02:17:58 | INFO | train | epoch 345 | loss 3.645 | ppl 12.51 | wps 39825.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 35471 | lr 0.000167905 | gnorm 1.1 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 57777
KL Stats: Epoch 345 Divergences: Uniform: 5.462531510746273 Unigram: 5.788333320828123
2022-03-15 02:17:58 | INFO | fairseq.trainer | begin training epoch 346
2022-03-15 02:17:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:18:44 | INFO | train_inner | epoch 346:     29 / 103 loss=3.648, ppl=12.53, wps=39800.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=35500, lr=0.000167836, gnorm=1.111, loss_scale=8, train_wall=155, gb_free=20.8, wall=57823
2022-03-15 02:20:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:20:44 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 9.848 | ppl 921.47 | wps 65756.4 | wpb 2040.3 | bsz 4 | num_updates 35574 | best_loss 7.59
2022-03-15 02:20:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 35574 updates
2022-03-15 02:20:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:20:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:20:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 346 @ 35574 updates, score 9.848) (writing took 0.9961922187358141 seconds)
2022-03-15 02:20:45 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-15 02:20:45 | INFO | train | epoch 346 | loss 3.644 | ppl 12.5 | wps 40196.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35574 | lr 0.000167662 | gnorm 1.105 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 57945
KL Stats: Epoch 346 Divergences: Uniform: 5.4619014702811315 Unigram: 5.787605254498419
2022-03-15 02:20:45 | INFO | fairseq.trainer | begin training epoch 347
2022-03-15 02:20:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:21:26 | INFO | train_inner | epoch 347:     26 / 103 loss=3.64, ppl=12.46, wps=40152.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=35600, lr=0.0001676, gnorm=1.104, loss_scale=8, train_wall=153, gb_free=20.8, wall=57986
2022-03-15 02:23:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:23:31 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 9.855 | ppl 926.04 | wps 66132.1 | wpb 2040.3 | bsz 4 | num_updates 35677 | best_loss 7.59
2022-03-15 02:23:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 35677 updates
2022-03-15 02:23:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:23:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:23:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 347 @ 35677 updates, score 9.855) (writing took 0.990480812266469 seconds)
2022-03-15 02:23:32 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-15 02:23:32 | INFO | train | epoch 347 | loss 3.642 | ppl 12.48 | wps 40199.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35677 | lr 0.000167419 | gnorm 1.108 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 58112
KL Stats: Epoch 347 Divergences: Uniform: 5.464511852888729 Unigram: 5.792833881581606
2022-03-15 02:23:32 | INFO | fairseq.trainer | begin training epoch 348
2022-03-15 02:23:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:24:09 | INFO | train_inner | epoch 348:     23 / 103 loss=3.645, ppl=12.51, wps=40169.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=35700, lr=0.000167365, gnorm=1.106, loss_scale=8, train_wall=153, gb_free=20.8, wall=58149
2022-03-15 02:26:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:26:19 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 9.846 | ppl 920.42 | wps 66047.5 | wpb 2040.3 | bsz 4 | num_updates 35780 | best_loss 7.59
2022-03-15 02:26:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 35780 updates
2022-03-15 02:26:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:26:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:26:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 348 @ 35780 updates, score 9.846) (writing took 0.9654797380790114 seconds)
2022-03-15 02:26:20 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-15 02:26:20 | INFO | train | epoch 348 | loss 3.641 | ppl 12.47 | wps 40204.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35780 | lr 0.000167178 | gnorm 1.101 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 58279
KL Stats: Epoch 348 Divergences: Uniform: 5.461940918305465 Unigram: 5.789913369277331
2022-03-15 02:26:20 | INFO | fairseq.trainer | begin training epoch 349
2022-03-15 02:26:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:26:52 | INFO | train_inner | epoch 349:     20 / 103 loss=3.64, ppl=12.47, wps=40173.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=35800, lr=0.000167132, gnorm=1.098, loss_scale=8, train_wall=153, gb_free=20.8, wall=58311
2022-03-15 02:29:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:29:06 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 9.841 | ppl 917.25 | wps 66260.9 | wpb 2040.3 | bsz 4 | num_updates 35883 | best_loss 7.59
2022-03-15 02:29:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 35883 updates
2022-03-15 02:29:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:29:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:29:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 349 @ 35883 updates, score 9.841) (writing took 1.0528220813721418 seconds)
2022-03-15 02:29:07 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-15 02:29:07 | INFO | train | epoch 349 | loss 3.639 | ppl 12.46 | wps 40182 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35883 | lr 0.000166938 | gnorm 1.101 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 58447
KL Stats: Epoch 349 Divergences: Uniform: 5.4643733069141724 Unigram: 5.791198075839201
2022-03-15 02:29:07 | INFO | fairseq.trainer | begin training epoch 350
2022-03-15 02:29:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:29:34 | INFO | train_inner | epoch 350:     17 / 103 loss=3.64, ppl=12.47, wps=40148.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=35900, lr=0.000166899, gnorm=1.106, loss_scale=8, train_wall=153, gb_free=20.8, wall=58474
2022-03-15 02:31:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:31:54 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 9.838 | ppl 915.05 | wps 65993.1 | wpb 2040.3 | bsz 4 | num_updates 35986 | best_loss 7.59
2022-03-15 02:31:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 35986 updates
2022-03-15 02:31:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:31:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:31:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 350 @ 35986 updates, score 9.838) (writing took 1.006996562704444 seconds)
2022-03-15 02:31:55 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-15 02:31:55 | INFO | train | epoch 350 | loss 3.638 | ppl 12.45 | wps 40197.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35986 | lr 0.000166699 | gnorm 1.1 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 58614
KL Stats: Epoch 350 Divergences: Uniform: 5.464711679119799 Unigram: 5.7929610865131025
2022-03-15 02:31:55 | INFO | fairseq.trainer | begin training epoch 351
2022-03-15 02:31:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:32:17 | INFO | train_inner | epoch 351:     14 / 103 loss=3.64, ppl=12.47, wps=40160.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=36000, lr=0.000166667, gnorm=1.099, loss_scale=16, train_wall=153, gb_free=20.8, wall=58636
2022-03-15 02:34:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 02:34:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:34:41 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 9.864 | ppl 931.79 | wps 65873.8 | wpb 2040.3 | bsz 4 | num_updates 36088 | best_loss 7.59
2022-03-15 02:34:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 36088 updates
2022-03-15 02:34:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:34:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:34:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 351 @ 36088 updates, score 9.864) (writing took 0.9436480076983571 seconds)
2022-03-15 02:34:42 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-15 02:34:42 | INFO | train | epoch 351 | loss 3.637 | ppl 12.44 | wps 39819.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 36088 | lr 0.000166463 | gnorm 1.098 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 58781
KL Stats: Epoch 351 Divergences: Uniform: 5.466492131756877 Unigram: 5.797067314476246
2022-03-15 02:34:42 | INFO | fairseq.trainer | begin training epoch 352
2022-03-15 02:34:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:35:01 | INFO | train_inner | epoch 352:     12 / 103 loss=3.637, ppl=12.44, wps=39793.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=36100, lr=0.000166436, gnorm=1.098, loss_scale=8, train_wall=155, gb_free=20.8, wall=58800
2022-03-15 02:37:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:37:28 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 9.868 | ppl 934.61 | wps 66231.2 | wpb 2040.3 | bsz 4 | num_updates 36191 | best_loss 7.59
2022-03-15 02:37:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 36191 updates
2022-03-15 02:37:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:37:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:37:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 352 @ 36191 updates, score 9.868) (writing took 1.0017823837697506 seconds)
2022-03-15 02:37:29 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-15 02:37:29 | INFO | train | epoch 352 | loss 3.637 | ppl 12.44 | wps 40208.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36191 | lr 0.000166226 | gnorm 1.111 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 58949
KL Stats: Epoch 352 Divergences: Uniform: 5.464740936753503 Unigram: 5.795577301721268
2022-03-15 02:37:29 | INFO | fairseq.trainer | begin training epoch 353
2022-03-15 02:37:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:37:43 | INFO | train_inner | epoch 353:      9 / 103 loss=3.639, ppl=12.46, wps=40160, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=36200, lr=0.000166206, gnorm=1.113, loss_scale=8, train_wall=153, gb_free=20.8, wall=58963
2022-03-15 02:40:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:40:16 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 9.856 | ppl 926.45 | wps 66250.7 | wpb 2040.3 | bsz 4 | num_updates 36294 | best_loss 7.59
2022-03-15 02:40:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 36294 updates
2022-03-15 02:40:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:40:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:40:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 353 @ 36294 updates, score 9.856) (writing took 0.9937822455540299 seconds)
2022-03-15 02:40:17 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-15 02:40:17 | INFO | train | epoch 353 | loss 3.636 | ppl 12.43 | wps 40185.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36294 | lr 0.00016599 | gnorm 1.1 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 59116
KL Stats: Epoch 353 Divergences: Uniform: 5.4653400516545085 Unigram: 5.796969463492895
2022-03-15 02:40:17 | INFO | fairseq.trainer | begin training epoch 354
2022-03-15 02:40:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:40:26 | INFO | train_inner | epoch 354:      6 / 103 loss=3.637, ppl=12.44, wps=40166.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=36300, lr=0.000165977, gnorm=1.099, loss_scale=8, train_wall=153, gb_free=20.8, wall=59126
2022-03-15 02:42:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:43:03 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 9.881 | ppl 943.14 | wps 66115.9 | wpb 2040.3 | bsz 4 | num_updates 36397 | best_loss 7.59
2022-03-15 02:43:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 36397 updates
2022-03-15 02:43:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:43:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:43:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 354 @ 36397 updates, score 9.881) (writing took 0.992395100183785 seconds)
2022-03-15 02:43:04 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-15 02:43:04 | INFO | train | epoch 354 | loss 3.634 | ppl 12.42 | wps 40224.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36397 | lr 0.000165755 | gnorm 1.092 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 59283
KL Stats: Epoch 354 Divergences: Uniform: 5.468514079423282 Unigram: 5.802570267958253
2022-03-15 02:43:04 | INFO | fairseq.trainer | begin training epoch 355
2022-03-15 02:43:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:43:09 | INFO | train_inner | epoch 355:      3 / 103 loss=3.636, ppl=12.43, wps=40188.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=36400, lr=0.000165748, gnorm=1.094, loss_scale=8, train_wall=153, gb_free=20.8, wall=59288
2022-03-15 02:45:47 | INFO | train_inner | epoch 355:    103 / 103 loss=3.632, ppl=12.4, wps=41347.4, ups=0.63, wpb=65305.6, bsz=127.6, num_updates=36500, lr=0.000165521, gnorm=1.105, loss_scale=8, train_wall=153, gb_free=20.8, wall=59446
2022-03-15 02:45:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:45:50 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 9.87 | ppl 935.95 | wps 66058 | wpb 2040.3 | bsz 4 | num_updates 36500 | best_loss 7.59
2022-03-15 02:45:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 36500 updates
2022-03-15 02:45:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:45:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:45:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 355 @ 36500 updates, score 9.87) (writing took 0.9698983710259199 seconds)
2022-03-15 02:45:51 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-15 02:45:51 | INFO | train | epoch 355 | loss 3.631 | ppl 12.39 | wps 40199.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36500 | lr 0.000165521 | gnorm 1.105 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 59451
KL Stats: Epoch 355 Divergences: Uniform: 5.467446811938382 Unigram: 5.802024814792309
2022-03-15 02:45:51 | INFO | fairseq.trainer | begin training epoch 356
2022-03-15 02:45:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:48:30 | INFO | train_inner | epoch 356:    100 / 103 loss=3.63, ppl=12.38, wps=40173.7, ups=0.61, wpb=65530.9, bsz=128, num_updates=36600, lr=0.000165295, gnorm=1.102, loss_scale=16, train_wall=154, gb_free=20.8, wall=59609
2022-03-15 02:48:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:48:37 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 9.864 | ppl 931.84 | wps 65935.2 | wpb 2040.3 | bsz 4 | num_updates 36603 | best_loss 7.59
2022-03-15 02:48:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 36603 updates
2022-03-15 02:48:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:48:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:48:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 356 @ 36603 updates, score 9.864) (writing took 1.0178752290084958 seconds)
2022-03-15 02:48:38 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-15 02:48:38 | INFO | train | epoch 356 | loss 3.631 | ppl 12.39 | wps 40191.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36603 | lr 0.000165288 | gnorm 1.103 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 59618
KL Stats: Epoch 356 Divergences: Uniform: 5.468295380472041 Unigram: 5.803548266546565
2022-03-15 02:48:39 | INFO | fairseq.trainer | begin training epoch 357
2022-03-15 02:48:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:50:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 02:51:14 | INFO | train_inner | epoch 357:     98 / 103 loss=3.628, ppl=12.37, wps=39768.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=36700, lr=0.00016507, gnorm=1.098, loss_scale=8, train_wall=155, gb_free=20.8, wall=59773
2022-03-15 02:51:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:51:25 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 9.874 | ppl 938.19 | wps 66066.5 | wpb 2040.3 | bsz 4 | num_updates 36705 | best_loss 7.59
2022-03-15 02:51:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 36705 updates
2022-03-15 02:51:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:51:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:51:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 357 @ 36705 updates, score 9.874) (writing took 0.9556645564734936 seconds)
2022-03-15 02:51:26 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-15 02:51:26 | INFO | train | epoch 357 | loss 3.629 | ppl 12.37 | wps 39814.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 36705 | lr 0.000165058 | gnorm 1.098 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 59785
KL Stats: Epoch 357 Divergences: Uniform: 5.469023857734009 Unigram: 5.805627077473749
2022-03-15 02:51:26 | INFO | fairseq.trainer | begin training epoch 358
2022-03-15 02:51:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:53:56 | INFO | train_inner | epoch 358:     95 / 103 loss=3.628, ppl=12.37, wps=40184.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=36800, lr=0.000164845, gnorm=1.099, loss_scale=8, train_wall=153, gb_free=20.8, wall=59936
2022-03-15 02:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:54:12 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 9.88 | ppl 942.31 | wps 65776.1 | wpb 2040.3 | bsz 4 | num_updates 36808 | best_loss 7.59
2022-03-15 02:54:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 36808 updates
2022-03-15 02:54:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:54:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:54:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 358 @ 36808 updates, score 9.88) (writing took 0.9952784990891814 seconds)
2022-03-15 02:54:13 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-15 02:54:13 | INFO | train | epoch 358 | loss 3.629 | ppl 12.38 | wps 40207.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36808 | lr 0.000164827 | gnorm 1.1 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 59953
KL Stats: Epoch 358 Divergences: Uniform: 5.468592559839707 Unigram: 5.8070119054583165
2022-03-15 02:54:13 | INFO | fairseq.trainer | begin training epoch 359
2022-03-15 02:54:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:56:39 | INFO | train_inner | epoch 359:     92 / 103 loss=3.626, ppl=12.34, wps=40156.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=36900, lr=0.000164622, gnorm=1.111, loss_scale=8, train_wall=153, gb_free=20.8, wall=60099
2022-03-15 02:56:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:56:59 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 9.893 | ppl 951 | wps 66244.6 | wpb 2040.3 | bsz 4 | num_updates 36911 | best_loss 7.59
2022-03-15 02:57:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 36911 updates
2022-03-15 02:57:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:57:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:57:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 359 @ 36911 updates, score 9.893) (writing took 1.0181076228618622 seconds)
2022-03-15 02:57:01 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-15 02:57:01 | INFO | train | epoch 359 | loss 3.627 | ppl 12.36 | wps 40185.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36911 | lr 0.000164597 | gnorm 1.11 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 60120
KL Stats: Epoch 359 Divergences: Uniform: 5.470764661159705 Unigram: 5.809390008778378
2022-03-15 02:57:01 | INFO | fairseq.trainer | begin training epoch 360
2022-03-15 02:57:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:59:22 | INFO | train_inner | epoch 360:     89 / 103 loss=3.624, ppl=12.33, wps=40167, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=37000, lr=0.000164399, gnorm=1.1, loss_scale=8, train_wall=153, gb_free=20.8, wall=60261
2022-03-15 02:59:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:59:47 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 9.869 | ppl 934.84 | wps 66277.2 | wpb 2040.3 | bsz 4 | num_updates 37014 | best_loss 7.59
2022-03-15 02:59:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 37014 updates
2022-03-15 02:59:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:59:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 02:59:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 360 @ 37014 updates, score 9.869) (writing took 0.9586444338783622 seconds)
2022-03-15 02:59:48 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-15 02:59:48 | INFO | train | epoch 360 | loss 3.625 | ppl 12.34 | wps 40217.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37014 | lr 0.000164368 | gnorm 1.097 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 60287
KL Stats: Epoch 360 Divergences: Uniform: 5.470779523467176 Unigram: 5.8101903040648475
2022-03-15 02:59:48 | INFO | fairseq.trainer | begin training epoch 361
2022-03-15 02:59:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:02:04 | INFO | train_inner | epoch 361:     86 / 103 loss=3.624, ppl=12.33, wps=40174.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=37100, lr=0.000164177, gnorm=1.103, loss_scale=8, train_wall=153, gb_free=20.8, wall=60424
2022-03-15 03:02:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:02:34 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 9.878 | ppl 940.9 | wps 66242.3 | wpb 2040.3 | bsz 4 | num_updates 37117 | best_loss 7.59
2022-03-15 03:02:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 37117 updates
2022-03-15 03:02:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:02:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:02:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 361 @ 37117 updates, score 9.878) (writing took 0.9756710194051266 seconds)
2022-03-15 03:02:35 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-15 03:02:35 | INFO | train | epoch 361 | loss 3.624 | ppl 12.33 | wps 40208.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37117 | lr 0.00016414 | gnorm 1.107 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 60455
KL Stats: Epoch 361 Divergences: Uniform: 5.4710767942388605 Unigram: 5.812696972503606
2022-03-15 03:02:35 | INFO | fairseq.trainer | begin training epoch 362
2022-03-15 03:02:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:04:47 | INFO | train_inner | epoch 362:     83 / 103 loss=3.621, ppl=12.3, wps=40170.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=37200, lr=0.000163956, gnorm=1.102, loss_scale=16, train_wall=153, gb_free=20.8, wall=60586
2022-03-15 03:05:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:05:21 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 9.887 | ppl 946.54 | wps 66105.3 | wpb 2040.3 | bsz 4 | num_updates 37220 | best_loss 7.59
2022-03-15 03:05:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 37220 updates
2022-03-15 03:05:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:05:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:05:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 362 @ 37220 updates, score 9.887) (writing took 0.9845258314162493 seconds)
2022-03-15 03:05:22 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-15 03:05:22 | INFO | train | epoch 362 | loss 3.624 | ppl 12.33 | wps 40199.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37220 | lr 0.000163912 | gnorm 1.098 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 60622
KL Stats: Epoch 362 Divergences: Uniform: 5.472271502145119 Unigram: 5.813703747574307
2022-03-15 03:05:22 | INFO | fairseq.trainer | begin training epoch 363
2022-03-15 03:05:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:07:29 | INFO | train_inner | epoch 363:     80 / 103 loss=3.622, ppl=12.31, wps=40189.2, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=37300, lr=0.000163737, gnorm=1.107, loss_scale=16, train_wall=153, gb_free=20.8, wall=60749
2022-03-15 03:08:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:08:09 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 9.89 | ppl 948.75 | wps 66270.5 | wpb 2040.3 | bsz 4 | num_updates 37323 | best_loss 7.59
2022-03-15 03:08:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 37323 updates
2022-03-15 03:08:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:08:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:08:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 363 @ 37323 updates, score 9.89) (writing took 0.9461187478154898 seconds)
2022-03-15 03:08:10 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-15 03:08:10 | INFO | train | epoch 363 | loss 3.622 | ppl 12.31 | wps 40226.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37323 | lr 0.000163686 | gnorm 1.104 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 60789
KL Stats: Epoch 363 Divergences: Uniform: 5.47191016375032 Unigram: 5.815956087943691
2022-03-15 03:08:10 | INFO | fairseq.trainer | begin training epoch 364
2022-03-15 03:08:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:10:12 | INFO | train_inner | epoch 364:     77 / 103 loss=3.617, ppl=12.27, wps=40177, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=37400, lr=0.000163517, gnorm=1.088, loss_scale=16, train_wall=153, gb_free=20.8, wall=60911
2022-03-15 03:10:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:10:56 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 9.883 | ppl 944.14 | wps 66071.6 | wpb 2040.3 | bsz 4 | num_updates 37426 | best_loss 7.59
2022-03-15 03:10:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 37426 updates
2022-03-15 03:10:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:10:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:10:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 364 @ 37426 updates, score 9.883) (writing took 0.9984507858753204 seconds)
2022-03-15 03:10:57 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-15 03:10:57 | INFO | train | epoch 364 | loss 3.621 | ppl 12.3 | wps 40207.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37426 | lr 0.000163461 | gnorm 1.093 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 60957
KL Stats: Epoch 364 Divergences: Uniform: 5.472296449479569 Unigram: 5.8147635086357
2022-03-15 03:10:57 | INFO | fairseq.trainer | begin training epoch 365
2022-03-15 03:10:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:11:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 03:12:56 | INFO | train_inner | epoch 365:     75 / 103 loss=3.623, ppl=12.32, wps=39789.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=37500, lr=0.000163299, gnorm=1.113, loss_scale=8, train_wall=155, gb_free=20.8, wall=61075
2022-03-15 03:13:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:13:43 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 9.893 | ppl 951.01 | wps 66048.3 | wpb 2040.3 | bsz 4 | num_updates 37528 | best_loss 7.59
2022-03-15 03:13:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 37528 updates
2022-03-15 03:13:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:13:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:13:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 365 @ 37528 updates, score 9.893) (writing took 0.9933153903111815 seconds)
2022-03-15 03:13:44 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-15 03:13:44 | INFO | train | epoch 365 | loss 3.62 | ppl 12.29 | wps 39817.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 37528 | lr 0.000163238 | gnorm 1.117 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 61124
KL Stats: Epoch 365 Divergences: Uniform: 5.472839345788201 Unigram: 5.816660452643139
2022-03-15 03:13:44 | INFO | fairseq.trainer | begin training epoch 366
2022-03-15 03:13:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:15:38 | INFO | train_inner | epoch 366:     72 / 103 loss=3.618, ppl=12.28, wps=40180.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=37600, lr=0.000163082, gnorm=1.115, loss_scale=8, train_wall=153, gb_free=20.8, wall=61238
2022-03-15 03:16:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:16:31 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 9.9 | ppl 955.51 | wps 66229.9 | wpb 2040.3 | bsz 4 | num_updates 37631 | best_loss 7.59
2022-03-15 03:16:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 37631 updates
2022-03-15 03:16:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:16:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:16:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 366 @ 37631 updates, score 9.9) (writing took 0.9517843928188086 seconds)
2022-03-15 03:16:32 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-15 03:16:32 | INFO | train | epoch 366 | loss 3.619 | ppl 12.28 | wps 40224.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37631 | lr 0.000163015 | gnorm 1.109 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 61291
KL Stats: Epoch 366 Divergences: Uniform: 5.47448040322812 Unigram: 5.820447966648227
2022-03-15 03:16:32 | INFO | fairseq.trainer | begin training epoch 367
2022-03-15 03:16:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:18:21 | INFO | train_inner | epoch 367:     69 / 103 loss=3.616, ppl=12.26, wps=40201.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=37700, lr=0.000162866, gnorm=1.099, loss_scale=8, train_wall=153, gb_free=20.8, wall=61400
2022-03-15 03:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:19:18 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 9.895 | ppl 952.34 | wps 66849.5 | wpb 2040.3 | bsz 4 | num_updates 37734 | best_loss 7.59
2022-03-15 03:19:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 37734 updates
2022-03-15 03:19:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:19:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:19:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 367 @ 37734 updates, score 9.895) (writing took 0.9458026951178908 seconds)
2022-03-15 03:19:19 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-15 03:19:19 | INFO | train | epoch 367 | loss 3.617 | ppl 12.27 | wps 40238.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37734 | lr 0.000162792 | gnorm 1.101 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 61458
KL Stats: Epoch 367 Divergences: Uniform: 5.473857950909956 Unigram: 5.820074368329906
2022-03-15 03:19:19 | INFO | fairseq.trainer | begin training epoch 368
2022-03-15 03:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:21:03 | INFO | train_inner | epoch 368:     66 / 103 loss=3.614, ppl=12.24, wps=40199.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=37800, lr=0.00016265, gnorm=1.099, loss_scale=8, train_wall=153, gb_free=20.8, wall=61563
2022-03-15 03:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:22:05 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 9.9 | ppl 955.38 | wps 66156.7 | wpb 2040.3 | bsz 4 | num_updates 37837 | best_loss 7.59
2022-03-15 03:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 37837 updates
2022-03-15 03:22:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:22:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:22:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 368 @ 37837 updates, score 9.9) (writing took 1.0186522603034973 seconds)
2022-03-15 03:22:06 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-15 03:22:06 | INFO | train | epoch 368 | loss 3.616 | ppl 12.26 | wps 40204.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37837 | lr 0.00016257 | gnorm 1.099 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 61626
KL Stats: Epoch 368 Divergences: Uniform: 5.475099078027936 Unigram: 5.821428383549771
2022-03-15 03:22:06 | INFO | fairseq.trainer | begin training epoch 369
2022-03-15 03:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:23:46 | INFO | train_inner | epoch 369:     63 / 103 loss=3.616, ppl=12.26, wps=40176.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=37900, lr=0.000162435, gnorm=1.108, loss_scale=8, train_wall=153, gb_free=20.8, wall=61725
2022-03-15 03:24:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:24:52 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 9.886 | ppl 945.95 | wps 66247.1 | wpb 2040.3 | bsz 4 | num_updates 37940 | best_loss 7.59
2022-03-15 03:24:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 37940 updates
2022-03-15 03:24:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:24:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:24:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 369 @ 37940 updates, score 9.886) (writing took 0.9525913242250681 seconds)
2022-03-15 03:24:53 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-15 03:24:53 | INFO | train | epoch 369 | loss 3.615 | ppl 12.25 | wps 40233.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37940 | lr 0.00016235 | gnorm 1.109 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 61793
KL Stats: Epoch 369 Divergences: Uniform: 5.474727319575005 Unigram: 5.820882589460164
2022-03-15 03:24:53 | INFO | fairseq.trainer | begin training epoch 370
2022-03-15 03:24:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:26:28 | INFO | train_inner | epoch 370:     60 / 103 loss=3.613, ppl=12.23, wps=40204.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=38000, lr=0.000162221, gnorm=1.099, loss_scale=16, train_wall=153, gb_free=20.8, wall=61888
2022-03-15 03:27:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:27:40 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 9.903 | ppl 957.67 | wps 66209 | wpb 2040.3 | bsz 4 | num_updates 38043 | best_loss 7.59
2022-03-15 03:27:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 38043 updates
2022-03-15 03:27:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:27:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:27:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 370 @ 38043 updates, score 9.903) (writing took 0.9651590157300234 seconds)
2022-03-15 03:27:41 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-15 03:27:41 | INFO | train | epoch 370 | loss 3.613 | ppl 12.24 | wps 40212.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38043 | lr 0.00016213 | gnorm 1.1 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 61960
KL Stats: Epoch 370 Divergences: Uniform: 5.4752158522386685 Unigram: 5.823531964054086
2022-03-15 03:27:41 | INFO | fairseq.trainer | begin training epoch 371
2022-03-15 03:27:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:29:11 | INFO | train_inner | epoch 371:     57 / 103 loss=3.613, ppl=12.23, wps=40162.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=38100, lr=0.000162008, gnorm=1.117, loss_scale=16, train_wall=153, gb_free=20.8, wall=62051
2022-03-15 03:30:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 03:30:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:30:27 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 9.883 | ppl 943.96 | wps 65776.9 | wpb 2040.3 | bsz 4 | num_updates 38145 | best_loss 7.59
2022-03-15 03:30:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 38145 updates
2022-03-15 03:30:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:30:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:30:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 371 @ 38145 updates, score 9.883) (writing took 1.0364808570593596 seconds)
2022-03-15 03:30:28 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-15 03:30:28 | INFO | train | epoch 371 | loss 3.612 | ppl 12.23 | wps 39767.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 38145 | lr 0.000161913 | gnorm 1.117 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 62128
KL Stats: Epoch 371 Divergences: Uniform: 5.472926474301506 Unigram: 5.823973634024673
2022-03-15 03:30:28 | INFO | fairseq.trainer | begin training epoch 372
2022-03-15 03:30:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:31:55 | INFO | train_inner | epoch 372:     55 / 103 loss=3.611, ppl=12.22, wps=39743.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=38200, lr=0.000161796, gnorm=1.097, loss_scale=8, train_wall=155, gb_free=20.8, wall=62215
2022-03-15 03:33:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:33:14 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 9.909 | ppl 961.11 | wps 66055.5 | wpb 2040.3 | bsz 4 | num_updates 38248 | best_loss 7.59
2022-03-15 03:33:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 38248 updates
2022-03-15 03:33:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:33:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:33:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 372 @ 38248 updates, score 9.909) (writing took 0.9716755710542202 seconds)
2022-03-15 03:33:15 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-15 03:33:15 | INFO | train | epoch 372 | loss 3.611 | ppl 12.22 | wps 40207.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38248 | lr 0.000161695 | gnorm 1.092 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 62295
KL Stats: Epoch 372 Divergences: Uniform: 5.476017306244693 Unigram: 5.826986668380844
2022-03-15 03:33:15 | INFO | fairseq.trainer | begin training epoch 373
2022-03-15 03:33:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:34:38 | INFO | train_inner | epoch 373:     52 / 103 loss=3.611, ppl=12.22, wps=40178, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=38300, lr=0.000161585, gnorm=1.092, loss_scale=8, train_wall=153, gb_free=20.8, wall=62377
2022-03-15 03:35:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:36:02 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 9.915 | ppl 965.44 | wps 65923.8 | wpb 2040.3 | bsz 4 | num_updates 38351 | best_loss 7.59
2022-03-15 03:36:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 38351 updates
2022-03-15 03:36:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:36:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:36:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 373 @ 38351 updates, score 9.915) (writing took 0.9955178601667285 seconds)
2022-03-15 03:36:03 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-15 03:36:03 | INFO | train | epoch 373 | loss 3.61 | ppl 12.21 | wps 40197.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38351 | lr 0.000161477 | gnorm 1.104 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 62462
KL Stats: Epoch 373 Divergences: Uniform: 5.477989851266595 Unigram: 5.828903852871736
2022-03-15 03:36:03 | INFO | fairseq.trainer | begin training epoch 374
2022-03-15 03:36:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:37:20 | INFO | train_inner | epoch 374:     49 / 103 loss=3.612, ppl=12.23, wps=40154.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=38400, lr=0.000161374, gnorm=1.11, loss_scale=8, train_wall=153, gb_free=20.8, wall=62540
2022-03-15 03:38:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:38:49 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 9.925 | ppl 972.15 | wps 66177.7 | wpb 2040.3 | bsz 4 | num_updates 38454 | best_loss 7.59
2022-03-15 03:38:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 38454 updates
2022-03-15 03:38:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:38:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:38:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 374 @ 38454 updates, score 9.925) (writing took 0.9829462328925729 seconds)
2022-03-15 03:38:50 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-15 03:38:50 | INFO | train | epoch 374 | loss 3.609 | ppl 12.2 | wps 40201.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38454 | lr 0.000161261 | gnorm 1.101 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 62630
KL Stats: Epoch 374 Divergences: Uniform: 5.478100801715521 Unigram: 5.830001948203353
2022-03-15 03:38:50 | INFO | fairseq.trainer | begin training epoch 375
2022-03-15 03:38:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:40:03 | INFO | train_inner | epoch 375:     46 / 103 loss=3.606, ppl=12.18, wps=40174.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=38500, lr=0.000161165, gnorm=1.111, loss_scale=8, train_wall=153, gb_free=20.8, wall=62703
2022-03-15 03:41:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:41:36 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 9.912 | ppl 963.38 | wps 66400.1 | wpb 2040.3 | bsz 4 | num_updates 38557 | best_loss 7.59
2022-03-15 03:41:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 38557 updates
2022-03-15 03:41:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:41:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:41:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 375 @ 38557 updates, score 9.912) (writing took 0.9819733686745167 seconds)
2022-03-15 03:41:37 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-15 03:41:37 | INFO | train | epoch 375 | loss 3.608 | ppl 12.19 | wps 40203.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38557 | lr 0.000161045 | gnorm 1.116 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 62797
KL Stats: Epoch 375 Divergences: Uniform: 5.479169219642406 Unigram: 5.830713817291989
2022-03-15 03:41:37 | INFO | fairseq.trainer | begin training epoch 376
2022-03-15 03:41:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:42:46 | INFO | train_inner | epoch 376:     43 / 103 loss=3.606, ppl=12.18, wps=40171.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=38600, lr=0.000160956, gnorm=1.11, loss_scale=8, train_wall=153, gb_free=20.8, wall=62865
2022-03-15 03:44:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:44:24 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 9.919 | ppl 968.34 | wps 66316.9 | wpb 2040.3 | bsz 4 | num_updates 38660 | best_loss 7.59
2022-03-15 03:44:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 38660 updates
2022-03-15 03:44:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:44:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:44:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 376 @ 38660 updates, score 9.919) (writing took 0.9922043923288584 seconds)
2022-03-15 03:44:25 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-15 03:44:25 | INFO | train | epoch 376 | loss 3.606 | ppl 12.18 | wps 40213.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38660 | lr 0.000160831 | gnorm 1.104 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 62964
KL Stats: Epoch 376 Divergences: Uniform: 5.478165303490187 Unigram: 5.832082326537592
2022-03-15 03:44:25 | INFO | fairseq.trainer | begin training epoch 377
2022-03-15 03:44:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:45:28 | INFO | train_inner | epoch 377:     40 / 103 loss=3.606, ppl=12.17, wps=40174.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=38700, lr=0.000160748, gnorm=1.104, loss_scale=16, train_wall=153, gb_free=20.8, wall=63028
2022-03-15 03:47:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:47:11 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 9.925 | ppl 972.2 | wps 66123.1 | wpb 2040.3 | bsz 4 | num_updates 38763 | best_loss 7.59
2022-03-15 03:47:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 38763 updates
2022-03-15 03:47:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:47:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:47:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 377 @ 38763 updates, score 9.925) (writing took 1.025660335086286 seconds)
2022-03-15 03:47:12 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-15 03:47:12 | INFO | train | epoch 377 | loss 3.606 | ppl 12.17 | wps 40197 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38763 | lr 0.000160617 | gnorm 1.11 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 63132
KL Stats: Epoch 377 Divergences: Uniform: 5.478643180676005 Unigram: 5.833907352347898
2022-03-15 03:47:12 | INFO | fairseq.trainer | begin training epoch 378
2022-03-15 03:47:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:47:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 03:48:12 | INFO | train_inner | epoch 378:     38 / 103 loss=3.606, ppl=12.17, wps=39776.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=38800, lr=0.00016054, gnorm=1.115, loss_scale=8, train_wall=155, gb_free=20.8, wall=63192
2022-03-15 03:49:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:49:58 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 9.916 | ppl 966.39 | wps 66104.6 | wpb 2040.3 | bsz 4 | num_updates 38865 | best_loss 7.59
2022-03-15 03:49:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 38865 updates
2022-03-15 03:49:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:49:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:49:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 378 @ 38865 updates, score 9.916) (writing took 0.9855965934693813 seconds)
2022-03-15 03:49:59 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-15 03:49:59 | INFO | train | epoch 378 | loss 3.603 | ppl 12.15 | wps 39804.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 38865 | lr 0.000160406 | gnorm 1.102 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 63299
KL Stats: Epoch 378 Divergences: Uniform: 5.479445775724062 Unigram: 5.835865561319388
2022-03-15 03:49:59 | INFO | fairseq.trainer | begin training epoch 379
2022-03-15 03:49:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:50:55 | INFO | train_inner | epoch 379:     35 / 103 loss=3.604, ppl=12.16, wps=40161.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=38900, lr=0.000160334, gnorm=1.098, loss_scale=8, train_wall=153, gb_free=20.8, wall=63354
2022-03-15 03:52:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:52:46 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 9.899 | ppl 954.73 | wps 66217.1 | wpb 2040.3 | bsz 4 | num_updates 38968 | best_loss 7.59
2022-03-15 03:52:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 38968 updates
2022-03-15 03:52:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:52:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:52:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 379 @ 38968 updates, score 9.899) (writing took 1.027090772986412 seconds)
2022-03-15 03:52:47 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-15 03:52:47 | INFO | train | epoch 379 | loss 3.603 | ppl 12.16 | wps 40193 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38968 | lr 0.000160194 | gnorm 1.103 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 63466
KL Stats: Epoch 379 Divergences: Uniform: 5.479666539929114 Unigram: 5.836097228207015
2022-03-15 03:52:47 | INFO | fairseq.trainer | begin training epoch 380
2022-03-15 03:52:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:53:38 | INFO | train_inner | epoch 380:     32 / 103 loss=3.604, ppl=12.16, wps=40154.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=39000, lr=0.000160128, gnorm=1.1, loss_scale=8, train_wall=153, gb_free=20.8, wall=63517
2022-03-15 03:55:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:55:33 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 9.907 | ppl 959.89 | wps 66175.1 | wpb 2040.3 | bsz 4 | num_updates 39071 | best_loss 7.59
2022-03-15 03:55:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 39071 updates
2022-03-15 03:55:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:55:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:55:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 380 @ 39071 updates, score 9.907) (writing took 1.0074747232720256 seconds)
2022-03-15 03:55:34 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-15 03:55:34 | INFO | train | epoch 380 | loss 3.602 | ppl 12.14 | wps 40180.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39071 | lr 0.000159983 | gnorm 1.109 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 63634
KL Stats: Epoch 380 Divergences: Uniform: 5.480561000645796 Unigram: 5.839214912378074
2022-03-15 03:55:34 | INFO | fairseq.trainer | begin training epoch 381
2022-03-15 03:55:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:56:20 | INFO | train_inner | epoch 381:     29 / 103 loss=3.602, ppl=12.14, wps=40153.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=39100, lr=0.000159923, gnorm=1.114, loss_scale=8, train_wall=153, gb_free=20.8, wall=63680
2022-03-15 03:58:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:58:21 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 9.911 | ppl 962.96 | wps 66133.5 | wpb 2040.3 | bsz 4 | num_updates 39174 | best_loss 7.59
2022-03-15 03:58:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 39174 updates
2022-03-15 03:58:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:58:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 03:58:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 381 @ 39174 updates, score 9.911) (writing took 0.9722733171656728 seconds)
2022-03-15 03:58:21 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-15 03:58:21 | INFO | train | epoch 381 | loss 3.601 | ppl 12.14 | wps 40209 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39174 | lr 0.000159772 | gnorm 1.115 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 63801
KL Stats: Epoch 381 Divergences: Uniform: 5.480141774114768 Unigram: 5.838054068713734
2022-03-15 03:58:21 | INFO | fairseq.trainer | begin training epoch 382
2022-03-15 03:58:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:59:03 | INFO | train_inner | epoch 382:     26 / 103 loss=3.6, ppl=12.12, wps=40173.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=39200, lr=0.000159719, gnorm=1.109, loss_scale=8, train_wall=153, gb_free=20.8, wall=63842
2022-03-15 04:01:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:01:08 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 9.93 | ppl 975.8 | wps 66236.9 | wpb 2040.3 | bsz 4 | num_updates 39277 | best_loss 7.59
2022-03-15 04:01:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 39277 updates
2022-03-15 04:01:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:01:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:01:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 382 @ 39277 updates, score 9.93) (writing took 1.0095178568735719 seconds)
2022-03-15 04:01:09 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-15 04:01:09 | INFO | train | epoch 382 | loss 3.599 | ppl 12.12 | wps 40207 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39277 | lr 0.000159563 | gnorm 1.108 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 63968
KL Stats: Epoch 382 Divergences: Uniform: 5.481886865321921 Unigram: 5.841889877291276
2022-03-15 04:01:09 | INFO | fairseq.trainer | begin training epoch 383
2022-03-15 04:01:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:01:45 | INFO | train_inner | epoch 383:     23 / 103 loss=3.601, ppl=12.14, wps=40178.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=39300, lr=0.000159516, gnorm=1.124, loss_scale=8, train_wall=153, gb_free=20.8, wall=64005
2022-03-15 04:03:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:03:55 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 9.915 | ppl 965.58 | wps 66227.3 | wpb 2040.3 | bsz 4 | num_updates 39380 | best_loss 7.59
2022-03-15 04:03:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 39380 updates
2022-03-15 04:03:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:03:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:03:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 383 @ 39380 updates, score 9.915) (writing took 1.013581239618361 seconds)
2022-03-15 04:03:56 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-15 04:03:56 | INFO | train | epoch 383 | loss 3.598 | ppl 12.11 | wps 40206.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39380 | lr 0.000159354 | gnorm 1.121 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 64136
KL Stats: Epoch 383 Divergences: Uniform: 5.482185558573031 Unigram: 5.843608364036479
2022-03-15 04:03:56 | INFO | fairseq.trainer | begin training epoch 384
2022-03-15 04:03:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:04:28 | INFO | train_inner | epoch 384:     20 / 103 loss=3.6, ppl=12.12, wps=40173.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=39400, lr=0.000159313, gnorm=1.113, loss_scale=16, train_wall=153, gb_free=20.8, wall=64167
2022-03-15 04:06:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 04:06:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:06:42 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 9.93 | ppl 975.28 | wps 66201.7 | wpb 2040.3 | bsz 4 | num_updates 39482 | best_loss 7.59
2022-03-15 04:06:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 39482 updates
2022-03-15 04:06:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:06:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:06:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 384 @ 39482 updates, score 9.93) (writing took 1.0036079259589314 seconds)
2022-03-15 04:06:43 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-15 04:06:43 | INFO | train | epoch 384 | loss 3.597 | ppl 12.1 | wps 39839.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 39482 | lr 0.000159148 | gnorm 1.112 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 64303
KL Stats: Epoch 384 Divergences: Uniform: 5.481972909052612 Unigram: 5.844725571857213
2022-03-15 04:06:43 | INFO | fairseq.trainer | begin training epoch 385
2022-03-15 04:06:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:07:12 | INFO | train_inner | epoch 385:     18 / 103 loss=3.595, ppl=12.09, wps=39804, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=39500, lr=0.000159111, gnorm=1.112, loss_scale=8, train_wall=154, gb_free=20.8, wall=64331
2022-03-15 04:09:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:09:30 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 9.932 | ppl 977.04 | wps 66094.9 | wpb 2040.3 | bsz 4 | num_updates 39585 | best_loss 7.59
2022-03-15 04:09:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 39585 updates
2022-03-15 04:09:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:09:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:09:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 385 @ 39585 updates, score 9.932) (writing took 1.0300804292783141 seconds)
2022-03-15 04:09:31 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-15 04:09:31 | INFO | train | epoch 385 | loss 3.597 | ppl 12.1 | wps 40200.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39585 | lr 0.000158941 | gnorm 1.121 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 64470
KL Stats: Epoch 385 Divergences: Uniform: 5.481540839590541 Unigram: 5.844925817227969
2022-03-15 04:09:31 | INFO | fairseq.trainer | begin training epoch 386
2022-03-15 04:09:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:09:55 | INFO | train_inner | epoch 386:     15 / 103 loss=3.6, ppl=12.12, wps=40166.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=39600, lr=0.00015891, gnorm=1.118, loss_scale=8, train_wall=153, gb_free=20.8, wall=64494
2022-03-15 04:12:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:12:17 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 9.907 | ppl 960.28 | wps 65716 | wpb 2040.3 | bsz 4 | num_updates 39688 | best_loss 7.59
2022-03-15 04:12:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 39688 updates
2022-03-15 04:12:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:12:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:12:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 386 @ 39688 updates, score 9.907) (writing took 1.0333015276119113 seconds)
2022-03-15 04:12:18 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-15 04:12:18 | INFO | train | epoch 386 | loss 3.594 | ppl 12.07 | wps 40214.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39688 | lr 0.000158734 | gnorm 1.105 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 64638
KL Stats: Epoch 386 Divergences: Uniform: 5.485530773652481 Unigram: 5.84935116839786
2022-03-15 04:12:18 | INFO | fairseq.trainer | begin training epoch 387
2022-03-15 04:12:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:12:37 | INFO | train_inner | epoch 387:     12 / 103 loss=3.594, ppl=12.08, wps=40184.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=39700, lr=0.00015871, gnorm=1.106, loss_scale=8, train_wall=153, gb_free=20.8, wall=64657
2022-03-15 04:15:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:15:04 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 9.909 | ppl 961.43 | wps 66255.8 | wpb 2040.3 | bsz 4 | num_updates 39791 | best_loss 7.59
2022-03-15 04:15:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 39791 updates
2022-03-15 04:15:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:15:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:15:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 387 @ 39791 updates, score 9.909) (writing took 0.9777732389047742 seconds)
2022-03-15 04:15:05 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-15 04:15:05 | INFO | train | epoch 387 | loss 3.594 | ppl 12.07 | wps 40214.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39791 | lr 0.000158529 | gnorm 1.108 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 64805
KL Stats: Epoch 387 Divergences: Uniform: 5.484794704525643 Unigram: 5.847335714274972
2022-03-15 04:15:05 | INFO | fairseq.trainer | begin training epoch 388
2022-03-15 04:15:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:15:20 | INFO | train_inner | epoch 388:      9 / 103 loss=3.595, ppl=12.08, wps=40174.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=39800, lr=0.000158511, gnorm=1.112, loss_scale=8, train_wall=153, gb_free=20.8, wall=64819
2022-03-15 04:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:17:52 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 9.933 | ppl 977.73 | wps 65935.9 | wpb 2040.3 | bsz 4 | num_updates 39894 | best_loss 7.59
2022-03-15 04:17:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 39894 updates
2022-03-15 04:17:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:17:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 388 @ 39894 updates, score 9.933) (writing took 0.9829312516376376 seconds)
2022-03-15 04:17:53 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-15 04:17:53 | INFO | train | epoch 388 | loss 3.593 | ppl 12.07 | wps 40211.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39894 | lr 0.000158324 | gnorm 1.109 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 64972
KL Stats: Epoch 388 Divergences: Uniform: 5.482940442757643 Unigram: 5.848254221403761
2022-03-15 04:17:53 | INFO | fairseq.trainer | begin training epoch 389
2022-03-15 04:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:18:02 | INFO | train_inner | epoch 389:      6 / 103 loss=3.595, ppl=12.09, wps=40176.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=39900, lr=0.000158312, gnorm=1.105, loss_scale=8, train_wall=153, gb_free=20.8, wall=64982
2022-03-15 04:20:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:20:39 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 9.902 | ppl 956.62 | wps 66311.8 | wpb 2040.3 | bsz 4 | num_updates 39997 | best_loss 7.59
2022-03-15 04:20:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 39997 updates
2022-03-15 04:20:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:20:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:20:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 389 @ 39997 updates, score 9.902) (writing took 1.0790373850613832 seconds)
2022-03-15 04:20:40 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-15 04:20:40 | INFO | train | epoch 389 | loss 3.591 | ppl 12.05 | wps 40154.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 39997 | lr 0.00015812 | gnorm 1.101 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 65140
KL Stats: Epoch 389 Divergences: Uniform: 5.483900940598 Unigram: 5.849388361906646
2022-03-15 04:20:40 | INFO | fairseq.trainer | begin training epoch 390
2022-03-15 04:20:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:20:45 | INFO | train_inner | epoch 390:      3 / 103 loss=3.592, ppl=12.06, wps=40120, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=40000, lr=0.000158114, gnorm=1.103, loss_scale=16, train_wall=153, gb_free=20.8, wall=65144
2022-03-15 04:23:23 | INFO | train_inner | epoch 390:    103 / 103 loss=3.593, ppl=12.07, wps=41368.8, ups=0.63, wpb=65305.6, bsz=127.6, num_updates=40100, lr=0.000157917, gnorm=1.106, loss_scale=16, train_wall=153, gb_free=20.8, wall=65302
2022-03-15 04:23:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:23:26 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 9.923 | ppl 970.5 | wps 66016.7 | wpb 2040.3 | bsz 4 | num_updates 40100 | best_loss 7.59
2022-03-15 04:23:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 40100 updates
2022-03-15 04:23:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:23:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:23:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 390 @ 40100 updates, score 9.923) (writing took 0.9701483203098178 seconds)
2022-03-15 04:23:27 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-15 04:23:27 | INFO | train | epoch 390 | loss 3.591 | ppl 12.05 | wps 40216.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40100 | lr 0.000157917 | gnorm 1.105 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 65307
KL Stats: Epoch 390 Divergences: Uniform: 5.485498405897078 Unigram: 5.850892371892841
2022-03-15 04:23:27 | INFO | fairseq.trainer | begin training epoch 391
2022-03-15 04:23:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:25:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 04:26:07 | INFO | train_inner | epoch 391:    101 / 103 loss=3.588, ppl=12.03, wps=39805.7, ups=0.61, wpb=65536, bsz=128, num_updates=40200, lr=0.00015772, gnorm=1.09, loss_scale=8, train_wall=155, gb_free=20.8, wall=65467
2022-03-15 04:26:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:26:14 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 9.91 | ppl 962 | wps 66041.1 | wpb 2040.3 | bsz 4 | num_updates 40202 | best_loss 7.59
2022-03-15 04:26:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 40202 updates
2022-03-15 04:26:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:26:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:26:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 391 @ 40202 updates, score 9.91) (writing took 1.0185091122984886 seconds)
2022-03-15 04:26:15 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-15 04:26:15 | INFO | train | epoch 391 | loss 3.589 | ppl 12.04 | wps 39813.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 40202 | lr 0.000157716 | gnorm 1.091 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 65474
KL Stats: Epoch 391 Divergences: Uniform: 5.485702125813076 Unigram: 5.851990882365657
2022-03-15 04:26:15 | INFO | fairseq.trainer | begin training epoch 392
2022-03-15 04:26:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:28:50 | INFO | train_inner | epoch 392:     98 / 103 loss=3.588, ppl=12.03, wps=40161, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=40300, lr=0.000157524, gnorm=1.115, loss_scale=8, train_wall=153, gb_free=20.8, wall=65630
2022-03-15 04:28:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:29:01 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 9.921 | ppl 969.16 | wps 66266 | wpb 2040.3 | bsz 4 | num_updates 40305 | best_loss 7.59
2022-03-15 04:29:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 40305 updates
2022-03-15 04:29:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:29:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:29:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 392 @ 40305 updates, score 9.921) (writing took 1.0247686030343175 seconds)
2022-03-15 04:29:02 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-15 04:29:02 | INFO | train | epoch 392 | loss 3.589 | ppl 12.04 | wps 40199.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40305 | lr 0.000157514 | gnorm 1.115 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 65642
KL Stats: Epoch 392 Divergences: Uniform: 5.4846834221321155 Unigram: 5.8512038418544305
2022-03-15 04:29:02 | INFO | fairseq.trainer | begin training epoch 393
2022-03-15 04:29:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:31:33 | INFO | train_inner | epoch 393:     95 / 103 loss=3.586, ppl=12.01, wps=40154, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=40400, lr=0.000157329, gnorm=1.105, loss_scale=8, train_wall=153, gb_free=20.8, wall=65792
2022-03-15 04:31:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:31:48 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 9.915 | ppl 965.4 | wps 65786.2 | wpb 2040.3 | bsz 4 | num_updates 40408 | best_loss 7.59
2022-03-15 04:31:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 40408 updates
2022-03-15 04:31:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:31:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:31:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 393 @ 40408 updates, score 9.915) (writing took 0.9620865182951093 seconds)
2022-03-15 04:31:49 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-15 04:31:49 | INFO | train | epoch 393 | loss 3.587 | ppl 12.02 | wps 40205.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40408 | lr 0.000157314 | gnorm 1.105 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 65809
KL Stats: Epoch 393 Divergences: Uniform: 5.486444204456011 Unigram: 5.853688163238222
2022-03-15 04:31:49 | INFO | fairseq.trainer | begin training epoch 394
2022-03-15 04:31:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:34:15 | INFO | train_inner | epoch 394:     92 / 103 loss=3.586, ppl=12.01, wps=40192.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=40500, lr=0.000157135, gnorm=1.109, loss_scale=8, train_wall=153, gb_free=20.8, wall=65955
2022-03-15 04:34:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:34:36 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 9.942 | ppl 983.58 | wps 66129.1 | wpb 2040.3 | bsz 4 | num_updates 40511 | best_loss 7.59
2022-03-15 04:34:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 40511 updates
2022-03-15 04:34:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:34:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:34:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 394 @ 40511 updates, score 9.942) (writing took 0.9993035979568958 seconds)
2022-03-15 04:34:37 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-15 04:34:37 | INFO | train | epoch 394 | loss 3.587 | ppl 12.01 | wps 40216.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40511 | lr 0.000157114 | gnorm 1.111 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 65976
KL Stats: Epoch 394 Divergences: Uniform: 5.487883007881527 Unigram: 5.8565429058965845
2022-03-15 04:34:37 | INFO | fairseq.trainer | begin training epoch 395
2022-03-15 04:34:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:36:58 | INFO | train_inner | epoch 395:     89 / 103 loss=3.582, ppl=11.97, wps=40189.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=40600, lr=0.000156941, gnorm=1.109, loss_scale=8, train_wall=153, gb_free=20.8, wall=66117
2022-03-15 04:37:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:37:23 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 9.932 | ppl 977.17 | wps 65919.7 | wpb 2040.3 | bsz 4 | num_updates 40614 | best_loss 7.59
2022-03-15 04:37:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 40614 updates
2022-03-15 04:37:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:37:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:37:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 395 @ 40614 updates, score 9.932) (writing took 1.0271763885393739 seconds)
2022-03-15 04:37:24 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-15 04:37:24 | INFO | train | epoch 395 | loss 3.585 | ppl 12 | wps 40217.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40614 | lr 0.000156914 | gnorm 1.109 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 66143
KL Stats: Epoch 395 Divergences: Uniform: 5.488131225771131 Unigram: 5.858437134440044
2022-03-15 04:37:24 | INFO | fairseq.trainer | begin training epoch 396
2022-03-15 04:37:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:39:40 | INFO | train_inner | epoch 396:     86 / 103 loss=3.584, ppl=11.99, wps=40185.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=40700, lr=0.000156748, gnorm=1.094, loss_scale=16, train_wall=153, gb_free=20.8, wall=66280
2022-03-15 04:39:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 04:40:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:40:10 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 9.953 | ppl 990.88 | wps 66161.8 | wpb 2040.3 | bsz 4 | num_updates 40716 | best_loss 7.59
2022-03-15 04:40:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 40716 updates
2022-03-15 04:40:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:40:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:40:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 396 @ 40716 updates, score 9.953) (writing took 1.0070170676335692 seconds)
2022-03-15 04:40:11 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-15 04:40:11 | INFO | train | epoch 396 | loss 3.583 | ppl 11.98 | wps 39831.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 40716 | lr 0.000156717 | gnorm 1.094 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 66311
KL Stats: Epoch 396 Divergences: Uniform: 5.4882576216051975 Unigram: 5.860168965189893
2022-03-15 04:40:11 | INFO | fairseq.trainer | begin training epoch 397
2022-03-15 04:40:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:42:24 | INFO | train_inner | epoch 397:     84 / 103 loss=3.581, ppl=11.97, wps=39791.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=40800, lr=0.000156556, gnorm=1.113, loss_scale=8, train_wall=155, gb_free=20.8, wall=66444
2022-03-15 04:42:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:42:57 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 9.941 | ppl 982.73 | wps 66039.5 | wpb 2040.3 | bsz 4 | num_updates 40819 | best_loss 7.59
2022-03-15 04:42:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 40819 updates
2022-03-15 04:42:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:42:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:42:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 397 @ 40819 updates, score 9.941) (writing took 1.0444893352687359 seconds)
2022-03-15 04:42:58 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-15 04:42:58 | INFO | train | epoch 397 | loss 3.584 | ppl 11.99 | wps 40204.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40819 | lr 0.00015652 | gnorm 1.112 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 66478
KL Stats: Epoch 397 Divergences: Uniform: 5.48733699029752 Unigram: 5.859680741321694
2022-03-15 04:42:58 | INFO | fairseq.trainer | begin training epoch 398
2022-03-15 04:42:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:45:07 | INFO | train_inner | epoch 398:     81 / 103 loss=3.581, ppl=11.97, wps=40183.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=40900, lr=0.000156365, gnorm=1.107, loss_scale=8, train_wall=153, gb_free=20.8, wall=66606
2022-03-15 04:45:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:45:45 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 9.934 | ppl 978.48 | wps 65916.6 | wpb 2040.3 | bsz 4 | num_updates 40922 | best_loss 7.59
2022-03-15 04:45:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 40922 updates
2022-03-15 04:45:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:45:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:45:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 398 @ 40922 updates, score 9.934) (writing took 1.0188705455511808 seconds)
2022-03-15 04:45:46 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-15 04:45:46 | INFO | train | epoch 398 | loss 3.582 | ppl 11.98 | wps 40209.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40922 | lr 0.000156323 | gnorm 1.105 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 66645
KL Stats: Epoch 398 Divergences: Uniform: 5.487799684104345 Unigram: 5.86096809838966
2022-03-15 04:45:46 | INFO | fairseq.trainer | begin training epoch 399
2022-03-15 04:45:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:47:49 | INFO | train_inner | epoch 399:     78 / 103 loss=3.582, ppl=11.97, wps=40161.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=41000, lr=0.000156174, gnorm=1.11, loss_scale=8, train_wall=153, gb_free=20.8, wall=66769
2022-03-15 04:48:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:48:32 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 9.946 | ppl 986.42 | wps 66149.8 | wpb 2040.3 | bsz 4 | num_updates 41025 | best_loss 7.59
2022-03-15 04:48:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 41025 updates
2022-03-15 04:48:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:48:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:48:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 399 @ 41025 updates, score 9.946) (writing took 0.9820091426372528 seconds)
2022-03-15 04:48:33 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-15 04:48:33 | INFO | train | epoch 399 | loss 3.581 | ppl 11.97 | wps 40221.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41025 | lr 0.000156126 | gnorm 1.109 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 66813
KL Stats: Epoch 399 Divergences: Uniform: 5.487991360786777 Unigram: 5.862363110872348
2022-03-15 04:48:33 | INFO | fairseq.trainer | begin training epoch 400
2022-03-15 04:48:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:50:32 | INFO | train_inner | epoch 400:     75 / 103 loss=3.578, ppl=11.94, wps=40188.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=41100, lr=0.000155984, gnorm=1.103, loss_scale=8, train_wall=153, gb_free=20.8, wall=66931
2022-03-15 04:51:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:51:19 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 9.939 | ppl 981.44 | wps 65518.4 | wpb 2040.3 | bsz 4 | num_updates 41128 | best_loss 7.59
2022-03-15 04:51:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 41128 updates
2022-03-15 04:51:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:51:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:51:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 400 @ 41128 updates, score 9.939) (writing took 1.0234730318188667 seconds)
2022-03-15 04:51:20 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-15 04:51:20 | INFO | train | epoch 400 | loss 3.579 | ppl 11.95 | wps 40207.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41128 | lr 0.000155931 | gnorm 1.107 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 66980
KL Stats: Epoch 400 Divergences: Uniform: 5.489311788572288 Unigram: 5.864785618026189
2022-03-15 04:51:20 | INFO | fairseq.trainer | begin training epoch 401
2022-03-15 04:51:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:53:14 | INFO | train_inner | epoch 401:     72 / 103 loss=3.579, ppl=11.95, wps=40193.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=41200, lr=0.000155794, gnorm=1.1, loss_scale=8, train_wall=153, gb_free=20.8, wall=67094
2022-03-15 04:53:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 04:54:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:54:07 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 9.95 | ppl 988.85 | wps 65978.8 | wpb 2040.3 | bsz 4 | num_updates 41230 | best_loss 7.59
2022-03-15 04:54:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 41230 updates
2022-03-15 04:54:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:54:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:54:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 401 @ 41230 updates, score 9.95) (writing took 1.018405626527965 seconds)
2022-03-15 04:54:08 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-15 04:54:08 | INFO | train | epoch 401 | loss 3.578 | ppl 11.94 | wps 39836 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 41230 | lr 0.000155738 | gnorm 1.102 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 67147
KL Stats: Epoch 401 Divergences: Uniform: 5.4911365809270505 Unigram: 5.86726230103639
2022-03-15 04:54:08 | INFO | fairseq.trainer | begin training epoch 402
2022-03-15 04:54:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:55:59 | INFO | train_inner | epoch 402:     70 / 103 loss=3.575, ppl=11.92, wps=39781.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=41300, lr=0.000155606, gnorm=1.112, loss_scale=8, train_wall=155, gb_free=20.8, wall=67258
2022-03-15 04:56:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:56:54 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 9.923 | ppl 970.96 | wps 65833.3 | wpb 2040.3 | bsz 4 | num_updates 41333 | best_loss 7.59
2022-03-15 04:56:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 41333 updates
2022-03-15 04:56:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:56:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:56:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 402 @ 41333 updates, score 9.923) (writing took 0.9637217549607158 seconds)
2022-03-15 04:56:55 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-15 04:56:55 | INFO | train | epoch 402 | loss 3.577 | ppl 11.94 | wps 40214.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41333 | lr 0.000155543 | gnorm 1.112 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 67314
KL Stats: Epoch 402 Divergences: Uniform: 5.489655480519863 Unigram: 5.866272594596411
2022-03-15 04:56:55 | INFO | fairseq.trainer | begin training epoch 403
2022-03-15 04:56:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:58:41 | INFO | train_inner | epoch 403:     67 / 103 loss=3.577, ppl=11.94, wps=40186.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=41400, lr=0.000155417, gnorm=1.124, loss_scale=8, train_wall=153, gb_free=20.8, wall=67421
2022-03-15 04:59:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:59:41 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 9.947 | ppl 987.29 | wps 65627.6 | wpb 2040.3 | bsz 4 | num_updates 41436 | best_loss 7.59
2022-03-15 04:59:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 41436 updates
2022-03-15 04:59:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:59:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 04:59:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 403 @ 41436 updates, score 9.947) (writing took 1.0206529628485441 seconds)
2022-03-15 04:59:42 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-15 04:59:42 | INFO | train | epoch 403 | loss 3.577 | ppl 11.93 | wps 40204 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41436 | lr 0.00015535 | gnorm 1.124 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 67482
KL Stats: Epoch 403 Divergences: Uniform: 5.490644180252956 Unigram: 5.868406517026003
2022-03-15 04:59:42 | INFO | fairseq.trainer | begin training epoch 404
2022-03-15 04:59:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:01:24 | INFO | train_inner | epoch 404:     64 / 103 loss=3.576, ppl=11.92, wps=40181.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=41500, lr=0.00015523, gnorm=1.11, loss_scale=8, train_wall=153, gb_free=20.8, wall=67583
2022-03-15 05:02:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:02:28 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 9.936 | ppl 979.71 | wps 65542.5 | wpb 2040.3 | bsz 4 | num_updates 41539 | best_loss 7.59
2022-03-15 05:02:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 41539 updates
2022-03-15 05:02:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:02:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:02:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 404 @ 41539 updates, score 9.936) (writing took 0.9956415900960565 seconds)
2022-03-15 05:02:29 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-15 05:02:29 | INFO | train | epoch 404 | loss 3.574 | ppl 11.91 | wps 40220.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41539 | lr 0.000155157 | gnorm 1.109 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 67649
KL Stats: Epoch 404 Divergences: Uniform: 5.492456294596743 Unigram: 5.869887750926549
2022-03-15 05:02:29 | INFO | fairseq.trainer | begin training epoch 405
2022-03-15 05:02:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:04:06 | INFO | train_inner | epoch 405:     61 / 103 loss=3.573, ppl=11.9, wps=40191.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=41600, lr=0.000155043, gnorm=1.114, loss_scale=8, train_wall=153, gb_free=20.8, wall=67746
2022-03-15 05:05:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:05:16 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 9.946 | ppl 986.65 | wps 66222.8 | wpb 2040.3 | bsz 4 | num_updates 41642 | best_loss 7.59
2022-03-15 05:05:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 41642 updates
2022-03-15 05:05:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:05:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:05:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 405 @ 41642 updates, score 9.946) (writing took 0.972236561588943 seconds)
2022-03-15 05:05:17 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-15 05:05:17 | INFO | train | epoch 405 | loss 3.574 | ppl 11.91 | wps 40220.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41642 | lr 0.000154965 | gnorm 1.113 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 67816
KL Stats: Epoch 405 Divergences: Uniform: 5.490501869036109 Unigram: 5.869550563816465
2022-03-15 05:05:17 | INFO | fairseq.trainer | begin training epoch 406
2022-03-15 05:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:06:49 | INFO | train_inner | epoch 406:     58 / 103 loss=3.573, ppl=11.9, wps=40184.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=41700, lr=0.000154857, gnorm=1.115, loss_scale=8, train_wall=153, gb_free=20.8, wall=67908
2022-03-15 05:07:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 05:07:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:08:03 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 9.953 | ppl 991.43 | wps 66057.5 | wpb 2040.3 | bsz 4 | num_updates 41744 | best_loss 7.59
2022-03-15 05:08:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 41744 updates
2022-03-15 05:08:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:08:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:08:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 406 @ 41744 updates, score 9.953) (writing took 1.0085824094712734 seconds)
2022-03-15 05:08:04 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-15 05:08:04 | INFO | train | epoch 406 | loss 3.572 | ppl 11.89 | wps 39813.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 41744 | lr 0.000154776 | gnorm 1.11 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 67984
KL Stats: Epoch 406 Divergences: Uniform: 5.493116979819968 Unigram: 5.872510767211016
2022-03-15 05:08:04 | INFO | fairseq.trainer | begin training epoch 407
2022-03-15 05:08:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:09:33 | INFO | train_inner | epoch 407:     56 / 103 loss=3.572, ppl=11.89, wps=39783.5, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=41800, lr=0.000154672, gnorm=1.107, loss_scale=8, train_wall=155, gb_free=20.8, wall=68072
2022-03-15 05:10:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:10:50 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 9.941 | ppl 982.69 | wps 66159.5 | wpb 2040.3 | bsz 4 | num_updates 41847 | best_loss 7.59
2022-03-15 05:10:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 41847 updates
2022-03-15 05:10:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:10:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:10:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 407 @ 41847 updates, score 9.941) (writing took 1.0166886048391461 seconds)
2022-03-15 05:10:51 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-15 05:10:51 | INFO | train | epoch 407 | loss 3.573 | ppl 11.9 | wps 40214 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41847 | lr 0.000154585 | gnorm 1.113 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 68151
KL Stats: Epoch 407 Divergences: Uniform: 5.4908142234350485 Unigram: 5.87174419222092
2022-03-15 05:10:51 | INFO | fairseq.trainer | begin training epoch 408
2022-03-15 05:10:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:12:15 | INFO | train_inner | epoch 408:     53 / 103 loss=3.572, ppl=11.89, wps=40174, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=41900, lr=0.000154487, gnorm=1.115, loss_scale=8, train_wall=153, gb_free=20.8, wall=68235
2022-03-15 05:13:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:13:38 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 9.963 | ppl 998.33 | wps 66028.9 | wpb 2040.3 | bsz 4 | num_updates 41950 | best_loss 7.59
2022-03-15 05:13:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 41950 updates
2022-03-15 05:13:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:13:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:13:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 408 @ 41950 updates, score 9.963) (writing took 0.9770805686712265 seconds)
2022-03-15 05:13:38 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-15 05:13:38 | INFO | train | epoch 408 | loss 3.573 | ppl 11.9 | wps 40222.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41950 | lr 0.000154395 | gnorm 1.115 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 68318
KL Stats: Epoch 408 Divergences: Uniform: 5.490315667826185 Unigram: 5.873608087397271
2022-03-15 05:13:39 | INFO | fairseq.trainer | begin training epoch 409
2022-03-15 05:13:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:14:58 | INFO | train_inner | epoch 409:     50 / 103 loss=3.572, ppl=11.9, wps=40196.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=42000, lr=0.000154303, gnorm=1.111, loss_scale=8, train_wall=153, gb_free=20.8, wall=68397
2022-03-15 05:16:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:16:25 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 9.953 | ppl 991.04 | wps 65918.2 | wpb 2040.3 | bsz 4 | num_updates 42053 | best_loss 7.59
2022-03-15 05:16:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 42053 updates
2022-03-15 05:16:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:16:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:16:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 409 @ 42053 updates, score 9.953) (writing took 1.0018505658954382 seconds)
2022-03-15 05:16:26 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-15 05:16:26 | INFO | train | epoch 409 | loss 3.57 | ppl 11.88 | wps 40211.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42053 | lr 0.000154206 | gnorm 1.118 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 68485
KL Stats: Epoch 409 Divergences: Uniform: 5.494356093734623 Unigram: 5.8760591885060585
2022-03-15 05:16:26 | INFO | fairseq.trainer | begin training epoch 410
2022-03-15 05:16:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:17:40 | INFO | train_inner | epoch 410:     47 / 103 loss=3.568, ppl=11.86, wps=40169.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=42100, lr=0.00015412, gnorm=1.109, loss_scale=8, train_wall=153, gb_free=20.8, wall=68560
2022-03-15 05:19:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:19:12 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 9.926 | ppl 972.68 | wps 66426.5 | wpb 2040.3 | bsz 4 | num_updates 42156 | best_loss 7.59
2022-03-15 05:19:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 42156 updates
2022-03-15 05:19:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:19:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:19:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 410 @ 42156 updates, score 9.926) (writing took 1.0112345684319735 seconds)
2022-03-15 05:19:13 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-15 05:19:13 | INFO | train | epoch 410 | loss 3.569 | ppl 11.87 | wps 40212.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42156 | lr 0.000154018 | gnorm 1.097 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 68653
KL Stats: Epoch 410 Divergences: Uniform: 5.494148248642321 Unigram: 5.875590618255604
2022-03-15 05:19:13 | INFO | fairseq.trainer | begin training epoch 411
2022-03-15 05:19:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:20:23 | INFO | train_inner | epoch 411:     44 / 103 loss=3.57, ppl=11.87, wps=40177.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=42200, lr=0.000153937, gnorm=1.096, loss_scale=8, train_wall=153, gb_free=20.8, wall=68722
2022-03-15 05:21:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:21:59 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 9.951 | ppl 989.62 | wps 66068.4 | wpb 2040.3 | bsz 4 | num_updates 42259 | best_loss 7.59
2022-03-15 05:21:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 42259 updates
2022-03-15 05:21:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:22:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:22:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 411 @ 42259 updates, score 9.951) (writing took 1.0142156761139631 seconds)
2022-03-15 05:22:00 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-15 05:22:00 | INFO | train | epoch 411 | loss 3.568 | ppl 11.86 | wps 40200.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42259 | lr 0.00015383 | gnorm 1.1 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 68820
KL Stats: Epoch 411 Divergences: Uniform: 5.495313213694924 Unigram: 5.878856456485817
2022-03-15 05:22:00 | INFO | fairseq.trainer | begin training epoch 412
2022-03-15 05:22:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:23:05 | INFO | train_inner | epoch 412:     41 / 103 loss=3.568, ppl=11.86, wps=40164.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=42300, lr=0.000153755, gnorm=1.116, loss_scale=16, train_wall=153, gb_free=20.8, wall=68885
2022-03-15 05:24:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:24:47 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 9.96 | ppl 995.66 | wps 66252.6 | wpb 2040.3 | bsz 4 | num_updates 42362 | best_loss 7.59
2022-03-15 05:24:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 42362 updates
2022-03-15 05:24:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:24:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:24:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 412 @ 42362 updates, score 9.96) (writing took 1.008824985474348 seconds)
2022-03-15 05:24:48 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-15 05:24:48 | INFO | train | epoch 412 | loss 3.568 | ppl 11.86 | wps 40218.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42362 | lr 0.000153643 | gnorm 1.111 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 68987
KL Stats: Epoch 412 Divergences: Uniform: 5.494351297022885 Unigram: 5.879176998664544
2022-03-15 05:24:48 | INFO | fairseq.trainer | begin training epoch 413
2022-03-15 05:24:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:25:48 | INFO | train_inner | epoch 413:     38 / 103 loss=3.568, ppl=11.86, wps=40188.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=42400, lr=0.000153574, gnorm=1.097, loss_scale=16, train_wall=153, gb_free=20.8, wall=69048
2022-03-15 05:26:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 05:27:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:27:34 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 9.971 | ppl 1003.69 | wps 66201.6 | wpb 2040.3 | bsz 4 | num_updates 42464 | best_loss 7.59
2022-03-15 05:27:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 42464 updates
2022-03-15 05:27:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:27:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:27:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 413 @ 42464 updates, score 9.971) (writing took 1.0081078419461846 seconds)
2022-03-15 05:27:35 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-15 05:27:35 | INFO | train | epoch 413 | loss 3.565 | ppl 11.84 | wps 39821 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 42464 | lr 0.000153458 | gnorm 1.105 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 69155
KL Stats: Epoch 413 Divergences: Uniform: 5.49602718963567 Unigram: 5.8801741744192615
2022-03-15 05:27:35 | INFO | fairseq.trainer | begin training epoch 414
2022-03-15 05:27:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:28:32 | INFO | train_inner | epoch 414:     36 / 103 loss=3.564, ppl=11.83, wps=39782.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=42500, lr=0.000153393, gnorm=1.11, loss_scale=8, train_wall=155, gb_free=20.8, wall=69212
2022-03-15 05:30:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:30:21 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 9.955 | ppl 992.26 | wps 66082 | wpb 2040.3 | bsz 4 | num_updates 42567 | best_loss 7.59
2022-03-15 05:30:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 42567 updates
2022-03-15 05:30:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:30:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:30:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 414 @ 42567 updates, score 9.955) (writing took 0.9720229404047132 seconds)
2022-03-15 05:30:22 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-15 05:30:22 | INFO | train | epoch 414 | loss 3.565 | ppl 11.83 | wps 40223.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42567 | lr 0.000153272 | gnorm 1.109 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 69322
KL Stats: Epoch 414 Divergences: Uniform: 5.495307653201946 Unigram: 5.8822678211376305
2022-03-15 05:30:22 | INFO | fairseq.trainer | begin training epoch 415
2022-03-15 05:30:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:31:15 | INFO | train_inner | epoch 415:     33 / 103 loss=3.564, ppl=11.83, wps=40199.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=42600, lr=0.000153213, gnorm=1.116, loss_scale=8, train_wall=153, gb_free=20.8, wall=69374
2022-03-15 05:33:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:33:09 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 9.98 | ppl 1009.71 | wps 65886.2 | wpb 2040.3 | bsz 4 | num_updates 42670 | best_loss 7.59
2022-03-15 05:33:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 42670 updates
2022-03-15 05:33:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:33:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:33:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 415 @ 42670 updates, score 9.98) (writing took 1.0175220165401697 seconds)
2022-03-15 05:33:10 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-15 05:33:10 | INFO | train | epoch 415 | loss 3.564 | ppl 11.82 | wps 40175.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42670 | lr 0.000153087 | gnorm 1.11 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 69489
KL Stats: Epoch 415 Divergences: Uniform: 5.497041568426404 Unigram: 5.884986868181751
2022-03-15 05:33:10 | INFO | fairseq.trainer | begin training epoch 416
2022-03-15 05:33:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:33:57 | INFO | train_inner | epoch 416:     30 / 103 loss=3.564, ppl=11.82, wps=40128.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=42700, lr=0.000153033, gnorm=1.098, loss_scale=8, train_wall=153, gb_free=20.8, wall=69537
2022-03-15 05:35:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:35:56 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 9.99 | ppl 1016.93 | wps 65768.4 | wpb 2040.3 | bsz 4 | num_updates 42773 | best_loss 7.59
2022-03-15 05:35:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 42773 updates
2022-03-15 05:35:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:35:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:35:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 416 @ 42773 updates, score 9.99) (writing took 1.0189176071435213 seconds)
2022-03-15 05:35:57 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-15 05:35:57 | INFO | train | epoch 416 | loss 3.563 | ppl 11.82 | wps 40183.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42773 | lr 0.000152903 | gnorm 1.109 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 69657
KL Stats: Epoch 416 Divergences: Uniform: 5.497142148763215 Unigram: 5.886664912822537
2022-03-15 05:35:57 | INFO | fairseq.trainer | begin training epoch 417
2022-03-15 05:35:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:36:40 | INFO | train_inner | epoch 417:     27 / 103 loss=3.562, ppl=11.81, wps=40140.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=42800, lr=0.000152854, gnorm=1.114, loss_scale=8, train_wall=153, gb_free=20.8, wall=69700
2022-03-15 05:38:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:38:43 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 9.967 | ppl 1000.85 | wps 65964.8 | wpb 2040.3 | bsz 4 | num_updates 42876 | best_loss 7.59
2022-03-15 05:38:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 42876 updates
2022-03-15 05:38:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:38:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:38:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 417 @ 42876 updates, score 9.967) (writing took 0.9803087329491973 seconds)
2022-03-15 05:38:44 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-15 05:38:44 | INFO | train | epoch 417 | loss 3.561 | ppl 11.8 | wps 40187.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42876 | lr 0.000152719 | gnorm 1.112 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 69824
KL Stats: Epoch 417 Divergences: Uniform: 5.496065127354152 Unigram: 5.886162356691967
2022-03-15 05:38:44 | INFO | fairseq.trainer | begin training epoch 418
2022-03-15 05:38:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:39:23 | INFO | train_inner | epoch 418:     24 / 103 loss=3.564, ppl=11.83, wps=40169.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=42900, lr=0.000152676, gnorm=1.115, loss_scale=8, train_wall=153, gb_free=20.8, wall=69862
2022-03-15 05:41:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:41:31 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 9.961 | ppl 996.45 | wps 66122.9 | wpb 2040.3 | bsz 4 | num_updates 42979 | best_loss 7.59
2022-03-15 05:41:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 42979 updates
2022-03-15 05:41:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:41:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:41:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 418 @ 42979 updates, score 9.961) (writing took 0.9736516317352653 seconds)
2022-03-15 05:41:32 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-15 05:41:32 | INFO | train | epoch 418 | loss 3.561 | ppl 11.8 | wps 40196.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42979 | lr 0.000152536 | gnorm 1.099 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 69991
KL Stats: Epoch 418 Divergences: Uniform: 5.496234774685993 Unigram: 5.887070313005072
2022-03-15 05:41:32 | INFO | fairseq.trainer | begin training epoch 419
2022-03-15 05:41:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:42:05 | INFO | train_inner | epoch 419:     21 / 103 loss=3.56, ppl=11.8, wps=40158.6, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=43000, lr=0.000152499, gnorm=1.1, loss_scale=16, train_wall=153, gb_free=20.8, wall=70025
2022-03-15 05:43:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 05:44:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:44:18 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 9.966 | ppl 1000.36 | wps 66283.6 | wpb 2040.3 | bsz 4 | num_updates 43081 | best_loss 7.59
2022-03-15 05:44:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 43081 updates
2022-03-15 05:44:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:44:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:44:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 419 @ 43081 updates, score 9.966) (writing took 0.9838237520307302 seconds)
2022-03-15 05:44:19 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-15 05:44:19 | INFO | train | epoch 419 | loss 3.561 | ppl 11.8 | wps 39813.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 43081 | lr 0.000152355 | gnorm 1.115 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 70159
KL Stats: Epoch 419 Divergences: Uniform: 5.49655753286852 Unigram: 5.88705629949931
2022-03-15 05:44:19 | INFO | fairseq.trainer | begin training epoch 420
2022-03-15 05:44:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:44:49 | INFO | train_inner | epoch 420:     19 / 103 loss=3.563, ppl=11.82, wps=39792.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=43100, lr=0.000152322, gnorm=1.117, loss_scale=8, train_wall=155, gb_free=20.8, wall=70189
2022-03-15 05:47:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:47:05 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 9.973 | ppl 1005.17 | wps 66281.6 | wpb 2040.3 | bsz 4 | num_updates 43184 | best_loss 7.59
2022-03-15 05:47:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 43184 updates
2022-03-15 05:47:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:47:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:47:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 420 @ 43184 updates, score 9.973) (writing took 0.9696547584608197 seconds)
2022-03-15 05:47:06 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-15 05:47:06 | INFO | train | epoch 420 | loss 3.559 | ppl 11.78 | wps 40218.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43184 | lr 0.000152173 | gnorm 1.119 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 70326
KL Stats: Epoch 420 Divergences: Uniform: 5.498119079404651 Unigram: 5.8899757578864875
2022-03-15 05:47:06 | INFO | fairseq.trainer | begin training epoch 421
2022-03-15 05:47:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:47:32 | INFO | train_inner | epoch 421:     16 / 103 loss=3.558, ppl=11.78, wps=40182.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=43200, lr=0.000152145, gnorm=1.115, loss_scale=8, train_wall=153, gb_free=20.8, wall=70351
2022-03-15 05:49:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:49:53 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 9.992 | ppl 1018.47 | wps 66280.9 | wpb 2040.3 | bsz 4 | num_updates 43287 | best_loss 7.59
2022-03-15 05:49:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 43287 updates
2022-03-15 05:49:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:49:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:49:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 421 @ 43287 updates, score 9.992) (writing took 0.9628501329571009 seconds)
2022-03-15 05:49:54 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-15 05:49:54 | INFO | train | epoch 421 | loss 3.557 | ppl 11.77 | wps 40229.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43287 | lr 0.000151992 | gnorm 1.108 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 70493
KL Stats: Epoch 421 Divergences: Uniform: 5.49953278902481 Unigram: 5.89153292979682
2022-03-15 05:49:54 | INFO | fairseq.trainer | begin training epoch 422
2022-03-15 05:49:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:50:14 | INFO | train_inner | epoch 422:     13 / 103 loss=3.559, ppl=11.79, wps=40197.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=43300, lr=0.000151969, gnorm=1.111, loss_scale=8, train_wall=153, gb_free=20.8, wall=70514
2022-03-15 05:52:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:52:40 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 9.987 | ppl 1014.68 | wps 66304.1 | wpb 2040.3 | bsz 4 | num_updates 43390 | best_loss 7.59
2022-03-15 05:52:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 43390 updates
2022-03-15 05:52:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:52:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:52:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 422 @ 43390 updates, score 9.987) (writing took 0.9682299150153995 seconds)
2022-03-15 05:52:41 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-15 05:52:41 | INFO | train | epoch 422 | loss 3.557 | ppl 11.77 | wps 40235.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43390 | lr 0.000151812 | gnorm 1.128 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 70660
KL Stats: Epoch 422 Divergences: Uniform: 5.499921688782726 Unigram: 5.893254121062772
2022-03-15 05:52:41 | INFO | fairseq.trainer | begin training epoch 423
2022-03-15 05:52:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:52:57 | INFO | train_inner | epoch 423:     10 / 103 loss=3.559, ppl=11.78, wps=40200.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=43400, lr=0.000151794, gnorm=1.131, loss_scale=8, train_wall=153, gb_free=20.8, wall=70676
2022-03-15 05:55:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:55:27 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 9.964 | ppl 999.1 | wps 66115.2 | wpb 2040.3 | bsz 4 | num_updates 43493 | best_loss 7.59
2022-03-15 05:55:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 43493 updates
2022-03-15 05:55:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:55:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:55:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 423 @ 43493 updates, score 9.964) (writing took 0.9331011455506086 seconds)
2022-03-15 05:55:28 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-15 05:55:28 | INFO | train | epoch 423 | loss 3.555 | ppl 11.76 | wps 40221.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43493 | lr 0.000151632 | gnorm 1.114 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 70828
KL Stats: Epoch 423 Divergences: Uniform: 5.499346413565015 Unigram: 5.8929941903409295
2022-03-15 05:55:28 | INFO | fairseq.trainer | begin training epoch 424
2022-03-15 05:55:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:55:39 | INFO | train_inner | epoch 424:      7 / 103 loss=3.556, ppl=11.76, wps=40185.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=43500, lr=0.00015162, gnorm=1.111, loss_scale=8, train_wall=153, gb_free=20.8, wall=70839
2022-03-15 05:58:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:58:14 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 9.976 | ppl 1007.03 | wps 66275.1 | wpb 2040.3 | bsz 4 | num_updates 43596 | best_loss 7.59
2022-03-15 05:58:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 43596 updates
2022-03-15 05:58:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:58:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 05:58:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 424 @ 43596 updates, score 9.976) (writing took 0.9595928164198995 seconds)
2022-03-15 05:58:15 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-15 05:58:15 | INFO | train | epoch 424 | loss 3.554 | ppl 11.75 | wps 40232.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43596 | lr 0.000151453 | gnorm 1.118 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 70995
KL Stats: Epoch 424 Divergences: Uniform: 5.499076891454014 Unigram: 5.894051735959714
2022-03-15 05:58:15 | INFO | fairseq.trainer | begin training epoch 425
2022-03-15 05:58:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:58:22 | INFO | train_inner | epoch 425:      4 / 103 loss=3.556, ppl=11.76, wps=40200.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=43600, lr=0.000151446, gnorm=1.121, loss_scale=16, train_wall=153, gb_free=20.8, wall=71001
2022-03-15 06:00:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:01:02 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 10.002 | ppl 1025.72 | wps 66111.5 | wpb 2040.3 | bsz 4 | num_updates 43699 | best_loss 7.59
2022-03-15 06:01:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 43699 updates
2022-03-15 06:01:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 06:01:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 06:01:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 425 @ 43699 updates, score 10.002) (writing took 0.964589268900454 seconds)
2022-03-15 06:01:03 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-15 06:01:03 | INFO | train | epoch 425 | loss 3.554 | ppl 11.74 | wps 40211.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43699 | lr 0.000151274 | gnorm 1.098 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 71162
KL Stats: Epoch 425 Divergences: Uniform: 5.500255254245322 Unigram: 5.89592087504705
2022-03-15 06:01:03 | INFO | fairseq.trainer | begin training epoch 426
2022-03-15 06:01:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:01:04 | INFO | train_inner | epoch 426:      1 / 103 loss=3.555, ppl=11.76, wps=40176.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=43700, lr=0.000151272, gnorm=1.096, loss_scale=16, train_wall=153, gb_free=20.8, wall=71164
2022-03-15 06:03:43 | INFO | train_inner | epoch 426:    101 / 103 loss=3.553, ppl=11.74, wps=41352.1, ups=0.63, wpb=65530.9, bsz=128, num_updates=43800, lr=0.000151099, gnorm=1.108, loss_scale=16, train_wall=154, gb_free=20.8, wall=71322
2022-03-15 06:03:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:03:49 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 10.008 | ppl 1029.6 | wps 65891.9 | wpb 2040.3 | bsz 4 | num_updates 43802 | best_loss 7.59
2022-03-15 06:03:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 43802 updates
2022-03-15 06:03:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 06:03:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 06:03:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 426 @ 43802 updates, score 10.008) (writing took 0.9495768202468753 seconds)
2022-03-15 06:03:50 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-15 06:03:50 | INFO | train | epoch 426 | loss 3.554 | ppl 11.74 | wps 40208.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43802 | lr 0.000151096 | gnorm 1.109 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 71329
KL Stats: Epoch 426 Divergences: Uniform: 5.498752240163081 Unigram: 5.8938772095613245
2022-03-15 06:03:50 | INFO | fairseq.trainer | begin training epoch 427
2022-03-15 06:03:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:06:25 | INFO | train_inner | epoch 427:     98 / 103 loss=3.551, ppl=11.72, wps=40182.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=43900, lr=0.000150927, gnorm=1.111, loss_scale=16, train_wall=153, gb_free=20.8, wall=71485
2022-03-15 06:06:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:06:36 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 10.001 | ppl 1024.5 | wps 66267.5 | wpb 2040.3 | bsz 4 | num_updates 43905 | best_loss 7.59
2022-03-15 06:06:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 43905 updates
2022-03-15 06:06:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 06:06:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 06:06:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 427 @ 43905 updates, score 10.001) (writing took 0.9606697931885719 seconds)
2022-03-15 06:06:37 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-15 06:06:37 | INFO | train | epoch 427 | loss 3.553 | ppl 11.74 | wps 40219.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43905 | lr 0.000150919 | gnorm 1.113 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 71497
KL Stats: Epoch 427 Divergences: Uniform: 5.500242060429474 Unigram: 5.897902800800959
2022-03-15 06:06:37 | INFO | fairseq.trainer | begin training epoch 428
2022-03-15 06:06:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:09:08 | INFO | train_inner | epoch 428:     95 / 103 loss=3.55, ppl=11.71, wps=40192.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=44000, lr=0.000150756, gnorm=1.109, loss_scale=16, train_wall=153, gb_free=20.8, wall=71647
2022-03-15 06:09:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:09:23 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 9.984 | ppl 1012.55 | wps 66278.4 | wpb 2040.3 | bsz 4 | num_updates 44008 | best_loss 7.59
2022-03-15 06:09:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 44008 updates
2022-03-15 06:09:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 06:09:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 06:09:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 428 @ 44008 updates, score 9.984) (writing took 0.9491282738745213 seconds)
2022-03-15 06:09:24 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-15 06:09:24 | INFO | train | epoch 428 | loss 3.552 | ppl 11.73 | wps 40227.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 44008 | lr 0.000150742 | gnorm 1.108 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 71664
KL Stats: Epoch 428 Divergences: Uniform: 5.499347456468734 Unigram: 5.897115026812818
2022-03-15 06:09:24 | INFO | fairseq.trainer | begin training epoch 429
2022-03-15 06:09:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:10:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 06:11:52 | INFO | train_inner | epoch 429:     93 / 103 loss=3.548, ppl=11.69, wps=39818.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=44100, lr=0.000150585, gnorm=1.113, loss_scale=8, train_wall=154, gb_free=20.8, wall=71811
2022-03-15 06:12:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:12:11 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 9.999 | ppl 1023.41 | wps 65933.8 | wpb 2040.3 | bsz 4 | num_updates 44110 | best_loss 7.59
2022-03-15 06:12:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 44110 updates
2022-03-15 06:12:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 06:12:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 06:12:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 429 @ 44110 updates, score 9.999) (writing took 0.9413537168875337 seconds)
2022-03-15 06:12:12 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-15 06:12:12 | INFO | train | epoch 429 | loss 3.549 | ppl 11.71 | wps 39848.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 44110 | lr 0.000150568 | gnorm 1.115 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 71831
KL Stats: Epoch 429 Divergences: Uniform: 5.5016215840347025 Unigram: 5.9006461456007
2022-03-15 06:12:12 | INFO | fairseq.trainer | begin training epoch 430
2022-03-15 06:12:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:14:34 | INFO | train_inner | epoch 430:     90 / 103 loss=3.551, ppl=11.72, wps=40184.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=44200, lr=0.000150414, gnorm=1.124, loss_scale=8, train_wall=153, gb_free=20.8, wall=71974
2022-03-15 06:14:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:14:58 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 9.98 | ppl 1009.7 | wps 66397.2 | wpb 2040.3 | bsz 4 | num_updates 44213 | best_loss 7.59
2022-03-15 06:14:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 44213 updates
2022-03-15 06:14:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 06:14:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 06:14:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 430 @ 44213 updates, score 9.98) (writing took 0.9619009019806981 seconds)
2022-03-15 06:14:59 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-15 06:14:59 | INFO | train | epoch 430 | loss 3.55 | ppl 11.71 | wps 40214.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 44213 | lr 0.000150392 | gnorm 1.12 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 71998
KL Stats: Epoch 430 Divergences: Uniform: 5.500901191153041 Unigram: 5.900461772260704
2022-03-15 06:14:59 | INFO | fairseq.trainer | begin training epoch 431
2022-03-15 06:14:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:17:17 | INFO | train_inner | epoch 431:     87 / 103 loss=3.548, ppl=11.7, wps=40193.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=44300, lr=0.000150244, gnorm=1.107, loss_scale=8, train_wall=153, gb_free=20.8, wall=72136
2022-03-15 06:17:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:17:45 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 9.994 | ppl 1019.94 | wps 66304.9 | wpb 2040.3 | bsz 4 | num_updates 44316 | best_loss 7.59
2022-03-15 06:17:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 44316 updates
2022-03-15 06:17:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 06:17:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt
2022-03-15 06:17:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.065_0.01_0.925_#1/checkpoint_last.pt (epoch 431 @ 44316 updates, score 9.994) (writing took 0.9786935159936547 seconds)
2022-03-15 06:17:46 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-15 06:17:46 | INFO | train | epoch 431 | loss 3.548 | ppl 11.7 | wps 40225.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 44316 | lr 0.000150217 | gnorm 1.108 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 72166
KL Stats: Epoch 431 Divergences: Uniform: 5.499603815138362 Unigram: 5.900748384959034
2022-03-15 06:17:46 | INFO | fairseq.trainer | begin training epoch 432
2022-03-15 06:17:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:19:59 | INFO | train_inner | epoch 432:     84 / 103 loss=3.545, ppl=11.67, wps=40207.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=44400, lr=0.000150075, gnorm=1.12, loss_scale=8, train_wall=153, gb_free=20.8, wall=72299
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 496, in train_step
    optimizer.backward(loss)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/optim/fp16_optimizer.py", line 105, in backward
    loss.backward()
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt
