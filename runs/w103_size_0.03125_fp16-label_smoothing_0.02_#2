Sender: LSF System <lsfadmin@eu-g2-04>
Subject: Job 207345739: <w103_size_0.03125_fp16_label_smoothing_0.02_#2> in cluster <euler> Done

Job <w103_size_0.03125_fp16_label_smoothing_0.02_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 13:01:34 2022
Job was executed on host(s) <eu-g2-04>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sun Mar  6 13:02:19 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 13:02:19 2022
Terminated at Tue Mar  8 03:57:08 2022
Results reported at Tue Mar  8 03:57:08 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.02 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575622 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   147962.30 sec.
    Max Memory :                                 5828 MB
    Average Memory :                             3571.47 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14172.00 MB
    Max Swap :                                   14 MB
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   140089 sec.
    Turnaround time :                            140134 sec.

The output (if any) follows:

2022-03-06 13:02:25 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575622, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575622, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.02, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 13:02:25 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-06 13:02:26 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-06 13:02:26 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 13:02:26 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 13:02:26 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-06 13:02:26 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-06 13:02:26 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 13:02:26 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-06 13:02:30 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 13:02:30 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 13:02:30 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-03-06 13:02:30 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 13:02:30 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 13:02:30 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 13:02:30 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 13:02:30 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 13:02:30 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 13:02:30 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-06 13:02:30 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 13:02:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:02:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 13:02:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:02:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 13:02:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 13:04:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-06 13:04:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:05:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.349 | nll_loss 15.307 | ppl 40551.4 | wps 38383.2 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-06 13:05:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-06 13:05:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:05:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:05:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.349) (writing took 4.297794062644243 seconds)
2022-03-06 13:05:09 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 13:05:09 | INFO | train | epoch 001 | loss 16.522 | nll_loss 16.505 | ppl 92999.8 | wps 21215.7 | ups 0.33 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 5.142 | loss_scale 4 | train_wall 136 | gb_free 8.8 | wall 159
2022-03-06 13:05:09 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 13:05:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:07:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:07:31 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.896 | nll_loss 13.825 | ppl 14510.7 | wps 38515.5 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 13.896
2022-03-06 13:07:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-06 13:07:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:07:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:07:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 2 @ 93 updates, score 13.896) (writing took 4.219401801005006 seconds)
2022-03-06 13:07:35 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 13:07:35 | INFO | train | epoch 002 | loss 14.646 | nll_loss 14.591 | ppl 24679.5 | wps 21749.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.21 | loss_scale 4 | train_wall 123 | gb_free 8.8 | wall 305
2022-03-06 13:07:35 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 13:07:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:07:54 | INFO | train_inner | epoch 003:      7 / 49 loss=15.423, nll_loss=15.384, ppl=42757.2, wps=21620.9, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.451, loss_scale=4, train_wall=277, gb_free=8.8, wall=325
2022-03-06 13:09:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:09:55 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.237 | nll_loss 13.153 | ppl 9105.63 | wps 38762 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.237
2022-03-06 13:09:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-06 13:09:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:09:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:10:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.237) (writing took 4.1519455797970295 seconds)
2022-03-06 13:10:00 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 13:10:00 | INFO | train | epoch 003 | loss 13.706 | nll_loss 13.632 | ppl 12697.9 | wps 21937.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.406 | loss_scale 4 | train_wall 122 | gb_free 8.8 | wall 450
2022-03-06 13:10:00 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 13:10:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:12:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:12:21 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.422 | nll_loss 12.319 | ppl 5110.99 | wps 38660 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.422
2022-03-06 13:12:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-06 13:12:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:12:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:12:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.422) (writing took 5.099892487749457 seconds)
2022-03-06 13:12:26 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 13:12:26 | INFO | train | epoch 004 | loss 12.968 | nll_loss 12.879 | ppl 7533.58 | wps 21751.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.23 | loss_scale 8 | train_wall 123 | gb_free 8.8 | wall 596
2022-03-06 13:12:26 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 13:12:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:12:51 | INFO | train_inner | epoch 005:      9 / 49 loss=13.21, nll_loss=13.126, ppl=8938.91, wps=21873.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.283, loss_scale=8, train_wall=250, gb_free=8.8, wall=621
2022-03-06 13:14:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:14:46 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.63 | nll_loss 11.508 | ppl 2912.35 | wps 38978.5 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 11.63
2022-03-06 13:14:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-06 13:14:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:14:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:20:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 5 @ 240 updates, score 11.63) (writing took 321.0127524342388 seconds)
2022-03-06 13:20:07 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 13:20:07 | INFO | train | epoch 005 | loss 12.106 | nll_loss 11.996 | ppl 4085.04 | wps 6895.2 | ups 0.11 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 0.981 | loss_scale 8 | train_wall 122 | gb_free 8.8 | wall 1057
2022-03-06 13:20:07 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 13:20:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:22:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:22:27 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.991 | nll_loss 10.849 | ppl 1844.07 | wps 38286.7 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 10.991
2022-03-06 13:22:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-06 13:22:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:22:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:22:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 6 @ 289 updates, score 10.991) (writing took 5.3436170388013124 seconds)
2022-03-06 13:22:32 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 13:22:32 | INFO | train | epoch 006 | loss 11.35 | nll_loss 11.22 | ppl 2384.98 | wps 21795.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.766 | loss_scale 16 | train_wall 122 | gb_free 8.8 | wall 1203
2022-03-06 13:22:32 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 13:22:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:23:03 | INFO | train_inner | epoch 007:     11 / 49 loss=11.577, nll_loss=11.453, ppl=2802.91, wps=10592.8, ups=0.16, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.833, loss_scale=16, train_wall=249, gb_free=8.8, wall=1234
2022-03-06 13:24:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:24:54 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.571 | nll_loss 10.412 | ppl 1362.01 | wps 37479.5 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 10.571
2022-03-06 13:24:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-06 13:24:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:24:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:24:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 7 @ 338 updates, score 10.571) (writing took 5.512246515601873 seconds)
2022-03-06 13:24:59 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 13:24:59 | INFO | train | epoch 007 | loss 10.778 | nll_loss 10.628 | ppl 1582.57 | wps 21611.9 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.601 | loss_scale 16 | train_wall 123 | gb_free 8.8 | wall 1350
2022-03-06 13:24:59 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 13:24:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:27:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:27:22 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.306 | nll_loss 10.132 | ppl 1122.03 | wps 38138.7 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.306
2022-03-06 13:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-06 13:27:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:27:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:27:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.306) (writing took 5.171989519149065 seconds)
2022-03-06 13:27:27 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 13:27:27 | INFO | train | epoch 008 | loss 10.413 | nll_loss 10.247 | ppl 1215.1 | wps 21573.5 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.506 | loss_scale 16 | train_wall 123 | gb_free 8.8 | wall 1497
2022-03-06 13:27:27 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 13:27:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:28:03 | INFO | train_inner | epoch 009:     13 / 49 loss=10.51, nll_loss=10.349, ppl=1303.98, wps=21633.9, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.524, loss_scale=16, train_wall=251, gb_free=8.8, wall=1534
2022-03-06 13:29:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:29:48 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.125 | nll_loss 9.94 | ppl 982.33 | wps 38863.4 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.125
2022-03-06 13:29:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-06 13:29:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:29:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:33:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.125) (writing took 202.08051315508783 seconds)
2022-03-06 13:33:10 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 13:33:10 | INFO | train | epoch 009 | loss 10.175 | nll_loss 9.996 | ppl 1021.45 | wps 9247.7 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.494 | loss_scale 32 | train_wall 123 | gb_free 8.8 | wall 1841
2022-03-06 13:33:10 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 13:33:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:35:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:35:31 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.971 | nll_loss 9.779 | ppl 878.63 | wps 38203.5 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 9.971
2022-03-06 13:35:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-06 13:35:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:35:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:35:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 10 @ 485 updates, score 9.971) (writing took 4.460884230211377 seconds)
2022-03-06 13:35:35 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 13:35:35 | INFO | train | epoch 010 | loss 9.988 | nll_loss 9.8 | ppl 891.33 | wps 21939.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.517 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 1986
2022-03-06 13:35:35 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 13:35:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:36:17 | INFO | train_inner | epoch 011:     15 / 49 loss=10.026, nll_loss=9.84, ppl=916.67, wps=13131.2, ups=0.2, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.518, loss_scale=32, train_wall=250, gb_free=8.8, wall=2028
2022-03-06 13:37:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:37:56 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.82 | nll_loss 9.622 | ppl 787.77 | wps 38616.6 | wpb 510.9 | bsz 1 | num_updates 534 | best_loss 9.82
2022-03-06 13:37:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 534 updates
2022-03-06 13:37:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:37:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:38:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 11 @ 534 updates, score 9.82) (writing took 4.67912675999105 seconds)
2022-03-06 13:38:01 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 13:38:01 | INFO | train | epoch 011 | loss 9.816 | nll_loss 9.621 | ppl 787.62 | wps 21848.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 534 | lr 6.68367e-05 | gnorm 0.576 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 2131
2022-03-06 13:38:01 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 13:38:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:38:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:40:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:40:20 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.697 | nll_loss 9.493 | ppl 720.74 | wps 38363.3 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 9.697
2022-03-06 13:40:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-06 13:40:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:40:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:40:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 12 @ 582 updates, score 9.697) (writing took 6.5436868872493505 seconds)
2022-03-06 13:40:27 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 13:40:27 | INFO | train | epoch 012 | loss 9.653 | nll_loss 9.452 | ppl 700.44 | wps 21291.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.669 | loss_scale 32 | train_wall 121 | gb_free 8.8 | wall 2277
2022-03-06 13:40:27 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 13:40:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:41:17 | INFO | train_inner | epoch 013:     18 / 49 loss=9.68, nll_loss=9.48, ppl=714.23, wps=21662.5, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.649, loss_scale=32, train_wall=250, gb_free=8.8, wall=2327
2022-03-06 13:42:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:42:46 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.581 | nll_loss 9.374 | ppl 663.39 | wps 38671 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 9.581
2022-03-06 13:42:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-06 13:42:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:42:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:42:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 13 @ 631 updates, score 9.581) (writing took 5.040127120912075 seconds)
2022-03-06 13:42:51 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 13:42:51 | INFO | train | epoch 013 | loss 9.503 | nll_loss 9.296 | ppl 628.8 | wps 22002.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.69 | loss_scale 32 | train_wall 121 | gb_free 8.8 | wall 2422
2022-03-06 13:42:51 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 13:42:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:44:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:45:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:45:11 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.47 | nll_loss 9.259 | ppl 612.81 | wps 39019 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 9.47
2022-03-06 13:45:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-06 13:45:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:45:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:45:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 14 @ 679 updates, score 9.47) (writing took 5.12999065220356 seconds)
2022-03-06 13:45:16 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 13:45:16 | INFO | train | epoch 014 | loss 9.358 | nll_loss 9.147 | ppl 566.94 | wps 21466.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.741 | loss_scale 32 | train_wall 121 | gb_free 8.8 | wall 2567
2022-03-06 13:45:16 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 13:45:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:46:14 | INFO | train_inner | epoch 015:     21 / 49 loss=9.373, nll_loss=9.163, ppl=573.12, wps=21792.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.743, loss_scale=32, train_wall=250, gb_free=8.8, wall=2625
2022-03-06 13:47:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:47:36 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.357 | nll_loss 9.142 | ppl 565.08 | wps 38155.3 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.357
2022-03-06 13:47:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-06 13:47:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:47:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:47:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.357) (writing took 4.596693320199847 seconds)
2022-03-06 13:47:41 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 13:47:41 | INFO | train | epoch 015 | loss 9.218 | nll_loss 9.002 | ppl 512.82 | wps 22038.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.802 | loss_scale 32 | train_wall 121 | gb_free 8.8 | wall 2711
2022-03-06 13:47:41 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 13:47:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:49:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:50:00 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.252 | nll_loss 9.032 | ppl 523.41 | wps 38512.4 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 9.252
2022-03-06 13:50:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-06 13:50:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:50:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:50:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 16 @ 777 updates, score 9.252) (writing took 5.103278916329145 seconds)
2022-03-06 13:50:05 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 13:50:05 | INFO | train | epoch 016 | loss 9.081 | nll_loss 8.86 | ppl 464.79 | wps 21946.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.838 | loss_scale 32 | train_wall 121 | gb_free 8.8 | wall 2856
2022-03-06 13:50:05 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 13:50:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:51:10 | INFO | train_inner | epoch 017:     23 / 49 loss=9.088, nll_loss=8.867, ppl=466.85, wps=21930.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.812, loss_scale=32, train_wall=249, gb_free=8.8, wall=2921
2022-03-06 13:51:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:52:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:52:26 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.155 | nll_loss 8.93 | ppl 487.78 | wps 38777.7 | wpb 510.9 | bsz 1 | num_updates 825 | best_loss 9.155
2022-03-06 13:52:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 825 updates
2022-03-06 13:52:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:52:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:52:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 17 @ 825 updates, score 9.155) (writing took 4.407946953549981 seconds)
2022-03-06 13:52:30 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 13:52:30 | INFO | train | epoch 017 | loss 8.949 | nll_loss 8.723 | ppl 422.62 | wps 21460.9 | ups 0.33 | wpb 64853.3 | bsz 126.7 | num_updates 825 | lr 0.000103204 | gnorm 0.858 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 3001
2022-03-06 13:52:30 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 13:52:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:54:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:54:50 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.062 | nll_loss 8.835 | ppl 456.63 | wps 38898.4 | wpb 510.9 | bsz 1 | num_updates 874 | best_loss 9.062
2022-03-06 13:54:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 874 updates
2022-03-06 13:54:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:54:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:54:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 18 @ 874 updates, score 9.062) (writing took 4.33012879639864 seconds)
2022-03-06 13:54:55 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 13:54:55 | INFO | train | epoch 018 | loss 8.822 | nll_loss 8.592 | ppl 385.83 | wps 22018.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 874 | lr 0.000109328 | gnorm 0.906 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 3145
2022-03-06 13:54:55 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 13:54:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:56:07 | INFO | train_inner | epoch 019:     26 / 49 loss=8.821, nll_loss=8.591, ppl=385.55, wps=21860, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.924, loss_scale=32, train_wall=250, gb_free=8.8, wall=3217
2022-03-06 13:57:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:57:15 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.975 | nll_loss 8.744 | ppl 428.7 | wps 39164.3 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 8.975
2022-03-06 13:57:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-06 13:57:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:57:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:57:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 19 @ 923 updates, score 8.975) (writing took 4.76871432736516 seconds)
2022-03-06 13:57:20 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 13:57:20 | INFO | train | epoch 019 | loss 8.701 | nll_loss 8.466 | ppl 353.68 | wps 21921.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.976 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 3290
2022-03-06 13:57:20 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 13:57:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:57:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:59:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:59:40 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.907 | nll_loss 8.674 | ppl 408.46 | wps 38817.8 | wpb 510.9 | bsz 1 | num_updates 971 | best_loss 8.907
2022-03-06 13:59:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 971 updates
2022-03-06 13:59:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:59:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:07:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 20 @ 971 updates, score 8.907) (writing took 498.11386303417385 seconds)
2022-03-06 14:07:58 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 14:07:58 | INFO | train | epoch 020 | loss 8.582 | nll_loss 8.343 | ppl 324.67 | wps 4876.4 | ups 0.08 | wpb 64844.1 | bsz 126.7 | num_updates 971 | lr 0.000121451 | gnorm 0.918 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 3928
2022-03-06 14:07:58 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 14:07:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:09:17 | INFO | train_inner | epoch 021:     29 / 49 loss=8.575, nll_loss=8.336, ppl=323.09, wps=8213.5, ups=0.13, wpb=64876.2, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.932, loss_scale=32, train_wall=250, gb_free=8.8, wall=4007
2022-03-06 14:10:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:10:15 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.848 | nll_loss 8.609 | ppl 390.4 | wps 40087.3 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 8.848
2022-03-06 14:10:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-06 14:10:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:10:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:10:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 21 @ 1020 updates, score 8.848) (writing took 4.375687824562192 seconds)
2022-03-06 14:10:20 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 14:10:20 | INFO | train | epoch 021 | loss 8.469 | nll_loss 8.226 | ppl 299.36 | wps 22432.1 | ups 0.35 | wpb 64858.2 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.926 | loss_scale 32 | train_wall 119 | gb_free 8.8 | wall 4070
2022-03-06 14:10:20 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 14:10:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:12:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:12:37 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.782 | nll_loss 8.541 | ppl 372.44 | wps 39772.1 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 8.782
2022-03-06 14:12:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-06 14:12:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:12:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:21:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 22 @ 1069 updates, score 8.782) (writing took 524.8900194466114 seconds)
2022-03-06 14:21:22 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 14:21:22 | INFO | train | epoch 022 | loss 8.359 | nll_loss 8.112 | ppl 276.57 | wps 4798.8 | ups 0.07 | wpb 64858.2 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.951 | loss_scale 64 | train_wall 119 | gb_free 8.8 | wall 4732
2022-03-06 14:21:22 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 14:21:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:21:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:22:52 | INFO | train_inner | epoch 023:     32 / 49 loss=8.346, nll_loss=8.098, ppl=273.97, wps=7960.7, ups=0.12, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.941, loss_scale=32, train_wall=248, gb_free=8.8, wall=4822
2022-03-06 14:23:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:23:43 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.743 | nll_loss 8.498 | ppl 361.55 | wps 38780.6 | wpb 510.9 | bsz 1 | num_updates 1117 | best_loss 8.743
2022-03-06 14:23:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1117 updates
2022-03-06 14:23:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:23:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:25:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 23 @ 1117 updates, score 8.743) (writing took 82.71879446320236 seconds)
2022-03-06 14:25:06 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 14:25:06 | INFO | train | epoch 023 | loss 8.254 | nll_loss 8.003 | ppl 256.6 | wps 13883.2 | ups 0.21 | wpb 64844.1 | bsz 126.7 | num_updates 1117 | lr 0.000139697 | gnorm 0.96 | loss_scale 32 | train_wall 123 | gb_free 8.8 | wall 4956
2022-03-06 14:25:06 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 14:25:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:27:27 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.691 | nll_loss 8.443 | ppl 348.11 | wps 39020.5 | wpb 510.9 | bsz 1 | num_updates 1166 | best_loss 8.691
2022-03-06 14:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1166 updates
2022-03-06 14:27:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:27:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:27:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 24 @ 1166 updates, score 8.691) (writing took 4.481215616688132 seconds)
2022-03-06 14:27:32 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 14:27:32 | INFO | train | epoch 024 | loss 8.148 | nll_loss 7.893 | ppl 237.68 | wps 21828.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1166 | lr 0.000145821 | gnorm 0.958 | loss_scale 32 | train_wall 123 | gb_free 8.8 | wall 5102
2022-03-06 14:27:32 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 14:27:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:29:07 | INFO | train_inner | epoch 025:     34 / 49 loss=8.13, nll_loss=7.875, ppl=234.69, wps=17301.4, ups=0.27, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.959, loss_scale=64, train_wall=250, gb_free=8.8, wall=5197
2022-03-06 14:29:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:29:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:29:53 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.638 | nll_loss 8.388 | ppl 334.95 | wps 39161 | wpb 510.9 | bsz 1 | num_updates 1214 | best_loss 8.638
2022-03-06 14:29:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1214 updates
2022-03-06 14:29:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:29:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:38:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 25 @ 1214 updates, score 8.638) (writing took 498.7885969467461 seconds)
2022-03-06 14:38:12 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 14:38:12 | INFO | train | epoch 025 | loss 8.046 | nll_loss 7.787 | ppl 220.88 | wps 4864.8 | ups 0.08 | wpb 64844.1 | bsz 126.7 | num_updates 1214 | lr 0.00015182 | gnorm 0.944 | loss_scale 32 | train_wall 123 | gb_free 8.8 | wall 5742
2022-03-06 14:38:12 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 14:38:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:40:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:40:32 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.602 | nll_loss 8.349 | ppl 326.04 | wps 38549.8 | wpb 510.9 | bsz 1 | num_updates 1263 | best_loss 8.602
2022-03-06 14:40:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1263 updates
2022-03-06 14:40:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:40:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:40:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 26 @ 1263 updates, score 8.602) (writing took 5.264600649476051 seconds)
2022-03-06 14:40:38 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 14:40:38 | INFO | train | epoch 026 | loss 7.945 | nll_loss 7.683 | ppl 205.49 | wps 21777 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1263 | lr 0.000157943 | gnorm 1.016 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 5888
2022-03-06 14:40:38 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 14:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:42:20 | INFO | train_inner | epoch 027:     37 / 49 loss=7.921, nll_loss=7.658, ppl=202, wps=8174.6, ups=0.13, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=0.997, loss_scale=32, train_wall=252, gb_free=8.8, wall=5990
2022-03-06 14:42:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:42:58 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.552 | nll_loss 8.298 | ppl 314.83 | wps 38356 | wpb 510.9 | bsz 1 | num_updates 1312 | best_loss 8.552
2022-03-06 14:42:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1312 updates
2022-03-06 14:42:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:43:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:43:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 27 @ 1312 updates, score 8.552) (writing took 5.231814472004771 seconds)
2022-03-06 14:43:03 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 14:43:03 | INFO | train | epoch 027 | loss 7.842 | nll_loss 7.576 | ppl 190.78 | wps 21829.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1312 | lr 0.000164067 | gnorm 0.979 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 6033
2022-03-06 14:43:03 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 14:43:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:45:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:45:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:45:25 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.506 | nll_loss 8.248 | ppl 304.01 | wps 38909.4 | wpb 510.9 | bsz 1 | num_updates 1360 | best_loss 8.506
2022-03-06 14:45:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1360 updates
2022-03-06 14:45:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:45:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:54:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 28 @ 1360 updates, score 8.506) (writing took 517.4978320635855 seconds)
2022-03-06 14:54:02 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 14:54:02 | INFO | train | epoch 028 | loss 7.738 | nll_loss 7.469 | ppl 177.17 | wps 4723.1 | ups 0.07 | wpb 64844.1 | bsz 126.7 | num_updates 1360 | lr 0.000170066 | gnorm 0.999 | loss_scale 32 | train_wall 123 | gb_free 8.8 | wall 6692
2022-03-06 14:54:02 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 14:54:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:55:53 | INFO | train_inner | epoch 029:     40 / 49 loss=7.71, nll_loss=7.439, ppl=173.53, wps=7981, ups=0.12, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=1, loss_scale=32, train_wall=252, gb_free=8.8, wall=6803
2022-03-06 14:56:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:56:22 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.469 | nll_loss 8.204 | ppl 294.91 | wps 38748.7 | wpb 510.9 | bsz 1 | num_updates 1409 | best_loss 8.469
2022-03-06 14:56:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1409 updates
2022-03-06 14:56:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:56:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:04:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 29 @ 1409 updates, score 8.469) (writing took 505.1020501218736 seconds)
2022-03-06 15:04:47 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 15:04:47 | INFO | train | epoch 029 | loss 7.64 | nll_loss 7.367 | ppl 165.06 | wps 4924.7 | ups 0.08 | wpb 64858.2 | bsz 126.7 | num_updates 1409 | lr 0.00017619 | gnorm 1.002 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 7338
2022-03-06 15:04:47 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 15:04:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:07:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:07:08 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.441 | nll_loss 8.172 | ppl 288.43 | wps 38613.5 | wpb 510.9 | bsz 1 | num_updates 1458 | best_loss 8.441
2022-03-06 15:07:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1458 updates
2022-03-06 15:07:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:07:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 30 @ 1458 updates, score 8.441) (writing took 4.490215208381414 seconds)
2022-03-06 15:07:12 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 15:07:12 | INFO | train | epoch 030 | loss 7.538 | nll_loss 7.261 | ppl 153.41 | wps 21916.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1458 | lr 0.000182314 | gnorm 1.023 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 7483
2022-03-06 15:07:12 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 15:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:09:09 | INFO | train_inner | epoch 031:     42 / 49 loss=7.501, nll_loss=7.224, ppl=149.47, wps=8149.2, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=1.013, loss_scale=64, train_wall=249, gb_free=8.8, wall=7599
2022-03-06 15:09:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:09:33 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.409 | nll_loss 8.142 | ppl 282.4 | wps 38932.7 | wpb 510.9 | bsz 1 | num_updates 1507 | best_loss 8.409
2022-03-06 15:09:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1507 updates
2022-03-06 15:09:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:09:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:09:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 31 @ 1507 updates, score 8.409) (writing took 4.457904778420925 seconds)
2022-03-06 15:09:37 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 15:09:37 | INFO | train | epoch 031 | loss 7.434 | nll_loss 7.154 | ppl 142.45 | wps 21936.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1507 | lr 0.000188437 | gnorm 1.016 | loss_scale 64 | train_wall 122 | gb_free 8.8 | wall 7628
2022-03-06 15:09:37 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 15:09:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:10:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:11:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:11:57 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.381 | nll_loss 8.112 | ppl 276.69 | wps 39210.3 | wpb 510.9 | bsz 1 | num_updates 1555 | best_loss 8.381
2022-03-06 15:11:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1555 updates
2022-03-06 15:11:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:12:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:12:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 32 @ 1555 updates, score 8.381) (writing took 4.972519524395466 seconds)
2022-03-06 15:12:02 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 15:12:02 | INFO | train | epoch 032 | loss 7.335 | nll_loss 7.051 | ppl 132.62 | wps 21479 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1555 | lr 0.000194436 | gnorm 1.027 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 7773
2022-03-06 15:12:02 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 15:12:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:14:08 | INFO | train_inner | epoch 033:     45 / 49 loss=7.295, nll_loss=7.01, ppl=128.92, wps=21723.2, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=1.021, loss_scale=32, train_wall=252, gb_free=8.8, wall=7898
2022-03-06 15:14:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:14:23 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.367 | nll_loss 8.096 | ppl 273.64 | wps 38716.2 | wpb 510.9 | bsz 1 | num_updates 1604 | best_loss 8.367
2022-03-06 15:14:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1604 updates
2022-03-06 15:14:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:14:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:14:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 33 @ 1604 updates, score 8.367) (writing took 5.049819493666291 seconds)
2022-03-06 15:14:28 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 15:14:28 | INFO | train | epoch 033 | loss 7.234 | nll_loss 6.947 | ppl 123.37 | wps 21766 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1604 | lr 0.00020056 | gnorm 1.004 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 7919
2022-03-06 15:14:28 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 15:14:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:16:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:16:49 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.352 | nll_loss 8.082 | ppl 270.91 | wps 37895.1 | wpb 510.9 | bsz 1 | num_updates 1653 | best_loss 8.352
2022-03-06 15:16:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1653 updates
2022-03-06 15:16:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:16:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:16:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 34 @ 1653 updates, score 8.352) (writing took 4.294892743229866 seconds)
2022-03-06 15:16:54 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 15:16:54 | INFO | train | epoch 034 | loss 7.134 | nll_loss 6.843 | ppl 114.78 | wps 21845.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1653 | lr 0.000206684 | gnorm 1.022 | loss_scale 64 | train_wall 123 | gb_free 8.8 | wall 8064
2022-03-06 15:16:54 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 15:16:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:16:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:19:06 | INFO | train_inner | epoch 035:     48 / 49 loss=7.09, nll_loss=6.798, ppl=111.25, wps=21747.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=1.043, loss_scale=32, train_wall=251, gb_free=8.8, wall=8196
2022-03-06 15:19:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:19:13 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.344 | nll_loss 8.069 | ppl 268.56 | wps 39383 | wpb 510.9 | bsz 1 | num_updates 1701 | best_loss 8.344
2022-03-06 15:19:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1701 updates
2022-03-06 15:19:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:19:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:19:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 35 @ 1701 updates, score 8.344) (writing took 4.502610735595226 seconds)
2022-03-06 15:19:18 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 15:19:18 | INFO | train | epoch 035 | loss 7.034 | nll_loss 6.74 | ppl 106.88 | wps 21644.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1701 | lr 0.000212682 | gnorm 1.069 | loss_scale 32 | train_wall 121 | gb_free 8.8 | wall 8208
2022-03-06 15:19:18 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 15:19:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:21:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:21:35 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.34 | nll_loss 8.066 | ppl 267.93 | wps 39709.3 | wpb 510.9 | bsz 1 | num_updates 1750 | best_loss 8.34
2022-03-06 15:21:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1750 updates
2022-03-06 15:21:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:21:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:21:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 36 @ 1750 updates, score 8.34) (writing took 4.457789083942771 seconds)
2022-03-06 15:21:40 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 15:21:40 | INFO | train | epoch 036 | loss 6.937 | nll_loss 6.639 | ppl 99.67 | wps 22334.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1750 | lr 0.000218806 | gnorm 1.073 | loss_scale 32 | train_wall 120 | gb_free 8.8 | wall 8350
2022-03-06 15:21:40 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 15:21:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:23:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:23:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:23:58 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.318 | nll_loss 8.04 | ppl 263.13 | wps 40059.3 | wpb 510.9 | bsz 1 | num_updates 1798 | best_loss 8.318
2022-03-06 15:23:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1798 updates
2022-03-06 15:23:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:24:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 15:24:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 37 @ 1798 updates, score 8.318) (writing took 4.367945780977607 seconds)
2022-03-06 15:24:02 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 15:24:02 | INFO | train | epoch 037 | loss 6.839 | nll_loss 6.537 | ppl 92.86 | wps 21847.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 1798 | lr 0.000224805 | gnorm 1.024 | loss_scale 32 | train_wall 120 | gb_free 8.8 | wall 8493
2022-03-06 15:24:02 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 15:24:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:24:08 | INFO | train_inner | epoch 038:      2 / 49 loss=6.886, nll_loss=6.587, ppl=96.11, wps=21386.7, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=1.048, loss_scale=32, train_wall=246, gb_free=8.8, wall=8498
2022-03-06 15:26:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:26:20 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.34 | nll_loss 8.062 | ppl 267.23 | wps 39502.9 | wpb 510.9 | bsz 1 | num_updates 1847 | best_loss 8.318
2022-03-06 15:26:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1847 updates
2022-03-06 15:26:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:26:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:26:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 38 @ 1847 updates, score 8.34) (writing took 2.5810670480132103 seconds)
2022-03-06 15:26:23 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 15:26:23 | INFO | train | epoch 038 | loss 6.746 | nll_loss 6.441 | ppl 86.91 | wps 22603.7 | ups 0.35 | wpb 64858.2 | bsz 126.7 | num_updates 1847 | lr 0.000230929 | gnorm 1.105 | loss_scale 32 | train_wall 120 | gb_free 8.8 | wall 8633
2022-03-06 15:26:23 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 15:26:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:28:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:28:41 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.341 | nll_loss 8.065 | ppl 267.76 | wps 38894.1 | wpb 510.9 | bsz 1 | num_updates 1896 | best_loss 8.318
2022-03-06 15:28:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1896 updates
2022-03-06 15:28:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:28:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:28:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 39 @ 1896 updates, score 8.341) (writing took 2.4842508248984814 seconds)
2022-03-06 15:28:43 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 15:28:43 | INFO | train | epoch 039 | loss 6.648 | nll_loss 6.339 | ppl 80.95 | wps 22653.6 | ups 0.35 | wpb 64858.2 | bsz 126.7 | num_updates 1896 | lr 0.000237053 | gnorm 1.095 | loss_scale 32 | train_wall 120 | gb_free 8.8 | wall 8773
2022-03-06 15:28:43 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 15:28:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:28:55 | INFO | train_inner | epoch 040:      4 / 49 loss=6.689, nll_loss=6.382, ppl=83.41, wps=22626.2, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=1.105, loss_scale=32, train_wall=245, gb_free=8.8, wall=8785
2022-03-06 15:29:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:30:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:31:03 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.343 | nll_loss 8.061 | ppl 267.02 | wps 38564.6 | wpb 510.9 | bsz 1 | num_updates 1944 | best_loss 8.318
2022-03-06 15:31:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1944 updates
2022-03-06 15:31:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:31:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:31:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 40 @ 1944 updates, score 8.343) (writing took 2.5610204711556435 seconds)
2022-03-06 15:31:06 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 15:31:06 | INFO | train | epoch 040 | loss 6.551 | nll_loss 6.239 | ppl 75.51 | wps 21789 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 1944 | lr 0.000243051 | gnorm 1.101 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 8916
2022-03-06 15:31:06 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 15:31:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:33:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:33:26 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.32 | nll_loss 8.033 | ppl 261.93 | wps 39260.1 | wpb 510.9 | bsz 1 | num_updates 1993 | best_loss 8.318
2022-03-06 15:33:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1993 updates
2022-03-06 15:33:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:33:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:33:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 41 @ 1993 updates, score 8.32) (writing took 2.4633271638303995 seconds)
2022-03-06 15:33:28 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 15:33:28 | INFO | train | epoch 041 | loss 6.459 | nll_loss 6.143 | ppl 70.65 | wps 22308 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1993 | lr 0.000249175 | gnorm 1.093 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 9059
2022-03-06 15:33:28 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 15:33:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:33:48 | INFO | train_inner | epoch 042:      7 / 49 loss=6.493, nll_loss=6.178, ppl=72.41, wps=22101, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=1.096, loss_scale=32, train_wall=251, gb_free=8.8, wall=9078
2022-03-06 15:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:35:50 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.384 | nll_loss 8.105 | ppl 275.27 | wps 38732.7 | wpb 510.9 | bsz 1 | num_updates 2042 | best_loss 8.318
2022-03-06 15:35:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2042 updates
2022-03-06 15:35:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:35:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:35:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 42 @ 2042 updates, score 8.384) (writing took 2.4629290755838156 seconds)
2022-03-06 15:35:52 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 15:35:52 | INFO | train | epoch 042 | loss 6.366 | nll_loss 6.047 | ppl 66.12 | wps 22131.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2042 | lr 0.000255299 | gnorm 1.139 | loss_scale 32 | train_wall 123 | gb_free 8.8 | wall 9202
2022-03-06 15:35:52 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 15:35:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:36:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:38:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:38:13 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.409 | nll_loss 8.127 | ppl 279.47 | wps 38561.4 | wpb 510.9 | bsz 1 | num_updates 2090 | best_loss 8.318
2022-03-06 15:38:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2090 updates
2022-03-06 15:38:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:38:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:38:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 43 @ 2090 updates, score 8.409) (writing took 2.4029730055481195 seconds)
2022-03-06 15:38:16 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 15:38:16 | INFO | train | epoch 043 | loss 6.271 | nll_loss 5.948 | ppl 61.73 | wps 21675 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2090 | lr 0.000261298 | gnorm 1.14 | loss_scale 32 | train_wall 123 | gb_free 8.8 | wall 9346
2022-03-06 15:38:16 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 15:38:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:38:44 | INFO | train_inner | epoch 044:     10 / 49 loss=6.301, nll_loss=5.979, ppl=63.09, wps=21945.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.135, loss_scale=32, train_wall=253, gb_free=8.8, wall=9374
2022-03-06 15:40:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:40:37 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.44 | nll_loss 8.156 | ppl 285.3 | wps 38717.9 | wpb 510.9 | bsz 1 | num_updates 2139 | best_loss 8.318
2022-03-06 15:40:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2139 updates
2022-03-06 15:40:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:40:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:40:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 44 @ 2139 updates, score 8.44) (writing took 2.380650447681546 seconds)
2022-03-06 15:40:39 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 15:40:39 | INFO | train | epoch 044 | loss 6.181 | nll_loss 5.855 | ppl 57.87 | wps 22152.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2139 | lr 0.000267422 | gnorm 1.163 | loss_scale 32 | train_wall 123 | gb_free 8.8 | wall 9489
2022-03-06 15:40:39 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 15:40:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:42:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:42:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:43:00 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.471 | nll_loss 8.191 | ppl 292.23 | wps 38553 | wpb 510.9 | bsz 1 | num_updates 2187 | best_loss 8.318
2022-03-06 15:43:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2187 updates
2022-03-06 15:43:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:43:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:43:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 45 @ 2187 updates, score 8.471) (writing took 2.522228389978409 seconds)
2022-03-06 15:43:03 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 15:43:03 | INFO | train | epoch 045 | loss 6.087 | nll_loss 5.756 | ppl 54.06 | wps 21670.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2187 | lr 0.00027342 | gnorm 1.182 | loss_scale 32 | train_wall 123 | gb_free 8.8 | wall 9633
2022-03-06 15:43:03 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 15:43:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:43:39 | INFO | train_inner | epoch 046:     13 / 49 loss=6.111, nll_loss=5.782, ppl=55.02, wps=21966, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.186, loss_scale=32, train_wall=253, gb_free=8.8, wall=9669
2022-03-06 15:45:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:45:23 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.495 | nll_loss 8.207 | ppl 295.58 | wps 39254.6 | wpb 510.9 | bsz 1 | num_updates 2236 | best_loss 8.318
2022-03-06 15:45:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2236 updates
2022-03-06 15:45:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:45:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:45:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 46 @ 2236 updates, score 8.495) (writing took 2.448477467522025 seconds)
2022-03-06 15:45:25 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 15:45:25 | INFO | train | epoch 046 | loss 5.999 | nll_loss 5.665 | ppl 50.75 | wps 22295 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2236 | lr 0.000279544 | gnorm 1.209 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 9776
2022-03-06 15:45:25 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 15:45:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:47:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:47:46 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.501 | nll_loss 8.212 | ppl 296.52 | wps 39047.8 | wpb 510.9 | bsz 1 | num_updates 2285 | best_loss 8.318
2022-03-06 15:47:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2285 updates
2022-03-06 15:47:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:47:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:47:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 47 @ 2285 updates, score 8.501) (writing took 3.111295949667692 seconds)
2022-03-06 15:47:49 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 15:47:49 | INFO | train | epoch 047 | loss 5.906 | nll_loss 5.569 | ppl 47.48 | wps 22141.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2285 | lr 0.000285668 | gnorm 1.201 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 9919
2022-03-06 15:47:49 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 15:47:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:48:31 | INFO | train_inner | epoch 048:     15 / 49 loss=5.925, nll_loss=5.588, ppl=48.1, wps=22249.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.188, loss_scale=32, train_wall=249, gb_free=8.8, wall=9961
2022-03-06 15:48:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:50:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:50:09 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.538 | nll_loss 8.251 | ppl 304.67 | wps 38835.5 | wpb 510.9 | bsz 1 | num_updates 2333 | best_loss 8.318
2022-03-06 15:50:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2333 updates
2022-03-06 15:50:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:50:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:50:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 48 @ 2333 updates, score 8.538) (writing took 3.387674205005169 seconds)
2022-03-06 15:50:12 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 15:50:12 | INFO | train | epoch 048 | loss 5.812 | nll_loss 5.471 | ppl 44.35 | wps 21737.6 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 2333 | lr 0.000291667 | gnorm 1.178 | loss_scale 32 | train_wall 121 | gb_free 8.8 | wall 10062
2022-03-06 15:50:12 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 15:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:52:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:52:32 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.639 | nll_loss 8.353 | ppl 327.03 | wps 38360.4 | wpb 510.9 | bsz 1 | num_updates 2382 | best_loss 8.318
2022-03-06 15:52:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2382 updates
2022-03-06 15:52:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:52:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:52:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 49 @ 2382 updates, score 8.639) (writing took 3.106847496703267 seconds)
2022-03-06 15:52:35 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 15:52:35 | INFO | train | epoch 049 | loss 5.725 | nll_loss 5.381 | ppl 41.67 | wps 22154.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2382 | lr 0.00029779 | gnorm 1.231 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 10206
2022-03-06 15:52:35 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 15:52:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:53:26 | INFO | train_inner | epoch 050:     18 / 49 loss=5.738, nll_loss=5.394, ppl=42.04, wps=21949.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.233, loss_scale=32, train_wall=251, gb_free=8.8, wall=10256
2022-03-06 15:54:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:54:56 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.615 | nll_loss 8.329 | ppl 321.5 | wps 38094.7 | wpb 510.9 | bsz 1 | num_updates 2431 | best_loss 8.318
2022-03-06 15:54:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2431 updates
2022-03-06 15:54:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:55:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:55:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 50 @ 2431 updates, score 8.615) (writing took 3.350964430719614 seconds)
2022-03-06 15:55:00 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 15:55:00 | INFO | train | epoch 050 | loss 5.637 | nll_loss 5.289 | ppl 39.09 | wps 22013.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2431 | lr 0.000303914 | gnorm 1.292 | loss_scale 64 | train_wall 122 | gb_free 8.8 | wall 10350
2022-03-06 15:55:00 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 15:55:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:55:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:55:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:57:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:57:21 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 8.664 | nll_loss 8.377 | ppl 332.56 | wps 38793.6 | wpb 510.9 | bsz 1 | num_updates 2478 | best_loss 8.318
2022-03-06 15:57:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2478 updates
2022-03-06 15:57:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:57:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:57:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 51 @ 2478 updates, score 8.664) (writing took 3.2284026462584734 seconds)
2022-03-06 15:57:24 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 15:57:24 | INFO | train | epoch 051 | loss 5.548 | nll_loss 5.196 | ppl 36.66 | wps 21148.8 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 2478 | lr 0.000309788 | gnorm 1.328 | loss_scale 16 | train_wall 122 | gb_free 8.8 | wall 10494
2022-03-06 15:57:24 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 15:57:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:58:25 | INFO | train_inner | epoch 052:     22 / 49 loss=5.555, nll_loss=5.203, ppl=36.84, wps=21680.2, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.309, loss_scale=16, train_wall=254, gb_free=8.8, wall=10556
2022-03-06 15:59:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:59:45 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 8.694 | nll_loss 8.402 | ppl 338.32 | wps 38726.2 | wpb 510.9 | bsz 1 | num_updates 2527 | best_loss 8.318
2022-03-06 15:59:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2527 updates
2022-03-06 15:59:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:59:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:59:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 52 @ 2527 updates, score 8.694) (writing took 2.573562119156122 seconds)
2022-03-06 15:59:47 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 15:59:47 | INFO | train | epoch 052 | loss 5.456 | nll_loss 5.101 | ppl 34.31 | wps 22145.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2527 | lr 0.000315912 | gnorm 1.225 | loss_scale 16 | train_wall 122 | gb_free 8.8 | wall 10638
2022-03-06 15:59:47 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 15:59:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:02:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:02:08 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 8.682 | nll_loss 8.396 | ppl 336.86 | wps 38886.6 | wpb 510.9 | bsz 1 | num_updates 2576 | best_loss 8.318
2022-03-06 16:02:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2576 updates
2022-03-06 16:02:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:02:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:02:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 53 @ 2576 updates, score 8.682) (writing took 3.217789636924863 seconds)
2022-03-06 16:02:11 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 16:02:11 | INFO | train | epoch 053 | loss 5.373 | nll_loss 5.013 | ppl 32.3 | wps 22106.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2576 | lr 0.000322036 | gnorm 1.354 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 10781
2022-03-06 16:02:11 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 16:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:03:18 | INFO | train_inner | epoch 054:     24 / 49 loss=5.371, nll_loss=5.012, ppl=32.26, wps=22130.5, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.277, loss_scale=32, train_wall=250, gb_free=8.8, wall=10849
2022-03-06 16:04:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:04:32 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 8.804 | nll_loss 8.513 | ppl 365.4 | wps 38591.7 | wpb 510.9 | bsz 1 | num_updates 2625 | best_loss 8.318
2022-03-06 16:04:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2625 updates
2022-03-06 16:04:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:04:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:04:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 54 @ 2625 updates, score 8.804) (writing took 3.142878171056509 seconds)
2022-03-06 16:04:35 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 16:04:35 | INFO | train | epoch 054 | loss 5.28 | nll_loss 4.917 | ppl 30.21 | wps 22091.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2625 | lr 0.000328159 | gnorm 1.319 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 10925
2022-03-06 16:04:35 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 16:04:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:06:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:06:56 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 8.879 | nll_loss 8.592 | ppl 385.98 | wps 38800.5 | wpb 510.9 | bsz 1 | num_updates 2674 | best_loss 8.318
2022-03-06 16:06:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2674 updates
2022-03-06 16:06:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:06:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:06:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 55 @ 2674 updates, score 8.879) (writing took 2.816553032025695 seconds)
2022-03-06 16:06:59 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 16:06:59 | INFO | train | epoch 055 | loss 5.193 | nll_loss 4.827 | ppl 28.38 | wps 22140 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2674 | lr 0.000334283 | gnorm 1.34 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 11069
2022-03-06 16:06:59 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 16:06:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:08:11 | INFO | train_inner | epoch 056:     26 / 49 loss=5.193, nll_loss=4.827, ppl=28.38, wps=22170.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.334, loss_scale=64, train_wall=249, gb_free=8.8, wall=11141
2022-03-06 16:08:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:09:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:09:19 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 8.864 | nll_loss 8.569 | ppl 379.81 | wps 38780.3 | wpb 510.9 | bsz 1 | num_updates 2722 | best_loss 8.318
2022-03-06 16:09:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2722 updates
2022-03-06 16:09:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:09:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:09:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 56 @ 2722 updates, score 8.864) (writing took 2.908795092254877 seconds)
2022-03-06 16:09:22 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 16:09:22 | INFO | train | epoch 056 | loss 5.106 | nll_loss 4.735 | ppl 26.63 | wps 21707.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2722 | lr 0.000340282 | gnorm 1.341 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 11212
2022-03-06 16:09:22 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 16:09:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:11:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:11:44 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 8.944 | nll_loss 8.642 | ppl 399.49 | wps 38189.4 | wpb 510.9 | bsz 1 | num_updates 2771 | best_loss 8.318
2022-03-06 16:11:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2771 updates
2022-03-06 16:11:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:11:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:11:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 57 @ 2771 updates, score 8.944) (writing took 2.5511526446789503 seconds)
2022-03-06 16:11:46 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 16:11:46 | INFO | train | epoch 057 | loss 5.022 | nll_loss 4.648 | ppl 25.06 | wps 22057.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2771 | lr 0.000346406 | gnorm 1.401 | loss_scale 32 | train_wall 123 | gb_free 8.8 | wall 11356
2022-03-06 16:11:46 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 16:11:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:13:07 | INFO | train_inner | epoch 058:     29 / 49 loss=5.013, nll_loss=4.638, ppl=24.9, wps=21930.6, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.38, loss_scale=32, train_wall=252, gb_free=8.8, wall=11437
2022-03-06 16:14:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:14:07 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 8.967 | nll_loss 8.671 | ppl 407.69 | wps 39564.9 | wpb 510.9 | bsz 1 | num_updates 2820 | best_loss 8.318
2022-03-06 16:14:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2820 updates
2022-03-06 16:14:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:14:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:14:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 58 @ 2820 updates, score 8.967) (writing took 3.2740302812308073 seconds)
2022-03-06 16:14:10 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 16:14:10 | INFO | train | epoch 058 | loss 4.933 | nll_loss 4.555 | ppl 23.5 | wps 22081.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2820 | lr 0.00035253 | gnorm 1.307 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 11500
2022-03-06 16:14:10 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 16:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:14:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:16:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:16:30 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.03 | nll_loss 8.743 | ppl 428.48 | wps 38083.3 | wpb 510.9 | bsz 1 | num_updates 2868 | best_loss 8.318
2022-03-06 16:16:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2868 updates
2022-03-06 16:16:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:16:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:16:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 59 @ 2868 updates, score 9.03) (writing took 2.6936167180538177 seconds)
2022-03-06 16:16:33 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 16:16:33 | INFO | train | epoch 059 | loss 4.842 | nll_loss 4.461 | ppl 22.02 | wps 21735.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 2868 | lr 0.000358528 | gnorm 1.373 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 11643
2022-03-06 16:16:33 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 16:16:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:18:02 | INFO | train_inner | epoch 060:     32 / 49 loss=4.841, nll_loss=4.459, ppl=22, wps=21973.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.427, loss_scale=32, train_wall=252, gb_free=8.8, wall=11732
2022-03-06 16:18:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:18:54 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.132 | nll_loss 8.842 | ppl 458.76 | wps 38693 | wpb 510.9 | bsz 1 | num_updates 2917 | best_loss 8.318
2022-03-06 16:18:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2917 updates
2022-03-06 16:18:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:18:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:18:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 60 @ 2917 updates, score 9.132) (writing took 3.2394125144928694 seconds)
2022-03-06 16:18:57 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 16:18:57 | INFO | train | epoch 060 | loss 4.772 | nll_loss 4.387 | ppl 20.92 | wps 22134.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2917 | lr 0.000364652 | gnorm 1.46 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 11787
2022-03-06 16:18:57 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 16:18:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:21:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:21:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:21:18 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.169 | nll_loss 8.87 | ppl 467.99 | wps 37767.2 | wpb 510.9 | bsz 1 | num_updates 2965 | best_loss 8.318
2022-03-06 16:21:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2965 updates
2022-03-06 16:21:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:21:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:21:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 61 @ 2965 updates, score 9.169) (writing took 3.2605158053338528 seconds)
2022-03-06 16:21:21 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 16:21:21 | INFO | train | epoch 061 | loss 4.684 | nll_loss 4.295 | ppl 19.63 | wps 21554.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2965 | lr 0.000370651 | gnorm 1.506 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 11931
2022-03-06 16:21:21 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 16:21:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:22:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:23:02 | INFO | train_inner | epoch 062:     36 / 49 loss=4.661, nll_loss=4.271, ppl=19.31, wps=21623.5, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.428, loss_scale=16, train_wall=255, gb_free=8.8, wall=12032
2022-03-06 16:23:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:23:43 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.215 | nll_loss 8.915 | ppl 482.71 | wps 38709.2 | wpb 510.9 | bsz 1 | num_updates 3013 | best_loss 8.318
2022-03-06 16:23:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3013 updates
2022-03-06 16:23:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:23:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:23:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 62 @ 3013 updates, score 9.215) (writing took 3.2557802386581898 seconds)
2022-03-06 16:23:46 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 16:23:46 | INFO | train | epoch 062 | loss 4.593 | nll_loss 4.2 | ppl 18.38 | wps 21485.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3013 | lr 0.00037665 | gnorm 1.389 | loss_scale 16 | train_wall 123 | gb_free 8.8 | wall 12076
2022-03-06 16:23:46 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 16:23:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:26:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:26:07 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.223 | nll_loss 8.915 | ppl 482.8 | wps 38577.3 | wpb 510.9 | bsz 1 | num_updates 3062 | best_loss 8.318
2022-03-06 16:26:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3062 updates
2022-03-06 16:26:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:26:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:26:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 63 @ 3062 updates, score 9.223) (writing took 2.5044257678091526 seconds)
2022-03-06 16:26:09 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 16:26:09 | INFO | train | epoch 063 | loss 4.511 | nll_loss 4.114 | ppl 17.32 | wps 22187.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3062 | lr 0.000382773 | gnorm 1.407 | loss_scale 16 | train_wall 122 | gb_free 8.8 | wall 12220
2022-03-06 16:26:09 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 16:26:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:27:55 | INFO | train_inner | epoch 064:     38 / 49 loss=4.494, nll_loss=4.096, ppl=17.1, wps=22137.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.411, loss_scale=16, train_wall=250, gb_free=8.8, wall=12325
2022-03-06 16:28:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:28:30 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.261 | nll_loss 8.956 | ppl 496.72 | wps 38883.8 | wpb 510.9 | bsz 1 | num_updates 3111 | best_loss 8.318
2022-03-06 16:28:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3111 updates
2022-03-06 16:28:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:28:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:28:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 64 @ 3111 updates, score 9.261) (writing took 3.346136413514614 seconds)
2022-03-06 16:28:33 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 16:28:33 | INFO | train | epoch 064 | loss 4.43 | nll_loss 4.03 | ppl 16.33 | wps 22088.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3111 | lr 0.000388897 | gnorm 1.453 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 12363
2022-03-06 16:28:33 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 16:28:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:28:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:30:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:30:54 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.342 | nll_loss 9.044 | ppl 527.93 | wps 38992.2 | wpb 510.9 | bsz 1 | num_updates 3159 | best_loss 8.318
2022-03-06 16:30:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3159 updates
2022-03-06 16:30:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:30:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:30:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 65 @ 3159 updates, score 9.342) (writing took 3.2615316100418568 seconds)
2022-03-06 16:30:57 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 16:30:57 | INFO | train | epoch 065 | loss 4.346 | nll_loss 3.942 | ppl 15.37 | wps 21565.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3159 | lr 0.000394896 | gnorm 1.43 | loss_scale 16 | train_wall 123 | gb_free 8.8 | wall 12508
2022-03-06 16:30:57 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 16:30:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:32:51 | INFO | train_inner | epoch 066:     41 / 49 loss=4.329, nll_loss=3.923, ppl=15.17, wps=21902.1, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.508, loss_scale=16, train_wall=252, gb_free=8.8, wall=12622
2022-03-06 16:33:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:33:17 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.431 | nll_loss 9.127 | ppl 559.18 | wps 38764.6 | wpb 510.9 | bsz 1 | num_updates 3208 | best_loss 8.318
2022-03-06 16:33:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3208 updates
2022-03-06 16:33:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:33:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:33:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 66 @ 3208 updates, score 9.431) (writing took 3.1465373374521732 seconds)
2022-03-06 16:33:21 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 16:33:21 | INFO | train | epoch 066 | loss 4.28 | nll_loss 3.872 | ppl 14.64 | wps 22209.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3208 | lr 0.00040102 | gnorm 1.527 | loss_scale 16 | train_wall 121 | gb_free 8.8 | wall 12651
2022-03-06 16:33:21 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 16:33:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:35:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:35:39 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.521 | nll_loss 9.22 | ppl 596.41 | wps 39206.1 | wpb 510.9 | bsz 1 | num_updates 3257 | best_loss 8.318
2022-03-06 16:35:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3257 updates
2022-03-06 16:35:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:35:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:35:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 67 @ 3257 updates, score 9.521) (writing took 3.19271083176136 seconds)
2022-03-06 16:35:42 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 16:35:42 | INFO | train | epoch 067 | loss 4.208 | nll_loss 3.796 | ppl 13.89 | wps 22417.9 | ups 0.35 | wpb 64858.2 | bsz 126.7 | num_updates 3257 | lr 0.000407144 | gnorm 1.646 | loss_scale 32 | train_wall 120 | gb_free 8.8 | wall 12793
2022-03-06 16:35:42 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 16:35:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:37:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:37:42 | INFO | train_inner | epoch 068:     44 / 49 loss=4.168, nll_loss=3.754, ppl=13.49, wps=22282.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.507, loss_scale=16, train_wall=247, gb_free=8.8, wall=12913
2022-03-06 16:37:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:38:00 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.577 | nll_loss 9.274 | ppl 619.23 | wps 40020.5 | wpb 510.9 | bsz 1 | num_updates 3305 | best_loss 8.318
2022-03-06 16:38:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3305 updates
2022-03-06 16:38:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:38:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:38:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 68 @ 3305 updates, score 9.577) (writing took 3.152376662939787 seconds)
2022-03-06 16:38:03 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 16:38:03 | INFO | train | epoch 068 | loss 4.104 | nll_loss 3.688 | ppl 12.89 | wps 22064.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 3305 | lr 0.000413142 | gnorm 1.42 | loss_scale 16 | train_wall 120 | gb_free 8.8 | wall 12934
2022-03-06 16:38:03 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 16:38:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:40:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:40:21 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.61 | nll_loss 9.307 | ppl 633.42 | wps 39970.1 | wpb 510.9 | bsz 1 | num_updates 3354 | best_loss 8.318
2022-03-06 16:40:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3354 updates
2022-03-06 16:40:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:40:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:40:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 69 @ 3354 updates, score 9.61) (writing took 2.9277377892285585 seconds)
2022-03-06 16:40:24 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 16:40:24 | INFO | train | epoch 069 | loss 4.031 | nll_loss 3.611 | ppl 12.22 | wps 22679.1 | ups 0.35 | wpb 64858.2 | bsz 126.7 | num_updates 3354 | lr 0.000419266 | gnorm 1.496 | loss_scale 16 | train_wall 119 | gb_free 8.8 | wall 13074
2022-03-06 16:40:24 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 16:40:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:42:29 | INFO | train_inner | epoch 070:     46 / 49 loss=4, nll_loss=3.578, ppl=11.94, wps=22618.7, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.514, loss_scale=16, train_wall=244, gb_free=8.8, wall=13200
2022-03-06 16:42:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:42:41 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.747 | nll_loss 9.447 | ppl 697.75 | wps 41547.1 | wpb 510.9 | bsz 1 | num_updates 3403 | best_loss 8.318
2022-03-06 16:42:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3403 updates
2022-03-06 16:42:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:42:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:42:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 70 @ 3403 updates, score 9.747) (writing took 2.516843928024173 seconds)
2022-03-06 16:42:44 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 16:42:44 | INFO | train | epoch 070 | loss 3.958 | nll_loss 3.534 | ppl 11.58 | wps 22658.4 | ups 0.35 | wpb 64858.2 | bsz 126.7 | num_updates 3403 | lr 0.00042539 | gnorm 1.544 | loss_scale 16 | train_wall 120 | gb_free 8.8 | wall 13214
2022-03-06 16:42:44 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 16:42:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:43:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:44:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:45:03 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.777 | nll_loss 9.476 | ppl 712.37 | wps 39095.1 | wpb 510.9 | bsz 1 | num_updates 3451 | best_loss 8.318
2022-03-06 16:45:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3451 updates
2022-03-06 16:45:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:45:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:45:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 71 @ 3451 updates, score 9.777) (writing took 2.481160044670105 seconds)
2022-03-06 16:45:06 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 16:45:06 | INFO | train | epoch 071 | loss 3.875 | nll_loss 3.447 | ppl 10.91 | wps 21918.9 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 3451 | lr 0.000431389 | gnorm 1.448 | loss_scale 16 | train_wall 121 | gb_free 8.8 | wall 13356
2022-03-06 16:45:06 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 16:45:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:47:20 | INFO | train_inner | epoch 072:     49 / 49 loss=3.848, nll_loss=3.418, ppl=10.69, wps=22176.7, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=3500, lr=0.000437513, gnorm=1.499, loss_scale=16, train_wall=249, gb_free=8.8, wall=13491
2022-03-06 16:47:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:47:26 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.859 | nll_loss 9.552 | ppl 750.7 | wps 39108.9 | wpb 510.9 | bsz 1 | num_updates 3500 | best_loss 8.318
2022-03-06 16:47:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3500 updates
2022-03-06 16:47:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:47:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:47:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 72 @ 3500 updates, score 9.859) (writing took 2.544640215113759 seconds)
2022-03-06 16:47:28 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 16:47:28 | INFO | train | epoch 072 | loss 3.811 | nll_loss 3.38 | ppl 10.41 | wps 22274.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3500 | lr 0.000437513 | gnorm 1.543 | loss_scale 16 | train_wall 122 | gb_free 8.8 | wall 13499
2022-03-06 16:47:28 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 16:47:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:49:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:49:48 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.949 | nll_loss 9.657 | ppl 807.16 | wps 38954.2 | wpb 510.9 | bsz 1 | num_updates 3549 | best_loss 8.318
2022-03-06 16:49:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3549 updates
2022-03-06 16:49:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:49:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:49:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 73 @ 3549 updates, score 9.949) (writing took 2.4531776793301105 seconds)
2022-03-06 16:49:51 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 16:49:51 | INFO | train | epoch 073 | loss 3.728 | nll_loss 3.293 | ppl 9.8 | wps 22354.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3549 | lr 0.000443636 | gnorm 1.555 | loss_scale 16 | train_wall 121 | gb_free 8.8 | wall 13641
2022-03-06 16:49:51 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 16:49:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:51:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:52:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:52:12 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.999 | nll_loss 9.696 | ppl 829.34 | wps 39272.7 | wpb 510.9 | bsz 1 | num_updates 3597 | best_loss 8.318
2022-03-06 16:52:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3597 updates
2022-03-06 16:52:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:52:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:52:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 74 @ 3597 updates, score 9.999) (writing took 2.5206265598535538 seconds)
2022-03-06 16:52:14 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 16:52:14 | INFO | train | epoch 074 | loss 3.651 | nll_loss 3.212 | ppl 9.26 | wps 21699.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3597 | lr 0.000449635 | gnorm 1.507 | loss_scale 16 | train_wall 123 | gb_free 8.8 | wall 13784
2022-03-06 16:52:14 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 16:52:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:52:23 | INFO | train_inner | epoch 075:      3 / 49 loss=3.686, nll_loss=3.248, ppl=9.5, wps=21464.4, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=3600, lr=0.00045001, gnorm=1.535, loss_scale=16, train_wall=251, gb_free=8.8, wall=13793
2022-03-06 16:54:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:54:35 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.065 | nll_loss 9.761 | ppl 867.45 | wps 38628.3 | wpb 510.9 | bsz 1 | num_updates 3646 | best_loss 8.318
2022-03-06 16:54:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3646 updates
2022-03-06 16:54:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:54:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:54:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 75 @ 3646 updates, score 10.065) (writing took 2.451007906347513 seconds)
2022-03-06 16:54:37 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 16:54:37 | INFO | train | epoch 075 | loss 3.589 | nll_loss 3.146 | ppl 8.85 | wps 22231.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3646 | lr 0.000455759 | gnorm 1.608 | loss_scale 16 | train_wall 122 | gb_free 8.8 | wall 13927
2022-03-06 16:54:37 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 16:54:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:56:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:56:58 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.188 | nll_loss 9.88 | ppl 942.58 | wps 38768.3 | wpb 510.9 | bsz 1 | num_updates 3695 | best_loss 8.318
2022-03-06 16:56:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3695 updates
2022-03-06 16:56:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:57:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:57:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 76 @ 3695 updates, score 10.188) (writing took 2.5784668065607548 seconds)
2022-03-06 16:57:01 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 16:57:01 | INFO | train | epoch 076 | loss 3.501 | nll_loss 3.054 | ppl 8.3 | wps 22129.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3695 | lr 0.000461883 | gnorm 1.455 | loss_scale 16 | train_wall 123 | gb_free 8.8 | wall 14071
2022-03-06 16:57:01 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 16:57:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:57:15 | INFO | train_inner | epoch 077:      5 / 49 loss=3.537, nll_loss=3.092, ppl=8.52, wps=22207.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.529, loss_scale=16, train_wall=250, gb_free=8.8, wall=14085
2022-03-06 16:59:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:59:21 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.2 | nll_loss 9.898 | ppl 954.42 | wps 38335.5 | wpb 510.9 | bsz 1 | num_updates 3744 | best_loss 8.318
2022-03-06 16:59:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3744 updates
2022-03-06 16:59:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:59:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:59:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 77 @ 3744 updates, score 10.2) (writing took 2.4879056997597218 seconds)
2022-03-06 16:59:24 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 16:59:24 | INFO | train | epoch 077 | loss 3.446 | nll_loss 2.994 | ppl 7.97 | wps 22224.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3744 | lr 0.000468006 | gnorm 1.599 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 14214
2022-03-06 16:59:24 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 16:59:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:59:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:01:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:01:44 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 10.344 | nll_loss 10.043 | ppl 1055.13 | wps 39038.3 | wpb 510.9 | bsz 1 | num_updates 3792 | best_loss 8.318
2022-03-06 17:01:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3792 updates
2022-03-06 17:01:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:01:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:01:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 78 @ 3792 updates, score 10.344) (writing took 2.442537659779191 seconds)
2022-03-06 17:01:47 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 17:01:47 | INFO | train | epoch 078 | loss 3.366 | nll_loss 2.911 | ppl 7.52 | wps 21764 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 3792 | lr 0.000474005 | gnorm 1.569 | loss_scale 16 | train_wall 122 | gb_free 8.8 | wall 14357
2022-03-06 17:01:47 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 17:01:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:02:09 | INFO | train_inner | epoch 079:      8 / 49 loss=3.396, nll_loss=2.942, ppl=7.69, wps=22031.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.591, loss_scale=16, train_wall=252, gb_free=8.8, wall=14379
2022-03-06 17:04:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:04:08 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 10.387 | nll_loss 10.088 | ppl 1088.4 | wps 39269.7 | wpb 510.9 | bsz 1 | num_updates 3841 | best_loss 8.318
2022-03-06 17:04:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3841 updates
2022-03-06 17:04:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:04:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:04:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 79 @ 3841 updates, score 10.387) (writing took 2.4094698522239923 seconds)
2022-03-06 17:04:10 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 17:04:10 | INFO | train | epoch 079 | loss 3.302 | nll_loss 2.843 | ppl 7.17 | wps 22154.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3841 | lr 0.000480129 | gnorm 1.558 | loss_scale 16 | train_wall 123 | gb_free 8.8 | wall 14500
2022-03-06 17:04:10 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 17:04:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:06:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:06:30 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 10.486 | nll_loss 10.181 | ppl 1161.2 | wps 39268.7 | wpb 510.9 | bsz 1 | num_updates 3890 | best_loss 8.318
2022-03-06 17:06:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3890 updates
2022-03-06 17:06:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:06:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:06:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 80 @ 3890 updates, score 10.486) (writing took 2.829824149608612 seconds)
2022-03-06 17:06:33 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 17:06:33 | INFO | train | epoch 080 | loss 3.239 | nll_loss 2.776 | ppl 6.85 | wps 22239.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3890 | lr 0.000486253 | gnorm 1.571 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 14643
2022-03-06 17:06:33 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 17:06:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:07:01 | INFO | train_inner | epoch 081:     10 / 49 loss=3.256, nll_loss=2.794, ppl=6.94, wps=22244.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.551, loss_scale=32, train_wall=249, gb_free=8.8, wall=14671
2022-03-06 17:07:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:08:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:08:53 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 10.645 | nll_loss 10.347 | ppl 1302.16 | wps 39044.6 | wpb 510.9 | bsz 1 | num_updates 3938 | best_loss 8.318
2022-03-06 17:08:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3938 updates
2022-03-06 17:08:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:08:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:08:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 81 @ 3938 updates, score 10.645) (writing took 2.409235928207636 seconds)
2022-03-06 17:08:55 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 17:08:55 | INFO | train | epoch 081 | loss 3.165 | nll_loss 2.698 | ppl 6.49 | wps 21888.6 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 3938 | lr 0.000492252 | gnorm 1.529 | loss_scale 16 | train_wall 121 | gb_free 8.8 | wall 14785
2022-03-06 17:08:55 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 17:08:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:11:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:11:16 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 10.691 | nll_loss 10.388 | ppl 1340.39 | wps 38977.4 | wpb 510.9 | bsz 1 | num_updates 3987 | best_loss 8.318
2022-03-06 17:11:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3987 updates
2022-03-06 17:11:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:11:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:11:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 82 @ 3987 updates, score 10.691) (writing took 2.6456774938851595 seconds)
2022-03-06 17:11:18 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-06 17:11:18 | INFO | train | epoch 082 | loss 3.105 | nll_loss 2.635 | ppl 6.21 | wps 22208.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3987 | lr 0.000498375 | gnorm 1.543 | loss_scale 16 | train_wall 122 | gb_free 8.8 | wall 14929
2022-03-06 17:11:18 | INFO | fairseq.trainer | begin training epoch 83
2022-03-06 17:11:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:11:54 | INFO | train_inner | epoch 083:     13 / 49 loss=3.119, nll_loss=2.649, ppl=6.27, wps=22087, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.572, loss_scale=16, train_wall=251, gb_free=8.8, wall=14965
2022-03-06 17:13:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:13:38 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 10.674 | nll_loss 10.371 | ppl 1324.63 | wps 39062.7 | wpb 510.9 | bsz 1 | num_updates 4036 | best_loss 8.318
2022-03-06 17:13:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4036 updates
2022-03-06 17:13:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:13:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:13:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 83 @ 4036 updates, score 10.674) (writing took 2.485384440049529 seconds)
2022-03-06 17:13:41 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-06 17:13:41 | INFO | train | epoch 083 | loss 3.039 | nll_loss 2.565 | ppl 5.92 | wps 22315.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4036 | lr 0.000497765 | gnorm 1.518 | loss_scale 32 | train_wall 122 | gb_free 8.8 | wall 15071
2022-03-06 17:13:41 | INFO | fairseq.trainer | begin training epoch 84
2022-03-06 17:13:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:14:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:15:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:16:01 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 10.85 | nll_loss 10.54 | ppl 1488.74 | wps 38824.8 | wpb 510.9 | bsz 1 | num_updates 4084 | best_loss 8.318
2022-03-06 17:16:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4084 updates
2022-03-06 17:16:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:16:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:16:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 84 @ 4084 updates, score 10.85) (writing took 2.362430529668927 seconds)
2022-03-06 17:16:03 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-06 17:16:03 | INFO | train | epoch 084 | loss 2.968 | nll_loss 2.489 | ppl 5.61 | wps 21837 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 4084 | lr 0.000494831 | gnorm 1.51 | loss_scale 16 | train_wall 122 | gb_free 8.8 | wall 15214
2022-03-06 17:16:03 | INFO | fairseq.trainer | begin training epoch 85
2022-03-06 17:16:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:16:48 | INFO | train_inner | epoch 085:     16 / 49 loss=2.983, nll_loss=2.505, ppl=5.67, wps=22111.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.49, loss_scale=16, train_wall=251, gb_free=8.8, wall=15258
2022-03-06 17:18:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:18:23 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 10.896 | nll_loss 10.59 | ppl 1541.83 | wps 38921.3 | wpb 510.9 | bsz 1 | num_updates 4133 | best_loss 8.318
2022-03-06 17:18:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4133 updates
2022-03-06 17:18:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:18:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:18:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 85 @ 4133 updates, score 10.896) (writing took 3.382146432995796 seconds)
2022-03-06 17:18:27 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-06 17:18:27 | INFO | train | epoch 085 | loss 2.905 | nll_loss 2.422 | ppl 5.36 | wps 22137.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4133 | lr 0.000491889 | gnorm 1.482 | loss_scale 16 | train_wall 122 | gb_free 8.8 | wall 15357
2022-03-06 17:18:27 | INFO | fairseq.trainer | begin training epoch 86
2022-03-06 17:18:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:20:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:20:48 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 10.974 | nll_loss 10.67 | ppl 1629.22 | wps 38857.1 | wpb 510.9 | bsz 1 | num_updates 4182 | best_loss 8.318
2022-03-06 17:20:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4182 updates
2022-03-06 17:20:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:20:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:20:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 86 @ 4182 updates, score 10.974) (writing took 3.2044474128633738 seconds)
2022-03-06 17:20:51 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-06 17:20:51 | INFO | train | epoch 086 | loss 2.84 | nll_loss 2.353 | ppl 5.11 | wps 21980.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4182 | lr 0.000488999 | gnorm 1.489 | loss_scale 32 | train_wall 123 | gb_free 8.8 | wall 15502
2022-03-06 17:20:51 | INFO | fairseq.trainer | begin training epoch 87
2022-03-06 17:20:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:21:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:21:44 | INFO | train_inner | epoch 087:     19 / 49 loss=2.847, nll_loss=2.361, ppl=5.14, wps=21910.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.461, loss_scale=16, train_wall=252, gb_free=8.8, wall=15554
2022-03-06 17:23:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:23:11 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.073 | nll_loss 10.767 | ppl 1742.26 | wps 38421.9 | wpb 510.9 | bsz 1 | num_updates 4230 | best_loss 8.318
2022-03-06 17:23:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4230 updates
2022-03-06 17:23:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:23:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 87 @ 4230 updates, score 11.073) (writing took 3.2610537111759186 seconds)
2022-03-06 17:23:14 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-06 17:23:14 | INFO | train | epoch 087 | loss 2.779 | nll_loss 2.289 | ppl 4.89 | wps 21792.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 4230 | lr 0.000486217 | gnorm 1.463 | loss_scale 16 | train_wall 121 | gb_free 8.8 | wall 15645
2022-03-06 17:23:14 | INFO | fairseq.trainer | begin training epoch 88
2022-03-06 17:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:25:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:25:33 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.15 | nll_loss 10.844 | ppl 1838.24 | wps 38549.9 | wpb 510.9 | bsz 1 | num_updates 4279 | best_loss 8.318
2022-03-06 17:25:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4279 updates
2022-03-06 17:25:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:25:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:25:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 88 @ 4279 updates, score 11.15) (writing took 3.2028283961117268 seconds)
2022-03-06 17:25:37 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-06 17:25:37 | INFO | train | epoch 088 | loss 2.726 | nll_loss 2.232 | ppl 4.7 | wps 22311.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4279 | lr 0.000483425 | gnorm 1.491 | loss_scale 16 | train_wall 121 | gb_free 8.8 | wall 15787
2022-03-06 17:25:37 | INFO | fairseq.trainer | begin training epoch 89
2022-03-06 17:25:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:26:35 | INFO | train_inner | epoch 089:     21 / 49 loss=2.728, nll_loss=2.234, ppl=4.7, wps=22270.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.438, loss_scale=16, train_wall=247, gb_free=8.8, wall=15845
2022-03-06 17:27:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:27:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:27:57 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.232 | nll_loss 10.921 | ppl 1938.95 | wps 38168.6 | wpb 510.9 | bsz 1 | num_updates 4327 | best_loss 8.318
2022-03-06 17:27:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4327 updates
2022-03-06 17:27:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:28:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:28:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 89 @ 4327 updates, score 11.232) (writing took 2.6824827529489994 seconds)
2022-03-06 17:28:00 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-06 17:28:00 | INFO | train | epoch 089 | loss 2.651 | nll_loss 2.154 | ppl 4.45 | wps 21726.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 4327 | lr 0.000480736 | gnorm 1.329 | loss_scale 16 | train_wall 122 | gb_free 8.8 | wall 15930
2022-03-06 17:28:00 | INFO | fairseq.trainer | begin training epoch 90
2022-03-06 17:28:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:30:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:30:20 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.368 | nll_loss 11.063 | ppl 2139.75 | wps 40849.2 | wpb 510.9 | bsz 1 | num_updates 4376 | best_loss 8.318
2022-03-06 17:30:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4376 updates
2022-03-06 17:30:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:30:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:30:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 90 @ 4376 updates, score 11.368) (writing took 2.4964533764868975 seconds)
2022-03-06 17:30:22 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-06 17:30:22 | INFO | train | epoch 090 | loss 2.6 | nll_loss 2.099 | ppl 4.28 | wps 22363.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4376 | lr 0.000478037 | gnorm 1.405 | loss_scale 16 | train_wall 121 | gb_free 8.8 | wall 16072
2022-03-06 17:30:22 | INFO | fairseq.trainer | begin training epoch 91
2022-03-06 17:30:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:31:27 | INFO | train_inner | epoch 091:     24 / 49 loss=2.602, nll_loss=2.101, ppl=4.29, wps=22256.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.403, loss_scale=16, train_wall=249, gb_free=8.8, wall=16137
2022-03-06 17:32:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:32:38 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.449 | nll_loss 11.142 | ppl 2260.35 | wps 40947.7 | wpb 510.9 | bsz 1 | num_updates 4425 | best_loss 8.318
2022-03-06 17:32:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4425 updates
2022-03-06 17:32:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:32:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:32:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 91 @ 4425 updates, score 11.449) (writing took 2.6614596229046583 seconds)
2022-03-06 17:32:40 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-06 17:32:40 | INFO | train | epoch 091 | loss 2.549 | nll_loss 2.044 | ppl 4.12 | wps 22991.7 | ups 0.35 | wpb 64858.2 | bsz 126.7 | num_updates 4425 | lr 0.000475383 | gnorm 1.411 | loss_scale 16 | train_wall 118 | gb_free 8.8 | wall 16211
2022-03-06 17:32:40 | INFO | fairseq.trainer | begin training epoch 92
2022-03-06 17:32:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:34:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:34:55 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.499 | nll_loss 11.194 | ppl 2343.03 | wps 41081.2 | wpb 510.9 | bsz 1 | num_updates 4474 | best_loss 8.318
2022-03-06 17:34:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4474 updates
2022-03-06 17:34:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:34:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:34:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 92 @ 4474 updates, score 11.499) (writing took 2.6911378484219313 seconds)
2022-03-06 17:34:58 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-06 17:34:58 | INFO | train | epoch 092 | loss 2.496 | nll_loss 1.988 | ppl 3.97 | wps 23114.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4474 | lr 0.000472772 | gnorm 1.397 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 16348
2022-03-06 17:34:58 | INFO | fairseq.trainer | begin training epoch 93
2022-03-06 17:34:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:36:07 | INFO | train_inner | epoch 093:     26 / 49 loss=2.493, nll_loss=1.985, ppl=3.96, wps=23118.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.389, loss_scale=32, train_wall=239, gb_free=8.8, wall=16418
2022-03-06 17:37:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:37:13 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 11.575 | nll_loss 11.268 | ppl 2466.71 | wps 41264.5 | wpb 510.9 | bsz 1 | num_updates 4523 | best_loss 8.318
2022-03-06 17:37:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4523 updates
2022-03-06 17:37:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:37:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:37:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 93 @ 4523 updates, score 11.575) (writing took 2.8109247107058764 seconds)
2022-03-06 17:37:15 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-06 17:37:15 | INFO | train | epoch 093 | loss 2.445 | nll_loss 1.934 | ppl 3.82 | wps 23101.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4523 | lr 0.000470204 | gnorm 1.384 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 16486
2022-03-06 17:37:15 | INFO | fairseq.trainer | begin training epoch 94
2022-03-06 17:37:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:39:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:39:30 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.698 | nll_loss 11.393 | ppl 2689.35 | wps 41228.5 | wpb 510.9 | bsz 1 | num_updates 4572 | best_loss 8.318
2022-03-06 17:39:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4572 updates
2022-03-06 17:39:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:39:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:39:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 94 @ 4572 updates, score 11.698) (writing took 2.779641119763255 seconds)
2022-03-06 17:39:33 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-06 17:39:33 | INFO | train | epoch 094 | loss 2.388 | nll_loss 1.873 | ppl 3.66 | wps 23117.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4572 | lr 0.000467678 | gnorm 1.318 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 16623
2022-03-06 17:39:33 | INFO | fairseq.trainer | begin training epoch 95
2022-03-06 17:39:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:40:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 17:40:51 | INFO | train_inner | epoch 095:     29 / 49 loss=2.391, nll_loss=1.876, ppl=3.67, wps=22843.6, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.347, loss_scale=32, train_wall=242, gb_free=8.8, wall=16702
2022-03-06 17:41:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:41:49 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 11.768 | nll_loss 11.461 | ppl 2819.84 | wps 41184 | wpb 510.9 | bsz 1 | num_updates 4620 | best_loss 8.318
2022-03-06 17:41:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4620 updates
2022-03-06 17:41:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:41:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:41:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 95 @ 4620 updates, score 11.768) (writing took 2.600968124344945 seconds)
2022-03-06 17:41:51 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-06 17:41:51 | INFO | train | epoch 095 | loss 2.342 | nll_loss 1.824 | ppl 3.54 | wps 22485.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 4620 | lr 0.000465242 | gnorm 1.334 | loss_scale 32 | train_wall 118 | gb_free 8.8 | wall 16762
2022-03-06 17:41:51 | INFO | fairseq.trainer | begin training epoch 96
2022-03-06 17:41:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:42:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:44:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:44:06 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 11.855 | nll_loss 11.56 | ppl 3018.42 | wps 41007 | wpb 510.9 | bsz 1 | num_updates 4668 | best_loss 8.318
2022-03-06 17:44:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4668 updates
2022-03-06 17:44:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:44:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:44:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 96 @ 4668 updates, score 11.855) (writing took 2.480310369282961 seconds)
2022-03-06 17:44:09 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-06 17:44:09 | INFO | train | epoch 096 | loss 2.299 | nll_loss 1.777 | ppl 3.43 | wps 22655.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 4668 | lr 0.000462844 | gnorm 1.328 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 16899
2022-03-06 17:44:09 | INFO | fairseq.trainer | begin training epoch 97
2022-03-06 17:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:45:34 | INFO | train_inner | epoch 097:     32 / 49 loss=2.293, nll_loss=1.771, ppl=3.41, wps=22956.8, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.33, loss_scale=16, train_wall=241, gb_free=8.8, wall=16984
2022-03-06 17:46:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:46:23 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 11.903 | nll_loss 11.602 | ppl 3109.12 | wps 41802.8 | wpb 510.9 | bsz 1 | num_updates 4717 | best_loss 8.318
2022-03-06 17:46:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4717 updates
2022-03-06 17:46:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:46:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:46:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 97 @ 4717 updates, score 11.903) (writing took 2.5962677970528603 seconds)
2022-03-06 17:46:25 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-06 17:46:25 | INFO | train | epoch 097 | loss 2.258 | nll_loss 1.734 | ppl 3.33 | wps 23234.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4717 | lr 0.000460434 | gnorm 1.33 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 17036
2022-03-06 17:46:25 | INFO | fairseq.trainer | begin training epoch 98
2022-03-06 17:46:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:48:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:48:39 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 12.059 | nll_loss 11.76 | ppl 3467.77 | wps 41865.6 | wpb 510.9 | bsz 1 | num_updates 4766 | best_loss 8.318
2022-03-06 17:48:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4766 updates
2022-03-06 17:48:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:48:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:48:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 98 @ 4766 updates, score 12.059) (writing took 2.4796036649495363 seconds)
2022-03-06 17:48:42 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-06 17:48:42 | INFO | train | epoch 098 | loss 2.214 | nll_loss 1.687 | ppl 3.22 | wps 23306.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4766 | lr 0.000458061 | gnorm 1.315 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 17172
2022-03-06 17:48:42 | INFO | fairseq.trainer | begin training epoch 99
2022-03-06 17:48:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:50:12 | INFO | train_inner | epoch 099:     34 / 49 loss=2.208, nll_loss=1.681, ppl=3.21, wps=23317.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.29, loss_scale=32, train_wall=238, gb_free=8.8, wall=17262
2022-03-06 17:50:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:50:56 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 12.115 | nll_loss 11.812 | ppl 3596.5 | wps 41437 | wpb 510.9 | bsz 1 | num_updates 4815 | best_loss 8.318
2022-03-06 17:50:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4815 updates
2022-03-06 17:50:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:50:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:50:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 99 @ 4815 updates, score 12.115) (writing took 2.5516519881784916 seconds)
2022-03-06 17:50:58 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-06 17:50:58 | INFO | train | epoch 099 | loss 2.171 | nll_loss 1.641 | ppl 3.12 | wps 23260.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4815 | lr 0.000455724 | gnorm 1.285 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 17309
2022-03-06 17:50:58 | INFO | fairseq.trainer | begin training epoch 100
2022-03-06 17:50:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:53:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:53:12 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.169 | nll_loss 11.871 | ppl 3746.37 | wps 41643.7 | wpb 510.9 | bsz 1 | num_updates 4864 | best_loss 8.318
2022-03-06 17:53:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4864 updates
2022-03-06 17:53:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:53:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:53:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 100 @ 4864 updates, score 12.169) (writing took 2.516556927934289 seconds)
2022-03-06 17:53:15 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-06 17:53:15 | INFO | train | epoch 100 | loss 2.129 | nll_loss 1.596 | ppl 3.02 | wps 23290.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4864 | lr 0.000453423 | gnorm 1.266 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 17445
2022-03-06 17:53:15 | INFO | fairseq.trainer | begin training epoch 101
2022-03-06 17:53:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:54:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 17:54:53 | INFO | train_inner | epoch 101:     37 / 49 loss=2.123, nll_loss=1.59, ppl=3.01, wps=23090.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.292, loss_scale=32, train_wall=240, gb_free=8.8, wall=17543
2022-03-06 17:55:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:55:29 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.264 | nll_loss 11.953 | ppl 3965.37 | wps 41288.4 | wpb 510.9 | bsz 1 | num_updates 4912 | best_loss 8.318
2022-03-06 17:55:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4912 updates
2022-03-06 17:55:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:55:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:55:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 101 @ 4912 updates, score 12.264) (writing took 2.4849050492048264 seconds)
2022-03-06 17:55:31 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-06 17:55:31 | INFO | train | epoch 101 | loss 2.094 | nll_loss 1.558 | ppl 2.94 | wps 22814.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 4912 | lr 0.000451202 | gnorm 1.283 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 17582
2022-03-06 17:55:31 | INFO | fairseq.trainer | begin training epoch 102
2022-03-06 17:55:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:57:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:57:46 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.334 | nll_loss 12.032 | ppl 4189.06 | wps 41541.8 | wpb 510.9 | bsz 1 | num_updates 4961 | best_loss 8.318
2022-03-06 17:57:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4961 updates
2022-03-06 17:57:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:57:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:57:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 102 @ 4961 updates, score 12.334) (writing took 2.5009793136268854 seconds)
2022-03-06 17:57:48 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-06 17:57:48 | INFO | train | epoch 102 | loss 2.059 | nll_loss 1.521 | ppl 2.87 | wps 23228.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4961 | lr 0.000448968 | gnorm 1.289 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 17718
2022-03-06 17:57:48 | INFO | fairseq.trainer | begin training epoch 103
2022-03-06 17:57:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:59:32 | INFO | train_inner | epoch 103:     39 / 49 loss=2.048, nll_loss=1.509, ppl=2.85, wps=23287.7, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.269, loss_scale=32, train_wall=238, gb_free=8.8, wall=17822
2022-03-06 17:59:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:00:02 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.377 | nll_loss 12.075 | ppl 4315.22 | wps 41603.2 | wpb 510.9 | bsz 1 | num_updates 5010 | best_loss 8.318
2022-03-06 18:00:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5010 updates
2022-03-06 18:00:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:00:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:00:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 103 @ 5010 updates, score 12.377) (writing took 2.503211982548237 seconds)
2022-03-06 18:00:05 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-06 18:00:05 | INFO | train | epoch 103 | loss 2.021 | nll_loss 1.48 | ppl 2.79 | wps 23293.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5010 | lr 0.000446767 | gnorm 1.253 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 17855
2022-03-06 18:00:05 | INFO | fairseq.trainer | begin training epoch 104
2022-03-06 18:00:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:00:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:02:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:02:18 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.485 | nll_loss 12.186 | ppl 4658.61 | wps 41588.8 | wpb 510.9 | bsz 1 | num_updates 5058 | best_loss 8.318
2022-03-06 18:02:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5058 updates
2022-03-06 18:02:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:02:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:02:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 104 @ 5058 updates, score 12.485) (writing took 2.5623751524835825 seconds)
2022-03-06 18:02:21 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-06 18:02:21 | INFO | train | epoch 104 | loss 1.988 | nll_loss 1.444 | ppl 2.72 | wps 22819.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5058 | lr 0.000444642 | gnorm 1.252 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 17991
2022-03-06 18:02:21 | INFO | fairseq.trainer | begin training epoch 105
2022-03-06 18:02:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:04:12 | INFO | train_inner | epoch 105:     42 / 49 loss=1.978, nll_loss=1.434, ppl=2.7, wps=23102.3, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.241, loss_scale=32, train_wall=240, gb_free=8.8, wall=18103
2022-03-06 18:04:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:04:35 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.538 | nll_loss 12.236 | ppl 4822.29 | wps 41390.3 | wpb 510.9 | bsz 1 | num_updates 5107 | best_loss 8.318
2022-03-06 18:04:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5107 updates
2022-03-06 18:04:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:04:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:04:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 105 @ 5107 updates, score 12.538) (writing took 2.4810591768473387 seconds)
2022-03-06 18:04:37 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-06 18:04:37 | INFO | train | epoch 105 | loss 1.955 | nll_loss 1.409 | ppl 2.65 | wps 23288.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5107 | lr 0.000442504 | gnorm 1.216 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 18128
2022-03-06 18:04:37 | INFO | fairseq.trainer | begin training epoch 106
2022-03-06 18:04:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:06:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:06:51 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.57 | nll_loss 12.268 | ppl 4931.42 | wps 41845.2 | wpb 510.9 | bsz 1 | num_updates 5156 | best_loss 8.318
2022-03-06 18:06:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5156 updates
2022-03-06 18:06:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:06:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:06:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 106 @ 5156 updates, score 12.57) (writing took 2.5661244615912437 seconds)
2022-03-06 18:06:54 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-06 18:06:54 | INFO | train | epoch 106 | loss 1.924 | nll_loss 1.376 | ppl 2.6 | wps 23295.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5156 | lr 0.000440396 | gnorm 1.21 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 18264
2022-03-06 18:06:54 | INFO | fairseq.trainer | begin training epoch 107
2022-03-06 18:06:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:06:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:08:53 | INFO | train_inner | epoch 107:     45 / 49 loss=1.915, nll_loss=1.366, ppl=2.58, wps=23093.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.218, loss_scale=32, train_wall=240, gb_free=8.8, wall=18384
2022-03-06 18:09:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:09:08 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.726 | nll_loss 12.426 | ppl 5503.91 | wps 40942.8 | wpb 510.9 | bsz 1 | num_updates 5204 | best_loss 8.318
2022-03-06 18:09:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5204 updates
2022-03-06 18:09:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:09:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:09:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 107 @ 5204 updates, score 12.726) (writing took 2.450217066332698 seconds)
2022-03-06 18:09:10 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-06 18:09:10 | INFO | train | epoch 107 | loss 1.894 | nll_loss 1.344 | ppl 2.54 | wps 22795.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5204 | lr 0.00043836 | gnorm 1.235 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 18401
2022-03-06 18:09:10 | INFO | fairseq.trainer | begin training epoch 108
2022-03-06 18:09:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:10:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:11:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:11:25 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.786 | nll_loss 12.488 | ppl 5743.91 | wps 41602.8 | wpb 510.9 | bsz 1 | num_updates 5252 | best_loss 8.318
2022-03-06 18:11:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5252 updates
2022-03-06 18:11:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:11:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:11:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 108 @ 5252 updates, score 12.786) (writing took 2.6064989119768143 seconds)
2022-03-06 18:11:27 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-06 18:11:27 | INFO | train | epoch 108 | loss 1.864 | nll_loss 1.311 | ppl 2.48 | wps 22744.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5252 | lr 0.000436353 | gnorm 1.198 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 18537
2022-03-06 18:11:27 | INFO | fairseq.trainer | begin training epoch 109
2022-03-06 18:11:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:13:34 | INFO | train_inner | epoch 109:     48 / 49 loss=1.854, nll_loss=1.3, ppl=2.46, wps=23075.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.191, loss_scale=16, train_wall=240, gb_free=8.8, wall=18665
2022-03-06 18:13:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:13:41 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.818 | nll_loss 12.525 | ppl 5894.73 | wps 40951.9 | wpb 510.9 | bsz 1 | num_updates 5301 | best_loss 8.318
2022-03-06 18:13:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5301 updates
2022-03-06 18:13:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:13:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:13:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 109 @ 5301 updates, score 12.818) (writing took 2.6328924112021923 seconds)
2022-03-06 18:13:44 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-06 18:13:44 | INFO | train | epoch 109 | loss 1.837 | nll_loss 1.282 | ppl 2.43 | wps 23275.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5301 | lr 0.000434331 | gnorm 1.176 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 18674
2022-03-06 18:13:44 | INFO | fairseq.trainer | begin training epoch 110
2022-03-06 18:13:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:15:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:15:58 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.864 | nll_loss 12.573 | ppl 6093.94 | wps 42045.7 | wpb 510.9 | bsz 1 | num_updates 5350 | best_loss 8.318
2022-03-06 18:15:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5350 updates
2022-03-06 18:15:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:16:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:16:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 110 @ 5350 updates, score 12.864) (writing took 2.4953776951879263 seconds)
2022-03-06 18:16:00 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-06 18:16:00 | INFO | train | epoch 110 | loss 1.809 | nll_loss 1.253 | ppl 2.38 | wps 23320.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5350 | lr 0.000432338 | gnorm 1.175 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 18810
2022-03-06 18:16:00 | INFO | fairseq.trainer | begin training epoch 111
2022-03-06 18:16:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:18:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:18:14 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.972 | nll_loss 12.683 | ppl 6574.06 | wps 41739.7 | wpb 510.9 | bsz 1 | num_updates 5399 | best_loss 8.318
2022-03-06 18:18:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5399 updates
2022-03-06 18:18:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:18:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:18:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 111 @ 5399 updates, score 12.972) (writing took 2.550046507269144 seconds)
2022-03-06 18:18:17 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-06 18:18:17 | INFO | train | epoch 111 | loss 1.784 | nll_loss 1.225 | ppl 2.34 | wps 23276.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5399 | lr 0.000430371 | gnorm 1.141 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 18947
2022-03-06 18:18:17 | INFO | fairseq.trainer | begin training epoch 112
2022-03-06 18:18:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:18:19 | INFO | train_inner | epoch 112:      1 / 49 loss=1.796, nll_loss=1.238, ppl=2.36, wps=22651.5, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=5400, lr=0.000430331, gnorm=1.159, loss_scale=32, train_wall=236, gb_free=8.8, wall=18950
2022-03-06 18:20:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:20:31 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 12.985 | nll_loss 12.691 | ppl 6614.08 | wps 41102.8 | wpb 510.9 | bsz 1 | num_updates 5448 | best_loss 8.318
2022-03-06 18:20:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5448 updates
2022-03-06 18:20:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:20:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:20:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 112 @ 5448 updates, score 12.985) (writing took 2.49444124661386 seconds)
2022-03-06 18:20:33 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-06 18:20:33 | INFO | train | epoch 112 | loss 1.761 | nll_loss 1.201 | ppl 2.3 | wps 23272.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5448 | lr 0.000428432 | gnorm 1.174 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 19083
2022-03-06 18:20:33 | INFO | fairseq.trainer | begin training epoch 113
2022-03-06 18:20:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:22:47 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 13.075 | nll_loss 12.774 | ppl 7004.73 | wps 41864.9 | wpb 510.9 | bsz 1 | num_updates 5497 | best_loss 8.318
2022-03-06 18:22:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5497 updates
2022-03-06 18:22:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:22:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:22:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 113 @ 5497 updates, score 13.075) (writing took 2.405045136809349 seconds)
2022-03-06 18:22:50 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-06 18:22:50 | INFO | train | epoch 113 | loss 1.733 | nll_loss 1.17 | ppl 2.25 | wps 23294.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5497 | lr 0.000426518 | gnorm 1.143 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 19220
2022-03-06 18:22:50 | INFO | fairseq.trainer | begin training epoch 114
2022-03-06 18:22:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:22:58 | INFO | train_inner | epoch 114:      3 / 49 loss=1.745, nll_loss=1.183, ppl=2.27, wps=23307.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=5500, lr=0.000426401, gnorm=1.157, loss_scale=64, train_wall=238, gb_free=8.8, wall=19228
2022-03-06 18:23:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:24:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:25:03 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 13.095 | nll_loss 12.801 | ppl 7134.85 | wps 41592.3 | wpb 510.9 | bsz 1 | num_updates 5545 | best_loss 8.318
2022-03-06 18:25:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5545 updates
2022-03-06 18:25:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:25:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:25:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 114 @ 5545 updates, score 13.095) (writing took 2.400000488385558 seconds)
2022-03-06 18:25:06 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-06 18:25:06 | INFO | train | epoch 114 | loss 1.708 | nll_loss 1.144 | ppl 2.21 | wps 22830.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5545 | lr 0.000424668 | gnorm 1.133 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 19356
2022-03-06 18:25:06 | INFO | fairseq.trainer | begin training epoch 115
2022-03-06 18:25:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:27:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:27:21 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 13.1 | nll_loss 12.797 | ppl 7119.06 | wps 40723.4 | wpb 510.9 | bsz 1 | num_updates 5594 | best_loss 8.318
2022-03-06 18:27:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5594 updates
2022-03-06 18:27:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:27:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:27:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 115 @ 5594 updates, score 13.1) (writing took 2.5236592143774033 seconds)
2022-03-06 18:27:24 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-06 18:27:24 | INFO | train | epoch 115 | loss 1.689 | nll_loss 1.123 | ppl 2.18 | wps 23036 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5594 | lr 0.000422804 | gnorm 1.142 | loss_scale 32 | train_wall 118 | gb_free 8.8 | wall 19494
2022-03-06 18:27:24 | INFO | fairseq.trainer | begin training epoch 116
2022-03-06 18:27:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:27:40 | INFO | train_inner | epoch 116:      6 / 49 loss=1.696, nll_loss=1.13, ppl=2.19, wps=22974.4, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=1.139, loss_scale=32, train_wall=241, gb_free=8.8, wall=19510
2022-03-06 18:29:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:29:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:29:38 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 13.187 | nll_loss 12.898 | ppl 7635.04 | wps 41283.3 | wpb 510.9 | bsz 1 | num_updates 5642 | best_loss 8.318
2022-03-06 18:29:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5642 updates
2022-03-06 18:29:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:29:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:29:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 116 @ 5642 updates, score 13.187) (writing took 2.492787951603532 seconds)
2022-03-06 18:29:40 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-06 18:29:40 | INFO | train | epoch 116 | loss 1.664 | nll_loss 1.095 | ppl 2.14 | wps 22814.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5642 | lr 0.000421001 | gnorm 1.092 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 19631
2022-03-06 18:29:40 | INFO | fairseq.trainer | begin training epoch 117
2022-03-06 18:29:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:31:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:31:54 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 13.298 | nll_loss 13.012 | ppl 8258.82 | wps 41323.3 | wpb 510.9 | bsz 1 | num_updates 5691 | best_loss 8.318
2022-03-06 18:31:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5691 updates
2022-03-06 18:31:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:31:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:31:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 117 @ 5691 updates, score 13.298) (writing took 2.4912465903908014 seconds)
2022-03-06 18:31:57 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-06 18:31:57 | INFO | train | epoch 117 | loss 1.647 | nll_loss 1.077 | ppl 2.11 | wps 23309.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5691 | lr 0.000419185 | gnorm 1.107 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 19767
2022-03-06 18:31:57 | INFO | fairseq.trainer | begin training epoch 118
2022-03-06 18:31:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:32:21 | INFO | train_inner | epoch 118:      9 / 49 loss=1.65, nll_loss=1.082, ppl=2.12, wps=23118.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=1.097, loss_scale=32, train_wall=240, gb_free=8.8, wall=19791
2022-03-06 18:34:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:34:11 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 13.332 | nll_loss 13.035 | ppl 8392.18 | wps 41152.1 | wpb 510.9 | bsz 1 | num_updates 5740 | best_loss 8.318
2022-03-06 18:34:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5740 updates
2022-03-06 18:34:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:34:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:34:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 118 @ 5740 updates, score 13.332) (writing took 2.5180154889822006 seconds)
2022-03-06 18:34:13 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-06 18:34:13 | INFO | train | epoch 118 | loss 1.629 | nll_loss 1.058 | ppl 2.08 | wps 23220.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5740 | lr 0.000417392 | gnorm 1.107 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 19904
2022-03-06 18:34:13 | INFO | fairseq.trainer | begin training epoch 119
2022-03-06 18:34:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:35:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:36:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:36:28 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 13.421 | nll_loss 13.132 | ppl 8977.35 | wps 41475.8 | wpb 510.9 | bsz 1 | num_updates 5788 | best_loss 8.318
2022-03-06 18:36:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5788 updates
2022-03-06 18:36:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:36:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:36:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 119 @ 5788 updates, score 13.421) (writing took 2.5417072605341673 seconds)
2022-03-06 18:36:30 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-06 18:36:30 | INFO | train | epoch 119 | loss 1.606 | nll_loss 1.033 | ppl 2.05 | wps 22773 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5788 | lr 0.000415658 | gnorm 1.103 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 20040
2022-03-06 18:36:30 | INFO | fairseq.trainer | begin training epoch 120
2022-03-06 18:36:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:37:02 | INFO | train_inner | epoch 120:     12 / 49 loss=1.613, nll_loss=1.041, ppl=2.06, wps=23044.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=1.1, loss_scale=32, train_wall=240, gb_free=8.8, wall=20072
2022-03-06 18:38:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:38:44 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 13.412 | nll_loss 13.121 | ppl 8909.93 | wps 41515.4 | wpb 510.9 | bsz 1 | num_updates 5837 | best_loss 8.318
2022-03-06 18:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5837 updates
2022-03-06 18:38:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:38:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:38:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 120 @ 5837 updates, score 13.412) (writing took 2.4544462207704782 seconds)
2022-03-06 18:38:47 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-06 18:38:47 | INFO | train | epoch 120 | loss 1.587 | nll_loss 1.013 | ppl 2.02 | wps 23260.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5837 | lr 0.000413909 | gnorm 1.07 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 20177
2022-03-06 18:38:47 | INFO | fairseq.trainer | begin training epoch 121
2022-03-06 18:38:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:40:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:41:01 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 13.469 | nll_loss 13.183 | ppl 9302.24 | wps 41611.9 | wpb 510.9 | bsz 1 | num_updates 5886 | best_loss 8.318
2022-03-06 18:41:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5886 updates
2022-03-06 18:41:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:41:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:41:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 121 @ 5886 updates, score 13.469) (writing took 2.4782247208058834 seconds)
2022-03-06 18:41:03 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-06 18:41:03 | INFO | train | epoch 121 | loss 1.568 | nll_loss 0.993 | ppl 1.99 | wps 23295.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5886 | lr 0.000412183 | gnorm 1.055 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 20313
2022-03-06 18:41:03 | INFO | fairseq.trainer | begin training epoch 122
2022-03-06 18:41:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:41:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:41:43 | INFO | train_inner | epoch 122:     15 / 49 loss=1.572, nll_loss=0.997, ppl=2, wps=23087.6, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=1.058, loss_scale=32, train_wall=240, gb_free=8.8, wall=20353
2022-03-06 18:43:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:43:17 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 13.562 | nll_loss 13.277 | ppl 9928.38 | wps 41668.7 | wpb 510.9 | bsz 1 | num_updates 5934 | best_loss 8.318
2022-03-06 18:43:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5934 updates
2022-03-06 18:43:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:43:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:43:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 122 @ 5934 updates, score 13.562) (writing took 2.5614599511027336 seconds)
2022-03-06 18:43:20 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-06 18:43:20 | INFO | train | epoch 122 | loss 1.551 | nll_loss 0.974 | ppl 1.96 | wps 22771.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5934 | lr 0.000410512 | gnorm 1.039 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 20450
2022-03-06 18:43:20 | INFO | fairseq.trainer | begin training epoch 123
2022-03-06 18:43:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:44:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:45:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:45:34 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 13.464 | nll_loss 13.177 | ppl 9261.52 | wps 41338.7 | wpb 510.9 | bsz 1 | num_updates 5982 | best_loss 8.318
2022-03-06 18:45:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5982 updates
2022-03-06 18:45:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:45:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:45:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 123 @ 5982 updates, score 13.464) (writing took 2.5283498894423246 seconds)
2022-03-06 18:45:37 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-06 18:45:37 | INFO | train | epoch 123 | loss 1.538 | nll_loss 0.961 | ppl 1.95 | wps 22752.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5982 | lr 0.000408862 | gnorm 1.07 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 20587
2022-03-06 18:45:37 | INFO | fairseq.trainer | begin training epoch 124
2022-03-06 18:45:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:46:24 | INFO | train_inner | epoch 124:     18 / 49 loss=1.539, nll_loss=0.962, ppl=1.95, wps=23053.2, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=1.053, loss_scale=16, train_wall=240, gb_free=8.8, wall=20635
2022-03-06 18:47:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:47:51 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 13.728 | nll_loss 13.446 | ppl 11159.9 | wps 41149.9 | wpb 510.9 | bsz 1 | num_updates 6031 | best_loss 8.318
2022-03-06 18:47:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6031 updates
2022-03-06 18:47:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:47:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:47:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 124 @ 6031 updates, score 13.728) (writing took 2.4642709475010633 seconds)
2022-03-06 18:47:53 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-06 18:47:53 | INFO | train | epoch 124 | loss 1.521 | nll_loss 0.943 | ppl 1.92 | wps 23285.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6031 | lr 0.000407198 | gnorm 1.046 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 20723
2022-03-06 18:47:53 | INFO | fairseq.trainer | begin training epoch 125
2022-03-06 18:47:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:50:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:50:07 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 13.652 | nll_loss 13.364 | ppl 10540.5 | wps 41736.8 | wpb 510.9 | bsz 1 | num_updates 6080 | best_loss 8.318
2022-03-06 18:50:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6080 updates
2022-03-06 18:50:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:50:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:50:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 125 @ 6080 updates, score 13.652) (writing took 2.403074935078621 seconds)
2022-03-06 18:50:10 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-06 18:50:10 | INFO | train | epoch 125 | loss 1.5 | nll_loss 0.921 | ppl 1.89 | wps 23281.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6080 | lr 0.000405554 | gnorm 1.029 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 20860
2022-03-06 18:50:10 | INFO | fairseq.trainer | begin training epoch 126
2022-03-06 18:50:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:51:03 | INFO | train_inner | epoch 126:     20 / 49 loss=1.504, nll_loss=0.925, ppl=1.9, wps=23304.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=1.037, loss_scale=32, train_wall=238, gb_free=8.8, wall=20913
2022-03-06 18:52:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:52:24 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 13.732 | nll_loss 13.448 | ppl 11172.9 | wps 41176.4 | wpb 510.9 | bsz 1 | num_updates 6129 | best_loss 8.318
2022-03-06 18:52:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6129 updates
2022-03-06 18:52:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:52:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:52:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 126 @ 6129 updates, score 13.732) (writing took 2.627769125625491 seconds)
2022-03-06 18:52:26 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-06 18:52:26 | INFO | train | epoch 126 | loss 1.488 | nll_loss 0.907 | ppl 1.88 | wps 23235.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6129 | lr 0.000403929 | gnorm 1.038 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 20997
2022-03-06 18:52:26 | INFO | fairseq.trainer | begin training epoch 127
2022-03-06 18:52:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:54:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:54:40 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 13.734 | nll_loss 13.452 | ppl 11204.2 | wps 41731.2 | wpb 510.9 | bsz 1 | num_updates 6178 | best_loss 8.318
2022-03-06 18:54:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6178 updates
2022-03-06 18:54:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:54:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:54:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 127 @ 6178 updates, score 13.734) (writing took 2.5264574214816093 seconds)
2022-03-06 18:54:43 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-06 18:54:43 | INFO | train | epoch 127 | loss 1.475 | nll_loss 0.893 | ppl 1.86 | wps 23302.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6178 | lr 0.000402324 | gnorm 1.006 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 21133
2022-03-06 18:54:43 | INFO | fairseq.trainer | begin training epoch 128
2022-03-06 18:54:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:55:41 | INFO | train_inner | epoch 128:     22 / 49 loss=1.474, nll_loss=0.892, ppl=1.86, wps=23308.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=1.012, loss_scale=32, train_wall=237, gb_free=8.8, wall=21191
2022-03-06 18:56:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:56:57 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 13.719 | nll_loss 13.434 | ppl 11064.9 | wps 41282.4 | wpb 510.9 | bsz 1 | num_updates 6227 | best_loss 8.318
2022-03-06 18:56:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6227 updates
2022-03-06 18:56:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:56:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:56:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 128 @ 6227 updates, score 13.719) (writing took 2.4490343257784843 seconds)
2022-03-06 18:56:59 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-06 18:56:59 | INFO | train | epoch 128 | loss 1.457 | nll_loss 0.874 | ppl 1.83 | wps 23310.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6227 | lr 0.000400738 | gnorm 0.991 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 21269
2022-03-06 18:56:59 | INFO | fairseq.trainer | begin training epoch 129
2022-03-06 18:56:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:57:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:59:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:59:13 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 13.774 | nll_loss 13.493 | ppl 11527.4 | wps 41873.9 | wpb 510.9 | bsz 1 | num_updates 6275 | best_loss 8.318
2022-03-06 18:59:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6275 updates
2022-03-06 18:59:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:59:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:59:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 129 @ 6275 updates, score 13.774) (writing took 2.4485778100788593 seconds)
2022-03-06 18:59:16 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-06 18:59:16 | INFO | train | epoch 129 | loss 1.448 | nll_loss 0.864 | ppl 1.82 | wps 22815.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 6275 | lr 0.000399202 | gnorm 1.029 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 21406
2022-03-06 18:59:16 | INFO | fairseq.trainer | begin training epoch 130
2022-03-06 18:59:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:59:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:00:25 | INFO | train_inner | epoch 130:     26 / 49 loss=1.446, nll_loss=0.863, ppl=1.82, wps=22877, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=1.003, loss_scale=16, train_wall=242, gb_free=8.8, wall=21475
2022-03-06 19:01:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:01:30 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 13.786 | nll_loss 13.504 | ppl 11614.7 | wps 40990 | wpb 510.9 | bsz 1 | num_updates 6323 | best_loss 8.318
2022-03-06 19:01:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6323 updates
2022-03-06 19:01:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:01:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:01:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 130 @ 6323 updates, score 13.786) (writing took 2.588984588161111 seconds)
2022-03-06 19:01:32 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-06 19:01:32 | INFO | train | epoch 130 | loss 1.431 | nll_loss 0.846 | ppl 1.8 | wps 22763.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 6323 | lr 0.000397684 | gnorm 0.988 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 21543
2022-03-06 19:01:32 | INFO | fairseq.trainer | begin training epoch 131
2022-03-06 19:01:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:03:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:03:46 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 13.865 | nll_loss 13.591 | ppl 12338.7 | wps 41640.4 | wpb 510.9 | bsz 1 | num_updates 6372 | best_loss 8.318
2022-03-06 19:03:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6372 updates
2022-03-06 19:03:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:03:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:03:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 131 @ 6372 updates, score 13.865) (writing took 2.429430603981018 seconds)
2022-03-06 19:03:49 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-06 19:03:49 | INFO | train | epoch 131 | loss 1.419 | nll_loss 0.833 | ppl 1.78 | wps 23267.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6372 | lr 0.000396152 | gnorm 0.979 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 21679
2022-03-06 19:03:49 | INFO | fairseq.trainer | begin training epoch 132
2022-03-06 19:03:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:05:03 | INFO | train_inner | epoch 132:     28 / 49 loss=1.419, nll_loss=0.833, ppl=1.78, wps=23293.5, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=0.984, loss_scale=16, train_wall=238, gb_free=8.8, wall=21754
2022-03-06 19:05:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:06:03 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 13.891 | nll_loss 13.614 | ppl 12538.3 | wps 41142.9 | wpb 510.9 | bsz 1 | num_updates 6421 | best_loss 8.318
2022-03-06 19:06:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6421 updates
2022-03-06 19:06:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:06:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:06:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 132 @ 6421 updates, score 13.891) (writing took 2.5778176952153444 seconds)
2022-03-06 19:06:06 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-06 19:06:06 | INFO | train | epoch 132 | loss 1.408 | nll_loss 0.822 | ppl 1.77 | wps 23260.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6421 | lr 0.000394638 | gnorm 0.982 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 21816
2022-03-06 19:06:06 | INFO | fairseq.trainer | begin training epoch 133
2022-03-06 19:06:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:08:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:08:19 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 13.947 | nll_loss 13.67 | ppl 13030.6 | wps 41546.5 | wpb 510.9 | bsz 1 | num_updates 6470 | best_loss 8.318
2022-03-06 19:08:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6470 updates
2022-03-06 19:08:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:08:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:08:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 133 @ 6470 updates, score 13.947) (writing took 2.529819395393133 seconds)
2022-03-06 19:08:22 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-06 19:08:22 | INFO | train | epoch 133 | loss 1.394 | nll_loss 0.807 | ppl 1.75 | wps 23290.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6470 | lr 0.000393141 | gnorm 0.942 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 21952
2022-03-06 19:08:22 | INFO | fairseq.trainer | begin training epoch 134
2022-03-06 19:08:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:09:42 | INFO | train_inner | epoch 134:     30 / 49 loss=1.395, nll_loss=0.808, ppl=1.75, wps=23295.9, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=0.959, loss_scale=32, train_wall=238, gb_free=8.8, wall=22032
2022-03-06 19:10:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:10:36 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 14.066 | nll_loss 13.794 | ppl 14204.9 | wps 41877.6 | wpb 510.9 | bsz 1 | num_updates 6519 | best_loss 8.318
2022-03-06 19:10:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6519 updates
2022-03-06 19:10:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:10:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:10:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 134 @ 6519 updates, score 14.066) (writing took 2.5057364515960217 seconds)
2022-03-06 19:10:38 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-06 19:10:38 | INFO | train | epoch 134 | loss 1.383 | nll_loss 0.796 | ppl 1.74 | wps 23280 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6519 | lr 0.00039166 | gnorm 0.962 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 22089
2022-03-06 19:10:39 | INFO | fairseq.trainer | begin training epoch 135
2022-03-06 19:10:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:11:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:12:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:12:52 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 13.96 | nll_loss 13.686 | ppl 13182.4 | wps 41957.1 | wpb 510.9 | bsz 1 | num_updates 6567 | best_loss 8.318
2022-03-06 19:12:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6567 updates
2022-03-06 19:12:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:12:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:12:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 135 @ 6567 updates, score 13.96) (writing took 2.5257475525140762 seconds)
2022-03-06 19:12:55 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-06 19:12:55 | INFO | train | epoch 135 | loss 1.373 | nll_loss 0.785 | ppl 1.72 | wps 22828.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 6567 | lr 0.000390226 | gnorm 0.965 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 22225
2022-03-06 19:12:55 | INFO | fairseq.trainer | begin training epoch 136
2022-03-06 19:12:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:13:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:14:26 | INFO | train_inner | epoch 136:     34 / 49 loss=1.37, nll_loss=0.782, ppl=1.72, wps=22801.4, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.955, loss_scale=16, train_wall=243, gb_free=8.8, wall=22317
2022-03-06 19:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:15:10 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 14.058 | nll_loss 13.782 | ppl 14087.3 | wps 41065.6 | wpb 510.9 | bsz 1 | num_updates 6615 | best_loss 8.318
2022-03-06 19:15:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6615 updates
2022-03-06 19:15:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:15:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:15:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 136 @ 6615 updates, score 14.058) (writing took 2.43934253975749 seconds)
2022-03-06 19:15:13 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-06 19:15:13 | INFO | train | epoch 136 | loss 1.36 | nll_loss 0.771 | ppl 1.71 | wps 22543.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 6615 | lr 0.000388808 | gnorm 0.938 | loss_scale 16 | train_wall 118 | gb_free 8.8 | wall 22363
2022-03-06 19:15:13 | INFO | fairseq.trainer | begin training epoch 137
2022-03-06 19:15:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:17:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:17:27 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 14.022 | nll_loss 13.743 | ppl 13715.1 | wps 41681.8 | wpb 510.9 | bsz 1 | num_updates 6664 | best_loss 8.318
2022-03-06 19:17:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6664 updates
2022-03-06 19:17:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:17:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:17:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 137 @ 6664 updates, score 14.022) (writing took 2.4968938399106264 seconds)
2022-03-06 19:17:29 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-06 19:17:29 | INFO | train | epoch 137 | loss 1.351 | nll_loss 0.761 | ppl 1.7 | wps 23267.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6664 | lr 0.000387376 | gnorm 0.947 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 22500
2022-03-06 19:17:30 | INFO | fairseq.trainer | begin training epoch 138
2022-03-06 19:17:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:19:05 | INFO | train_inner | epoch 138:     36 / 49 loss=1.349, nll_loss=0.759, ppl=1.69, wps=23262.9, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.942, loss_scale=32, train_wall=238, gb_free=8.8, wall=22595
2022-03-06 19:19:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:19:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:19:44 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 14.032 | nll_loss 13.761 | ppl 13883.8 | wps 41645.3 | wpb 510.9 | bsz 1 | num_updates 6712 | best_loss 8.318
2022-03-06 19:19:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6712 updates
2022-03-06 19:19:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:19:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:19:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 138 @ 6712 updates, score 14.032) (writing took 2.4969456121325493 seconds)
2022-03-06 19:19:46 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-06 19:19:46 | INFO | train | epoch 138 | loss 1.34 | nll_loss 0.75 | ppl 1.68 | wps 22791.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 6712 | lr 0.000385988 | gnorm 0.941 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 22636
2022-03-06 19:19:46 | INFO | fairseq.trainer | begin training epoch 139
2022-03-06 19:19:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:21:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:22:00 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 14.084 | nll_loss 13.81 | ppl 14361.8 | wps 41400.9 | wpb 510.9 | bsz 1 | num_updates 6761 | best_loss 8.318
2022-03-06 19:22:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6761 updates
2022-03-06 19:22:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:22:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:22:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 139 @ 6761 updates, score 14.084) (writing took 2.513432454317808 seconds)
2022-03-06 19:22:03 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-06 19:22:03 | INFO | train | epoch 139 | loss 1.328 | nll_loss 0.737 | ppl 1.67 | wps 23205.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6761 | lr 0.000384587 | gnorm 0.913 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 22773
2022-03-06 19:22:03 | INFO | fairseq.trainer | begin training epoch 140
2022-03-06 19:22:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:23:47 | INFO | train_inner | epoch 140:     39 / 49 loss=1.326, nll_loss=0.735, ppl=1.66, wps=23004.6, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.912, loss_scale=16, train_wall=241, gb_free=8.8, wall=22877
2022-03-06 19:24:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:24:18 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 14.208 | nll_loss 13.939 | ppl 15709.3 | wps 40868.7 | wpb 510.9 | bsz 1 | num_updates 6810 | best_loss 8.318
2022-03-06 19:24:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6810 updates
2022-03-06 19:24:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:24:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:24:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 140 @ 6810 updates, score 14.208) (writing took 2.577979151159525 seconds)
2022-03-06 19:24:20 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-06 19:24:20 | INFO | train | epoch 140 | loss 1.318 | nll_loss 0.727 | ppl 1.66 | wps 23150.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6810 | lr 0.000383201 | gnorm 0.901 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 22911
2022-03-06 19:24:20 | INFO | fairseq.trainer | begin training epoch 141
2022-03-06 19:24:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:26:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:26:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:26:35 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 14.229 | nll_loss 13.961 | ppl 15948.7 | wps 40349.3 | wpb 510.9 | bsz 1 | num_updates 6858 | best_loss 8.318
2022-03-06 19:26:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6858 updates
2022-03-06 19:26:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:26:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:26:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 141 @ 6858 updates, score 14.229) (writing took 2.5024881567806005 seconds)
2022-03-06 19:26:37 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-06 19:26:37 | INFO | train | epoch 141 | loss 1.311 | nll_loss 0.72 | ppl 1.65 | wps 22704.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 6858 | lr 0.000381857 | gnorm 0.903 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23048
2022-03-06 19:26:37 | INFO | fairseq.trainer | begin training epoch 142
2022-03-06 19:26:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:28:29 | INFO | train_inner | epoch 142:     42 / 49 loss=1.309, nll_loss=0.717, ppl=1.64, wps=22980.4, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.902, loss_scale=16, train_wall=241, gb_free=8.8, wall=23160
2022-03-06 19:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:28:52 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 14.179 | nll_loss 13.907 | ppl 15363.1 | wps 40980.7 | wpb 510.9 | bsz 1 | num_updates 6907 | best_loss 8.318
2022-03-06 19:28:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6907 updates
2022-03-06 19:28:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:28:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:28:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 142 @ 6907 updates, score 14.179) (writing took 2.513090591877699 seconds)
2022-03-06 19:28:55 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-06 19:28:55 | INFO | train | epoch 142 | loss 1.302 | nll_loss 0.71 | ppl 1.64 | wps 23168.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6907 | lr 0.000380501 | gnorm 0.902 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23185
2022-03-06 19:28:55 | INFO | fairseq.trainer | begin training epoch 143
2022-03-06 19:28:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:31:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:31:09 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 14.164 | nll_loss 13.89 | ppl 15183.4 | wps 40749.5 | wpb 510.9 | bsz 1 | num_updates 6956 | best_loss 8.318
2022-03-06 19:31:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6956 updates
2022-03-06 19:31:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:31:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:31:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 143 @ 6956 updates, score 14.164) (writing took 2.548622539266944 seconds)
2022-03-06 19:31:12 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-06 19:31:12 | INFO | train | epoch 143 | loss 1.289 | nll_loss 0.697 | ppl 1.62 | wps 23121.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6956 | lr 0.000379158 | gnorm 0.869 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23322
2022-03-06 19:31:12 | INFO | fairseq.trainer | begin training epoch 144
2022-03-06 19:31:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:33:10 | INFO | train_inner | epoch 144:     44 / 49 loss=1.288, nll_loss=0.696, ppl=1.62, wps=23155, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.887, loss_scale=32, train_wall=239, gb_free=8.8, wall=23440
2022-03-06 19:33:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:33:27 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 14.185 | nll_loss 13.915 | ppl 15449.2 | wps 41256.2 | wpb 510.9 | bsz 1 | num_updates 7005 | best_loss 8.318
2022-03-06 19:33:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7005 updates
2022-03-06 19:33:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:33:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:33:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 144 @ 7005 updates, score 14.185) (writing took 2.5397859364748 seconds)
2022-03-06 19:33:29 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-06 19:33:29 | INFO | train | epoch 144 | loss 1.283 | nll_loss 0.691 | ppl 1.61 | wps 23127 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7005 | lr 0.00037783 | gnorm 0.897 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 23460
2022-03-06 19:33:29 | INFO | fairseq.trainer | begin training epoch 145
2022-03-06 19:33:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:34:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:35:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:35:44 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 14.196 | nll_loss 13.927 | ppl 15580 | wps 40818.5 | wpb 510.9 | bsz 1 | num_updates 7053 | best_loss 8.318
2022-03-06 19:35:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7053 updates
2022-03-06 19:35:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:35:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:35:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 145 @ 7053 updates, score 14.196) (writing took 2.5414150562137365 seconds)
2022-03-06 19:35:47 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-06 19:35:47 | INFO | train | epoch 145 | loss 1.274 | nll_loss 0.681 | ppl 1.6 | wps 22649.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7053 | lr 0.000376542 | gnorm 0.883 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23597
2022-03-06 19:35:47 | INFO | fairseq.trainer | begin training epoch 146
2022-03-06 19:35:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:37:52 | INFO | train_inner | epoch 146:     47 / 49 loss=1.272, nll_loss=0.679, ppl=1.6, wps=22963.2, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.885, loss_scale=16, train_wall=241, gb_free=8.8, wall=23722
2022-03-06 19:37:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:38:01 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 14.239 | nll_loss 13.972 | ppl 16069.7 | wps 41317.1 | wpb 510.9 | bsz 1 | num_updates 7102 | best_loss 8.318
2022-03-06 19:38:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7102 updates
2022-03-06 19:38:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:38:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:38:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 146 @ 7102 updates, score 14.239) (writing took 2.593178369104862 seconds)
2022-03-06 19:38:04 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-06 19:38:04 | INFO | train | epoch 146 | loss 1.267 | nll_loss 0.674 | ppl 1.6 | wps 23183 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7102 | lr 0.00037524 | gnorm 0.887 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23734
2022-03-06 19:38:04 | INFO | fairseq.trainer | begin training epoch 147
2022-03-06 19:38:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:40:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:40:18 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 14.301 | nll_loss 14.04 | ppl 16839 | wps 41140.9 | wpb 510.9 | bsz 1 | num_updates 7151 | best_loss 8.318
2022-03-06 19:40:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7151 updates
2022-03-06 19:40:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:40:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:40:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 147 @ 7151 updates, score 14.301) (writing took 2.4556889086961746 seconds)
2022-03-06 19:40:21 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-06 19:40:21 | INFO | train | epoch 147 | loss 1.254 | nll_loss 0.661 | ppl 1.58 | wps 23259.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7151 | lr 0.000373953 | gnorm 0.846 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 23871
2022-03-06 19:40:21 | INFO | fairseq.trainer | begin training epoch 148
2022-03-06 19:40:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:41:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:42:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:42:35 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 14.265 | nll_loss 13.998 | ppl 16366.1 | wps 41494.3 | wpb 510.9 | bsz 1 | num_updates 7199 | best_loss 8.318
2022-03-06 19:42:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7199 updates
2022-03-06 19:42:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:42:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:42:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 148 @ 7199 updates, score 14.265) (writing took 2.598173640668392 seconds)
2022-03-06 19:42:37 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-06 19:42:37 | INFO | train | epoch 148 | loss 1.248 | nll_loss 0.655 | ppl 1.57 | wps 22777.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7199 | lr 0.000372704 | gnorm 0.855 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 24008
2022-03-06 19:42:37 | INFO | fairseq.trainer | begin training epoch 149
2022-03-06 19:42:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:42:40 | INFO | train_inner | epoch 149:      1 / 49 loss=1.251, nll_loss=0.658, ppl=1.58, wps=22415.9, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=7200, lr=0.000372678, gnorm=0.855, loss_scale=16, train_wall=239, gb_free=8.8, wall=24010
2022-03-06 19:44:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:44:51 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 14.25 | nll_loss 13.987 | ppl 16236.1 | wps 41602.9 | wpb 510.9 | bsz 1 | num_updates 7248 | best_loss 8.318
2022-03-06 19:44:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7248 updates
2022-03-06 19:44:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:44:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:44:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 149 @ 7248 updates, score 14.25) (writing took 2.501383511349559 seconds)
2022-03-06 19:44:54 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-06 19:44:54 | INFO | train | epoch 149 | loss 1.241 | nll_loss 0.647 | ppl 1.57 | wps 23295.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7248 | lr 0.000371442 | gnorm 0.847 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 24144
2022-03-06 19:44:54 | INFO | fairseq.trainer | begin training epoch 150
2022-03-06 19:44:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:47:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:47:08 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 14.267 | nll_loss 14.003 | ppl 16415 | wps 41552.8 | wpb 510.9 | bsz 1 | num_updates 7297 | best_loss 8.318
2022-03-06 19:47:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7297 updates
2022-03-06 19:47:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:47:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:47:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 150 @ 7297 updates, score 14.267) (writing took 2.430103311315179 seconds)
2022-03-06 19:47:10 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-06 19:47:10 | INFO | train | epoch 150 | loss 1.233 | nll_loss 0.639 | ppl 1.56 | wps 23279.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7297 | lr 0.000370193 | gnorm 0.853 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 24280
2022-03-06 19:47:10 | INFO | fairseq.trainer | begin training epoch 151
2022-03-06 19:47:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:47:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:47:21 | INFO | train_inner | epoch 151:      4 / 49 loss=1.236, nll_loss=0.642, ppl=1.56, wps=23095.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=7300, lr=0.000370117, gnorm=0.849, loss_scale=16, train_wall=240, gb_free=8.8, wall=24291
2022-03-06 19:49:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:49:24 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 14.287 | nll_loss 14.025 | ppl 16675.8 | wps 41863.3 | wpb 510.9 | bsz 1 | num_updates 7345 | best_loss 8.318
2022-03-06 19:49:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7345 updates
2022-03-06 19:49:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:49:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:49:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 151 @ 7345 updates, score 14.287) (writing took 2.445892598479986 seconds)
2022-03-06 19:49:26 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-06 19:49:26 | INFO | train | epoch 151 | loss 1.226 | nll_loss 0.633 | ppl 1.55 | wps 22829.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7345 | lr 0.000368981 | gnorm 0.839 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 24417
2022-03-06 19:49:26 | INFO | fairseq.trainer | begin training epoch 152
2022-03-06 19:49:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:51:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:51:40 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 14.358 | nll_loss 14.101 | ppl 17567.9 | wps 41601.8 | wpb 510.9 | bsz 1 | num_updates 7394 | best_loss 8.318
2022-03-06 19:51:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7394 updates
2022-03-06 19:51:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:51:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:51:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 152 @ 7394 updates, score 14.358) (writing took 2.4682684242725372 seconds)
2022-03-06 19:51:43 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-06 19:51:43 | INFO | train | epoch 152 | loss 1.22 | nll_loss 0.626 | ppl 1.54 | wps 23300.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7394 | lr 0.000367756 | gnorm 0.843 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 24553
2022-03-06 19:51:43 | INFO | fairseq.trainer | begin training epoch 153
2022-03-06 19:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:51:59 | INFO | train_inner | epoch 153:      6 / 49 loss=1.222, nll_loss=0.628, ppl=1.55, wps=23332.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=7400, lr=0.000367607, gnorm=0.839, loss_scale=16, train_wall=237, gb_free=8.8, wall=24569
2022-03-06 19:53:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:53:57 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 14.302 | nll_loss 14.035 | ppl 16789.7 | wps 41763.5 | wpb 510.9 | bsz 1 | num_updates 7443 | best_loss 8.318
2022-03-06 19:53:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7443 updates
2022-03-06 19:53:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:53:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:53:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 153 @ 7443 updates, score 14.302) (writing took 2.49100124835968 seconds)
2022-03-06 19:53:59 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-06 19:53:59 | INFO | train | epoch 153 | loss 1.212 | nll_loss 0.618 | ppl 1.53 | wps 23307.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7443 | lr 0.000366544 | gnorm 0.821 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 24690
2022-03-06 19:53:59 | INFO | fairseq.trainer | begin training epoch 154
2022-03-06 19:53:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:56:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:56:13 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 14.366 | nll_loss 14.107 | ppl 17646.9 | wps 41167.6 | wpb 510.9 | bsz 1 | num_updates 7492 | best_loss 8.318
2022-03-06 19:56:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7492 updates
2022-03-06 19:56:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:56:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:56:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 154 @ 7492 updates, score 14.366) (writing took 2.542512306943536 seconds)
2022-03-06 19:56:16 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-06 19:56:16 | INFO | train | epoch 154 | loss 1.204 | nll_loss 0.609 | ppl 1.53 | wps 23285.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7492 | lr 0.000365343 | gnorm 0.817 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 24826
2022-03-06 19:56:16 | INFO | fairseq.trainer | begin training epoch 155
2022-03-06 19:56:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:56:37 | INFO | train_inner | epoch 155:      8 / 49 loss=1.207, nll_loss=0.613, ppl=1.53, wps=23326.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.82, loss_scale=32, train_wall=237, gb_free=8.8, wall=24847
2022-03-06 19:58:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:58:30 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 14.362 | nll_loss 14.106 | ppl 17635.3 | wps 41109.7 | wpb 510.9 | bsz 1 | num_updates 7541 | best_loss 8.318
2022-03-06 19:58:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7541 updates
2022-03-06 19:58:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:58:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:58:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 155 @ 7541 updates, score 14.362) (writing took 2.537649318575859 seconds)
2022-03-06 19:58:32 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-06 19:58:32 | INFO | train | epoch 155 | loss 1.198 | nll_loss 0.604 | ppl 1.52 | wps 23265 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7541 | lr 0.000364154 | gnorm 0.831 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 24963
2022-03-06 19:58:32 | INFO | fairseq.trainer | begin training epoch 156
2022-03-06 19:58:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:59:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:00:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:00:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:00:46 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 14.353 | nll_loss 14.096 | ppl 17512.2 | wps 41367.2 | wpb 510.9 | bsz 1 | num_updates 7588 | best_loss 8.318
2022-03-06 20:00:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7588 updates
2022-03-06 20:00:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:00:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:00:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 156 @ 7588 updates, score 14.353) (writing took 2.5606465321034193 seconds)
2022-03-06 20:00:49 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-06 20:00:49 | INFO | train | epoch 156 | loss 1.189 | nll_loss 0.595 | ppl 1.51 | wps 22305.2 | ups 0.34 | wpb 64829.4 | bsz 126.6 | num_updates 7588 | lr 0.000363025 | gnorm 0.804 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 25099
2022-03-06 20:00:49 | INFO | fairseq.trainer | begin training epoch 157
2022-03-06 20:00:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:01:21 | INFO | train_inner | epoch 157:     12 / 49 loss=1.191, nll_loss=0.597, ppl=1.51, wps=22855.2, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.81, loss_scale=16, train_wall=242, gb_free=8.8, wall=25131
2022-03-06 20:02:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:03:03 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 14.391 | nll_loss 14.136 | ppl 17998.2 | wps 41643.1 | wpb 510.9 | bsz 1 | num_updates 7637 | best_loss 8.318
2022-03-06 20:03:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7637 updates
2022-03-06 20:03:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:03:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:03:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 157 @ 7637 updates, score 14.391) (writing took 2.6344241481274366 seconds)
2022-03-06 20:03:05 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-06 20:03:05 | INFO | train | epoch 157 | loss 1.186 | nll_loss 0.592 | ppl 1.51 | wps 23290.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7637 | lr 0.000361858 | gnorm 0.806 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 25236
2022-03-06 20:03:05 | INFO | fairseq.trainer | begin training epoch 158
2022-03-06 20:03:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:05:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:05:20 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 14.318 | nll_loss 14.061 | ppl 17087.2 | wps 40785.3 | wpb 510.9 | bsz 1 | num_updates 7686 | best_loss 8.318
2022-03-06 20:05:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7686 updates
2022-03-06 20:05:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:05:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:05:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 158 @ 7686 updates, score 14.318) (writing took 2.4738123174756765 seconds)
2022-03-06 20:05:22 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-06 20:05:22 | INFO | train | epoch 158 | loss 1.178 | nll_loss 0.584 | ppl 1.5 | wps 23261.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7686 | lr 0.000360703 | gnorm 0.815 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 25372
2022-03-06 20:05:22 | INFO | fairseq.trainer | begin training epoch 159
2022-03-06 20:05:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:05:59 | INFO | train_inner | epoch 159:     14 / 49 loss=1.18, nll_loss=0.586, ppl=1.5, wps=23308.5, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.81, loss_scale=16, train_wall=237, gb_free=8.8, wall=25409
2022-03-06 20:07:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:07:36 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 14.312 | nll_loss 14.049 | ppl 16953.6 | wps 41486.7 | wpb 510.9 | bsz 1 | num_updates 7735 | best_loss 8.318
2022-03-06 20:07:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7735 updates
2022-03-06 20:07:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:07:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:07:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 159 @ 7735 updates, score 14.312) (writing took 2.4393043536692858 seconds)
2022-03-06 20:07:39 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-06 20:07:39 | INFO | train | epoch 159 | loss 1.171 | nll_loss 0.576 | ppl 1.49 | wps 23280.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7735 | lr 0.000359559 | gnorm 0.786 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 25509
2022-03-06 20:07:39 | INFO | fairseq.trainer | begin training epoch 160
2022-03-06 20:07:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:09:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:09:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:09:53 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 14.387 | nll_loss 14.131 | ppl 17941.7 | wps 41657.4 | wpb 510.9 | bsz 1 | num_updates 7783 | best_loss 8.318
2022-03-06 20:09:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7783 updates
2022-03-06 20:09:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:09:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:09:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 160 @ 7783 updates, score 14.387) (writing took 2.490537280216813 seconds)
2022-03-06 20:09:55 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-06 20:09:55 | INFO | train | epoch 160 | loss 1.165 | nll_loss 0.571 | ppl 1.49 | wps 22804.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7783 | lr 0.000358448 | gnorm 0.791 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 25645
2022-03-06 20:09:55 | INFO | fairseq.trainer | begin training epoch 161
2022-03-06 20:09:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:10:40 | INFO | train_inner | epoch 161:     17 / 49 loss=1.166, nll_loss=0.572, ppl=1.49, wps=23080.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.793, loss_scale=16, train_wall=240, gb_free=8.8, wall=25690
2022-03-06 20:12:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:12:09 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 14.358 | nll_loss 14.101 | ppl 17567.3 | wps 41300.7 | wpb 510.9 | bsz 1 | num_updates 7832 | best_loss 8.318
2022-03-06 20:12:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7832 updates
2022-03-06 20:12:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:12:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:12:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 161 @ 7832 updates, score 14.358) (writing took 2.4609516505151987 seconds)
2022-03-06 20:12:11 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-06 20:12:11 | INFO | train | epoch 161 | loss 1.159 | nll_loss 0.565 | ppl 1.48 | wps 23305.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7832 | lr 0.000357325 | gnorm 0.785 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 25782
2022-03-06 20:12:11 | INFO | fairseq.trainer | begin training epoch 162
2022-03-06 20:12:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:14:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:14:26 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 14.409 | nll_loss 14.158 | ppl 18283.2 | wps 41470.7 | wpb 510.9 | bsz 1 | num_updates 7881 | best_loss 8.318
2022-03-06 20:14:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7881 updates
2022-03-06 20:14:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:14:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:14:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 162 @ 7881 updates, score 14.409) (writing took 2.4354534056037664 seconds)
2022-03-06 20:14:28 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-06 20:14:28 | INFO | train | epoch 162 | loss 1.156 | nll_loss 0.562 | ppl 1.48 | wps 23235.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7881 | lr 0.000356213 | gnorm 0.787 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 25918
2022-03-06 20:14:28 | INFO | fairseq.trainer | begin training epoch 163
2022-03-06 20:14:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:15:19 | INFO | train_inner | epoch 163:     19 / 49 loss=1.155, nll_loss=0.561, ppl=1.48, wps=23294.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.781, loss_scale=32, train_wall=238, gb_free=8.8, wall=25969
2022-03-06 20:16:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:16:42 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 14.414 | nll_loss 14.16 | ppl 18302.7 | wps 41237.3 | wpb 510.9 | bsz 1 | num_updates 7930 | best_loss 8.318
2022-03-06 20:16:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7930 updates
2022-03-06 20:16:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:16:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:16:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 163 @ 7930 updates, score 14.414) (writing took 2.5026935152709484 seconds)
2022-03-06 20:16:45 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-06 20:16:45 | INFO | train | epoch 163 | loss 1.148 | nll_loss 0.554 | ppl 1.47 | wps 23245.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7930 | lr 0.00035511 | gnorm 0.781 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 26055
2022-03-06 20:16:45 | INFO | fairseq.trainer | begin training epoch 164
2022-03-06 20:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:17:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:18:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:19:00 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 14.456 | nll_loss 14.204 | ppl 18868.5 | wps 40737 | wpb 510.9 | bsz 1 | num_updates 7978 | best_loss 8.318
2022-03-06 20:19:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7978 updates
2022-03-06 20:19:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:19:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:19:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 164 @ 7978 updates, score 14.456) (writing took 2.5176182333379984 seconds)
2022-03-06 20:19:03 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-06 20:19:03 | INFO | train | epoch 164 | loss 1.142 | nll_loss 0.548 | ppl 1.46 | wps 22606.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7978 | lr 0.000354041 | gnorm 0.755 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 26193
2022-03-06 20:19:03 | INFO | fairseq.trainer | begin training epoch 165
2022-03-06 20:19:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:20:01 | INFO | train_inner | epoch 165:     22 / 49 loss=1.143, nll_loss=0.549, ppl=1.46, wps=22946.2, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.766, loss_scale=16, train_wall=241, gb_free=8.8, wall=26252
2022-03-06 20:21:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:21:17 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 14.468 | nll_loss 14.221 | ppl 19091.8 | wps 41725.7 | wpb 510.9 | bsz 1 | num_updates 8027 | best_loss 8.318
2022-03-06 20:21:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8027 updates
2022-03-06 20:21:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:21:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:21:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 165 @ 8027 updates, score 14.468) (writing took 2.5222679413855076 seconds)
2022-03-06 20:21:19 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-06 20:21:19 | INFO | train | epoch 165 | loss 1.137 | nll_loss 0.543 | ppl 1.46 | wps 23220.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8027 | lr 0.000352958 | gnorm 0.761 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 26330
2022-03-06 20:21:19 | INFO | fairseq.trainer | begin training epoch 166
2022-03-06 20:21:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:23:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:23:33 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 14.493 | nll_loss 14.245 | ppl 19413.2 | wps 41583.5 | wpb 510.9 | bsz 1 | num_updates 8076 | best_loss 8.318
2022-03-06 20:23:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8076 updates
2022-03-06 20:23:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:23:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:23:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 166 @ 8076 updates, score 14.493) (writing took 2.551928700879216 seconds)
2022-03-06 20:23:36 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-06 20:23:36 | INFO | train | epoch 166 | loss 1.131 | nll_loss 0.537 | ppl 1.45 | wps 23305.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8076 | lr 0.000351886 | gnorm 0.76 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 26466
2022-03-06 20:23:36 | INFO | fairseq.trainer | begin training epoch 167
2022-03-06 20:23:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:24:40 | INFO | train_inner | epoch 167:     24 / 49 loss=1.131, nll_loss=0.537, ppl=1.45, wps=23316.5, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.76, loss_scale=32, train_wall=237, gb_free=8.8, wall=26530
2022-03-06 20:25:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:25:50 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 14.444 | nll_loss 14.196 | ppl 18769 | wps 41509.4 | wpb 510.9 | bsz 1 | num_updates 8125 | best_loss 8.318
2022-03-06 20:25:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8125 updates
2022-03-06 20:25:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:25:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:25:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 167 @ 8125 updates, score 14.444) (writing took 2.516138941049576 seconds)
2022-03-06 20:25:53 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-06 20:25:53 | INFO | train | epoch 167 | loss 1.126 | nll_loss 0.532 | ppl 1.45 | wps 23235.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8125 | lr 0.000350823 | gnorm 0.757 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 26603
2022-03-06 20:25:53 | INFO | fairseq.trainer | begin training epoch 168
2022-03-06 20:25:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:28:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:28:07 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 14.378 | nll_loss 14.123 | ppl 17836.9 | wps 41084.5 | wpb 510.9 | bsz 1 | num_updates 8174 | best_loss 8.318
2022-03-06 20:28:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8174 updates
2022-03-06 20:28:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:28:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:28:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 168 @ 8174 updates, score 14.378) (writing took 2.541927020996809 seconds)
2022-03-06 20:28:10 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-06 20:28:10 | INFO | train | epoch 168 | loss 1.122 | nll_loss 0.528 | ppl 1.44 | wps 23155.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8174 | lr 0.00034977 | gnorm 0.752 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 26740
2022-03-06 20:28:10 | INFO | fairseq.trainer | begin training epoch 169
2022-03-06 20:28:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:28:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:29:22 | INFO | train_inner | epoch 169:     27 / 49 loss=1.121, nll_loss=0.528, ppl=1.44, wps=22983.9, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.751, loss_scale=16, train_wall=241, gb_free=8.8, wall=26812
2022-03-06 20:30:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:30:25 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 14.494 | nll_loss 14.241 | ppl 19364.5 | wps 40962.6 | wpb 510.9 | bsz 1 | num_updates 8222 | best_loss 8.318
2022-03-06 20:30:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8222 updates
2022-03-06 20:30:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:30:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:30:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 169 @ 8222 updates, score 14.494) (writing took 2.4770550206303596 seconds)
2022-03-06 20:30:27 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-06 20:30:27 | INFO | train | epoch 169 | loss 1.116 | nll_loss 0.522 | ppl 1.44 | wps 22679.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 8222 | lr 0.000348748 | gnorm 0.745 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 26877
2022-03-06 20:30:27 | INFO | fairseq.trainer | begin training epoch 170
2022-03-06 20:30:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:32:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:32:42 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 14.335 | nll_loss 14.081 | ppl 17324.5 | wps 41248.7 | wpb 510.9 | bsz 1 | num_updates 8271 | best_loss 8.318
2022-03-06 20:32:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8271 updates
2022-03-06 20:32:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:32:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:32:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 170 @ 8271 updates, score 14.335) (writing took 2.494704170152545 seconds)
2022-03-06 20:32:44 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-06 20:32:44 | INFO | train | epoch 170 | loss 1.113 | nll_loss 0.52 | ppl 1.43 | wps 23181.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8271 | lr 0.000347713 | gnorm 0.748 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 27014
2022-03-06 20:32:44 | INFO | fairseq.trainer | begin training epoch 171
2022-03-06 20:32:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:34:01 | INFO | train_inner | epoch 171:     29 / 49 loss=1.111, nll_loss=0.518, ppl=1.43, wps=23212.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.741, loss_scale=16, train_wall=239, gb_free=8.8, wall=27092
2022-03-06 20:34:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:34:59 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 14.384 | nll_loss 14.136 | ppl 18002.4 | wps 41581 | wpb 510.9 | bsz 1 | num_updates 8320 | best_loss 8.318
2022-03-06 20:34:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8320 updates
2022-03-06 20:34:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:35:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:35:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 171 @ 8320 updates, score 14.384) (writing took 2.442015379667282 seconds)
2022-03-06 20:35:01 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-06 20:35:01 | INFO | train | epoch 171 | loss 1.109 | nll_loss 0.516 | ppl 1.43 | wps 23208 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8320 | lr 0.000346688 | gnorm 0.734 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 27151
2022-03-06 20:35:01 | INFO | fairseq.trainer | begin training epoch 172
2022-03-06 20:35:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:37:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:37:16 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 14.416 | nll_loss 14.168 | ppl 18406.4 | wps 41215.8 | wpb 510.9 | bsz 1 | num_updates 8369 | best_loss 8.318
2022-03-06 20:37:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8369 updates
2022-03-06 20:37:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:37:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:37:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 172 @ 8369 updates, score 14.416) (writing took 2.522226296365261 seconds)
2022-03-06 20:37:18 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-06 20:37:18 | INFO | train | epoch 172 | loss 1.102 | nll_loss 0.508 | ppl 1.42 | wps 23166.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8369 | lr 0.000345671 | gnorm 0.73 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 27289
2022-03-06 20:37:18 | INFO | fairseq.trainer | begin training epoch 173
2022-03-06 20:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:38:41 | INFO | train_inner | epoch 173:     31 / 49 loss=1.103, nll_loss=0.51, ppl=1.42, wps=23199, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.731, loss_scale=32, train_wall=239, gb_free=8.8, wall=27371
2022-03-06 20:39:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:39:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:39:33 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 14.409 | nll_loss 14.163 | ppl 18345.5 | wps 40658.2 | wpb 510.9 | bsz 1 | num_updates 8417 | best_loss 8.318
2022-03-06 20:39:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8417 updates
2022-03-06 20:39:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:39:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:39:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 173 @ 8417 updates, score 14.409) (writing took 2.6188786290585995 seconds)
2022-03-06 20:39:36 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-06 20:39:36 | INFO | train | epoch 173 | loss 1.099 | nll_loss 0.506 | ppl 1.42 | wps 22627.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 8417 | lr 0.000344684 | gnorm 0.728 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 27426
2022-03-06 20:39:36 | INFO | fairseq.trainer | begin training epoch 174
2022-03-06 20:39:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:41:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:41:51 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 14.436 | nll_loss 14.188 | ppl 18665.2 | wps 40960.2 | wpb 510.9 | bsz 1 | num_updates 8466 | best_loss 8.318
2022-03-06 20:41:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8466 updates
2022-03-06 20:41:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:41:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:41:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 174 @ 8466 updates, score 14.436) (writing took 2.61072881706059 seconds)
2022-03-06 20:41:53 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-06 20:41:53 | INFO | train | epoch 174 | loss 1.092 | nll_loss 0.499 | ppl 1.41 | wps 23132.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8466 | lr 0.000343685 | gnorm 0.724 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 27563
2022-03-06 20:41:53 | INFO | fairseq.trainer | begin training epoch 175
2022-03-06 20:41:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:43:24 | INFO | train_inner | epoch 175:     34 / 49 loss=1.092, nll_loss=0.499, ppl=1.41, wps=22913.1, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.719, loss_scale=16, train_wall=241, gb_free=8.8, wall=27654
2022-03-06 20:44:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:44:08 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 14.511 | nll_loss 14.268 | ppl 19723.3 | wps 41428.4 | wpb 510.9 | bsz 1 | num_updates 8515 | best_loss 8.318
2022-03-06 20:44:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8515 updates
2022-03-06 20:44:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:44:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:44:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 175 @ 8515 updates, score 14.511) (writing took 2.5521477181464434 seconds)
2022-03-06 20:44:10 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-06 20:44:10 | INFO | train | epoch 175 | loss 1.087 | nll_loss 0.495 | ppl 1.41 | wps 23155.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8515 | lr 0.000342695 | gnorm 0.713 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 27701
2022-03-06 20:44:10 | INFO | fairseq.trainer | begin training epoch 176
2022-03-06 20:44:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:45:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:46:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:46:25 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 14.522 | nll_loss 14.279 | ppl 19886.4 | wps 41486.5 | wpb 510.9 | bsz 1 | num_updates 8563 | best_loss 8.318
2022-03-06 20:46:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8563 updates
2022-03-06 20:46:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:46:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:46:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 176 @ 8563 updates, score 14.522) (writing took 2.4223321340978146 seconds)
2022-03-06 20:46:27 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-06 20:46:27 | INFO | train | epoch 176 | loss 1.084 | nll_loss 0.492 | ppl 1.41 | wps 22783.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 8563 | lr 0.000341733 | gnorm 0.722 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 27837
2022-03-06 20:46:27 | INFO | fairseq.trainer | begin training epoch 177
2022-03-06 20:46:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:48:05 | INFO | train_inner | epoch 177:     37 / 49 loss=1.083, nll_loss=0.491, ppl=1.41, wps=23076.2, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.718, loss_scale=16, train_wall=240, gb_free=8.8, wall=27936
2022-03-06 20:48:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:48:41 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 14.451 | nll_loss 14.204 | ppl 18878.6 | wps 41670.1 | wpb 510.9 | bsz 1 | num_updates 8612 | best_loss 8.318
2022-03-06 20:48:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8612 updates
2022-03-06 20:48:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:48:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:48:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 177 @ 8612 updates, score 14.451) (writing took 2.441380562260747 seconds)
2022-03-06 20:48:43 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-06 20:48:43 | INFO | train | epoch 177 | loss 1.08 | nll_loss 0.488 | ppl 1.4 | wps 23305.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8612 | lr 0.00034076 | gnorm 0.716 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 27974
2022-03-06 20:48:43 | INFO | fairseq.trainer | begin training epoch 178
2022-03-06 20:48:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:50:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:50:57 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 14.372 | nll_loss 14.121 | ppl 17812.4 | wps 40908.4 | wpb 510.9 | bsz 1 | num_updates 8661 | best_loss 8.318
2022-03-06 20:50:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8661 updates
2022-03-06 20:50:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:51:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:51:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 178 @ 8661 updates, score 14.372) (writing took 2.5070457477122545 seconds)
2022-03-06 20:51:00 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-06 20:51:00 | INFO | train | epoch 178 | loss 1.073 | nll_loss 0.481 | ppl 1.4 | wps 23284 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8661 | lr 0.000339794 | gnorm 0.696 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 28110
2022-03-06 20:51:00 | INFO | fairseq.trainer | begin training epoch 179
2022-03-06 20:51:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:52:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:52:46 | INFO | train_inner | epoch 179:     40 / 49 loss=1.073, nll_loss=0.481, ppl=1.4, wps=23102.1, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.706, loss_scale=16, train_wall=240, gb_free=8.8, wall=28216
2022-03-06 20:53:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:53:14 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 14.446 | nll_loss 14.203 | ppl 18852.9 | wps 41321.5 | wpb 510.9 | bsz 1 | num_updates 8709 | best_loss 8.318
2022-03-06 20:53:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8709 updates
2022-03-06 20:53:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:53:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:53:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 179 @ 8709 updates, score 14.446) (writing took 2.4953177627176046 seconds)
2022-03-06 20:53:16 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-06 20:53:16 | INFO | train | epoch 179 | loss 1.07 | nll_loss 0.478 | ppl 1.39 | wps 22814.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 8709 | lr 0.000338857 | gnorm 0.709 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 28247
2022-03-06 20:53:16 | INFO | fairseq.trainer | begin training epoch 180
2022-03-06 20:53:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:55:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:55:30 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 14.398 | nll_loss 14.154 | ppl 18235.5 | wps 41480 | wpb 510.9 | bsz 1 | num_updates 8758 | best_loss 8.318
2022-03-06 20:55:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8758 updates
2022-03-06 20:55:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:55:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:55:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 180 @ 8758 updates, score 14.398) (writing took 2.4350199811160564 seconds)
2022-03-06 20:55:33 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-06 20:55:33 | INFO | train | epoch 180 | loss 1.067 | nll_loss 0.475 | ppl 1.39 | wps 23318.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8758 | lr 0.000337907 | gnorm 0.703 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 28383
2022-03-06 20:55:33 | INFO | fairseq.trainer | begin training epoch 181
2022-03-06 20:55:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:57:24 | INFO | train_inner | epoch 181:     42 / 49 loss=1.065, nll_loss=0.473, ppl=1.39, wps=23322.4, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.697, loss_scale=16, train_wall=237, gb_free=8.8, wall=28494
2022-03-06 20:57:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:57:47 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 14.499 | nll_loss 14.256 | ppl 19571.9 | wps 41456.6 | wpb 510.9 | bsz 1 | num_updates 8807 | best_loss 8.318
2022-03-06 20:57:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8807 updates
2022-03-06 20:57:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:57:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:57:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 181 @ 8807 updates, score 14.499) (writing took 2.577132409438491 seconds)
2022-03-06 20:57:49 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-06 20:57:49 | INFO | train | epoch 181 | loss 1.061 | nll_loss 0.47 | ppl 1.38 | wps 23256.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8807 | lr 0.000336966 | gnorm 0.692 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 28520
2022-03-06 20:57:49 | INFO | fairseq.trainer | begin training epoch 182
2022-03-06 20:57:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:59:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:59:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:00:03 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 14.389 | nll_loss 14.143 | ppl 18094.5 | wps 41782.3 | wpb 510.9 | bsz 1 | num_updates 8855 | best_loss 8.318
2022-03-06 21:00:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8855 updates
2022-03-06 21:00:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:00:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:00:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 182 @ 8855 updates, score 14.389) (writing took 2.5641190372407436 seconds)
2022-03-06 21:00:06 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-06 21:00:06 | INFO | train | epoch 182 | loss 1.059 | nll_loss 0.468 | ppl 1.38 | wps 22781.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 8855 | lr 0.000336051 | gnorm 0.69 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 28656
2022-03-06 21:00:06 | INFO | fairseq.trainer | begin training epoch 183
2022-03-06 21:00:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:02:05 | INFO | train_inner | epoch 183:     45 / 49 loss=1.057, nll_loss=0.466, ppl=1.38, wps=23075.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.688, loss_scale=16, train_wall=240, gb_free=8.8, wall=28776
2022-03-06 21:02:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:02:20 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 14.477 | nll_loss 14.235 | ppl 19287.1 | wps 41069.8 | wpb 510.9 | bsz 1 | num_updates 8904 | best_loss 8.318
2022-03-06 21:02:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8904 updates
2022-03-06 21:02:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:02:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:02:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 183 @ 8904 updates, score 14.477) (writing took 2.5811763796955347 seconds)
2022-03-06 21:02:23 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-06 21:02:23 | INFO | train | epoch 183 | loss 1.053 | nll_loss 0.462 | ppl 1.38 | wps 23254.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8904 | lr 0.000335125 | gnorm 0.682 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 28793
2022-03-06 21:02:23 | INFO | fairseq.trainer | begin training epoch 184
2022-03-06 21:02:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:04:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:04:37 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 14.476 | nll_loss 14.235 | ppl 19286.3 | wps 41207.9 | wpb 510.9 | bsz 1 | num_updates 8953 | best_loss 8.318
2022-03-06 21:04:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8953 updates
2022-03-06 21:04:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:04:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:04:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 184 @ 8953 updates, score 14.476) (writing took 2.583520730957389 seconds)
2022-03-06 21:04:39 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-06 21:04:39 | INFO | train | epoch 184 | loss 1.053 | nll_loss 0.462 | ppl 1.38 | wps 23251.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8953 | lr 0.000334207 | gnorm 0.705 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 28930
2022-03-06 21:04:39 | INFO | fairseq.trainer | begin training epoch 185
2022-03-06 21:04:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:05:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:06:47 | INFO | train_inner | epoch 185:     48 / 49 loss=1.05, nll_loss=0.459, ppl=1.37, wps=23058.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.692, loss_scale=16, train_wall=240, gb_free=8.8, wall=29057
2022-03-06 21:06:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:06:53 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 14.518 | nll_loss 14.278 | ppl 19863 | wps 41721.2 | wpb 510.9 | bsz 1 | num_updates 9001 | best_loss 8.318
2022-03-06 21:06:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9001 updates
2022-03-06 21:06:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:06:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:06:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 185 @ 9001 updates, score 14.518) (writing took 2.736186310648918 seconds)
2022-03-06 21:06:56 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-06 21:06:56 | INFO | train | epoch 185 | loss 1.045 | nll_loss 0.455 | ppl 1.37 | wps 22759.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 9001 | lr 0.000333315 | gnorm 0.679 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 29066
2022-03-06 21:06:56 | INFO | fairseq.trainer | begin training epoch 186
2022-03-06 21:06:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:09:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:09:10 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 14.487 | nll_loss 14.25 | ppl 19485.2 | wps 41300.9 | wpb 510.9 | bsz 1 | num_updates 9050 | best_loss 8.318
2022-03-06 21:09:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9050 updates
2022-03-06 21:09:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:09:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:09:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 186 @ 9050 updates, score 14.487) (writing took 2.544513450935483 seconds)
2022-03-06 21:09:12 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-06 21:09:12 | INFO | train | epoch 186 | loss 1.044 | nll_loss 0.453 | ppl 1.37 | wps 23298.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9050 | lr 0.000332411 | gnorm 0.682 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 29203
2022-03-06 21:09:12 | INFO | fairseq.trainer | begin training epoch 187
2022-03-06 21:09:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:11:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:11:26 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 14.479 | nll_loss 14.237 | ppl 19307.9 | wps 41073.9 | wpb 510.9 | bsz 1 | num_updates 9099 | best_loss 8.318
2022-03-06 21:11:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9099 updates
2022-03-06 21:11:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:11:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:11:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 187 @ 9099 updates, score 14.479) (writing took 2.481301559135318 seconds)
2022-03-06 21:11:29 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-06 21:11:29 | INFO | train | epoch 187 | loss 1.041 | nll_loss 0.451 | ppl 1.37 | wps 23293.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9099 | lr 0.000331515 | gnorm 0.673 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 29339
2022-03-06 21:11:29 | INFO | fairseq.trainer | begin training epoch 188
2022-03-06 21:11:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:11:32 | INFO | train_inner | epoch 188:      1 / 49 loss=1.042, nll_loss=0.452, ppl=1.37, wps=22649.3, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=9100, lr=0.000331497, gnorm=0.679, loss_scale=16, train_wall=236, gb_free=8.8, wall=29342
2022-03-06 21:13:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:13:43 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 14.51 | nll_loss 14.273 | ppl 19798.8 | wps 41517.2 | wpb 510.9 | bsz 1 | num_updates 9148 | best_loss 8.318
2022-03-06 21:13:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9148 updates
2022-03-06 21:13:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:13:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:13:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 188 @ 9148 updates, score 14.51) (writing took 2.4560394193977118 seconds)
2022-03-06 21:13:45 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-06 21:13:45 | INFO | train | epoch 188 | loss 1.037 | nll_loss 0.447 | ppl 1.36 | wps 23296.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9148 | lr 0.000330626 | gnorm 0.681 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 29476
2022-03-06 21:13:45 | INFO | fairseq.trainer | begin training epoch 189
2022-03-06 21:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:14:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:15:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:15:59 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 14.46 | nll_loss 14.221 | ppl 19096 | wps 41061.5 | wpb 510.9 | bsz 1 | num_updates 9196 | best_loss 8.318
2022-03-06 21:15:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9196 updates
2022-03-06 21:15:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:16:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:16:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 189 @ 9196 updates, score 14.46) (writing took 2.4432548321783543 seconds)
2022-03-06 21:16:02 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-06 21:16:02 | INFO | train | epoch 189 | loss 1.032 | nll_loss 0.442 | ppl 1.36 | wps 22827.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 9196 | lr 0.000329762 | gnorm 0.671 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 29612
2022-03-06 21:16:02 | INFO | fairseq.trainer | begin training epoch 190
2022-03-06 21:16:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:16:12 | INFO | train_inner | epoch 190:      4 / 49 loss=1.034, nll_loss=0.444, ppl=1.36, wps=23104, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=9200, lr=0.00032969, gnorm=0.675, loss_scale=16, train_wall=240, gb_free=8.8, wall=29623
2022-03-06 21:18:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:18:16 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 14.556 | nll_loss 14.323 | ppl 20498.6 | wps 41492.9 | wpb 510.9 | bsz 1 | num_updates 9245 | best_loss 8.318
2022-03-06 21:18:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9245 updates
2022-03-06 21:18:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:18:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:18:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 190 @ 9245 updates, score 14.556) (writing took 2.5144245605915785 seconds)
2022-03-06 21:18:18 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-06 21:18:18 | INFO | train | epoch 190 | loss 1.029 | nll_loss 0.439 | ppl 1.36 | wps 23258.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9245 | lr 0.000328887 | gnorm 0.668 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 29749
2022-03-06 21:18:18 | INFO | fairseq.trainer | begin training epoch 191
2022-03-06 21:18:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:20:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:20:32 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 14.387 | nll_loss 14.146 | ppl 18132.9 | wps 41391.8 | wpb 510.9 | bsz 1 | num_updates 9294 | best_loss 8.318
2022-03-06 21:20:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9294 updates
2022-03-06 21:20:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:20:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:20:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 191 @ 9294 updates, score 14.387) (writing took 2.513109838590026 seconds)
2022-03-06 21:20:35 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-06 21:20:35 | INFO | train | epoch 191 | loss 1.026 | nll_loss 0.436 | ppl 1.35 | wps 23269.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9294 | lr 0.000328019 | gnorm 0.664 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 29885
2022-03-06 21:20:35 | INFO | fairseq.trainer | begin training epoch 192
2022-03-06 21:20:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:20:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:20:53 | INFO | train_inner | epoch 192:      7 / 49 loss=1.027, nll_loss=0.437, ppl=1.35, wps=23081.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.667, loss_scale=16, train_wall=240, gb_free=8.8, wall=29904
2022-03-06 21:22:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:22:50 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 14.368 | nll_loss 14.126 | ppl 17879.1 | wps 40341 | wpb 510.9 | bsz 1 | num_updates 9342 | best_loss 8.318
2022-03-06 21:22:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9342 updates
2022-03-06 21:22:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:22:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:22:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 192 @ 9342 updates, score 14.368) (writing took 2.5582549553364515 seconds)
2022-03-06 21:22:53 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-06 21:22:53 | INFO | train | epoch 192 | loss 1.022 | nll_loss 0.432 | ppl 1.35 | wps 22566.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 9342 | lr 0.000327175 | gnorm 0.66 | loss_scale 16 | train_wall 118 | gb_free 8.8 | wall 30023
2022-03-06 21:22:53 | INFO | fairseq.trainer | begin training epoch 193
2022-03-06 21:22:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:25:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:25:09 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 14.466 | nll_loss 14.227 | ppl 19181.4 | wps 40163.9 | wpb 510.9 | bsz 1 | num_updates 9391 | best_loss 8.318
2022-03-06 21:25:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9391 updates
2022-03-06 21:25:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:25:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:25:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 193 @ 9391 updates, score 14.466) (writing took 2.4841783307492733 seconds)
2022-03-06 21:25:12 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-06 21:25:12 | INFO | train | epoch 193 | loss 1.018 | nll_loss 0.429 | ppl 1.35 | wps 22884.7 | ups 0.35 | wpb 64858.2 | bsz 126.7 | num_updates 9391 | lr 0.00032632 | gnorm 0.65 | loss_scale 16 | train_wall 118 | gb_free 8.8 | wall 30162
2022-03-06 21:25:12 | INFO | fairseq.trainer | begin training epoch 194
2022-03-06 21:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:25:36 | INFO | train_inner | epoch 194:      9 / 49 loss=1.019, nll_loss=0.429, ppl=1.35, wps=22959.1, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.652, loss_scale=16, train_wall=241, gb_free=8.8, wall=30186
2022-03-06 21:26:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:27:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:27:26 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 14.458 | nll_loss 14.22 | ppl 19089 | wps 41622.8 | wpb 510.9 | bsz 1 | num_updates 9439 | best_loss 8.318
2022-03-06 21:27:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9439 updates
2022-03-06 21:27:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:27:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:27:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 194 @ 9439 updates, score 14.458) (writing took 2.432874431833625 seconds)
2022-03-06 21:27:29 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-06 21:27:29 | INFO | train | epoch 194 | loss 1.016 | nll_loss 0.427 | ppl 1.34 | wps 22699 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 9439 | lr 0.00032549 | gnorm 0.655 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 30299
2022-03-06 21:27:29 | INFO | fairseq.trainer | begin training epoch 195
2022-03-06 21:27:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:29:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:29:43 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 14.534 | nll_loss 14.302 | ppl 20196.4 | wps 41801.6 | wpb 510.9 | bsz 1 | num_updates 9488 | best_loss 8.318
2022-03-06 21:29:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9488 updates
2022-03-06 21:29:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:29:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:29:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 195 @ 9488 updates, score 14.534) (writing took 2.4596117734909058 seconds)
2022-03-06 21:29:45 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-06 21:29:45 | INFO | train | epoch 195 | loss 1.014 | nll_loss 0.425 | ppl 1.34 | wps 23305 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9488 | lr 0.000324648 | gnorm 0.652 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 30435
2022-03-06 21:29:45 | INFO | fairseq.trainer | begin training epoch 196
2022-03-06 21:29:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:30:17 | INFO | train_inner | epoch 196:     12 / 49 loss=1.014, nll_loss=0.425, ppl=1.34, wps=23075.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.652, loss_scale=16, train_wall=240, gb_free=8.8, wall=30467
2022-03-06 21:31:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:32:00 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 14.525 | nll_loss 14.296 | ppl 20111.4 | wps 41728.5 | wpb 510.9 | bsz 1 | num_updates 9537 | best_loss 8.318
2022-03-06 21:32:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9537 updates
2022-03-06 21:32:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:32:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:32:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 196 @ 9537 updates, score 14.525) (writing took 2.6096483431756496 seconds)
2022-03-06 21:32:02 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-06 21:32:02 | INFO | train | epoch 196 | loss 1.009 | nll_loss 0.421 | ppl 1.34 | wps 23180.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9537 | lr 0.000323813 | gnorm 0.633 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 30573
2022-03-06 21:32:02 | INFO | fairseq.trainer | begin training epoch 197
2022-03-06 21:32:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:33:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:34:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:34:17 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 14.413 | nll_loss 14.177 | ppl 18520.6 | wps 41154.9 | wpb 510.9 | bsz 1 | num_updates 9585 | best_loss 8.318
2022-03-06 21:34:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9585 updates
2022-03-06 21:34:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:34:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:34:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 197 @ 9585 updates, score 14.413) (writing took 2.5088252499699593 seconds)
2022-03-06 21:34:19 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-06 21:34:19 | INFO | train | epoch 197 | loss 1.006 | nll_loss 0.418 | ppl 1.34 | wps 22691.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 9585 | lr 0.000323001 | gnorm 0.637 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 30710
2022-03-06 21:34:19 | INFO | fairseq.trainer | begin training epoch 198
2022-03-06 21:34:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:35:00 | INFO | train_inner | epoch 198:     15 / 49 loss=1.006, nll_loss=0.418, ppl=1.34, wps=22972.5, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.634, loss_scale=16, train_wall=241, gb_free=8.8, wall=30750
2022-03-06 21:36:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:36:32 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 14.537 | nll_loss 14.306 | ppl 20249.2 | wps 46152.5 | wpb 510.9 | bsz 1 | num_updates 9634 | best_loss 8.318
2022-03-06 21:36:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9634 updates
2022-03-06 21:36:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:36:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:36:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 198 @ 9634 updates, score 14.537) (writing took 2.5098908934742212 seconds)
2022-03-06 21:36:34 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-06 21:36:34 | INFO | train | epoch 198 | loss 1.003 | nll_loss 0.415 | ppl 1.33 | wps 23541.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9634 | lr 0.000322179 | gnorm 0.637 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 30845
2022-03-06 21:36:34 | INFO | fairseq.trainer | begin training epoch 199
2022-03-06 21:36:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:38:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:38:41 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 14.567 | nll_loss 14.334 | ppl 20649 | wps 45545.5 | wpb 510.9 | bsz 1 | num_updates 9683 | best_loss 8.318
2022-03-06 21:38:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9683 updates
2022-03-06 21:38:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:38:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:38:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 199 @ 9683 updates, score 14.567) (writing took 2.5031329225748777 seconds)
2022-03-06 21:38:43 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-06 21:38:43 | INFO | train | epoch 199 | loss 1 | nll_loss 0.412 | ppl 1.33 | wps 24639.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9683 | lr 0.000321362 | gnorm 0.635 | loss_scale 16 | train_wall 110 | gb_free 8.8 | wall 30974
2022-03-06 21:38:43 | INFO | fairseq.trainer | begin training epoch 200
2022-03-06 21:38:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:39:26 | INFO | train_inner | epoch 200:     17 / 49 loss=1.001, nll_loss=0.413, ppl=1.33, wps=24326, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.638, loss_scale=16, train_wall=227, gb_free=8.8, wall=31016
2022-03-06 21:40:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:40:50 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 14.468 | nll_loss 14.237 | ppl 19313.7 | wps 46149.8 | wpb 510.9 | bsz 1 | num_updates 9732 | best_loss 8.318
2022-03-06 21:40:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9732 updates
2022-03-06 21:40:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:40:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:40:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 200 @ 9732 updates, score 14.468) (writing took 2.489978611469269 seconds)
2022-03-06 21:40:52 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-06 21:40:52 | INFO | train | epoch 200 | loss 0.996 | nll_loss 0.409 | ppl 1.33 | wps 24623.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9732 | lr 0.000320552 | gnorm 0.634 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 31103
2022-03-06 21:40:52 | INFO | fairseq.trainer | begin training epoch 201
2022-03-06 21:40:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:42:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:42:59 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 14.547 | nll_loss 14.318 | ppl 20419.6 | wps 46259.1 | wpb 510.9 | bsz 1 | num_updates 9781 | best_loss 8.318
2022-03-06 21:42:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9781 updates
2022-03-06 21:42:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:43:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:43:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 201 @ 9781 updates, score 14.547) (writing took 2.514826998114586 seconds)
2022-03-06 21:43:01 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-06 21:43:01 | INFO | train | epoch 201 | loss 0.993 | nll_loss 0.406 | ppl 1.32 | wps 24646.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9781 | lr 0.000319748 | gnorm 0.617 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 31232
2022-03-06 21:43:01 | INFO | fairseq.trainer | begin training epoch 202
2022-03-06 21:43:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:43:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:43:52 | INFO | train_inner | epoch 202:     20 / 49 loss=0.994, nll_loss=0.406, ppl=1.33, wps=24443.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.626, loss_scale=16, train_wall=226, gb_free=8.8, wall=31282
2022-03-06 21:45:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:45:08 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 14.582 | nll_loss 14.354 | ppl 20946.8 | wps 45972.7 | wpb 510.9 | bsz 1 | num_updates 9829 | best_loss 8.318
2022-03-06 21:45:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9829 updates
2022-03-06 21:45:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:45:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:45:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 202 @ 9829 updates, score 14.582) (writing took 2.540774028748274 seconds)
2022-03-06 21:45:10 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-06 21:45:10 | INFO | train | epoch 202 | loss 0.992 | nll_loss 0.405 | ppl 1.32 | wps 24121.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 9829 | lr 0.000318967 | gnorm 0.632 | loss_scale 16 | train_wall 110 | gb_free 8.8 | wall 31361
2022-03-06 21:45:10 | INFO | fairseq.trainer | begin training epoch 203
2022-03-06 21:45:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:47:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:47:17 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 14.387 | nll_loss 14.153 | ppl 18216 | wps 46308 | wpb 510.9 | bsz 1 | num_updates 9878 | best_loss 8.318
2022-03-06 21:47:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9878 updates
2022-03-06 21:47:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:47:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:47:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 203 @ 9878 updates, score 14.387) (writing took 2.534111151471734 seconds)
2022-03-06 21:47:19 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-06 21:47:19 | INFO | train | epoch 203 | loss 0.989 | nll_loss 0.401 | ppl 1.32 | wps 24647.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9878 | lr 0.000318175 | gnorm 0.617 | loss_scale 16 | train_wall 110 | gb_free 8.8 | wall 31490
2022-03-06 21:47:19 | INFO | fairseq.trainer | begin training epoch 204
2022-03-06 21:47:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:48:15 | INFO | train_inner | epoch 204:     22 / 49 loss=0.988, nll_loss=0.401, ppl=1.32, wps=24654.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.618, loss_scale=16, train_wall=224, gb_free=8.8, wall=31545
2022-03-06 21:49:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:49:26 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 14.568 | nll_loss 14.341 | ppl 20753.9 | wps 46175.8 | wpb 510.9 | bsz 1 | num_updates 9927 | best_loss 8.318
2022-03-06 21:49:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9927 updates
2022-03-06 21:49:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:49:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:49:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 204 @ 9927 updates, score 14.568) (writing took 2.520485183224082 seconds)
2022-03-06 21:49:28 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-06 21:49:28 | INFO | train | epoch 204 | loss 0.985 | nll_loss 0.398 | ppl 1.32 | wps 24632.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9927 | lr 0.000317388 | gnorm 0.618 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 31619
2022-03-06 21:49:28 | INFO | fairseq.trainer | begin training epoch 205
2022-03-06 21:49:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:51:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:51:35 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 14.478 | nll_loss 14.249 | ppl 19473.4 | wps 45575.2 | wpb 510.9 | bsz 1 | num_updates 9976 | best_loss 8.318
2022-03-06 21:51:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9976 updates
2022-03-06 21:51:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:51:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:51:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 205 @ 9976 updates, score 14.478) (writing took 2.492286903783679 seconds)
2022-03-06 21:51:37 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-06 21:51:37 | INFO | train | epoch 205 | loss 0.983 | nll_loss 0.396 | ppl 1.32 | wps 24613.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9976 | lr 0.000316608 | gnorm 0.621 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 31748
2022-03-06 21:51:37 | INFO | fairseq.trainer | begin training epoch 206
2022-03-06 21:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:52:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:52:40 | INFO | train_inner | epoch 206:     25 / 49 loss=0.983, nll_loss=0.397, ppl=1.32, wps=24443.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.624, loss_scale=16, train_wall=226, gb_free=8.8, wall=31810
2022-03-06 21:53:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:53:44 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 14.446 | nll_loss 14.214 | ppl 19008 | wps 46231.8 | wpb 510.9 | bsz 1 | num_updates 10024 | best_loss 8.318
2022-03-06 21:53:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10024 updates
2022-03-06 21:53:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:53:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:53:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 206 @ 10024 updates, score 14.446) (writing took 2.495089115574956 seconds)
2022-03-06 21:53:46 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-06 21:53:46 | INFO | train | epoch 206 | loss 0.982 | nll_loss 0.395 | ppl 1.32 | wps 24150.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10024 | lr 0.000315849 | gnorm 0.626 | loss_scale 16 | train_wall 110 | gb_free 8.8 | wall 31877
2022-03-06 21:53:46 | INFO | fairseq.trainer | begin training epoch 207
2022-03-06 21:53:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:55:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:55:53 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 14.488 | nll_loss 14.259 | ppl 19609.9 | wps 46182.8 | wpb 510.9 | bsz 1 | num_updates 10073 | best_loss 8.318
2022-03-06 21:55:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10073 updates
2022-03-06 21:55:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:55:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:55:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 207 @ 10073 updates, score 14.488) (writing took 2.5084429532289505 seconds)
2022-03-06 21:55:55 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-06 21:55:55 | INFO | train | epoch 207 | loss 0.976 | nll_loss 0.39 | ppl 1.31 | wps 24631.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10073 | lr 0.00031508 | gnorm 0.609 | loss_scale 16 | train_wall 110 | gb_free 8.8 | wall 32006
2022-03-06 21:55:55 | INFO | fairseq.trainer | begin training epoch 208
2022-03-06 21:55:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:57:03 | INFO | train_inner | epoch 208:     27 / 49 loss=0.977, nll_loss=0.391, ppl=1.31, wps=24655.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.613, loss_scale=16, train_wall=224, gb_free=8.8, wall=32074
2022-03-06 21:57:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:58:02 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 14.426 | nll_loss 14.197 | ppl 18778.7 | wps 46246.9 | wpb 510.9 | bsz 1 | num_updates 10122 | best_loss 8.318
2022-03-06 21:58:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10122 updates
2022-03-06 21:58:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:58:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:58:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 208 @ 10122 updates, score 14.426) (writing took 2.525290347635746 seconds)
2022-03-06 21:58:04 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-06 21:58:04 | INFO | train | epoch 208 | loss 0.975 | nll_loss 0.389 | ppl 1.31 | wps 24635.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10122 | lr 0.000314316 | gnorm 0.621 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 32135
2022-03-06 21:58:04 | INFO | fairseq.trainer | begin training epoch 209
2022-03-06 21:58:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:00:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:00:11 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 14.401 | nll_loss 14.171 | ppl 18449.4 | wps 45811 | wpb 510.9 | bsz 1 | num_updates 10171 | best_loss 8.318
2022-03-06 22:00:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10171 updates
2022-03-06 22:00:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:00:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:00:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 209 @ 10171 updates, score 14.401) (writing took 2.508002256974578 seconds)
2022-03-06 22:00:13 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-06 22:00:13 | INFO | train | epoch 209 | loss 0.972 | nll_loss 0.387 | ppl 1.31 | wps 24619.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10171 | lr 0.000313558 | gnorm 0.61 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 32264
2022-03-06 22:00:13 | INFO | fairseq.trainer | begin training epoch 210
2022-03-06 22:00:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:01:26 | INFO | train_inner | epoch 210:     29 / 49 loss=0.972, nll_loss=0.386, ppl=1.31, wps=24650.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.611, loss_scale=32, train_wall=224, gb_free=8.8, wall=32337
2022-03-06 22:02:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:02:20 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 14.532 | nll_loss 14.307 | ppl 20267 | wps 46266.6 | wpb 510.9 | bsz 1 | num_updates 10220 | best_loss 8.318
2022-03-06 22:02:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10220 updates
2022-03-06 22:02:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:02:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:02:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 210 @ 10220 updates, score 14.532) (writing took 2.5044362265616655 seconds)
2022-03-06 22:02:23 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-06 22:02:23 | INFO | train | epoch 210 | loss 0.969 | nll_loss 0.384 | ppl 1.3 | wps 24629.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10220 | lr 0.000312806 | gnorm 0.605 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 32393
2022-03-06 22:02:23 | INFO | fairseq.trainer | begin training epoch 211
2022-03-06 22:02:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:03:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:04:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:04:29 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 14.567 | nll_loss 14.343 | ppl 20781.6 | wps 45974.4 | wpb 510.9 | bsz 1 | num_updates 10268 | best_loss 8.318
2022-03-06 22:04:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10268 updates
2022-03-06 22:04:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:04:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:04:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 211 @ 10268 updates, score 14.567) (writing took 2.503498574718833 seconds)
2022-03-06 22:04:31 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-06 22:04:31 | INFO | train | epoch 211 | loss 0.966 | nll_loss 0.381 | ppl 1.3 | wps 24137.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10268 | lr 0.000312074 | gnorm 0.595 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 32522
2022-03-06 22:04:31 | INFO | fairseq.trainer | begin training epoch 212
2022-03-06 22:04:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:04:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:05:54 | INFO | train_inner | epoch 212:     33 / 49 loss=0.966, nll_loss=0.381, ppl=1.3, wps=24228.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.602, loss_scale=16, train_wall=228, gb_free=8.8, wall=32604
2022-03-06 22:06:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:06:38 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 14.41 | nll_loss 14.179 | ppl 18546.1 | wps 46225.3 | wpb 510.9 | bsz 1 | num_updates 10316 | best_loss 8.318
2022-03-06 22:06:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10316 updates
2022-03-06 22:06:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:06:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:06:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 212 @ 10316 updates, score 14.41) (writing took 2.508244266733527 seconds)
2022-03-06 22:06:40 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-06 22:06:40 | INFO | train | epoch 212 | loss 0.964 | nll_loss 0.379 | ppl 1.3 | wps 24174.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10316 | lr 0.000311347 | gnorm 0.605 | loss_scale 16 | train_wall 110 | gb_free 8.8 | wall 32651
2022-03-06 22:06:40 | INFO | fairseq.trainer | begin training epoch 213
2022-03-06 22:06:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:08:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:08:47 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 14.515 | nll_loss 14.287 | ppl 19996.8 | wps 45347.1 | wpb 510.9 | bsz 1 | num_updates 10365 | best_loss 8.318
2022-03-06 22:08:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10365 updates
2022-03-06 22:08:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:08:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:08:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 213 @ 10365 updates, score 14.515) (writing took 2.5182125605642796 seconds)
2022-03-06 22:08:50 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-06 22:08:50 | INFO | train | epoch 213 | loss 0.961 | nll_loss 0.376 | ppl 1.3 | wps 24577.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10365 | lr 0.00031061 | gnorm 0.597 | loss_scale 16 | train_wall 110 | gb_free 8.8 | wall 32780
2022-03-06 22:08:50 | INFO | fairseq.trainer | begin training epoch 214
2022-03-06 22:08:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:10:18 | INFO | train_inner | epoch 214:     35 / 49 loss=0.961, nll_loss=0.376, ppl=1.3, wps=24599.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.6, loss_scale=16, train_wall=225, gb_free=8.8, wall=32868
2022-03-06 22:10:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:10:56 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 14.494 | nll_loss 14.268 | ppl 19727.8 | wps 46130.1 | wpb 510.9 | bsz 1 | num_updates 10414 | best_loss 8.318
2022-03-06 22:10:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10414 updates
2022-03-06 22:10:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:10:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:10:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 214 @ 10414 updates, score 14.494) (writing took 2.5661759227514267 seconds)
2022-03-06 22:10:59 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-06 22:10:59 | INFO | train | epoch 214 | loss 0.96 | nll_loss 0.375 | ppl 1.3 | wps 24548.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10414 | lr 0.000309878 | gnorm 0.605 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 32909
2022-03-06 22:10:59 | INFO | fairseq.trainer | begin training epoch 215
2022-03-06 22:10:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:12:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:13:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:13:05 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 14.438 | nll_loss 14.212 | ppl 18983.2 | wps 46157.9 | wpb 510.9 | bsz 1 | num_updates 10462 | best_loss 8.318
2022-03-06 22:13:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10462 updates
2022-03-06 22:13:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:13:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:13:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 215 @ 10462 updates, score 14.438) (writing took 2.5219450760632753 seconds)
2022-03-06 22:13:08 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-06 22:13:08 | INFO | train | epoch 215 | loss 0.956 | nll_loss 0.372 | ppl 1.29 | wps 24130.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10462 | lr 0.000309167 | gnorm 0.597 | loss_scale 16 | train_wall 110 | gb_free 8.8 | wall 33038
2022-03-06 22:13:08 | INFO | fairseq.trainer | begin training epoch 216
2022-03-06 22:13:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:14:43 | INFO | train_inner | epoch 216:     38 / 49 loss=0.956, nll_loss=0.372, ppl=1.29, wps=24436.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.598, loss_scale=16, train_wall=226, gb_free=8.8, wall=33134
2022-03-06 22:15:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:15:14 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 14.482 | nll_loss 14.26 | ppl 19622.9 | wps 46239.1 | wpb 510.9 | bsz 1 | num_updates 10511 | best_loss 8.318
2022-03-06 22:15:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10511 updates
2022-03-06 22:15:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:15:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:15:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 216 @ 10511 updates, score 14.482) (writing took 2.5232299212366343 seconds)
2022-03-06 22:15:17 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-06 22:15:17 | INFO | train | epoch 216 | loss 0.954 | nll_loss 0.37 | ppl 1.29 | wps 24629.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10511 | lr 0.000308445 | gnorm 0.595 | loss_scale 16 | train_wall 110 | gb_free 8.8 | wall 33167
2022-03-06 22:15:17 | INFO | fairseq.trainer | begin training epoch 217
2022-03-06 22:15:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:17:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:17:23 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 14.439 | nll_loss 14.213 | ppl 18984.1 | wps 46333.9 | wpb 510.9 | bsz 1 | num_updates 10560 | best_loss 8.318
2022-03-06 22:17:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10560 updates
2022-03-06 22:17:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:17:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:17:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 217 @ 10560 updates, score 14.439) (writing took 2.52970696054399 seconds)
2022-03-06 22:17:26 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-06 22:17:26 | INFO | train | epoch 217 | loss 0.951 | nll_loss 0.367 | ppl 1.29 | wps 24660.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10560 | lr 0.000307729 | gnorm 0.58 | loss_scale 16 | train_wall 110 | gb_free 8.8 | wall 33296
2022-03-06 22:17:26 | INFO | fairseq.trainer | begin training epoch 218
2022-03-06 22:17:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:19:06 | INFO | train_inner | epoch 218:     40 / 49 loss=0.95, nll_loss=0.367, ppl=1.29, wps=24666, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.582, loss_scale=32, train_wall=224, gb_free=8.8, wall=33397
2022-03-06 22:19:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:19:32 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 14.484 | nll_loss 14.26 | ppl 19626.2 | wps 46080.1 | wpb 510.9 | bsz 1 | num_updates 10609 | best_loss 8.318
2022-03-06 22:19:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10609 updates
2022-03-06 22:19:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:19:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:19:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 218 @ 10609 updates, score 14.484) (writing took 2.4982313625514507 seconds)
2022-03-06 22:19:35 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-06 22:19:35 | INFO | train | epoch 218 | loss 0.95 | nll_loss 0.366 | ppl 1.29 | wps 24637.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10609 | lr 0.000307017 | gnorm 0.587 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 33425
2022-03-06 22:19:35 | INFO | fairseq.trainer | begin training epoch 219
2022-03-06 22:19:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:21:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:21:43 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 14.454 | nll_loss 14.228 | ppl 19184.7 | wps 44932.8 | wpb 510.9 | bsz 1 | num_updates 10657 | best_loss 8.318
2022-03-06 22:21:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10657 updates
2022-03-06 22:21:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:21:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:21:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 219 @ 10657 updates, score 14.454) (writing took 2.5482483115047216 seconds)
2022-03-06 22:21:46 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-06 22:21:46 | INFO | train | epoch 219 | loss 0.947 | nll_loss 0.364 | ppl 1.29 | wps 23736.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10657 | lr 0.000306325 | gnorm 0.589 | loss_scale 16 | train_wall 112 | gb_free 8.8 | wall 33556
2022-03-06 22:21:46 | INFO | fairseq.trainer | begin training epoch 220
2022-03-06 22:21:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:23:36 | INFO | train_inner | epoch 220:     43 / 49 loss=0.948, nll_loss=0.364, ppl=1.29, wps=24059.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.59, loss_scale=16, train_wall=230, gb_free=8.8, wall=33666
2022-03-06 22:23:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:23:55 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 14.633 | nll_loss 14.415 | ppl 21839.5 | wps 44515.7 | wpb 510.9 | bsz 1 | num_updates 10706 | best_loss 8.318
2022-03-06 22:23:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10706 updates
2022-03-06 22:23:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:23:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:23:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 220 @ 10706 updates, score 14.633) (writing took 2.5430235508829355 seconds)
2022-03-06 22:23:58 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-06 22:23:58 | INFO | train | epoch 220 | loss 0.946 | nll_loss 0.362 | ppl 1.29 | wps 24165.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 10706 | lr 0.000305623 | gnorm 0.587 | loss_scale 16 | train_wall 112 | gb_free 8.8 | wall 33688
2022-03-06 22:23:58 | INFO | fairseq.trainer | begin training epoch 221
2022-03-06 22:23:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:26:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:26:06 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 14.487 | nll_loss 14.264 | ppl 19668.4 | wps 44377.1 | wpb 510.9 | bsz 1 | num_updates 10755 | best_loss 8.318
2022-03-06 22:26:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10755 updates
2022-03-06 22:26:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:26:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:26:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 221 @ 10755 updates, score 14.487) (writing took 2.5353712160140276 seconds)
2022-03-06 22:26:09 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-06 22:26:09 | INFO | train | epoch 221 | loss 0.942 | nll_loss 0.359 | ppl 1.28 | wps 24226.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 10755 | lr 0.000304926 | gnorm 0.581 | loss_scale 16 | train_wall 112 | gb_free 8.8 | wall 33819
2022-03-06 22:26:09 | INFO | fairseq.trainer | begin training epoch 222
2022-03-06 22:26:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:28:03 | INFO | train_inner | epoch 222:     45 / 49 loss=0.942, nll_loss=0.359, ppl=1.28, wps=24253.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.578, loss_scale=32, train_wall=228, gb_free=8.8, wall=33934
2022-03-06 22:28:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:28:17 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 14.507 | nll_loss 14.283 | ppl 19931.1 | wps 44564.5 | wpb 510.9 | bsz 1 | num_updates 10804 | best_loss 8.318
2022-03-06 22:28:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10804 updates
2022-03-06 22:28:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:28:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:28:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 222 @ 10804 updates, score 14.507) (writing took 2.518821120262146 seconds)
2022-03-06 22:28:20 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-06 22:28:20 | INFO | train | epoch 222 | loss 0.941 | nll_loss 0.358 | ppl 1.28 | wps 24239.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 10804 | lr 0.000304234 | gnorm 0.576 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 33950
2022-03-06 22:28:20 | INFO | fairseq.trainer | begin training epoch 223
2022-03-06 22:28:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:30:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:30:29 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 14.531 | nll_loss 14.311 | ppl 20325 | wps 43341.6 | wpb 510.9 | bsz 1 | num_updates 10853 | best_loss 8.318
2022-03-06 22:30:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10853 updates
2022-03-06 22:30:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:30:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:30:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 223 @ 10853 updates, score 14.531) (writing took 2.5646437369287014 seconds)
2022-03-06 22:30:31 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-06 22:30:31 | INFO | train | epoch 223 | loss 0.938 | nll_loss 0.356 | ppl 1.28 | wps 24151.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 10853 | lr 0.000303546 | gnorm 0.574 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 34082
2022-03-06 22:30:31 | INFO | fairseq.trainer | begin training epoch 224
2022-03-06 22:30:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:32:31 | INFO | train_inner | epoch 224:     47 / 49 loss=0.938, nll_loss=0.356, ppl=1.28, wps=24222.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=10900, lr=0.000302891, gnorm=0.572, loss_scale=64, train_wall=228, gb_free=8.8, wall=34202
2022-03-06 22:32:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:32:40 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 14.471 | nll_loss 14.249 | ppl 19469 | wps 43734.3 | wpb 510.9 | bsz 1 | num_updates 10902 | best_loss 8.318
2022-03-06 22:32:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10902 updates
2022-03-06 22:32:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:32:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:32:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 224 @ 10902 updates, score 14.471) (writing took 2.5360641200095415 seconds)
2022-03-06 22:32:43 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-06 22:32:43 | INFO | train | epoch 224 | loss 0.937 | nll_loss 0.354 | ppl 1.28 | wps 24208.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 10902 | lr 0.000302863 | gnorm 0.566 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 34213
2022-03-06 22:32:43 | INFO | fairseq.trainer | begin training epoch 225
2022-03-06 22:32:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:32:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:34:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:34:51 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 14.506 | nll_loss 14.282 | ppl 19926.5 | wps 44287.9 | wpb 510.9 | bsz 1 | num_updates 10950 | best_loss 8.318
2022-03-06 22:34:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10950 updates
2022-03-06 22:34:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:34:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:34:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 225 @ 10950 updates, score 14.506) (writing took 2.5506243240088224 seconds)
2022-03-06 22:34:54 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-06 22:34:54 | INFO | train | epoch 225 | loss 0.934 | nll_loss 0.352 | ppl 1.28 | wps 23710.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10950 | lr 0.000302199 | gnorm 0.578 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 34344
2022-03-06 22:34:54 | INFO | fairseq.trainer | begin training epoch 226
2022-03-06 22:34:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:37:03 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 14.402 | nll_loss 14.179 | ppl 18542.4 | wps 44206.5 | wpb 510.9 | bsz 1 | num_updates 10999 | best_loss 8.318
2022-03-06 22:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 10999 updates
2022-03-06 22:37:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:37:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:37:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 226 @ 10999 updates, score 14.402) (writing took 2.5431987438350916 seconds)
2022-03-06 22:37:05 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-06 22:37:05 | INFO | train | epoch 226 | loss 0.932 | nll_loss 0.35 | ppl 1.27 | wps 24231.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 10999 | lr 0.000301525 | gnorm 0.575 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 34475
2022-03-06 22:37:05 | INFO | fairseq.trainer | begin training epoch 227
2022-03-06 22:37:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:37:08 | INFO | train_inner | epoch 227:      1 / 49 loss=0.933, nll_loss=0.351, ppl=1.28, wps=23339.9, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=11000, lr=0.000301511, gnorm=0.578, loss_scale=32, train_wall=229, gb_free=8.8, wall=34478
2022-03-06 22:38:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:39:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:39:14 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 14.479 | nll_loss 14.258 | ppl 19591.4 | wps 44656.4 | wpb 510.9 | bsz 1 | num_updates 11047 | best_loss 8.318
2022-03-06 22:39:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11047 updates
2022-03-06 22:39:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:39:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:39:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 227 @ 11047 updates, score 14.479) (writing took 2.5433778930455446 seconds)
2022-03-06 22:39:16 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-06 22:39:16 | INFO | train | epoch 227 | loss 0.93 | nll_loss 0.348 | ppl 1.27 | wps 23702.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11047 | lr 0.000300869 | gnorm 0.573 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 34607
2022-03-06 22:39:16 | INFO | fairseq.trainer | begin training epoch 228
2022-03-06 22:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:41:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:41:25 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 14.393 | nll_loss 14.168 | ppl 18405.2 | wps 44151.1 | wpb 510.9 | bsz 1 | num_updates 11096 | best_loss 8.318
2022-03-06 22:41:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11096 updates
2022-03-06 22:41:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:41:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:41:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 228 @ 11096 updates, score 14.393) (writing took 2.544669261202216 seconds)
2022-03-06 22:41:28 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-06 22:41:28 | INFO | train | epoch 228 | loss 0.927 | nll_loss 0.346 | ppl 1.27 | wps 24235.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11096 | lr 0.000300204 | gnorm 0.568 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 34738
2022-03-06 22:41:28 | INFO | fairseq.trainer | begin training epoch 229
2022-03-06 22:41:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:41:38 | INFO | train_inner | epoch 229:      4 / 49 loss=0.928, nll_loss=0.347, ppl=1.27, wps=24017, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=11100, lr=0.00030015, gnorm=0.572, loss_scale=32, train_wall=230, gb_free=8.8, wall=34748
2022-03-06 22:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:43:36 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 14.455 | nll_loss 14.235 | ppl 19288.2 | wps 44526.4 | wpb 510.9 | bsz 1 | num_updates 11145 | best_loss 8.318
2022-03-06 22:43:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11145 updates
2022-03-06 22:43:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:43:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:43:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 229 @ 11145 updates, score 14.455) (writing took 2.5604416131973267 seconds)
2022-03-06 22:43:39 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-06 22:43:39 | INFO | train | epoch 229 | loss 0.926 | nll_loss 0.345 | ppl 1.27 | wps 24214 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11145 | lr 0.000299544 | gnorm 0.569 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 34869
2022-03-06 22:43:39 | INFO | fairseq.trainer | begin training epoch 230
2022-03-06 22:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:45:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:45:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:45:48 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 14.483 | nll_loss 14.262 | ppl 19644.7 | wps 44300.8 | wpb 510.9 | bsz 1 | num_updates 11193 | best_loss 8.318
2022-03-06 22:45:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11193 updates
2022-03-06 22:45:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:45:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:45:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 230 @ 11193 updates, score 14.483) (writing took 2.569086652249098 seconds)
2022-03-06 22:45:50 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-06 22:45:50 | INFO | train | epoch 230 | loss 0.924 | nll_loss 0.343 | ppl 1.27 | wps 23706 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11193 | lr 0.000298901 | gnorm 0.565 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 35000
2022-03-06 22:45:50 | INFO | fairseq.trainer | begin training epoch 231
2022-03-06 22:45:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:45:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:46:11 | INFO | train_inner | epoch 231:      8 / 49 loss=0.925, nll_loss=0.344, ppl=1.27, wps=23791.5, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.568, loss_scale=16, train_wall=233, gb_free=8.8, wall=35021
2022-03-06 22:47:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:47:59 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 14.463 | nll_loss 14.242 | ppl 19374 | wps 44131.1 | wpb 510.9 | bsz 1 | num_updates 11241 | best_loss 8.318
2022-03-06 22:47:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11241 updates
2022-03-06 22:47:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:48:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:48:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 231 @ 11241 updates, score 14.463) (writing took 2.5716685205698013 seconds)
2022-03-06 22:48:01 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-06 22:48:01 | INFO | train | epoch 231 | loss 0.921 | nll_loss 0.34 | ppl 1.27 | wps 23699.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11241 | lr 0.000298262 | gnorm 0.559 | loss_scale 16 | train_wall 112 | gb_free 8.8 | wall 35132
2022-03-06 22:48:01 | INFO | fairseq.trainer | begin training epoch 232
2022-03-06 22:48:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:50:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:50:10 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 14.407 | nll_loss 14.187 | ppl 18647.5 | wps 42678.6 | wpb 510.9 | bsz 1 | num_updates 11290 | best_loss 8.318
2022-03-06 22:50:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11290 updates
2022-03-06 22:50:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:50:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:50:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 232 @ 11290 updates, score 14.407) (writing took 2.5702235773205757 seconds)
2022-03-06 22:50:13 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-06 22:50:13 | INFO | train | epoch 232 | loss 0.919 | nll_loss 0.339 | ppl 1.26 | wps 24211.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11290 | lr 0.000297614 | gnorm 0.557 | loss_scale 16 | train_wall 111 | gb_free 8.8 | wall 35263
2022-03-06 22:50:13 | INFO | fairseq.trainer | begin training epoch 233
2022-03-06 22:50:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:50:38 | INFO | train_inner | epoch 233:     10 / 49 loss=0.919, nll_loss=0.339, ppl=1.26, wps=24234.6, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.554, loss_scale=16, train_wall=228, gb_free=8.8, wall=35289
2022-03-06 22:52:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:52:21 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 14.463 | nll_loss 14.242 | ppl 19380.6 | wps 44310.6 | wpb 510.9 | bsz 1 | num_updates 11339 | best_loss 8.318
2022-03-06 22:52:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11339 updates
2022-03-06 22:52:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:52:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:52:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 233 @ 11339 updates, score 14.463) (writing took 2.5395598858594894 seconds)
2022-03-06 22:52:24 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-06 22:52:24 | INFO | train | epoch 233 | loss 0.918 | nll_loss 0.337 | ppl 1.26 | wps 24219.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11339 | lr 0.00029697 | gnorm 0.548 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 35394
2022-03-06 22:52:24 | INFO | fairseq.trainer | begin training epoch 234
2022-03-06 22:52:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:54:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:54:33 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 14.449 | nll_loss 14.233 | ppl 19257.4 | wps 43934.1 | wpb 510.9 | bsz 1 | num_updates 11388 | best_loss 8.318
2022-03-06 22:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11388 updates
2022-03-06 22:54:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 234 @ 11388 updates, score 14.449) (writing took 2.534635504707694 seconds)
2022-03-06 22:54:35 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-06 22:54:35 | INFO | train | epoch 234 | loss 0.915 | nll_loss 0.335 | ppl 1.26 | wps 24180.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11388 | lr 0.00029633 | gnorm 0.555 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 35526
2022-03-06 22:54:35 | INFO | fairseq.trainer | begin training epoch 235
2022-03-06 22:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:55:06 | INFO | train_inner | epoch 235:     12 / 49 loss=0.916, nll_loss=0.336, ppl=1.26, wps=24236.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.552, loss_scale=32, train_wall=228, gb_free=8.8, wall=35556
2022-03-06 22:56:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:56:44 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 14.446 | nll_loss 14.228 | ppl 19195.7 | wps 44084.5 | wpb 510.9 | bsz 1 | num_updates 11437 | best_loss 8.318
2022-03-06 22:56:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11437 updates
2022-03-06 22:56:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:56:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:56:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 235 @ 11437 updates, score 14.446) (writing took 2.5620789378881454 seconds)
2022-03-06 22:56:46 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-06 22:56:46 | INFO | train | epoch 235 | loss 0.914 | nll_loss 0.334 | ppl 1.26 | wps 24243.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11437 | lr 0.000295695 | gnorm 0.55 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 35657
2022-03-06 22:56:46 | INFO | fairseq.trainer | begin training epoch 236
2022-03-06 22:56:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:57:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:58:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:58:55 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 14.432 | nll_loss 14.213 | ppl 18986.6 | wps 43928.2 | wpb 510.9 | bsz 1 | num_updates 11485 | best_loss 8.318
2022-03-06 22:58:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11485 updates
2022-03-06 22:58:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:58:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:58:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 236 @ 11485 updates, score 14.432) (writing took 2.5505839195102453 seconds)
2022-03-06 22:58:58 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-06 22:58:58 | INFO | train | epoch 236 | loss 0.912 | nll_loss 0.332 | ppl 1.26 | wps 23702.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11485 | lr 0.000295076 | gnorm 0.546 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 35788
2022-03-06 22:58:58 | INFO | fairseq.trainer | begin training epoch 237
2022-03-06 22:58:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:59:36 | INFO | train_inner | epoch 237:     15 / 49 loss=0.912, nll_loss=0.333, ppl=1.26, wps=24022.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.546, loss_scale=32, train_wall=230, gb_free=8.8, wall=35826
2022-03-06 23:01:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:01:06 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 14.462 | nll_loss 14.246 | ppl 19427.9 | wps 43410.3 | wpb 510.9 | bsz 1 | num_updates 11534 | best_loss 8.318
2022-03-06 23:01:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11534 updates
2022-03-06 23:01:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:01:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:01:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 237 @ 11534 updates, score 14.462) (writing took 2.558848014101386 seconds)
2022-03-06 23:01:09 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-06 23:01:09 | INFO | train | epoch 237 | loss 0.91 | nll_loss 0.331 | ppl 1.26 | wps 24214.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11534 | lr 0.000294449 | gnorm 0.544 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 35919
2022-03-06 23:01:09 | INFO | fairseq.trainer | begin training epoch 238
2022-03-06 23:01:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:03:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:03:17 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 14.502 | nll_loss 14.287 | ppl 19992.9 | wps 45281.1 | wpb 510.9 | bsz 1 | num_updates 11583 | best_loss 8.318
2022-03-06 23:03:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11583 updates
2022-03-06 23:03:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:03:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:03:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 238 @ 11583 updates, score 14.502) (writing took 2.539732448756695 seconds)
2022-03-06 23:03:20 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-06 23:03:20 | INFO | train | epoch 238 | loss 0.909 | nll_loss 0.329 | ppl 1.26 | wps 24263.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11583 | lr 0.000293825 | gnorm 0.543 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 36050
2022-03-06 23:03:20 | INFO | fairseq.trainer | begin training epoch 239
2022-03-06 23:03:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:03:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:04:06 | INFO | train_inner | epoch 239:     18 / 49 loss=0.909, nll_loss=0.329, ppl=1.26, wps=24038.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.544, loss_scale=32, train_wall=230, gb_free=8.8, wall=36096
2022-03-06 23:05:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:05:29 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 14.472 | nll_loss 14.255 | ppl 19556.5 | wps 43722 | wpb 510.9 | bsz 1 | num_updates 11631 | best_loss 8.318
2022-03-06 23:05:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11631 updates
2022-03-06 23:05:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:05:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:05:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 239 @ 11631 updates, score 14.472) (writing took 2.5967692732810974 seconds)
2022-03-06 23:05:31 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-06 23:05:31 | INFO | train | epoch 239 | loss 0.906 | nll_loss 0.327 | ppl 1.25 | wps 23711.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11631 | lr 0.000293219 | gnorm 0.544 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 36182
2022-03-06 23:05:31 | INFO | fairseq.trainer | begin training epoch 240
2022-03-06 23:05:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:07:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:07:40 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 14.404 | nll_loss 14.184 | ppl 18606.3 | wps 44236.6 | wpb 510.9 | bsz 1 | num_updates 11680 | best_loss 8.318
2022-03-06 23:07:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11680 updates
2022-03-06 23:07:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:07:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:07:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 240 @ 11680 updates, score 14.404) (writing took 2.5115896370261908 seconds)
2022-03-06 23:07:42 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-06 23:07:42 | INFO | train | epoch 240 | loss 0.905 | nll_loss 0.326 | ppl 1.25 | wps 24225.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11680 | lr 0.000292603 | gnorm 0.546 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 36313
2022-03-06 23:07:42 | INFO | fairseq.trainer | begin training epoch 241
2022-03-06 23:07:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:08:33 | INFO | train_inner | epoch 241:     20 / 49 loss=0.905, nll_loss=0.326, ppl=1.25, wps=24246, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.543, loss_scale=32, train_wall=228, gb_free=8.8, wall=36364
2022-03-06 23:09:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:09:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:09:51 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 14.446 | nll_loss 14.229 | ppl 19198.1 | wps 45112.3 | wpb 510.9 | bsz 1 | num_updates 11728 | best_loss 8.318
2022-03-06 23:09:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11728 updates
2022-03-06 23:09:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:09:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:09:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 241 @ 11728 updates, score 14.446) (writing took 2.5674498602747917 seconds)
2022-03-06 23:09:54 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-06 23:09:54 | INFO | train | epoch 241 | loss 0.902 | nll_loss 0.323 | ppl 1.25 | wps 23669.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11728 | lr 0.000292003 | gnorm 0.537 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 36444
2022-03-06 23:09:54 | INFO | fairseq.trainer | begin training epoch 242
2022-03-06 23:09:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:11:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:12:02 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 14.341 | nll_loss 14.12 | ppl 17804.7 | wps 44986.8 | wpb 510.9 | bsz 1 | num_updates 11777 | best_loss 8.318
2022-03-06 23:12:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11777 updates
2022-03-06 23:12:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:12:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:12:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 242 @ 11777 updates, score 14.341) (writing took 2.5414587166160345 seconds)
2022-03-06 23:12:05 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-06 23:12:05 | INFO | train | epoch 242 | loss 0.901 | nll_loss 0.323 | ppl 1.25 | wps 24289.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11777 | lr 0.000291395 | gnorm 0.536 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 36575
2022-03-06 23:12:05 | INFO | fairseq.trainer | begin training epoch 243
2022-03-06 23:12:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:13:03 | INFO | train_inner | epoch 243:     23 / 49 loss=0.901, nll_loss=0.322, ppl=1.25, wps=24026.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.537, loss_scale=32, train_wall=230, gb_free=8.8, wall=36634
2022-03-06 23:14:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:14:13 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 14.424 | nll_loss 14.209 | ppl 18933.9 | wps 44262.8 | wpb 510.9 | bsz 1 | num_updates 11826 | best_loss 8.318
2022-03-06 23:14:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11826 updates
2022-03-06 23:14:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:14:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:14:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 243 @ 11826 updates, score 14.424) (writing took 2.530523704364896 seconds)
2022-03-06 23:14:16 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-06 23:14:16 | INFO | train | epoch 243 | loss 0.9 | nll_loss 0.322 | ppl 1.25 | wps 24235.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11826 | lr 0.000290791 | gnorm 0.539 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 36706
2022-03-06 23:14:16 | INFO | fairseq.trainer | begin training epoch 244
2022-03-06 23:14:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:16:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:16:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:16:24 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 14.393 | nll_loss 14.172 | ppl 18459.9 | wps 43707.8 | wpb 510.9 | bsz 1 | num_updates 11874 | best_loss 8.318
2022-03-06 23:16:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11874 updates
2022-03-06 23:16:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:16:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:16:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 244 @ 11874 updates, score 14.393) (writing took 2.5568437818437815 seconds)
2022-03-06 23:16:27 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-06 23:16:27 | INFO | train | epoch 244 | loss 0.897 | nll_loss 0.319 | ppl 1.25 | wps 23747.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11874 | lr 0.000290203 | gnorm 0.527 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 36837
2022-03-06 23:16:27 | INFO | fairseq.trainer | begin training epoch 245
2022-03-06 23:16:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:17:33 | INFO | train_inner | epoch 245:     26 / 49 loss=0.897, nll_loss=0.319, ppl=1.25, wps=24054.5, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.531, loss_scale=32, train_wall=230, gb_free=8.8, wall=36903
2022-03-06 23:18:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:18:35 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 14.475 | nll_loss 14.258 | ppl 19586.8 | wps 44552.9 | wpb 510.9 | bsz 1 | num_updates 11923 | best_loss 8.318
2022-03-06 23:18:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11923 updates
2022-03-06 23:18:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:18:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:18:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 245 @ 11923 updates, score 14.475) (writing took 2.535010451450944 seconds)
2022-03-06 23:18:38 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-06 23:18:38 | INFO | train | epoch 245 | loss 0.895 | nll_loss 0.317 | ppl 1.25 | wps 24265.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11923 | lr 0.000289606 | gnorm 0.529 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 36968
2022-03-06 23:18:38 | INFO | fairseq.trainer | begin training epoch 246
2022-03-06 23:18:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:20:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:20:46 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 14.424 | nll_loss 14.208 | ppl 18918.8 | wps 45035.5 | wpb 510.9 | bsz 1 | num_updates 11972 | best_loss 8.318
2022-03-06 23:20:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11972 updates
2022-03-06 23:20:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:20:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:20:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 246 @ 11972 updates, score 14.424) (writing took 2.5627828408032656 seconds)
2022-03-06 23:20:49 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-06 23:20:49 | INFO | train | epoch 246 | loss 0.895 | nll_loss 0.318 | ppl 1.25 | wps 24259.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11972 | lr 0.000289013 | gnorm 0.541 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 37099
2022-03-06 23:20:49 | INFO | fairseq.trainer | begin training epoch 247
2022-03-06 23:20:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:22:00 | INFO | train_inner | epoch 247:     28 / 49 loss=0.894, nll_loss=0.317, ppl=1.25, wps=24272.9, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.533, loss_scale=64, train_wall=228, gb_free=8.8, wall=37171
2022-03-06 23:22:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:22:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:22:58 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 14.415 | nll_loss 14.195 | ppl 18750.6 | wps 43919.9 | wpb 510.9 | bsz 1 | num_updates 12020 | best_loss 8.318
2022-03-06 23:22:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12020 updates
2022-03-06 23:22:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:23:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:23:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 247 @ 12020 updates, score 14.415) (writing took 2.544833729043603 seconds)
2022-03-06 23:23:00 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-06 23:23:00 | INFO | train | epoch 247 | loss 0.892 | nll_loss 0.315 | ppl 1.24 | wps 23692.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12020 | lr 0.000288435 | gnorm 0.529 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 37231
2022-03-06 23:23:00 | INFO | fairseq.trainer | begin training epoch 248
2022-03-06 23:23:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:25:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:25:09 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 14.401 | nll_loss 14.186 | ppl 18636.5 | wps 44484 | wpb 510.9 | bsz 1 | num_updates 12069 | best_loss 8.318
2022-03-06 23:25:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12069 updates
2022-03-06 23:25:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:25:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:25:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 248 @ 12069 updates, score 14.401) (writing took 2.5409562047570944 seconds)
2022-03-06 23:25:11 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-06 23:25:11 | INFO | train | epoch 248 | loss 0.891 | nll_loss 0.314 | ppl 1.24 | wps 24252 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12069 | lr 0.000287849 | gnorm 0.524 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 37362
2022-03-06 23:25:11 | INFO | fairseq.trainer | begin training epoch 249
2022-03-06 23:25:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:26:31 | INFO | train_inner | epoch 249:     31 / 49 loss=0.891, nll_loss=0.314, ppl=1.24, wps=23995.5, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.53, loss_scale=32, train_wall=230, gb_free=8.8, wall=37441
2022-03-06 23:27:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:27:20 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 14.575 | nll_loss 14.362 | ppl 21052.7 | wps 44258.6 | wpb 510.9 | bsz 1 | num_updates 12118 | best_loss 8.318
2022-03-06 23:27:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12118 updates
2022-03-06 23:27:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:27:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:27:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 249 @ 12118 updates, score 14.575) (writing took 2.5754624530673027 seconds)
2022-03-06 23:27:23 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-06 23:27:23 | INFO | train | epoch 249 | loss 0.89 | nll_loss 0.313 | ppl 1.24 | wps 24156 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12118 | lr 0.000287266 | gnorm 0.535 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 37493
2022-03-06 23:27:23 | INFO | fairseq.trainer | begin training epoch 250
2022-03-06 23:27:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:28:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:29:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:29:32 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 14.398 | nll_loss 14.181 | ppl 18575.8 | wps 44407.4 | wpb 510.9 | bsz 1 | num_updates 12166 | best_loss 8.318
2022-03-06 23:29:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12166 updates
2022-03-06 23:29:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:29:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:29:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 250 @ 12166 updates, score 14.398) (writing took 2.500996170565486 seconds)
2022-03-06 23:29:34 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-06 23:29:34 | INFO | train | epoch 250 | loss 0.889 | nll_loss 0.312 | ppl 1.24 | wps 23736.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12166 | lr 0.000286699 | gnorm 0.53 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 37624
2022-03-06 23:29:34 | INFO | fairseq.trainer | begin training epoch 251
2022-03-06 23:29:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:31:01 | INFO | train_inner | epoch 251:     34 / 49 loss=0.888, nll_loss=0.311, ppl=1.24, wps=23985.8, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.53, loss_scale=32, train_wall=231, gb_free=8.8, wall=37712
2022-03-06 23:31:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:31:43 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 14.381 | nll_loss 14.167 | ppl 18398.2 | wps 43996.7 | wpb 510.9 | bsz 1 | num_updates 12215 | best_loss 8.318
2022-03-06 23:31:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12215 updates
2022-03-06 23:31:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:31:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:31:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 251 @ 12215 updates, score 14.381) (writing took 2.5339342560619116 seconds)
2022-03-06 23:31:46 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-06 23:31:46 | INFO | train | epoch 251 | loss 0.886 | nll_loss 0.309 | ppl 1.24 | wps 24133 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12215 | lr 0.000286123 | gnorm 0.526 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 37756
2022-03-06 23:31:46 | INFO | fairseq.trainer | begin training epoch 252
2022-03-06 23:31:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:33:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:33:55 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 14.366 | nll_loss 14.15 | ppl 18181 | wps 43994.5 | wpb 510.9 | bsz 1 | num_updates 12264 | best_loss 8.318
2022-03-06 23:33:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12264 updates
2022-03-06 23:33:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:33:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:33:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 252 @ 12264 updates, score 14.366) (writing took 2.544384241104126 seconds)
2022-03-06 23:33:57 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-06 23:33:57 | INFO | train | epoch 252 | loss 0.884 | nll_loss 0.308 | ppl 1.24 | wps 24198.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12264 | lr 0.000285551 | gnorm 0.521 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 37887
2022-03-06 23:33:57 | INFO | fairseq.trainer | begin training epoch 253
2022-03-06 23:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:34:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:35:31 | INFO | train_inner | epoch 253:     37 / 49 loss=0.884, nll_loss=0.308, ppl=1.24, wps=24020.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.522, loss_scale=32, train_wall=230, gb_free=8.8, wall=37982
2022-03-06 23:36:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:36:06 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 14.514 | nll_loss 14.302 | ppl 20204.7 | wps 44234.7 | wpb 510.9 | bsz 1 | num_updates 12312 | best_loss 8.318
2022-03-06 23:36:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12312 updates
2022-03-06 23:36:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:36:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:36:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 253 @ 12312 updates, score 14.514) (writing took 2.553022939711809 seconds)
2022-03-06 23:36:08 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-06 23:36:08 | INFO | train | epoch 253 | loss 0.883 | nll_loss 0.307 | ppl 1.24 | wps 23752.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12312 | lr 0.000284994 | gnorm 0.521 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 38018
2022-03-06 23:36:08 | INFO | fairseq.trainer | begin training epoch 254
2022-03-06 23:36:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:38:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:38:17 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 14.426 | nll_loss 14.213 | ppl 18986.3 | wps 44263.3 | wpb 510.9 | bsz 1 | num_updates 12361 | best_loss 8.318
2022-03-06 23:38:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12361 updates
2022-03-06 23:38:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:38:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:38:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 254 @ 12361 updates, score 14.426) (writing took 2.5100577790290117 seconds)
2022-03-06 23:38:20 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-06 23:38:20 | INFO | train | epoch 254 | loss 0.882 | nll_loss 0.306 | ppl 1.24 | wps 24176.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12361 | lr 0.000284429 | gnorm 0.521 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 38150
2022-03-06 23:38:20 | INFO | fairseq.trainer | begin training epoch 255
2022-03-06 23:38:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:39:59 | INFO | train_inner | epoch 255:     39 / 49 loss=0.881, nll_loss=0.305, ppl=1.24, wps=24242.6, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.517, loss_scale=32, train_wall=228, gb_free=8.8, wall=38249
2022-03-06 23:40:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:40:28 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 14.487 | nll_loss 14.275 | ppl 19824.8 | wps 44103 | wpb 510.9 | bsz 1 | num_updates 12410 | best_loss 8.318
2022-03-06 23:40:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12410 updates
2022-03-06 23:40:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:40:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 255 @ 12410 updates, score 14.487) (writing took 2.540383292362094 seconds)
2022-03-06 23:40:31 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-06 23:40:31 | INFO | train | epoch 255 | loss 0.88 | nll_loss 0.304 | ppl 1.23 | wps 24254.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12410 | lr 0.000283866 | gnorm 0.512 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 38281
2022-03-06 23:40:31 | INFO | fairseq.trainer | begin training epoch 256
2022-03-06 23:40:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:40:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:42:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:42:39 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 14.45 | nll_loss 14.235 | ppl 19281.2 | wps 44320.8 | wpb 510.9 | bsz 1 | num_updates 12458 | best_loss 8.318
2022-03-06 23:42:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12458 updates
2022-03-06 23:42:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:42:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:42:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 256 @ 12458 updates, score 14.45) (writing took 2.546927958726883 seconds)
2022-03-06 23:42:42 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-06 23:42:42 | INFO | train | epoch 256 | loss 0.879 | nll_loss 0.303 | ppl 1.23 | wps 23735 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12458 | lr 0.000283319 | gnorm 0.525 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 38412
2022-03-06 23:42:42 | INFO | fairseq.trainer | begin training epoch 257
2022-03-06 23:42:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:44:29 | INFO | train_inner | epoch 257:     42 / 49 loss=0.878, nll_loss=0.303, ppl=1.23, wps=24049.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.521, loss_scale=32, train_wall=230, gb_free=8.8, wall=38519
2022-03-06 23:44:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:44:50 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 14.435 | nll_loss 14.221 | ppl 19099.3 | wps 44363.4 | wpb 510.9 | bsz 1 | num_updates 12507 | best_loss 8.318
2022-03-06 23:44:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12507 updates
2022-03-06 23:44:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:44:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:44:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 257 @ 12507 updates, score 14.435) (writing took 2.5325432997196913 seconds)
2022-03-06 23:44:53 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-06 23:44:53 | INFO | train | epoch 257 | loss 0.877 | nll_loss 0.301 | ppl 1.23 | wps 24271.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12507 | lr 0.000282764 | gnorm 0.519 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 38543
2022-03-06 23:44:53 | INFO | fairseq.trainer | begin training epoch 258
2022-03-06 23:44:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:46:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:46:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:47:01 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 14.44 | nll_loss 14.227 | ppl 19175.5 | wps 44560.9 | wpb 510.9 | bsz 1 | num_updates 12555 | best_loss 8.318
2022-03-06 23:47:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12555 updates
2022-03-06 23:47:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:47:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:47:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 258 @ 12555 updates, score 14.44) (writing took 2.580055892467499 seconds)
2022-03-06 23:47:04 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-06 23:47:04 | INFO | train | epoch 258 | loss 0.875 | nll_loss 0.3 | ppl 1.23 | wps 23772.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12555 | lr 0.000282223 | gnorm 0.516 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 38674
2022-03-06 23:47:04 | INFO | fairseq.trainer | begin training epoch 259
2022-03-06 23:47:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:48:58 | INFO | train_inner | epoch 259:     45 / 49 loss=0.875, nll_loss=0.3, ppl=1.23, wps=24060.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.516, loss_scale=32, train_wall=230, gb_free=8.8, wall=38789
2022-03-06 23:49:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:49:12 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 14.409 | nll_loss 14.197 | ppl 18780.4 | wps 44423.5 | wpb 510.9 | bsz 1 | num_updates 12604 | best_loss 8.318
2022-03-06 23:49:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12604 updates
2022-03-06 23:49:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:49:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:49:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 259 @ 12604 updates, score 14.409) (writing took 2.5382199455052614 seconds)
2022-03-06 23:49:15 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-06 23:49:15 | INFO | train | epoch 259 | loss 0.874 | nll_loss 0.299 | ppl 1.23 | wps 24257.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12604 | lr 0.000281673 | gnorm 0.515 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 38805
2022-03-06 23:49:15 | INFO | fairseq.trainer | begin training epoch 260
2022-03-06 23:49:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:51:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:51:23 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 14.413 | nll_loss 14.2 | ppl 18817.8 | wps 44202.3 | wpb 510.9 | bsz 1 | num_updates 12653 | best_loss 8.318
2022-03-06 23:51:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12653 updates
2022-03-06 23:51:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:51:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:51:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 260 @ 12653 updates, score 14.413) (writing took 2.464243395254016 seconds)
2022-03-06 23:51:26 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-06 23:51:26 | INFO | train | epoch 260 | loss 0.872 | nll_loss 0.298 | ppl 1.23 | wps 24264.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12653 | lr 0.000281127 | gnorm 0.51 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 38936
2022-03-06 23:51:26 | INFO | fairseq.trainer | begin training epoch 261
2022-03-06 23:51:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:53:25 | INFO | train_inner | epoch 261:     47 / 49 loss=0.872, nll_loss=0.298, ppl=1.23, wps=24284.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=12700, lr=0.000280607, gnorm=0.508, loss_scale=64, train_wall=228, gb_free=8.8, wall=39056
2022-03-06 23:53:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:53:34 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 14.385 | nll_loss 14.174 | ppl 18479.8 | wps 44402.7 | wpb 510.9 | bsz 1 | num_updates 12702 | best_loss 8.318
2022-03-06 23:53:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12702 updates
2022-03-06 23:53:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:53:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:53:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 261 @ 12702 updates, score 14.385) (writing took 2.534834023565054 seconds)
2022-03-06 23:53:37 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-06 23:53:37 | INFO | train | epoch 261 | loss 0.872 | nll_loss 0.297 | ppl 1.23 | wps 24236.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12702 | lr 0.000280585 | gnorm 0.506 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 39067
2022-03-06 23:53:37 | INFO | fairseq.trainer | begin training epoch 262
2022-03-06 23:53:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:55:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:55:45 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 14.365 | nll_loss 14.15 | ppl 18177 | wps 43902.6 | wpb 510.9 | bsz 1 | num_updates 12751 | best_loss 8.318
2022-03-06 23:55:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12751 updates
2022-03-06 23:55:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:55:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:55:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 262 @ 12751 updates, score 14.365) (writing took 2.5510375294834375 seconds)
2022-03-06 23:55:48 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-06 23:55:48 | INFO | train | epoch 262 | loss 0.87 | nll_loss 0.296 | ppl 1.23 | wps 24212.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12751 | lr 0.000280045 | gnorm 0.505 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 39198
2022-03-06 23:55:48 | INFO | fairseq.trainer | begin training epoch 263
2022-03-06 23:55:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:57:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:57:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:57:56 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 14.44 | nll_loss 14.228 | ppl 19187 | wps 44662.6 | wpb 510.9 | bsz 1 | num_updates 12799 | best_loss 8.318
2022-03-06 23:57:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12799 updates
2022-03-06 23:57:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:57:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:57:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 263 @ 12799 updates, score 14.44) (writing took 2.5498698875308037 seconds)
2022-03-06 23:57:59 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-06 23:57:59 | INFO | train | epoch 263 | loss 0.868 | nll_loss 0.294 | ppl 1.23 | wps 23764.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12799 | lr 0.000279519 | gnorm 0.508 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 39329
2022-03-06 23:57:59 | INFO | fairseq.trainer | begin training epoch 264
2022-03-06 23:57:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:58:02 | INFO | train_inner | epoch 264:      1 / 49 loss=0.869, nll_loss=0.295, ppl=1.23, wps=23365.9, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=12800, lr=0.000279508, gnorm=0.508, loss_scale=32, train_wall=229, gb_free=8.8, wall=39332
2022-03-07 00:00:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:00:08 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 14.35 | nll_loss 14.139 | ppl 18043.2 | wps 43125.7 | wpb 510.9 | bsz 1 | num_updates 12848 | best_loss 8.318
2022-03-07 00:00:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12848 updates
2022-03-07 00:00:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:00:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:00:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 264 @ 12848 updates, score 14.35) (writing took 2.528551882132888 seconds)
2022-03-07 00:00:10 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-07 00:00:10 | INFO | train | epoch 264 | loss 0.867 | nll_loss 0.293 | ppl 1.22 | wps 24178.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12848 | lr 0.000278986 | gnorm 0.509 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 39461
2022-03-07 00:00:10 | INFO | fairseq.trainer | begin training epoch 265
2022-03-07 00:00:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:02:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:02:19 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 14.389 | nll_loss 14.173 | ppl 18472.1 | wps 44531.8 | wpb 510.9 | bsz 1 | num_updates 12897 | best_loss 8.318
2022-03-07 00:02:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12897 updates
2022-03-07 00:02:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:02:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:02:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 265 @ 12897 updates, score 14.389) (writing took 2.556520525366068 seconds)
2022-03-07 00:02:22 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-07 00:02:22 | INFO | train | epoch 265 | loss 0.865 | nll_loss 0.291 | ppl 1.22 | wps 24219.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12897 | lr 0.000278455 | gnorm 0.501 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 39592
2022-03-07 00:02:22 | INFO | fairseq.trainer | begin training epoch 266
2022-03-07 00:02:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:02:29 | INFO | train_inner | epoch 266:      3 / 49 loss=0.866, nll_loss=0.292, ppl=1.22, wps=24226.6, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=12900, lr=0.000278423, gnorm=0.505, loss_scale=32, train_wall=228, gb_free=8.8, wall=39600
2022-03-07 00:04:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:04:30 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 14.312 | nll_loss 14.096 | ppl 17508.3 | wps 44014.2 | wpb 510.9 | bsz 1 | num_updates 12946 | best_loss 8.318
2022-03-07 00:04:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12946 updates
2022-03-07 00:04:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:04:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:04:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 266 @ 12946 updates, score 14.312) (writing took 2.5793382860720158 seconds)
2022-03-07 00:04:33 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-07 00:04:33 | INFO | train | epoch 266 | loss 0.863 | nll_loss 0.289 | ppl 1.22 | wps 24233.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12946 | lr 0.000277928 | gnorm 0.5 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 39723
2022-03-07 00:04:33 | INFO | fairseq.trainer | begin training epoch 267
2022-03-07 00:04:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:05:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:06:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:06:41 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 14.338 | nll_loss 14.124 | ppl 17852.3 | wps 44247.7 | wpb 510.9 | bsz 1 | num_updates 12994 | best_loss 8.318
2022-03-07 00:06:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12994 updates
2022-03-07 00:06:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:06:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:06:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 267 @ 12994 updates, score 14.338) (writing took 2.548105787485838 seconds)
2022-03-07 00:06:44 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-07 00:06:44 | INFO | train | epoch 267 | loss 0.863 | nll_loss 0.289 | ppl 1.22 | wps 23725.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12994 | lr 0.000277414 | gnorm 0.504 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 39854
2022-03-07 00:06:44 | INFO | fairseq.trainer | begin training epoch 268
2022-03-07 00:06:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:06:59 | INFO | train_inner | epoch 268:      6 / 49 loss=0.863, nll_loss=0.289, ppl=1.22, wps=24026.8, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=13000, lr=0.00027735, gnorm=0.501, loss_scale=32, train_wall=230, gb_free=8.8, wall=39870
2022-03-07 00:08:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:08:53 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 14.418 | nll_loss 14.209 | ppl 18933.7 | wps 44639.4 | wpb 510.9 | bsz 1 | num_updates 13043 | best_loss 8.318
2022-03-07 00:08:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13043 updates
2022-03-07 00:08:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:08:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:08:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 268 @ 13043 updates, score 14.418) (writing took 2.4931960441172123 seconds)
2022-03-07 00:08:55 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-07 00:08:55 | INFO | train | epoch 268 | loss 0.862 | nll_loss 0.289 | ppl 1.22 | wps 24223.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13043 | lr 0.000276893 | gnorm 0.501 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 39985
2022-03-07 00:08:55 | INFO | fairseq.trainer | begin training epoch 269
2022-03-07 00:08:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:10:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:10:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:11:04 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 14.335 | nll_loss 14.12 | ppl 17806.6 | wps 43126.1 | wpb 510.9 | bsz 1 | num_updates 13091 | best_loss 8.318
2022-03-07 00:11:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13091 updates
2022-03-07 00:11:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:11:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:11:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 269 @ 13091 updates, score 14.335) (writing took 2.5559080950915813 seconds)
2022-03-07 00:11:07 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-07 00:11:07 | INFO | train | epoch 269 | loss 0.859 | nll_loss 0.286 | ppl 1.22 | wps 23635 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 13091 | lr 0.000276384 | gnorm 0.496 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 40117
2022-03-07 00:11:07 | INFO | fairseq.trainer | begin training epoch 270
2022-03-07 00:11:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:11:30 | INFO | train_inner | epoch 270:      9 / 49 loss=0.861, nll_loss=0.288, ppl=1.22, wps=23987.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.5, loss_scale=32, train_wall=231, gb_free=8.8, wall=40140
2022-03-07 00:13:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:13:16 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 14.458 | nll_loss 14.246 | ppl 19425.2 | wps 43816.1 | wpb 510.9 | bsz 1 | num_updates 13140 | best_loss 8.318
2022-03-07 00:13:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13140 updates
2022-03-07 00:13:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:13:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:13:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 270 @ 13140 updates, score 14.458) (writing took 2.570499926805496 seconds)
2022-03-07 00:13:18 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-07 00:13:18 | INFO | train | epoch 270 | loss 0.86 | nll_loss 0.287 | ppl 1.22 | wps 24192.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13140 | lr 0.000275869 | gnorm 0.5 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 40248
2022-03-07 00:13:18 | INFO | fairseq.trainer | begin training epoch 271
2022-03-07 00:13:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:15:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:15:27 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 14.38 | nll_loss 14.168 | ppl 18410.1 | wps 44420.3 | wpb 510.9 | bsz 1 | num_updates 13189 | best_loss 8.318
2022-03-07 00:15:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13189 updates
2022-03-07 00:15:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:15:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:15:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 271 @ 13189 updates, score 14.38) (writing took 2.501080336049199 seconds)
2022-03-07 00:15:29 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-07 00:15:29 | INFO | train | epoch 271 | loss 0.858 | nll_loss 0.285 | ppl 1.22 | wps 24249.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13189 | lr 0.000275356 | gnorm 0.496 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 40380
2022-03-07 00:15:29 | INFO | fairseq.trainer | begin training epoch 272
2022-03-07 00:15:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:15:58 | INFO | train_inner | epoch 272:     11 / 49 loss=0.858, nll_loss=0.285, ppl=1.22, wps=24235.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.497, loss_scale=32, train_wall=228, gb_free=8.8, wall=40408
2022-03-07 00:17:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:17:38 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 14.433 | nll_loss 14.225 | ppl 19147.7 | wps 44664.1 | wpb 510.9 | bsz 1 | num_updates 13238 | best_loss 8.318
2022-03-07 00:17:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13238 updates
2022-03-07 00:17:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:17:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:17:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 272 @ 13238 updates, score 14.433) (writing took 2.5369870606809855 seconds)
2022-03-07 00:17:41 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-07 00:17:41 | INFO | train | epoch 272 | loss 0.856 | nll_loss 0.283 | ppl 1.22 | wps 24185.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13238 | lr 0.000274846 | gnorm 0.495 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 40511
2022-03-07 00:17:41 | INFO | fairseq.trainer | begin training epoch 273
2022-03-07 00:17:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:19:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:19:49 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 14.391 | nll_loss 14.181 | ppl 18575.5 | wps 44200.6 | wpb 510.9 | bsz 1 | num_updates 13287 | best_loss 8.318
2022-03-07 00:19:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13287 updates
2022-03-07 00:19:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 273 @ 13287 updates, score 14.391) (writing took 2.535475045442581 seconds)
2022-03-07 00:19:52 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-07 00:19:52 | INFO | train | epoch 273 | loss 0.856 | nll_loss 0.283 | ppl 1.22 | wps 24248.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13287 | lr 0.000274338 | gnorm 0.489 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 40642
2022-03-07 00:19:52 | INFO | fairseq.trainer | begin training epoch 274
2022-03-07 00:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:20:25 | INFO | train_inner | epoch 274:     13 / 49 loss=0.855, nll_loss=0.283, ppl=1.22, wps=24257.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.491, loss_scale=64, train_wall=228, gb_free=8.8, wall=40675
2022-03-07 00:20:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:21:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:22:00 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 14.431 | nll_loss 14.222 | ppl 19106.5 | wps 44500.6 | wpb 510.9 | bsz 1 | num_updates 13335 | best_loss 8.318
2022-03-07 00:22:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13335 updates
2022-03-07 00:22:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:22:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:22:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 274 @ 13335 updates, score 14.431) (writing took 2.510919975116849 seconds)
2022-03-07 00:22:03 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-07 00:22:03 | INFO | train | epoch 274 | loss 0.853 | nll_loss 0.281 | ppl 1.22 | wps 23717.6 | ups 0.37 | wpb 64853.3 | bsz 126.7 | num_updates 13335 | lr 0.000273844 | gnorm 0.487 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 40773
2022-03-07 00:22:03 | INFO | fairseq.trainer | begin training epoch 275
2022-03-07 00:22:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:24:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:24:11 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 14.425 | nll_loss 14.219 | ppl 19063.7 | wps 44943.7 | wpb 510.9 | bsz 1 | num_updates 13384 | best_loss 8.318
2022-03-07 00:24:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13384 updates
2022-03-07 00:24:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:24:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:24:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 275 @ 13384 updates, score 14.425) (writing took 2.5416075587272644 seconds)
2022-03-07 00:24:14 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-07 00:24:14 | INFO | train | epoch 275 | loss 0.852 | nll_loss 0.279 | ppl 1.21 | wps 24261.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13384 | lr 0.000273342 | gnorm 0.488 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 40904
2022-03-07 00:24:14 | INFO | fairseq.trainer | begin training epoch 276
2022-03-07 00:24:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:24:55 | INFO | train_inner | epoch 276:     16 / 49 loss=0.852, nll_loss=0.28, ppl=1.21, wps=24039.4, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.484, loss_scale=32, train_wall=230, gb_free=8.8, wall=40945
2022-03-07 00:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:26:22 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 14.423 | nll_loss 14.216 | ppl 19029.2 | wps 45698.3 | wpb 510.9 | bsz 1 | num_updates 13433 | best_loss 8.318
2022-03-07 00:26:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13433 updates
2022-03-07 00:26:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:26:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:26:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 276 @ 13433 updates, score 14.423) (writing took 2.528148027136922 seconds)
2022-03-07 00:26:25 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-07 00:26:25 | INFO | train | epoch 276 | loss 0.851 | nll_loss 0.279 | ppl 1.21 | wps 24273.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13433 | lr 0.000272843 | gnorm 0.479 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 41035
2022-03-07 00:26:25 | INFO | fairseq.trainer | begin training epoch 277
2022-03-07 00:26:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:27:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:28:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:28:34 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 14.365 | nll_loss 14.156 | ppl 18260.3 | wps 44312 | wpb 510.9 | bsz 1 | num_updates 13481 | best_loss 8.318
2022-03-07 00:28:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13481 updates
2022-03-07 00:28:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:28:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:28:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 277 @ 13481 updates, score 14.365) (writing took 2.4689052049070597 seconds)
2022-03-07 00:28:36 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-07 00:28:36 | INFO | train | epoch 277 | loss 0.852 | nll_loss 0.28 | ppl 1.21 | wps 23708.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13481 | lr 0.000272357 | gnorm 0.487 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 41166
2022-03-07 00:28:36 | INFO | fairseq.trainer | begin training epoch 278
2022-03-07 00:28:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:29:25 | INFO | train_inner | epoch 278:     19 / 49 loss=0.851, nll_loss=0.279, ppl=1.21, wps=24046.4, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.484, loss_scale=32, train_wall=230, gb_free=8.8, wall=41215
2022-03-07 00:30:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:30:45 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 14.497 | nll_loss 14.29 | ppl 20035.1 | wps 44224.7 | wpb 510.9 | bsz 1 | num_updates 13530 | best_loss 8.318
2022-03-07 00:30:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13530 updates
2022-03-07 00:30:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:30:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:30:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 278 @ 13530 updates, score 14.497) (writing took 2.5333458986133337 seconds)
2022-03-07 00:30:47 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-07 00:30:47 | INFO | train | epoch 278 | loss 0.849 | nll_loss 0.278 | ppl 1.21 | wps 24223.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13530 | lr 0.000271864 | gnorm 0.485 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 41298
2022-03-07 00:30:47 | INFO | fairseq.trainer | begin training epoch 279
2022-03-07 00:30:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:32:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:32:56 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 14.322 | nll_loss 14.113 | ppl 17716.7 | wps 44153.3 | wpb 510.9 | bsz 1 | num_updates 13579 | best_loss 8.318
2022-03-07 00:32:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13579 updates
2022-03-07 00:32:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:32:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:32:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 279 @ 13579 updates, score 14.322) (writing took 2.5600473564118147 seconds)
2022-03-07 00:32:59 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-07 00:32:59 | INFO | train | epoch 279 | loss 0.847 | nll_loss 0.276 | ppl 1.21 | wps 24216.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13579 | lr 0.000271373 | gnorm 0.484 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 41429
2022-03-07 00:32:59 | INFO | fairseq.trainer | begin training epoch 280
2022-03-07 00:32:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:33:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:33:55 | INFO | train_inner | epoch 280:     22 / 49 loss=0.847, nll_loss=0.276, ppl=1.21, wps=24002.8, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.485, loss_scale=32, train_wall=230, gb_free=8.8, wall=41485
2022-03-07 00:35:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:35:07 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 14.404 | nll_loss 14.198 | ppl 18797.2 | wps 43372.3 | wpb 510.9 | bsz 1 | num_updates 13627 | best_loss 8.318
2022-03-07 00:35:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13627 updates
2022-03-07 00:35:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:35:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:35:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 280 @ 13627 updates, score 14.404) (writing took 2.539706652984023 seconds)
2022-03-07 00:35:10 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-07 00:35:10 | INFO | train | epoch 280 | loss 0.846 | nll_loss 0.275 | ppl 1.21 | wps 23700.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13627 | lr 0.000270894 | gnorm 0.484 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 41560
2022-03-07 00:35:10 | INFO | fairseq.trainer | begin training epoch 281
2022-03-07 00:35:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:37:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:37:19 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 14.408 | nll_loss 14.202 | ppl 18845.2 | wps 44373.6 | wpb 510.9 | bsz 1 | num_updates 13676 | best_loss 8.318
2022-03-07 00:37:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13676 updates
2022-03-07 00:37:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:37:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:37:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 281 @ 13676 updates, score 14.408) (writing took 2.5405586268752813 seconds)
2022-03-07 00:37:21 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-07 00:37:21 | INFO | train | epoch 281 | loss 0.846 | nll_loss 0.274 | ppl 1.21 | wps 24181.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13676 | lr 0.000270409 | gnorm 0.488 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 41692
2022-03-07 00:37:21 | INFO | fairseq.trainer | begin training epoch 282
2022-03-07 00:37:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:38:23 | INFO | train_inner | epoch 282:     24 / 49 loss=0.845, nll_loss=0.274, ppl=1.21, wps=24193.6, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.484, loss_scale=32, train_wall=228, gb_free=8.8, wall=41753
2022-03-07 00:39:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:39:30 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 14.446 | nll_loss 14.238 | ppl 19325.5 | wps 44705.9 | wpb 510.9 | bsz 1 | num_updates 13725 | best_loss 8.318
2022-03-07 00:39:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13725 updates
2022-03-07 00:39:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:39:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:39:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 282 @ 13725 updates, score 14.446) (writing took 2.5149495862424374 seconds)
2022-03-07 00:39:33 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-07 00:39:33 | INFO | train | epoch 282 | loss 0.844 | nll_loss 0.273 | ppl 1.21 | wps 24190.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13725 | lr 0.000269925 | gnorm 0.481 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 41823
2022-03-07 00:39:33 | INFO | fairseq.trainer | begin training epoch 283
2022-03-07 00:39:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:40:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:41:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:41:41 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 14.427 | nll_loss 14.222 | ppl 19116 | wps 44337.6 | wpb 510.9 | bsz 1 | num_updates 13773 | best_loss 8.318
2022-03-07 00:41:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13773 updates
2022-03-07 00:41:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:41:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:41:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 283 @ 13773 updates, score 14.427) (writing took 2.5063123367726803 seconds)
2022-03-07 00:41:44 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-07 00:41:44 | INFO | train | epoch 283 | loss 0.842 | nll_loss 0.272 | ppl 1.21 | wps 23742.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13773 | lr 0.000269455 | gnorm 0.483 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 41954
2022-03-07 00:41:44 | INFO | fairseq.trainer | begin training epoch 284
2022-03-07 00:41:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:42:53 | INFO | train_inner | epoch 284:     27 / 49 loss=0.843, nll_loss=0.272, ppl=1.21, wps=24059.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.482, loss_scale=32, train_wall=230, gb_free=8.8, wall=42023
2022-03-07 00:43:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:43:52 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 14.43 | nll_loss 14.221 | ppl 19102.5 | wps 44341.5 | wpb 510.9 | bsz 1 | num_updates 13822 | best_loss 8.318
2022-03-07 00:43:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13822 updates
2022-03-07 00:43:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:43:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:43:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 284 @ 13822 updates, score 14.43) (writing took 2.545862404629588 seconds)
2022-03-07 00:43:55 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-07 00:43:55 | INFO | train | epoch 284 | loss 0.842 | nll_loss 0.272 | ppl 1.21 | wps 24262 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13822 | lr 0.000268977 | gnorm 0.479 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 42085
2022-03-07 00:43:55 | INFO | fairseq.trainer | begin training epoch 285
2022-03-07 00:43:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:45:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:46:03 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 14.403 | nll_loss 14.194 | ppl 18745 | wps 44469.6 | wpb 510.9 | bsz 1 | num_updates 13871 | best_loss 8.318
2022-03-07 00:46:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13871 updates
2022-03-07 00:46:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:46:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:46:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 285 @ 13871 updates, score 14.403) (writing took 2.4841195438057184 seconds)
2022-03-07 00:46:06 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-07 00:46:06 | INFO | train | epoch 285 | loss 0.839 | nll_loss 0.269 | ppl 1.21 | wps 24252.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13871 | lr 0.000268501 | gnorm 0.475 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 42216
2022-03-07 00:46:06 | INFO | fairseq.trainer | begin training epoch 286
2022-03-07 00:46:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:46:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:47:22 | INFO | train_inner | epoch 286:     30 / 49 loss=0.84, nll_loss=0.269, ppl=1.21, wps=24048.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.476, loss_scale=32, train_wall=230, gb_free=8.8, wall=42293
2022-03-07 00:48:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:48:14 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 14.402 | nll_loss 14.193 | ppl 18723.5 | wps 44507.2 | wpb 510.9 | bsz 1 | num_updates 13919 | best_loss 8.318
2022-03-07 00:48:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13919 updates
2022-03-07 00:48:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:48:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:48:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 286 @ 13919 updates, score 14.402) (writing took 2.528618549928069 seconds)
2022-03-07 00:48:17 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-07 00:48:17 | INFO | train | epoch 286 | loss 0.839 | nll_loss 0.269 | ppl 1.21 | wps 23744.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13919 | lr 0.000268038 | gnorm 0.475 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 42347
2022-03-07 00:48:17 | INFO | fairseq.trainer | begin training epoch 287
2022-03-07 00:48:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:50:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:50:25 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 14.436 | nll_loss 14.231 | ppl 19223 | wps 44086.8 | wpb 510.9 | bsz 1 | num_updates 13968 | best_loss 8.318
2022-03-07 00:50:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13968 updates
2022-03-07 00:50:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:50:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:50:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 287 @ 13968 updates, score 14.436) (writing took 2.5237458795309067 seconds)
2022-03-07 00:50:28 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-07 00:50:28 | INFO | train | epoch 287 | loss 0.839 | nll_loss 0.269 | ppl 1.21 | wps 24267.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13968 | lr 0.000267567 | gnorm 0.483 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 42478
2022-03-07 00:50:28 | INFO | fairseq.trainer | begin training epoch 288
2022-03-07 00:50:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:51:50 | INFO | train_inner | epoch 288:     32 / 49 loss=0.839, nll_loss=0.269, ppl=1.2, wps=24276.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.476, loss_scale=32, train_wall=228, gb_free=8.8, wall=42560
2022-03-07 00:52:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:52:37 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 14.448 | nll_loss 14.243 | ppl 19387.2 | wps 44574.3 | wpb 510.9 | bsz 1 | num_updates 14017 | best_loss 8.318
2022-03-07 00:52:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14017 updates
2022-03-07 00:52:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:52:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:52:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 288 @ 14017 updates, score 14.448) (writing took 2.5311195738613605 seconds)
2022-03-07 00:52:39 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-07 00:52:39 | INFO | train | epoch 288 | loss 0.837 | nll_loss 0.267 | ppl 1.2 | wps 24214.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14017 | lr 0.000267099 | gnorm 0.472 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 42609
2022-03-07 00:52:39 | INFO | fairseq.trainer | begin training epoch 289
2022-03-07 00:52:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:54:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:54:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:54:48 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 14.249 | nll_loss 14.039 | ppl 16831.8 | wps 45081.1 | wpb 510.9 | bsz 1 | num_updates 14065 | best_loss 8.318
2022-03-07 00:54:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14065 updates
2022-03-07 00:54:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:54:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:54:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 289 @ 14065 updates, score 14.249) (writing took 2.522432232275605 seconds)
2022-03-07 00:54:50 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-07 00:54:50 | INFO | train | epoch 289 | loss 0.836 | nll_loss 0.266 | ppl 1.2 | wps 23773.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14065 | lr 0.000266643 | gnorm 0.471 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 42740
2022-03-07 00:54:50 | INFO | fairseq.trainer | begin training epoch 290
2022-03-07 00:54:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:56:19 | INFO | train_inner | epoch 290:     35 / 49 loss=0.836, nll_loss=0.266, ppl=1.2, wps=24066.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.473, loss_scale=32, train_wall=230, gb_free=8.8, wall=42829
2022-03-07 00:56:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:56:58 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 14.425 | nll_loss 14.22 | ppl 19078 | wps 45206.3 | wpb 510.9 | bsz 1 | num_updates 14114 | best_loss 8.318
2022-03-07 00:56:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14114 updates
2022-03-07 00:56:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:57:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:57:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 290 @ 14114 updates, score 14.425) (writing took 2.5478881020098925 seconds)
2022-03-07 00:57:01 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-07 00:57:01 | INFO | train | epoch 290 | loss 0.835 | nll_loss 0.265 | ppl 1.2 | wps 24311.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14114 | lr 0.00026618 | gnorm 0.474 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 42871
2022-03-07 00:57:01 | INFO | fairseq.trainer | begin training epoch 291
2022-03-07 00:57:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:59:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:59:09 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 14.444 | nll_loss 14.239 | ppl 19332.8 | wps 43986.4 | wpb 510.9 | bsz 1 | num_updates 14163 | best_loss 8.318
2022-03-07 00:59:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14163 updates
2022-03-07 00:59:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:59:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:59:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 291 @ 14163 updates, score 14.444) (writing took 2.5387057177722454 seconds)
2022-03-07 00:59:12 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-07 00:59:12 | INFO | train | epoch 291 | loss 0.833 | nll_loss 0.264 | ppl 1.2 | wps 24295.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14163 | lr 0.000265719 | gnorm 0.468 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 43002
2022-03-07 00:59:12 | INFO | fairseq.trainer | begin training epoch 292
2022-03-07 00:59:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:00:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:00:48 | INFO | train_inner | epoch 292:     38 / 49 loss=0.833, nll_loss=0.264, ppl=1.2, wps=24117, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.472, loss_scale=32, train_wall=229, gb_free=8.8, wall=43098
2022-03-07 01:01:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:01:20 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 14.531 | nll_loss 14.329 | ppl 20580.4 | wps 44859.5 | wpb 510.9 | bsz 1 | num_updates 14211 | best_loss 8.318
2022-03-07 01:01:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14211 updates
2022-03-07 01:01:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:01:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:01:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 292 @ 14211 updates, score 14.531) (writing took 2.531359251588583 seconds)
2022-03-07 01:01:22 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-07 01:01:22 | INFO | train | epoch 292 | loss 0.833 | nll_loss 0.264 | ppl 1.2 | wps 23782.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14211 | lr 0.00026527 | gnorm 0.473 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 43133
2022-03-07 01:01:22 | INFO | fairseq.trainer | begin training epoch 293
2022-03-07 01:01:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:03:31 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 14.485 | nll_loss 14.282 | ppl 19914.1 | wps 44519.5 | wpb 510.9 | bsz 1 | num_updates 14260 | best_loss 8.318
2022-03-07 01:03:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14260 updates
2022-03-07 01:03:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:03:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:03:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 293 @ 14260 updates, score 14.485) (writing took 2.5088101904839277 seconds)
2022-03-07 01:03:33 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-07 01:03:33 | INFO | train | epoch 293 | loss 0.832 | nll_loss 0.263 | ppl 1.2 | wps 24300.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14260 | lr 0.000264814 | gnorm 0.469 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 43264
2022-03-07 01:03:33 | INFO | fairseq.trainer | begin training epoch 294
2022-03-07 01:03:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:05:15 | INFO | train_inner | epoch 294:     40 / 49 loss=0.832, nll_loss=0.264, ppl=1.2, wps=24304.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.473, loss_scale=32, train_wall=228, gb_free=8.8, wall=43365
2022-03-07 01:05:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:05:42 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 14.399 | nll_loss 14.192 | ppl 18713.5 | wps 44122.4 | wpb 510.9 | bsz 1 | num_updates 14309 | best_loss 8.318
2022-03-07 01:05:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14309 updates
2022-03-07 01:05:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:05:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:05:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 294 @ 14309 updates, score 14.399) (writing took 2.6398115940392017 seconds)
2022-03-07 01:05:44 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-07 01:05:44 | INFO | train | epoch 294 | loss 0.832 | nll_loss 0.263 | ppl 1.2 | wps 24258.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14309 | lr 0.00026436 | gnorm 0.478 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 43395
2022-03-07 01:05:44 | INFO | fairseq.trainer | begin training epoch 295
2022-03-07 01:05:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:07:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:07:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:07:53 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 14.443 | nll_loss 14.237 | ppl 19313.8 | wps 44233.4 | wpb 510.9 | bsz 1 | num_updates 14357 | best_loss 8.318
2022-03-07 01:07:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14357 updates
2022-03-07 01:07:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:07:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:07:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 295 @ 14357 updates, score 14.443) (writing took 2.5223151948302984 seconds)
2022-03-07 01:07:55 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 01:07:55 | INFO | train | epoch 295 | loss 0.83 | nll_loss 0.261 | ppl 1.2 | wps 23774 | ups 0.37 | wpb 64853.3 | bsz 126.7 | num_updates 14357 | lr 0.000263917 | gnorm 0.464 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 43525
2022-03-07 01:07:55 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 01:07:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:09:44 | INFO | train_inner | epoch 296:     43 / 49 loss=0.829, nll_loss=0.261, ppl=1.2, wps=24077.7, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.466, loss_scale=32, train_wall=230, gb_free=8.8, wall=43635
2022-03-07 01:09:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:10:03 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 14.374 | nll_loss 14.168 | ppl 18407.2 | wps 44508.2 | wpb 510.9 | bsz 1 | num_updates 14406 | best_loss 8.318
2022-03-07 01:10:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14406 updates
2022-03-07 01:10:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:10:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:10:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 296 @ 14406 updates, score 14.374) (writing took 2.565513275563717 seconds)
2022-03-07 01:10:06 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 01:10:06 | INFO | train | epoch 296 | loss 0.829 | nll_loss 0.261 | ppl 1.2 | wps 24303 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14406 | lr 0.000263468 | gnorm 0.468 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 43656
2022-03-07 01:10:06 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 01:10:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:12:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:12:15 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 14.451 | nll_loss 14.245 | ppl 19422.9 | wps 44962 | wpb 510.9 | bsz 1 | num_updates 14455 | best_loss 8.318
2022-03-07 01:12:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14455 updates
2022-03-07 01:12:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:12:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:12:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 297 @ 14455 updates, score 14.451) (writing took 2.5687395874410868 seconds)
2022-03-07 01:12:18 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 01:12:18 | INFO | train | epoch 297 | loss 0.828 | nll_loss 0.26 | ppl 1.2 | wps 24103.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14455 | lr 0.000263021 | gnorm 0.465 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 43788
2022-03-07 01:12:18 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 01:12:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:13:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:14:15 | INFO | train_inner | epoch 298:     46 / 49 loss=0.827, nll_loss=0.259, ppl=1.2, wps=23984.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=14500, lr=0.000262613, gnorm=0.467, loss_scale=32, train_wall=231, gb_free=8.8, wall=43905
2022-03-07 01:14:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:14:26 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 14.452 | nll_loss 14.247 | ppl 19447.2 | wps 43976.8 | wpb 510.9 | bsz 1 | num_updates 14503 | best_loss 8.318
2022-03-07 01:14:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14503 updates
2022-03-07 01:14:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:14:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:14:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 298 @ 14503 updates, score 14.452) (writing took 2.502133548259735 seconds)
2022-03-07 01:14:29 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 01:14:29 | INFO | train | epoch 298 | loss 0.826 | nll_loss 0.258 | ppl 1.2 | wps 23754.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14503 | lr 0.000262586 | gnorm 0.467 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 43919
2022-03-07 01:14:29 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 01:14:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:16:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:16:37 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 14.428 | nll_loss 14.224 | ppl 19131.5 | wps 44493 | wpb 510.9 | bsz 1 | num_updates 14552 | best_loss 8.318
2022-03-07 01:16:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14552 updates
2022-03-07 01:16:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:16:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:16:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 299 @ 14552 updates, score 14.428) (writing took 2.515662871301174 seconds)
2022-03-07 01:16:40 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 01:16:40 | INFO | train | epoch 299 | loss 0.825 | nll_loss 0.258 | ppl 1.2 | wps 24259.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14552 | lr 0.000262143 | gnorm 0.457 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 44050
2022-03-07 01:16:40 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 01:16:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:18:42 | INFO | train_inner | epoch 300:     48 / 49 loss=0.825, nll_loss=0.258, ppl=1.2, wps=24303.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=14600, lr=0.000261712, gnorm=0.459, loss_scale=32, train_wall=227, gb_free=8.8, wall=44172
2022-03-07 01:18:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:18:48 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 14.379 | nll_loss 14.176 | ppl 18508.2 | wps 44728.3 | wpb 510.9 | bsz 1 | num_updates 14601 | best_loss 8.318
2022-03-07 01:18:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14601 updates
2022-03-07 01:18:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:18:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:18:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 300 @ 14601 updates, score 14.379) (writing took 2.537851555272937 seconds)
2022-03-07 01:18:51 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 01:18:51 | INFO | train | epoch 300 | loss 0.825 | nll_loss 0.257 | ppl 1.2 | wps 24300.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14601 | lr 0.000261703 | gnorm 0.461 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 44181
2022-03-07 01:18:51 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 01:18:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:20:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:20:59 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 14.442 | nll_loss 14.237 | ppl 19310.1 | wps 45037.8 | wpb 510.9 | bsz 1 | num_updates 14650 | best_loss 8.318
2022-03-07 01:20:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14650 updates
2022-03-07 01:20:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:21:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:21:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 301 @ 14650 updates, score 14.442) (writing took 2.584947546944022 seconds)
2022-03-07 01:21:02 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 01:21:02 | INFO | train | epoch 301 | loss 0.823 | nll_loss 0.256 | ppl 1.19 | wps 24211.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14650 | lr 0.000261265 | gnorm 0.454 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 44312
2022-03-07 01:21:02 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 01:21:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:21:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:23:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:23:11 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 14.345 | nll_loss 14.14 | ppl 18047.5 | wps 42624.7 | wpb 510.9 | bsz 1 | num_updates 14698 | best_loss 8.318
2022-03-07 01:23:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14698 updates
2022-03-07 01:23:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:23:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 302 @ 14698 updates, score 14.345) (writing took 2.547470023855567 seconds)
2022-03-07 01:23:14 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 01:23:14 | INFO | train | epoch 302 | loss 0.823 | nll_loss 0.256 | ppl 1.19 | wps 23643.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 14698 | lr 0.000260838 | gnorm 0.465 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 44444
2022-03-07 01:23:14 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 01:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:23:19 | INFO | train_inner | epoch 303:      2 / 49 loss=0.823, nll_loss=0.256, ppl=1.19, wps=23313.8, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=14700, lr=0.00026082, gnorm=0.461, loss_scale=32, train_wall=229, gb_free=8.8, wall=44449
2022-03-07 01:25:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:25:22 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 14.321 | nll_loss 14.114 | ppl 17733 | wps 44259.4 | wpb 510.9 | bsz 1 | num_updates 14747 | best_loss 8.318
2022-03-07 01:25:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14747 updates
2022-03-07 01:25:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:25:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:25:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 303 @ 14747 updates, score 14.321) (writing took 2.4995258804410696 seconds)
2022-03-07 01:25:25 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 01:25:25 | INFO | train | epoch 303 | loss 0.821 | nll_loss 0.254 | ppl 1.19 | wps 24231.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14747 | lr 0.000260404 | gnorm 0.466 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 44575
2022-03-07 01:25:25 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 01:25:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:27:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:27:33 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 14.312 | nll_loss 14.106 | ppl 17634.9 | wps 44364.6 | wpb 510.9 | bsz 1 | num_updates 14796 | best_loss 8.318
2022-03-07 01:27:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14796 updates
2022-03-07 01:27:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:27:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:27:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 304 @ 14796 updates, score 14.312) (writing took 2.4798595625907183 seconds)
2022-03-07 01:27:36 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 01:27:36 | INFO | train | epoch 304 | loss 0.82 | nll_loss 0.253 | ppl 1.19 | wps 24216.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14796 | lr 0.000259973 | gnorm 0.456 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 44706
2022-03-07 01:27:36 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 01:27:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:27:46 | INFO | train_inner | epoch 305:      4 / 49 loss=0.821, nll_loss=0.254, ppl=1.19, wps=24255.8, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.461, loss_scale=64, train_wall=228, gb_free=8.8, wall=44716
2022-03-07 01:29:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:29:44 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 14.363 | nll_loss 14.156 | ppl 18254.2 | wps 44479.6 | wpb 510.9 | bsz 1 | num_updates 14845 | best_loss 8.318
2022-03-07 01:29:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14845 updates
2022-03-07 01:29:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:29:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:29:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 305 @ 14845 updates, score 14.363) (writing took 2.55096741206944 seconds)
2022-03-07 01:29:47 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 01:29:47 | INFO | train | epoch 305 | loss 0.82 | nll_loss 0.253 | ppl 1.19 | wps 24301.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14845 | lr 0.000259543 | gnorm 0.456 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 44837
2022-03-07 01:29:47 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 01:29:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:29:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:31:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:31:55 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 14.364 | nll_loss 14.158 | ppl 18280.2 | wps 44259.3 | wpb 510.9 | bsz 1 | num_updates 14893 | best_loss 8.318
2022-03-07 01:31:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14893 updates
2022-03-07 01:31:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:31:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:31:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 306 @ 14893 updates, score 14.364) (writing took 2.5392023883759975 seconds)
2022-03-07 01:31:58 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 01:31:58 | INFO | train | epoch 306 | loss 0.819 | nll_loss 0.252 | ppl 1.19 | wps 23716.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14893 | lr 0.000259125 | gnorm 0.46 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 44968
2022-03-07 01:31:58 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 01:31:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:32:16 | INFO | train_inner | epoch 307:      7 / 49 loss=0.819, nll_loss=0.252, ppl=1.19, wps=24054.8, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.458, loss_scale=32, train_wall=230, gb_free=8.8, wall=44986
2022-03-07 01:34:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:34:06 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 14.388 | nll_loss 14.184 | ppl 18610.6 | wps 44318.4 | wpb 510.9 | bsz 1 | num_updates 14942 | best_loss 8.318
2022-03-07 01:34:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14942 updates
2022-03-07 01:34:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:34:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:34:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 307 @ 14942 updates, score 14.388) (writing took 2.521526040509343 seconds)
2022-03-07 01:34:09 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 01:34:09 | INFO | train | epoch 307 | loss 0.817 | nll_loss 0.25 | ppl 1.19 | wps 24283.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14942 | lr 0.0002587 | gnorm 0.453 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 45099
2022-03-07 01:34:09 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 01:34:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:35:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:36:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:36:17 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 14.405 | nll_loss 14.2 | ppl 18824.1 | wps 44096.7 | wpb 510.9 | bsz 1 | num_updates 14990 | best_loss 8.318
2022-03-07 01:36:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14990 updates
2022-03-07 01:36:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:36:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:36:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 308 @ 14990 updates, score 14.405) (writing took 2.5804736334830523 seconds)
2022-03-07 01:36:20 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 01:36:20 | INFO | train | epoch 308 | loss 0.816 | nll_loss 0.25 | ppl 1.19 | wps 23776.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14990 | lr 0.000258285 | gnorm 0.452 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 45230
2022-03-07 01:36:20 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 01:36:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:36:45 | INFO | train_inner | epoch 309:     10 / 49 loss=0.816, nll_loss=0.25, ppl=1.19, wps=24080.5, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.451, loss_scale=32, train_wall=230, gb_free=8.8, wall=45256
2022-03-07 01:38:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:38:29 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 14.368 | nll_loss 14.161 | ppl 18321.5 | wps 44388.4 | wpb 510.9 | bsz 1 | num_updates 15039 | best_loss 8.318
2022-03-07 01:38:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15039 updates
2022-03-07 01:38:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:38:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:38:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 309 @ 15039 updates, score 14.368) (writing took 2.4706404507160187 seconds)
2022-03-07 01:38:31 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 01:38:31 | INFO | train | epoch 309 | loss 0.816 | nll_loss 0.25 | ppl 1.19 | wps 24199.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15039 | lr 0.000257864 | gnorm 0.453 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 45361
2022-03-07 01:38:31 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 01:38:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:40:40 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 14.406 | nll_loss 14.205 | ppl 18886.3 | wps 44648.7 | wpb 510.9 | bsz 1 | num_updates 15088 | best_loss 8.318
2022-03-07 01:40:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15088 updates
2022-03-07 01:40:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:40:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:40:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 310 @ 15088 updates, score 14.406) (writing took 2.43788349814713 seconds)
2022-03-07 01:40:42 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 01:40:42 | INFO | train | epoch 310 | loss 0.815 | nll_loss 0.249 | ppl 1.19 | wps 24269.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15088 | lr 0.000257445 | gnorm 0.45 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 45492
2022-03-07 01:40:42 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 01:40:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:41:13 | INFO | train_inner | epoch 311:     12 / 49 loss=0.815, nll_loss=0.25, ppl=1.19, wps=24259.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.452, loss_scale=32, train_wall=228, gb_free=8.8, wall=45523
2022-03-07 01:41:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:42:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:42:51 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 14.458 | nll_loss 14.256 | ppl 19561.8 | wps 43691.6 | wpb 510.9 | bsz 1 | num_updates 15136 | best_loss 8.318
2022-03-07 01:42:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15136 updates
2022-03-07 01:42:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:42:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:42:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 311 @ 15136 updates, score 14.458) (writing took 2.510196302086115 seconds)
2022-03-07 01:42:53 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 01:42:53 | INFO | train | epoch 311 | loss 0.814 | nll_loss 0.248 | ppl 1.19 | wps 23749.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 15136 | lr 0.000257036 | gnorm 0.451 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 45623
2022-03-07 01:42:53 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 01:42:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:44:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:45:01 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 14.344 | nll_loss 14.14 | ppl 18053 | wps 45208 | wpb 510.9 | bsz 1 | num_updates 15185 | best_loss 8.318
2022-03-07 01:45:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15185 updates
2022-03-07 01:45:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:45:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:45:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 312 @ 15185 updates, score 14.344) (writing took 2.4904922768473625 seconds)
2022-03-07 01:45:04 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 01:45:04 | INFO | train | epoch 312 | loss 0.812 | nll_loss 0.247 | ppl 1.19 | wps 24312.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15185 | lr 0.000256621 | gnorm 0.447 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 45754
2022-03-07 01:45:04 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 01:45:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:45:42 | INFO | train_inner | epoch 313:     15 / 49 loss=0.813, nll_loss=0.247, ppl=1.19, wps=24067.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.45, loss_scale=32, train_wall=230, gb_free=8.8, wall=45792
2022-03-07 01:47:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:47:13 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 14.408 | nll_loss 14.206 | ppl 18898.9 | wps 43560.6 | wpb 510.9 | bsz 1 | num_updates 15234 | best_loss 8.318
2022-03-07 01:47:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15234 updates
2022-03-07 01:47:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:47:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 313 @ 15234 updates, score 14.408) (writing took 2.495373258367181 seconds)
2022-03-07 01:47:15 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 01:47:15 | INFO | train | epoch 313 | loss 0.813 | nll_loss 0.247 | ppl 1.19 | wps 24188.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15234 | lr 0.000256208 | gnorm 0.451 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 45885
2022-03-07 01:47:15 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 01:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:49:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:49:24 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 14.4 | nll_loss 14.197 | ppl 18774.8 | wps 44472.1 | wpb 510.9 | bsz 1 | num_updates 15283 | best_loss 8.318
2022-03-07 01:49:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15283 updates
2022-03-07 01:49:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:49:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:49:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 314 @ 15283 updates, score 14.4) (writing took 2.5533017944544554 seconds)
2022-03-07 01:49:26 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 01:49:26 | INFO | train | epoch 314 | loss 0.81 | nll_loss 0.245 | ppl 1.19 | wps 24241.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15283 | lr 0.000255797 | gnorm 0.438 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 46017
2022-03-07 01:49:26 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 01:49:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:49:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:50:12 | INFO | train_inner | epoch 315:     18 / 49 loss=0.811, nll_loss=0.246, ppl=1.19, wps=24034.6, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.444, loss_scale=32, train_wall=230, gb_free=8.8, wall=46062
2022-03-07 01:51:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:51:35 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 14.369 | nll_loss 14.166 | ppl 18384.4 | wps 44642 | wpb 510.9 | bsz 1 | num_updates 15331 | best_loss 8.318
2022-03-07 01:51:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15331 updates
2022-03-07 01:51:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:51:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:51:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 315 @ 15331 updates, score 14.369) (writing took 2.4316751286387444 seconds)
2022-03-07 01:51:37 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 01:51:37 | INFO | train | epoch 315 | loss 0.811 | nll_loss 0.245 | ppl 1.19 | wps 23767.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 15331 | lr 0.000255396 | gnorm 0.451 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 46148
2022-03-07 01:51:37 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 01:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:53:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:53:46 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 14.358 | nll_loss 14.154 | ppl 18224.5 | wps 44462.8 | wpb 510.9 | bsz 1 | num_updates 15380 | best_loss 8.318
2022-03-07 01:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15380 updates
2022-03-07 01:53:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:53:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 316 @ 15380 updates, score 14.358) (writing took 2.5372272469103336 seconds)
2022-03-07 01:53:48 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 01:53:48 | INFO | train | epoch 316 | loss 0.81 | nll_loss 0.245 | ppl 1.18 | wps 24256 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15380 | lr 0.000254989 | gnorm 0.444 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 46279
2022-03-07 01:53:48 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 01:53:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:54:39 | INFO | train_inner | epoch 317:     20 / 49 loss=0.809, nll_loss=0.244, ppl=1.18, wps=24286.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.445, loss_scale=32, train_wall=228, gb_free=8.8, wall=46330
2022-03-07 01:55:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:55:57 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 14.532 | nll_loss 14.331 | ppl 20606.3 | wps 43887.3 | wpb 510.9 | bsz 1 | num_updates 15429 | best_loss 8.318
2022-03-07 01:55:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15429 updates
2022-03-07 01:55:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:55:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:55:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 317 @ 15429 updates, score 14.532) (writing took 2.5362683087587357 seconds)
2022-03-07 01:55:59 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 01:55:59 | INFO | train | epoch 317 | loss 0.808 | nll_loss 0.244 | ppl 1.18 | wps 24226.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15429 | lr 0.000254584 | gnorm 0.44 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 46410
2022-03-07 01:55:59 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 01:55:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:57:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:58:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:58:08 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 14.506 | nll_loss 14.307 | ppl 20262.6 | wps 44278.8 | wpb 510.9 | bsz 1 | num_updates 15477 | best_loss 8.318
2022-03-07 01:58:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15477 updates
2022-03-07 01:58:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:58:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:58:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 318 @ 15477 updates, score 14.506) (writing took 2.4826440010219812 seconds)
2022-03-07 01:58:10 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 01:58:10 | INFO | train | epoch 318 | loss 0.807 | nll_loss 0.242 | ppl 1.18 | wps 23770 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 15477 | lr 0.000254189 | gnorm 0.441 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 46541
2022-03-07 01:58:10 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 01:58:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:59:09 | INFO | train_inner | epoch 319:     23 / 49 loss=0.807, nll_loss=0.243, ppl=1.18, wps=24054.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.441, loss_scale=32, train_wall=230, gb_free=8.8, wall=46599
2022-03-07 02:00:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:00:19 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 14.225 | nll_loss 14.021 | ppl 16621.9 | wps 44527.5 | wpb 510.9 | bsz 1 | num_updates 15526 | best_loss 8.318
2022-03-07 02:00:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15526 updates
2022-03-07 02:00:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:00:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:00:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 319 @ 15526 updates, score 14.225) (writing took 2.5406695175915956 seconds)
2022-03-07 02:00:21 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 02:00:21 | INFO | train | epoch 319 | loss 0.807 | nll_loss 0.243 | ppl 1.18 | wps 24249.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15526 | lr 0.000253787 | gnorm 0.443 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 46672
2022-03-07 02:00:21 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 02:00:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:02:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:02:30 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 14.402 | nll_loss 14.202 | ppl 18841 | wps 44143.6 | wpb 510.9 | bsz 1 | num_updates 15575 | best_loss 8.318
2022-03-07 02:02:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15575 updates
2022-03-07 02:02:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:02:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:02:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 320 @ 15575 updates, score 14.402) (writing took 2.47252756357193 seconds)
2022-03-07 02:02:32 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 02:02:32 | INFO | train | epoch 320 | loss 0.806 | nll_loss 0.242 | ppl 1.18 | wps 24295.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15575 | lr 0.000253388 | gnorm 0.438 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 46803
2022-03-07 02:02:32 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 02:02:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:03:36 | INFO | train_inner | epoch 321:     25 / 49 loss=0.806, nll_loss=0.242, ppl=1.18, wps=24285.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.44, loss_scale=64, train_wall=228, gb_free=8.8, wall=46866
2022-03-07 02:04:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:04:41 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 14.366 | nll_loss 14.166 | ppl 18381.7 | wps 44587.2 | wpb 510.9 | bsz 1 | num_updates 15624 | best_loss 8.318
2022-03-07 02:04:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15624 updates
2022-03-07 02:04:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:04:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:04:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 321 @ 15624 updates, score 14.366) (writing took 2.4968847557902336 seconds)
2022-03-07 02:04:43 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 02:04:43 | INFO | train | epoch 321 | loss 0.805 | nll_loss 0.241 | ppl 1.18 | wps 24232.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15624 | lr 0.00025299 | gnorm 0.437 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 46934
2022-03-07 02:04:43 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 02:04:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:06:52 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 14.331 | nll_loss 14.128 | ppl 17909.2 | wps 44529.9 | wpb 510.9 | bsz 1 | num_updates 15673 | best_loss 8.318
2022-03-07 02:06:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15673 updates
2022-03-07 02:06:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:06:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:06:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 322 @ 15673 updates, score 14.331) (writing took 2.5324396397918463 seconds)
2022-03-07 02:06:54 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 02:06:54 | INFO | train | epoch 322 | loss 0.804 | nll_loss 0.24 | ppl 1.18 | wps 24242.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15673 | lr 0.000252595 | gnorm 0.436 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 47065
2022-03-07 02:06:54 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 02:06:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:07:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:08:06 | INFO | train_inner | epoch 323:     28 / 49 loss=0.804, nll_loss=0.24, ppl=1.18, wps=24033.4, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.438, loss_scale=32, train_wall=230, gb_free=8.8, wall=47136
2022-03-07 02:08:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:09:03 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 14.378 | nll_loss 14.176 | ppl 18510.1 | wps 45260.3 | wpb 510.9 | bsz 1 | num_updates 15721 | best_loss 8.318
2022-03-07 02:09:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15721 updates
2022-03-07 02:09:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:09:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:09:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 323 @ 15721 updates, score 14.378) (writing took 2.535894475877285 seconds)
2022-03-07 02:09:05 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 02:09:05 | INFO | train | epoch 323 | loss 0.803 | nll_loss 0.239 | ppl 1.18 | wps 23758.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 15721 | lr 0.000252209 | gnorm 0.443 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 47196
2022-03-07 02:09:05 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 02:09:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:11:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:11:14 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 14.428 | nll_loss 14.228 | ppl 19194.1 | wps 43781.7 | wpb 510.9 | bsz 1 | num_updates 15770 | best_loss 8.318
2022-03-07 02:11:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15770 updates
2022-03-07 02:11:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:11:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:11:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 324 @ 15770 updates, score 14.428) (writing took 2.5412636753171682 seconds)
2022-03-07 02:11:17 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 02:11:17 | INFO | train | epoch 324 | loss 0.803 | nll_loss 0.239 | ppl 1.18 | wps 24232.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15770 | lr 0.000251816 | gnorm 0.44 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 47327
2022-03-07 02:11:17 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 02:11:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:12:33 | INFO | train_inner | epoch 325:     30 / 49 loss=0.803, nll_loss=0.239, ppl=1.18, wps=24284.5, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.439, loss_scale=32, train_wall=228, gb_free=8.8, wall=47403
2022-03-07 02:13:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:13:25 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 14.377 | nll_loss 14.177 | ppl 18520.2 | wps 44331.2 | wpb 510.9 | bsz 1 | num_updates 15819 | best_loss 8.318
2022-03-07 02:13:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15819 updates
2022-03-07 02:13:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:13:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:13:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 325 @ 15819 updates, score 14.377) (writing took 2.534358646720648 seconds)
2022-03-07 02:13:28 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 02:13:28 | INFO | train | epoch 325 | loss 0.801 | nll_loss 0.238 | ppl 1.18 | wps 24224.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15819 | lr 0.000251426 | gnorm 0.435 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 47458
2022-03-07 02:13:28 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 02:13:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:14:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:15:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:15:37 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 14.308 | nll_loss 14.108 | ppl 17660.3 | wps 44155.4 | wpb 510.9 | bsz 1 | num_updates 15867 | best_loss 8.318
2022-03-07 02:15:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15867 updates
2022-03-07 02:15:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:15:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:15:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 326 @ 15867 updates, score 14.308) (writing took 2.4510385040193796 seconds)
2022-03-07 02:15:39 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 02:15:39 | INFO | train | epoch 326 | loss 0.801 | nll_loss 0.238 | ppl 1.18 | wps 23690.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 15867 | lr 0.000251046 | gnorm 0.445 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 47589
2022-03-07 02:15:39 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 02:15:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:17:03 | INFO | train_inner | epoch 327:     33 / 49 loss=0.801, nll_loss=0.238, ppl=1.18, wps=24010, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.442, loss_scale=32, train_wall=230, gb_free=8.8, wall=47674
2022-03-07 02:17:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:17:48 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 14.34 | nll_loss 14.14 | ppl 18056.7 | wps 44408.4 | wpb 510.9 | bsz 1 | num_updates 15916 | best_loss 8.318
2022-03-07 02:17:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15916 updates
2022-03-07 02:17:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:17:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:17:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 327 @ 15916 updates, score 14.34) (writing took 2.557212060317397 seconds)
2022-03-07 02:17:50 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 02:17:50 | INFO | train | epoch 327 | loss 0.8 | nll_loss 0.237 | ppl 1.18 | wps 24257.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15916 | lr 0.000250659 | gnorm 0.438 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 47720
2022-03-07 02:17:50 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 02:17:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:19:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:19:59 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 14.361 | nll_loss 14.16 | ppl 18302.2 | wps 44383.5 | wpb 510.9 | bsz 1 | num_updates 15965 | best_loss 8.318
2022-03-07 02:19:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15965 updates
2022-03-07 02:19:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:20:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:20:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 328 @ 15965 updates, score 14.361) (writing took 2.546411456540227 seconds)
2022-03-07 02:20:01 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 02:20:01 | INFO | train | epoch 328 | loss 0.798 | nll_loss 0.235 | ppl 1.18 | wps 24206.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15965 | lr 0.000250274 | gnorm 0.432 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 47852
2022-03-07 02:20:02 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 02:20:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:21:31 | INFO | train_inner | epoch 329:     35 / 49 loss=0.799, nll_loss=0.235, ppl=1.18, wps=24236.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.432, loss_scale=64, train_wall=228, gb_free=8.8, wall=47941
2022-03-07 02:22:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:22:10 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 14.351 | nll_loss 14.15 | ppl 18177.4 | wps 44303.3 | wpb 510.9 | bsz 1 | num_updates 16014 | best_loss 8.318
2022-03-07 02:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16014 updates
2022-03-07 02:22:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:22:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:22:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 329 @ 16014 updates, score 14.351) (writing took 2.4355575311928988 seconds)
2022-03-07 02:22:13 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 02:22:13 | INFO | train | epoch 329 | loss 0.798 | nll_loss 0.235 | ppl 1.18 | wps 24215.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 16014 | lr 0.000249891 | gnorm 0.434 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 47983
2022-03-07 02:22:13 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 02:22:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:24:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:24:21 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 14.379 | nll_loss 14.182 | ppl 18584.9 | wps 45245.1 | wpb 510.9 | bsz 1 | num_updates 16063 | best_loss 8.318
2022-03-07 02:24:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16063 updates
2022-03-07 02:24:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:24:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:24:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 330 @ 16063 updates, score 14.379) (writing took 2.531479300931096 seconds)
2022-03-07 02:24:23 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 02:24:23 | INFO | train | epoch 330 | loss 0.799 | nll_loss 0.236 | ppl 1.18 | wps 24310.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 16063 | lr 0.000249509 | gnorm 0.439 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 48114
2022-03-07 02:24:23 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 02:24:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:24:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:26:00 | INFO | train_inner | epoch 331:     38 / 49 loss=0.798, nll_loss=0.235, ppl=1.18, wps=24090.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.436, loss_scale=32, train_wall=230, gb_free=8.8, wall=48211
2022-03-07 02:26:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:26:32 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 14.399 | nll_loss 14.201 | ppl 18835 | wps 44643.8 | wpb 510.9 | bsz 1 | num_updates 16111 | best_loss 8.318
2022-03-07 02:26:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16111 updates
2022-03-07 02:26:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:26:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:26:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 331 @ 16111 updates, score 14.399) (writing took 2.4893241431564093 seconds)
2022-03-07 02:26:34 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 02:26:34 | INFO | train | epoch 331 | loss 0.796 | nll_loss 0.234 | ppl 1.18 | wps 23796.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16111 | lr 0.000249137 | gnorm 0.435 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 48245
2022-03-07 02:26:34 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 02:26:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:28:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:28:43 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 14.413 | nll_loss 14.213 | ppl 18985 | wps 44325.7 | wpb 510.9 | bsz 1 | num_updates 16160 | best_loss 8.318
2022-03-07 02:28:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16160 updates
2022-03-07 02:28:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:28:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:28:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 332 @ 16160 updates, score 14.413) (writing took 2.433358935639262 seconds)
2022-03-07 02:28:45 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 02:28:45 | INFO | train | epoch 332 | loss 0.796 | nll_loss 0.233 | ppl 1.18 | wps 24287.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 16160 | lr 0.000248759 | gnorm 0.433 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 48375
2022-03-07 02:28:45 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 02:28:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:30:27 | INFO | train_inner | epoch 333:     40 / 49 loss=0.796, nll_loss=0.233, ppl=1.18, wps=24320.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.433, loss_scale=64, train_wall=227, gb_free=8.8, wall=48477
2022-03-07 02:30:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:30:54 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 14.444 | nll_loss 14.244 | ppl 19398.8 | wps 44206.4 | wpb 510.9 | bsz 1 | num_updates 16209 | best_loss 8.318
2022-03-07 02:30:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16209 updates
2022-03-07 02:30:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:30:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:30:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 333 @ 16209 updates, score 14.444) (writing took 2.5543622355908155 seconds)
2022-03-07 02:30:56 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 02:30:56 | INFO | train | epoch 333 | loss 0.795 | nll_loss 0.233 | ppl 1.18 | wps 24262.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 16209 | lr 0.000248383 | gnorm 0.432 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 48506
2022-03-07 02:30:56 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 02:30:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:31:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:32:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:33:04 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 14.323 | nll_loss 14.124 | ppl 17852.5 | wps 45367.9 | wpb 510.9 | bsz 1 | num_updates 16257 | best_loss 8.318
2022-03-07 02:33:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16257 updates
2022-03-07 02:33:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:33:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:33:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 334 @ 16257 updates, score 14.323) (writing took 2.4945089239627123 seconds)
2022-03-07 02:33:07 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 02:33:07 | INFO | train | epoch 334 | loss 0.794 | nll_loss 0.231 | ppl 1.17 | wps 23821.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16257 | lr 0.000248016 | gnorm 0.431 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 48637
2022-03-07 02:33:07 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 02:33:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:34:56 | INFO | train_inner | epoch 335:     43 / 49 loss=0.794, nll_loss=0.232, ppl=1.17, wps=24097.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.429, loss_scale=32, train_wall=230, gb_free=8.8, wall=48746
2022-03-07 02:35:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:35:15 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 14.455 | nll_loss 14.257 | ppl 19577.5 | wps 44955 | wpb 510.9 | bsz 1 | num_updates 16306 | best_loss 8.318
2022-03-07 02:35:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16306 updates
2022-03-07 02:35:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:35:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:35:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 335 @ 16306 updates, score 14.455) (writing took 2.5301621425896883 seconds)
2022-03-07 02:35:18 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 02:35:18 | INFO | train | epoch 335 | loss 0.793 | nll_loss 0.231 | ppl 1.17 | wps 24280.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 16306 | lr 0.000247643 | gnorm 0.425 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 48768
2022-03-07 02:35:18 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 02:35:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:37:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:37:26 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 14.37 | nll_loss 14.171 | ppl 18440.5 | wps 44278.4 | wpb 510.9 | bsz 1 | num_updates 16355 | best_loss 8.318
2022-03-07 02:37:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16355 updates
2022-03-07 02:37:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:37:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:37:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 336 @ 16355 updates, score 14.37) (writing took 2.520446788519621 seconds)
2022-03-07 02:37:28 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 02:37:28 | INFO | train | epoch 336 | loss 0.793 | nll_loss 0.231 | ppl 1.17 | wps 24294.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 16355 | lr 0.000247272 | gnorm 0.431 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 48899
2022-03-07 02:37:28 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 02:37:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:38:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:39:26 | INFO | train_inner | epoch 337:     46 / 49 loss=0.792, nll_loss=0.23, ppl=1.17, wps=24083.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=16400, lr=0.000246932, gnorm=0.429, loss_scale=32, train_wall=230, gb_free=8.8, wall=49016
2022-03-07 02:39:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:39:37 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 14.351 | nll_loss 14.151 | ppl 18192.9 | wps 44550.1 | wpb 510.9 | bsz 1 | num_updates 16403 | best_loss 8.318
2022-03-07 02:39:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16403 updates
2022-03-07 02:39:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:39:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:39:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 337 @ 16403 updates, score 14.351) (writing took 2.459612727165222 seconds)
2022-03-07 02:39:39 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 02:39:39 | INFO | train | epoch 337 | loss 0.792 | nll_loss 0.23 | ppl 1.17 | wps 23789.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16403 | lr 0.00024691 | gnorm 0.426 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 49030
2022-03-07 02:39:39 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 02:39:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:41:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:41:48 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 14.46 | nll_loss 14.265 | ppl 19684 | wps 43342.7 | wpb 510.9 | bsz 1 | num_updates 16452 | best_loss 8.318
2022-03-07 02:41:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16452 updates
2022-03-07 02:41:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:41:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:41:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 338 @ 16452 updates, score 14.46) (writing took 2.557747671380639 seconds)
2022-03-07 02:41:50 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 02:41:50 | INFO | train | epoch 338 | loss 0.791 | nll_loss 0.229 | ppl 1.17 | wps 24263.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 16452 | lr 0.000246542 | gnorm 0.424 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 49161
2022-03-07 02:41:50 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 02:41:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:43:52 | INFO | train_inner | epoch 339:     48 / 49 loss=0.791, nll_loss=0.229, ppl=1.17, wps=24321.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=16500, lr=0.000246183, gnorm=0.425, loss_scale=32, train_wall=227, gb_free=8.8, wall=49283
2022-03-07 02:43:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:43:58 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 14.394 | nll_loss 14.196 | ppl 18774.4 | wps 44732.5 | wpb 510.9 | bsz 1 | num_updates 16501 | best_loss 8.318
2022-03-07 02:43:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16501 updates
2022-03-07 02:43:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:44:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:44:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 339 @ 16501 updates, score 14.394) (writing took 2.454466773197055 seconds)
2022-03-07 02:44:01 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 02:44:01 | INFO | train | epoch 339 | loss 0.791 | nll_loss 0.229 | ppl 1.17 | wps 24325.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16501 | lr 0.000246176 | gnorm 0.427 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 49291
2022-03-07 02:44:01 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 02:44:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:46:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:46:09 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 14.287 | nll_loss 14.088 | ppl 17416.2 | wps 44747.9 | wpb 510.9 | bsz 1 | num_updates 16550 | best_loss 8.318
2022-03-07 02:46:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16550 updates
2022-03-07 02:46:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:46:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:46:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 340 @ 16550 updates, score 14.287) (writing took 2.5117746517062187 seconds)
2022-03-07 02:46:12 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 02:46:12 | INFO | train | epoch 340 | loss 0.79 | nll_loss 0.229 | ppl 1.17 | wps 24325.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16550 | lr 0.000245811 | gnorm 0.423 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 49422
2022-03-07 02:46:12 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 02:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:47:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:48:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:48:20 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 14.336 | nll_loss 14.139 | ppl 18035.9 | wps 44801.7 | wpb 510.9 | bsz 1 | num_updates 16598 | best_loss 8.318
2022-03-07 02:48:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16598 updates
2022-03-07 02:48:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:48:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:48:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 341 @ 16598 updates, score 14.336) (writing took 2.5298788975924253 seconds)
2022-03-07 02:48:22 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 02:48:22 | INFO | train | epoch 341 | loss 0.789 | nll_loss 0.228 | ppl 1.17 | wps 23831.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16598 | lr 0.000245455 | gnorm 0.424 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 49552
2022-03-07 02:48:22 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 02:48:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:48:27 | INFO | train_inner | epoch 342:      2 / 49 loss=0.79, nll_loss=0.228, ppl=1.17, wps=23456.5, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=16600, lr=0.00024544, gnorm=0.424, loss_scale=32, train_wall=228, gb_free=8.8, wall=49558
2022-03-07 02:50:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:50:31 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 14.417 | nll_loss 14.219 | ppl 19065.8 | wps 44459.2 | wpb 510.9 | bsz 1 | num_updates 16647 | best_loss 8.318
2022-03-07 02:50:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16647 updates
2022-03-07 02:50:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:50:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:50:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 342 @ 16647 updates, score 14.417) (writing took 2.540497027337551 seconds)
2022-03-07 02:50:33 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 02:50:33 | INFO | train | epoch 342 | loss 0.789 | nll_loss 0.228 | ppl 1.17 | wps 24254.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 16647 | lr 0.000245094 | gnorm 0.425 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 49684
2022-03-07 02:50:33 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 02:50:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:52:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:52:42 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 14.276 | nll_loss 14.075 | ppl 17254.5 | wps 44420.8 | wpb 510.9 | bsz 1 | num_updates 16696 | best_loss 8.318
2022-03-07 02:52:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16696 updates
2022-03-07 02:52:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:52:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:52:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 343 @ 16696 updates, score 14.276) (writing took 2.4257140699774027 seconds)
2022-03-07 02:52:44 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 02:52:44 | INFO | train | epoch 343 | loss 0.787 | nll_loss 0.226 | ppl 1.17 | wps 24296.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 16696 | lr 0.000244734 | gnorm 0.421 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 49814
2022-03-07 02:52:44 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 02:52:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:52:54 | INFO | train_inner | epoch 344:      4 / 49 loss=0.788, nll_loss=0.227, ppl=1.17, wps=24304.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.423, loss_scale=32, train_wall=228, gb_free=8.8, wall=49825
2022-03-07 02:54:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:54:52 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 14.438 | nll_loss 14.238 | ppl 19329.2 | wps 44480.8 | wpb 510.9 | bsz 1 | num_updates 16745 | best_loss 8.318
2022-03-07 02:54:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16745 updates
2022-03-07 02:54:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:54:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:54:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 344 @ 16745 updates, score 14.438) (writing took 2.4564354438334703 seconds)
2022-03-07 02:54:55 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 02:54:55 | INFO | train | epoch 344 | loss 0.787 | nll_loss 0.227 | ppl 1.17 | wps 24290.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 16745 | lr 0.000244375 | gnorm 0.423 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 49945
2022-03-07 02:54:55 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 02:54:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:56:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:56:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:57:03 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 14.404 | nll_loss 14.205 | ppl 18888.6 | wps 44729.3 | wpb 510.9 | bsz 1 | num_updates 16793 | best_loss 8.318
2022-03-07 02:57:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16793 updates
2022-03-07 02:57:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:57:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:57:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 345 @ 16793 updates, score 14.404) (writing took 2.4885104466229677 seconds)
2022-03-07 02:57:06 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 02:57:06 | INFO | train | epoch 345 | loss 0.786 | nll_loss 0.225 | ppl 1.17 | wps 23779.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16793 | lr 0.000244026 | gnorm 0.427 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 50076
2022-03-07 02:57:06 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 02:57:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:57:24 | INFO | train_inner | epoch 346:      7 / 49 loss=0.786, nll_loss=0.226, ppl=1.17, wps=24096, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.426, loss_scale=32, train_wall=230, gb_free=8.8, wall=50094
2022-03-07 02:59:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:59:15 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 14.524 | nll_loss 14.327 | ppl 20559.1 | wps 42578.7 | wpb 510.9 | bsz 1 | num_updates 16842 | best_loss 8.318
2022-03-07 02:59:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16842 updates
2022-03-07 02:59:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:59:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:59:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 346 @ 16842 updates, score 14.524) (writing took 2.465894455090165 seconds)
2022-03-07 02:59:18 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 02:59:18 | INFO | train | epoch 346 | loss 0.786 | nll_loss 0.225 | ppl 1.17 | wps 24035 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 16842 | lr 0.000243671 | gnorm 0.423 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 50208
2022-03-07 02:59:18 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 02:59:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:01:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:01:30 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 14.367 | nll_loss 14.171 | ppl 18448 | wps 41588.9 | wpb 510.9 | bsz 1 | num_updates 16891 | best_loss 8.318
2022-03-07 03:01:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16891 updates
2022-03-07 03:01:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:01:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:01:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 347 @ 16891 updates, score 14.367) (writing took 2.330946695059538 seconds)
2022-03-07 03:01:33 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 03:01:33 | INFO | train | epoch 347 | loss 0.784 | nll_loss 0.224 | ppl 1.17 | wps 23595.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16891 | lr 0.000243317 | gnorm 0.418 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 50343
2022-03-07 03:01:33 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 03:01:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:01:56 | INFO | train_inner | epoch 348:      9 / 49 loss=0.785, nll_loss=0.224, ppl=1.17, wps=23789.8, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.419, loss_scale=32, train_wall=233, gb_free=8.8, wall=50367
2022-03-07 03:03:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:03:45 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 14.393 | nll_loss 14.196 | ppl 18773.5 | wps 42298.5 | wpb 510.9 | bsz 1 | num_updates 16940 | best_loss 8.318
2022-03-07 03:03:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16940 updates
2022-03-07 03:03:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:03:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:03:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 348 @ 16940 updates, score 14.393) (writing took 2.3423558119684458 seconds)
2022-03-07 03:03:47 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 03:03:47 | INFO | train | epoch 348 | loss 0.783 | nll_loss 0.223 | ppl 1.17 | wps 23654.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16940 | lr 0.000242965 | gnorm 0.416 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 50477
2022-03-07 03:03:47 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 03:03:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:05:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:05:59 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 14.307 | nll_loss 14.108 | ppl 17659.5 | wps 42085.1 | wpb 510.9 | bsz 1 | num_updates 16989 | best_loss 8.318
2022-03-07 03:05:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16989 updates
2022-03-07 03:05:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:06:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:06:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 349 @ 16989 updates, score 14.307) (writing took 2.326395872980356 seconds)
2022-03-07 03:06:01 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 03:06:01 | INFO | train | epoch 349 | loss 0.783 | nll_loss 0.223 | ppl 1.17 | wps 23671 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16989 | lr 0.000242614 | gnorm 0.42 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 50612
2022-03-07 03:06:01 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 03:06:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:06:30 | INFO | train_inner | epoch 350:     11 / 49 loss=0.783, nll_loss=0.223, ppl=1.17, wps=23684.5, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.417, loss_scale=64, train_wall=234, gb_free=8.8, wall=50640
2022-03-07 03:08:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:08:13 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 14.37 | nll_loss 14.172 | ppl 18458.3 | wps 44004.4 | wpb 510.9 | bsz 1 | num_updates 17038 | best_loss 8.318
2022-03-07 03:08:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17038 updates
2022-03-07 03:08:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:08:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:08:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 350 @ 17038 updates, score 14.37) (writing took 2.555521335452795 seconds)
2022-03-07 03:08:15 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 03:08:15 | INFO | train | epoch 350 | loss 0.782 | nll_loss 0.223 | ppl 1.17 | wps 23729.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 17038 | lr 0.000242265 | gnorm 0.415 | loss_scale 128 | train_wall 114 | gb_free 8.8 | wall 50745
2022-03-07 03:08:15 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 03:08:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:08:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 03:10:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:10:23 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 14.31 | nll_loss 14.113 | ppl 17716.6 | wps 44904.2 | wpb 510.9 | bsz 1 | num_updates 17086 | best_loss 8.318
2022-03-07 03:10:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17086 updates
2022-03-07 03:10:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:10:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:10:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 351 @ 17086 updates, score 14.31) (writing took 2.4490053337067366 seconds)
2022-03-07 03:10:26 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 03:10:26 | INFO | train | epoch 351 | loss 0.781 | nll_loss 0.221 | ppl 1.17 | wps 23815.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 17086 | lr 0.000241924 | gnorm 0.418 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 50876
2022-03-07 03:10:26 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 03:10:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:11:02 | INFO | train_inner | epoch 352:     14 / 49 loss=0.782, nll_loss=0.222, ppl=1.17, wps=23864.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.418, loss_scale=64, train_wall=232, gb_free=8.8, wall=50912
2022-03-07 03:12:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:12:38 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 14.341 | nll_loss 14.141 | ppl 18070.2 | wps 42678.7 | wpb 510.9 | bsz 1 | num_updates 17135 | best_loss 8.318
2022-03-07 03:12:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17135 updates
2022-03-07 03:12:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:12:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:12:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 352 @ 17135 updates, score 14.341) (writing took 2.599432220682502 seconds)
2022-03-07 03:12:40 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 03:12:40 | INFO | train | epoch 352 | loss 0.781 | nll_loss 0.222 | ppl 1.17 | wps 23663.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17135 | lr 0.000241578 | gnorm 0.417 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 51010
2022-03-07 03:12:40 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 03:12:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:14:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 03:14:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:14:52 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 14.414 | nll_loss 14.217 | ppl 19049.4 | wps 42017.1 | wpb 510.9 | bsz 1 | num_updates 17183 | best_loss 8.318
2022-03-07 03:14:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17183 updates
2022-03-07 03:14:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:14:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:14:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 353 @ 17183 updates, score 14.414) (writing took 2.507987257093191 seconds)
2022-03-07 03:14:55 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 03:14:55 | INFO | train | epoch 353 | loss 0.78 | nll_loss 0.221 | ppl 1.17 | wps 23110.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 17183 | lr 0.000241241 | gnorm 0.417 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 51145
2022-03-07 03:14:55 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 03:14:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:15:40 | INFO | train_inner | epoch 354:     17 / 49 loss=0.781, nll_loss=0.221, ppl=1.17, wps=23363, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.415, loss_scale=64, train_wall=237, gb_free=8.8, wall=51190
2022-03-07 03:17:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:17:06 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 14.294 | nll_loss 14.096 | ppl 17513.3 | wps 42011 | wpb 510.9 | bsz 1 | num_updates 17232 | best_loss 8.318
2022-03-07 03:17:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17232 updates
2022-03-07 03:17:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:17:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:17:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 354 @ 17232 updates, score 14.294) (writing took 2.409225534647703 seconds)
2022-03-07 03:17:08 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 03:17:08 | INFO | train | epoch 354 | loss 0.78 | nll_loss 0.221 | ppl 1.17 | wps 23801.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 17232 | lr 0.000240897 | gnorm 0.415 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 51279
2022-03-07 03:17:08 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 03:17:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:19:20 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 14.328 | nll_loss 14.131 | ppl 17936.3 | wps 42959.4 | wpb 510.9 | bsz 1 | num_updates 17281 | best_loss 8.318
2022-03-07 03:19:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17281 updates
2022-03-07 03:19:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:19:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:19:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 355 @ 17281 updates, score 14.328) (writing took 2.5320408642292023 seconds)
2022-03-07 03:19:22 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 03:19:22 | INFO | train | epoch 355 | loss 0.779 | nll_loss 0.22 | ppl 1.16 | wps 23766.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 17281 | lr 0.000240556 | gnorm 0.411 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 51412
2022-03-07 03:19:22 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 03:19:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:19:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 03:20:14 | INFO | train_inner | epoch 356:     20 / 49 loss=0.779, nll_loss=0.22, ppl=1.16, wps=23633.4, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.413, loss_scale=64, train_wall=234, gb_free=8.8, wall=51464
2022-03-07 03:21:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:21:33 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 14.329 | nll_loss 14.13 | ppl 17933.9 | wps 43379.8 | wpb 510.9 | bsz 1 | num_updates 17329 | best_loss 8.318
2022-03-07 03:21:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17329 updates
2022-03-07 03:21:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:21:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:21:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 356 @ 17329 updates, score 14.329) (writing took 2.40857008472085 seconds)
2022-03-07 03:21:36 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 03:21:36 | INFO | train | epoch 356 | loss 0.778 | nll_loss 0.219 | ppl 1.16 | wps 23288.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 17329 | lr 0.000240222 | gnorm 0.413 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 51546
2022-03-07 03:21:36 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 03:21:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:22:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:23:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:23:47 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 14.385 | nll_loss 14.188 | ppl 18664.5 | wps 41240.6 | wpb 510.9 | bsz 1 | num_updates 17377 | best_loss 8.318
2022-03-07 03:23:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17377 updates
2022-03-07 03:23:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:23:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:23:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 357 @ 17377 updates, score 14.385) (writing took 2.4321146067231894 seconds)
2022-03-07 03:23:50 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 03:23:50 | INFO | train | epoch 357 | loss 0.778 | nll_loss 0.219 | ppl 1.16 | wps 23225.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 17377 | lr 0.00023989 | gnorm 0.416 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 51680
2022-03-07 03:23:50 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 03:23:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:24:50 | INFO | train_inner | epoch 358:     23 / 49 loss=0.778, nll_loss=0.219, ppl=1.16, wps=23482.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.414, loss_scale=32, train_wall=236, gb_free=8.8, wall=51741
2022-03-07 03:25:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:26:02 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 14.373 | nll_loss 14.177 | ppl 18527 | wps 41851.9 | wpb 510.9 | bsz 1 | num_updates 17426 | best_loss 8.318
2022-03-07 03:26:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17426 updates
2022-03-07 03:26:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:26:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:26:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 358 @ 17426 updates, score 14.373) (writing took 2.504081616178155 seconds)
2022-03-07 03:26:05 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 03:26:05 | INFO | train | epoch 358 | loss 0.777 | nll_loss 0.219 | ppl 1.16 | wps 23571.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17426 | lr 0.000239553 | gnorm 0.417 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 51815
2022-03-07 03:26:05 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 03:26:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:28:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:28:16 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 14.321 | nll_loss 14.125 | ppl 17865.7 | wps 42045.7 | wpb 510.9 | bsz 1 | num_updates 17475 | best_loss 8.318
2022-03-07 03:28:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17475 updates
2022-03-07 03:28:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:28:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:28:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 359 @ 17475 updates, score 14.321) (writing took 2.3961735907942057 seconds)
2022-03-07 03:28:19 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 03:28:19 | INFO | train | epoch 359 | loss 0.776 | nll_loss 0.218 | ppl 1.16 | wps 23727.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 17475 | lr 0.000239217 | gnorm 0.411 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 51949
2022-03-07 03:28:19 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 03:28:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:29:24 | INFO | train_inner | epoch 360:     25 / 49 loss=0.777, nll_loss=0.218, ppl=1.16, wps=23723.1, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.413, loss_scale=64, train_wall=233, gb_free=8.8, wall=52014
2022-03-07 03:30:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:30:30 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 14.347 | nll_loss 14.152 | ppl 18198.6 | wps 41538.7 | wpb 510.9 | bsz 1 | num_updates 17524 | best_loss 8.318
2022-03-07 03:30:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17524 updates
2022-03-07 03:30:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:30:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:30:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 360 @ 17524 updates, score 14.347) (writing took 2.456012209877372 seconds)
2022-03-07 03:30:33 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 03:30:33 | INFO | train | epoch 360 | loss 0.777 | nll_loss 0.218 | ppl 1.16 | wps 23647.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17524 | lr 0.000238882 | gnorm 0.412 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 52083
2022-03-07 03:30:33 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 03:30:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:32:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:32:44 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 14.385 | nll_loss 14.191 | ppl 18702.8 | wps 42154.1 | wpb 510.9 | bsz 1 | num_updates 17573 | best_loss 8.318
2022-03-07 03:32:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17573 updates
2022-03-07 03:32:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:32:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:32:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 361 @ 17573 updates, score 14.385) (writing took 2.4042706452310085 seconds)
2022-03-07 03:32:46 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 03:32:46 | INFO | train | epoch 361 | loss 0.775 | nll_loss 0.217 | ppl 1.16 | wps 23819 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 17573 | lr 0.000238549 | gnorm 0.409 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 52217
2022-03-07 03:32:46 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 03:32:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:32:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:33:59 | INFO | train_inner | epoch 362:     28 / 49 loss=0.776, nll_loss=0.217, ppl=1.16, wps=23556.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.411, loss_scale=32, train_wall=235, gb_free=8.8, wall=52290
2022-03-07 03:34:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:34:58 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 14.364 | nll_loss 14.167 | ppl 18395.8 | wps 42335 | wpb 510.9 | bsz 1 | num_updates 17621 | best_loss 8.318
2022-03-07 03:34:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17621 updates
2022-03-07 03:34:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:35:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:35:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 362 @ 17621 updates, score 14.364) (writing took 2.423404533416033 seconds)
2022-03-07 03:35:00 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 03:35:00 | INFO | train | epoch 362 | loss 0.775 | nll_loss 0.217 | ppl 1.16 | wps 23239.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 17621 | lr 0.000238224 | gnorm 0.415 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 52351
2022-03-07 03:35:00 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 03:35:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:37:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:37:12 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 14.317 | nll_loss 14.12 | ppl 17810.3 | wps 42138.8 | wpb 510.9 | bsz 1 | num_updates 17670 | best_loss 8.318
2022-03-07 03:37:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17670 updates
2022-03-07 03:37:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:37:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:37:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 363 @ 17670 updates, score 14.317) (writing took 2.5204976741224527 seconds)
2022-03-07 03:37:14 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 03:37:14 | INFO | train | epoch 363 | loss 0.773 | nll_loss 0.215 | ppl 1.16 | wps 23712.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 17670 | lr 0.000237893 | gnorm 0.407 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 52485
2022-03-07 03:37:14 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 03:37:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:38:32 | INFO | train_inner | epoch 364:     30 / 49 loss=0.774, nll_loss=0.215, ppl=1.16, wps=23750.4, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.409, loss_scale=32, train_wall=233, gb_free=8.8, wall=52563
2022-03-07 03:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:39:26 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 14.404 | nll_loss 14.207 | ppl 18915.6 | wps 41457 | wpb 510.9 | bsz 1 | num_updates 17719 | best_loss 8.318
2022-03-07 03:39:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17719 updates
2022-03-07 03:39:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:39:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:39:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 364 @ 17719 updates, score 14.404) (writing took 2.4319891165941954 seconds)
2022-03-07 03:39:29 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 03:39:29 | INFO | train | epoch 364 | loss 0.773 | nll_loss 0.215 | ppl 1.16 | wps 23678.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 17719 | lr 0.000237564 | gnorm 0.407 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 52619
2022-03-07 03:39:29 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 03:39:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:41:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:41:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:41:40 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 14.345 | nll_loss 14.149 | ppl 18167.1 | wps 41650.9 | wpb 510.9 | bsz 1 | num_updates 17767 | best_loss 8.318
2022-03-07 03:41:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17767 updates
2022-03-07 03:41:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:41:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:41:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 365 @ 17767 updates, score 14.345) (writing took 2.418460391461849 seconds)
2022-03-07 03:41:42 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 03:41:42 | INFO | train | epoch 365 | loss 0.772 | nll_loss 0.214 | ppl 1.16 | wps 23244.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 17767 | lr 0.000237243 | gnorm 0.406 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 52753
2022-03-07 03:41:42 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 03:41:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:43:09 | INFO | train_inner | epoch 366:     33 / 49 loss=0.772, nll_loss=0.214, ppl=1.16, wps=23494.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.407, loss_scale=32, train_wall=236, gb_free=8.8, wall=52839
2022-03-07 03:43:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:43:54 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 14.327 | nll_loss 14.13 | ppl 17931.1 | wps 42694.8 | wpb 510.9 | bsz 1 | num_updates 17816 | best_loss 8.318
2022-03-07 03:43:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17816 updates
2022-03-07 03:43:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:43:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:43:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 366 @ 17816 updates, score 14.327) (writing took 2.474474608898163 seconds)
2022-03-07 03:43:57 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 03:43:57 | INFO | train | epoch 366 | loss 0.771 | nll_loss 0.214 | ppl 1.16 | wps 23672.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17816 | lr 0.000236916 | gnorm 0.408 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 52887
2022-03-07 03:43:57 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 03:43:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:46:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:46:08 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 14.286 | nll_loss 14.09 | ppl 17433 | wps 42810 | wpb 510.9 | bsz 1 | num_updates 17865 | best_loss 8.318
2022-03-07 03:46:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17865 updates
2022-03-07 03:46:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:46:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:46:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 367 @ 17865 updates, score 14.286) (writing took 2.4319101460278034 seconds)
2022-03-07 03:46:11 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 03:46:11 | INFO | train | epoch 367 | loss 0.771 | nll_loss 0.213 | ppl 1.16 | wps 23748.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 17865 | lr 0.000236591 | gnorm 0.409 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 53021
2022-03-07 03:46:11 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 03:46:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:47:42 | INFO | train_inner | epoch 368:     35 / 49 loss=0.771, nll_loss=0.213, ppl=1.16, wps=23724.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.408, loss_scale=64, train_wall=233, gb_free=8.8, wall=53112
2022-03-07 03:48:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:48:22 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 14.345 | nll_loss 14.148 | ppl 18153.1 | wps 42219.3 | wpb 510.9 | bsz 1 | num_updates 17914 | best_loss 8.318
2022-03-07 03:48:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17914 updates
2022-03-07 03:48:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:48:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:48:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 368 @ 17914 updates, score 14.345) (writing took 2.403743287548423 seconds)
2022-03-07 03:48:25 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 03:48:25 | INFO | train | epoch 368 | loss 0.771 | nll_loss 0.213 | ppl 1.16 | wps 23681.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 17914 | lr 0.000236267 | gnorm 0.408 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 53155
2022-03-07 03:48:25 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 03:48:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:48:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:50:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:50:36 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 14.346 | nll_loss 14.15 | ppl 18181.5 | wps 41818.2 | wpb 510.9 | bsz 1 | num_updates 17962 | best_loss 8.318
2022-03-07 03:50:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17962 updates
2022-03-07 03:50:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:50:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:50:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 369 @ 17962 updates, score 14.346) (writing took 2.408109361305833 seconds)
2022-03-07 03:50:39 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 03:50:39 | INFO | train | epoch 369 | loss 0.77 | nll_loss 0.213 | ppl 1.16 | wps 23227 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 17962 | lr 0.000235951 | gnorm 0.401 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 53289
2022-03-07 03:50:39 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 03:50:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:52:17 | INFO | train_inner | epoch 370:     38 / 49 loss=0.77, nll_loss=0.213, ppl=1.16, wps=23561.1, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.404, loss_scale=32, train_wall=235, gb_free=8.8, wall=53388
2022-03-07 03:52:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:52:49 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 14.229 | nll_loss 14.031 | ppl 16737 | wps 43795.9 | wpb 510.9 | bsz 1 | num_updates 18011 | best_loss 8.318
2022-03-07 03:52:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18011 updates
2022-03-07 03:52:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:52:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:52:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 370 @ 18011 updates, score 14.229) (writing took 2.428252523764968 seconds)
2022-03-07 03:52:52 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 03:52:52 | INFO | train | epoch 370 | loss 0.77 | nll_loss 0.213 | ppl 1.16 | wps 23860.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18011 | lr 0.00023563 | gnorm 0.405 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 53422
2022-03-07 03:52:52 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 03:52:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:54:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:55:01 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 14.265 | nll_loss 14.068 | ppl 17178.2 | wps 43119.9 | wpb 510.9 | bsz 1 | num_updates 18060 | best_loss 8.318
2022-03-07 03:55:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18060 updates
2022-03-07 03:55:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:55:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:55:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 371 @ 18060 updates, score 14.265) (writing took 2.4450073949992657 seconds)
2022-03-07 03:55:04 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 03:55:04 | INFO | train | epoch 371 | loss 0.769 | nll_loss 0.211 | ppl 1.16 | wps 24110.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18060 | lr 0.00023531 | gnorm 0.398 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 53554
2022-03-07 03:55:04 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 03:55:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:56:46 | INFO | train_inner | epoch 372:     40 / 49 loss=0.769, nll_loss=0.212, ppl=1.16, wps=24165.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.404, loss_scale=64, train_wall=229, gb_free=8.8, wall=53656
2022-03-07 03:57:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:57:12 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 14.371 | nll_loss 14.176 | ppl 18507.6 | wps 43733.2 | wpb 510.9 | bsz 1 | num_updates 18109 | best_loss 8.318
2022-03-07 03:57:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18109 updates
2022-03-07 03:57:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:57:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:57:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 372 @ 18109 updates, score 14.371) (writing took 2.4004720002412796 seconds)
2022-03-07 03:57:15 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 03:57:15 | INFO | train | epoch 372 | loss 0.769 | nll_loss 0.212 | ppl 1.16 | wps 24235.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18109 | lr 0.000234992 | gnorm 0.409 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 53685
2022-03-07 03:57:15 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 03:57:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:59:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:59:24 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 14.291 | nll_loss 14.094 | ppl 17482.3 | wps 44531.3 | wpb 510.9 | bsz 1 | num_updates 18158 | best_loss 8.318
2022-03-07 03:59:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18158 updates
2022-03-07 03:59:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:59:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:59:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 373 @ 18158 updates, score 14.291) (writing took 2.388285044580698 seconds)
2022-03-07 03:59:26 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 03:59:26 | INFO | train | epoch 373 | loss 0.767 | nll_loss 0.21 | ppl 1.16 | wps 24225.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18158 | lr 0.000234675 | gnorm 0.399 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 53816
2022-03-07 03:59:26 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 03:59:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:00:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 04:01:16 | INFO | train_inner | epoch 374:     43 / 49 loss=0.768, nll_loss=0.211, ppl=1.16, wps=24029.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=18200, lr=0.000234404, gnorm=0.401, loss_scale=64, train_wall=230, gb_free=8.8, wall=53926
2022-03-07 04:01:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:01:35 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 14.286 | nll_loss 14.09 | ppl 17440.2 | wps 44630.6 | wpb 510.9 | bsz 1 | num_updates 18206 | best_loss 8.318
2022-03-07 04:01:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18206 updates
2022-03-07 04:01:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:01:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:01:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 374 @ 18206 updates, score 14.286) (writing took 2.406834552064538 seconds)
2022-03-07 04:01:37 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 04:01:37 | INFO | train | epoch 374 | loss 0.767 | nll_loss 0.21 | ppl 1.16 | wps 23772.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18206 | lr 0.000234365 | gnorm 0.4 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 53947
2022-03-07 04:01:37 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 04:01:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:01:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:03:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:03:45 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 14.359 | nll_loss 14.166 | ppl 18378.2 | wps 44350.6 | wpb 510.9 | bsz 1 | num_updates 18254 | best_loss 8.318
2022-03-07 04:03:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18254 updates
2022-03-07 04:03:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:03:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 375 @ 18254 updates, score 14.359) (writing took 2.443371092900634 seconds)
2022-03-07 04:03:48 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 04:03:48 | INFO | train | epoch 375 | loss 0.767 | nll_loss 0.21 | ppl 1.16 | wps 23785.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18254 | lr 0.000234057 | gnorm 0.406 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 54078
2022-03-07 04:03:48 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 04:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:05:45 | INFO | train_inner | epoch 376:     46 / 49 loss=0.767, nll_loss=0.21, ppl=1.16, wps=24090.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=18300, lr=0.000233762, gnorm=0.406, loss_scale=32, train_wall=230, gb_free=8.8, wall=54195
2022-03-07 04:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:05:56 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 14.313 | nll_loss 14.117 | ppl 17772.8 | wps 44526.8 | wpb 510.9 | bsz 1 | num_updates 18303 | best_loss 8.318
2022-03-07 04:05:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18303 updates
2022-03-07 04:05:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 376 @ 18303 updates, score 14.313) (writing took 2.41642701998353 seconds)
2022-03-07 04:05:59 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 04:05:59 | INFO | train | epoch 376 | loss 0.766 | nll_loss 0.209 | ppl 1.16 | wps 24285.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18303 | lr 0.000233743 | gnorm 0.406 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 54209
2022-03-07 04:05:59 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 04:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:07:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:08:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:08:07 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 14.28 | nll_loss 14.084 | ppl 17365.7 | wps 44128.6 | wpb 510.9 | bsz 1 | num_updates 18351 | best_loss 8.318
2022-03-07 04:08:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18351 updates
2022-03-07 04:08:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:08:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:08:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 377 @ 18351 updates, score 14.28) (writing took 2.4338398315012455 seconds)
2022-03-07 04:08:10 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 04:08:10 | INFO | train | epoch 377 | loss 0.765 | nll_loss 0.209 | ppl 1.16 | wps 23762.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18351 | lr 0.000233437 | gnorm 0.403 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 54340
2022-03-07 04:08:10 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 04:08:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:10:13 | INFO | train_inner | epoch 378:     49 / 49 loss=0.765, nll_loss=0.208, ppl=1.16, wps=24065.8, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=18400, lr=0.000233126, gnorm=0.4, loss_scale=32, train_wall=229, gb_free=8.8, wall=54463
2022-03-07 04:10:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:10:18 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 14.271 | nll_loss 14.076 | ppl 17268.5 | wps 44460.6 | wpb 510.9 | bsz 1 | num_updates 18400 | best_loss 8.318
2022-03-07 04:10:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18400 updates
2022-03-07 04:10:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:10:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:10:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 378 @ 18400 updates, score 14.271) (writing took 2.3864309433847666 seconds)
2022-03-07 04:10:21 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 04:10:21 | INFO | train | epoch 378 | loss 0.764 | nll_loss 0.208 | ppl 1.15 | wps 24292.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18400 | lr 0.000233126 | gnorm 0.395 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 54471
2022-03-07 04:10:21 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 04:10:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:12:29 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 14.321 | nll_loss 14.125 | ppl 17866.2 | wps 43829.2 | wpb 510.9 | bsz 1 | num_updates 18449 | best_loss 8.318
2022-03-07 04:12:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18449 updates
2022-03-07 04:12:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:12:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:12:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 379 @ 18449 updates, score 14.321) (writing took 2.551046187058091 seconds)
2022-03-07 04:12:32 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 04:12:32 | INFO | train | epoch 379 | loss 0.765 | nll_loss 0.208 | ppl 1.16 | wps 24229.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18449 | lr 0.000232816 | gnorm 0.407 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 54602
2022-03-07 04:12:32 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 04:12:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:14:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:14:40 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 14.254 | nll_loss 14.059 | ppl 17071.7 | wps 44428.3 | wpb 510.9 | bsz 1 | num_updates 18498 | best_loss 8.318
2022-03-07 04:14:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18498 updates
2022-03-07 04:14:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:14:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:14:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 380 @ 18498 updates, score 14.254) (writing took 2.4357295874506235 seconds)
2022-03-07 04:14:42 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 04:14:42 | INFO | train | epoch 380 | loss 0.764 | nll_loss 0.208 | ppl 1.16 | wps 24310.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18498 | lr 0.000232508 | gnorm 0.399 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 54733
2022-03-07 04:14:42 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 04:14:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:14:48 | INFO | train_inner | epoch 381:      2 / 49 loss=0.764, nll_loss=0.208, ppl=1.16, wps=23638.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.402, loss_scale=64, train_wall=228, gb_free=8.8, wall=54738
2022-03-07 04:16:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:16:51 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 14.284 | nll_loss 14.087 | ppl 17403.5 | wps 44836.4 | wpb 510.9 | bsz 1 | num_updates 18547 | best_loss 8.318
2022-03-07 04:16:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18547 updates
2022-03-07 04:16:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:16:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:16:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 381 @ 18547 updates, score 14.284) (writing took 2.4781407825648785 seconds)
2022-03-07 04:16:53 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 04:16:53 | INFO | train | epoch 381 | loss 0.763 | nll_loss 0.207 | ppl 1.15 | wps 24337.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18547 | lr 0.000232201 | gnorm 0.395 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 54863
2022-03-07 04:16:53 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 04:16:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:18:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:18:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:19:01 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 14.294 | nll_loss 14.099 | ppl 17543.5 | wps 44618.5 | wpb 510.9 | bsz 1 | num_updates 18595 | best_loss 8.318
2022-03-07 04:19:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18595 updates
2022-03-07 04:19:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:19:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:19:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 382 @ 18595 updates, score 14.294) (writing took 2.5356940999627113 seconds)
2022-03-07 04:19:04 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 04:19:04 | INFO | train | epoch 382 | loss 0.763 | nll_loss 0.207 | ppl 1.15 | wps 23786.5 | ups 0.37 | wpb 64853.3 | bsz 126.7 | num_updates 18595 | lr 0.000231901 | gnorm 0.401 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 54994
2022-03-07 04:19:04 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 04:19:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:19:17 | INFO | train_inner | epoch 383:      5 / 49 loss=0.763, nll_loss=0.207, ppl=1.15, wps=24109.2, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.398, loss_scale=32, train_wall=229, gb_free=8.8, wall=55007
2022-03-07 04:21:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:21:12 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 14.257 | nll_loss 14.062 | ppl 17103 | wps 44275.2 | wpb 510.9 | bsz 1 | num_updates 18644 | best_loss 8.318
2022-03-07 04:21:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18644 updates
2022-03-07 04:21:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:21:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:21:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 383 @ 18644 updates, score 14.257) (writing took 2.496945559978485 seconds)
2022-03-07 04:21:15 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 04:21:15 | INFO | train | epoch 383 | loss 0.762 | nll_loss 0.206 | ppl 1.15 | wps 24313.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18644 | lr 0.000231596 | gnorm 0.397 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 55125
2022-03-07 04:21:15 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 04:21:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:23:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:23:23 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 14.283 | nll_loss 14.09 | ppl 17439.1 | wps 44619.6 | wpb 510.9 | bsz 1 | num_updates 18693 | best_loss 8.318
2022-03-07 04:23:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18693 updates
2022-03-07 04:23:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:23:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:23:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 384 @ 18693 updates, score 14.283) (writing took 2.4469675421714783 seconds)
2022-03-07 04:23:25 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 04:23:25 | INFO | train | epoch 384 | loss 0.762 | nll_loss 0.206 | ppl 1.15 | wps 24281.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18693 | lr 0.000231292 | gnorm 0.394 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 55256
2022-03-07 04:23:25 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 04:23:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:23:43 | INFO | train_inner | epoch 385:      7 / 49 loss=0.761, nll_loss=0.206, ppl=1.15, wps=24330, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.395, loss_scale=32, train_wall=227, gb_free=8.8, wall=55274
2022-03-07 04:25:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:25:34 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 14.312 | nll_loss 14.116 | ppl 17757.7 | wps 44503.2 | wpb 510.9 | bsz 1 | num_updates 18742 | best_loss 8.318
2022-03-07 04:25:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18742 updates
2022-03-07 04:25:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:25:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:25:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 385 @ 18742 updates, score 14.312) (writing took 2.4589417297393084 seconds)
2022-03-07 04:25:36 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 04:25:36 | INFO | train | epoch 385 | loss 0.761 | nll_loss 0.206 | ppl 1.15 | wps 24316.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18742 | lr 0.000230989 | gnorm 0.396 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 55386
2022-03-07 04:25:36 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 04:25:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:27:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:27:45 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 14.332 | nll_loss 14.139 | ppl 18039.6 | wps 44733.1 | wpb 510.9 | bsz 1 | num_updates 18791 | best_loss 8.318
2022-03-07 04:27:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18791 updates
2022-03-07 04:27:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:27:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:27:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 386 @ 18791 updates, score 14.332) (writing took 2.45484970882535 seconds)
2022-03-07 04:27:47 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 04:27:47 | INFO | train | epoch 386 | loss 0.759 | nll_loss 0.204 | ppl 1.15 | wps 24293.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18791 | lr 0.000230688 | gnorm 0.39 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 55517
2022-03-07 04:27:47 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 04:27:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:28:10 | INFO | train_inner | epoch 387:      9 / 49 loss=0.76, nll_loss=0.205, ppl=1.15, wps=24328.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.393, loss_scale=64, train_wall=227, gb_free=8.8, wall=55540
2022-03-07 04:28:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:29:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:29:55 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 14.3 | nll_loss 14.106 | ppl 17636.1 | wps 44492.6 | wpb 510.9 | bsz 1 | num_updates 18839 | best_loss 8.318
2022-03-07 04:29:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18839 updates
2022-03-07 04:29:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:29:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:29:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 387 @ 18839 updates, score 14.3) (writing took 2.451471393927932 seconds)
2022-03-07 04:29:58 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 04:29:58 | INFO | train | epoch 387 | loss 0.759 | nll_loss 0.204 | ppl 1.15 | wps 23806.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18839 | lr 0.000230394 | gnorm 0.399 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 55648
2022-03-07 04:29:58 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 04:29:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:32:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:32:06 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 14.368 | nll_loss 14.174 | ppl 18486.9 | wps 44256.2 | wpb 510.9 | bsz 1 | num_updates 18888 | best_loss 8.318
2022-03-07 04:32:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18888 updates
2022-03-07 04:32:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:32:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:32:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 388 @ 18888 updates, score 14.368) (writing took 2.5397774651646614 seconds)
2022-03-07 04:32:09 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 04:32:09 | INFO | train | epoch 388 | loss 0.759 | nll_loss 0.204 | ppl 1.15 | wps 24244.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18888 | lr 0.000230095 | gnorm 0.39 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 55779
2022-03-07 04:32:09 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 04:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:32:39 | INFO | train_inner | epoch 389:     12 / 49 loss=0.759, nll_loss=0.204, ppl=1.15, wps=24069.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.394, loss_scale=32, train_wall=230, gb_free=8.8, wall=55810
2022-03-07 04:34:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:34:17 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 14.273 | nll_loss 14.079 | ppl 17303.9 | wps 44823.2 | wpb 510.9 | bsz 1 | num_updates 18937 | best_loss 8.318
2022-03-07 04:34:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18937 updates
2022-03-07 04:34:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:34:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:34:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 389 @ 18937 updates, score 14.273) (writing took 2.4426337387412786 seconds)
2022-03-07 04:34:19 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 04:34:19 | INFO | train | epoch 389 | loss 0.759 | nll_loss 0.204 | ppl 1.15 | wps 24315 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18937 | lr 0.000229797 | gnorm 0.394 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 55910
2022-03-07 04:34:20 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 04:34:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:36:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:36:28 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 14.326 | nll_loss 14.132 | ppl 17955.2 | wps 43997.6 | wpb 510.9 | bsz 1 | num_updates 18985 | best_loss 8.318
2022-03-07 04:36:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18985 updates
2022-03-07 04:36:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:36:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:36:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 390 @ 18985 updates, score 14.326) (writing took 2.5343621596693993 seconds)
2022-03-07 04:36:30 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 04:36:30 | INFO | train | epoch 390 | loss 0.758 | nll_loss 0.203 | ppl 1.15 | wps 23790.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18985 | lr 0.000229506 | gnorm 0.393 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 56041
2022-03-07 04:36:30 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 04:36:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:37:09 | INFO | train_inner | epoch 391:     15 / 49 loss=0.758, nll_loss=0.203, ppl=1.15, wps=24113.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.394, loss_scale=32, train_wall=229, gb_free=8.8, wall=56079
2022-03-07 04:38:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:38:39 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 14.305 | nll_loss 14.113 | ppl 17714.4 | wps 45111.2 | wpb 510.9 | bsz 1 | num_updates 19034 | best_loss 8.318
2022-03-07 04:38:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19034 updates
2022-03-07 04:38:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:38:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:38:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 391 @ 19034 updates, score 14.305) (writing took 2.495072852820158 seconds)
2022-03-07 04:38:41 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 04:38:41 | INFO | train | epoch 391 | loss 0.757 | nll_loss 0.203 | ppl 1.15 | wps 24313.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 19034 | lr 0.000229211 | gnorm 0.398 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 56171
2022-03-07 04:38:41 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 04:38:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:40:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:40:49 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 14.366 | nll_loss 14.175 | ppl 18496.4 | wps 44371.8 | wpb 510.9 | bsz 1 | num_updates 19083 | best_loss 8.318
2022-03-07 04:40:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19083 updates
2022-03-07 04:40:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:40:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:40:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 392 @ 19083 updates, score 14.366) (writing took 2.436412239447236 seconds)
2022-03-07 04:40:52 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 04:40:52 | INFO | train | epoch 392 | loss 0.757 | nll_loss 0.203 | ppl 1.15 | wps 24277.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 19083 | lr 0.000228916 | gnorm 0.393 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 56302
2022-03-07 04:40:52 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 04:40:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:41:35 | INFO | train_inner | epoch 393:     17 / 49 loss=0.757, nll_loss=0.203, ppl=1.15, wps=24308.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.395, loss_scale=32, train_wall=227, gb_free=8.8, wall=56346
2022-03-07 04:42:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:43:00 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 14.268 | nll_loss 14.072 | ppl 17224.6 | wps 44485 | wpb 510.9 | bsz 1 | num_updates 19132 | best_loss 8.318
2022-03-07 04:43:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19132 updates
2022-03-07 04:43:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:43:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:43:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 393 @ 19132 updates, score 14.268) (writing took 2.4546803645789623 seconds)
2022-03-07 04:43:03 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 04:43:03 | INFO | train | epoch 393 | loss 0.757 | nll_loss 0.203 | ppl 1.15 | wps 24282.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 19132 | lr 0.000228623 | gnorm 0.393 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 56433
2022-03-07 04:43:03 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 04:43:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:45:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:45:11 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 14.294 | nll_loss 14.102 | ppl 17582.9 | wps 43929.8 | wpb 510.9 | bsz 1 | num_updates 19181 | best_loss 8.318
2022-03-07 04:45:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19181 updates
2022-03-07 04:45:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:45:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:45:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 394 @ 19181 updates, score 14.294) (writing took 2.4372723419219255 seconds)
2022-03-07 04:45:14 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 04:45:14 | INFO | train | epoch 394 | loss 0.756 | nll_loss 0.202 | ppl 1.15 | wps 24272.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 19181 | lr 0.000228331 | gnorm 0.39 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 56564
2022-03-07 04:45:14 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 04:45:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:46:02 | INFO | train_inner | epoch 395:     19 / 49 loss=0.756, nll_loss=0.202, ppl=1.15, wps=24319.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.391, loss_scale=64, train_wall=227, gb_free=8.8, wall=56612
2022-03-07 04:46:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:47:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:47:22 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 14.304 | nll_loss 14.111 | ppl 17689.3 | wps 44363.3 | wpb 510.9 | bsz 1 | num_updates 19229 | best_loss 8.318
2022-03-07 04:47:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19229 updates
2022-03-07 04:47:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:47:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:47:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 395 @ 19229 updates, score 14.304) (writing took 2.5562968347221613 seconds)
2022-03-07 04:47:25 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 04:47:25 | INFO | train | epoch 395 | loss 0.755 | nll_loss 0.201 | ppl 1.15 | wps 23783.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19229 | lr 0.000228046 | gnorm 0.388 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 56695
2022-03-07 04:47:25 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 04:47:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:49:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:49:33 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 14.271 | nll_loss 14.077 | ppl 17286.6 | wps 43545 | wpb 510.9 | bsz 1 | num_updates 19278 | best_loss 8.318
2022-03-07 04:49:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19278 updates
2022-03-07 04:49:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:49:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:49:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 396 @ 19278 updates, score 14.271) (writing took 2.475262939929962 seconds)
2022-03-07 04:49:36 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 04:49:36 | INFO | train | epoch 396 | loss 0.755 | nll_loss 0.201 | ppl 1.15 | wps 24256.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 19278 | lr 0.000227756 | gnorm 0.391 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 56826
2022-03-07 04:49:36 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 04:49:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:50:32 | INFO | train_inner | epoch 397:     22 / 49 loss=0.755, nll_loss=0.201, ppl=1.15, wps=24074.4, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.391, loss_scale=32, train_wall=230, gb_free=8.8, wall=56882
2022-03-07 04:51:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:51:44 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 14.219 | nll_loss 14.024 | ppl 16653.6 | wps 44607.6 | wpb 510.9 | bsz 1 | num_updates 19327 | best_loss 8.318
2022-03-07 04:51:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19327 updates
2022-03-07 04:51:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:51:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:51:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 397 @ 19327 updates, score 14.219) (writing took 2.432444516569376 seconds)
2022-03-07 04:51:46 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 04:51:46 | INFO | train | epoch 397 | loss 0.754 | nll_loss 0.2 | ppl 1.15 | wps 24347.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19327 | lr 0.000227467 | gnorm 0.388 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 56956
2022-03-07 04:51:46 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 04:51:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:53:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:53:55 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 14.314 | nll_loss 14.121 | ppl 17814.7 | wps 45291.8 | wpb 510.9 | bsz 1 | num_updates 19376 | best_loss 8.318
2022-03-07 04:53:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19376 updates
2022-03-07 04:53:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:53:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:53:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 398 @ 19376 updates, score 14.314) (writing took 2.5245397724211216 seconds)
2022-03-07 04:53:57 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-07 04:53:57 | INFO | train | epoch 398 | loss 0.754 | nll_loss 0.201 | ppl 1.15 | wps 24274.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 19376 | lr 0.000227179 | gnorm 0.389 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 57087
2022-03-07 04:53:57 | INFO | fairseq.trainer | begin training epoch 399
2022-03-07 04:53:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:54:58 | INFO | train_inner | epoch 399:     24 / 49 loss=0.754, nll_loss=0.2, ppl=1.15, wps=24330.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.388, loss_scale=64, train_wall=227, gb_free=8.8, wall=57148
2022-03-07 04:55:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:56:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:56:05 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 14.34 | nll_loss 14.15 | ppl 18178.3 | wps 45259.2 | wpb 510.9 | bsz 1 | num_updates 19424 | best_loss 8.318
2022-03-07 04:56:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19424 updates
2022-03-07 04:56:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:56:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:56:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 399 @ 19424 updates, score 14.34) (writing took 2.499938663095236 seconds)
2022-03-07 04:56:08 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-07 04:56:08 | INFO | train | epoch 399 | loss 0.753 | nll_loss 0.199 | ppl 1.15 | wps 23818.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19424 | lr 0.000226898 | gnorm 0.391 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 57218
2022-03-07 04:56:08 | INFO | fairseq.trainer | begin training epoch 400
2022-03-07 04:56:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:58:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:58:16 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 14.312 | nll_loss 14.122 | ppl 17828.7 | wps 44794.8 | wpb 510.9 | bsz 1 | num_updates 19473 | best_loss 8.318
2022-03-07 04:58:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19473 updates
2022-03-07 04:58:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:58:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:58:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 400 @ 19473 updates, score 14.312) (writing took 2.409493140876293 seconds)
2022-03-07 04:58:18 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-07 04:58:18 | INFO | train | epoch 400 | loss 0.753 | nll_loss 0.199 | ppl 1.15 | wps 24319.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 19473 | lr 0.000226612 | gnorm 0.388 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 57349
2022-03-07 04:58:18 | INFO | fairseq.trainer | begin training epoch 401
2022-03-07 04:58:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:59:27 | INFO | train_inner | epoch 401:     27 / 49 loss=0.753, nll_loss=0.199, ppl=1.15, wps=24117.9, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.387, loss_scale=32, train_wall=230, gb_free=8.8, wall=57417
2022-03-07 05:00:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:00:27 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 14.304 | nll_loss 14.112 | ppl 17700.9 | wps 44735.4 | wpb 510.9 | bsz 1 | num_updates 19522 | best_loss 8.318
2022-03-07 05:00:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19522 updates
2022-03-07 05:00:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:00:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:00:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 401 @ 19522 updates, score 14.304) (writing took 2.401182373985648 seconds)
2022-03-07 05:00:29 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-07 05:00:29 | INFO | train | epoch 401 | loss 0.752 | nll_loss 0.199 | ppl 1.15 | wps 24332.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19522 | lr 0.000226328 | gnorm 0.386 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 57479
2022-03-07 05:00:29 | INFO | fairseq.trainer | begin training epoch 402
2022-03-07 05:00:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:02:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:02:37 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 14.291 | nll_loss 14.1 | ppl 17559.7 | wps 45119.1 | wpb 510.9 | bsz 1 | num_updates 19571 | best_loss 8.318
2022-03-07 05:02:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19571 updates
2022-03-07 05:02:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:02:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:02:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 402 @ 19571 updates, score 14.291) (writing took 2.48293998837471 seconds)
2022-03-07 05:02:40 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-07 05:02:40 | INFO | train | epoch 402 | loss 0.752 | nll_loss 0.199 | ppl 1.15 | wps 24298.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 19571 | lr 0.000226044 | gnorm 0.388 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 57610
2022-03-07 05:02:40 | INFO | fairseq.trainer | begin training epoch 403
2022-03-07 05:02:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:03:54 | INFO | train_inner | epoch 403:     29 / 49 loss=0.752, nll_loss=0.198, ppl=1.15, wps=24354.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.387, loss_scale=64, train_wall=227, gb_free=8.8, wall=57684
2022-03-07 05:04:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:04:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:04:48 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 14.222 | nll_loss 14.028 | ppl 16706.2 | wps 44520.4 | wpb 510.9 | bsz 1 | num_updates 19619 | best_loss 8.318
2022-03-07 05:04:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19619 updates
2022-03-07 05:04:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:04:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:04:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 403 @ 19619 updates, score 14.222) (writing took 2.5082084238529205 seconds)
2022-03-07 05:04:51 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-07 05:04:51 | INFO | train | epoch 403 | loss 0.751 | nll_loss 0.198 | ppl 1.15 | wps 23813.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19619 | lr 0.000225768 | gnorm 0.383 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 57741
2022-03-07 05:04:51 | INFO | fairseq.trainer | begin training epoch 404
2022-03-07 05:04:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:06:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:06:59 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 14.291 | nll_loss 14.098 | ppl 17531 | wps 44584.4 | wpb 510.9 | bsz 1 | num_updates 19668 | best_loss 8.318
2022-03-07 05:06:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19668 updates
2022-03-07 05:06:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:07:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:07:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 404 @ 19668 updates, score 14.291) (writing took 2.5707244481891394 seconds)
2022-03-07 05:07:01 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-07 05:07:01 | INFO | train | epoch 404 | loss 0.75 | nll_loss 0.197 | ppl 1.15 | wps 24296.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 19668 | lr 0.000225486 | gnorm 0.383 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 57872
2022-03-07 05:07:01 | INFO | fairseq.trainer | begin training epoch 405
2022-03-07 05:07:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:08:23 | INFO | train_inner | epoch 405:     32 / 49 loss=0.75, nll_loss=0.197, ppl=1.15, wps=24089.3, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.382, loss_scale=32, train_wall=230, gb_free=8.8, wall=57953
2022-03-07 05:09:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:09:10 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 14.321 | nll_loss 14.128 | ppl 17910.1 | wps 44865.2 | wpb 510.9 | bsz 1 | num_updates 19717 | best_loss 8.318
2022-03-07 05:09:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19717 updates
2022-03-07 05:09:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:09:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:09:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 405 @ 19717 updates, score 14.321) (writing took 2.430109493434429 seconds)
2022-03-07 05:09:12 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-07 05:09:12 | INFO | train | epoch 405 | loss 0.75 | nll_loss 0.197 | ppl 1.15 | wps 24317 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 19717 | lr 0.000225206 | gnorm 0.382 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 58002
2022-03-07 05:09:12 | INFO | fairseq.trainer | begin training epoch 406
2022-03-07 05:09:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:09:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:11:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:11:20 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 14.315 | nll_loss 14.125 | ppl 17868.7 | wps 44128.7 | wpb 510.9 | bsz 1 | num_updates 19765 | best_loss 8.318
2022-03-07 05:11:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19765 updates
2022-03-07 05:11:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:11:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:11:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 406 @ 19765 updates, score 14.315) (writing took 2.6337332483381033 seconds)
2022-03-07 05:11:23 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-07 05:11:23 | INFO | train | epoch 406 | loss 0.75 | nll_loss 0.197 | ppl 1.15 | wps 23790.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19765 | lr 0.000224932 | gnorm 0.389 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 58133
2022-03-07 05:11:23 | INFO | fairseq.trainer | begin training epoch 407
2022-03-07 05:11:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:12:52 | INFO | train_inner | epoch 407:     35 / 49 loss=0.75, nll_loss=0.197, ppl=1.15, wps=24104.5, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.386, loss_scale=32, train_wall=230, gb_free=8.8, wall=58222
2022-03-07 05:13:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:13:31 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 14.237 | nll_loss 14.042 | ppl 16873 | wps 45884.1 | wpb 510.9 | bsz 1 | num_updates 19814 | best_loss 8.318
2022-03-07 05:13:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19814 updates
2022-03-07 05:13:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:13:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:13:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 407 @ 19814 updates, score 14.237) (writing took 2.4765439573675394 seconds)
2022-03-07 05:13:33 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-07 05:13:33 | INFO | train | epoch 407 | loss 0.749 | nll_loss 0.196 | ppl 1.15 | wps 24343.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19814 | lr 0.000224654 | gnorm 0.382 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 58264
2022-03-07 05:13:33 | INFO | fairseq.trainer | begin training epoch 408
2022-03-07 05:13:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:15:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:15:42 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 14.237 | nll_loss 14.044 | ppl 16891.7 | wps 44850.4 | wpb 510.9 | bsz 1 | num_updates 19863 | best_loss 8.318
2022-03-07 05:15:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19863 updates
2022-03-07 05:15:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:15:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:15:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 408 @ 19863 updates, score 14.237) (writing took 2.5694535933434963 seconds)
2022-03-07 05:15:45 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-07 05:15:45 | INFO | train | epoch 408 | loss 0.749 | nll_loss 0.196 | ppl 1.15 | wps 24236 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 19863 | lr 0.000224377 | gnorm 0.386 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 58395
2022-03-07 05:15:45 | INFO | fairseq.trainer | begin training epoch 409
2022-03-07 05:15:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:17:19 | INFO | train_inner | epoch 409:     37 / 49 loss=0.749, nll_loss=0.196, ppl=1.15, wps=24329.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.384, loss_scale=64, train_wall=227, gb_free=8.8, wall=58489
2022-03-07 05:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:17:53 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 14.423 | nll_loss 14.234 | ppl 19275.5 | wps 44943.5 | wpb 510.9 | bsz 1 | num_updates 19912 | best_loss 8.318
2022-03-07 05:17:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19912 updates
2022-03-07 05:17:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:17:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:17:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 409 @ 19912 updates, score 14.423) (writing took 2.459196774289012 seconds)
2022-03-07 05:17:55 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-07 05:17:55 | INFO | train | epoch 409 | loss 0.748 | nll_loss 0.196 | ppl 1.15 | wps 24324 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19912 | lr 0.0002241 | gnorm 0.384 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 58526
2022-03-07 05:17:55 | INFO | fairseq.trainer | begin training epoch 410
2022-03-07 05:17:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:19:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:20:04 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 14.362 | nll_loss 14.173 | ppl 18465.9 | wps 44616.9 | wpb 510.9 | bsz 1 | num_updates 19961 | best_loss 8.318
2022-03-07 05:20:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19961 updates
2022-03-07 05:20:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:20:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:20:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 410 @ 19961 updates, score 14.362) (writing took 2.4600767362862825 seconds)
2022-03-07 05:20:06 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-07 05:20:06 | INFO | train | epoch 410 | loss 0.748 | nll_loss 0.195 | ppl 1.14 | wps 24280.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 19961 | lr 0.000223825 | gnorm 0.381 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 58656
2022-03-07 05:20:06 | INFO | fairseq.trainer | begin training epoch 411
2022-03-07 05:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:21:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:21:48 | INFO | train_inner | epoch 411:     40 / 49 loss=0.748, nll_loss=0.195, ppl=1.14, wps=24123, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=20000, lr=0.000223607, gnorm=0.382, loss_scale=32, train_wall=229, gb_free=8.8, wall=58758
2022-03-07 05:22:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:22:14 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 14.374 | nll_loss 14.183 | ppl 18598.8 | wps 44771.9 | wpb 510.9 | bsz 1 | num_updates 20009 | best_loss 8.318
2022-03-07 05:22:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 20009 updates
2022-03-07 05:22:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:22:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:22:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 411 @ 20009 updates, score 14.374) (writing took 2.5361520759761333 seconds)
2022-03-07 05:22:17 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-07 05:22:17 | INFO | train | epoch 411 | loss 0.747 | nll_loss 0.195 | ppl 1.14 | wps 23853.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 20009 | lr 0.000223557 | gnorm 0.384 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 58787
2022-03-07 05:22:17 | INFO | fairseq.trainer | begin training epoch 412
2022-03-07 05:22:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:24:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:24:25 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 14.243 | nll_loss 14.048 | ppl 16933.9 | wps 45008.9 | wpb 510.9 | bsz 1 | num_updates 20058 | best_loss 8.318
2022-03-07 05:24:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20058 updates
2022-03-07 05:24:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:24:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:24:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 412 @ 20058 updates, score 14.243) (writing took 2.5172450114041567 seconds)
2022-03-07 05:24:27 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-07 05:24:27 | INFO | train | epoch 412 | loss 0.747 | nll_loss 0.195 | ppl 1.14 | wps 24340.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20058 | lr 0.000223283 | gnorm 0.382 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 58917
2022-03-07 05:24:27 | INFO | fairseq.trainer | begin training epoch 413
2022-03-07 05:24:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:26:14 | INFO | train_inner | epoch 413:     42 / 49 loss=0.747, nll_loss=0.195, ppl=1.14, wps=24353.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=20100, lr=0.00022305, gnorm=0.381, loss_scale=32, train_wall=227, gb_free=8.8, wall=59024
2022-03-07 05:26:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:26:35 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 14.245 | nll_loss 14.053 | ppl 16996.5 | wps 44833 | wpb 510.9 | bsz 1 | num_updates 20107 | best_loss 8.318
2022-03-07 05:26:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20107 updates
2022-03-07 05:26:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:26:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:26:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 413 @ 20107 updates, score 14.245) (writing took 2.415603343397379 seconds)
2022-03-07 05:26:38 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-07 05:26:38 | INFO | train | epoch 413 | loss 0.747 | nll_loss 0.194 | ppl 1.14 | wps 24343.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20107 | lr 0.000223011 | gnorm 0.38 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 59048
2022-03-07 05:26:38 | INFO | fairseq.trainer | begin training epoch 414
2022-03-07 05:26:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:28:46 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 14.303 | nll_loss 14.112 | ppl 17702.8 | wps 45121.3 | wpb 510.9 | bsz 1 | num_updates 20156 | best_loss 8.318
2022-03-07 05:28:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20156 updates
2022-03-07 05:28:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:28:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:28:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 414 @ 20156 updates, score 14.303) (writing took 2.557262372225523 seconds)
2022-03-07 05:28:49 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-07 05:28:49 | INFO | train | epoch 414 | loss 0.746 | nll_loss 0.194 | ppl 1.14 | wps 24292.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20156 | lr 0.00022274 | gnorm 0.383 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 59179
2022-03-07 05:28:49 | INFO | fairseq.trainer | begin training epoch 415
2022-03-07 05:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:28:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:30:43 | INFO | train_inner | epoch 415:     45 / 49 loss=0.746, nll_loss=0.194, ppl=1.14, wps=24129.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.382, loss_scale=32, train_wall=229, gb_free=8.8, wall=59293
2022-03-07 05:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:30:57 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 14.313 | nll_loss 14.122 | ppl 17831.1 | wps 44998 | wpb 510.9 | bsz 1 | num_updates 20204 | best_loss 8.318
2022-03-07 05:30:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20204 updates
2022-03-07 05:30:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:30:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:30:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 415 @ 20204 updates, score 14.313) (writing took 2.3712074123322964 seconds)
2022-03-07 05:30:59 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-07 05:30:59 | INFO | train | epoch 415 | loss 0.746 | nll_loss 0.193 | ppl 1.14 | wps 23877.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 20204 | lr 0.000222475 | gnorm 0.38 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 59309
2022-03-07 05:30:59 | INFO | fairseq.trainer | begin training epoch 416
2022-03-07 05:30:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:33:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:33:07 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 14.341 | nll_loss 14.151 | ppl 18191.8 | wps 44361 | wpb 510.9 | bsz 1 | num_updates 20253 | best_loss 8.318
2022-03-07 05:33:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20253 updates
2022-03-07 05:33:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:33:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:33:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 416 @ 20253 updates, score 14.341) (writing took 2.569738060235977 seconds)
2022-03-07 05:33:10 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-07 05:33:10 | INFO | train | epoch 416 | loss 0.745 | nll_loss 0.192 | ppl 1.14 | wps 24289 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20253 | lr 0.000222206 | gnorm 0.376 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 59440
2022-03-07 05:33:10 | INFO | fairseq.trainer | begin training epoch 417
2022-03-07 05:33:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:35:09 | INFO | train_inner | epoch 417:     47 / 49 loss=0.745, nll_loss=0.193, ppl=1.14, wps=24368, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.376, loss_scale=64, train_wall=227, gb_free=8.8, wall=59559
2022-03-07 05:35:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:35:18 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 14.31 | nll_loss 14.119 | ppl 17787.3 | wps 44588.2 | wpb 510.9 | bsz 1 | num_updates 20302 | best_loss 8.318
2022-03-07 05:35:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20302 updates
2022-03-07 05:35:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:35:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:35:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 417 @ 20302 updates, score 14.31) (writing took 2.4274957850575447 seconds)
2022-03-07 05:35:20 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-07 05:35:20 | INFO | train | epoch 417 | loss 0.744 | nll_loss 0.192 | ppl 1.14 | wps 24361.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20302 | lr 0.000221937 | gnorm 0.375 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 59570
2022-03-07 05:35:20 | INFO | fairseq.trainer | begin training epoch 418
2022-03-07 05:35:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:37:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:37:28 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 14.233 | nll_loss 14.04 | ppl 16842.1 | wps 44297.8 | wpb 510.9 | bsz 1 | num_updates 20351 | best_loss 8.318
2022-03-07 05:37:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20351 updates
2022-03-07 05:37:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:37:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:37:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 418 @ 20351 updates, score 14.233) (writing took 2.4051435068249702 seconds)
2022-03-07 05:37:31 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-07 05:37:31 | INFO | train | epoch 418 | loss 0.744 | nll_loss 0.193 | ppl 1.14 | wps 24327.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20351 | lr 0.00022167 | gnorm 0.382 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 59701
2022-03-07 05:37:31 | INFO | fairseq.trainer | begin training epoch 419
2022-03-07 05:37:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:39:34 | INFO | train_inner | epoch 419:     49 / 49 loss=0.744, nll_loss=0.193, ppl=1.14, wps=24346.1, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=20400, lr=0.000221404, gnorm=0.382, loss_scale=64, train_wall=226, gb_free=8.8, wall=59824
2022-03-07 05:39:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:39:39 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 14.31 | nll_loss 14.119 | ppl 17793.1 | wps 44721.9 | wpb 510.9 | bsz 1 | num_updates 20400 | best_loss 8.318
2022-03-07 05:39:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20400 updates
2022-03-07 05:39:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:39:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:39:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 419 @ 20400 updates, score 14.31) (writing took 2.5051396377384663 seconds)
2022-03-07 05:39:42 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-07 05:39:42 | INFO | train | epoch 419 | loss 0.744 | nll_loss 0.192 | ppl 1.14 | wps 24313.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20400 | lr 0.000221404 | gnorm 0.379 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 59832
2022-03-07 05:39:42 | INFO | fairseq.trainer | begin training epoch 420
2022-03-07 05:39:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:40:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 05:41:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:41:50 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 14.281 | nll_loss 14.091 | ppl 17451 | wps 44428.4 | wpb 510.9 | bsz 1 | num_updates 20448 | best_loss 8.318
2022-03-07 05:41:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20448 updates
2022-03-07 05:41:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:41:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:41:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 420 @ 20448 updates, score 14.281) (writing took 2.4814953804016113 seconds)
2022-03-07 05:41:52 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-07 05:41:52 | INFO | train | epoch 420 | loss 0.742 | nll_loss 0.19 | ppl 1.14 | wps 23852.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 20448 | lr 0.000221144 | gnorm 0.372 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 59962
2022-03-07 05:41:52 | INFO | fairseq.trainer | begin training epoch 421
2022-03-07 05:41:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:42:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:43:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:44:00 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 14.313 | nll_loss 14.122 | ppl 17828.1 | wps 44644.3 | wpb 510.9 | bsz 1 | num_updates 20496 | best_loss 8.318
2022-03-07 05:44:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20496 updates
2022-03-07 05:44:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:44:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:44:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 421 @ 20496 updates, score 14.313) (writing took 2.41101985424757 seconds)
2022-03-07 05:44:03 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-07 05:44:03 | INFO | train | epoch 421 | loss 0.743 | nll_loss 0.191 | ppl 1.14 | wps 23820.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 20496 | lr 0.000220885 | gnorm 0.381 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 60093
2022-03-07 05:44:03 | INFO | fairseq.trainer | begin training epoch 422
2022-03-07 05:44:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:44:13 | INFO | train_inner | epoch 422:      4 / 49 loss=0.742, nll_loss=0.191, ppl=1.14, wps=23253.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.376, loss_scale=32, train_wall=232, gb_free=8.8, wall=60103
2022-03-07 05:46:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:46:11 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 14.31 | nll_loss 14.119 | ppl 17788.1 | wps 44571.8 | wpb 510.9 | bsz 1 | num_updates 20545 | best_loss 8.318
2022-03-07 05:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20545 updates
2022-03-07 05:46:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:46:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:46:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 422 @ 20545 updates, score 14.31) (writing took 2.4644833225756884 seconds)
2022-03-07 05:46:13 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-07 05:46:13 | INFO | train | epoch 422 | loss 0.742 | nll_loss 0.191 | ppl 1.14 | wps 24320.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20545 | lr 0.000220621 | gnorm 0.374 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 60224
2022-03-07 05:46:13 | INFO | fairseq.trainer | begin training epoch 423
2022-03-07 05:46:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:48:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:48:22 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 14.271 | nll_loss 14.078 | ppl 17292.7 | wps 44680.3 | wpb 510.9 | bsz 1 | num_updates 20594 | best_loss 8.318
2022-03-07 05:48:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20594 updates
2022-03-07 05:48:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:48:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:48:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 423 @ 20594 updates, score 14.271) (writing took 2.434041576460004 seconds)
2022-03-07 05:48:24 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-07 05:48:24 | INFO | train | epoch 423 | loss 0.742 | nll_loss 0.191 | ppl 1.14 | wps 24321.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20594 | lr 0.000220358 | gnorm 0.377 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 60354
2022-03-07 05:48:24 | INFO | fairseq.trainer | begin training epoch 424
2022-03-07 05:48:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:48:39 | INFO | train_inner | epoch 424:      6 / 49 loss=0.742, nll_loss=0.191, ppl=1.14, wps=24363.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.375, loss_scale=64, train_wall=227, gb_free=8.8, wall=60370
2022-03-07 05:50:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:50:32 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 14.269 | nll_loss 14.078 | ppl 17299.9 | wps 44203 | wpb 510.9 | bsz 1 | num_updates 20643 | best_loss 8.318
2022-03-07 05:50:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20643 updates
2022-03-07 05:50:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:50:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:50:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 424 @ 20643 updates, score 14.269) (writing took 2.507628995925188 seconds)
2022-03-07 05:50:35 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-07 05:50:35 | INFO | train | epoch 424 | loss 0.741 | nll_loss 0.19 | ppl 1.14 | wps 24344.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20643 | lr 0.000220097 | gnorm 0.369 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 60485
2022-03-07 05:50:35 | INFO | fairseq.trainer | begin training epoch 425
2022-03-07 05:50:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:52:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:52:43 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 14.31 | nll_loss 14.119 | ppl 17792.4 | wps 44569.5 | wpb 510.9 | bsz 1 | num_updates 20692 | best_loss 8.318
2022-03-07 05:52:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20692 updates
2022-03-07 05:52:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:52:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:52:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 425 @ 20692 updates, score 14.31) (writing took 2.484967425465584 seconds)
2022-03-07 05:52:45 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-07 05:52:45 | INFO | train | epoch 425 | loss 0.741 | nll_loss 0.19 | ppl 1.14 | wps 24282.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20692 | lr 0.000219836 | gnorm 0.376 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 60616
2022-03-07 05:52:45 | INFO | fairseq.trainer | begin training epoch 426
2022-03-07 05:52:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:53:06 | INFO | train_inner | epoch 426:      8 / 49 loss=0.741, nll_loss=0.19, ppl=1.14, wps=24337.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.373, loss_scale=64, train_wall=227, gb_free=8.8, wall=60636
2022-03-07 05:53:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 05:53:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:54:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:54:54 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 14.39 | nll_loss 14.204 | ppl 18867.5 | wps 44902.3 | wpb 510.9 | bsz 1 | num_updates 20739 | best_loss 8.318
2022-03-07 05:54:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20739 updates
2022-03-07 05:54:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:54:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:54:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 426 @ 20739 updates, score 14.39) (writing took 2.4852886237204075 seconds)
2022-03-07 05:54:56 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-07 05:54:56 | INFO | train | epoch 426 | loss 0.74 | nll_loss 0.189 | ppl 1.14 | wps 23337.2 | ups 0.36 | wpb 64829.4 | bsz 126.6 | num_updates 20739 | lr 0.000219587 | gnorm 0.376 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 60746
2022-03-07 05:54:56 | INFO | fairseq.trainer | begin training epoch 427
2022-03-07 05:54:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:56:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:57:04 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 14.302 | nll_loss 14.112 | ppl 17712.6 | wps 45276.1 | wpb 510.9 | bsz 1 | num_updates 20788 | best_loss 8.318
2022-03-07 05:57:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20788 updates
2022-03-07 05:57:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:57:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:57:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 427 @ 20788 updates, score 14.302) (writing took 2.496240481734276 seconds)
2022-03-07 05:57:07 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-07 05:57:07 | INFO | train | epoch 427 | loss 0.74 | nll_loss 0.189 | ppl 1.14 | wps 24336.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20788 | lr 0.000219328 | gnorm 0.375 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 60877
2022-03-07 05:57:07 | INFO | fairseq.trainer | begin training epoch 428
2022-03-07 05:57:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:57:37 | INFO | train_inner | epoch 428:     12 / 49 loss=0.74, nll_loss=0.189, ppl=1.14, wps=23915.8, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.376, loss_scale=32, train_wall=232, gb_free=8.8, wall=60907
2022-03-07 05:59:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:59:14 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 14.391 | nll_loss 14.203 | ppl 18865.1 | wps 45844.4 | wpb 510.9 | bsz 1 | num_updates 20837 | best_loss 8.318
2022-03-07 05:59:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20837 updates
2022-03-07 05:59:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:59:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:59:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 428 @ 20837 updates, score 14.391) (writing took 2.4849978052079678 seconds)
2022-03-07 05:59:17 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-07 05:59:17 | INFO | train | epoch 428 | loss 0.74 | nll_loss 0.189 | ppl 1.14 | wps 24382.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20837 | lr 0.00021907 | gnorm 0.372 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 61007
2022-03-07 05:59:17 | INFO | fairseq.trainer | begin training epoch 429
2022-03-07 05:59:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:01:25 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 14.316 | nll_loss 14.126 | ppl 17878.7 | wps 44660.7 | wpb 510.9 | bsz 1 | num_updates 20886 | best_loss 8.318
2022-03-07 06:01:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20886 updates
2022-03-07 06:01:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:01:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:01:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 429 @ 20886 updates, score 14.316) (writing took 2.5333952493965626 seconds)
2022-03-07 06:01:28 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-07 06:01:28 | INFO | train | epoch 429 | loss 0.739 | nll_loss 0.188 | ppl 1.14 | wps 24258.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20886 | lr 0.000218813 | gnorm 0.374 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 61138
2022-03-07 06:01:28 | INFO | fairseq.trainer | begin training epoch 430
2022-03-07 06:01:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:02:04 | INFO | train_inner | epoch 430:     14 / 49 loss=0.739, nll_loss=0.189, ppl=1.14, wps=24348.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.373, loss_scale=64, train_wall=227, gb_free=8.8, wall=61174
2022-03-07 06:03:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:03:36 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 14.268 | nll_loss 14.078 | ppl 17294.5 | wps 44729.6 | wpb 510.9 | bsz 1 | num_updates 20935 | best_loss 8.318
2022-03-07 06:03:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20935 updates
2022-03-07 06:03:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:03:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:03:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 430 @ 20935 updates, score 14.268) (writing took 2.421466391533613 seconds)
2022-03-07 06:03:38 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-07 06:03:38 | INFO | train | epoch 430 | loss 0.739 | nll_loss 0.189 | ppl 1.14 | wps 24361.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20935 | lr 0.000218556 | gnorm 0.378 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 61269
2022-03-07 06:03:38 | INFO | fairseq.trainer | begin training epoch 431
2022-03-07 06:03:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:03:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:05:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:05:47 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 14.267 | nll_loss 14.076 | ppl 17274.5 | wps 45136.1 | wpb 510.9 | bsz 1 | num_updates 20983 | best_loss 8.318
2022-03-07 06:05:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20983 updates
2022-03-07 06:05:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:05:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:05:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 431 @ 20983 updates, score 14.267) (writing took 2.4513453245162964 seconds)
2022-03-07 06:05:49 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-07 06:05:49 | INFO | train | epoch 431 | loss 0.737 | nll_loss 0.186 | ppl 1.14 | wps 23816 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 20983 | lr 0.000218306 | gnorm 0.366 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 61399
2022-03-07 06:05:49 | INFO | fairseq.trainer | begin training epoch 432
2022-03-07 06:05:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:06:32 | INFO | train_inner | epoch 432:     17 / 49 loss=0.738, nll_loss=0.187, ppl=1.14, wps=24127, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.37, loss_scale=32, train_wall=229, gb_free=8.8, wall=61443
2022-03-07 06:07:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:07:57 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 14.255 | nll_loss 14.065 | ppl 17134.5 | wps 44950.6 | wpb 510.9 | bsz 1 | num_updates 21032 | best_loss 8.318
2022-03-07 06:07:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21032 updates
2022-03-07 06:07:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:08:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:08:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 432 @ 21032 updates, score 14.255) (writing took 2.524731185287237 seconds)
2022-03-07 06:08:00 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-07 06:08:00 | INFO | train | epoch 432 | loss 0.737 | nll_loss 0.187 | ppl 1.14 | wps 24308 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21032 | lr 0.000218052 | gnorm 0.37 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 61530
2022-03-07 06:08:00 | INFO | fairseq.trainer | begin training epoch 433
2022-03-07 06:08:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:10:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:10:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:10:08 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 14.367 | nll_loss 14.179 | ppl 18549.1 | wps 44525.7 | wpb 510.9 | bsz 1 | num_updates 21080 | best_loss 8.318
2022-03-07 06:10:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21080 updates
2022-03-07 06:10:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:10:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:10:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 433 @ 21080 updates, score 14.367) (writing took 2.426748564466834 seconds)
2022-03-07 06:10:10 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-07 06:10:10 | INFO | train | epoch 433 | loss 0.738 | nll_loss 0.187 | ppl 1.14 | wps 23868.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21080 | lr 0.000217803 | gnorm 0.37 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 61661
2022-03-07 06:10:10 | INFO | fairseq.trainer | begin training epoch 434
2022-03-07 06:10:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:11:01 | INFO | train_inner | epoch 434:     20 / 49 loss=0.737, nll_loss=0.187, ppl=1.14, wps=24139.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.37, loss_scale=32, train_wall=229, gb_free=8.8, wall=61711
2022-03-07 06:12:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:12:18 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 14.38 | nll_loss 14.192 | ppl 18718.5 | wps 44934.4 | wpb 510.9 | bsz 1 | num_updates 21129 | best_loss 8.318
2022-03-07 06:12:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21129 updates
2022-03-07 06:12:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:12:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:12:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 434 @ 21129 updates, score 14.38) (writing took 2.4649850074201822 seconds)
2022-03-07 06:12:21 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-07 06:12:21 | INFO | train | epoch 434 | loss 0.737 | nll_loss 0.187 | ppl 1.14 | wps 24334.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21129 | lr 0.000217551 | gnorm 0.366 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 61791
2022-03-07 06:12:21 | INFO | fairseq.trainer | begin training epoch 435
2022-03-07 06:12:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:14:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:14:29 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 14.266 | nll_loss 14.076 | ppl 17275.5 | wps 44467.3 | wpb 510.9 | bsz 1 | num_updates 21178 | best_loss 8.318
2022-03-07 06:14:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21178 updates
2022-03-07 06:14:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:14:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:14:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 435 @ 21178 updates, score 14.266) (writing took 2.4725920539349318 seconds)
2022-03-07 06:14:32 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-07 06:14:32 | INFO | train | epoch 435 | loss 0.737 | nll_loss 0.187 | ppl 1.14 | wps 24322.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21178 | lr 0.000217299 | gnorm 0.369 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 61922
2022-03-07 06:14:32 | INFO | fairseq.trainer | begin training epoch 436
2022-03-07 06:14:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:15:27 | INFO | train_inner | epoch 436:     22 / 49 loss=0.736, nll_loss=0.186, ppl=1.14, wps=24368.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.367, loss_scale=32, train_wall=227, gb_free=8.8, wall=61978
2022-03-07 06:16:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:16:40 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 14.336 | nll_loss 14.147 | ppl 18145.2 | wps 44771.7 | wpb 510.9 | bsz 1 | num_updates 21227 | best_loss 8.318
2022-03-07 06:16:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21227 updates
2022-03-07 06:16:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:16:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:16:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 436 @ 21227 updates, score 14.336) (writing took 2.4027899969369173 seconds)
2022-03-07 06:16:42 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-07 06:16:42 | INFO | train | epoch 436 | loss 0.736 | nll_loss 0.186 | ppl 1.14 | wps 24362.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21227 | lr 0.000217048 | gnorm 0.371 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 62052
2022-03-07 06:16:42 | INFO | fairseq.trainer | begin training epoch 437
2022-03-07 06:16:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:16:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:18:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:18:50 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 14.29 | nll_loss 14.1 | ppl 17561.5 | wps 45010 | wpb 510.9 | bsz 1 | num_updates 21275 | best_loss 8.318
2022-03-07 06:18:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21275 updates
2022-03-07 06:18:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:18:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:18:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 437 @ 21275 updates, score 14.29) (writing took 2.5232160724699497 seconds)
2022-03-07 06:18:52 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-07 06:18:52 | INFO | train | epoch 437 | loss 0.735 | nll_loss 0.186 | ppl 1.14 | wps 23871.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21275 | lr 0.000216803 | gnorm 0.371 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 62183
2022-03-07 06:18:52 | INFO | fairseq.trainer | begin training epoch 438
2022-03-07 06:18:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:19:56 | INFO | train_inner | epoch 438:     25 / 49 loss=0.736, nll_loss=0.186, ppl=1.14, wps=24142.4, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.37, loss_scale=32, train_wall=229, gb_free=8.8, wall=62246
2022-03-07 06:20:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:21:01 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 14.283 | nll_loss 14.094 | ppl 17490 | wps 44778.9 | wpb 510.9 | bsz 1 | num_updates 21324 | best_loss 8.318
2022-03-07 06:21:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21324 updates
2022-03-07 06:21:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:21:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:21:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 438 @ 21324 updates, score 14.283) (writing took 2.5212768856436014 seconds)
2022-03-07 06:21:03 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-07 06:21:03 | INFO | train | epoch 438 | loss 0.735 | nll_loss 0.185 | ppl 1.14 | wps 24297.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21324 | lr 0.000216554 | gnorm 0.367 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 62313
2022-03-07 06:21:03 | INFO | fairseq.trainer | begin training epoch 439
2022-03-07 06:21:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:23:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:23:11 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 14.312 | nll_loss 14.122 | ppl 17828.1 | wps 44538.7 | wpb 510.9 | bsz 1 | num_updates 21373 | best_loss 8.318
2022-03-07 06:23:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21373 updates
2022-03-07 06:23:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:23:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 439 @ 21373 updates, score 14.312) (writing took 2.432845078408718 seconds)
2022-03-07 06:23:14 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-07 06:23:14 | INFO | train | epoch 439 | loss 0.735 | nll_loss 0.185 | ppl 1.14 | wps 24307.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21373 | lr 0.000216305 | gnorm 0.367 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 62444
2022-03-07 06:23:14 | INFO | fairseq.trainer | begin training epoch 440
2022-03-07 06:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:24:23 | INFO | train_inner | epoch 440:     27 / 49 loss=0.735, nll_loss=0.185, ppl=1.14, wps=24346.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.367, loss_scale=64, train_wall=227, gb_free=8.8, wall=62513
2022-03-07 06:25:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:25:22 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 14.341 | nll_loss 14.154 | ppl 18225.8 | wps 45168.4 | wpb 510.9 | bsz 1 | num_updates 21422 | best_loss 8.318
2022-03-07 06:25:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21422 updates
2022-03-07 06:25:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:25:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:25:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 440 @ 21422 updates, score 14.341) (writing took 2.548703232780099 seconds)
2022-03-07 06:25:25 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-07 06:25:25 | INFO | train | epoch 440 | loss 0.734 | nll_loss 0.185 | ppl 1.14 | wps 24310.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21422 | lr 0.000216058 | gnorm 0.368 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 62575
2022-03-07 06:25:25 | INFO | fairseq.trainer | begin training epoch 441
2022-03-07 06:25:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:27:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:27:33 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 14.335 | nll_loss 14.146 | ppl 18127.1 | wps 45827.6 | wpb 510.9 | bsz 1 | num_updates 21471 | best_loss 8.318
2022-03-07 06:27:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21471 updates
2022-03-07 06:27:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:27:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:27:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 441 @ 21471 updates, score 14.335) (writing took 2.435280129313469 seconds)
2022-03-07 06:27:35 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-07 06:27:35 | INFO | train | epoch 441 | loss 0.735 | nll_loss 0.185 | ppl 1.14 | wps 24354.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21471 | lr 0.000215811 | gnorm 0.369 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 62705
2022-03-07 06:27:35 | INFO | fairseq.trainer | begin training epoch 442
2022-03-07 06:27:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:28:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 06:28:51 | INFO | train_inner | epoch 442:     30 / 49 loss=0.734, nll_loss=0.185, ppl=1.14, wps=24141.4, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.368, loss_scale=64, train_wall=229, gb_free=8.8, wall=62782
2022-03-07 06:29:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:29:43 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 14.297 | nll_loss 14.106 | ppl 17631.5 | wps 45285.5 | wpb 510.9 | bsz 1 | num_updates 21519 | best_loss 8.318
2022-03-07 06:29:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21519 updates
2022-03-07 06:29:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:29:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:29:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 442 @ 21519 updates, score 14.297) (writing took 2.5993057191371918 seconds)
2022-03-07 06:29:46 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-07 06:29:46 | INFO | train | epoch 442 | loss 0.733 | nll_loss 0.184 | ppl 1.14 | wps 23812.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21519 | lr 0.00021557 | gnorm 0.362 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 62836
2022-03-07 06:29:46 | INFO | fairseq.trainer | begin training epoch 443
2022-03-07 06:29:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:31:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:31:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:31:54 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 14.367 | nll_loss 14.179 | ppl 18546.7 | wps 44472.9 | wpb 510.9 | bsz 1 | num_updates 21567 | best_loss 8.318
2022-03-07 06:31:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21567 updates
2022-03-07 06:31:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:31:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:31:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 443 @ 21567 updates, score 14.367) (writing took 2.419475082308054 seconds)
2022-03-07 06:31:57 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-07 06:31:57 | INFO | train | epoch 443 | loss 0.733 | nll_loss 0.184 | ppl 1.14 | wps 23810.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21567 | lr 0.00021533 | gnorm 0.367 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 62967
2022-03-07 06:31:57 | INFO | fairseq.trainer | begin training epoch 444
2022-03-07 06:31:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:33:20 | INFO | train_inner | epoch 444:     33 / 49 loss=0.733, nll_loss=0.184, ppl=1.14, wps=24100.1, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.366, loss_scale=32, train_wall=230, gb_free=8.8, wall=63051
2022-03-07 06:34:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:34:05 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 14.298 | nll_loss 14.109 | ppl 17667.4 | wps 45106.4 | wpb 510.9 | bsz 1 | num_updates 21616 | best_loss 8.318
2022-03-07 06:34:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21616 updates
2022-03-07 06:34:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:34:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:34:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 444 @ 21616 updates, score 14.298) (writing took 2.473799131810665 seconds)
2022-03-07 06:34:07 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-07 06:34:07 | INFO | train | epoch 444 | loss 0.733 | nll_loss 0.184 | ppl 1.14 | wps 24319.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21616 | lr 0.000215086 | gnorm 0.369 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 63098
2022-03-07 06:34:07 | INFO | fairseq.trainer | begin training epoch 445
2022-03-07 06:34:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:36:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:36:15 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 14.293 | nll_loss 14.103 | ppl 17598.7 | wps 44824.6 | wpb 510.9 | bsz 1 | num_updates 21665 | best_loss 8.318
2022-03-07 06:36:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21665 updates
2022-03-07 06:36:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:36:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:36:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 445 @ 21665 updates, score 14.293) (writing took 2.5614043716341257 seconds)
2022-03-07 06:36:18 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-07 06:36:18 | INFO | train | epoch 445 | loss 0.733 | nll_loss 0.184 | ppl 1.14 | wps 24308.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21665 | lr 0.000214843 | gnorm 0.367 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 63228
2022-03-07 06:36:18 | INFO | fairseq.trainer | begin training epoch 446
2022-03-07 06:36:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:37:47 | INFO | train_inner | epoch 446:     35 / 49 loss=0.732, nll_loss=0.183, ppl=1.14, wps=24351.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.367, loss_scale=64, train_wall=227, gb_free=8.8, wall=63317
2022-03-07 06:38:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:38:26 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 14.365 | nll_loss 14.18 | ppl 18555.6 | wps 44501.3 | wpb 510.9 | bsz 1 | num_updates 21714 | best_loss 8.318
2022-03-07 06:38:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21714 updates
2022-03-07 06:38:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:38:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:38:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 446 @ 21714 updates, score 14.365) (writing took 2.439970074221492 seconds)
2022-03-07 06:38:28 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-07 06:38:28 | INFO | train | epoch 446 | loss 0.732 | nll_loss 0.183 | ppl 1.13 | wps 24365.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21714 | lr 0.0002146 | gnorm 0.366 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 63359
2022-03-07 06:38:28 | INFO | fairseq.trainer | begin training epoch 447
2022-03-07 06:38:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:40:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:40:37 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 14.32 | nll_loss 14.132 | ppl 17954.4 | wps 44647.9 | wpb 510.9 | bsz 1 | num_updates 21763 | best_loss 8.318
2022-03-07 06:40:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21763 updates
2022-03-07 06:40:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:40:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:40:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 447 @ 21763 updates, score 14.32) (writing took 2.4398129787296057 seconds)
2022-03-07 06:40:39 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-07 06:40:39 | INFO | train | epoch 447 | loss 0.732 | nll_loss 0.183 | ppl 1.14 | wps 24326.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21763 | lr 0.000214358 | gnorm 0.362 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 63489
2022-03-07 06:40:39 | INFO | fairseq.trainer | begin training epoch 448
2022-03-07 06:40:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:42:13 | INFO | train_inner | epoch 448:     37 / 49 loss=0.732, nll_loss=0.183, ppl=1.14, wps=24385.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21800, lr=0.000214176, gnorm=0.365, loss_scale=64, train_wall=227, gb_free=8.8, wall=63583
2022-03-07 06:42:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 06:42:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:42:47 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 14.262 | nll_loss 14.073 | ppl 17236.5 | wps 44610.3 | wpb 510.9 | bsz 1 | num_updates 21811 | best_loss 8.318
2022-03-07 06:42:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21811 updates
2022-03-07 06:42:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:42:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:42:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 448 @ 21811 updates, score 14.262) (writing took 2.4790099002420902 seconds)
2022-03-07 06:42:49 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-07 06:42:49 | INFO | train | epoch 448 | loss 0.731 | nll_loss 0.183 | ppl 1.13 | wps 23865.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21811 | lr 0.000214122 | gnorm 0.368 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 63620
2022-03-07 06:42:49 | INFO | fairseq.trainer | begin training epoch 449
2022-03-07 06:42:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:44:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:44:58 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 14.281 | nll_loss 14.094 | ppl 17485.1 | wps 44695.6 | wpb 510.9 | bsz 1 | num_updates 21860 | best_loss 8.318
2022-03-07 06:44:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21860 updates
2022-03-07 06:44:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:45:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:45:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 449 @ 21860 updates, score 14.281) (writing took 2.431389946490526 seconds)
2022-03-07 06:45:00 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-07 06:45:00 | INFO | train | epoch 449 | loss 0.73 | nll_loss 0.182 | ppl 1.13 | wps 24336.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21860 | lr 0.000213882 | gnorm 0.361 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 63750
2022-03-07 06:45:00 | INFO | fairseq.trainer | begin training epoch 450
2022-03-07 06:45:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:46:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:46:44 | INFO | train_inner | epoch 450:     41 / 49 loss=0.731, nll_loss=0.182, ppl=1.13, wps=23891.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=21900, lr=0.000213687, gnorm=0.364, loss_scale=32, train_wall=232, gb_free=8.8, wall=63855
2022-03-07 06:47:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:47:08 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 14.274 | nll_loss 14.086 | ppl 17391.2 | wps 44232.7 | wpb 510.9 | bsz 1 | num_updates 21908 | best_loss 8.318
2022-03-07 06:47:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21908 updates
2022-03-07 06:47:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:47:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:47:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 450 @ 21908 updates, score 14.274) (writing took 2.465316629037261 seconds)
2022-03-07 06:47:11 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-07 06:47:11 | INFO | train | epoch 450 | loss 0.73 | nll_loss 0.182 | ppl 1.13 | wps 23775.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21908 | lr 0.000213648 | gnorm 0.365 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 63881
2022-03-07 06:47:11 | INFO | fairseq.trainer | begin training epoch 451
2022-03-07 06:47:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:49:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:49:19 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 14.266 | nll_loss 14.078 | ppl 17291.3 | wps 45025.4 | wpb 510.9 | bsz 1 | num_updates 21957 | best_loss 8.318
2022-03-07 06:49:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21957 updates
2022-03-07 06:49:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:49:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:49:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 451 @ 21957 updates, score 14.266) (writing took 2.4330075196921825 seconds)
2022-03-07 06:49:21 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-07 06:49:21 | INFO | train | epoch 451 | loss 0.73 | nll_loss 0.182 | ppl 1.13 | wps 24345.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21957 | lr 0.000213409 | gnorm 0.361 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 64012
2022-03-07 06:49:22 | INFO | fairseq.trainer | begin training epoch 452
2022-03-07 06:49:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:51:11 | INFO | train_inner | epoch 452:     43 / 49 loss=0.73, nll_loss=0.181, ppl=1.13, wps=24345.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.361, loss_scale=32, train_wall=227, gb_free=8.8, wall=64121
2022-03-07 06:51:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:51:30 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 14.277 | nll_loss 14.089 | ppl 17424 | wps 43313.9 | wpb 510.9 | bsz 1 | num_updates 22006 | best_loss 8.318
2022-03-07 06:51:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 22006 updates
2022-03-07 06:51:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:51:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:51:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 452 @ 22006 updates, score 14.277) (writing took 2.4226441234350204 seconds)
2022-03-07 06:51:32 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-07 06:51:32 | INFO | train | epoch 452 | loss 0.73 | nll_loss 0.181 | ppl 1.13 | wps 24283.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 22006 | lr 0.000213172 | gnorm 0.362 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 64143
2022-03-07 06:51:32 | INFO | fairseq.trainer | begin training epoch 453
2022-03-07 06:51:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:53:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:53:40 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 14.284 | nll_loss 14.094 | ppl 17484.2 | wps 44846 | wpb 510.9 | bsz 1 | num_updates 22055 | best_loss 8.318
2022-03-07 06:53:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22055 updates
2022-03-07 06:53:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:53:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:53:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 453 @ 22055 updates, score 14.284) (writing took 2.557939985767007 seconds)
2022-03-07 06:53:43 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-07 06:53:43 | INFO | train | epoch 453 | loss 0.729 | nll_loss 0.181 | ppl 1.13 | wps 24320.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 22055 | lr 0.000212935 | gnorm 0.363 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 64273
2022-03-07 06:53:43 | INFO | fairseq.trainer | begin training epoch 454
2022-03-07 06:53:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:55:37 | INFO | train_inner | epoch 454:     45 / 49 loss=0.729, nll_loss=0.181, ppl=1.13, wps=24331, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.363, loss_scale=64, train_wall=227, gb_free=8.8, wall=64388
2022-03-07 06:55:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:55:51 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 14.358 | nll_loss 14.172 | ppl 18460.4 | wps 44352.5 | wpb 510.9 | bsz 1 | num_updates 22104 | best_loss 8.318
2022-03-07 06:55:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22104 updates
2022-03-07 06:55:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:55:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:55:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 454 @ 22104 updates, score 14.358) (writing took 2.4132486768066883 seconds)
2022-03-07 06:55:54 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-07 06:55:54 | INFO | train | epoch 454 | loss 0.729 | nll_loss 0.181 | ppl 1.13 | wps 24310.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 22104 | lr 0.000212699 | gnorm 0.362 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 64404
2022-03-07 06:55:54 | INFO | fairseq.trainer | begin training epoch 455
2022-03-07 06:55:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:57:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 06:57:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:58:02 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 14.258 | nll_loss 14.068 | ppl 17175.1 | wps 44780.2 | wpb 510.9 | bsz 1 | num_updates 22152 | best_loss 8.318
2022-03-07 06:58:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22152 updates
2022-03-07 06:58:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:58:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:58:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 455 @ 22152 updates, score 14.258) (writing took 2.418850490823388 seconds)
2022-03-07 06:58:04 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-07 06:58:04 | INFO | train | epoch 455 | loss 0.729 | nll_loss 0.181 | ppl 1.13 | wps 23888 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22152 | lr 0.000212468 | gnorm 0.36 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 64534
2022-03-07 06:58:04 | INFO | fairseq.trainer | begin training epoch 456
2022-03-07 06:58:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:00:06 | INFO | train_inner | epoch 456:     48 / 49 loss=0.729, nll_loss=0.181, ppl=1.13, wps=24159.5, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.359, loss_scale=64, train_wall=229, gb_free=8.8, wall=64656
2022-03-07 07:00:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:00:12 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 14.28 | nll_loss 14.091 | ppl 17447.5 | wps 44204.6 | wpb 510.9 | bsz 1 | num_updates 22201 | best_loss 8.318
2022-03-07 07:00:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22201 updates
2022-03-07 07:00:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:00:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:00:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 456 @ 22201 updates, score 14.28) (writing took 2.4979492481797934 seconds)
2022-03-07 07:00:15 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-07 07:00:15 | INFO | train | epoch 456 | loss 0.728 | nll_loss 0.18 | ppl 1.13 | wps 24312.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 22201 | lr 0.000212233 | gnorm 0.358 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 64665
2022-03-07 07:00:15 | INFO | fairseq.trainer | begin training epoch 457
2022-03-07 07:00:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:02:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:02:21 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 14.283 | nll_loss 14.094 | ppl 17481.1 | wps 46567.2 | wpb 510.9 | bsz 1 | num_updates 22250 | best_loss 8.318
2022-03-07 07:02:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22250 updates
2022-03-07 07:02:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:02:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:02:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 457 @ 22250 updates, score 14.283) (writing took 2.539220592007041 seconds)
2022-03-07 07:02:24 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-07 07:02:24 | INFO | train | epoch 457 | loss 0.728 | nll_loss 0.18 | ppl 1.13 | wps 24585.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22250 | lr 0.000212 | gnorm 0.357 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 64794
2022-03-07 07:02:24 | INFO | fairseq.trainer | begin training epoch 458
2022-03-07 07:02:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:03:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 07:04:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:04:30 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 14.284 | nll_loss 14.096 | ppl 17509.3 | wps 44838.2 | wpb 510.9 | bsz 1 | num_updates 22298 | best_loss 8.318
2022-03-07 07:04:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22298 updates
2022-03-07 07:04:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:04:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:04:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 458 @ 22298 updates, score 14.284) (writing took 2.412670463323593 seconds)
2022-03-07 07:04:33 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-07 07:04:33 | INFO | train | epoch 458 | loss 0.728 | nll_loss 0.18 | ppl 1.13 | wps 24174.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22298 | lr 0.000211771 | gnorm 0.363 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 64923
2022-03-07 07:04:33 | INFO | fairseq.trainer | begin training epoch 459
2022-03-07 07:04:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:04:38 | INFO | train_inner | epoch 459:      2 / 49 loss=0.728, nll_loss=0.18, ppl=1.13, wps=23730.7, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=22300, lr=0.000211762, gnorm=0.361, loss_scale=64, train_wall=225, gb_free=8.8, wall=64928
2022-03-07 07:06:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:06:41 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 14.32 | nll_loss 14.134 | ppl 17984.8 | wps 44787.6 | wpb 510.9 | bsz 1 | num_updates 22347 | best_loss 8.318
2022-03-07 07:06:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22347 updates
2022-03-07 07:06:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:06:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:06:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 459 @ 22347 updates, score 14.32) (writing took 2.5018238313496113 seconds)
2022-03-07 07:06:43 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-07 07:06:43 | INFO | train | epoch 459 | loss 0.727 | nll_loss 0.179 | ppl 1.13 | wps 24326.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22347 | lr 0.000211539 | gnorm 0.36 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 65054
2022-03-07 07:06:43 | INFO | fairseq.trainer | begin training epoch 460
2022-03-07 07:06:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:07:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:08:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:08:52 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 14.268 | nll_loss 14.082 | ppl 17340 | wps 44845.8 | wpb 510.9 | bsz 1 | num_updates 22395 | best_loss 8.318
2022-03-07 07:08:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22395 updates
2022-03-07 07:08:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:08:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:08:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 460 @ 22395 updates, score 14.268) (writing took 2.409230088815093 seconds)
2022-03-07 07:08:54 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-07 07:08:54 | INFO | train | epoch 460 | loss 0.726 | nll_loss 0.179 | ppl 1.13 | wps 23842.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22395 | lr 0.000211312 | gnorm 0.353 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 65184
2022-03-07 07:08:54 | INFO | fairseq.trainer | begin training epoch 461
2022-03-07 07:08:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:09:07 | INFO | train_inner | epoch 461:      5 / 49 loss=0.726, nll_loss=0.179, ppl=1.13, wps=24126.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.356, loss_scale=32, train_wall=229, gb_free=8.8, wall=65197
2022-03-07 07:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:11:02 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 14.267 | nll_loss 14.079 | ppl 17307.6 | wps 44953.5 | wpb 510.9 | bsz 1 | num_updates 22444 | best_loss 8.318
2022-03-07 07:11:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22444 updates
2022-03-07 07:11:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:11:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:11:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 461 @ 22444 updates, score 14.267) (writing took 2.546894643455744 seconds)
2022-03-07 07:11:05 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-07 07:11:05 | INFO | train | epoch 461 | loss 0.727 | nll_loss 0.179 | ppl 1.13 | wps 24302.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 22444 | lr 0.000211081 | gnorm 0.361 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 65315
2022-03-07 07:11:05 | INFO | fairseq.trainer | begin training epoch 462
2022-03-07 07:11:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:13:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:13:13 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 14.298 | nll_loss 14.11 | ppl 17683.9 | wps 44711.4 | wpb 510.9 | bsz 1 | num_updates 22493 | best_loss 8.318
2022-03-07 07:13:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22493 updates
2022-03-07 07:13:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:13:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:13:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 462 @ 22493 updates, score 14.298) (writing took 2.3703640829771757 seconds)
2022-03-07 07:13:15 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-07 07:13:15 | INFO | train | epoch 462 | loss 0.726 | nll_loss 0.179 | ppl 1.13 | wps 24348.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22493 | lr 0.000210851 | gnorm 0.357 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 65446
2022-03-07 07:13:15 | INFO | fairseq.trainer | begin training epoch 463
2022-03-07 07:13:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:13:33 | INFO | train_inner | epoch 463:      7 / 49 loss=0.727, nll_loss=0.179, ppl=1.13, wps=24366.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.36, loss_scale=64, train_wall=227, gb_free=8.8, wall=65463
2022-03-07 07:15:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:15:24 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 14.293 | nll_loss 14.106 | ppl 17627.6 | wps 44665.6 | wpb 510.9 | bsz 1 | num_updates 22542 | best_loss 8.318
2022-03-07 07:15:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22542 updates
2022-03-07 07:15:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:15:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:15:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 463 @ 22542 updates, score 14.293) (writing took 2.5225643776357174 seconds)
2022-03-07 07:15:26 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-07 07:15:26 | INFO | train | epoch 463 | loss 0.726 | nll_loss 0.178 | ppl 1.13 | wps 24286.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 22542 | lr 0.000210622 | gnorm 0.359 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 65576
2022-03-07 07:15:26 | INFO | fairseq.trainer | begin training epoch 464
2022-03-07 07:15:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:17:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:17:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:17:34 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 14.249 | nll_loss 14.063 | ppl 17118.4 | wps 43487.3 | wpb 510.9 | bsz 1 | num_updates 22590 | best_loss 8.318
2022-03-07 07:17:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22590 updates
2022-03-07 07:17:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:17:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:17:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 464 @ 22590 updates, score 14.249) (writing took 2.4336904119700193 seconds)
2022-03-07 07:17:37 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-07 07:17:37 | INFO | train | epoch 464 | loss 0.725 | nll_loss 0.178 | ppl 1.13 | wps 23830.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22590 | lr 0.000210398 | gnorm 0.358 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 65707
2022-03-07 07:17:37 | INFO | fairseq.trainer | begin training epoch 465
2022-03-07 07:17:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:18:02 | INFO | train_inner | epoch 465:     10 / 49 loss=0.725, nll_loss=0.178, ppl=1.13, wps=24106.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.358, loss_scale=32, train_wall=229, gb_free=8.8, wall=65732
2022-03-07 07:19:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:19:45 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 14.337 | nll_loss 14.15 | ppl 18178.7 | wps 44951.4 | wpb 510.9 | bsz 1 | num_updates 22639 | best_loss 8.318
2022-03-07 07:19:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22639 updates
2022-03-07 07:19:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:19:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:19:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 465 @ 22639 updates, score 14.337) (writing took 2.468648362904787 seconds)
2022-03-07 07:19:47 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-07 07:19:47 | INFO | train | epoch 465 | loss 0.724 | nll_loss 0.177 | ppl 1.13 | wps 24327.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22639 | lr 0.00021017 | gnorm 0.357 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 65838
2022-03-07 07:19:47 | INFO | fairseq.trainer | begin training epoch 466
2022-03-07 07:19:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:21:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:21:55 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 14.36 | nll_loss 14.174 | ppl 18490.5 | wps 44625.2 | wpb 510.9 | bsz 1 | num_updates 22688 | best_loss 8.318
2022-03-07 07:21:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22688 updates
2022-03-07 07:21:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:21:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:21:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 466 @ 22688 updates, score 14.36) (writing took 2.5463883094489574 seconds)
2022-03-07 07:21:58 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-07 07:21:58 | INFO | train | epoch 466 | loss 0.724 | nll_loss 0.177 | ppl 1.13 | wps 24354.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22688 | lr 0.000209943 | gnorm 0.356 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 65968
2022-03-07 07:21:58 | INFO | fairseq.trainer | begin training epoch 467
2022-03-07 07:21:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:22:29 | INFO | train_inner | epoch 467:     12 / 49 loss=0.724, nll_loss=0.177, ppl=1.13, wps=24359.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.356, loss_scale=32, train_wall=227, gb_free=8.8, wall=65999
2022-03-07 07:24:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:24:06 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 14.384 | nll_loss 14.199 | ppl 18806.1 | wps 45688.1 | wpb 510.9 | bsz 1 | num_updates 22737 | best_loss 8.318
2022-03-07 07:24:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22737 updates
2022-03-07 07:24:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:24:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:24:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 467 @ 22737 updates, score 14.384) (writing took 2.422985365614295 seconds)
2022-03-07 07:24:08 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-07 07:24:08 | INFO | train | epoch 467 | loss 0.724 | nll_loss 0.177 | ppl 1.13 | wps 24358.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22737 | lr 0.000209717 | gnorm 0.357 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 66099
2022-03-07 07:24:08 | INFO | fairseq.trainer | begin training epoch 468
2022-03-07 07:24:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:26:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:26:16 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 14.233 | nll_loss 14.043 | ppl 16883.9 | wps 45193.9 | wpb 510.9 | bsz 1 | num_updates 22786 | best_loss 8.318
2022-03-07 07:26:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22786 updates
2022-03-07 07:26:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:26:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:26:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 468 @ 22786 updates, score 14.233) (writing took 2.561536779627204 seconds)
2022-03-07 07:26:19 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-07 07:26:19 | INFO | train | epoch 468 | loss 0.724 | nll_loss 0.177 | ppl 1.13 | wps 24327.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22786 | lr 0.000209491 | gnorm 0.358 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 66229
2022-03-07 07:26:19 | INFO | fairseq.trainer | begin training epoch 469
2022-03-07 07:26:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:26:55 | INFO | train_inner | epoch 469:     14 / 49 loss=0.724, nll_loss=0.177, ppl=1.13, wps=24371.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.357, loss_scale=64, train_wall=227, gb_free=8.8, wall=66265
2022-03-07 07:28:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 07:28:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:28:27 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 14.293 | nll_loss 14.106 | ppl 17638.8 | wps 44074.4 | wpb 510.9 | bsz 1 | num_updates 22834 | best_loss 8.318
2022-03-07 07:28:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22834 updates
2022-03-07 07:28:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:28:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:28:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 469 @ 22834 updates, score 14.293) (writing took 2.438821766525507 seconds)
2022-03-07 07:28:30 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-07 07:28:30 | INFO | train | epoch 469 | loss 0.723 | nll_loss 0.176 | ppl 1.13 | wps 24067.5 | ups 0.37 | wpb 65526.8 | bsz 128 | num_updates 22834 | lr 0.000209271 | gnorm 0.353 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 66360
2022-03-07 07:28:30 | INFO | fairseq.trainer | begin training epoch 470
2022-03-07 07:28:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:28:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:30:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:30:38 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 14.243 | nll_loss 14.054 | ppl 17009.5 | wps 44976 | wpb 510.9 | bsz 1 | num_updates 22882 | best_loss 8.318
2022-03-07 07:30:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22882 updates
2022-03-07 07:30:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:30:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:30:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 470 @ 22882 updates, score 14.243) (writing took 2.4143824372440577 seconds)
2022-03-07 07:30:40 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-07 07:30:40 | INFO | train | epoch 470 | loss 0.722 | nll_loss 0.175 | ppl 1.13 | wps 23824 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22882 | lr 0.000209051 | gnorm 0.358 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 66491
2022-03-07 07:30:40 | INFO | fairseq.trainer | begin training epoch 471
2022-03-07 07:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:31:26 | INFO | train_inner | epoch 471:     18 / 49 loss=0.722, nll_loss=0.176, ppl=1.13, wps=24029.5, ups=0.37, wpb=65199.5, bsz=127.4, num_updates=22900, lr=0.000208969, gnorm=0.355, loss_scale=32, train_wall=232, gb_free=8.8, wall=66536
2022-03-07 07:32:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:32:48 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 14.229 | nll_loss 14.042 | ppl 16871.4 | wps 44740.3 | wpb 510.9 | bsz 1 | num_updates 22931 | best_loss 8.318
2022-03-07 07:32:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22931 updates
2022-03-07 07:32:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:32:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:32:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 471 @ 22931 updates, score 14.229) (writing took 2.4650899581611156 seconds)
2022-03-07 07:32:51 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-07 07:32:51 | INFO | train | epoch 471 | loss 0.723 | nll_loss 0.176 | ppl 1.13 | wps 24365.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22931 | lr 0.000208828 | gnorm 0.357 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 66621
2022-03-07 07:32:51 | INFO | fairseq.trainer | begin training epoch 472
2022-03-07 07:32:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:34:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:34:59 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 14.248 | nll_loss 14.061 | ppl 17096 | wps 45180.7 | wpb 510.9 | bsz 1 | num_updates 22980 | best_loss 8.318
2022-03-07 07:34:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22980 updates
2022-03-07 07:34:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:35:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:35:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 472 @ 22980 updates, score 14.248) (writing took 2.5276739969849586 seconds)
2022-03-07 07:35:01 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-07 07:35:01 | INFO | train | epoch 472 | loss 0.722 | nll_loss 0.176 | ppl 1.13 | wps 24320.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 22980 | lr 0.000208605 | gnorm 0.355 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 66752
2022-03-07 07:35:01 | INFO | fairseq.trainer | begin training epoch 473
2022-03-07 07:35:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:35:52 | INFO | train_inner | epoch 473:     20 / 49 loss=0.723, nll_loss=0.176, ppl=1.13, wps=24357.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.356, loss_scale=64, train_wall=227, gb_free=8.8, wall=66803
2022-03-07 07:37:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:37:10 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 14.229 | nll_loss 14.04 | ppl 16844.2 | wps 43340 | wpb 510.9 | bsz 1 | num_updates 23029 | best_loss 8.318
2022-03-07 07:37:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23029 updates
2022-03-07 07:37:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:37:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:37:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 473 @ 23029 updates, score 14.229) (writing took 2.4513980727642775 seconds)
2022-03-07 07:37:12 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-07 07:37:12 | INFO | train | epoch 473 | loss 0.723 | nll_loss 0.176 | ppl 1.13 | wps 24276.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23029 | lr 0.000208383 | gnorm 0.352 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 66883
2022-03-07 07:37:12 | INFO | fairseq.trainer | begin training epoch 474
2022-03-07 07:37:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:39:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:39:21 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 14.32 | nll_loss 14.134 | ppl 17982.8 | wps 44625.5 | wpb 510.9 | bsz 1 | num_updates 23078 | best_loss 8.318
2022-03-07 07:39:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23078 updates
2022-03-07 07:39:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:39:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:39:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 474 @ 23078 updates, score 14.32) (writing took 2.4139922820031643 seconds)
2022-03-07 07:39:23 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-07 07:39:23 | INFO | train | epoch 474 | loss 0.722 | nll_loss 0.175 | ppl 1.13 | wps 24277.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23078 | lr 0.000208162 | gnorm 0.352 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 67014
2022-03-07 07:39:23 | INFO | fairseq.trainer | begin training epoch 475
2022-03-07 07:39:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:40:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 07:40:22 | INFO | train_inner | epoch 475:     23 / 49 loss=0.722, nll_loss=0.175, ppl=1.13, wps=24089.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.352, loss_scale=64, train_wall=230, gb_free=8.8, wall=67072
2022-03-07 07:41:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:41:31 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 14.287 | nll_loss 14.1 | ppl 17564.6 | wps 44261 | wpb 510.9 | bsz 1 | num_updates 23126 | best_loss 8.318
2022-03-07 07:41:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23126 updates
2022-03-07 07:41:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:41:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:41:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 475 @ 23126 updates, score 14.287) (writing took 2.4178392458707094 seconds)
2022-03-07 07:41:34 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-07 07:41:34 | INFO | train | epoch 475 | loss 0.722 | nll_loss 0.175 | ppl 1.13 | wps 23862.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 23126 | lr 0.000207946 | gnorm 0.353 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 67144
2022-03-07 07:41:34 | INFO | fairseq.trainer | begin training epoch 476
2022-03-07 07:41:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:43:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:43:42 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 14.272 | nll_loss 14.083 | ppl 17358.5 | wps 45437.4 | wpb 510.9 | bsz 1 | num_updates 23175 | best_loss 8.318
2022-03-07 07:43:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23175 updates
2022-03-07 07:43:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:43:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:43:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 476 @ 23175 updates, score 14.272) (writing took 2.4941591192036867 seconds)
2022-03-07 07:43:44 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-07 07:43:44 | INFO | train | epoch 476 | loss 0.721 | nll_loss 0.175 | ppl 1.13 | wps 24351.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23175 | lr 0.000207726 | gnorm 0.353 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 67274
2022-03-07 07:43:44 | INFO | fairseq.trainer | begin training epoch 477
2022-03-07 07:43:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:44:48 | INFO | train_inner | epoch 477:     25 / 49 loss=0.721, nll_loss=0.175, ppl=1.13, wps=24368.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.353, loss_scale=64, train_wall=227, gb_free=8.8, wall=67338
2022-03-07 07:45:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 07:45:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:45:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:45:52 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 14.268 | nll_loss 14.082 | ppl 17339.9 | wps 45113.8 | wpb 510.9 | bsz 1 | num_updates 23222 | best_loss 8.318
2022-03-07 07:45:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23222 updates
2022-03-07 07:45:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:45:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:45:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 477 @ 23222 updates, score 14.268) (writing took 2.42939112521708 seconds)
2022-03-07 07:45:55 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-07 07:45:55 | INFO | train | epoch 477 | loss 0.721 | nll_loss 0.174 | ppl 1.13 | wps 23348.7 | ups 0.36 | wpb 64829.4 | bsz 126.6 | num_updates 23222 | lr 0.000207515 | gnorm 0.352 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 67405
2022-03-07 07:45:55 | INFO | fairseq.trainer | begin training epoch 478
2022-03-07 07:45:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:47:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:48:03 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 14.295 | nll_loss 14.109 | ppl 17664 | wps 44973.2 | wpb 510.9 | bsz 1 | num_updates 23271 | best_loss 8.318
2022-03-07 07:48:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23271 updates
2022-03-07 07:48:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:48:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:48:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 478 @ 23271 updates, score 14.295) (writing took 2.4291528053581715 seconds)
2022-03-07 07:48:05 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-07 07:48:05 | INFO | train | epoch 478 | loss 0.72 | nll_loss 0.174 | ppl 1.13 | wps 24334.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23271 | lr 0.000207297 | gnorm 0.35 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 67536
2022-03-07 07:48:05 | INFO | fairseq.trainer | begin training epoch 479
2022-03-07 07:48:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:49:19 | INFO | train_inner | epoch 479:     29 / 49 loss=0.72, nll_loss=0.174, ppl=1.13, wps=23926.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.35, loss_scale=32, train_wall=232, gb_free=8.8, wall=67609
2022-03-07 07:50:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:50:14 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 14.334 | nll_loss 14.147 | ppl 18141.2 | wps 44430 | wpb 510.9 | bsz 1 | num_updates 23320 | best_loss 8.318
2022-03-07 07:50:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23320 updates
2022-03-07 07:50:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:50:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:50:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 479 @ 23320 updates, score 14.334) (writing took 2.420669751241803 seconds)
2022-03-07 07:50:16 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-07 07:50:16 | INFO | train | epoch 479 | loss 0.72 | nll_loss 0.174 | ppl 1.13 | wps 24322.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23320 | lr 0.000207079 | gnorm 0.35 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 67666
2022-03-07 07:50:16 | INFO | fairseq.trainer | begin training epoch 480
2022-03-07 07:50:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:52:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:52:24 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 14.386 | nll_loss 14.203 | ppl 18864.3 | wps 44886.3 | wpb 510.9 | bsz 1 | num_updates 23369 | best_loss 8.318
2022-03-07 07:52:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23369 updates
2022-03-07 07:52:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:52:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:52:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 480 @ 23369 updates, score 14.386) (writing took 2.3952529057860374 seconds)
2022-03-07 07:52:27 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-07 07:52:27 | INFO | train | epoch 480 | loss 0.72 | nll_loss 0.174 | ppl 1.13 | wps 24321.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23369 | lr 0.000206862 | gnorm 0.351 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 67797
2022-03-07 07:52:27 | INFO | fairseq.trainer | begin training epoch 481
2022-03-07 07:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:53:45 | INFO | train_inner | epoch 481:     31 / 49 loss=0.719, nll_loss=0.173, ppl=1.13, wps=24345.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.35, loss_scale=64, train_wall=227, gb_free=8.8, wall=67876
2022-03-07 07:54:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:54:35 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 14.33 | nll_loss 14.146 | ppl 18123.5 | wps 44487.2 | wpb 510.9 | bsz 1 | num_updates 23418 | best_loss 8.318
2022-03-07 07:54:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23418 updates
2022-03-07 07:54:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:54:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:54:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 481 @ 23418 updates, score 14.33) (writing took 2.4743315875530243 seconds)
2022-03-07 07:54:37 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-07 07:54:37 | INFO | train | epoch 481 | loss 0.719 | nll_loss 0.173 | ppl 1.13 | wps 24290.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23418 | lr 0.000206645 | gnorm 0.353 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 67928
2022-03-07 07:54:37 | INFO | fairseq.trainer | begin training epoch 482
2022-03-07 07:54:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:56:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:56:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:56:46 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 14.271 | nll_loss 14.083 | ppl 17359.8 | wps 44692.4 | wpb 510.9 | bsz 1 | num_updates 23466 | best_loss 8.318
2022-03-07 07:56:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23466 updates
2022-03-07 07:56:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:56:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:56:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 482 @ 23466 updates, score 14.271) (writing took 2.456583170220256 seconds)
2022-03-07 07:56:48 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-07 07:56:48 | INFO | train | epoch 482 | loss 0.719 | nll_loss 0.173 | ppl 1.13 | wps 23807.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 23466 | lr 0.000206434 | gnorm 0.355 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 68058
2022-03-07 07:56:48 | INFO | fairseq.trainer | begin training epoch 483
2022-03-07 07:56:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:58:15 | INFO | train_inner | epoch 483:     34 / 49 loss=0.719, nll_loss=0.173, ppl=1.13, wps=24097.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.354, loss_scale=32, train_wall=230, gb_free=8.8, wall=68145
2022-03-07 07:58:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:58:56 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 14.27 | nll_loss 14.083 | ppl 17358.6 | wps 44324.9 | wpb 510.9 | bsz 1 | num_updates 23515 | best_loss 8.318
2022-03-07 07:58:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23515 updates
2022-03-07 07:58:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:58:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:58:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 483 @ 23515 updates, score 14.27) (writing took 2.419875418767333 seconds)
2022-03-07 07:58:59 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-07 07:58:59 | INFO | train | epoch 483 | loss 0.718 | nll_loss 0.172 | ppl 1.13 | wps 24311.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23515 | lr 0.000206218 | gnorm 0.348 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 68189
2022-03-07 07:58:59 | INFO | fairseq.trainer | begin training epoch 484
2022-03-07 07:58:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:01:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:01:07 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 14.281 | nll_loss 14.095 | ppl 17502.9 | wps 44560.7 | wpb 510.9 | bsz 1 | num_updates 23564 | best_loss 8.318
2022-03-07 08:01:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23564 updates
2022-03-07 08:01:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:01:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:01:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 484 @ 23564 updates, score 14.281) (writing took 2.3998026084154844 seconds)
2022-03-07 08:01:09 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-07 08:01:09 | INFO | train | epoch 484 | loss 0.718 | nll_loss 0.172 | ppl 1.13 | wps 24337.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23564 | lr 0.000206004 | gnorm 0.349 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 68320
2022-03-07 08:01:09 | INFO | fairseq.trainer | begin training epoch 485
2022-03-07 08:01:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:02:41 | INFO | train_inner | epoch 485:     36 / 49 loss=0.718, nll_loss=0.172, ppl=1.13, wps=24341.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23600, lr=0.000205847, gnorm=0.349, loss_scale=64, train_wall=227, gb_free=8.8, wall=68411
2022-03-07 08:03:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:03:18 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 14.317 | nll_loss 14.131 | ppl 17936.7 | wps 44804.2 | wpb 510.9 | bsz 1 | num_updates 23613 | best_loss 8.318
2022-03-07 08:03:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23613 updates
2022-03-07 08:03:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:03:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:03:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 485 @ 23613 updates, score 14.317) (writing took 2.3993650283664465 seconds)
2022-03-07 08:03:20 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-07 08:03:20 | INFO | train | epoch 485 | loss 0.718 | nll_loss 0.173 | ppl 1.13 | wps 24296.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23613 | lr 0.00020579 | gnorm 0.351 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 68451
2022-03-07 08:03:20 | INFO | fairseq.trainer | begin training epoch 486
2022-03-07 08:03:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:05:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:05:28 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 14.266 | nll_loss 14.081 | ppl 17326.9 | wps 44409.2 | wpb 510.9 | bsz 1 | num_updates 23662 | best_loss 8.318
2022-03-07 08:05:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23662 updates
2022-03-07 08:05:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:05:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:05:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 486 @ 23662 updates, score 14.266) (writing took 2.558433039113879 seconds)
2022-03-07 08:05:31 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-07 08:05:31 | INFO | train | epoch 486 | loss 0.718 | nll_loss 0.172 | ppl 1.13 | wps 24312 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23662 | lr 0.000205577 | gnorm 0.351 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 68581
2022-03-07 08:05:31 | INFO | fairseq.trainer | begin training epoch 487
2022-03-07 08:05:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:07:08 | INFO | train_inner | epoch 487:     38 / 49 loss=0.718, nll_loss=0.172, ppl=1.13, wps=24341.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=23700, lr=0.000205412, gnorm=0.348, loss_scale=64, train_wall=227, gb_free=8.8, wall=68678
2022-03-07 08:07:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:07:39 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 14.274 | nll_loss 14.088 | ppl 17419.8 | wps 44741.2 | wpb 510.9 | bsz 1 | num_updates 23711 | best_loss 8.318
2022-03-07 08:07:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23711 updates
2022-03-07 08:07:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:07:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:07:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 487 @ 23711 updates, score 14.274) (writing took 2.41057994030416 seconds)
2022-03-07 08:07:42 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-07 08:07:42 | INFO | train | epoch 487 | loss 0.717 | nll_loss 0.172 | ppl 1.13 | wps 24321.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23711 | lr 0.000205364 | gnorm 0.346 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 68712
2022-03-07 08:07:42 | INFO | fairseq.trainer | begin training epoch 488
2022-03-07 08:07:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:08:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 08:09:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:09:50 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 14.278 | nll_loss 14.092 | ppl 17460.8 | wps 44462.2 | wpb 510.9 | bsz 1 | num_updates 23759 | best_loss 8.318
2022-03-07 08:09:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23759 updates
2022-03-07 08:09:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:09:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:09:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 488 @ 23759 updates, score 14.278) (writing took 2.417800499126315 seconds)
2022-03-07 08:09:52 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-07 08:09:52 | INFO | train | epoch 488 | loss 0.717 | nll_loss 0.172 | ppl 1.13 | wps 23855.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 23759 | lr 0.000205157 | gnorm 0.351 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 68842
2022-03-07 08:09:52 | INFO | fairseq.trainer | begin training epoch 489
2022-03-07 08:09:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:11:36 | INFO | train_inner | epoch 489:     41 / 49 loss=0.717, nll_loss=0.172, ppl=1.13, wps=24139.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.35, loss_scale=64, train_wall=229, gb_free=8.8, wall=68947
2022-03-07 08:11:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:12:00 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 14.278 | nll_loss 14.09 | ppl 17441.8 | wps 44951 | wpb 510.9 | bsz 1 | num_updates 23808 | best_loss 8.318
2022-03-07 08:12:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23808 updates
2022-03-07 08:12:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:12:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:12:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 489 @ 23808 updates, score 14.278) (writing took 2.386671667918563 seconds)
2022-03-07 08:12:03 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-07 08:12:03 | INFO | train | epoch 489 | loss 0.717 | nll_loss 0.172 | ppl 1.13 | wps 24349.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23808 | lr 0.000204946 | gnorm 0.348 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 68973
2022-03-07 08:12:03 | INFO | fairseq.trainer | begin training epoch 490
2022-03-07 08:12:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:13:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 08:14:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:14:11 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 14.23 | nll_loss 14.042 | ppl 16872 | wps 44732.5 | wpb 510.9 | bsz 1 | num_updates 23856 | best_loss 8.318
2022-03-07 08:14:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23856 updates
2022-03-07 08:14:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:14:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:14:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 490 @ 23856 updates, score 14.23) (writing took 2.4582363720983267 seconds)
2022-03-07 08:14:13 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-07 08:14:13 | INFO | train | epoch 490 | loss 0.716 | nll_loss 0.17 | ppl 1.13 | wps 23826.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 23856 | lr 0.000204739 | gnorm 0.346 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 69104
2022-03-07 08:14:13 | INFO | fairseq.trainer | begin training epoch 491
2022-03-07 08:14:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:16:05 | INFO | train_inner | epoch 491:     44 / 49 loss=0.716, nll_loss=0.171, ppl=1.13, wps=24139.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.347, loss_scale=64, train_wall=229, gb_free=8.8, wall=69215
2022-03-07 08:16:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:16:21 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 14.296 | nll_loss 14.108 | ppl 17660.9 | wps 44935 | wpb 510.9 | bsz 1 | num_updates 23905 | best_loss 8.318
2022-03-07 08:16:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23905 updates
2022-03-07 08:16:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:16:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:16:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 491 @ 23905 updates, score 14.296) (writing took 2.4478760045021772 seconds)
2022-03-07 08:16:24 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-07 08:16:24 | INFO | train | epoch 491 | loss 0.716 | nll_loss 0.171 | ppl 1.13 | wps 24332.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23905 | lr 0.000204529 | gnorm 0.349 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 69234
2022-03-07 08:16:24 | INFO | fairseq.trainer | begin training epoch 492
2022-03-07 08:16:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:18:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:18:32 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 14.362 | nll_loss 14.178 | ppl 18541.2 | wps 44155.1 | wpb 510.9 | bsz 1 | num_updates 23954 | best_loss 8.318
2022-03-07 08:18:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23954 updates
2022-03-07 08:18:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:18:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:18:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 492 @ 23954 updates, score 14.362) (writing took 2.4165277648717165 seconds)
2022-03-07 08:18:35 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-07 08:18:35 | INFO | train | epoch 492 | loss 0.716 | nll_loss 0.171 | ppl 1.13 | wps 24300.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23954 | lr 0.00020432 | gnorm 0.352 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 69365
2022-03-07 08:18:35 | INFO | fairseq.trainer | begin training epoch 493
2022-03-07 08:18:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:19:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 08:20:34 | INFO | train_inner | epoch 493:     47 / 49 loss=0.716, nll_loss=0.171, ppl=1.13, wps=24094.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.35, loss_scale=64, train_wall=230, gb_free=8.8, wall=69485
2022-03-07 08:20:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:20:43 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 14.299 | nll_loss 14.114 | ppl 17726.4 | wps 44373.9 | wpb 510.9 | bsz 1 | num_updates 24002 | best_loss 8.318
2022-03-07 08:20:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 24002 updates
2022-03-07 08:20:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:20:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:20:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 493 @ 24002 updates, score 14.299) (writing took 2.413631921634078 seconds)
2022-03-07 08:20:46 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-07 08:20:46 | INFO | train | epoch 493 | loss 0.715 | nll_loss 0.17 | ppl 1.13 | wps 23778.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24002 | lr 0.000204116 | gnorm 0.347 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 69496
2022-03-07 08:20:46 | INFO | fairseq.trainer | begin training epoch 494
2022-03-07 08:20:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:22:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:22:54 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 14.268 | nll_loss 14.083 | ppl 17355.9 | wps 44995.8 | wpb 510.9 | bsz 1 | num_updates 24051 | best_loss 8.318
2022-03-07 08:22:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24051 updates
2022-03-07 08:22:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:22:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:22:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 494 @ 24051 updates, score 14.268) (writing took 2.463775409385562 seconds)
2022-03-07 08:22:56 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-07 08:22:56 | INFO | train | epoch 494 | loss 0.715 | nll_loss 0.17 | ppl 1.13 | wps 24340.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24051 | lr 0.000203908 | gnorm 0.344 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 69626
2022-03-07 08:22:56 | INFO | fairseq.trainer | begin training epoch 495
2022-03-07 08:22:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:25:00 | INFO | train_inner | epoch 495:     49 / 49 loss=0.714, nll_loss=0.17, ppl=1.12, wps=24342.5, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=24100, lr=0.0002037, gnorm=0.347, loss_scale=64, train_wall=226, gb_free=8.8, wall=69750
2022-03-07 08:25:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:25:04 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 14.309 | nll_loss 14.124 | ppl 17855.4 | wps 44697.9 | wpb 510.9 | bsz 1 | num_updates 24100 | best_loss 8.318
2022-03-07 08:25:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24100 updates
2022-03-07 08:25:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:25:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:25:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 495 @ 24100 updates, score 14.309) (writing took 2.41108625382185 seconds)
2022-03-07 08:25:07 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-07 08:25:07 | INFO | train | epoch 495 | loss 0.714 | nll_loss 0.169 | ppl 1.12 | wps 24311.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24100 | lr 0.0002037 | gnorm 0.347 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 69757
2022-03-07 08:25:07 | INFO | fairseq.trainer | begin training epoch 496
2022-03-07 08:25:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:25:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 08:27:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:27:15 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 14.312 | nll_loss 14.128 | ppl 17901.6 | wps 44172.6 | wpb 510.9 | bsz 1 | num_updates 24148 | best_loss 8.318
2022-03-07 08:27:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24148 updates
2022-03-07 08:27:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:27:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:27:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 496 @ 24148 updates, score 14.312) (writing took 2.4296874068677425 seconds)
2022-03-07 08:27:18 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-07 08:27:18 | INFO | train | epoch 496 | loss 0.714 | nll_loss 0.169 | ppl 1.12 | wps 23825.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24148 | lr 0.000203498 | gnorm 0.345 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 69888
2022-03-07 08:27:18 | INFO | fairseq.trainer | begin training epoch 497
2022-03-07 08:27:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:29:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:29:26 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 14.27 | nll_loss 14.084 | ppl 17367.8 | wps 44861.9 | wpb 510.9 | bsz 1 | num_updates 24197 | best_loss 8.318
2022-03-07 08:29:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24197 updates
2022-03-07 08:29:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:29:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:29:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 497 @ 24197 updates, score 14.27) (writing took 2.4272884223610163 seconds)
2022-03-07 08:29:28 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-07 08:29:28 | INFO | train | epoch 497 | loss 0.714 | nll_loss 0.169 | ppl 1.12 | wps 24323.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24197 | lr 0.000203292 | gnorm 0.348 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 70018
2022-03-07 08:29:28 | INFO | fairseq.trainer | begin training epoch 498
2022-03-07 08:29:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:29:36 | INFO | train_inner | epoch 498:      3 / 49 loss=0.714, nll_loss=0.169, ppl=1.12, wps=23470.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.346, loss_scale=64, train_wall=230, gb_free=8.8, wall=70026
2022-03-07 08:30:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 08:31:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:31:36 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 14.371 | nll_loss 14.186 | ppl 18643.8 | wps 45038.9 | wpb 510.9 | bsz 1 | num_updates 24245 | best_loss 8.318
2022-03-07 08:31:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24245 updates
2022-03-07 08:31:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:31:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:31:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 498 @ 24245 updates, score 14.371) (writing took 2.4189650155603886 seconds)
2022-03-07 08:31:39 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-07 08:31:39 | INFO | train | epoch 498 | loss 0.714 | nll_loss 0.169 | ppl 1.12 | wps 23851.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24245 | lr 0.00020309 | gnorm 0.348 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 70149
2022-03-07 08:31:39 | INFO | fairseq.trainer | begin training epoch 499
2022-03-07 08:31:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:33:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:33:47 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 14.256 | nll_loss 14.068 | ppl 17176 | wps 44367.8 | wpb 510.9 | bsz 1 | num_updates 24294 | best_loss 8.318
2022-03-07 08:33:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24294 updates
2022-03-07 08:33:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:33:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:33:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 499 @ 24294 updates, score 14.256) (writing took 2.4540040381252766 seconds)
2022-03-07 08:33:49 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-07 08:33:49 | INFO | train | epoch 499 | loss 0.713 | nll_loss 0.169 | ppl 1.12 | wps 24312.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24294 | lr 0.000202885 | gnorm 0.345 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 70280
2022-03-07 08:33:49 | INFO | fairseq.trainer | begin training epoch 500
2022-03-07 08:33:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:34:05 | INFO | train_inner | epoch 500:      6 / 49 loss=0.713, nll_loss=0.169, ppl=1.12, wps=24138.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.347, loss_scale=64, train_wall=229, gb_free=8.8, wall=70295
2022-03-07 08:35:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:35:58 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 14.273 | nll_loss 14.088 | ppl 17410.6 | wps 44431.6 | wpb 510.9 | bsz 1 | num_updates 24343 | best_loss 8.318
2022-03-07 08:35:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24343 updates
2022-03-07 08:35:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:36:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:36:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 500 @ 24343 updates, score 14.273) (writing took 2.4107322432100773 seconds)
2022-03-07 08:36:00 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-07 08:36:00 | INFO | train | epoch 500 | loss 0.713 | nll_loss 0.168 | ppl 1.12 | wps 24283.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24343 | lr 0.000202681 | gnorm 0.344 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 70411
2022-03-07 08:36:00 | INFO | fairseq.trainer | begin training epoch 501
2022-03-07 08:36:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:36:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 08:38:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:38:09 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 14.245 | nll_loss 14.059 | ppl 17065.7 | wps 44568.6 | wpb 510.9 | bsz 1 | num_updates 24391 | best_loss 8.318
2022-03-07 08:38:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24391 updates
2022-03-07 08:38:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:38:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:38:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 501 @ 24391 updates, score 14.245) (writing took 2.460551343858242 seconds)
2022-03-07 08:38:11 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-07 08:38:11 | INFO | train | epoch 501 | loss 0.713 | nll_loss 0.169 | ppl 1.12 | wps 23809 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24391 | lr 0.000202481 | gnorm 0.347 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 70541
2022-03-07 08:38:11 | INFO | fairseq.trainer | begin training epoch 502
2022-03-07 08:38:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:38:34 | INFO | train_inner | epoch 502:      9 / 49 loss=0.713, nll_loss=0.169, ppl=1.12, wps=24090.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.345, loss_scale=64, train_wall=230, gb_free=8.8, wall=70564
2022-03-07 08:40:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:40:20 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 14.275 | nll_loss 14.089 | ppl 17431.1 | wps 44710.9 | wpb 510.9 | bsz 1 | num_updates 24440 | best_loss 8.318
2022-03-07 08:40:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24440 updates
2022-03-07 08:40:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:40:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:40:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 502 @ 24440 updates, score 14.275) (writing took 2.3922272883355618 seconds)
2022-03-07 08:40:22 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-07 08:40:22 | INFO | train | epoch 502 | loss 0.711 | nll_loss 0.167 | ppl 1.12 | wps 24244.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24440 | lr 0.000202278 | gnorm 0.342 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 70672
2022-03-07 08:40:22 | INFO | fairseq.trainer | begin training epoch 503
2022-03-07 08:40:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:41:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:42:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:42:30 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 14.231 | nll_loss 14.045 | ppl 16901.3 | wps 44747.8 | wpb 510.9 | bsz 1 | num_updates 24488 | best_loss 8.318
2022-03-07 08:42:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24488 updates
2022-03-07 08:42:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:42:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:42:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 503 @ 24488 updates, score 14.231) (writing took 2.621588882058859 seconds)
2022-03-07 08:42:33 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-07 08:42:33 | INFO | train | epoch 503 | loss 0.712 | nll_loss 0.168 | ppl 1.12 | wps 23820.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24488 | lr 0.00020208 | gnorm 0.348 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 70803
2022-03-07 08:42:33 | INFO | fairseq.trainer | begin training epoch 504
2022-03-07 08:42:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:43:03 | INFO | train_inner | epoch 504:     12 / 49 loss=0.712, nll_loss=0.168, ppl=1.12, wps=24076.7, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.344, loss_scale=32, train_wall=230, gb_free=8.8, wall=70834
2022-03-07 08:44:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:44:43 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 14.141 | nll_loss 13.952 | ppl 15852.1 | wps 43418.8 | wpb 510.9 | bsz 1 | num_updates 24537 | best_loss 8.318
2022-03-07 08:44:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24537 updates
2022-03-07 08:44:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:44:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:44:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 504 @ 24537 updates, score 14.141) (writing took 2.583187522366643 seconds)
2022-03-07 08:44:45 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-07 08:44:45 | INFO | train | epoch 504 | loss 0.712 | nll_loss 0.168 | ppl 1.12 | wps 23943.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24537 | lr 0.000201878 | gnorm 0.343 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 70936
2022-03-07 08:44:45 | INFO | fairseq.trainer | begin training epoch 505
2022-03-07 08:44:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:46:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:46:56 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 14.276 | nll_loss 14.09 | ppl 17436.1 | wps 42922.7 | wpb 510.9 | bsz 1 | num_updates 24586 | best_loss 8.318
2022-03-07 08:46:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24586 updates
2022-03-07 08:46:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:46:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:46:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 505 @ 24586 updates, score 14.276) (writing took 2.4161494225263596 seconds)
2022-03-07 08:46:59 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-07 08:46:59 | INFO | train | epoch 505 | loss 0.711 | nll_loss 0.167 | ppl 1.12 | wps 23863.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24586 | lr 0.000201677 | gnorm 0.342 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 71069
2022-03-07 08:46:59 | INFO | fairseq.trainer | begin training epoch 506
2022-03-07 08:46:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:47:35 | INFO | train_inner | epoch 506:     14 / 49 loss=0.711, nll_loss=0.167, ppl=1.12, wps=23888.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.342, loss_scale=64, train_wall=232, gb_free=8.8, wall=71105
2022-03-07 08:49:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:49:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:49:08 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 14.288 | nll_loss 14.103 | ppl 17596.2 | wps 44121.8 | wpb 510.9 | bsz 1 | num_updates 24634 | best_loss 8.318
2022-03-07 08:49:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24634 updates
2022-03-07 08:49:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:49:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:49:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 506 @ 24634 updates, score 14.288) (writing took 2.4337611366063356 seconds)
2022-03-07 08:49:10 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-07 08:49:10 | INFO | train | epoch 506 | loss 0.711 | nll_loss 0.167 | ppl 1.12 | wps 23681.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24634 | lr 0.00020148 | gnorm 0.34 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 71200
2022-03-07 08:49:10 | INFO | fairseq.trainer | begin training epoch 507
2022-03-07 08:49:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:51:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:51:18 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 14.197 | nll_loss 14.01 | ppl 16493.4 | wps 44675 | wpb 510.9 | bsz 1 | num_updates 24683 | best_loss 8.318
2022-03-07 08:51:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24683 updates
2022-03-07 08:51:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:51:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:51:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 507 @ 24683 updates, score 14.197) (writing took 2.412855627015233 seconds)
2022-03-07 08:51:21 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-07 08:51:21 | INFO | train | epoch 507 | loss 0.711 | nll_loss 0.168 | ppl 1.12 | wps 24333.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24683 | lr 0.00020128 | gnorm 0.342 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 71331
2022-03-07 08:51:21 | INFO | fairseq.trainer | begin training epoch 508
2022-03-07 08:51:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:52:04 | INFO | train_inner | epoch 508:     17 / 49 loss=0.711, nll_loss=0.167, ppl=1.12, wps=24122.8, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.342, loss_scale=32, train_wall=230, gb_free=8.8, wall=71374
2022-03-07 08:53:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:53:31 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 14.318 | nll_loss 14.134 | ppl 17981.2 | wps 42305.9 | wpb 510.9 | bsz 1 | num_updates 24732 | best_loss 8.318
2022-03-07 08:53:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24732 updates
2022-03-07 08:53:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:53:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:53:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 508 @ 24732 updates, score 14.318) (writing took 2.392652191221714 seconds)
2022-03-07 08:53:33 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-07 08:53:33 | INFO | train | epoch 508 | loss 0.711 | nll_loss 0.167 | ppl 1.12 | wps 23991.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24732 | lr 0.000201081 | gnorm 0.344 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 71463
2022-03-07 08:53:33 | INFO | fairseq.trainer | begin training epoch 509
2022-03-07 08:53:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:55:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:55:44 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 14.263 | nll_loss 14.077 | ppl 17278.5 | wps 43129.1 | wpb 510.9 | bsz 1 | num_updates 24781 | best_loss 8.318
2022-03-07 08:55:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24781 updates
2022-03-07 08:55:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:55:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:55:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 509 @ 24781 updates, score 14.263) (writing took 2.4973609894514084 seconds)
2022-03-07 08:55:46 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-07 08:55:46 | INFO | train | epoch 509 | loss 0.71 | nll_loss 0.166 | ppl 1.12 | wps 23836.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24781 | lr 0.000200882 | gnorm 0.34 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 71597
2022-03-07 08:55:46 | INFO | fairseq.trainer | begin training epoch 510
2022-03-07 08:55:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:56:36 | INFO | train_inner | epoch 510:     19 / 49 loss=0.71, nll_loss=0.166, ppl=1.12, wps=23861.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.341, loss_scale=64, train_wall=232, gb_free=8.8, wall=71646
2022-03-07 08:57:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:57:56 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 14.29 | nll_loss 14.106 | ppl 17638.2 | wps 45343.3 | wpb 510.9 | bsz 1 | num_updates 24830 | best_loss 8.318
2022-03-07 08:57:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24830 updates
2022-03-07 08:57:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:57:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:57:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 510 @ 24830 updates, score 14.29) (writing took 2.4218058176338673 seconds)
2022-03-07 08:57:58 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-07 08:57:58 | INFO | train | epoch 510 | loss 0.709 | nll_loss 0.166 | ppl 1.12 | wps 24161.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24830 | lr 0.000200683 | gnorm 0.338 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 71728
2022-03-07 08:57:58 | INFO | fairseq.trainer | begin training epoch 511
2022-03-07 08:57:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:00:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:00:07 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 14.243 | nll_loss 14.057 | ppl 17043 | wps 42042.7 | wpb 510.9 | bsz 1 | num_updates 24879 | best_loss 8.318
2022-03-07 09:00:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24879 updates
2022-03-07 09:00:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:00:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:00:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 511 @ 24879 updates, score 14.243) (writing took 2.4938446786254644 seconds)
2022-03-07 09:00:10 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-07 09:00:10 | INFO | train | epoch 511 | loss 0.709 | nll_loss 0.166 | ppl 1.12 | wps 24101.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24879 | lr 0.000200486 | gnorm 0.341 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 71860
2022-03-07 09:00:10 | INFO | fairseq.trainer | begin training epoch 512
2022-03-07 09:00:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:00:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:01:07 | INFO | train_inner | epoch 512:     22 / 49 loss=0.709, nll_loss=0.166, ppl=1.12, wps=23910.7, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.34, loss_scale=64, train_wall=231, gb_free=8.8, wall=71917
2022-03-07 09:02:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:02:21 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 14.31 | nll_loss 14.126 | ppl 17877 | wps 42909.6 | wpb 510.9 | bsz 1 | num_updates 24927 | best_loss 8.318
2022-03-07 09:02:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24927 updates
2022-03-07 09:02:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:02:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:02:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 512 @ 24927 updates, score 14.31) (writing took 2.4387368839234114 seconds)
2022-03-07 09:02:23 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-07 09:02:23 | INFO | train | epoch 512 | loss 0.709 | nll_loss 0.166 | ppl 1.12 | wps 23324.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 24927 | lr 0.000200293 | gnorm 0.344 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 71994
2022-03-07 09:02:23 | INFO | fairseq.trainer | begin training epoch 513
2022-03-07 09:02:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:04:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:04:34 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 14.283 | nll_loss 14.098 | ppl 17537.5 | wps 43540.5 | wpb 510.9 | bsz 1 | num_updates 24976 | best_loss 8.318
2022-03-07 09:04:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24976 updates
2022-03-07 09:04:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:04:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:04:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 513 @ 24976 updates, score 14.283) (writing took 2.4164121989160776 seconds)
2022-03-07 09:04:36 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-07 09:04:36 | INFO | train | epoch 513 | loss 0.709 | nll_loss 0.165 | ppl 1.12 | wps 23868.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24976 | lr 0.000200096 | gnorm 0.338 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 72127
2022-03-07 09:04:36 | INFO | fairseq.trainer | begin training epoch 514
2022-03-07 09:04:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:05:39 | INFO | train_inner | epoch 514:     24 / 49 loss=0.709, nll_loss=0.166, ppl=1.12, wps=23892.3, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.34, loss_scale=64, train_wall=232, gb_free=8.8, wall=72189
2022-03-07 09:06:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:06:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:06:47 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 14.249 | nll_loss 14.065 | ppl 17138.4 | wps 42745.5 | wpb 510.9 | bsz 1 | num_updates 25024 | best_loss 8.318
2022-03-07 09:06:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25024 updates
2022-03-07 09:06:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:06:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:06:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 514 @ 25024 updates, score 14.249) (writing took 2.4380477108061314 seconds)
2022-03-07 09:06:49 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-07 09:06:49 | INFO | train | epoch 514 | loss 0.708 | nll_loss 0.165 | ppl 1.12 | wps 23398.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25024 | lr 0.000199904 | gnorm 0.339 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 72260
2022-03-07 09:06:49 | INFO | fairseq.trainer | begin training epoch 515
2022-03-07 09:06:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:08:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:09:00 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 14.323 | nll_loss 14.14 | ppl 18054.9 | wps 43493.1 | wpb 510.9 | bsz 1 | num_updates 25073 | best_loss 8.318
2022-03-07 09:09:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25073 updates
2022-03-07 09:09:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:09:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:09:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 515 @ 25073 updates, score 14.323) (writing took 2.4486358240246773 seconds)
2022-03-07 09:09:03 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-07 09:09:03 | INFO | train | epoch 515 | loss 0.709 | nll_loss 0.166 | ppl 1.12 | wps 23873.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25073 | lr 0.000199709 | gnorm 0.341 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 72393
2022-03-07 09:09:03 | INFO | fairseq.trainer | begin training epoch 516
2022-03-07 09:09:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:10:12 | INFO | train_inner | epoch 516:     27 / 49 loss=0.709, nll_loss=0.166, ppl=1.12, wps=23683.2, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.341, loss_scale=64, train_wall=234, gb_free=8.8, wall=72463
2022-03-07 09:11:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:11:13 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 14.186 | nll_loss 14.001 | ppl 16390.5 | wps 43088.1 | wpb 510.9 | bsz 1 | num_updates 25122 | best_loss 8.318
2022-03-07 09:11:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25122 updates
2022-03-07 09:11:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:11:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:11:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 516 @ 25122 updates, score 14.186) (writing took 2.4285991732031107 seconds)
2022-03-07 09:11:16 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-07 09:11:16 | INFO | train | epoch 516 | loss 0.708 | nll_loss 0.164 | ppl 1.12 | wps 23867.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25122 | lr 0.000199514 | gnorm 0.339 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 72526
2022-03-07 09:11:16 | INFO | fairseq.trainer | begin training epoch 517
2022-03-07 09:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:12:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:13:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:13:27 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 14.217 | nll_loss 14.031 | ppl 16745 | wps 42812 | wpb 510.9 | bsz 1 | num_updates 25170 | best_loss 8.318
2022-03-07 09:13:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25170 updates
2022-03-07 09:13:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:13:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:13:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 517 @ 25170 updates, score 14.217) (writing took 2.413594536483288 seconds)
2022-03-07 09:13:29 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-07 09:13:29 | INFO | train | epoch 517 | loss 0.708 | nll_loss 0.165 | ppl 1.12 | wps 23368.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25170 | lr 0.000199323 | gnorm 0.338 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 72659
2022-03-07 09:13:29 | INFO | fairseq.trainer | begin training epoch 518
2022-03-07 09:13:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:14:47 | INFO | train_inner | epoch 518:     30 / 49 loss=0.708, nll_loss=0.165, ppl=1.12, wps=23661.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.339, loss_scale=64, train_wall=234, gb_free=8.8, wall=72737
2022-03-07 09:15:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:15:40 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 14.257 | nll_loss 14.074 | ppl 17241.9 | wps 43195.5 | wpb 510.9 | bsz 1 | num_updates 25219 | best_loss 8.318
2022-03-07 09:15:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25219 updates
2022-03-07 09:15:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:15:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:15:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 518 @ 25219 updates, score 14.257) (writing took 2.4467175882309675 seconds)
2022-03-07 09:15:42 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-07 09:15:42 | INFO | train | epoch 518 | loss 0.708 | nll_loss 0.165 | ppl 1.12 | wps 23867.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25219 | lr 0.00019913 | gnorm 0.342 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 72792
2022-03-07 09:15:42 | INFO | fairseq.trainer | begin training epoch 519
2022-03-07 09:15:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:17:53 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 14.174 | nll_loss 13.986 | ppl 16228.8 | wps 42943.5 | wpb 510.9 | bsz 1 | num_updates 25268 | best_loss 8.318
2022-03-07 09:17:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25268 updates
2022-03-07 09:17:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:17:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:17:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 519 @ 25268 updates, score 14.174) (writing took 2.4345159474760294 seconds)
2022-03-07 09:17:55 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-07 09:17:55 | INFO | train | epoch 519 | loss 0.707 | nll_loss 0.165 | ppl 1.12 | wps 23870.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25268 | lr 0.000198937 | gnorm 0.337 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 72926
2022-03-07 09:17:55 | INFO | fairseq.trainer | begin training epoch 520
2022-03-07 09:17:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:18:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:19:21 | INFO | train_inner | epoch 520:     33 / 49 loss=0.708, nll_loss=0.165, ppl=1.12, wps=23657.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.34, loss_scale=32, train_wall=234, gb_free=8.8, wall=73011
2022-03-07 09:20:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:20:06 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 14.406 | nll_loss 14.222 | ppl 19112.1 | wps 43403.1 | wpb 510.9 | bsz 1 | num_updates 25316 | best_loss 8.318
2022-03-07 09:20:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25316 updates
2022-03-07 09:20:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:20:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:20:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 520 @ 25316 updates, score 14.406) (writing took 2.436717890202999 seconds)
2022-03-07 09:20:08 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-07 09:20:08 | INFO | train | epoch 520 | loss 0.708 | nll_loss 0.165 | ppl 1.12 | wps 23366.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25316 | lr 0.000198748 | gnorm 0.341 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 73059
2022-03-07 09:20:08 | INFO | fairseq.trainer | begin training epoch 521
2022-03-07 09:20:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:22:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:22:19 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 14.246 | nll_loss 14.059 | ppl 17067.7 | wps 42514.8 | wpb 510.9 | bsz 1 | num_updates 25365 | best_loss 8.318
2022-03-07 09:22:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25365 updates
2022-03-07 09:22:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:22:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:22:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 521 @ 25365 updates, score 14.246) (writing took 2.4277297873049974 seconds)
2022-03-07 09:22:21 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-07 09:22:21 | INFO | train | epoch 521 | loss 0.707 | nll_loss 0.164 | ppl 1.12 | wps 23910.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25365 | lr 0.000198556 | gnorm 0.337 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 73192
2022-03-07 09:22:21 | INFO | fairseq.trainer | begin training epoch 522
2022-03-07 09:22:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:23:52 | INFO | train_inner | epoch 522:     35 / 49 loss=0.707, nll_loss=0.164, ppl=1.12, wps=23928.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=25400, lr=0.000198419, gnorm=0.336, loss_scale=64, train_wall=231, gb_free=8.8, wall=73282
2022-03-07 09:24:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:24:32 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 14.245 | nll_loss 14.058 | ppl 17058.5 | wps 42631.4 | wpb 510.9 | bsz 1 | num_updates 25414 | best_loss 8.318
2022-03-07 09:24:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25414 updates
2022-03-07 09:24:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:24:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:24:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 522 @ 25414 updates, score 14.245) (writing took 2.414170019328594 seconds)
2022-03-07 09:24:34 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-07 09:24:34 | INFO | train | epoch 522 | loss 0.706 | nll_loss 0.164 | ppl 1.12 | wps 23886.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25414 | lr 0.000198364 | gnorm 0.335 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 73325
2022-03-07 09:24:34 | INFO | fairseq.trainer | begin training epoch 523
2022-03-07 09:24:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:26:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:26:45 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 14.22 | nll_loss 14.034 | ppl 16773.1 | wps 43124.5 | wpb 510.9 | bsz 1 | num_updates 25463 | best_loss 8.318
2022-03-07 09:26:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25463 updates
2022-03-07 09:26:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:26:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:26:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 523 @ 25463 updates, score 14.22) (writing took 2.4409789610654116 seconds)
2022-03-07 09:26:47 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-07 09:26:47 | INFO | train | epoch 523 | loss 0.706 | nll_loss 0.164 | ppl 1.12 | wps 23898.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25463 | lr 0.000198173 | gnorm 0.336 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 73458
2022-03-07 09:26:47 | INFO | fairseq.trainer | begin training epoch 524
2022-03-07 09:26:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:26:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:28:26 | INFO | train_inner | epoch 524:     38 / 49 loss=0.706, nll_loss=0.164, ppl=1.12, wps=23680.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=25500, lr=0.00019803, gnorm=0.337, loss_scale=32, train_wall=234, gb_free=8.8, wall=73556
2022-03-07 09:28:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:28:58 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 14.331 | nll_loss 14.149 | ppl 18163.4 | wps 43160.6 | wpb 510.9 | bsz 1 | num_updates 25511 | best_loss 8.318
2022-03-07 09:28:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25511 updates
2022-03-07 09:28:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:29:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:29:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 524 @ 25511 updates, score 14.331) (writing took 2.408760664984584 seconds)
2022-03-07 09:29:01 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-07 09:29:01 | INFO | train | epoch 524 | loss 0.706 | nll_loss 0.163 | ppl 1.12 | wps 23369.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25511 | lr 0.000197987 | gnorm 0.337 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 73591
2022-03-07 09:29:01 | INFO | fairseq.trainer | begin training epoch 525
2022-03-07 09:29:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:31:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:31:11 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 14.309 | nll_loss 14.125 | ppl 17863 | wps 42702.5 | wpb 510.9 | bsz 1 | num_updates 25560 | best_loss 8.318
2022-03-07 09:31:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25560 updates
2022-03-07 09:31:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:31:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:31:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 525 @ 25560 updates, score 14.309) (writing took 2.416766816750169 seconds)
2022-03-07 09:31:14 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-07 09:31:14 | INFO | train | epoch 525 | loss 0.706 | nll_loss 0.164 | ppl 1.12 | wps 23893.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25560 | lr 0.000197797 | gnorm 0.343 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 73724
2022-03-07 09:31:14 | INFO | fairseq.trainer | begin training epoch 526
2022-03-07 09:31:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:32:57 | INFO | train_inner | epoch 526:     40 / 49 loss=0.706, nll_loss=0.163, ppl=1.12, wps=23919.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.341, loss_scale=64, train_wall=232, gb_free=8.8, wall=73827
2022-03-07 09:33:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:33:24 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 14.285 | nll_loss 14.101 | ppl 17571.8 | wps 42723.7 | wpb 510.9 | bsz 1 | num_updates 25609 | best_loss 8.318
2022-03-07 09:33:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25609 updates
2022-03-07 09:33:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:33:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:33:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 526 @ 25609 updates, score 14.285) (writing took 2.424570571631193 seconds)
2022-03-07 09:33:27 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-07 09:33:27 | INFO | train | epoch 526 | loss 0.705 | nll_loss 0.163 | ppl 1.12 | wps 23874.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25609 | lr 0.000197608 | gnorm 0.339 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 73857
2022-03-07 09:33:27 | INFO | fairseq.trainer | begin training epoch 527
2022-03-07 09:33:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:35:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:35:37 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 14.322 | nll_loss 14.139 | ppl 18045.4 | wps 43488.2 | wpb 510.9 | bsz 1 | num_updates 25658 | best_loss 8.318
2022-03-07 09:35:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25658 updates
2022-03-07 09:35:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:35:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:35:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 527 @ 25658 updates, score 14.322) (writing took 2.4283096101135015 seconds)
2022-03-07 09:35:40 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-07 09:35:40 | INFO | train | epoch 527 | loss 0.705 | nll_loss 0.162 | ppl 1.12 | wps 23853.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25658 | lr 0.000197419 | gnorm 0.335 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 73990
2022-03-07 09:35:40 | INFO | fairseq.trainer | begin training epoch 528
2022-03-07 09:35:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:37:29 | INFO | train_inner | epoch 528:     42 / 49 loss=0.705, nll_loss=0.163, ppl=1.12, wps=23892.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.337, loss_scale=64, train_wall=232, gb_free=8.8, wall=74099
2022-03-07 09:37:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:37:51 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 14.223 | nll_loss 14.037 | ppl 16813.8 | wps 43124.4 | wpb 510.9 | bsz 1 | num_updates 25707 | best_loss 8.318
2022-03-07 09:37:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25707 updates
2022-03-07 09:37:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:37:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:37:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 528 @ 25707 updates, score 14.223) (writing took 2.4060787353664637 seconds)
2022-03-07 09:37:53 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-07 09:37:53 | INFO | train | epoch 528 | loss 0.705 | nll_loss 0.163 | ppl 1.12 | wps 23873.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25707 | lr 0.000197231 | gnorm 0.339 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 74123
2022-03-07 09:37:53 | INFO | fairseq.trainer | begin training epoch 529
2022-03-07 09:37:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:38:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:39:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:40:04 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 14.242 | nll_loss 14.057 | ppl 17044.3 | wps 42994 | wpb 510.9 | bsz 1 | num_updates 25755 | best_loss 8.318
2022-03-07 09:40:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25755 updates
2022-03-07 09:40:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:40:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:40:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 529 @ 25755 updates, score 14.242) (writing took 2.384942028671503 seconds)
2022-03-07 09:40:06 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-07 09:40:06 | INFO | train | epoch 529 | loss 0.705 | nll_loss 0.162 | ppl 1.12 | wps 23393.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25755 | lr 0.000197047 | gnorm 0.339 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 74256
2022-03-07 09:40:06 | INFO | fairseq.trainer | begin training epoch 530
2022-03-07 09:40:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:42:02 | INFO | train_inner | epoch 530:     45 / 49 loss=0.704, nll_loss=0.162, ppl=1.12, wps=23705.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.335, loss_scale=64, train_wall=234, gb_free=8.8, wall=74373
2022-03-07 09:42:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:42:16 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 14.202 | nll_loss 14.015 | ppl 16558.3 | wps 42942.4 | wpb 510.9 | bsz 1 | num_updates 25804 | best_loss 8.318
2022-03-07 09:42:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25804 updates
2022-03-07 09:42:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:42:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:42:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 530 @ 25804 updates, score 14.202) (writing took 2.4390019588172436 seconds)
2022-03-07 09:42:19 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-07 09:42:19 | INFO | train | epoch 530 | loss 0.704 | nll_loss 0.162 | ppl 1.12 | wps 23924.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25804 | lr 0.00019686 | gnorm 0.332 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 74389
2022-03-07 09:42:19 | INFO | fairseq.trainer | begin training epoch 531
2022-03-07 09:42:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:42:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:44:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:44:30 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 14.319 | nll_loss 14.134 | ppl 17978.2 | wps 42643.6 | wpb 510.9 | bsz 1 | num_updates 25852 | best_loss 8.318
2022-03-07 09:44:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25852 updates
2022-03-07 09:44:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:44:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:44:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 531 @ 25852 updates, score 14.319) (writing took 2.414684597402811 seconds)
2022-03-07 09:44:32 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-07 09:44:32 | INFO | train | epoch 531 | loss 0.704 | nll_loss 0.162 | ppl 1.12 | wps 23381.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25852 | lr 0.000196677 | gnorm 0.339 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 74522
2022-03-07 09:44:32 | INFO | fairseq.trainer | begin training epoch 532
2022-03-07 09:44:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:46:36 | INFO | train_inner | epoch 532:     48 / 49 loss=0.704, nll_loss=0.162, ppl=1.12, wps=23661.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.338, loss_scale=32, train_wall=234, gb_free=8.8, wall=74647
2022-03-07 09:46:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:46:43 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 14.23 | nll_loss 14.045 | ppl 16907.3 | wps 43812.4 | wpb 510.9 | bsz 1 | num_updates 25901 | best_loss 8.318
2022-03-07 09:46:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25901 updates
2022-03-07 09:46:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:46:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:46:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 532 @ 25901 updates, score 14.23) (writing took 2.42791541852057 seconds)
2022-03-07 09:46:45 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-07 09:46:45 | INFO | train | epoch 532 | loss 0.703 | nll_loss 0.161 | ppl 1.12 | wps 23862.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25901 | lr 0.000196491 | gnorm 0.336 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 74656
2022-03-07 09:46:45 | INFO | fairseq.trainer | begin training epoch 533
2022-03-07 09:46:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:48:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:48:56 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 14.292 | nll_loss 14.109 | ppl 17667.9 | wps 43329 | wpb 510.9 | bsz 1 | num_updates 25950 | best_loss 8.318
2022-03-07 09:48:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25950 updates
2022-03-07 09:48:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:48:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:48:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 533 @ 25950 updates, score 14.292) (writing took 2.3939068876206875 seconds)
2022-03-07 09:48:58 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-07 09:48:58 | INFO | train | epoch 533 | loss 0.703 | nll_loss 0.161 | ppl 1.12 | wps 23866.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25950 | lr 0.000196305 | gnorm 0.33 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 74789
2022-03-07 09:48:58 | INFO | fairseq.trainer | begin training epoch 534
2022-03-07 09:48:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:51:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:51:09 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 14.242 | nll_loss 14.059 | ppl 17067.2 | wps 42271.6 | wpb 510.9 | bsz 1 | num_updates 25999 | best_loss 8.318
2022-03-07 09:51:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25999 updates
2022-03-07 09:51:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:51:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:51:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 534 @ 25999 updates, score 14.242) (writing took 2.4151035882532597 seconds)
2022-03-07 09:51:12 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-07 09:51:12 | INFO | train | epoch 534 | loss 0.703 | nll_loss 0.162 | ppl 1.12 | wps 23848.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25999 | lr 0.00019612 | gnorm 0.336 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 74922
2022-03-07 09:51:12 | INFO | fairseq.trainer | begin training epoch 535
2022-03-07 09:51:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:51:14 | INFO | train_inner | epoch 535:      1 / 49 loss=0.703, nll_loss=0.161, ppl=1.12, wps=23225.1, ups=0.36, wpb=64539.7, bsz=126.1, num_updates=26000, lr=0.000196116, gnorm=0.334, loss_scale=64, train_wall=231, gb_free=8.8, wall=74925
2022-03-07 09:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:53:22 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 14.315 | nll_loss 14.133 | ppl 17964.4 | wps 42489.8 | wpb 510.9 | bsz 1 | num_updates 26048 | best_loss 8.318
2022-03-07 09:53:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26048 updates
2022-03-07 09:53:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:53:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:53:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 535 @ 26048 updates, score 14.315) (writing took 2.3810380548238754 seconds)
2022-03-07 09:53:25 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-07 09:53:25 | INFO | train | epoch 535 | loss 0.703 | nll_loss 0.161 | ppl 1.12 | wps 23880.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26048 | lr 0.000195935 | gnorm 0.334 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 75055
2022-03-07 09:53:25 | INFO | fairseq.trainer | begin training epoch 536
2022-03-07 09:53:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:54:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:55:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:55:36 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 14.22 | nll_loss 14.037 | ppl 16810 | wps 42779.7 | wpb 510.9 | bsz 1 | num_updates 26096 | best_loss 8.318
2022-03-07 09:55:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26096 updates
2022-03-07 09:55:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:55:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:55:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 536 @ 26096 updates, score 14.22) (writing took 2.4282176084816456 seconds)
2022-03-07 09:55:38 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-07 09:55:38 | INFO | train | epoch 536 | loss 0.703 | nll_loss 0.161 | ppl 1.12 | wps 23360.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 26096 | lr 0.000195755 | gnorm 0.334 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 75188
2022-03-07 09:55:38 | INFO | fairseq.trainer | begin training epoch 537
2022-03-07 09:55:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:55:48 | INFO | train_inner | epoch 537:      4 / 49 loss=0.703, nll_loss=0.161, ppl=1.12, wps=23671.1, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.334, loss_scale=64, train_wall=234, gb_free=8.8, wall=75199
2022-03-07 09:56:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:57:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:57:49 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 14.261 | nll_loss 14.077 | ppl 17283.3 | wps 43078.6 | wpb 510.9 | bsz 1 | num_updates 26144 | best_loss 8.318
2022-03-07 09:57:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26144 updates
2022-03-07 09:57:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:57:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:57:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 537 @ 26144 updates, score 14.261) (writing took 2.4685498159378767 seconds)
2022-03-07 09:57:51 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-07 09:57:51 | INFO | train | epoch 537 | loss 0.702 | nll_loss 0.161 | ppl 1.12 | wps 23387.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 26144 | lr 0.000195575 | gnorm 0.335 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 75321
2022-03-07 09:57:51 | INFO | fairseq.trainer | begin training epoch 538
2022-03-07 09:57:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:59:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:00:02 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 14.291 | nll_loss 14.108 | ppl 17657.2 | wps 43073.7 | wpb 510.9 | bsz 1 | num_updates 26193 | best_loss 8.318
2022-03-07 10:00:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26193 updates
2022-03-07 10:00:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:00:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:00:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 538 @ 26193 updates, score 14.291) (writing took 2.454657655209303 seconds)
2022-03-07 10:00:04 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-07 10:00:04 | INFO | train | epoch 538 | loss 0.702 | nll_loss 0.161 | ppl 1.12 | wps 23834.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26193 | lr 0.000195392 | gnorm 0.332 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 75455
2022-03-07 10:00:04 | INFO | fairseq.trainer | begin training epoch 539
2022-03-07 10:00:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:00:23 | INFO | train_inner | epoch 539:      7 / 49 loss=0.702, nll_loss=0.161, ppl=1.12, wps=23660.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.334, loss_scale=32, train_wall=234, gb_free=8.8, wall=75473
2022-03-07 10:02:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:02:15 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 14.166 | nll_loss 13.981 | ppl 16167.1 | wps 43264.1 | wpb 510.9 | bsz 1 | num_updates 26242 | best_loss 8.318
2022-03-07 10:02:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26242 updates
2022-03-07 10:02:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:02:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:02:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 539 @ 26242 updates, score 14.166) (writing took 2.4391202572733164 seconds)
2022-03-07 10:02:18 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-07 10:02:18 | INFO | train | epoch 539 | loss 0.701 | nll_loss 0.16 | ppl 1.12 | wps 23859.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26242 | lr 0.00019521 | gnorm 0.331 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 75588
2022-03-07 10:02:18 | INFO | fairseq.trainer | begin training epoch 540
2022-03-07 10:02:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:04:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:04:25 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 14.213 | nll_loss 14.029 | ppl 16716.3 | wps 45588.9 | wpb 510.9 | bsz 1 | num_updates 26291 | best_loss 8.318
2022-03-07 10:04:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26291 updates
2022-03-07 10:04:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:04:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:04:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 540 @ 26291 updates, score 14.213) (writing took 2.536274129524827 seconds)
2022-03-07 10:04:28 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-07 10:04:28 | INFO | train | epoch 540 | loss 0.701 | nll_loss 0.16 | ppl 1.12 | wps 24373.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26291 | lr 0.000195028 | gnorm 0.332 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 75718
2022-03-07 10:04:28 | INFO | fairseq.trainer | begin training epoch 541
2022-03-07 10:04:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:04:51 | INFO | train_inner | epoch 541:      9 / 49 loss=0.701, nll_loss=0.16, ppl=1.12, wps=24182.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.331, loss_scale=64, train_wall=229, gb_free=8.8, wall=75741
2022-03-07 10:06:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:06:37 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 14.236 | nll_loss 14.052 | ppl 16985.2 | wps 43869.8 | wpb 510.9 | bsz 1 | num_updates 26340 | best_loss 8.318
2022-03-07 10:06:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26340 updates
2022-03-07 10:06:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:06:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:06:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 541 @ 26340 updates, score 14.236) (writing took 2.406614700332284 seconds)
2022-03-07 10:06:39 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-07 10:06:39 | INFO | train | epoch 541 | loss 0.701 | nll_loss 0.16 | ppl 1.12 | wps 24188.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26340 | lr 0.000194846 | gnorm 0.329 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 75850
2022-03-07 10:06:39 | INFO | fairseq.trainer | begin training epoch 542
2022-03-07 10:06:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:07:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:08:49 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 14.213 | nll_loss 14.028 | ppl 16702.7 | wps 45361.7 | wpb 510.9 | bsz 1 | num_updates 26388 | best_loss 8.318
2022-03-07 10:08:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26388 updates
2022-03-07 10:08:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:08:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:08:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 542 @ 26388 updates, score 14.213) (writing took 2.530307598412037 seconds)
2022-03-07 10:08:52 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-07 10:08:52 | INFO | train | epoch 542 | loss 0.701 | nll_loss 0.16 | ppl 1.12 | wps 23516 | ups 0.36 | wpb 64853.3 | bsz 126.7 | num_updates 26388 | lr 0.000194669 | gnorm 0.332 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 75982
2022-03-07 10:08:52 | INFO | fairseq.trainer | begin training epoch 543
2022-03-07 10:08:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:09:22 | INFO | train_inner | epoch 543:     12 / 49 loss=0.701, nll_loss=0.16, ppl=1.12, wps=23896.2, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.331, loss_scale=64, train_wall=232, gb_free=8.8, wall=76013
2022-03-07 10:10:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:11:00 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 14.278 | nll_loss 14.096 | ppl 17516.3 | wps 43458.6 | wpb 510.9 | bsz 1 | num_updates 26437 | best_loss 8.318
2022-03-07 10:11:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26437 updates
2022-03-07 10:11:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:11:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:11:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 543 @ 26437 updates, score 14.278) (writing took 2.533122695982456 seconds)
2022-03-07 10:11:03 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-07 10:11:03 | INFO | train | epoch 543 | loss 0.7 | nll_loss 0.159 | ppl 1.12 | wps 24292.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26437 | lr 0.000194488 | gnorm 0.33 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 76113
2022-03-07 10:11:03 | INFO | fairseq.trainer | begin training epoch 544
2022-03-07 10:11:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:13:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:13:12 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 14.28 | nll_loss 14.098 | ppl 17536.5 | wps 44093 | wpb 510.9 | bsz 1 | num_updates 26486 | best_loss 8.318
2022-03-07 10:13:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26486 updates
2022-03-07 10:13:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:13:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:13:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 544 @ 26486 updates, score 14.28) (writing took 2.5033162776380777 seconds)
2022-03-07 10:13:15 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-07 10:13:15 | INFO | train | epoch 544 | loss 0.7 | nll_loss 0.159 | ppl 1.12 | wps 24002.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26486 | lr 0.000194309 | gnorm 0.33 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 76245
2022-03-07 10:13:15 | INFO | fairseq.trainer | begin training epoch 545
2022-03-07 10:13:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:13:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:13:54 | INFO | train_inner | epoch 545:     15 / 49 loss=0.7, nll_loss=0.159, ppl=1.12, wps=23912.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.33, loss_scale=64, train_wall=232, gb_free=8.8, wall=76284
2022-03-07 10:15:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:15:25 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 14.252 | nll_loss 14.068 | ppl 17178.6 | wps 44429.9 | wpb 510.9 | bsz 1 | num_updates 26534 | best_loss 8.318
2022-03-07 10:15:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26534 updates
2022-03-07 10:15:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:15:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:15:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 545 @ 26534 updates, score 14.252) (writing took 2.55716191790998 seconds)
2022-03-07 10:15:27 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-07 10:15:27 | INFO | train | epoch 545 | loss 0.7 | nll_loss 0.159 | ppl 1.12 | wps 23498.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 26534 | lr 0.000194133 | gnorm 0.328 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 76378
2022-03-07 10:15:27 | INFO | fairseq.trainer | begin training epoch 546
2022-03-07 10:15:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:17:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:17:38 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 14.182 | nll_loss 13.997 | ppl 16353.4 | wps 44519.2 | wpb 510.9 | bsz 1 | num_updates 26583 | best_loss 8.318
2022-03-07 10:17:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26583 updates
2022-03-07 10:17:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:17:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:17:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 546 @ 26583 updates, score 14.182) (writing took 2.524658301845193 seconds)
2022-03-07 10:17:40 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-07 10:17:40 | INFO | train | epoch 546 | loss 0.7 | nll_loss 0.159 | ppl 1.12 | wps 23951.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26583 | lr 0.000193954 | gnorm 0.33 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 76510
2022-03-07 10:17:40 | INFO | fairseq.trainer | begin training epoch 547
2022-03-07 10:17:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:18:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:18:27 | INFO | train_inner | epoch 547:     18 / 49 loss=0.7, nll_loss=0.159, ppl=1.12, wps=23763.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.33, loss_scale=32, train_wall=233, gb_free=8.8, wall=76557
2022-03-07 10:19:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:19:50 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 14.264 | nll_loss 14.08 | ppl 17319.3 | wps 43729.9 | wpb 510.9 | bsz 1 | num_updates 26631 | best_loss 8.318
2022-03-07 10:19:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26631 updates
2022-03-07 10:19:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 547 @ 26631 updates, score 14.264) (writing took 2.4424510579556227 seconds)
2022-03-07 10:19:52 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-07 10:19:52 | INFO | train | epoch 547 | loss 0.7 | nll_loss 0.159 | ppl 1.12 | wps 23526.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 26631 | lr 0.000193779 | gnorm 0.336 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 76643
2022-03-07 10:19:52 | INFO | fairseq.trainer | begin training epoch 548
2022-03-07 10:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:21:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:22:02 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 14.204 | nll_loss 14.021 | ppl 16625.6 | wps 44482.5 | wpb 510.9 | bsz 1 | num_updates 26680 | best_loss 8.318
2022-03-07 10:22:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26680 updates
2022-03-07 10:22:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:22:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:22:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 548 @ 26680 updates, score 14.204) (writing took 2.5407533925026655 seconds)
2022-03-07 10:22:05 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-07 10:22:05 | INFO | train | epoch 548 | loss 0.699 | nll_loss 0.158 | ppl 1.12 | wps 23995.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26680 | lr 0.000193601 | gnorm 0.331 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 76775
2022-03-07 10:22:05 | INFO | fairseq.trainer | begin training epoch 549
2022-03-07 10:22:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:22:56 | INFO | train_inner | epoch 549:     20 / 49 loss=0.699, nll_loss=0.159, ppl=1.12, wps=24054.5, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.333, loss_scale=32, train_wall=230, gb_free=8.8, wall=76827
2022-03-07 10:24:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:24:15 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 14.236 | nll_loss 14.053 | ppl 16995.6 | wps 44009.6 | wpb 510.9 | bsz 1 | num_updates 26729 | best_loss 8.318
2022-03-07 10:24:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26729 updates
2022-03-07 10:24:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:24:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:24:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 549 @ 26729 updates, score 14.236) (writing took 2.3773919250816107 seconds)
2022-03-07 10:24:17 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-07 10:24:17 | INFO | train | epoch 549 | loss 0.699 | nll_loss 0.158 | ppl 1.12 | wps 24007 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26729 | lr 0.000193423 | gnorm 0.329 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 76908
2022-03-07 10:24:17 | INFO | fairseq.trainer | begin training epoch 550
2022-03-07 10:24:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:26:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:26:27 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 14.243 | nll_loss 14.059 | ppl 17072.8 | wps 44285.8 | wpb 510.9 | bsz 1 | num_updates 26778 | best_loss 8.318
2022-03-07 10:26:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26778 updates
2022-03-07 10:26:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:26:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:26:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 550 @ 26778 updates, score 14.243) (writing took 2.4796391017735004 seconds)
2022-03-07 10:26:29 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-07 10:26:29 | INFO | train | epoch 550 | loss 0.698 | nll_loss 0.158 | ppl 1.12 | wps 24048 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26778 | lr 0.000193246 | gnorm 0.33 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 77040
2022-03-07 10:26:29 | INFO | fairseq.trainer | begin training epoch 551
2022-03-07 10:26:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:27:26 | INFO | train_inner | epoch 551:     22 / 49 loss=0.698, nll_loss=0.158, ppl=1.12, wps=24033.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.328, loss_scale=64, train_wall=231, gb_free=8.8, wall=77097
2022-03-07 10:28:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:28:39 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 14.286 | nll_loss 14.102 | ppl 17583 | wps 44061.9 | wpb 510.9 | bsz 1 | num_updates 26827 | best_loss 8.318
2022-03-07 10:28:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26827 updates
2022-03-07 10:28:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:28:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:28:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 551 @ 26827 updates, score 14.286) (writing took 2.4829797502607107 seconds)
2022-03-07 10:28:42 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-07 10:28:42 | INFO | train | epoch 551 | loss 0.698 | nll_loss 0.158 | ppl 1.12 | wps 24002.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26827 | lr 0.00019307 | gnorm 0.327 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 77172
2022-03-07 10:28:42 | INFO | fairseq.trainer | begin training epoch 552
2022-03-07 10:28:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:29:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:30:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:30:52 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 14.264 | nll_loss 14.081 | ppl 17326.4 | wps 44326.9 | wpb 510.9 | bsz 1 | num_updates 26875 | best_loss 8.318
2022-03-07 10:30:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26875 updates
2022-03-07 10:30:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:30:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:30:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 552 @ 26875 updates, score 14.264) (writing took 2.4950217828154564 seconds)
2022-03-07 10:30:54 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-07 10:30:54 | INFO | train | epoch 552 | loss 0.698 | nll_loss 0.158 | ppl 1.12 | wps 23541.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 26875 | lr 0.000192897 | gnorm 0.335 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 77304
2022-03-07 10:30:54 | INFO | fairseq.trainer | begin training epoch 553
2022-03-07 10:30:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:31:58 | INFO | train_inner | epoch 553:     25 / 49 loss=0.698, nll_loss=0.158, ppl=1.12, wps=23834.7, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.331, loss_scale=64, train_wall=233, gb_free=8.8, wall=77369
2022-03-07 10:32:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:33:04 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 14.258 | nll_loss 14.076 | ppl 17269.6 | wps 44240 | wpb 510.9 | bsz 1 | num_updates 26924 | best_loss 8.318
2022-03-07 10:33:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26924 updates
2022-03-07 10:33:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:33:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:33:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 553 @ 26924 updates, score 14.258) (writing took 2.5765552520751953 seconds)
2022-03-07 10:33:07 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-07 10:33:07 | INFO | train | epoch 553 | loss 0.698 | nll_loss 0.157 | ppl 1.12 | wps 23978.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26924 | lr 0.000192722 | gnorm 0.328 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 77437
2022-03-07 10:33:07 | INFO | fairseq.trainer | begin training epoch 554
2022-03-07 10:33:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:34:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:35:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:35:17 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 14.284 | nll_loss 14.103 | ppl 17600.9 | wps 43954 | wpb 510.9 | bsz 1 | num_updates 26972 | best_loss 8.318
2022-03-07 10:35:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26972 updates
2022-03-07 10:35:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:35:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:35:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 554 @ 26972 updates, score 14.284) (writing took 2.509503973647952 seconds)
2022-03-07 10:35:19 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-07 10:35:19 | INFO | train | epoch 554 | loss 0.697 | nll_loss 0.157 | ppl 1.11 | wps 23446.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 26972 | lr 0.00019255 | gnorm 0.329 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 77570
2022-03-07 10:35:19 | INFO | fairseq.trainer | begin training epoch 555
2022-03-07 10:35:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:36:32 | INFO | train_inner | epoch 555:     28 / 49 loss=0.697, nll_loss=0.157, ppl=1.12, wps=23736.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.328, loss_scale=32, train_wall=233, gb_free=8.8, wall=77642
2022-03-07 10:37:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:37:30 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 14.221 | nll_loss 14.036 | ppl 16795.3 | wps 43535 | wpb 510.9 | bsz 1 | num_updates 27021 | best_loss 8.318
2022-03-07 10:37:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27021 updates
2022-03-07 10:37:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:37:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:37:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 555 @ 27021 updates, score 14.221) (writing took 2.521559914574027 seconds)
2022-03-07 10:37:32 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-07 10:37:32 | INFO | train | epoch 555 | loss 0.698 | nll_loss 0.157 | ppl 1.12 | wps 23942.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27021 | lr 0.000192375 | gnorm 0.329 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 77702
2022-03-07 10:37:32 | INFO | fairseq.trainer | begin training epoch 556
2022-03-07 10:37:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:39:42 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 14.249 | nll_loss 14.067 | ppl 17158.5 | wps 44317 | wpb 510.9 | bsz 1 | num_updates 27070 | best_loss 8.318
2022-03-07 10:39:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27070 updates
2022-03-07 10:39:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:39:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:39:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 556 @ 27070 updates, score 14.249) (writing took 2.434758810326457 seconds)
2022-03-07 10:39:44 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-07 10:39:44 | INFO | train | epoch 556 | loss 0.697 | nll_loss 0.157 | ppl 1.11 | wps 24081.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27070 | lr 0.000192201 | gnorm 0.329 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 77834
2022-03-07 10:39:44 | INFO | fairseq.trainer | begin training epoch 557
2022-03-07 10:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:41:01 | INFO | train_inner | epoch 557:     30 / 49 loss=0.698, nll_loss=0.157, ppl=1.12, wps=24102.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=27100, lr=0.000192095, gnorm=0.331, loss_scale=64, train_wall=230, gb_free=8.8, wall=77911
2022-03-07 10:41:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:41:53 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 14.345 | nll_loss 14.165 | ppl 18364 | wps 43650.9 | wpb 510.9 | bsz 1 | num_updates 27119 | best_loss 8.318
2022-03-07 10:41:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27119 updates
2022-03-07 10:41:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:41:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:41:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 557 @ 27119 updates, score 14.345) (writing took 2.397379506379366 seconds)
2022-03-07 10:41:56 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-07 10:41:56 | INFO | train | epoch 557 | loss 0.698 | nll_loss 0.158 | ppl 1.12 | wps 24143.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27119 | lr 0.000192027 | gnorm 0.333 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 77966
2022-03-07 10:41:56 | INFO | fairseq.trainer | begin training epoch 558
2022-03-07 10:41:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:44:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:44:05 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 14.302 | nll_loss 14.12 | ppl 17810.3 | wps 44445.4 | wpb 510.9 | bsz 1 | num_updates 27168 | best_loss 8.318
2022-03-07 10:44:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27168 updates
2022-03-07 10:44:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:44:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:44:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 558 @ 27168 updates, score 14.302) (writing took 2.5479552559554577 seconds)
2022-03-07 10:44:08 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-07 10:44:08 | INFO | train | epoch 558 | loss 0.697 | nll_loss 0.157 | ppl 1.11 | wps 24073.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27168 | lr 0.000191854 | gnorm 0.329 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 78098
2022-03-07 10:44:08 | INFO | fairseq.trainer | begin training epoch 559
2022-03-07 10:44:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:45:30 | INFO | train_inner | epoch 559:     32 / 49 loss=0.697, nll_loss=0.157, ppl=1.11, wps=24128.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=27200, lr=0.000191741, gnorm=0.328, loss_scale=64, train_wall=230, gb_free=8.8, wall=78180
2022-03-07 10:46:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:46:17 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 14.254 | nll_loss 14.071 | ppl 17208.7 | wps 44141.1 | wpb 510.9 | bsz 1 | num_updates 27217 | best_loss 8.318
2022-03-07 10:46:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27217 updates
2022-03-07 10:46:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:46:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:46:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 559 @ 27217 updates, score 14.254) (writing took 2.5133435018360615 seconds)
2022-03-07 10:46:20 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-07 10:46:20 | INFO | train | epoch 559 | loss 0.696 | nll_loss 0.156 | ppl 1.11 | wps 24099.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27217 | lr 0.000191681 | gnorm 0.326 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 78230
2022-03-07 10:46:20 | INFO | fairseq.trainer | begin training epoch 560
2022-03-07 10:46:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:46:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:48:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:48:29 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 14.19 | nll_loss 14.006 | ppl 16450.5 | wps 44396.8 | wpb 510.9 | bsz 1 | num_updates 27265 | best_loss 8.318
2022-03-07 10:48:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27265 updates
2022-03-07 10:48:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:48:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:48:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 560 @ 27265 updates, score 14.19) (writing took 2.5232984516769648 seconds)
2022-03-07 10:48:31 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-07 10:48:31 | INFO | train | epoch 560 | loss 0.696 | nll_loss 0.156 | ppl 1.11 | wps 23595.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 27265 | lr 0.000191513 | gnorm 0.329 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 78362
2022-03-07 10:48:31 | INFO | fairseq.trainer | begin training epoch 561
2022-03-07 10:48:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:50:01 | INFO | train_inner | epoch 561:     35 / 49 loss=0.696, nll_loss=0.156, ppl=1.11, wps=23897.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=27300, lr=0.00019139, gnorm=0.328, loss_scale=64, train_wall=232, gb_free=8.8, wall=78451
2022-03-07 10:50:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:50:41 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 14.258 | nll_loss 14.076 | ppl 17269.1 | wps 43980 | wpb 510.9 | bsz 1 | num_updates 27314 | best_loss 8.318
2022-03-07 10:50:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27314 updates
2022-03-07 10:50:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:50:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:50:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 561 @ 27314 updates, score 14.258) (writing took 2.424998067319393 seconds)
2022-03-07 10:50:43 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-07 10:50:43 | INFO | train | epoch 561 | loss 0.696 | nll_loss 0.156 | ppl 1.11 | wps 24126.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27314 | lr 0.000191341 | gnorm 0.326 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 78493
2022-03-07 10:50:43 | INFO | fairseq.trainer | begin training epoch 562
2022-03-07 10:50:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:52:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:52:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:52:53 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 14.302 | nll_loss 14.121 | ppl 17820.2 | wps 44343.9 | wpb 510.9 | bsz 1 | num_updates 27362 | best_loss 8.318
2022-03-07 10:52:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27362 updates
2022-03-07 10:52:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:52:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:52:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 562 @ 27362 updates, score 14.302) (writing took 2.47169866040349 seconds)
2022-03-07 10:52:55 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-07 10:52:55 | INFO | train | epoch 562 | loss 0.696 | nll_loss 0.156 | ppl 1.11 | wps 23599.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 27362 | lr 0.000191173 | gnorm 0.326 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 78625
2022-03-07 10:52:55 | INFO | fairseq.trainer | begin training epoch 563
2022-03-07 10:52:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:54:32 | INFO | train_inner | epoch 563:     38 / 49 loss=0.696, nll_loss=0.156, ppl=1.11, wps=23910.3, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.326, loss_scale=64, train_wall=232, gb_free=8.8, wall=78723
2022-03-07 10:54:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:55:04 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 14.24 | nll_loss 14.058 | ppl 17054.9 | wps 44304.1 | wpb 510.9 | bsz 1 | num_updates 27411 | best_loss 8.318
2022-03-07 10:55:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27411 updates
2022-03-07 10:55:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:55:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:55:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 563 @ 27411 updates, score 14.24) (writing took 2.52016444504261 seconds)
2022-03-07 10:55:07 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-07 10:55:07 | INFO | train | epoch 563 | loss 0.696 | nll_loss 0.156 | ppl 1.11 | wps 24111.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27411 | lr 0.000191002 | gnorm 0.325 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 78757
2022-03-07 10:55:07 | INFO | fairseq.trainer | begin training epoch 564
2022-03-07 10:55:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:57:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:57:16 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 14.204 | nll_loss 14.019 | ppl 16597.2 | wps 45234.6 | wpb 510.9 | bsz 1 | num_updates 27460 | best_loss 8.318
2022-03-07 10:57:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27460 updates
2022-03-07 10:57:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:57:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:57:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 564 @ 27460 updates, score 14.204) (writing took 2.4966245964169502 seconds)
2022-03-07 10:57:18 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-07 10:57:18 | INFO | train | epoch 564 | loss 0.695 | nll_loss 0.156 | ppl 1.11 | wps 24170.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27460 | lr 0.000190831 | gnorm 0.325 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 78889
2022-03-07 10:57:18 | INFO | fairseq.trainer | begin training epoch 565
2022-03-07 10:57:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:57:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:59:02 | INFO | train_inner | epoch 565:     41 / 49 loss=0.695, nll_loss=0.156, ppl=1.11, wps=24082.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.325, loss_scale=64, train_wall=230, gb_free=8.8, wall=78992
2022-03-07 10:59:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:59:26 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 14.271 | nll_loss 14.09 | ppl 17443.8 | wps 45762.5 | wpb 510.9 | bsz 1 | num_updates 27508 | best_loss 8.318
2022-03-07 10:59:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27508 updates
2022-03-07 10:59:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:59:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:59:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 565 @ 27508 updates, score 14.271) (writing took 2.5363461673259735 seconds)
2022-03-07 10:59:28 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-07 10:59:28 | INFO | train | epoch 565 | loss 0.695 | nll_loss 0.155 | ppl 1.11 | wps 23980.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 27508 | lr 0.000190665 | gnorm 0.326 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 79018
2022-03-07 10:59:28 | INFO | fairseq.trainer | begin training epoch 566
2022-03-07 10:59:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:01:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:01:35 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 14.275 | nll_loss 14.091 | ppl 17448.8 | wps 45699.6 | wpb 510.9 | bsz 1 | num_updates 27557 | best_loss 8.318
2022-03-07 11:01:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27557 updates
2022-03-07 11:01:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:01:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:01:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 566 @ 27557 updates, score 14.275) (writing took 2.5203110203146935 seconds)
2022-03-07 11:01:38 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-07 11:01:38 | INFO | train | epoch 566 | loss 0.695 | nll_loss 0.155 | ppl 1.11 | wps 24481.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27557 | lr 0.000190495 | gnorm 0.323 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 79148
2022-03-07 11:01:38 | INFO | fairseq.trainer | begin training epoch 567
2022-03-07 11:01:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:03:27 | INFO | train_inner | epoch 567:     43 / 49 loss=0.695, nll_loss=0.155, ppl=1.11, wps=24503.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.325, loss_scale=64, train_wall=226, gb_free=8.8, wall=79257
2022-03-07 11:03:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:03:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:03:45 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 14.223 | nll_loss 14.037 | ppl 16810.2 | wps 45593 | wpb 510.9 | bsz 1 | num_updates 27605 | best_loss 8.318
2022-03-07 11:03:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27605 updates
2022-03-07 11:03:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:03:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 567 @ 27605 updates, score 14.223) (writing took 2.5421128533780575 seconds)
2022-03-07 11:03:48 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-07 11:03:48 | INFO | train | epoch 567 | loss 0.695 | nll_loss 0.155 | ppl 1.11 | wps 23960.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 27605 | lr 0.00019033 | gnorm 0.325 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 79278
2022-03-07 11:03:48 | INFO | fairseq.trainer | begin training epoch 568
2022-03-07 11:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:05:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:05:55 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 14.265 | nll_loss 14.082 | ppl 17348.1 | wps 45719.4 | wpb 510.9 | bsz 1 | num_updates 27654 | best_loss 8.318
2022-03-07 11:05:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27654 updates
2022-03-07 11:05:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:05:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:05:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 568 @ 27654 updates, score 14.265) (writing took 2.5740132089704275 seconds)
2022-03-07 11:05:58 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-07 11:05:58 | INFO | train | epoch 568 | loss 0.694 | nll_loss 0.155 | ppl 1.11 | wps 24480.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27654 | lr 0.000190161 | gnorm 0.326 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 79408
2022-03-07 11:05:58 | INFO | fairseq.trainer | begin training epoch 569
2022-03-07 11:05:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:07:54 | INFO | train_inner | epoch 569:     46 / 49 loss=0.694, nll_loss=0.155, ppl=1.11, wps=24254.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.326, loss_scale=64, train_wall=228, gb_free=8.8, wall=79524
2022-03-07 11:08:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:08:05 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 14.174 | nll_loss 13.991 | ppl 16279 | wps 45481.1 | wpb 510.9 | bsz 1 | num_updates 27703 | best_loss 8.318
2022-03-07 11:08:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27703 updates
2022-03-07 11:08:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:08:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:08:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 569 @ 27703 updates, score 14.174) (writing took 2.5309365522116423 seconds)
2022-03-07 11:08:08 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-07 11:08:08 | INFO | train | epoch 569 | loss 0.694 | nll_loss 0.155 | ppl 1.11 | wps 24436.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27703 | lr 0.000189993 | gnorm 0.326 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 79538
2022-03-07 11:08:08 | INFO | fairseq.trainer | begin training epoch 570
2022-03-07 11:08:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:09:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:10:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:10:15 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 14.257 | nll_loss 14.075 | ppl 17254.5 | wps 45393.5 | wpb 510.9 | bsz 1 | num_updates 27751 | best_loss 8.318
2022-03-07 11:10:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27751 updates
2022-03-07 11:10:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:10:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:10:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 570 @ 27751 updates, score 14.257) (writing took 2.528132915496826 seconds)
2022-03-07 11:10:18 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-07 11:10:18 | INFO | train | epoch 570 | loss 0.694 | nll_loss 0.155 | ppl 1.11 | wps 23977.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 27751 | lr 0.000189828 | gnorm 0.328 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 79668
2022-03-07 11:10:18 | INFO | fairseq.trainer | begin training epoch 571
2022-03-07 11:10:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:12:20 | INFO | train_inner | epoch 571:     49 / 49 loss=0.694, nll_loss=0.154, ppl=1.11, wps=24285.6, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=27800, lr=0.000189661, gnorm=0.326, loss_scale=64, train_wall=227, gb_free=8.8, wall=79790
2022-03-07 11:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:12:25 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 14.373 | nll_loss 14.195 | ppl 18751.9 | wps 45694.9 | wpb 510.9 | bsz 1 | num_updates 27800 | best_loss 8.318
2022-03-07 11:12:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27800 updates
2022-03-07 11:12:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:12:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:12:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 571 @ 27800 updates, score 14.373) (writing took 2.567080371081829 seconds)
2022-03-07 11:12:27 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-07 11:12:27 | INFO | train | epoch 571 | loss 0.693 | nll_loss 0.154 | ppl 1.11 | wps 24502.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27800 | lr 0.000189661 | gnorm 0.323 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 79798
2022-03-07 11:12:27 | INFO | fairseq.trainer | begin training epoch 572
2022-03-07 11:12:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:14:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:14:34 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 14.333 | nll_loss 14.152 | ppl 18199.4 | wps 46125.2 | wpb 510.9 | bsz 1 | num_updates 27849 | best_loss 8.318
2022-03-07 11:14:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27849 updates
2022-03-07 11:14:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:14:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:14:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 572 @ 27849 updates, score 14.333) (writing took 2.514724161475897 seconds)
2022-03-07 11:14:37 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-07 11:14:37 | INFO | train | epoch 572 | loss 0.693 | nll_loss 0.154 | ppl 1.11 | wps 24532.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27849 | lr 0.000189494 | gnorm 0.325 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 79927
2022-03-07 11:14:37 | INFO | fairseq.trainer | begin training epoch 573
2022-03-07 11:14:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:15:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:16:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:16:44 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 14.23 | nll_loss 14.047 | ppl 16922.2 | wps 45864.8 | wpb 510.9 | bsz 1 | num_updates 27897 | best_loss 8.318
2022-03-07 11:16:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27897 updates
2022-03-07 11:16:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:16:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:16:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 573 @ 27897 updates, score 14.23) (writing took 2.510475432500243 seconds)
2022-03-07 11:16:47 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-07 11:16:47 | INFO | train | epoch 573 | loss 0.693 | nll_loss 0.155 | ppl 1.11 | wps 23996.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 27897 | lr 0.000189331 | gnorm 0.323 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 80057
2022-03-07 11:16:47 | INFO | fairseq.trainer | begin training epoch 574
2022-03-07 11:16:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:16:54 | INFO | train_inner | epoch 574:      3 / 49 loss=0.693, nll_loss=0.154, ppl=1.11, wps=23645.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=27900, lr=0.000189321, gnorm=0.324, loss_scale=64, train_wall=228, gb_free=8.8, wall=80064
2022-03-07 11:18:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:18:54 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 14.206 | nll_loss 14.022 | ppl 16636 | wps 45767.5 | wpb 510.9 | bsz 1 | num_updates 27946 | best_loss 8.318
2022-03-07 11:18:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27946 updates
2022-03-07 11:18:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:18:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:18:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 574 @ 27946 updates, score 14.206) (writing took 2.5188232269138098 seconds)
2022-03-07 11:18:56 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-07 11:18:56 | INFO | train | epoch 574 | loss 0.693 | nll_loss 0.154 | ppl 1.11 | wps 24480.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27946 | lr 0.000189165 | gnorm 0.323 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 80187
2022-03-07 11:18:56 | INFO | fairseq.trainer | begin training epoch 575
2022-03-07 11:18:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:20:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:20:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:21:04 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 14.278 | nll_loss 14.096 | ppl 17506.4 | wps 46034 | wpb 510.9 | bsz 1 | num_updates 27994 | best_loss 8.318
2022-03-07 11:21:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27994 updates
2022-03-07 11:21:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:21:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:21:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 575 @ 27994 updates, score 14.278) (writing took 2.5351715479046106 seconds)
2022-03-07 11:21:06 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-07 11:21:06 | INFO | train | epoch 575 | loss 0.692 | nll_loss 0.153 | ppl 1.11 | wps 23943.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 27994 | lr 0.000189002 | gnorm 0.32 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 80317
2022-03-07 11:21:06 | INFO | fairseq.trainer | begin training epoch 576
2022-03-07 11:21:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:21:22 | INFO | train_inner | epoch 576:      6 / 49 loss=0.692, nll_loss=0.153, ppl=1.11, wps=24252.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.321, loss_scale=64, train_wall=228, gb_free=8.8, wall=80332
2022-03-07 11:23:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:23:14 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 14.392 | nll_loss 14.214 | ppl 19000.5 | wps 45574.6 | wpb 510.9 | bsz 1 | num_updates 28043 | best_loss 8.318
2022-03-07 11:23:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28043 updates
2022-03-07 11:23:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:23:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:23:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 576 @ 28043 updates, score 14.392) (writing took 2.5361043605953455 seconds)
2022-03-07 11:23:17 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-07 11:23:17 | INFO | train | epoch 576 | loss 0.693 | nll_loss 0.154 | ppl 1.11 | wps 24409.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28043 | lr 0.000188837 | gnorm 0.323 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 80447
2022-03-07 11:23:17 | INFO | fairseq.trainer | begin training epoch 577
2022-03-07 11:23:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:25:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:25:24 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 14.226 | nll_loss 14.044 | ppl 16893.9 | wps 46097.5 | wpb 510.9 | bsz 1 | num_updates 28092 | best_loss 8.318
2022-03-07 11:25:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28092 updates
2022-03-07 11:25:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:25:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:25:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 577 @ 28092 updates, score 14.226) (writing took 2.5349587462842464 seconds)
2022-03-07 11:25:26 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-07 11:25:26 | INFO | train | epoch 577 | loss 0.692 | nll_loss 0.153 | ppl 1.11 | wps 24509.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28092 | lr 0.000188673 | gnorm 0.324 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 80576
2022-03-07 11:25:26 | INFO | fairseq.trainer | begin training epoch 578
2022-03-07 11:25:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:25:47 | INFO | train_inner | epoch 578:      8 / 49 loss=0.692, nll_loss=0.153, ppl=1.11, wps=24492.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.324, loss_scale=64, train_wall=226, gb_free=8.8, wall=80597
2022-03-07 11:26:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:27:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:27:34 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 14.284 | nll_loss 14.102 | ppl 17583.4 | wps 46121.9 | wpb 510.9 | bsz 1 | num_updates 28140 | best_loss 8.318
2022-03-07 11:27:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28140 updates
2022-03-07 11:27:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:27:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:27:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 578 @ 28140 updates, score 14.284) (writing took 2.5434843450784683 seconds)
2022-03-07 11:27:36 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-07 11:27:36 | INFO | train | epoch 578 | loss 0.692 | nll_loss 0.153 | ppl 1.11 | wps 23941.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 28140 | lr 0.000188512 | gnorm 0.322 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 80706
2022-03-07 11:27:36 | INFO | fairseq.trainer | begin training epoch 579
2022-03-07 11:27:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:29:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:29:43 | INFO | valid | epoch 579 | valid on 'valid' subset | loss 14.242 | nll_loss 14.06 | ppl 17083.9 | wps 45830.1 | wpb 510.9 | bsz 1 | num_updates 28189 | best_loss 8.318
2022-03-07 11:29:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 28189 updates
2022-03-07 11:29:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:29:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:29:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 579 @ 28189 updates, score 14.242) (writing took 2.5306222029030323 seconds)
2022-03-07 11:29:46 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2022-03-07 11:29:46 | INFO | train | epoch 579 | loss 0.692 | nll_loss 0.154 | ppl 1.11 | wps 24490.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28189 | lr 0.000188348 | gnorm 0.32 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 80836
2022-03-07 11:29:46 | INFO | fairseq.trainer | begin training epoch 580
2022-03-07 11:29:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:30:14 | INFO | train_inner | epoch 580:     11 / 49 loss=0.692, nll_loss=0.153, ppl=1.11, wps=24277.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=28200, lr=0.000188311, gnorm=0.322, loss_scale=64, train_wall=228, gb_free=8.8, wall=80864
2022-03-07 11:31:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:31:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:31:53 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 14.3 | nll_loss 14.119 | ppl 17791.9 | wps 45322.6 | wpb 510.9 | bsz 1 | num_updates 28237 | best_loss 8.318
2022-03-07 11:31:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 28237 updates
2022-03-07 11:31:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:31:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:31:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 580 @ 28237 updates, score 14.3) (writing took 2.56822900287807 seconds)
2022-03-07 11:31:56 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2022-03-07 11:31:56 | INFO | train | epoch 580 | loss 0.692 | nll_loss 0.153 | ppl 1.11 | wps 23996.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 28237 | lr 0.000188187 | gnorm 0.329 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 80966
2022-03-07 11:31:56 | INFO | fairseq.trainer | begin training epoch 581
2022-03-07 11:31:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:33:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:34:03 | INFO | valid | epoch 581 | valid on 'valid' subset | loss 14.233 | nll_loss 14.053 | ppl 16993.2 | wps 45533.6 | wpb 510.9 | bsz 1 | num_updates 28286 | best_loss 8.318
2022-03-07 11:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 581 @ 28286 updates
2022-03-07 11:34:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:34:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:34:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 581 @ 28286 updates, score 14.233) (writing took 2.529209528118372 seconds)
2022-03-07 11:34:05 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)
2022-03-07 11:34:05 | INFO | train | epoch 581 | loss 0.691 | nll_loss 0.153 | ppl 1.11 | wps 24508.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28286 | lr 0.000188024 | gnorm 0.321 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 81096
2022-03-07 11:34:05 | INFO | fairseq.trainer | begin training epoch 582
2022-03-07 11:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:34:41 | INFO | train_inner | epoch 582:     14 / 49 loss=0.691, nll_loss=0.153, ppl=1.11, wps=24295.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=28300, lr=0.000187978, gnorm=0.324, loss_scale=32, train_wall=228, gb_free=8.8, wall=81131
2022-03-07 11:36:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:36:13 | INFO | valid | epoch 582 | valid on 'valid' subset | loss 14.305 | nll_loss 14.124 | ppl 17853.6 | wps 45704.2 | wpb 510.9 | bsz 1 | num_updates 28335 | best_loss 8.318
2022-03-07 11:36:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 582 @ 28335 updates
2022-03-07 11:36:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:36:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:36:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 582 @ 28335 updates, score 14.305) (writing took 2.5114170499145985 seconds)
2022-03-07 11:36:15 | INFO | fairseq_cli.train | end of epoch 582 (average epoch stats below)
2022-03-07 11:36:15 | INFO | train | epoch 582 | loss 0.691 | nll_loss 0.152 | ppl 1.11 | wps 24452.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28335 | lr 0.000187862 | gnorm 0.32 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 81226
2022-03-07 11:36:15 | INFO | fairseq.trainer | begin training epoch 583
2022-03-07 11:36:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:36:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:38:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:38:23 | INFO | valid | epoch 583 | valid on 'valid' subset | loss 14.249 | nll_loss 14.067 | ppl 17159.9 | wps 45393.4 | wpb 510.9 | bsz 1 | num_updates 28383 | best_loss 8.318
2022-03-07 11:38:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 583 @ 28383 updates
2022-03-07 11:38:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:38:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:38:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 583 @ 28383 updates, score 14.249) (writing took 2.5094108395278454 seconds)
2022-03-07 11:38:25 | INFO | fairseq_cli.train | end of epoch 583 (average epoch stats below)
2022-03-07 11:38:25 | INFO | train | epoch 583 | loss 0.691 | nll_loss 0.152 | ppl 1.11 | wps 23983.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 28383 | lr 0.000187703 | gnorm 0.325 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 81355
2022-03-07 11:38:25 | INFO | fairseq.trainer | begin training epoch 584
2022-03-07 11:38:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:39:08 | INFO | train_inner | epoch 584:     17 / 49 loss=0.691, nll_loss=0.152, ppl=1.11, wps=24263.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=28400, lr=0.000187647, gnorm=0.323, loss_scale=32, train_wall=228, gb_free=8.8, wall=81398
2022-03-07 11:40:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:40:33 | INFO | valid | epoch 584 | valid on 'valid' subset | loss 14.294 | nll_loss 14.113 | ppl 17720.3 | wps 43911.1 | wpb 510.9 | bsz 1 | num_updates 28432 | best_loss 8.318
2022-03-07 11:40:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 584 @ 28432 updates
2022-03-07 11:40:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:40:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:40:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 584 @ 28432 updates, score 14.294) (writing took 2.499285764992237 seconds)
2022-03-07 11:40:35 | INFO | fairseq_cli.train | end of epoch 584 (average epoch stats below)
2022-03-07 11:40:35 | INFO | train | epoch 584 | loss 0.69 | nll_loss 0.152 | ppl 1.11 | wps 24444.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28432 | lr 0.000187541 | gnorm 0.322 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 81485
2022-03-07 11:40:35 | INFO | fairseq.trainer | begin training epoch 585
2022-03-07 11:40:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:42:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:42:42 | INFO | valid | epoch 585 | valid on 'valid' subset | loss 14.277 | nll_loss 14.095 | ppl 17501.6 | wps 45879.1 | wpb 510.9 | bsz 1 | num_updates 28481 | best_loss 8.318
2022-03-07 11:42:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 585 @ 28481 updates
2022-03-07 11:42:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:42:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:42:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 585 @ 28481 updates, score 14.277) (writing took 2.55829150788486 seconds)
2022-03-07 11:42:45 | INFO | fairseq_cli.train | end of epoch 585 (average epoch stats below)
2022-03-07 11:42:45 | INFO | train | epoch 585 | loss 0.69 | nll_loss 0.152 | ppl 1.11 | wps 24486 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28481 | lr 0.00018738 | gnorm 0.319 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 81615
2022-03-07 11:42:45 | INFO | fairseq.trainer | begin training epoch 586
2022-03-07 11:42:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:43:33 | INFO | train_inner | epoch 586:     19 / 49 loss=0.69, nll_loss=0.152, ppl=1.11, wps=24496.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=28500, lr=0.000187317, gnorm=0.321, loss_scale=64, train_wall=226, gb_free=8.8, wall=81663
2022-03-07 11:44:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:44:52 | INFO | valid | epoch 586 | valid on 'valid' subset | loss 14.228 | nll_loss 14.044 | ppl 16895.3 | wps 45600 | wpb 510.9 | bsz 1 | num_updates 28530 | best_loss 8.318
2022-03-07 11:44:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 586 @ 28530 updates
2022-03-07 11:44:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:44:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:44:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 586 @ 28530 updates, score 14.228) (writing took 2.544726178050041 seconds)
2022-03-07 11:44:55 | INFO | fairseq_cli.train | end of epoch 586 (average epoch stats below)
2022-03-07 11:44:55 | INFO | train | epoch 586 | loss 0.69 | nll_loss 0.152 | ppl 1.11 | wps 24490.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28530 | lr 0.000187219 | gnorm 0.32 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 81745
2022-03-07 11:44:55 | INFO | fairseq.trainer | begin training epoch 587
2022-03-07 11:44:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:46:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:47:02 | INFO | valid | epoch 587 | valid on 'valid' subset | loss 14.322 | nll_loss 14.141 | ppl 18063.2 | wps 45545.3 | wpb 510.9 | bsz 1 | num_updates 28579 | best_loss 8.318
2022-03-07 11:47:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 587 @ 28579 updates
2022-03-07 11:47:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:47:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:47:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 587 @ 28579 updates, score 14.322) (writing took 2.5202539395540953 seconds)
2022-03-07 11:47:05 | INFO | fairseq_cli.train | end of epoch 587 (average epoch stats below)
2022-03-07 11:47:05 | INFO | train | epoch 587 | loss 0.69 | nll_loss 0.152 | ppl 1.11 | wps 24455.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28579 | lr 0.000187058 | gnorm 0.325 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 81875
2022-03-07 11:47:05 | INFO | fairseq.trainer | begin training epoch 588
2022-03-07 11:47:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:47:57 | INFO | train_inner | epoch 588:     21 / 49 loss=0.69, nll_loss=0.152, ppl=1.11, wps=24535.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=28600, lr=0.000186989, gnorm=0.322, loss_scale=64, train_wall=225, gb_free=8.8, wall=81928
2022-03-07 11:48:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:49:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:49:11 | INFO | valid | epoch 588 | valid on 'valid' subset | loss 14.353 | nll_loss 14.171 | ppl 18445.8 | wps 46217.7 | wpb 510.9 | bsz 1 | num_updates 28627 | best_loss 8.318
2022-03-07 11:49:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 588 @ 28627 updates
2022-03-07 11:49:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:49:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:49:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 588 @ 28627 updates, score 14.353) (writing took 2.503631668165326 seconds)
2022-03-07 11:49:13 | INFO | fairseq_cli.train | end of epoch 588 (average epoch stats below)
2022-03-07 11:49:13 | INFO | train | epoch 588 | loss 0.69 | nll_loss 0.152 | ppl 1.11 | wps 24191.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 28627 | lr 0.000186901 | gnorm 0.319 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 82004
2022-03-07 11:49:13 | INFO | fairseq.trainer | begin training epoch 589
2022-03-07 11:49:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:51:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:51:20 | INFO | valid | epoch 589 | valid on 'valid' subset | loss 14.244 | nll_loss 14.062 | ppl 17109.2 | wps 45735.1 | wpb 510.9 | bsz 1 | num_updates 28676 | best_loss 8.318
2022-03-07 11:51:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 589 @ 28676 updates
2022-03-07 11:51:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:51:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:51:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 589 @ 28676 updates, score 14.244) (writing took 2.530484814196825 seconds)
2022-03-07 11:51:22 | INFO | fairseq_cli.train | end of epoch 589 (average epoch stats below)
2022-03-07 11:51:22 | INFO | train | epoch 589 | loss 0.689 | nll_loss 0.151 | ppl 1.11 | wps 24626.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28676 | lr 0.000186741 | gnorm 0.32 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 82133
2022-03-07 11:51:22 | INFO | fairseq.trainer | begin training epoch 590
2022-03-07 11:51:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:52:22 | INFO | train_inner | epoch 590:     24 / 49 loss=0.689, nll_loss=0.151, ppl=1.11, wps=24471.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=28700, lr=0.000186663, gnorm=0.319, loss_scale=64, train_wall=226, gb_free=8.8, wall=82193
2022-03-07 11:53:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:53:28 | INFO | valid | epoch 590 | valid on 'valid' subset | loss 14.288 | nll_loss 14.107 | ppl 17646.6 | wps 46483.5 | wpb 510.9 | bsz 1 | num_updates 28725 | best_loss 8.318
2022-03-07 11:53:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 590 @ 28725 updates
2022-03-07 11:53:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:53:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:53:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 590 @ 28725 updates, score 14.288) (writing took 2.514975879341364 seconds)
2022-03-07 11:53:31 | INFO | fairseq_cli.train | end of epoch 590 (average epoch stats below)
2022-03-07 11:53:31 | INFO | train | epoch 590 | loss 0.689 | nll_loss 0.151 | ppl 1.11 | wps 24719.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28725 | lr 0.000186582 | gnorm 0.319 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 82261
2022-03-07 11:53:31 | INFO | fairseq.trainer | begin training epoch 591
2022-03-07 11:53:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:53:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:55:37 | INFO | valid | epoch 591 | valid on 'valid' subset | loss 14.272 | nll_loss 14.091 | ppl 17454.9 | wps 46694 | wpb 510.9 | bsz 1 | num_updates 28773 | best_loss 8.318
2022-03-07 11:55:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 591 @ 28773 updates
2022-03-07 11:55:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:55:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:55:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 591 @ 28773 updates, score 14.272) (writing took 2.5252521857619286 seconds)
2022-03-07 11:55:40 | INFO | fairseq_cli.train | end of epoch 591 (average epoch stats below)
2022-03-07 11:55:40 | INFO | train | epoch 591 | loss 0.689 | nll_loss 0.151 | ppl 1.11 | wps 24184.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 28773 | lr 0.000186426 | gnorm 0.321 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 82390
2022-03-07 11:55:40 | INFO | fairseq.trainer | begin training epoch 592
2022-03-07 11:55:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:56:47 | INFO | train_inner | epoch 592:     27 / 49 loss=0.689, nll_loss=0.151, ppl=1.11, wps=24505.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=28800, lr=0.000186339, gnorm=0.321, loss_scale=64, train_wall=226, gb_free=8.8, wall=82457
2022-03-07 11:57:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:57:46 | INFO | valid | epoch 592 | valid on 'valid' subset | loss 14.353 | nll_loss 14.172 | ppl 18457.5 | wps 46598.7 | wpb 510.9 | bsz 1 | num_updates 28822 | best_loss 8.318
2022-03-07 11:57:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 592 @ 28822 updates
2022-03-07 11:57:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:57:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:57:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 592 @ 28822 updates, score 14.353) (writing took 2.5171051789075136 seconds)
2022-03-07 11:57:48 | INFO | fairseq_cli.train | end of epoch 592 (average epoch stats below)
2022-03-07 11:57:48 | INFO | train | epoch 592 | loss 0.689 | nll_loss 0.151 | ppl 1.11 | wps 24720.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28822 | lr 0.000186268 | gnorm 0.318 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 82518
2022-03-07 11:57:48 | INFO | fairseq.trainer | begin training epoch 593
2022-03-07 11:57:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:59:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:59:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:59:56 | INFO | valid | epoch 593 | valid on 'valid' subset | loss 14.257 | nll_loss 14.074 | ppl 17247 | wps 44346.5 | wpb 510.9 | bsz 1 | num_updates 28870 | best_loss 8.318
2022-03-07 11:59:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 593 @ 28870 updates
2022-03-07 11:59:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:59:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:59:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 593 @ 28870 updates, score 14.257) (writing took 2.315651999786496 seconds)
2022-03-07 11:59:58 | INFO | fairseq_cli.train | end of epoch 593 (average epoch stats below)
2022-03-07 11:59:58 | INFO | train | epoch 593 | loss 0.688 | nll_loss 0.151 | ppl 1.11 | wps 23902.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 28870 | lr 0.000186113 | gnorm 0.318 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 82649
2022-03-07 11:59:58 | INFO | fairseq.trainer | begin training epoch 594
2022-03-07 11:59:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:01:16 | INFO | train_inner | epoch 594:     30 / 49 loss=0.688, nll_loss=0.151, ppl=1.11, wps=24127.4, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=28900, lr=0.000186016, gnorm=0.318, loss_scale=64, train_wall=230, gb_free=8.8, wall=82726
2022-03-07 12:02:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:02:08 | INFO | valid | epoch 594 | valid on 'valid' subset | loss 14.369 | nll_loss 14.189 | ppl 18680.5 | wps 43864 | wpb 510.9 | bsz 1 | num_updates 28919 | best_loss 8.318
2022-03-07 12:02:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 594 @ 28919 updates
2022-03-07 12:02:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:02:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:02:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 594 @ 28919 updates, score 14.369) (writing took 2.2017067782580853 seconds)
2022-03-07 12:02:11 | INFO | fairseq_cli.train | end of epoch 594 (average epoch stats below)
2022-03-07 12:02:11 | INFO | train | epoch 594 | loss 0.688 | nll_loss 0.151 | ppl 1.11 | wps 24026.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 28919 | lr 0.000185955 | gnorm 0.32 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 82781
2022-03-07 12:02:11 | INFO | fairseq.trainer | begin training epoch 595
2022-03-07 12:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:04:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:04:19 | INFO | valid | epoch 595 | valid on 'valid' subset | loss 14.278 | nll_loss 14.098 | ppl 17540.6 | wps 44312.8 | wpb 510.9 | bsz 1 | num_updates 28968 | best_loss 8.318
2022-03-07 12:04:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 595 @ 28968 updates
2022-03-07 12:04:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:04:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:04:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 595 @ 28968 updates, score 14.278) (writing took 3.1614043917506933 seconds)
2022-03-07 12:04:23 | INFO | fairseq_cli.train | end of epoch 595 (average epoch stats below)
2022-03-07 12:04:23 | INFO | train | epoch 595 | loss 0.688 | nll_loss 0.15 | ppl 1.11 | wps 24096.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 28968 | lr 0.000185798 | gnorm 0.319 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 82913
2022-03-07 12:04:23 | INFO | fairseq.trainer | begin training epoch 596
2022-03-07 12:04:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:05:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:05:47 | INFO | train_inner | epoch 596:     33 / 49 loss=0.688, nll_loss=0.151, ppl=1.11, wps=23957.2, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=29000, lr=0.000185695, gnorm=0.319, loss_scale=64, train_wall=231, gb_free=8.8, wall=82997
2022-03-07 12:06:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:06:31 | INFO | valid | epoch 596 | valid on 'valid' subset | loss 14.333 | nll_loss 14.152 | ppl 18208.5 | wps 43884.8 | wpb 510.9 | bsz 1 | num_updates 29016 | best_loss 8.318
2022-03-07 12:06:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 596 @ 29016 updates
2022-03-07 12:06:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:06:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:06:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 596 @ 29016 updates, score 14.333) (writing took 3.1794412191957235 seconds)
2022-03-07 12:06:35 | INFO | fairseq_cli.train | end of epoch 596 (average epoch stats below)
2022-03-07 12:06:35 | INFO | train | epoch 596 | loss 0.688 | nll_loss 0.15 | ppl 1.11 | wps 23577.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29016 | lr 0.000185644 | gnorm 0.317 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 83045
2022-03-07 12:06:35 | INFO | fairseq.trainer | begin training epoch 597
2022-03-07 12:06:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:08:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:08:44 | INFO | valid | epoch 597 | valid on 'valid' subset | loss 14.306 | nll_loss 14.125 | ppl 17867.4 | wps 42979.7 | wpb 510.9 | bsz 1 | num_updates 29065 | best_loss 8.318
2022-03-07 12:08:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 597 @ 29065 updates
2022-03-07 12:08:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:08:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:08:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 597 @ 29065 updates, score 14.306) (writing took 3.194453140720725 seconds)
2022-03-07 12:08:47 | INFO | fairseq_cli.train | end of epoch 597 (average epoch stats below)
2022-03-07 12:08:47 | INFO | train | epoch 597 | loss 0.687 | nll_loss 0.15 | ppl 1.11 | wps 24017.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29065 | lr 0.000185488 | gnorm 0.316 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 83177
2022-03-07 12:08:47 | INFO | fairseq.trainer | begin training epoch 598
2022-03-07 12:08:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:10:18 | INFO | train_inner | epoch 598:     35 / 49 loss=0.688, nll_loss=0.15, ppl=1.11, wps=23960.2, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=29100, lr=0.000185376, gnorm=0.316, loss_scale=64, train_wall=229, gb_free=8.8, wall=83268
2022-03-07 12:10:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:10:58 | INFO | valid | epoch 598 | valid on 'valid' subset | loss 14.285 | nll_loss 14.104 | ppl 17603.2 | wps 42498.2 | wpb 510.9 | bsz 1 | num_updates 29114 | best_loss 8.318
2022-03-07 12:10:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 598 @ 29114 updates
2022-03-07 12:10:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:11:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:11:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 598 @ 29114 updates, score 14.285) (writing took 2.385687867179513 seconds)
2022-03-07 12:11:00 | INFO | fairseq_cli.train | end of epoch 598 (average epoch stats below)
2022-03-07 12:11:00 | INFO | train | epoch 598 | loss 0.687 | nll_loss 0.15 | ppl 1.11 | wps 23843.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29114 | lr 0.000185331 | gnorm 0.318 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 83310
2022-03-07 12:11:00 | INFO | fairseq.trainer | begin training epoch 599
2022-03-07 12:11:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:11:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:13:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:13:11 | INFO | valid | epoch 599 | valid on 'valid' subset | loss 14.316 | nll_loss 14.137 | ppl 18016.8 | wps 42543 | wpb 510.9 | bsz 1 | num_updates 29162 | best_loss 8.318
2022-03-07 12:13:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 599 @ 29162 updates
2022-03-07 12:13:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:13:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:13:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 599 @ 29162 updates, score 14.316) (writing took 2.461963811889291 seconds)
2022-03-07 12:13:14 | INFO | fairseq_cli.train | end of epoch 599 (average epoch stats below)
2022-03-07 12:13:14 | INFO | train | epoch 599 | loss 0.688 | nll_loss 0.15 | ppl 1.11 | wps 23301 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29162 | lr 0.000185179 | gnorm 0.32 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 83444
2022-03-07 12:13:14 | INFO | fairseq.trainer | begin training epoch 600
2022-03-07 12:13:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:14:51 | INFO | train_inner | epoch 600:     38 / 49 loss=0.687, nll_loss=0.15, ppl=1.11, wps=23691.6, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=29200, lr=0.000185058, gnorm=0.319, loss_scale=64, train_wall=234, gb_free=8.8, wall=83542
2022-03-07 12:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:15:23 | INFO | valid | epoch 600 | valid on 'valid' subset | loss 14.263 | nll_loss 14.081 | ppl 17328.9 | wps 43981.5 | wpb 510.9 | bsz 1 | num_updates 29211 | best_loss 8.318
2022-03-07 12:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 600 @ 29211 updates
2022-03-07 12:15:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:15:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:15:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 600 @ 29211 updates, score 14.263) (writing took 2.4564258623868227 seconds)
2022-03-07 12:15:26 | INFO | fairseq_cli.train | end of epoch 600 (average epoch stats below)
2022-03-07 12:15:26 | INFO | train | epoch 600 | loss 0.687 | nll_loss 0.15 | ppl 1.11 | wps 24049.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29211 | lr 0.000185023 | gnorm 0.316 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 83576
2022-03-07 12:15:26 | INFO | fairseq.trainer | begin training epoch 601
2022-03-07 12:15:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:17:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:17:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:17:36 | INFO | valid | epoch 601 | valid on 'valid' subset | loss 14.264 | nll_loss 14.083 | ppl 17353.2 | wps 43675.5 | wpb 510.9 | bsz 1 | num_updates 29259 | best_loss 8.318
2022-03-07 12:17:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 601 @ 29259 updates
2022-03-07 12:17:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:17:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:17:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 601 @ 29259 updates, score 14.264) (writing took 2.4332397654652596 seconds)
2022-03-07 12:17:39 | INFO | fairseq_cli.train | end of epoch 601 (average epoch stats below)
2022-03-07 12:17:39 | INFO | train | epoch 601 | loss 0.687 | nll_loss 0.15 | ppl 1.11 | wps 23398.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29259 | lr 0.000184872 | gnorm 0.32 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 83709
2022-03-07 12:17:39 | INFO | fairseq.trainer | begin training epoch 602
2022-03-07 12:17:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:19:25 | INFO | train_inner | epoch 602:     41 / 49 loss=0.687, nll_loss=0.15, ppl=1.11, wps=23719.6, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=29300, lr=0.000184742, gnorm=0.319, loss_scale=64, train_wall=234, gb_free=8.8, wall=83815
2022-03-07 12:19:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:19:50 | INFO | valid | epoch 602 | valid on 'valid' subset | loss 14.316 | nll_loss 14.137 | ppl 18013.5 | wps 41944.6 | wpb 510.9 | bsz 1 | num_updates 29308 | best_loss 8.318
2022-03-07 12:19:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 602 @ 29308 updates
2022-03-07 12:19:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 602 @ 29308 updates, score 14.316) (writing took 2.44050670042634 seconds)
2022-03-07 12:19:52 | INFO | fairseq_cli.train | end of epoch 602 (average epoch stats below)
2022-03-07 12:19:52 | INFO | train | epoch 602 | loss 0.687 | nll_loss 0.15 | ppl 1.11 | wps 23869.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29308 | lr 0.000184717 | gnorm 0.319 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 83842
2022-03-07 12:19:52 | INFO | fairseq.trainer | begin training epoch 603
2022-03-07 12:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:21:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:22:03 | INFO | valid | epoch 603 | valid on 'valid' subset | loss 14.305 | nll_loss 14.124 | ppl 17857.2 | wps 42917.9 | wpb 510.9 | bsz 1 | num_updates 29357 | best_loss 8.318
2022-03-07 12:22:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 603 @ 29357 updates
2022-03-07 12:22:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:22:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:22:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 603 @ 29357 updates, score 14.305) (writing took 2.4673424903303385 seconds)
2022-03-07 12:22:06 | INFO | fairseq_cli.train | end of epoch 603 (average epoch stats below)
2022-03-07 12:22:06 | INFO | train | epoch 603 | loss 0.687 | nll_loss 0.149 | ppl 1.11 | wps 23799 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29357 | lr 0.000184563 | gnorm 0.314 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 83976
2022-03-07 12:22:06 | INFO | fairseq.trainer | begin training epoch 604
2022-03-07 12:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:22:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:24:00 | INFO | train_inner | epoch 604:     44 / 49 loss=0.687, nll_loss=0.15, ppl=1.11, wps=23594.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=29400, lr=0.000184428, gnorm=0.317, loss_scale=64, train_wall=235, gb_free=8.8, wall=84090
2022-03-07 12:24:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:24:17 | INFO | valid | epoch 604 | valid on 'valid' subset | loss 14.269 | nll_loss 14.089 | ppl 17421.7 | wps 42769.2 | wpb 510.9 | bsz 1 | num_updates 29405 | best_loss 8.318
2022-03-07 12:24:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 604 @ 29405 updates
2022-03-07 12:24:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:24:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:24:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 604 @ 29405 updates, score 14.269) (writing took 2.494939513504505 seconds)
2022-03-07 12:24:19 | INFO | fairseq_cli.train | end of epoch 604 (average epoch stats below)
2022-03-07 12:24:19 | INFO | train | epoch 604 | loss 0.686 | nll_loss 0.149 | ppl 1.11 | wps 23299.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29405 | lr 0.000184412 | gnorm 0.318 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 84109
2022-03-07 12:24:19 | INFO | fairseq.trainer | begin training epoch 605
2022-03-07 12:24:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:26:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:26:30 | INFO | valid | epoch 605 | valid on 'valid' subset | loss 14.31 | nll_loss 14.128 | ppl 17905 | wps 42459.7 | wpb 510.9 | bsz 1 | num_updates 29454 | best_loss 8.318
2022-03-07 12:26:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 605 @ 29454 updates
2022-03-07 12:26:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:26:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:26:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 605 @ 29454 updates, score 14.31) (writing took 2.4380026645958424 seconds)
2022-03-07 12:26:32 | INFO | fairseq_cli.train | end of epoch 605 (average epoch stats below)
2022-03-07 12:26:32 | INFO | train | epoch 605 | loss 0.686 | nll_loss 0.149 | ppl 1.11 | wps 23864 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29454 | lr 0.000184259 | gnorm 0.321 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 84243
2022-03-07 12:26:32 | INFO | fairseq.trainer | begin training epoch 606
2022-03-07 12:26:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:28:32 | INFO | train_inner | epoch 606:     46 / 49 loss=0.686, nll_loss=0.149, ppl=1.11, wps=23823.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=29500, lr=0.000184115, gnorm=0.321, loss_scale=64, train_wall=232, gb_free=8.8, wall=84362
2022-03-07 12:28:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:28:44 | INFO | valid | epoch 606 | valid on 'valid' subset | loss 14.226 | nll_loss 14.043 | ppl 16883.6 | wps 42802.4 | wpb 510.9 | bsz 1 | num_updates 29503 | best_loss 8.318
2022-03-07 12:28:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 606 @ 29503 updates
2022-03-07 12:28:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:28:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:28:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 606 @ 29503 updates, score 14.226) (writing took 2.477034367620945 seconds)
2022-03-07 12:28:46 | INFO | fairseq_cli.train | end of epoch 606 (average epoch stats below)
2022-03-07 12:28:46 | INFO | train | epoch 606 | loss 0.686 | nll_loss 0.149 | ppl 1.11 | wps 23742 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29503 | lr 0.000184106 | gnorm 0.322 | loss_scale 128 | train_wall 114 | gb_free 8.8 | wall 84376
2022-03-07 12:28:46 | INFO | fairseq.trainer | begin training epoch 607
2022-03-07 12:28:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:28:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:30:57 | INFO | valid | epoch 607 | valid on 'valid' subset | loss 14.331 | nll_loss 14.151 | ppl 18196.8 | wps 42647.7 | wpb 510.9 | bsz 1 | num_updates 29551 | best_loss 8.318
2022-03-07 12:30:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 607 @ 29551 updates
2022-03-07 12:30:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:31:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:31:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 607 @ 29551 updates, score 14.331) (writing took 2.454250928014517 seconds)
2022-03-07 12:31:00 | INFO | fairseq_cli.train | end of epoch 607 (average epoch stats below)
2022-03-07 12:31:00 | INFO | train | epoch 607 | loss 0.685 | nll_loss 0.148 | ppl 1.11 | wps 23275.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29551 | lr 0.000183956 | gnorm 0.315 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 84510
2022-03-07 12:31:00 | INFO | fairseq.trainer | begin training epoch 608
2022-03-07 12:31:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:33:06 | INFO | train_inner | epoch 608:     49 / 49 loss=0.685, nll_loss=0.149, ppl=1.11, wps=23584.6, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=29600, lr=0.000183804, gnorm=0.316, loss_scale=64, train_wall=234, gb_free=8.8, wall=84636
2022-03-07 12:33:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:33:11 | INFO | valid | epoch 608 | valid on 'valid' subset | loss 14.248 | nll_loss 14.068 | ppl 17176.5 | wps 42046.3 | wpb 510.9 | bsz 1 | num_updates 29600 | best_loss 8.318
2022-03-07 12:33:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 608 @ 29600 updates
2022-03-07 12:33:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:33:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:33:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 608 @ 29600 updates, score 14.248) (writing took 2.4516536351293325 seconds)
2022-03-07 12:33:13 | INFO | fairseq_cli.train | end of epoch 608 (average epoch stats below)
2022-03-07 12:33:13 | INFO | train | epoch 608 | loss 0.685 | nll_loss 0.148 | ppl 1.11 | wps 23797.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29600 | lr 0.000183804 | gnorm 0.316 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 84644
2022-03-07 12:33:13 | INFO | fairseq.trainer | begin training epoch 609
2022-03-07 12:33:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:34:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:35:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:35:24 | INFO | valid | epoch 609 | valid on 'valid' subset | loss 14.334 | nll_loss 14.154 | ppl 18235.6 | wps 42450.2 | wpb 510.9 | bsz 1 | num_updates 29648 | best_loss 8.318
2022-03-07 12:35:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 609 @ 29648 updates
2022-03-07 12:35:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:35:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:35:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 609 @ 29648 updates, score 14.334) (writing took 2.4406229816377163 seconds)
2022-03-07 12:35:27 | INFO | fairseq_cli.train | end of epoch 609 (average epoch stats below)
2022-03-07 12:35:27 | INFO | train | epoch 609 | loss 0.685 | nll_loss 0.148 | ppl 1.11 | wps 23343.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29648 | lr 0.000183655 | gnorm 0.317 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 84777
2022-03-07 12:35:27 | INFO | fairseq.trainer | begin training epoch 610
2022-03-07 12:35:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:37:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:37:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:37:38 | INFO | valid | epoch 610 | valid on 'valid' subset | loss 14.254 | nll_loss 14.074 | ppl 17243.8 | wps 42849.6 | wpb 510.9 | bsz 1 | num_updates 29696 | best_loss 8.318
2022-03-07 12:37:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 610 @ 29696 updates
2022-03-07 12:37:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:37:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:37:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 610 @ 29696 updates, score 14.254) (writing took 2.4620513170957565 seconds)
2022-03-07 12:37:40 | INFO | fairseq_cli.train | end of epoch 610 (average epoch stats below)
2022-03-07 12:37:40 | INFO | train | epoch 610 | loss 0.685 | nll_loss 0.148 | ppl 1.11 | wps 23305 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29696 | lr 0.000183506 | gnorm 0.318 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 84911
2022-03-07 12:37:40 | INFO | fairseq.trainer | begin training epoch 611
2022-03-07 12:37:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:37:51 | INFO | train_inner | epoch 611:      4 / 49 loss=0.685, nll_loss=0.148, ppl=1.11, wps=22757.1, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=29700, lr=0.000183494, gnorm=0.317, loss_scale=32, train_wall=237, gb_free=8.8, wall=84921
2022-03-07 12:39:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:39:51 | INFO | valid | epoch 611 | valid on 'valid' subset | loss 14.236 | nll_loss 14.055 | ppl 17015.5 | wps 42435.9 | wpb 510.9 | bsz 1 | num_updates 29745 | best_loss 8.318
2022-03-07 12:39:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 611 @ 29745 updates
2022-03-07 12:39:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:39:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:39:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 611 @ 29745 updates, score 14.236) (writing took 2.440392615273595 seconds)
2022-03-07 12:39:54 | INFO | fairseq_cli.train | end of epoch 611 (average epoch stats below)
2022-03-07 12:39:54 | INFO | train | epoch 611 | loss 0.685 | nll_loss 0.148 | ppl 1.11 | wps 23816.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29745 | lr 0.000183355 | gnorm 0.315 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 85044
2022-03-07 12:39:54 | INFO | fairseq.trainer | begin training epoch 612
2022-03-07 12:39:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:41:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:42:01 | INFO | valid | epoch 612 | valid on 'valid' subset | loss 14.285 | nll_loss 14.104 | ppl 17609.4 | wps 46738.4 | wpb 510.9 | bsz 1 | num_updates 29794 | best_loss 8.318
2022-03-07 12:42:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 612 @ 29794 updates
2022-03-07 12:42:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:42:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:42:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 612 @ 29794 updates, score 14.285) (writing took 2.5523019563406706 seconds)
2022-03-07 12:42:04 | INFO | fairseq_cli.train | end of epoch 612 (average epoch stats below)
2022-03-07 12:42:04 | INFO | train | epoch 612 | loss 0.684 | nll_loss 0.148 | ppl 1.11 | wps 24450.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29794 | lr 0.000183204 | gnorm 0.315 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 85174
2022-03-07 12:42:04 | INFO | fairseq.trainer | begin training epoch 613
2022-03-07 12:42:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:42:19 | INFO | train_inner | epoch 613:      6 / 49 loss=0.684, nll_loss=0.148, ppl=1.11, wps=24199.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=29800, lr=0.000183186, gnorm=0.315, loss_scale=32, train_wall=229, gb_free=8.8, wall=85189
2022-03-07 12:44:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:44:10 | INFO | valid | epoch 613 | valid on 'valid' subset | loss 14.284 | nll_loss 14.104 | ppl 17613.7 | wps 45500.7 | wpb 510.9 | bsz 1 | num_updates 29843 | best_loss 8.318
2022-03-07 12:44:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 613 @ 29843 updates
2022-03-07 12:44:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:44:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:44:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 613 @ 29843 updates, score 14.284) (writing took 2.5258157588541508 seconds)
2022-03-07 12:44:12 | INFO | fairseq_cli.train | end of epoch 613 (average epoch stats below)
2022-03-07 12:44:12 | INFO | train | epoch 613 | loss 0.684 | nll_loss 0.148 | ppl 1.11 | wps 24714.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29843 | lr 0.000183054 | gnorm 0.315 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 85303
2022-03-07 12:44:12 | INFO | fairseq.trainer | begin training epoch 614
2022-03-07 12:44:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:46:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:46:18 | INFO | valid | epoch 614 | valid on 'valid' subset | loss 14.239 | nll_loss 14.061 | ppl 17089.4 | wps 46710.2 | wpb 510.9 | bsz 1 | num_updates 29892 | best_loss 8.318
2022-03-07 12:46:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 614 @ 29892 updates
2022-03-07 12:46:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:46:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:46:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 614 @ 29892 updates, score 14.239) (writing took 2.507679831236601 seconds)
2022-03-07 12:46:21 | INFO | fairseq_cli.train | end of epoch 614 (average epoch stats below)
2022-03-07 12:46:21 | INFO | train | epoch 614 | loss 0.684 | nll_loss 0.148 | ppl 1.11 | wps 24733.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29892 | lr 0.000182904 | gnorm 0.316 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 85431
2022-03-07 12:46:21 | INFO | fairseq.trainer | begin training epoch 615
2022-03-07 12:46:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:46:41 | INFO | train_inner | epoch 615:      8 / 49 loss=0.684, nll_loss=0.148, ppl=1.11, wps=24747.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=29900, lr=0.000182879, gnorm=0.316, loss_scale=64, train_wall=223, gb_free=8.8, wall=85451
2022-03-07 12:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:48:27 | INFO | valid | epoch 615 | valid on 'valid' subset | loss 14.302 | nll_loss 14.123 | ppl 17838.5 | wps 45975.5 | wpb 510.9 | bsz 1 | num_updates 29941 | best_loss 8.318
2022-03-07 12:48:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 615 @ 29941 updates
2022-03-07 12:48:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:48:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:48:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 615 @ 29941 updates, score 14.302) (writing took 2.5245343055576086 seconds)
2022-03-07 12:48:30 | INFO | fairseq_cli.train | end of epoch 615 (average epoch stats below)
2022-03-07 12:48:30 | INFO | train | epoch 615 | loss 0.684 | nll_loss 0.147 | ppl 1.11 | wps 24699.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29941 | lr 0.000182754 | gnorm 0.315 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 85560
2022-03-07 12:48:30 | INFO | fairseq.trainer | begin training epoch 616
2022-03-07 12:48:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:48:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:50:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:50:36 | INFO | valid | epoch 616 | valid on 'valid' subset | loss 14.263 | nll_loss 14.082 | ppl 17342.1 | wps 46556 | wpb 510.9 | bsz 1 | num_updates 29989 | best_loss 8.318
2022-03-07 12:50:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 616 @ 29989 updates
2022-03-07 12:50:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:50:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:50:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 616 @ 29989 updates, score 14.263) (writing took 2.527655355632305 seconds)
2022-03-07 12:50:38 | INFO | fairseq_cli.train | end of epoch 616 (average epoch stats below)
2022-03-07 12:50:38 | INFO | train | epoch 616 | loss 0.684 | nll_loss 0.147 | ppl 1.11 | wps 24188.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 29989 | lr 0.000182608 | gnorm 0.316 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 85689
2022-03-07 12:50:38 | INFO | fairseq.trainer | begin training epoch 617
2022-03-07 12:50:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:51:06 | INFO | train_inner | epoch 617:     11 / 49 loss=0.684, nll_loss=0.147, ppl=1.11, wps=24501.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=30000, lr=0.000182574, gnorm=0.315, loss_scale=64, train_wall=226, gb_free=8.8, wall=85716
2022-03-07 12:52:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:52:44 | INFO | valid | epoch 617 | valid on 'valid' subset | loss 14.239 | nll_loss 14.06 | ppl 17075.9 | wps 46422.7 | wpb 510.9 | bsz 1 | num_updates 30038 | best_loss 8.318
2022-03-07 12:52:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 617 @ 30038 updates
2022-03-07 12:52:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:52:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:52:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 617 @ 30038 updates, score 14.239) (writing took 2.549666367471218 seconds)
2022-03-07 12:52:47 | INFO | fairseq_cli.train | end of epoch 617 (average epoch stats below)
2022-03-07 12:52:47 | INFO | train | epoch 617 | loss 0.684 | nll_loss 0.147 | ppl 1.11 | wps 24711.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30038 | lr 0.000182459 | gnorm 0.315 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 85817
2022-03-07 12:52:47 | INFO | fairseq.trainer | begin training epoch 618
2022-03-07 12:52:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:54:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:54:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:54:53 | INFO | valid | epoch 618 | valid on 'valid' subset | loss 14.212 | nll_loss 14.03 | ppl 16730.1 | wps 46656.1 | wpb 510.9 | bsz 1 | num_updates 30086 | best_loss 8.318
2022-03-07 12:54:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 618 @ 30086 updates
2022-03-07 12:54:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:54:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:54:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 618 @ 30086 updates, score 14.212) (writing took 2.520220885053277 seconds)
2022-03-07 12:54:55 | INFO | fairseq_cli.train | end of epoch 618 (average epoch stats below)
2022-03-07 12:54:55 | INFO | train | epoch 618 | loss 0.683 | nll_loss 0.147 | ppl 1.11 | wps 24199.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30086 | lr 0.000182313 | gnorm 0.315 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 85946
2022-03-07 12:54:55 | INFO | fairseq.trainer | begin training epoch 619
2022-03-07 12:54:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:55:31 | INFO | train_inner | epoch 619:     14 / 49 loss=0.683, nll_loss=0.147, ppl=1.11, wps=24495.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30100, lr=0.000182271, gnorm=0.314, loss_scale=64, train_wall=226, gb_free=8.8, wall=85981
2022-03-07 12:56:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:57:02 | INFO | valid | epoch 619 | valid on 'valid' subset | loss 14.181 | nll_loss 13.999 | ppl 16374.7 | wps 46662.1 | wpb 510.9 | bsz 1 | num_updates 30135 | best_loss 8.318
2022-03-07 12:57:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 619 @ 30135 updates
2022-03-07 12:57:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:57:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:57:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 619 @ 30135 updates, score 14.181) (writing took 2.52736509218812 seconds)
2022-03-07 12:57:04 | INFO | fairseq_cli.train | end of epoch 619 (average epoch stats below)
2022-03-07 12:57:04 | INFO | train | epoch 619 | loss 0.683 | nll_loss 0.147 | ppl 1.11 | wps 24709.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30135 | lr 0.000182165 | gnorm 0.31 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 86074
2022-03-07 12:57:04 | INFO | fairseq.trainer | begin training epoch 620
2022-03-07 12:57:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:59:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:59:10 | INFO | valid | epoch 620 | valid on 'valid' subset | loss 14.317 | nll_loss 14.139 | ppl 18037.6 | wps 45138.1 | wpb 510.9 | bsz 1 | num_updates 30184 | best_loss 8.318
2022-03-07 12:59:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 620 @ 30184 updates
2022-03-07 12:59:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:59:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:59:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 620 @ 30184 updates, score 14.317) (writing took 2.5235954262316227 seconds)
2022-03-07 12:59:13 | INFO | fairseq_cli.train | end of epoch 620 (average epoch stats below)
2022-03-07 12:59:13 | INFO | train | epoch 620 | loss 0.683 | nll_loss 0.147 | ppl 1.11 | wps 24685.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30184 | lr 0.000182017 | gnorm 0.315 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 86203
2022-03-07 12:59:13 | INFO | fairseq.trainer | begin training epoch 621
2022-03-07 12:59:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:59:53 | INFO | train_inner | epoch 621:     16 / 49 loss=0.683, nll_loss=0.147, ppl=1.11, wps=24726.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30200, lr=0.000181969, gnorm=0.312, loss_scale=128, train_wall=223, gb_free=8.8, wall=86243
2022-03-07 12:59:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:01:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:01:19 | INFO | valid | epoch 621 | valid on 'valid' subset | loss 14.235 | nll_loss 14.054 | ppl 17006.1 | wps 46168.5 | wpb 510.9 | bsz 1 | num_updates 30232 | best_loss 8.318
2022-03-07 13:01:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 621 @ 30232 updates
2022-03-07 13:01:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:01:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:01:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 621 @ 30232 updates, score 14.235) (writing took 2.5394627042114735 seconds)
2022-03-07 13:01:21 | INFO | fairseq_cli.train | end of epoch 621 (average epoch stats below)
2022-03-07 13:01:21 | INFO | train | epoch 621 | loss 0.683 | nll_loss 0.147 | ppl 1.11 | wps 24189.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30232 | lr 0.000181872 | gnorm 0.315 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 86332
2022-03-07 13:01:21 | INFO | fairseq.trainer | begin training epoch 622
2022-03-07 13:01:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:02:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:03:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:03:27 | INFO | valid | epoch 622 | valid on 'valid' subset | loss 14.276 | nll_loss 14.096 | ppl 17512.8 | wps 46153.5 | wpb 510.9 | bsz 1 | num_updates 30280 | best_loss 8.318
2022-03-07 13:03:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 622 @ 30280 updates
2022-03-07 13:03:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:03:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:03:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 622 @ 30280 updates, score 14.276) (writing took 2.5253815203905106 seconds)
2022-03-07 13:03:30 | INFO | fairseq_cli.train | end of epoch 622 (average epoch stats below)
2022-03-07 13:03:30 | INFO | train | epoch 622 | loss 0.682 | nll_loss 0.146 | ppl 1.11 | wps 24223.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30280 | lr 0.000181728 | gnorm 0.31 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 86460
2022-03-07 13:03:30 | INFO | fairseq.trainer | begin training epoch 623
2022-03-07 13:03:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:04:20 | INFO | train_inner | epoch 623:     20 / 49 loss=0.683, nll_loss=0.147, ppl=1.11, wps=24295.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=30300, lr=0.000181668, gnorm=0.313, loss_scale=32, train_wall=228, gb_free=8.8, wall=86510
2022-03-07 13:05:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:05:36 | INFO | valid | epoch 623 | valid on 'valid' subset | loss 14.276 | nll_loss 14.096 | ppl 17510.8 | wps 46565.5 | wpb 510.9 | bsz 1 | num_updates 30329 | best_loss 8.318
2022-03-07 13:05:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 623 @ 30329 updates
2022-03-07 13:05:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:05:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:05:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 623 @ 30329 updates, score 14.276) (writing took 2.5231240447610617 seconds)
2022-03-07 13:05:39 | INFO | fairseq_cli.train | end of epoch 623 (average epoch stats below)
2022-03-07 13:05:39 | INFO | train | epoch 623 | loss 0.682 | nll_loss 0.146 | ppl 1.11 | wps 24725.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30329 | lr 0.000181581 | gnorm 0.313 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 86589
2022-03-07 13:05:39 | INFO | fairseq.trainer | begin training epoch 624
2022-03-07 13:05:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:07:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:07:45 | INFO | valid | epoch 624 | valid on 'valid' subset | loss 14.355 | nll_loss 14.178 | ppl 18536.3 | wps 46481.7 | wpb 510.9 | bsz 1 | num_updates 30378 | best_loss 8.318
2022-03-07 13:07:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 624 @ 30378 updates
2022-03-07 13:07:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:07:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:07:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 624 @ 30378 updates, score 14.355) (writing took 2.525804629549384 seconds)
2022-03-07 13:07:47 | INFO | fairseq_cli.train | end of epoch 624 (average epoch stats below)
2022-03-07 13:07:47 | INFO | train | epoch 624 | loss 0.682 | nll_loss 0.146 | ppl 1.11 | wps 24717 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30378 | lr 0.000181435 | gnorm 0.312 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 86717
2022-03-07 13:07:47 | INFO | fairseq.trainer | begin training epoch 625
2022-03-07 13:07:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:08:42 | INFO | train_inner | epoch 625:     22 / 49 loss=0.682, nll_loss=0.146, ppl=1.11, wps=24728.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=30400, lr=0.000181369, gnorm=0.312, loss_scale=64, train_wall=224, gb_free=8.8, wall=86773
2022-03-07 13:09:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:09:53 | INFO | valid | epoch 625 | valid on 'valid' subset | loss 14.265 | nll_loss 14.085 | ppl 17372.6 | wps 45958.1 | wpb 510.9 | bsz 1 | num_updates 30427 | best_loss 8.318
2022-03-07 13:09:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 625 @ 30427 updates
2022-03-07 13:09:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:09:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:09:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 625 @ 30427 updates, score 14.265) (writing took 2.523856408894062 seconds)
2022-03-07 13:09:56 | INFO | fairseq_cli.train | end of epoch 625 (average epoch stats below)
2022-03-07 13:09:56 | INFO | train | epoch 625 | loss 0.682 | nll_loss 0.146 | ppl 1.11 | wps 24656.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30427 | lr 0.000181289 | gnorm 0.313 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 86846
2022-03-07 13:09:56 | INFO | fairseq.trainer | begin training epoch 626
2022-03-07 13:09:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:11:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:12:02 | INFO | valid | epoch 626 | valid on 'valid' subset | loss 14.372 | nll_loss 14.195 | ppl 18751.4 | wps 46690.4 | wpb 510.9 | bsz 1 | num_updates 30476 | best_loss 8.318
2022-03-07 13:12:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 626 @ 30476 updates
2022-03-07 13:12:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:12:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:12:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 626 @ 30476 updates, score 14.372) (writing took 2.5447626896202564 seconds)
2022-03-07 13:12:05 | INFO | fairseq_cli.train | end of epoch 626 (average epoch stats below)
2022-03-07 13:12:05 | INFO | train | epoch 626 | loss 0.682 | nll_loss 0.146 | ppl 1.11 | wps 24717.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30476 | lr 0.000181143 | gnorm 0.315 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 86975
2022-03-07 13:12:05 | INFO | fairseq.trainer | begin training epoch 627
2022-03-07 13:12:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:13:05 | INFO | train_inner | epoch 627:     24 / 49 loss=0.682, nll_loss=0.146, ppl=1.11, wps=24723.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=30500, lr=0.000181071, gnorm=0.313, loss_scale=64, train_wall=224, gb_free=8.8, wall=87035
2022-03-07 13:13:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:13:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:14:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:14:11 | INFO | valid | epoch 627 | valid on 'valid' subset | loss 14.174 | nll_loss 13.993 | ppl 16302.2 | wps 45642.2 | wpb 510.9 | bsz 1 | num_updates 30523 | best_loss 8.318
2022-03-07 13:14:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 627 @ 30523 updates
2022-03-07 13:14:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:14:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:14:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 627 @ 30523 updates, score 14.174) (writing took 2.512258719652891 seconds)
2022-03-07 13:14:13 | INFO | fairseq_cli.train | end of epoch 627 (average epoch stats below)
2022-03-07 13:14:13 | INFO | train | epoch 627 | loss 0.681 | nll_loss 0.145 | ppl 1.11 | wps 23668.2 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 30523 | lr 0.000181003 | gnorm 0.311 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 87104
2022-03-07 13:14:13 | INFO | fairseq.trainer | begin training epoch 628
2022-03-07 13:14:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:16:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:16:19 | INFO | valid | epoch 628 | valid on 'valid' subset | loss 14.295 | nll_loss 14.115 | ppl 17743.8 | wps 46642.4 | wpb 510.9 | bsz 1 | num_updates 30572 | best_loss 8.318
2022-03-07 13:16:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 628 @ 30572 updates
2022-03-07 13:16:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:16:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:16:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 628 @ 30572 updates, score 14.295) (writing took 2.5295853856951 seconds)
2022-03-07 13:16:22 | INFO | fairseq_cli.train | end of epoch 628 (average epoch stats below)
2022-03-07 13:16:22 | INFO | train | epoch 628 | loss 0.682 | nll_loss 0.146 | ppl 1.11 | wps 24726.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30572 | lr 0.000180858 | gnorm 0.312 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 87232
2022-03-07 13:16:22 | INFO | fairseq.trainer | begin training epoch 629
2022-03-07 13:16:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:17:32 | INFO | train_inner | epoch 629:     28 / 49 loss=0.682, nll_loss=0.146, ppl=1.11, wps=24272.8, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=30600, lr=0.000180775, gnorm=0.312, loss_scale=32, train_wall=228, gb_free=8.8, wall=87302
2022-03-07 13:18:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:18:28 | INFO | valid | epoch 629 | valid on 'valid' subset | loss 14.272 | nll_loss 14.093 | ppl 17469.8 | wps 46083.8 | wpb 510.9 | bsz 1 | num_updates 30621 | best_loss 8.318
2022-03-07 13:18:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 629 @ 30621 updates
2022-03-07 13:18:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:18:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:18:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 629 @ 30621 updates, score 14.272) (writing took 2.529573690146208 seconds)
2022-03-07 13:18:30 | INFO | fairseq_cli.train | end of epoch 629 (average epoch stats below)
2022-03-07 13:18:30 | INFO | train | epoch 629 | loss 0.681 | nll_loss 0.146 | ppl 1.11 | wps 24703.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30621 | lr 0.000180713 | gnorm 0.311 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 87361
2022-03-07 13:18:30 | INFO | fairseq.trainer | begin training epoch 630
2022-03-07 13:18:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:20:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:20:37 | INFO | valid | epoch 630 | valid on 'valid' subset | loss 14.247 | nll_loss 14.067 | ppl 17165.1 | wps 46692.7 | wpb 510.9 | bsz 1 | num_updates 30670 | best_loss 8.318
2022-03-07 13:20:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 630 @ 30670 updates
2022-03-07 13:20:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:20:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:20:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 630 @ 30670 updates, score 14.247) (writing took 2.527213394641876 seconds)
2022-03-07 13:20:39 | INFO | fairseq_cli.train | end of epoch 630 (average epoch stats below)
2022-03-07 13:20:39 | INFO | train | epoch 630 | loss 0.681 | nll_loss 0.145 | ppl 1.11 | wps 24688 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30670 | lr 0.000180569 | gnorm 0.31 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 87489
2022-03-07 13:20:39 | INFO | fairseq.trainer | begin training epoch 631
2022-03-07 13:20:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:21:54 | INFO | train_inner | epoch 631:     30 / 49 loss=0.681, nll_loss=0.145, ppl=1.11, wps=24736.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30700, lr=0.000180481, gnorm=0.31, loss_scale=64, train_wall=223, gb_free=8.8, wall=87565
2022-03-07 13:22:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:22:45 | INFO | valid | epoch 631 | valid on 'valid' subset | loss 14.37 | nll_loss 14.192 | ppl 18711.2 | wps 46337.5 | wpb 510.9 | bsz 1 | num_updates 30719 | best_loss 8.318
2022-03-07 13:22:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 631 @ 30719 updates
2022-03-07 13:22:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:22:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:22:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 631 @ 30719 updates, score 14.37) (writing took 2.5269058477133512 seconds)
2022-03-07 13:22:48 | INFO | fairseq_cli.train | end of epoch 631 (average epoch stats below)
2022-03-07 13:22:48 | INFO | train | epoch 631 | loss 0.681 | nll_loss 0.145 | ppl 1.11 | wps 24731.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30719 | lr 0.000180425 | gnorm 0.312 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 87618
2022-03-07 13:22:48 | INFO | fairseq.trainer | begin training epoch 632
2022-03-07 13:22:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:24:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:24:54 | INFO | valid | epoch 632 | valid on 'valid' subset | loss 14.162 | nll_loss 13.98 | ppl 16159.3 | wps 46612.3 | wpb 510.9 | bsz 1 | num_updates 30768 | best_loss 8.318
2022-03-07 13:24:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 632 @ 30768 updates
2022-03-07 13:24:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:24:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:24:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 632 @ 30768 updates, score 14.162) (writing took 2.5279655437916517 seconds)
2022-03-07 13:24:57 | INFO | fairseq_cli.train | end of epoch 632 (average epoch stats below)
2022-03-07 13:24:57 | INFO | train | epoch 632 | loss 0.68 | nll_loss 0.145 | ppl 1.11 | wps 24665.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30768 | lr 0.000180281 | gnorm 0.313 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 87747
2022-03-07 13:24:57 | INFO | fairseq.trainer | begin training epoch 633
2022-03-07 13:24:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:25:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:25:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:26:22 | INFO | train_inner | epoch 633:     34 / 49 loss=0.681, nll_loss=0.145, ppl=1.11, wps=24256.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=30800, lr=0.000180187, gnorm=0.313, loss_scale=32, train_wall=228, gb_free=8.8, wall=87832
2022-03-07 13:26:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:27:03 | INFO | valid | epoch 633 | valid on 'valid' subset | loss 14.216 | nll_loss 14.037 | ppl 16807 | wps 46572.1 | wpb 510.9 | bsz 1 | num_updates 30815 | best_loss 8.318
2022-03-07 13:27:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 633 @ 30815 updates
2022-03-07 13:27:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:27:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:27:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 633 @ 30815 updates, score 14.216) (writing took 2.549854727461934 seconds)
2022-03-07 13:27:05 | INFO | fairseq_cli.train | end of epoch 633 (average epoch stats below)
2022-03-07 13:27:05 | INFO | train | epoch 633 | loss 0.68 | nll_loss 0.145 | ppl 1.11 | wps 23681.2 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 30815 | lr 0.000180144 | gnorm 0.313 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 87876
2022-03-07 13:27:05 | INFO | fairseq.trainer | begin training epoch 634
2022-03-07 13:27:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:29:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:29:11 | INFO | valid | epoch 634 | valid on 'valid' subset | loss 14.251 | nll_loss 14.072 | ppl 17221.5 | wps 46620.9 | wpb 510.9 | bsz 1 | num_updates 30864 | best_loss 8.318
2022-03-07 13:29:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 634 @ 30864 updates
2022-03-07 13:29:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:29:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:29:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 634 @ 30864 updates, score 14.251) (writing took 2.551569152623415 seconds)
2022-03-07 13:29:14 | INFO | fairseq_cli.train | end of epoch 634 (average epoch stats below)
2022-03-07 13:29:14 | INFO | train | epoch 634 | loss 0.68 | nll_loss 0.145 | ppl 1.11 | wps 24673.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30864 | lr 0.000180001 | gnorm 0.312 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 88004
2022-03-07 13:29:14 | INFO | fairseq.trainer | begin training epoch 635
2022-03-07 13:29:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:30:44 | INFO | train_inner | epoch 635:     36 / 49 loss=0.68, nll_loss=0.144, ppl=1.11, wps=24726.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30900, lr=0.000179896, gnorm=0.311, loss_scale=32, train_wall=224, gb_free=8.8, wall=88094
2022-03-07 13:31:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:31:20 | INFO | valid | epoch 635 | valid on 'valid' subset | loss 14.325 | nll_loss 14.145 | ppl 18117.9 | wps 46649.3 | wpb 510.9 | bsz 1 | num_updates 30913 | best_loss 8.318
2022-03-07 13:31:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 635 @ 30913 updates
2022-03-07 13:31:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:31:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:31:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 635 @ 30913 updates, score 14.325) (writing took 2.5352353043854237 seconds)
2022-03-07 13:31:23 | INFO | fairseq_cli.train | end of epoch 635 (average epoch stats below)
2022-03-07 13:31:23 | INFO | train | epoch 635 | loss 0.68 | nll_loss 0.144 | ppl 1.11 | wps 24733.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30913 | lr 0.000179858 | gnorm 0.311 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 88133
2022-03-07 13:31:23 | INFO | fairseq.trainer | begin training epoch 636
2022-03-07 13:31:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:33:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:33:29 | INFO | valid | epoch 636 | valid on 'valid' subset | loss 14.232 | nll_loss 14.052 | ppl 16987.6 | wps 45584.7 | wpb 510.9 | bsz 1 | num_updates 30962 | best_loss 8.318
2022-03-07 13:33:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 636 @ 30962 updates
2022-03-07 13:33:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:33:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:33:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 636 @ 30962 updates, score 14.232) (writing took 2.5291601940989494 seconds)
2022-03-07 13:33:31 | INFO | fairseq_cli.train | end of epoch 636 (average epoch stats below)
2022-03-07 13:33:31 | INFO | train | epoch 636 | loss 0.68 | nll_loss 0.144 | ppl 1.11 | wps 24688.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30962 | lr 0.000179715 | gnorm 0.31 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 88262
2022-03-07 13:33:31 | INFO | fairseq.trainer | begin training epoch 637
2022-03-07 13:33:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:35:06 | INFO | train_inner | epoch 637:     38 / 49 loss=0.68, nll_loss=0.144, ppl=1.11, wps=24730.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31000, lr=0.000179605, gnorm=0.31, loss_scale=64, train_wall=223, gb_free=8.8, wall=88357
2022-03-07 13:35:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:35:37 | INFO | valid | epoch 637 | valid on 'valid' subset | loss 14.298 | nll_loss 14.117 | ppl 17768.9 | wps 46130.5 | wpb 510.9 | bsz 1 | num_updates 31011 | best_loss 8.318
2022-03-07 13:35:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 637 @ 31011 updates
2022-03-07 13:35:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:35:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:35:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 637 @ 31011 updates, score 14.298) (writing took 2.5232098139822483 seconds)
2022-03-07 13:35:40 | INFO | fairseq_cli.train | end of epoch 637 (average epoch stats below)
2022-03-07 13:35:40 | INFO | train | epoch 637 | loss 0.68 | nll_loss 0.144 | ppl 1.11 | wps 24686.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31011 | lr 0.000179573 | gnorm 0.309 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 88390
2022-03-07 13:35:40 | INFO | fairseq.trainer | begin training epoch 638
2022-03-07 13:35:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:36:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:37:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:37:46 | INFO | valid | epoch 638 | valid on 'valid' subset | loss 14.188 | nll_loss 14.007 | ppl 16467.5 | wps 46501.4 | wpb 510.9 | bsz 1 | num_updates 31059 | best_loss 8.318
2022-03-07 13:37:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 638 @ 31059 updates
2022-03-07 13:37:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:37:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:37:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 638 @ 31059 updates, score 14.188) (writing took 2.5150238517671824 seconds)
2022-03-07 13:37:49 | INFO | fairseq_cli.train | end of epoch 638 (average epoch stats below)
2022-03-07 13:37:49 | INFO | train | epoch 638 | loss 0.679 | nll_loss 0.144 | ppl 1.11 | wps 24205.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31059 | lr 0.000179435 | gnorm 0.31 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 88519
2022-03-07 13:37:49 | INFO | fairseq.trainer | begin training epoch 639
2022-03-07 13:37:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:39:31 | INFO | train_inner | epoch 639:     41 / 49 loss=0.679, nll_loss=0.144, ppl=1.11, wps=24486.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31100, lr=0.000179316, gnorm=0.31, loss_scale=64, train_wall=226, gb_free=8.8, wall=88622
2022-03-07 13:39:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:39:55 | INFO | valid | epoch 639 | valid on 'valid' subset | loss 14.196 | nll_loss 14.015 | ppl 16552.7 | wps 46127.2 | wpb 510.9 | bsz 1 | num_updates 31108 | best_loss 8.318
2022-03-07 13:39:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 639 @ 31108 updates
2022-03-07 13:39:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:39:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:39:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 639 @ 31108 updates, score 14.196) (writing took 2.5365588404238224 seconds)
2022-03-07 13:39:57 | INFO | fairseq_cli.train | end of epoch 639 (average epoch stats below)
2022-03-07 13:39:57 | INFO | train | epoch 639 | loss 0.679 | nll_loss 0.144 | ppl 1.11 | wps 24682.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31108 | lr 0.000179293 | gnorm 0.31 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 88648
2022-03-07 13:39:57 | INFO | fairseq.trainer | begin training epoch 640
2022-03-07 13:39:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:42:03 | INFO | valid | epoch 640 | valid on 'valid' subset | loss 14.193 | nll_loss 14.014 | ppl 16545 | wps 46640 | wpb 510.9 | bsz 1 | num_updates 31157 | best_loss 8.318
2022-03-07 13:42:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 640 @ 31157 updates
2022-03-07 13:42:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:42:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:42:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 640 @ 31157 updates, score 14.193) (writing took 2.550035146996379 seconds)
2022-03-07 13:42:06 | INFO | fairseq_cli.train | end of epoch 640 (average epoch stats below)
2022-03-07 13:42:06 | INFO | train | epoch 640 | loss 0.679 | nll_loss 0.144 | ppl 1.1 | wps 24691.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31157 | lr 0.000179152 | gnorm 0.307 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 88776
2022-03-07 13:42:06 | INFO | fairseq.trainer | begin training epoch 641
2022-03-07 13:42:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:42:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:43:56 | INFO | train_inner | epoch 641:     44 / 49 loss=0.679, nll_loss=0.144, ppl=1.11, wps=24493, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=31200, lr=0.000179029, gnorm=0.308, loss_scale=64, train_wall=226, gb_free=8.8, wall=88886
2022-03-07 13:44:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:44:12 | INFO | valid | epoch 641 | valid on 'valid' subset | loss 14.225 | nll_loss 14.046 | ppl 16909 | wps 46455.6 | wpb 510.9 | bsz 1 | num_updates 31205 | best_loss 8.318
2022-03-07 13:44:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 641 @ 31205 updates
2022-03-07 13:44:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:44:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:44:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 641 @ 31205 updates, score 14.225) (writing took 2.527903852984309 seconds)
2022-03-07 13:44:15 | INFO | fairseq_cli.train | end of epoch 641 (average epoch stats below)
2022-03-07 13:44:15 | INFO | train | epoch 641 | loss 0.679 | nll_loss 0.144 | ppl 1.1 | wps 24194.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31205 | lr 0.000179014 | gnorm 0.309 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 88905
2022-03-07 13:44:15 | INFO | fairseq.trainer | begin training epoch 642
2022-03-07 13:44:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:46:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:46:21 | INFO | valid | epoch 642 | valid on 'valid' subset | loss 14.316 | nll_loss 14.139 | ppl 18036.2 | wps 46507.5 | wpb 510.9 | bsz 1 | num_updates 31254 | best_loss 8.318
2022-03-07 13:46:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 642 @ 31254 updates
2022-03-07 13:46:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:46:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:46:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 642 @ 31254 updates, score 14.316) (writing took 2.5543639808893204 seconds)
2022-03-07 13:46:23 | INFO | fairseq_cli.train | end of epoch 642 (average epoch stats below)
2022-03-07 13:46:23 | INFO | train | epoch 642 | loss 0.679 | nll_loss 0.144 | ppl 1.1 | wps 24712.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31254 | lr 0.000178874 | gnorm 0.307 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 89034
2022-03-07 13:46:23 | INFO | fairseq.trainer | begin training epoch 643
2022-03-07 13:46:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:48:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:48:21 | INFO | train_inner | epoch 643:     47 / 49 loss=0.678, nll_loss=0.144, ppl=1.1, wps=24495.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=31300, lr=0.000178743, gnorm=0.307, loss_scale=64, train_wall=226, gb_free=8.8, wall=89151
2022-03-07 13:48:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:48:30 | INFO | valid | epoch 643 | valid on 'valid' subset | loss 14.309 | nll_loss 14.131 | ppl 17938.9 | wps 45448.3 | wpb 510.9 | bsz 1 | num_updates 31302 | best_loss 8.318
2022-03-07 13:48:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 643 @ 31302 updates
2022-03-07 13:48:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:48:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:48:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 643 @ 31302 updates, score 14.309) (writing took 2.506342427805066 seconds)
2022-03-07 13:48:32 | INFO | fairseq_cli.train | end of epoch 643 (average epoch stats below)
2022-03-07 13:48:32 | INFO | train | epoch 643 | loss 0.678 | nll_loss 0.143 | ppl 1.1 | wps 24166.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31302 | lr 0.000178737 | gnorm 0.306 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 89162
2022-03-07 13:48:32 | INFO | fairseq.trainer | begin training epoch 644
2022-03-07 13:48:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:50:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:50:38 | INFO | valid | epoch 644 | valid on 'valid' subset | loss 14.246 | nll_loss 14.067 | ppl 17163.2 | wps 46592.7 | wpb 510.9 | bsz 1 | num_updates 31351 | best_loss 8.318
2022-03-07 13:50:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 644 @ 31351 updates
2022-03-07 13:50:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:50:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:50:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 644 @ 31351 updates, score 14.246) (writing took 2.5162505973130465 seconds)
2022-03-07 13:50:41 | INFO | fairseq_cli.train | end of epoch 644 (average epoch stats below)
2022-03-07 13:50:41 | INFO | train | epoch 644 | loss 0.678 | nll_loss 0.144 | ppl 1.1 | wps 24720.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31351 | lr 0.000178597 | gnorm 0.307 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 89291
2022-03-07 13:50:41 | INFO | fairseq.trainer | begin training epoch 645
2022-03-07 13:50:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:52:42 | INFO | train_inner | epoch 645:     49 / 49 loss=0.679, nll_loss=0.144, ppl=1.1, wps=24722.2, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=31400, lr=0.000178458, gnorm=0.308, loss_scale=64, train_wall=222, gb_free=8.8, wall=89412
2022-03-07 13:52:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:52:47 | INFO | valid | epoch 645 | valid on 'valid' subset | loss 14.332 | nll_loss 14.155 | ppl 18247.2 | wps 46528.4 | wpb 510.9 | bsz 1 | num_updates 31400 | best_loss 8.318
2022-03-07 13:52:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 645 @ 31400 updates
2022-03-07 13:52:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:52:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:52:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 645 @ 31400 updates, score 14.332) (writing took 2.5214745178818703 seconds)
2022-03-07 13:52:49 | INFO | fairseq_cli.train | end of epoch 645 (average epoch stats below)
2022-03-07 13:52:49 | INFO | train | epoch 645 | loss 0.679 | nll_loss 0.144 | ppl 1.1 | wps 24698.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31400 | lr 0.000178458 | gnorm 0.308 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 89420
2022-03-07 13:52:49 | INFO | fairseq.trainer | begin training epoch 646
2022-03-07 13:52:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:53:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:54:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:54:55 | INFO | valid | epoch 646 | valid on 'valid' subset | loss 14.325 | nll_loss 14.147 | ppl 18141.3 | wps 46468.1 | wpb 510.9 | bsz 1 | num_updates 31448 | best_loss 8.318
2022-03-07 13:54:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 646 @ 31448 updates
2022-03-07 13:54:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:54:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:54:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 646 @ 31448 updates, score 14.325) (writing took 2.53617762029171 seconds)
2022-03-07 13:54:58 | INFO | fairseq_cli.train | end of epoch 646 (average epoch stats below)
2022-03-07 13:54:58 | INFO | train | epoch 646 | loss 0.678 | nll_loss 0.144 | ppl 1.1 | wps 24179.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31448 | lr 0.000178321 | gnorm 0.311 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 89548
2022-03-07 13:54:58 | INFO | fairseq.trainer | begin training epoch 647
2022-03-07 13:54:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:56:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:57:04 | INFO | valid | epoch 647 | valid on 'valid' subset | loss 14.265 | nll_loss 14.086 | ppl 17387.2 | wps 46625.6 | wpb 510.9 | bsz 1 | num_updates 31497 | best_loss 8.318
2022-03-07 13:57:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 647 @ 31497 updates
2022-03-07 13:57:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:57:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:57:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 647 @ 31497 updates, score 14.265) (writing took 2.511789543554187 seconds)
2022-03-07 13:57:07 | INFO | fairseq_cli.train | end of epoch 647 (average epoch stats below)
2022-03-07 13:57:07 | INFO | train | epoch 647 | loss 0.678 | nll_loss 0.144 | ppl 1.1 | wps 24712.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31497 | lr 0.000178183 | gnorm 0.31 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 89677
2022-03-07 13:57:07 | INFO | fairseq.trainer | begin training epoch 648
2022-03-07 13:57:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:57:14 | INFO | train_inner | epoch 648:      3 / 49 loss=0.678, nll_loss=0.143, ppl=1.1, wps=23830.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=31500, lr=0.000178174, gnorm=0.31, loss_scale=64, train_wall=226, gb_free=8.8, wall=89685
2022-03-07 13:59:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:59:13 | INFO | valid | epoch 648 | valid on 'valid' subset | loss 14.241 | nll_loss 14.062 | ppl 17101 | wps 46208.1 | wpb 510.9 | bsz 1 | num_updates 31546 | best_loss 8.318
2022-03-07 13:59:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 648 @ 31546 updates
2022-03-07 13:59:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:59:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:59:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 648 @ 31546 updates, score 14.241) (writing took 2.576028771698475 seconds)
2022-03-07 13:59:15 | INFO | fairseq_cli.train | end of epoch 648 (average epoch stats below)
2022-03-07 13:59:15 | INFO | train | epoch 648 | loss 0.678 | nll_loss 0.143 | ppl 1.1 | wps 24688.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31546 | lr 0.000178044 | gnorm 0.31 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 89806
2022-03-07 13:59:15 | INFO | fairseq.trainer | begin training epoch 649
2022-03-07 13:59:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:59:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:01:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:01:21 | INFO | valid | epoch 649 | valid on 'valid' subset | loss 14.303 | nll_loss 14.124 | ppl 17855.8 | wps 46646.6 | wpb 510.9 | bsz 1 | num_updates 31594 | best_loss 8.318
2022-03-07 14:01:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 649 @ 31594 updates
2022-03-07 14:01:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:01:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:01:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 649 @ 31594 updates, score 14.303) (writing took 2.5469798892736435 seconds)
2022-03-07 14:01:24 | INFO | fairseq_cli.train | end of epoch 649 (average epoch stats below)
2022-03-07 14:01:24 | INFO | train | epoch 649 | loss 0.678 | nll_loss 0.143 | ppl 1.1 | wps 24222.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31594 | lr 0.000177909 | gnorm 0.312 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 89934
2022-03-07 14:01:24 | INFO | fairseq.trainer | begin training epoch 650
2022-03-07 14:01:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:01:39 | INFO | train_inner | epoch 650:      6 / 49 loss=0.678, nll_loss=0.143, ppl=1.1, wps=24500.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31600, lr=0.000177892, gnorm=0.31, loss_scale=64, train_wall=226, gb_free=8.8, wall=89949
2022-03-07 14:03:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:03:30 | INFO | valid | epoch 650 | valid on 'valid' subset | loss 14.299 | nll_loss 14.119 | ppl 17794.5 | wps 45749.6 | wpb 510.9 | bsz 1 | num_updates 31643 | best_loss 8.318
2022-03-07 14:03:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 650 @ 31643 updates
2022-03-07 14:03:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:03:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:03:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 650 @ 31643 updates, score 14.299) (writing took 2.5390431322157383 seconds)
2022-03-07 14:03:33 | INFO | fairseq_cli.train | end of epoch 650 (average epoch stats below)
2022-03-07 14:03:33 | INFO | train | epoch 650 | loss 0.677 | nll_loss 0.143 | ppl 1.1 | wps 24645.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31643 | lr 0.000177771 | gnorm 0.306 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 90063
2022-03-07 14:03:33 | INFO | fairseq.trainer | begin training epoch 651
2022-03-07 14:03:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:05:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:05:39 | INFO | valid | epoch 651 | valid on 'valid' subset | loss 14.325 | nll_loss 14.148 | ppl 18158 | wps 46575.5 | wpb 510.9 | bsz 1 | num_updates 31691 | best_loss 8.318
2022-03-07 14:05:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 651 @ 31691 updates
2022-03-07 14:05:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:05:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:05:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 651 @ 31691 updates, score 14.325) (writing took 2.5530328806489706 seconds)
2022-03-07 14:05:41 | INFO | fairseq_cli.train | end of epoch 651 (average epoch stats below)
2022-03-07 14:05:41 | INFO | train | epoch 651 | loss 0.677 | nll_loss 0.142 | ppl 1.1 | wps 24225.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31691 | lr 0.000177636 | gnorm 0.306 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 90192
2022-03-07 14:05:41 | INFO | fairseq.trainer | begin training epoch 652
2022-03-07 14:05:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:06:04 | INFO | train_inner | epoch 652:      9 / 49 loss=0.677, nll_loss=0.142, ppl=1.1, wps=24494.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31700, lr=0.000177611, gnorm=0.307, loss_scale=64, train_wall=226, gb_free=8.8, wall=90214
2022-03-07 14:07:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:07:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:07:47 | INFO | valid | epoch 652 | valid on 'valid' subset | loss 14.202 | nll_loss 14.021 | ppl 16629 | wps 46679.6 | wpb 510.9 | bsz 1 | num_updates 31739 | best_loss 8.318
2022-03-07 14:07:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 652 @ 31739 updates
2022-03-07 14:07:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:07:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:07:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 652 @ 31739 updates, score 14.202) (writing took 2.534317096695304 seconds)
2022-03-07 14:07:50 | INFO | fairseq_cli.train | end of epoch 652 (average epoch stats below)
2022-03-07 14:07:50 | INFO | train | epoch 652 | loss 0.677 | nll_loss 0.143 | ppl 1.1 | wps 24185.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31739 | lr 0.000177502 | gnorm 0.312 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 90320
2022-03-07 14:07:50 | INFO | fairseq.trainer | begin training epoch 653
2022-03-07 14:07:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:09:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:09:56 | INFO | valid | epoch 653 | valid on 'valid' subset | loss 14.377 | nll_loss 14.2 | ppl 18817.2 | wps 46199.3 | wpb 510.9 | bsz 1 | num_updates 31788 | best_loss 8.318
2022-03-07 14:09:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 653 @ 31788 updates
2022-03-07 14:09:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:09:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:09:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 653 @ 31788 updates, score 14.377) (writing took 2.551923820748925 seconds)
2022-03-07 14:09:59 | INFO | fairseq_cli.train | end of epoch 653 (average epoch stats below)
2022-03-07 14:09:59 | INFO | train | epoch 653 | loss 0.676 | nll_loss 0.142 | ppl 1.1 | wps 24695.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31788 | lr 0.000177365 | gnorm 0.308 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 90449
2022-03-07 14:09:59 | INFO | fairseq.trainer | begin training epoch 654
2022-03-07 14:09:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:10:29 | INFO | train_inner | epoch 654:     12 / 49 loss=0.676, nll_loss=0.142, ppl=1.1, wps=24486.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31800, lr=0.000177332, gnorm=0.308, loss_scale=32, train_wall=226, gb_free=8.8, wall=90479
2022-03-07 14:12:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:12:05 | INFO | valid | epoch 654 | valid on 'valid' subset | loss 14.347 | nll_loss 14.17 | ppl 18435.1 | wps 46751.7 | wpb 510.9 | bsz 1 | num_updates 31837 | best_loss 8.318
2022-03-07 14:12:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 654 @ 31837 updates
2022-03-07 14:12:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:12:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:12:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 654 @ 31837 updates, score 14.347) (writing took 2.509490756317973 seconds)
2022-03-07 14:12:07 | INFO | fairseq_cli.train | end of epoch 654 (average epoch stats below)
2022-03-07 14:12:07 | INFO | train | epoch 654 | loss 0.677 | nll_loss 0.142 | ppl 1.1 | wps 24692.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31837 | lr 0.000177229 | gnorm 0.306 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 90578
2022-03-07 14:12:07 | INFO | fairseq.trainer | begin training epoch 655
2022-03-07 14:12:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:14:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:14:13 | INFO | valid | epoch 655 | valid on 'valid' subset | loss 14.378 | nll_loss 14.202 | ppl 18840.5 | wps 46609 | wpb 510.9 | bsz 1 | num_updates 31886 | best_loss 8.318
2022-03-07 14:14:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 655 @ 31886 updates
2022-03-07 14:14:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:14:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:14:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 655 @ 31886 updates, score 14.378) (writing took 2.538587264716625 seconds)
2022-03-07 14:14:16 | INFO | fairseq_cli.train | end of epoch 655 (average epoch stats below)
2022-03-07 14:14:16 | INFO | train | epoch 655 | loss 0.676 | nll_loss 0.142 | ppl 1.1 | wps 24709 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31886 | lr 0.000177092 | gnorm 0.302 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 90706
2022-03-07 14:14:16 | INFO | fairseq.trainer | begin training epoch 656
2022-03-07 14:14:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:14:51 | INFO | train_inner | epoch 656:     14 / 49 loss=0.676, nll_loss=0.142, ppl=1.1, wps=24738.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31900, lr=0.000177054, gnorm=0.305, loss_scale=64, train_wall=223, gb_free=8.8, wall=90741
2022-03-07 14:16:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:16:22 | INFO | valid | epoch 656 | valid on 'valid' subset | loss 14.238 | nll_loss 14.059 | ppl 17067.3 | wps 46617 | wpb 510.9 | bsz 1 | num_updates 31935 | best_loss 8.318
2022-03-07 14:16:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 656 @ 31935 updates
2022-03-07 14:16:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:16:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:16:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 656 @ 31935 updates, score 14.238) (writing took 2.536879001185298 seconds)
2022-03-07 14:16:25 | INFO | fairseq_cli.train | end of epoch 656 (average epoch stats below)
2022-03-07 14:16:25 | INFO | train | epoch 656 | loss 0.676 | nll_loss 0.142 | ppl 1.1 | wps 24710.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31935 | lr 0.000176957 | gnorm 0.312 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 90835
2022-03-07 14:16:25 | INFO | fairseq.trainer | begin training epoch 657
2022-03-07 14:16:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:18:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:18:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:18:31 | INFO | valid | epoch 657 | valid on 'valid' subset | loss 14.261 | nll_loss 14.082 | ppl 17343.6 | wps 46538.2 | wpb 510.9 | bsz 1 | num_updates 31983 | best_loss 8.318
2022-03-07 14:18:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 657 @ 31983 updates
2022-03-07 14:18:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:18:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:18:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 657 @ 31983 updates, score 14.261) (writing took 2.530623570084572 seconds)
2022-03-07 14:18:33 | INFO | fairseq_cli.train | end of epoch 657 (average epoch stats below)
2022-03-07 14:18:33 | INFO | train | epoch 657 | loss 0.676 | nll_loss 0.142 | ppl 1.1 | wps 24198.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31983 | lr 0.000176824 | gnorm 0.306 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 90964
2022-03-07 14:18:33 | INFO | fairseq.trainer | begin training epoch 658
2022-03-07 14:18:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:19:16 | INFO | train_inner | epoch 658:     17 / 49 loss=0.676, nll_loss=0.142, ppl=1.1, wps=24502.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32000, lr=0.000176777, gnorm=0.308, loss_scale=64, train_wall=226, gb_free=8.8, wall=91006
2022-03-07 14:20:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:20:39 | INFO | valid | epoch 658 | valid on 'valid' subset | loss 14.301 | nll_loss 14.124 | ppl 17848.8 | wps 46535.5 | wpb 510.9 | bsz 1 | num_updates 32032 | best_loss 8.318
2022-03-07 14:20:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 658 @ 32032 updates
2022-03-07 14:20:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:20:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 658 @ 32032 updates, score 14.301) (writing took 2.5865122694522142 seconds)
2022-03-07 14:20:42 | INFO | fairseq_cli.train | end of epoch 658 (average epoch stats below)
2022-03-07 14:20:42 | INFO | train | epoch 658 | loss 0.676 | nll_loss 0.142 | ppl 1.1 | wps 24699.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32032 | lr 0.000176688 | gnorm 0.306 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 91092
2022-03-07 14:20:42 | INFO | fairseq.trainer | begin training epoch 659
2022-03-07 14:20:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:22:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:22:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:22:48 | INFO | valid | epoch 659 | valid on 'valid' subset | loss 14.231 | nll_loss 14.053 | ppl 16996.2 | wps 46384 | wpb 510.9 | bsz 1 | num_updates 32080 | best_loss 8.318
2022-03-07 14:22:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 659 @ 32080 updates
2022-03-07 14:22:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:22:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:22:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 659 @ 32080 updates, score 14.231) (writing took 2.5543989818543196 seconds)
2022-03-07 14:22:51 | INFO | fairseq_cli.train | end of epoch 659 (average epoch stats below)
2022-03-07 14:22:51 | INFO | train | epoch 659 | loss 0.676 | nll_loss 0.141 | ppl 1.1 | wps 24193.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 32080 | lr 0.000176556 | gnorm 0.312 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 91221
2022-03-07 14:22:51 | INFO | fairseq.trainer | begin training epoch 660
2022-03-07 14:22:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:23:41 | INFO | train_inner | epoch 660:     20 / 49 loss=0.676, nll_loss=0.142, ppl=1.1, wps=24489.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=32100, lr=0.000176501, gnorm=0.31, loss_scale=32, train_wall=226, gb_free=8.8, wall=91271
2022-03-07 14:24:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:24:57 | INFO | valid | epoch 660 | valid on 'valid' subset | loss 14.275 | nll_loss 14.097 | ppl 17517.9 | wps 46474.1 | wpb 510.9 | bsz 1 | num_updates 32129 | best_loss 8.318
2022-03-07 14:24:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 660 @ 32129 updates
2022-03-07 14:24:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:24:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:24:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 660 @ 32129 updates, score 14.275) (writing took 2.526264311745763 seconds)
2022-03-07 14:24:59 | INFO | fairseq_cli.train | end of epoch 660 (average epoch stats below)
2022-03-07 14:24:59 | INFO | train | epoch 660 | loss 0.676 | nll_loss 0.142 | ppl 1.1 | wps 24702.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32129 | lr 0.000176421 | gnorm 0.309 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 91349
2022-03-07 14:24:59 | INFO | fairseq.trainer | begin training epoch 661
2022-03-07 14:24:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:27:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:27:05 | INFO | valid | epoch 661 | valid on 'valid' subset | loss 14.288 | nll_loss 14.11 | ppl 17681.8 | wps 46466.2 | wpb 510.9 | bsz 1 | num_updates 32178 | best_loss 8.318
2022-03-07 14:27:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 661 @ 32178 updates
2022-03-07 14:27:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:27:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:27:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 661 @ 32178 updates, score 14.288) (writing took 2.5511565767228603 seconds)
2022-03-07 14:27:08 | INFO | fairseq_cli.train | end of epoch 661 (average epoch stats below)
2022-03-07 14:27:08 | INFO | train | epoch 661 | loss 0.675 | nll_loss 0.141 | ppl 1.1 | wps 24679.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32178 | lr 0.000176287 | gnorm 0.305 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 91478
2022-03-07 14:27:08 | INFO | fairseq.trainer | begin training epoch 662
2022-03-07 14:27:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:28:03 | INFO | train_inner | epoch 662:     22 / 49 loss=0.675, nll_loss=0.141, ppl=1.1, wps=24727.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32200, lr=0.000176227, gnorm=0.306, loss_scale=32, train_wall=224, gb_free=8.8, wall=91533
2022-03-07 14:29:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:29:14 | INFO | valid | epoch 662 | valid on 'valid' subset | loss 14.336 | nll_loss 14.159 | ppl 18293.4 | wps 46399.2 | wpb 510.9 | bsz 1 | num_updates 32227 | best_loss 8.318
2022-03-07 14:29:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 662 @ 32227 updates
2022-03-07 14:29:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:29:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:29:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 662 @ 32227 updates, score 14.336) (writing took 2.5058160349726677 seconds)
2022-03-07 14:29:17 | INFO | fairseq_cli.train | end of epoch 662 (average epoch stats below)
2022-03-07 14:29:17 | INFO | train | epoch 662 | loss 0.675 | nll_loss 0.141 | ppl 1.1 | wps 24689.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32227 | lr 0.000176153 | gnorm 0.306 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 91607
2022-03-07 14:29:17 | INFO | fairseq.trainer | begin training epoch 663
2022-03-07 14:29:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:31:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:31:23 | INFO | valid | epoch 663 | valid on 'valid' subset | loss 14.276 | nll_loss 14.096 | ppl 17507 | wps 46682.2 | wpb 510.9 | bsz 1 | num_updates 32276 | best_loss 8.318
2022-03-07 14:31:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 663 @ 32276 updates
2022-03-07 14:31:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:31:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:31:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 663 @ 32276 updates, score 14.276) (writing took 2.5170689690858126 seconds)
2022-03-07 14:31:25 | INFO | fairseq_cli.train | end of epoch 663 (average epoch stats below)
2022-03-07 14:31:25 | INFO | train | epoch 663 | loss 0.675 | nll_loss 0.141 | ppl 1.1 | wps 24678 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32276 | lr 0.000176019 | gnorm 0.306 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 91736
2022-03-07 14:31:25 | INFO | fairseq.trainer | begin training epoch 664
2022-03-07 14:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:32:26 | INFO | train_inner | epoch 664:     24 / 49 loss=0.675, nll_loss=0.141, ppl=1.1, wps=24705.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=32300, lr=0.000175954, gnorm=0.304, loss_scale=64, train_wall=224, gb_free=8.8, wall=91796
2022-03-07 14:33:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:33:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:33:32 | INFO | valid | epoch 664 | valid on 'valid' subset | loss 14.311 | nll_loss 14.134 | ppl 17978.5 | wps 46430.7 | wpb 510.9 | bsz 1 | num_updates 32324 | best_loss 8.318
2022-03-07 14:33:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 664 @ 32324 updates
2022-03-07 14:33:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:33:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:33:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 664 @ 32324 updates, score 14.311) (writing took 2.537796299904585 seconds)
2022-03-07 14:33:34 | INFO | fairseq_cli.train | end of epoch 664 (average epoch stats below)
2022-03-07 14:33:34 | INFO | train | epoch 664 | loss 0.674 | nll_loss 0.141 | ppl 1.1 | wps 24208.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 32324 | lr 0.000175889 | gnorm 0.302 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 91864
2022-03-07 14:33:34 | INFO | fairseq.trainer | begin training epoch 665
2022-03-07 14:33:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:35:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:35:40 | INFO | valid | epoch 665 | valid on 'valid' subset | loss 14.243 | nll_loss 14.064 | ppl 17132.5 | wps 46432.1 | wpb 510.9 | bsz 1 | num_updates 32373 | best_loss 8.318
2022-03-07 14:35:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 665 @ 32373 updates
2022-03-07 14:35:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:35:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:35:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 665 @ 32373 updates, score 14.243) (writing took 2.5346949324011803 seconds)
2022-03-07 14:35:43 | INFO | fairseq_cli.train | end of epoch 665 (average epoch stats below)
2022-03-07 14:35:43 | INFO | train | epoch 665 | loss 0.675 | nll_loss 0.141 | ppl 1.1 | wps 24707.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32373 | lr 0.000175755 | gnorm 0.303 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 91993
2022-03-07 14:35:43 | INFO | fairseq.trainer | begin training epoch 666
2022-03-07 14:35:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:36:50 | INFO | train_inner | epoch 666:     27 / 49 loss=0.674, nll_loss=0.141, ppl=1.1, wps=24514.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32400, lr=0.000175682, gnorm=0.303, loss_scale=32, train_wall=226, gb_free=8.8, wall=92061
2022-03-07 14:37:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:37:49 | INFO | valid | epoch 666 | valid on 'valid' subset | loss 14.282 | nll_loss 14.103 | ppl 17601.2 | wps 46626.9 | wpb 510.9 | bsz 1 | num_updates 32422 | best_loss 8.318
2022-03-07 14:37:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 666 @ 32422 updates
2022-03-07 14:37:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:37:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:37:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 666 @ 32422 updates, score 14.282) (writing took 2.530048578977585 seconds)
2022-03-07 14:37:51 | INFO | fairseq_cli.train | end of epoch 666 (average epoch stats below)
2022-03-07 14:37:51 | INFO | train | epoch 666 | loss 0.674 | nll_loss 0.141 | ppl 1.1 | wps 24721.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32422 | lr 0.000175622 | gnorm 0.302 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 92122
2022-03-07 14:37:51 | INFO | fairseq.trainer | begin training epoch 667
2022-03-07 14:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:39:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:39:57 | INFO | valid | epoch 667 | valid on 'valid' subset | loss 14.316 | nll_loss 14.137 | ppl 18012.8 | wps 46649.5 | wpb 510.9 | bsz 1 | num_updates 32471 | best_loss 8.318
2022-03-07 14:39:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 667 @ 32471 updates
2022-03-07 14:39:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:40:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:40:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 667 @ 32471 updates, score 14.316) (writing took 2.559146571904421 seconds)
2022-03-07 14:40:00 | INFO | fairseq_cli.train | end of epoch 667 (average epoch stats below)
2022-03-07 14:40:00 | INFO | train | epoch 667 | loss 0.674 | nll_loss 0.141 | ppl 1.1 | wps 24705.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32471 | lr 0.00017549 | gnorm 0.306 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 92250
2022-03-07 14:40:00 | INFO | fairseq.trainer | begin training epoch 668
2022-03-07 14:40:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:41:13 | INFO | train_inner | epoch 668:     29 / 49 loss=0.674, nll_loss=0.141, ppl=1.1, wps=24728.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=32500, lr=0.000175412, gnorm=0.303, loss_scale=64, train_wall=224, gb_free=8.8, wall=92323
2022-03-07 14:42:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:42:06 | INFO | valid | epoch 668 | valid on 'valid' subset | loss 14.267 | nll_loss 14.09 | ppl 17434.5 | wps 46286.7 | wpb 510.9 | bsz 1 | num_updates 32520 | best_loss 8.318
2022-03-07 14:42:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 668 @ 32520 updates
2022-03-07 14:42:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:42:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:42:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 668 @ 32520 updates, score 14.267) (writing took 2.522574195638299 seconds)
2022-03-07 14:42:09 | INFO | fairseq_cli.train | end of epoch 668 (average epoch stats below)
2022-03-07 14:42:09 | INFO | train | epoch 668 | loss 0.674 | nll_loss 0.14 | ppl 1.1 | wps 24699.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32520 | lr 0.000175358 | gnorm 0.302 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 92379
2022-03-07 14:42:09 | INFO | fairseq.trainer | begin training epoch 669
2022-03-07 14:42:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:44:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:44:15 | INFO | valid | epoch 669 | valid on 'valid' subset | loss 14.289 | nll_loss 14.111 | ppl 17697.4 | wps 46513.4 | wpb 510.9 | bsz 1 | num_updates 32569 | best_loss 8.318
2022-03-07 14:44:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 669 @ 32569 updates
2022-03-07 14:44:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:44:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:44:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 669 @ 32569 updates, score 14.289) (writing took 2.521982230246067 seconds)
2022-03-07 14:44:17 | INFO | fairseq_cli.train | end of epoch 669 (average epoch stats below)
2022-03-07 14:44:17 | INFO | train | epoch 669 | loss 0.674 | nll_loss 0.14 | ppl 1.1 | wps 24711.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32569 | lr 0.000175226 | gnorm 0.308 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 92507
2022-03-07 14:44:17 | INFO | fairseq.trainer | begin training epoch 670
2022-03-07 14:44:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:44:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:45:37 | INFO | train_inner | epoch 670:     32 / 49 loss=0.674, nll_loss=0.141, ppl=1.1, wps=24498.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32600, lr=0.000175142, gnorm=0.305, loss_scale=64, train_wall=226, gb_free=8.8, wall=92588
2022-03-07 14:46:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:46:23 | INFO | valid | epoch 670 | valid on 'valid' subset | loss 14.337 | nll_loss 14.161 | ppl 18320.5 | wps 46568 | wpb 510.9 | bsz 1 | num_updates 32617 | best_loss 8.318
2022-03-07 14:46:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 670 @ 32617 updates
2022-03-07 14:46:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:46:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:46:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 670 @ 32617 updates, score 14.337) (writing took 2.507825391367078 seconds)
2022-03-07 14:46:26 | INFO | fairseq_cli.train | end of epoch 670 (average epoch stats below)
2022-03-07 14:46:26 | INFO | train | epoch 670 | loss 0.674 | nll_loss 0.141 | ppl 1.1 | wps 24185.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 32617 | lr 0.000175097 | gnorm 0.305 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 92636
2022-03-07 14:46:26 | INFO | fairseq.trainer | begin training epoch 671
2022-03-07 14:46:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:48:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:48:32 | INFO | valid | epoch 671 | valid on 'valid' subset | loss 14.258 | nll_loss 14.078 | ppl 17297.8 | wps 45960.6 | wpb 510.9 | bsz 1 | num_updates 32666 | best_loss 8.318
2022-03-07 14:48:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 671 @ 32666 updates
2022-03-07 14:48:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:48:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:48:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 671 @ 32666 updates, score 14.258) (writing took 2.520451931282878 seconds)
2022-03-07 14:48:35 | INFO | fairseq_cli.train | end of epoch 671 (average epoch stats below)
2022-03-07 14:48:35 | INFO | train | epoch 671 | loss 0.674 | nll_loss 0.141 | ppl 1.1 | wps 24683.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32666 | lr 0.000174965 | gnorm 0.307 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 92765
2022-03-07 14:48:35 | INFO | fairseq.trainer | begin training epoch 672
2022-03-07 14:48:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:50:00 | INFO | train_inner | epoch 672:     34 / 49 loss=0.674, nll_loss=0.141, ppl=1.1, wps=24731.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32700, lr=0.000174874, gnorm=0.305, loss_scale=64, train_wall=224, gb_free=8.8, wall=92850
2022-03-07 14:50:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:50:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:50:41 | INFO | valid | epoch 672 | valid on 'valid' subset | loss 14.285 | nll_loss 14.108 | ppl 17658.3 | wps 46665.6 | wpb 510.9 | bsz 1 | num_updates 32714 | best_loss 8.318
2022-03-07 14:50:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 672 @ 32714 updates
2022-03-07 14:50:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:50:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:50:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 672 @ 32714 updates, score 14.285) (writing took 2.536710973829031 seconds)
2022-03-07 14:50:43 | INFO | fairseq_cli.train | end of epoch 672 (average epoch stats below)
2022-03-07 14:50:43 | INFO | train | epoch 672 | loss 0.674 | nll_loss 0.14 | ppl 1.1 | wps 24192 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 32714 | lr 0.000174837 | gnorm 0.303 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 92894
2022-03-07 14:50:43 | INFO | fairseq.trainer | begin training epoch 673
2022-03-07 14:50:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:52:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:52:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:52:49 | INFO | valid | epoch 673 | valid on 'valid' subset | loss 14.316 | nll_loss 14.139 | ppl 18042.6 | wps 46316.4 | wpb 510.9 | bsz 1 | num_updates 32762 | best_loss 8.318
2022-03-07 14:52:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 673 @ 32762 updates
2022-03-07 14:52:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:52:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:52:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 673 @ 32762 updates, score 14.316) (writing took 2.5380778331309557 seconds)
2022-03-07 14:52:52 | INFO | fairseq_cli.train | end of epoch 673 (average epoch stats below)
2022-03-07 14:52:52 | INFO | train | epoch 673 | loss 0.673 | nll_loss 0.14 | ppl 1.1 | wps 24220 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 32762 | lr 0.000174709 | gnorm 0.305 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 93022
2022-03-07 14:52:52 | INFO | fairseq.trainer | begin training epoch 674
2022-03-07 14:52:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:54:27 | INFO | train_inner | epoch 674:     38 / 49 loss=0.673, nll_loss=0.14, ppl=1.1, wps=24282, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=32800, lr=0.000174608, gnorm=0.305, loss_scale=32, train_wall=228, gb_free=8.8, wall=93117
2022-03-07 14:54:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:54:58 | INFO | valid | epoch 674 | valid on 'valid' subset | loss 14.274 | nll_loss 14.094 | ppl 17491.6 | wps 46565.1 | wpb 510.9 | bsz 1 | num_updates 32811 | best_loss 8.318
2022-03-07 14:54:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 674 @ 32811 updates
2022-03-07 14:54:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:55:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:55:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 674 @ 32811 updates, score 14.274) (writing took 2.5218207128345966 seconds)
2022-03-07 14:55:00 | INFO | fairseq_cli.train | end of epoch 674 (average epoch stats below)
2022-03-07 14:55:00 | INFO | train | epoch 674 | loss 0.673 | nll_loss 0.14 | ppl 1.1 | wps 24714.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32811 | lr 0.000174578 | gnorm 0.305 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 93151
2022-03-07 14:55:00 | INFO | fairseq.trainer | begin training epoch 675
2022-03-07 14:55:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:57:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:57:07 | INFO | valid | epoch 675 | valid on 'valid' subset | loss 14.249 | nll_loss 14.071 | ppl 17207 | wps 46423.2 | wpb 510.9 | bsz 1 | num_updates 32860 | best_loss 8.318
2022-03-07 14:57:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 675 @ 32860 updates
2022-03-07 14:57:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:57:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:57:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 675 @ 32860 updates, score 14.249) (writing took 2.515255782753229 seconds)
2022-03-07 14:57:09 | INFO | fairseq_cli.train | end of epoch 675 (average epoch stats below)
2022-03-07 14:57:09 | INFO | train | epoch 675 | loss 0.673 | nll_loss 0.14 | ppl 1.1 | wps 24680.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32860 | lr 0.000174448 | gnorm 0.302 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 93279
2022-03-07 14:57:09 | INFO | fairseq.trainer | begin training epoch 676
2022-03-07 14:57:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:58:49 | INFO | train_inner | epoch 676:     40 / 49 loss=0.673, nll_loss=0.14, ppl=1.1, wps=24709.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=32900, lr=0.000174342, gnorm=0.302, loss_scale=64, train_wall=224, gb_free=8.8, wall=93380
2022-03-07 14:59:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:59:15 | INFO | valid | epoch 676 | valid on 'valid' subset | loss 14.285 | nll_loss 14.105 | ppl 17623.7 | wps 46691.9 | wpb 510.9 | bsz 1 | num_updates 32909 | best_loss 8.318
2022-03-07 14:59:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 676 @ 32909 updates
2022-03-07 14:59:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:59:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:59:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 676 @ 32909 updates, score 14.285) (writing took 2.5159393679350615 seconds)
2022-03-07 14:59:18 | INFO | fairseq_cli.train | end of epoch 676 (average epoch stats below)
2022-03-07 14:59:18 | INFO | train | epoch 676 | loss 0.672 | nll_loss 0.139 | ppl 1.1 | wps 24689.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32909 | lr 0.000174318 | gnorm 0.302 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 93408
2022-03-07 14:59:18 | INFO | fairseq.trainer | begin training epoch 677
2022-03-07 14:59:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:01:24 | INFO | valid | epoch 677 | valid on 'valid' subset | loss 14.312 | nll_loss 14.136 | ppl 18002.4 | wps 46616 | wpb 510.9 | bsz 1 | num_updates 32958 | best_loss 8.318
2022-03-07 15:01:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 677 @ 32958 updates
2022-03-07 15:01:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:01:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:01:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 677 @ 32958 updates, score 14.312) (writing took 2.525947777554393 seconds)
2022-03-07 15:01:26 | INFO | fairseq_cli.train | end of epoch 677 (average epoch stats below)
2022-03-07 15:01:26 | INFO | train | epoch 677 | loss 0.673 | nll_loss 0.139 | ppl 1.1 | wps 24710.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32958 | lr 0.000174189 | gnorm 0.303 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 93537
2022-03-07 15:01:26 | INFO | fairseq.trainer | begin training epoch 678
2022-03-07 15:01:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:01:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:03:14 | INFO | train_inner | epoch 678:     43 / 49 loss=0.673, nll_loss=0.14, ppl=1.1, wps=24526.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33000, lr=0.000174078, gnorm=0.305, loss_scale=32, train_wall=226, gb_free=8.8, wall=93644
2022-03-07 15:03:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:03:33 | INFO | valid | epoch 678 | valid on 'valid' subset | loss 14.288 | nll_loss 14.112 | ppl 17708.8 | wps 46111.8 | wpb 510.9 | bsz 1 | num_updates 33006 | best_loss 8.318
2022-03-07 15:03:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 678 @ 33006 updates
2022-03-07 15:03:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:03:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:03:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 678 @ 33006 updates, score 14.288) (writing took 2.5058808103203773 seconds)
2022-03-07 15:03:35 | INFO | fairseq_cli.train | end of epoch 678 (average epoch stats below)
2022-03-07 15:03:35 | INFO | train | epoch 678 | loss 0.673 | nll_loss 0.14 | ppl 1.1 | wps 24198.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 33006 | lr 0.000174062 | gnorm 0.308 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 93665
2022-03-07 15:03:35 | INFO | fairseq.trainer | begin training epoch 679
2022-03-07 15:03:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:05:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:05:41 | INFO | valid | epoch 679 | valid on 'valid' subset | loss 14.258 | nll_loss 14.078 | ppl 17298.4 | wps 45704.4 | wpb 510.9 | bsz 1 | num_updates 33055 | best_loss 8.318
2022-03-07 15:05:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 679 @ 33055 updates
2022-03-07 15:05:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:05:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:05:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 679 @ 33055 updates, score 14.258) (writing took 2.530903162434697 seconds)
2022-03-07 15:05:44 | INFO | fairseq_cli.train | end of epoch 679 (average epoch stats below)
2022-03-07 15:05:44 | INFO | train | epoch 679 | loss 0.672 | nll_loss 0.139 | ppl 1.1 | wps 24707.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33055 | lr 0.000173933 | gnorm 0.308 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 93794
2022-03-07 15:05:44 | INFO | fairseq.trainer | begin training epoch 680
2022-03-07 15:05:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:07:36 | INFO | train_inner | epoch 680:     45 / 49 loss=0.672, nll_loss=0.139, ppl=1.1, wps=24720.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33100, lr=0.000173814, gnorm=0.305, loss_scale=64, train_wall=224, gb_free=8.8, wall=93907
2022-03-07 15:07:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:07:50 | INFO | valid | epoch 680 | valid on 'valid' subset | loss 14.196 | nll_loss 14.017 | ppl 16574.4 | wps 46594 | wpb 510.9 | bsz 1 | num_updates 33104 | best_loss 8.318
2022-03-07 15:07:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 680 @ 33104 updates
2022-03-07 15:07:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:07:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:07:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 680 @ 33104 updates, score 14.196) (writing took 2.5325279776006937 seconds)
2022-03-07 15:07:52 | INFO | fairseq_cli.train | end of epoch 680 (average epoch stats below)
2022-03-07 15:07:52 | INFO | train | epoch 680 | loss 0.672 | nll_loss 0.139 | ppl 1.1 | wps 24711.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33104 | lr 0.000173804 | gnorm 0.301 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 93923
2022-03-07 15:07:52 | INFO | fairseq.trainer | begin training epoch 681
2022-03-07 15:07:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:09:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:09:59 | INFO | valid | epoch 681 | valid on 'valid' subset | loss 14.329 | nll_loss 14.151 | ppl 18188.9 | wps 46273.1 | wpb 510.9 | bsz 1 | num_updates 33153 | best_loss 8.318
2022-03-07 15:09:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 681 @ 33153 updates
2022-03-07 15:09:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:10:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:10:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 681 @ 33153 updates, score 14.329) (writing took 2.5171726923435926 seconds)
2022-03-07 15:10:01 | INFO | fairseq_cli.train | end of epoch 681 (average epoch stats below)
2022-03-07 15:10:01 | INFO | train | epoch 681 | loss 0.672 | nll_loss 0.139 | ppl 1.1 | wps 24686.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33153 | lr 0.000173676 | gnorm 0.304 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 94051
2022-03-07 15:10:01 | INFO | fairseq.trainer | begin training epoch 682
2022-03-07 15:10:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:11:59 | INFO | train_inner | epoch 682:     47 / 49 loss=0.672, nll_loss=0.139, ppl=1.1, wps=24734.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33200, lr=0.000173553, gnorm=0.302, loss_scale=64, train_wall=224, gb_free=8.8, wall=94169
2022-03-07 15:12:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:12:07 | INFO | valid | epoch 682 | valid on 'valid' subset | loss 14.251 | nll_loss 14.074 | ppl 17241.2 | wps 46506 | wpb 510.9 | bsz 1 | num_updates 33202 | best_loss 8.318
2022-03-07 15:12:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 682 @ 33202 updates
2022-03-07 15:12:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:12:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:12:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 682 @ 33202 updates, score 14.251) (writing took 2.5443900860846043 seconds)
2022-03-07 15:12:10 | INFO | fairseq_cli.train | end of epoch 682 (average epoch stats below)
2022-03-07 15:12:10 | INFO | train | epoch 682 | loss 0.672 | nll_loss 0.139 | ppl 1.1 | wps 24720 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33202 | lr 0.000173547 | gnorm 0.301 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 94180
2022-03-07 15:12:10 | INFO | fairseq.trainer | begin training epoch 683
2022-03-07 15:12:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:12:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:14:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:14:16 | INFO | valid | epoch 683 | valid on 'valid' subset | loss 14.268 | nll_loss 14.09 | ppl 17432.9 | wps 46775.2 | wpb 510.9 | bsz 1 | num_updates 33250 | best_loss 8.318
2022-03-07 15:14:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 683 @ 33250 updates
2022-03-07 15:14:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:14:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:14:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 683 @ 33250 updates, score 14.268) (writing took 2.5488501470535994 seconds)
2022-03-07 15:14:18 | INFO | fairseq_cli.train | end of epoch 683 (average epoch stats below)
2022-03-07 15:14:18 | INFO | train | epoch 683 | loss 0.671 | nll_loss 0.138 | ppl 1.1 | wps 24212.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 33250 | lr 0.000173422 | gnorm 0.303 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 94308
2022-03-07 15:14:18 | INFO | fairseq.trainer | begin training epoch 684
2022-03-07 15:14:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:14:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:16:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:16:24 | INFO | valid | epoch 684 | valid on 'valid' subset | loss 14.313 | nll_loss 14.136 | ppl 18007 | wps 46470.7 | wpb 510.9 | bsz 1 | num_updates 33298 | best_loss 8.318
2022-03-07 15:16:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 684 @ 33298 updates
2022-03-07 15:16:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:16:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:16:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 684 @ 33298 updates, score 14.313) (writing took 2.526521746069193 seconds)
2022-03-07 15:16:27 | INFO | fairseq_cli.train | end of epoch 684 (average epoch stats below)
2022-03-07 15:16:27 | INFO | train | epoch 684 | loss 0.671 | nll_loss 0.138 | ppl 1.1 | wps 24183.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 33298 | lr 0.000173297 | gnorm 0.301 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 94437
2022-03-07 15:16:27 | INFO | fairseq.trainer | begin training epoch 685
2022-03-07 15:16:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:16:32 | INFO | train_inner | epoch 685:      2 / 49 loss=0.671, nll_loss=0.138, ppl=1.1, wps=23604.6, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=33300, lr=0.000173292, gnorm=0.303, loss_scale=32, train_wall=227, gb_free=8.8, wall=94442
2022-03-07 15:18:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:18:33 | INFO | valid | epoch 685 | valid on 'valid' subset | loss 14.212 | nll_loss 14.032 | ppl 16754.6 | wps 45928.1 | wpb 510.9 | bsz 1 | num_updates 33347 | best_loss 8.318
2022-03-07 15:18:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 685 @ 33347 updates
2022-03-07 15:18:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:18:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:18:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 685 @ 33347 updates, score 14.212) (writing took 2.518682235851884 seconds)
2022-03-07 15:18:36 | INFO | fairseq_cli.train | end of epoch 685 (average epoch stats below)
2022-03-07 15:18:36 | INFO | train | epoch 685 | loss 0.671 | nll_loss 0.139 | ppl 1.1 | wps 24691.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33347 | lr 0.00017317 | gnorm 0.303 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 94566
2022-03-07 15:18:36 | INFO | fairseq.trainer | begin training epoch 686
2022-03-07 15:18:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:20:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:20:42 | INFO | valid | epoch 686 | valid on 'valid' subset | loss 14.281 | nll_loss 14.103 | ppl 17597.4 | wps 46381.5 | wpb 510.9 | bsz 1 | num_updates 33396 | best_loss 8.318
2022-03-07 15:20:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 686 @ 33396 updates
2022-03-07 15:20:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:20:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:20:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 686 @ 33396 updates, score 14.281) (writing took 2.5299551133066416 seconds)
2022-03-07 15:20:44 | INFO | fairseq_cli.train | end of epoch 686 (average epoch stats below)
2022-03-07 15:20:44 | INFO | train | epoch 686 | loss 0.671 | nll_loss 0.138 | ppl 1.1 | wps 24714.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33396 | lr 0.000173042 | gnorm 0.305 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 94694
2022-03-07 15:20:44 | INFO | fairseq.trainer | begin training epoch 687
2022-03-07 15:20:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:20:54 | INFO | train_inner | epoch 687:      4 / 49 loss=0.671, nll_loss=0.138, ppl=1.1, wps=24736.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33400, lr=0.000173032, gnorm=0.304, loss_scale=64, train_wall=223, gb_free=8.8, wall=94705
2022-03-07 15:22:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:22:50 | INFO | valid | epoch 687 | valid on 'valid' subset | loss 14.218 | nll_loss 14.04 | ppl 16838.9 | wps 46636.4 | wpb 510.9 | bsz 1 | num_updates 33445 | best_loss 8.318
2022-03-07 15:22:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 687 @ 33445 updates
2022-03-07 15:22:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:22:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:22:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 687 @ 33445 updates, score 14.218) (writing took 2.5293613616377115 seconds)
2022-03-07 15:22:53 | INFO | fairseq_cli.train | end of epoch 687 (average epoch stats below)
2022-03-07 15:22:53 | INFO | train | epoch 687 | loss 0.671 | nll_loss 0.138 | ppl 1.1 | wps 24708.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33445 | lr 0.000172916 | gnorm 0.3 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 94823
2022-03-07 15:22:53 | INFO | fairseq.trainer | begin training epoch 688
2022-03-07 15:22:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:24:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:24:59 | INFO | valid | epoch 688 | valid on 'valid' subset | loss 14.285 | nll_loss 14.107 | ppl 17648.2 | wps 46597.2 | wpb 510.9 | bsz 1 | num_updates 33494 | best_loss 8.318
2022-03-07 15:24:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 688 @ 33494 updates
2022-03-07 15:24:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:25:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:25:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 688 @ 33494 updates, score 14.285) (writing took 2.5337010882794857 seconds)
2022-03-07 15:25:01 | INFO | fairseq_cli.train | end of epoch 688 (average epoch stats below)
2022-03-07 15:25:01 | INFO | train | epoch 688 | loss 0.67 | nll_loss 0.138 | ppl 1.1 | wps 24702.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33494 | lr 0.000172789 | gnorm 0.303 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 94952
2022-03-07 15:25:01 | INFO | fairseq.trainer | begin training epoch 689
2022-03-07 15:25:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:25:17 | INFO | train_inner | epoch 689:      6 / 49 loss=0.671, nll_loss=0.138, ppl=1.1, wps=24733.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33500, lr=0.000172774, gnorm=0.302, loss_scale=64, train_wall=223, gb_free=8.8, wall=94967
2022-03-07 15:25:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:27:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:27:08 | INFO | valid | epoch 689 | valid on 'valid' subset | loss 14.316 | nll_loss 14.137 | ppl 18018.3 | wps 46398.2 | wpb 510.9 | bsz 1 | num_updates 33542 | best_loss 8.318
2022-03-07 15:27:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 689 @ 33542 updates
2022-03-07 15:27:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:27:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:27:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 689 @ 33542 updates, score 14.316) (writing took 2.521708734333515 seconds)
2022-03-07 15:27:10 | INFO | fairseq_cli.train | end of epoch 689 (average epoch stats below)
2022-03-07 15:27:10 | INFO | train | epoch 689 | loss 0.67 | nll_loss 0.138 | ppl 1.1 | wps 24204.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 33542 | lr 0.000172665 | gnorm 0.301 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 95080
2022-03-07 15:27:10 | INFO | fairseq.trainer | begin training epoch 690
2022-03-07 15:27:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:29:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:29:16 | INFO | valid | epoch 690 | valid on 'valid' subset | loss 14.287 | nll_loss 14.108 | ppl 17663.2 | wps 46697.3 | wpb 510.9 | bsz 1 | num_updates 33591 | best_loss 8.318
2022-03-07 15:29:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 690 @ 33591 updates
2022-03-07 15:29:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:29:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:29:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 690 @ 33591 updates, score 14.287) (writing took 2.5130001604557037 seconds)
2022-03-07 15:29:19 | INFO | fairseq_cli.train | end of epoch 690 (average epoch stats below)
2022-03-07 15:29:19 | INFO | train | epoch 690 | loss 0.67 | nll_loss 0.138 | ppl 1.1 | wps 24692.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33591 | lr 0.000172539 | gnorm 0.302 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 95209
2022-03-07 15:29:19 | INFO | fairseq.trainer | begin training epoch 691
2022-03-07 15:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:29:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:29:44 | INFO | train_inner | epoch 691:     10 / 49 loss=0.67, nll_loss=0.138, ppl=1.1, wps=24264.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=33600, lr=0.000172516, gnorm=0.301, loss_scale=32, train_wall=228, gb_free=8.8, wall=95234
2022-03-07 15:31:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:31:25 | INFO | valid | epoch 691 | valid on 'valid' subset | loss 14.218 | nll_loss 14.039 | ppl 16838.7 | wps 46578.1 | wpb 510.9 | bsz 1 | num_updates 33639 | best_loss 8.318
2022-03-07 15:31:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 691 @ 33639 updates
2022-03-07 15:31:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:31:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:31:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 691 @ 33639 updates, score 14.218) (writing took 2.5356457252055407 seconds)
2022-03-07 15:31:28 | INFO | fairseq_cli.train | end of epoch 691 (average epoch stats below)
2022-03-07 15:31:28 | INFO | train | epoch 691 | loss 0.67 | nll_loss 0.138 | ppl 1.1 | wps 24153.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 33639 | lr 0.000172416 | gnorm 0.302 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 95338
2022-03-07 15:31:28 | INFO | fairseq.trainer | begin training epoch 692
2022-03-07 15:31:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:33:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:33:33 | INFO | valid | epoch 692 | valid on 'valid' subset | loss 14.327 | nll_loss 14.15 | ppl 18176 | wps 46600.4 | wpb 510.9 | bsz 1 | num_updates 33688 | best_loss 8.318
2022-03-07 15:33:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 692 @ 33688 updates
2022-03-07 15:33:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:33:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:33:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 692 @ 33688 updates, score 14.327) (writing took 2.542517626658082 seconds)
2022-03-07 15:33:36 | INFO | fairseq_cli.train | end of epoch 692 (average epoch stats below)
2022-03-07 15:33:36 | INFO | train | epoch 692 | loss 0.67 | nll_loss 0.138 | ppl 1.1 | wps 24753.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33688 | lr 0.000172291 | gnorm 0.298 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 95466
2022-03-07 15:33:36 | INFO | fairseq.trainer | begin training epoch 693
2022-03-07 15:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:34:06 | INFO | train_inner | epoch 693:     12 / 49 loss=0.67, nll_loss=0.137, ppl=1.1, wps=24728.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=33700, lr=0.00017226, gnorm=0.3, loss_scale=32, train_wall=224, gb_free=8.8, wall=95496
2022-03-07 15:35:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:35:42 | INFO | valid | epoch 693 | valid on 'valid' subset | loss 14.256 | nll_loss 14.079 | ppl 17311.5 | wps 46658.6 | wpb 510.9 | bsz 1 | num_updates 33737 | best_loss 8.318
2022-03-07 15:35:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 693 @ 33737 updates
2022-03-07 15:35:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:35:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:35:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 693 @ 33737 updates, score 14.256) (writing took 2.506147064268589 seconds)
2022-03-07 15:35:45 | INFO | fairseq_cli.train | end of epoch 693 (average epoch stats below)
2022-03-07 15:35:45 | INFO | train | epoch 693 | loss 0.67 | nll_loss 0.137 | ppl 1.1 | wps 24708.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33737 | lr 0.000172166 | gnorm 0.3 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 95595
2022-03-07 15:35:45 | INFO | fairseq.trainer | begin training epoch 694
2022-03-07 15:35:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:37:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:37:51 | INFO | valid | epoch 694 | valid on 'valid' subset | loss 14.306 | nll_loss 14.129 | ppl 17921.4 | wps 46615.3 | wpb 510.9 | bsz 1 | num_updates 33786 | best_loss 8.318
2022-03-07 15:37:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 694 @ 33786 updates
2022-03-07 15:37:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:37:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:37:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 694 @ 33786 updates, score 14.306) (writing took 2.5666668098419905 seconds)
2022-03-07 15:37:53 | INFO | fairseq_cli.train | end of epoch 694 (average epoch stats below)
2022-03-07 15:37:53 | INFO | train | epoch 694 | loss 0.67 | nll_loss 0.137 | ppl 1.1 | wps 24704.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33786 | lr 0.000172041 | gnorm 0.302 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 95724
2022-03-07 15:37:53 | INFO | fairseq.trainer | begin training epoch 695
2022-03-07 15:37:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:38:28 | INFO | train_inner | epoch 695:     14 / 49 loss=0.67, nll_loss=0.138, ppl=1.1, wps=24746, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=33800, lr=0.000172005, gnorm=0.302, loss_scale=64, train_wall=223, gb_free=8.8, wall=95759
2022-03-07 15:39:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:39:59 | INFO | valid | epoch 695 | valid on 'valid' subset | loss 14.266 | nll_loss 14.089 | ppl 17422.4 | wps 46282 | wpb 510.9 | bsz 1 | num_updates 33835 | best_loss 8.318
2022-03-07 15:39:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 695 @ 33835 updates
2022-03-07 15:39:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:40:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:40:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 695 @ 33835 updates, score 14.266) (writing took 2.5484124459326267 seconds)
2022-03-07 15:40:02 | INFO | fairseq_cli.train | end of epoch 695 (average epoch stats below)
2022-03-07 15:40:02 | INFO | train | epoch 695 | loss 0.67 | nll_loss 0.138 | ppl 1.1 | wps 24679.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33835 | lr 0.000171916 | gnorm 0.301 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 95852
2022-03-07 15:40:02 | INFO | fairseq.trainer | begin training epoch 696
2022-03-07 15:40:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:40:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:42:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:42:08 | INFO | valid | epoch 696 | valid on 'valid' subset | loss 14.286 | nll_loss 14.11 | ppl 17686.2 | wps 46449.9 | wpb 510.9 | bsz 1 | num_updates 33883 | best_loss 8.318
2022-03-07 15:42:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 696 @ 33883 updates
2022-03-07 15:42:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:42:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:42:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 696 @ 33883 updates, score 14.286) (writing took 2.559144364669919 seconds)
2022-03-07 15:42:11 | INFO | fairseq_cli.train | end of epoch 696 (average epoch stats below)
2022-03-07 15:42:11 | INFO | train | epoch 696 | loss 0.67 | nll_loss 0.138 | ppl 1.1 | wps 24190.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 33883 | lr 0.000171794 | gnorm 0.298 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 95981
2022-03-07 15:42:11 | INFO | fairseq.trainer | begin training epoch 697
2022-03-07 15:42:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:42:53 | INFO | train_inner | epoch 697:     17 / 49 loss=0.669, nll_loss=0.137, ppl=1.1, wps=24488.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33900, lr=0.000171751, gnorm=0.299, loss_scale=64, train_wall=226, gb_free=8.8, wall=96024
2022-03-07 15:44:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:44:17 | INFO | valid | epoch 697 | valid on 'valid' subset | loss 14.271 | nll_loss 14.093 | ppl 17475.9 | wps 46539.9 | wpb 510.9 | bsz 1 | num_updates 33932 | best_loss 8.318
2022-03-07 15:44:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 697 @ 33932 updates
2022-03-07 15:44:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:44:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:44:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 697 @ 33932 updates, score 14.271) (writing took 2.5458531957119703 seconds)
2022-03-07 15:44:19 | INFO | fairseq_cli.train | end of epoch 697 (average epoch stats below)
2022-03-07 15:44:19 | INFO | train | epoch 697 | loss 0.669 | nll_loss 0.137 | ppl 1.1 | wps 24695.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33932 | lr 0.00017167 | gnorm 0.298 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 96110
2022-03-07 15:44:19 | INFO | fairseq.trainer | begin training epoch 698
2022-03-07 15:44:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:46:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:46:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:46:25 | INFO | valid | epoch 698 | valid on 'valid' subset | loss 14.265 | nll_loss 14.086 | ppl 17389.1 | wps 46340.4 | wpb 510.9 | bsz 1 | num_updates 33980 | best_loss 8.318
2022-03-07 15:46:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 698 @ 33980 updates
2022-03-07 15:46:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:46:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:46:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 698 @ 33980 updates, score 14.265) (writing took 2.5480526257306337 seconds)
2022-03-07 15:46:28 | INFO | fairseq_cli.train | end of epoch 698 (average epoch stats below)
2022-03-07 15:46:28 | INFO | train | epoch 698 | loss 0.669 | nll_loss 0.137 | ppl 1.1 | wps 24190.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 33980 | lr 0.000171549 | gnorm 0.3 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 96238
2022-03-07 15:46:28 | INFO | fairseq.trainer | begin training epoch 699
2022-03-07 15:46:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:47:18 | INFO | train_inner | epoch 699:     20 / 49 loss=0.669, nll_loss=0.137, ppl=1.1, wps=24491, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=34000, lr=0.000171499, gnorm=0.299, loss_scale=64, train_wall=226, gb_free=8.8, wall=96288
2022-03-07 15:48:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:48:34 | INFO | valid | epoch 699 | valid on 'valid' subset | loss 14.221 | nll_loss 14.042 | ppl 16865.4 | wps 46646.5 | wpb 510.9 | bsz 1 | num_updates 34029 | best_loss 8.318
2022-03-07 15:48:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 699 @ 34029 updates
2022-03-07 15:48:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:48:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:48:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 699 @ 34029 updates, score 14.221) (writing took 2.549901319667697 seconds)
2022-03-07 15:48:37 | INFO | fairseq_cli.train | end of epoch 699 (average epoch stats below)
2022-03-07 15:48:37 | INFO | train | epoch 699 | loss 0.669 | nll_loss 0.137 | ppl 1.1 | wps 24702.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34029 | lr 0.000171425 | gnorm 0.299 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 96367
2022-03-07 15:48:37 | INFO | fairseq.trainer | begin training epoch 700
2022-03-07 15:48:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:50:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:50:43 | INFO | valid | epoch 700 | valid on 'valid' subset | loss 14.255 | nll_loss 14.077 | ppl 17281.6 | wps 46517.3 | wpb 510.9 | bsz 1 | num_updates 34078 | best_loss 8.318
2022-03-07 15:50:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 700 @ 34078 updates
2022-03-07 15:50:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:50:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:50:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 700 @ 34078 updates, score 14.255) (writing took 2.520743813365698 seconds)
2022-03-07 15:50:45 | INFO | fairseq_cli.train | end of epoch 700 (average epoch stats below)
2022-03-07 15:50:45 | INFO | train | epoch 700 | loss 0.668 | nll_loss 0.137 | ppl 1.1 | wps 24712.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34078 | lr 0.000171302 | gnorm 0.299 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 96496
2022-03-07 15:50:45 | INFO | fairseq.trainer | begin training epoch 701
2022-03-07 15:50:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:51:40 | INFO | train_inner | epoch 701:     22 / 49 loss=0.668, nll_loss=0.137, ppl=1.1, wps=24732.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=34100, lr=0.000171247, gnorm=0.298, loss_scale=64, train_wall=224, gb_free=8.8, wall=96551
2022-03-07 15:51:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:52:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:52:51 | INFO | valid | epoch 701 | valid on 'valid' subset | loss 14.242 | nll_loss 14.064 | ppl 17122.4 | wps 46596.9 | wpb 510.9 | bsz 1 | num_updates 34126 | best_loss 8.318
2022-03-07 15:52:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 701 @ 34126 updates
2022-03-07 15:52:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:52:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:52:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 701 @ 34126 updates, score 14.242) (writing took 2.5347697492688894 seconds)
2022-03-07 15:52:54 | INFO | fairseq_cli.train | end of epoch 701 (average epoch stats below)
2022-03-07 15:52:54 | INFO | train | epoch 701 | loss 0.668 | nll_loss 0.136 | ppl 1.1 | wps 24199.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 34126 | lr 0.000171182 | gnorm 0.297 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 96624
2022-03-07 15:52:54 | INFO | fairseq.trainer | begin training epoch 702
2022-03-07 15:52:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:54:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:55:00 | INFO | valid | epoch 702 | valid on 'valid' subset | loss 14.292 | nll_loss 14.114 | ppl 17729.7 | wps 46661.5 | wpb 510.9 | bsz 1 | num_updates 34175 | best_loss 8.318
2022-03-07 15:55:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 702 @ 34175 updates
2022-03-07 15:55:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:55:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:55:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 702 @ 34175 updates, score 14.292) (writing took 2.531995514407754 seconds)
2022-03-07 15:55:03 | INFO | fairseq_cli.train | end of epoch 702 (average epoch stats below)
2022-03-07 15:55:03 | INFO | train | epoch 702 | loss 0.669 | nll_loss 0.137 | ppl 1.1 | wps 24705.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34175 | lr 0.000171059 | gnorm 0.305 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 96753
2022-03-07 15:55:03 | INFO | fairseq.trainer | begin training epoch 703
2022-03-07 15:55:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:56:05 | INFO | train_inner | epoch 703:     25 / 49 loss=0.668, nll_loss=0.137, ppl=1.1, wps=24493.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=34200, lr=0.000170996, gnorm=0.302, loss_scale=64, train_wall=226, gb_free=8.8, wall=96816
2022-03-07 15:57:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:57:09 | INFO | valid | epoch 703 | valid on 'valid' subset | loss 14.251 | nll_loss 14.072 | ppl 17227.9 | wps 46363.7 | wpb 510.9 | bsz 1 | num_updates 34224 | best_loss 8.318
2022-03-07 15:57:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 703 @ 34224 updates
2022-03-07 15:57:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:57:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:57:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 703 @ 34224 updates, score 14.251) (writing took 2.557361824437976 seconds)
2022-03-07 15:57:11 | INFO | fairseq_cli.train | end of epoch 703 (average epoch stats below)
2022-03-07 15:57:11 | INFO | train | epoch 703 | loss 0.668 | nll_loss 0.136 | ppl 1.1 | wps 24690.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34224 | lr 0.000170936 | gnorm 0.299 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 96882
2022-03-07 15:57:11 | INFO | fairseq.trainer | begin training epoch 704
2022-03-07 15:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:57:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:59:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:59:17 | INFO | valid | epoch 704 | valid on 'valid' subset | loss 14.26 | nll_loss 14.082 | ppl 17341.9 | wps 46630.5 | wpb 510.9 | bsz 1 | num_updates 34272 | best_loss 8.318
2022-03-07 15:59:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 704 @ 34272 updates
2022-03-07 15:59:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:59:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 704 @ 34272 updates, score 14.26) (writing took 2.537860471755266 seconds)
2022-03-07 15:59:20 | INFO | fairseq_cli.train | end of epoch 704 (average epoch stats below)
2022-03-07 15:59:20 | INFO | train | epoch 704 | loss 0.668 | nll_loss 0.136 | ppl 1.1 | wps 24209.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 34272 | lr 0.000170817 | gnorm 0.299 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 97010
2022-03-07 15:59:20 | INFO | fairseq.trainer | begin training epoch 705
2022-03-07 15:59:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:00:30 | INFO | train_inner | epoch 705:     28 / 49 loss=0.668, nll_loss=0.136, ppl=1.1, wps=24490.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34300, lr=0.000170747, gnorm=0.299, loss_scale=64, train_wall=226, gb_free=8.8, wall=97080
2022-03-07 16:01:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:01:26 | INFO | valid | epoch 705 | valid on 'valid' subset | loss 14.358 | nll_loss 14.182 | ppl 18593 | wps 46505.3 | wpb 510.9 | bsz 1 | num_updates 34321 | best_loss 8.318
2022-03-07 16:01:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 705 @ 34321 updates
2022-03-07 16:01:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:01:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:01:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 705 @ 34321 updates, score 14.358) (writing took 2.533833187073469 seconds)
2022-03-07 16:01:29 | INFO | fairseq_cli.train | end of epoch 705 (average epoch stats below)
2022-03-07 16:01:29 | INFO | train | epoch 705 | loss 0.668 | nll_loss 0.137 | ppl 1.1 | wps 24645.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34321 | lr 0.000170695 | gnorm 0.301 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 97139
2022-03-07 16:01:29 | INFO | fairseq.trainer | begin training epoch 706
2022-03-07 16:01:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:03:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:03:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:03:35 | INFO | valid | epoch 706 | valid on 'valid' subset | loss 14.304 | nll_loss 14.128 | ppl 17903.3 | wps 46424.5 | wpb 510.9 | bsz 1 | num_updates 34369 | best_loss 8.318
2022-03-07 16:03:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 706 @ 34369 updates
2022-03-07 16:03:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:03:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:03:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 706 @ 34369 updates, score 14.304) (writing took 2.5310711599886417 seconds)
2022-03-07 16:03:37 | INFO | fairseq_cli.train | end of epoch 706 (average epoch stats below)
2022-03-07 16:03:37 | INFO | train | epoch 706 | loss 0.667 | nll_loss 0.136 | ppl 1.1 | wps 24185.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 34369 | lr 0.000170575 | gnorm 0.294 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 97268
2022-03-07 16:03:38 | INFO | fairseq.trainer | begin training epoch 707
2022-03-07 16:03:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:04:55 | INFO | train_inner | epoch 707:     31 / 49 loss=0.667, nll_loss=0.136, ppl=1.1, wps=24486.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34400, lr=0.000170499, gnorm=0.296, loss_scale=64, train_wall=226, gb_free=8.8, wall=97345
2022-03-07 16:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:05:44 | INFO | valid | epoch 707 | valid on 'valid' subset | loss 14.319 | nll_loss 14.142 | ppl 18084.7 | wps 46649.7 | wpb 510.9 | bsz 1 | num_updates 34418 | best_loss 8.318
2022-03-07 16:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 707 @ 34418 updates
2022-03-07 16:05:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:05:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:05:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 707 @ 34418 updates, score 14.319) (writing took 2.507212420925498 seconds)
2022-03-07 16:05:46 | INFO | fairseq_cli.train | end of epoch 707 (average epoch stats below)
2022-03-07 16:05:46 | INFO | train | epoch 707 | loss 0.667 | nll_loss 0.136 | ppl 1.1 | wps 24708.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34418 | lr 0.000170454 | gnorm 0.297 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 97396
2022-03-07 16:05:46 | INFO | fairseq.trainer | begin training epoch 708
2022-03-07 16:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:07:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:07:52 | INFO | valid | epoch 708 | valid on 'valid' subset | loss 14.279 | nll_loss 14.103 | ppl 17594.7 | wps 46535.5 | wpb 510.9 | bsz 1 | num_updates 34467 | best_loss 8.318
2022-03-07 16:07:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 708 @ 34467 updates
2022-03-07 16:07:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:07:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:07:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 708 @ 34467 updates, score 14.279) (writing took 2.5323755871504545 seconds)
2022-03-07 16:07:55 | INFO | fairseq_cli.train | end of epoch 708 (average epoch stats below)
2022-03-07 16:07:55 | INFO | train | epoch 708 | loss 0.667 | nll_loss 0.136 | ppl 1.1 | wps 24722.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34467 | lr 0.000170333 | gnorm 0.296 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 97525
2022-03-07 16:07:55 | INFO | fairseq.trainer | begin training epoch 709
2022-03-07 16:07:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:08:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:09:20 | INFO | train_inner | epoch 709:     34 / 49 loss=0.667, nll_loss=0.136, ppl=1.1, wps=24513.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34500, lr=0.000170251, gnorm=0.296, loss_scale=64, train_wall=226, gb_free=8.8, wall=97610
2022-03-07 16:09:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:10:01 | INFO | valid | epoch 709 | valid on 'valid' subset | loss 14.297 | nll_loss 14.119 | ppl 17798.8 | wps 46340.2 | wpb 510.9 | bsz 1 | num_updates 34515 | best_loss 8.318
2022-03-07 16:10:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 709 @ 34515 updates
2022-03-07 16:10:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:10:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:10:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 709 @ 34515 updates, score 14.297) (writing took 2.550695212557912 seconds)
2022-03-07 16:10:03 | INFO | fairseq_cli.train | end of epoch 709 (average epoch stats below)
2022-03-07 16:10:03 | INFO | train | epoch 709 | loss 0.667 | nll_loss 0.136 | ppl 1.1 | wps 24208.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 34515 | lr 0.000170214 | gnorm 0.294 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 97654
2022-03-07 16:10:03 | INFO | fairseq.trainer | begin training epoch 710
2022-03-07 16:10:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:12:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:12:09 | INFO | valid | epoch 710 | valid on 'valid' subset | loss 14.39 | nll_loss 14.214 | ppl 19008.5 | wps 46457.8 | wpb 510.9 | bsz 1 | num_updates 34564 | best_loss 8.318
2022-03-07 16:12:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 710 @ 34564 updates
2022-03-07 16:12:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:12:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:12:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 710 @ 34564 updates, score 14.39) (writing took 2.5351656321436167 seconds)
2022-03-07 16:12:12 | INFO | fairseq_cli.train | end of epoch 710 (average epoch stats below)
2022-03-07 16:12:12 | INFO | train | epoch 710 | loss 0.668 | nll_loss 0.136 | ppl 1.1 | wps 24716.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34564 | lr 0.000170094 | gnorm 0.3 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 97782
2022-03-07 16:12:12 | INFO | fairseq.trainer | begin training epoch 711
2022-03-07 16:12:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:13:42 | INFO | train_inner | epoch 711:     36 / 49 loss=0.667, nll_loss=0.136, ppl=1.1, wps=24745.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=34600, lr=0.000170005, gnorm=0.299, loss_scale=64, train_wall=223, gb_free=8.8, wall=97872
2022-03-07 16:14:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:14:18 | INFO | valid | epoch 711 | valid on 'valid' subset | loss 14.312 | nll_loss 14.137 | ppl 18021.3 | wps 46477 | wpb 510.9 | bsz 1 | num_updates 34613 | best_loss 8.318
2022-03-07 16:14:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 711 @ 34613 updates
2022-03-07 16:14:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:14:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:14:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 711 @ 34613 updates, score 14.312) (writing took 2.5168762765824795 seconds)
2022-03-07 16:14:20 | INFO | fairseq_cli.train | end of epoch 711 (average epoch stats below)
2022-03-07 16:14:20 | INFO | train | epoch 711 | loss 0.667 | nll_loss 0.135 | ppl 1.1 | wps 24722.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34613 | lr 0.000169973 | gnorm 0.298 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 97911
2022-03-07 16:14:20 | INFO | fairseq.trainer | begin training epoch 712
2022-03-07 16:14:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:14:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:16:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:16:26 | INFO | valid | epoch 712 | valid on 'valid' subset | loss 14.23 | nll_loss 14.054 | ppl 17005.3 | wps 46358.4 | wpb 510.9 | bsz 1 | num_updates 34661 | best_loss 8.318
2022-03-07 16:16:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 712 @ 34661 updates
2022-03-07 16:16:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:16:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:16:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 712 @ 34661 updates, score 14.23) (writing took 2.5136241894215345 seconds)
2022-03-07 16:16:29 | INFO | fairseq_cli.train | end of epoch 712 (average epoch stats below)
2022-03-07 16:16:29 | INFO | train | epoch 712 | loss 0.667 | nll_loss 0.136 | ppl 1.1 | wps 24194.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 34661 | lr 0.000169855 | gnorm 0.297 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 98039
2022-03-07 16:16:29 | INFO | fairseq.trainer | begin training epoch 713
2022-03-07 16:16:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:18:07 | INFO | train_inner | epoch 713:     39 / 49 loss=0.667, nll_loss=0.135, ppl=1.1, wps=24505.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=34700, lr=0.00016976, gnorm=0.298, loss_scale=64, train_wall=226, gb_free=8.8, wall=98137
2022-03-07 16:18:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:18:35 | INFO | valid | epoch 713 | valid on 'valid' subset | loss 14.248 | nll_loss 14.071 | ppl 17211.5 | wps 46619.2 | wpb 510.9 | bsz 1 | num_updates 34710 | best_loss 8.318
2022-03-07 16:18:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 713 @ 34710 updates
2022-03-07 16:18:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:18:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:18:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 713 @ 34710 updates, score 14.248) (writing took 2.5292665734887123 seconds)
2022-03-07 16:18:38 | INFO | fairseq_cli.train | end of epoch 713 (average epoch stats below)
2022-03-07 16:18:38 | INFO | train | epoch 713 | loss 0.667 | nll_loss 0.135 | ppl 1.1 | wps 24713.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34710 | lr 0.000169736 | gnorm 0.298 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 98168
2022-03-07 16:18:38 | INFO | fairseq.trainer | begin training epoch 714
2022-03-07 16:18:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:20:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:20:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:20:46 | INFO | valid | epoch 714 | valid on 'valid' subset | loss 14.257 | nll_loss 14.08 | ppl 17319.9 | wps 42953.1 | wpb 510.9 | bsz 1 | num_updates 34758 | best_loss 8.318
2022-03-07 16:20:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 714 @ 34758 updates
2022-03-07 16:20:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:20:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:20:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 714 @ 34758 updates, score 14.257) (writing took 2.5982171073555946 seconds)
2022-03-07 16:20:49 | INFO | fairseq_cli.train | end of epoch 714 (average epoch stats below)
2022-03-07 16:20:49 | INFO | train | epoch 714 | loss 0.666 | nll_loss 0.135 | ppl 1.1 | wps 23677.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 34758 | lr 0.000169618 | gnorm 0.296 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 98299
2022-03-07 16:20:49 | INFO | fairseq.trainer | begin training epoch 715
2022-03-07 16:20:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:22:38 | INFO | train_inner | epoch 715:     42 / 49 loss=0.666, nll_loss=0.135, ppl=1.1, wps=23914, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=34800, lr=0.000169516, gnorm=0.297, loss_scale=64, train_wall=231, gb_free=8.8, wall=98408
2022-03-07 16:22:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:23:00 | INFO | valid | epoch 715 | valid on 'valid' subset | loss 14.288 | nll_loss 14.113 | ppl 17714.1 | wps 43060.4 | wpb 510.9 | bsz 1 | num_updates 34807 | best_loss 8.318
2022-03-07 16:23:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 715 @ 34807 updates
2022-03-07 16:23:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:23:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:23:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 715 @ 34807 updates, score 14.288) (writing took 2.5761430710554123 seconds)
2022-03-07 16:23:02 | INFO | fairseq_cli.train | end of epoch 715 (average epoch stats below)
2022-03-07 16:23:02 | INFO | train | epoch 715 | loss 0.666 | nll_loss 0.135 | ppl 1.1 | wps 23826.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 34807 | lr 0.000169499 | gnorm 0.298 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 98433
2022-03-07 16:23:02 | INFO | fairseq.trainer | begin training epoch 716
2022-03-07 16:23:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:25:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:25:14 | INFO | valid | epoch 716 | valid on 'valid' subset | loss 14.269 | nll_loss 14.093 | ppl 17474.5 | wps 44069.6 | wpb 510.9 | bsz 1 | num_updates 34856 | best_loss 8.318
2022-03-07 16:25:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 716 @ 34856 updates
2022-03-07 16:25:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:25:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:25:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 716 @ 34856 updates, score 14.269) (writing took 2.6181381084024906 seconds)
2022-03-07 16:25:17 | INFO | fairseq_cli.train | end of epoch 716 (average epoch stats below)
2022-03-07 16:25:17 | INFO | train | epoch 716 | loss 0.666 | nll_loss 0.135 | ppl 1.1 | wps 23696.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 34856 | lr 0.00016938 | gnorm 0.297 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 98567
2022-03-07 16:25:17 | INFO | fairseq.trainer | begin training epoch 717
2022-03-07 16:25:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:26:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:27:13 | INFO | train_inner | epoch 717:     45 / 49 loss=0.666, nll_loss=0.135, ppl=1.1, wps=23574.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=34900, lr=0.000169273, gnorm=0.297, loss_scale=64, train_wall=235, gb_free=8.8, wall=98683
2022-03-07 16:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:27:27 | INFO | valid | epoch 717 | valid on 'valid' subset | loss 14.277 | nll_loss 14.103 | ppl 17595.5 | wps 43546.6 | wpb 510.9 | bsz 1 | num_updates 34904 | best_loss 8.318
2022-03-07 16:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 717 @ 34904 updates
2022-03-07 16:27:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:27:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:27:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 717 @ 34904 updates, score 14.277) (writing took 2.5668271500617266 seconds)
2022-03-07 16:27:30 | INFO | fairseq_cli.train | end of epoch 717 (average epoch stats below)
2022-03-07 16:27:30 | INFO | train | epoch 717 | loss 0.665 | nll_loss 0.134 | ppl 1.1 | wps 23360.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 34904 | lr 0.000169263 | gnorm 0.296 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 98700
2022-03-07 16:27:30 | INFO | fairseq.trainer | begin training epoch 718
2022-03-07 16:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:29:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:29:41 | INFO | valid | epoch 718 | valid on 'valid' subset | loss 14.219 | nll_loss 14.042 | ppl 16867.3 | wps 43798.3 | wpb 510.9 | bsz 1 | num_updates 34953 | best_loss 8.318
2022-03-07 16:29:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 718 @ 34953 updates
2022-03-07 16:29:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:29:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:29:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 718 @ 34953 updates, score 14.219) (writing took 2.5737950392067432 seconds)
2022-03-07 16:29:44 | INFO | fairseq_cli.train | end of epoch 718 (average epoch stats below)
2022-03-07 16:29:44 | INFO | train | epoch 718 | loss 0.666 | nll_loss 0.135 | ppl 1.1 | wps 23767.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 34953 | lr 0.000169144 | gnorm 0.296 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 98834
2022-03-07 16:29:44 | INFO | fairseq.trainer | begin training epoch 719
2022-03-07 16:29:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:31:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:31:48 | INFO | train_inner | epoch 719:     48 / 49 loss=0.666, nll_loss=0.135, ppl=1.1, wps=23588.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=35000, lr=0.000169031, gnorm=0.297, loss_scale=32, train_wall=235, gb_free=8.8, wall=98958
2022-03-07 16:31:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:31:54 | INFO | valid | epoch 719 | valid on 'valid' subset | loss 14.29 | nll_loss 14.113 | ppl 17722.5 | wps 43784.1 | wpb 510.9 | bsz 1 | num_updates 35001 | best_loss 8.318
2022-03-07 16:31:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 719 @ 35001 updates
2022-03-07 16:31:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:31:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:31:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 719 @ 35001 updates, score 14.29) (writing took 2.5856814943253994 seconds)
2022-03-07 16:31:57 | INFO | fairseq_cli.train | end of epoch 719 (average epoch stats below)
2022-03-07 16:31:57 | INFO | train | epoch 719 | loss 0.666 | nll_loss 0.135 | ppl 1.1 | wps 23312.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 35001 | lr 0.000169028 | gnorm 0.297 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 98967
2022-03-07 16:31:57 | INFO | fairseq.trainer | begin training epoch 720
2022-03-07 16:31:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:34:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:34:09 | INFO | valid | epoch 720 | valid on 'valid' subset | loss 14.281 | nll_loss 14.104 | ppl 17613.7 | wps 43376.6 | wpb 510.9 | bsz 1 | num_updates 35050 | best_loss 8.318
2022-03-07 16:34:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 720 @ 35050 updates
2022-03-07 16:34:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:34:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:34:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 720 @ 35050 updates, score 14.281) (writing took 2.560410926118493 seconds)
2022-03-07 16:34:11 | INFO | fairseq_cli.train | end of epoch 720 (average epoch stats below)
2022-03-07 16:34:11 | INFO | train | epoch 720 | loss 0.666 | nll_loss 0.135 | ppl 1.1 | wps 23658.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35050 | lr 0.00016891 | gnorm 0.296 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 99102
2022-03-07 16:34:11 | INFO | fairseq.trainer | begin training epoch 721
2022-03-07 16:34:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:36:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:36:22 | INFO | valid | epoch 721 | valid on 'valid' subset | loss 14.209 | nll_loss 14.031 | ppl 16741.5 | wps 43406.8 | wpb 510.9 | bsz 1 | num_updates 35099 | best_loss 8.318
2022-03-07 16:36:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 721 @ 35099 updates
2022-03-07 16:36:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:36:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:36:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 721 @ 35099 updates, score 14.209) (writing took 2.5842914264649153 seconds)
2022-03-07 16:36:24 | INFO | fairseq_cli.train | end of epoch 721 (average epoch stats below)
2022-03-07 16:36:24 | INFO | train | epoch 721 | loss 0.666 | nll_loss 0.135 | ppl 1.1 | wps 23871.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35099 | lr 0.000168792 | gnorm 0.295 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 99235
2022-03-07 16:36:25 | INFO | fairseq.trainer | begin training epoch 722
2022-03-07 16:36:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:36:27 | INFO | train_inner | epoch 722:      1 / 49 loss=0.666, nll_loss=0.135, ppl=1.1, wps=23124, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=35100, lr=0.00016879, gnorm=0.296, loss_scale=32, train_wall=231, gb_free=8.8, wall=99237
2022-03-07 16:38:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:38:36 | INFO | valid | epoch 722 | valid on 'valid' subset | loss 14.269 | nll_loss 14.093 | ppl 17479 | wps 43493.6 | wpb 510.9 | bsz 1 | num_updates 35148 | best_loss 8.318
2022-03-07 16:38:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 722 @ 35148 updates
2022-03-07 16:38:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:38:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:38:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 722 @ 35148 updates, score 14.269) (writing took 2.5587865747511387 seconds)
2022-03-07 16:38:39 | INFO | fairseq_cli.train | end of epoch 722 (average epoch stats below)
2022-03-07 16:38:39 | INFO | train | epoch 722 | loss 0.666 | nll_loss 0.135 | ppl 1.1 | wps 23700.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35148 | lr 0.000168675 | gnorm 0.298 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 99369
2022-03-07 16:38:39 | INFO | fairseq.trainer | begin training epoch 723
2022-03-07 16:38:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:40:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:40:49 | INFO | valid | epoch 723 | valid on 'valid' subset | loss 14.272 | nll_loss 14.097 | ppl 17526.7 | wps 43376.1 | wpb 510.9 | bsz 1 | num_updates 35197 | best_loss 8.318
2022-03-07 16:40:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 723 @ 35197 updates
2022-03-07 16:40:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:40:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:40:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 723 @ 35197 updates, score 14.272) (writing took 2.5939819142222404 seconds)
2022-03-07 16:40:52 | INFO | fairseq_cli.train | end of epoch 723 (average epoch stats below)
2022-03-07 16:40:52 | INFO | train | epoch 723 | loss 0.666 | nll_loss 0.135 | ppl 1.1 | wps 23907 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35197 | lr 0.000168557 | gnorm 0.302 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 99502
2022-03-07 16:40:52 | INFO | fairseq.trainer | begin training epoch 724
2022-03-07 16:40:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:40:59 | INFO | train_inner | epoch 724:      3 / 49 loss=0.666, nll_loss=0.135, ppl=1.1, wps=23833.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=35200, lr=0.00016855, gnorm=0.3, loss_scale=64, train_wall=232, gb_free=8.8, wall=99510
2022-03-07 16:42:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:42:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:43:02 | INFO | valid | epoch 724 | valid on 'valid' subset | loss 14.24 | nll_loss 14.064 | ppl 17129.9 | wps 43626 | wpb 510.9 | bsz 1 | num_updates 35245 | best_loss 8.318
2022-03-07 16:43:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 724 @ 35245 updates
2022-03-07 16:43:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:43:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:43:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 724 @ 35245 updates, score 14.24) (writing took 2.5576760210096836 seconds)
2022-03-07 16:43:04 | INFO | fairseq_cli.train | end of epoch 724 (average epoch stats below)
2022-03-07 16:43:04 | INFO | train | epoch 724 | loss 0.665 | nll_loss 0.134 | ppl 1.1 | wps 23434.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 35245 | lr 0.000168442 | gnorm 0.297 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 99635
2022-03-07 16:43:04 | INFO | fairseq.trainer | begin training epoch 725
2022-03-07 16:43:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:45:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:45:16 | INFO | valid | epoch 725 | valid on 'valid' subset | loss 14.193 | nll_loss 14.014 | ppl 16541.3 | wps 43764.1 | wpb 510.9 | bsz 1 | num_updates 35294 | best_loss 8.318
2022-03-07 16:45:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 725 @ 35294 updates
2022-03-07 16:45:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:45:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:45:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 725 @ 35294 updates, score 14.193) (writing took 2.5770175959914923 seconds)
2022-03-07 16:45:18 | INFO | fairseq_cli.train | end of epoch 725 (average epoch stats below)
2022-03-07 16:45:18 | INFO | train | epoch 725 | loss 0.665 | nll_loss 0.134 | ppl 1.1 | wps 23752 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35294 | lr 0.000168325 | gnorm 0.294 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 99768
2022-03-07 16:45:18 | INFO | fairseq.trainer | begin training epoch 726
2022-03-07 16:45:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:45:34 | INFO | train_inner | epoch 726:      6 / 49 loss=0.665, nll_loss=0.134, ppl=1.1, wps=23650.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=35300, lr=0.000168311, gnorm=0.295, loss_scale=64, train_wall=234, gb_free=8.8, wall=99784
2022-03-07 16:47:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:47:29 | INFO | valid | epoch 726 | valid on 'valid' subset | loss 14.315 | nll_loss 14.14 | ppl 18052.3 | wps 43776.5 | wpb 510.9 | bsz 1 | num_updates 35343 | best_loss 8.318
2022-03-07 16:47:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 726 @ 35343 updates
2022-03-07 16:47:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:47:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:47:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 726 @ 35343 updates, score 14.315) (writing took 2.5352222956717014 seconds)
2022-03-07 16:47:31 | INFO | fairseq_cli.train | end of epoch 726 (average epoch stats below)
2022-03-07 16:47:31 | INFO | train | epoch 726 | loss 0.664 | nll_loss 0.134 | ppl 1.1 | wps 23865 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35343 | lr 0.000168209 | gnorm 0.295 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 99902
2022-03-07 16:47:31 | INFO | fairseq.trainer | begin training epoch 727
2022-03-07 16:47:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:48:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:49:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:49:43 | INFO | valid | epoch 727 | valid on 'valid' subset | loss 14.315 | nll_loss 14.14 | ppl 18057.5 | wps 42659.7 | wpb 510.9 | bsz 1 | num_updates 35391 | best_loss 8.318
2022-03-07 16:49:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 727 @ 35391 updates
2022-03-07 16:49:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:49:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:49:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 727 @ 35391 updates, score 14.315) (writing took 2.5871786810457706 seconds)
2022-03-07 16:49:46 | INFO | fairseq_cli.train | end of epoch 727 (average epoch stats below)
2022-03-07 16:49:46 | INFO | train | epoch 727 | loss 0.665 | nll_loss 0.134 | ppl 1.1 | wps 23102.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 35391 | lr 0.000168095 | gnorm 0.296 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 100036
2022-03-07 16:49:46 | INFO | fairseq.trainer | begin training epoch 728
2022-03-07 16:49:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:50:10 | INFO | train_inner | epoch 728:      9 / 49 loss=0.664, nll_loss=0.134, ppl=1.1, wps=23505.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=35400, lr=0.000168073, gnorm=0.295, loss_scale=64, train_wall=236, gb_free=8.8, wall=100060
2022-03-07 16:51:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:51:58 | INFO | valid | epoch 728 | valid on 'valid' subset | loss 14.218 | nll_loss 14.042 | ppl 16870.7 | wps 42824.1 | wpb 510.9 | bsz 1 | num_updates 35440 | best_loss 8.318
2022-03-07 16:51:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 728 @ 35440 updates
2022-03-07 16:51:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:52:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:52:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 728 @ 35440 updates, score 14.218) (writing took 2.561698604375124 seconds)
2022-03-07 16:52:01 | INFO | fairseq_cli.train | end of epoch 728 (average epoch stats below)
2022-03-07 16:52:01 | INFO | train | epoch 728 | loss 0.664 | nll_loss 0.134 | ppl 1.1 | wps 23538.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35440 | lr 0.000167978 | gnorm 0.293 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 100171
2022-03-07 16:52:01 | INFO | fairseq.trainer | begin training epoch 729
2022-03-07 16:52:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:54:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:54:13 | INFO | valid | epoch 729 | valid on 'valid' subset | loss 14.283 | nll_loss 14.109 | ppl 17664.2 | wps 42825.8 | wpb 510.9 | bsz 1 | num_updates 35489 | best_loss 8.318
2022-03-07 16:54:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 729 @ 35489 updates
2022-03-07 16:54:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:54:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:54:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 729 @ 35489 updates, score 14.283) (writing took 2.5485849790275097 seconds)
2022-03-07 16:54:15 | INFO | fairseq_cli.train | end of epoch 729 (average epoch stats below)
2022-03-07 16:54:15 | INFO | train | epoch 729 | loss 0.665 | nll_loss 0.134 | ppl 1.1 | wps 23672.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35489 | lr 0.000167862 | gnorm 0.297 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 100306
2022-03-07 16:54:15 | INFO | fairseq.trainer | begin training epoch 730
2022-03-07 16:54:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:54:44 | INFO | train_inner | epoch 730:     11 / 49 loss=0.665, nll_loss=0.134, ppl=1.1, wps=23644, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=35500, lr=0.000167836, gnorm=0.295, loss_scale=128, train_wall=234, gb_free=8.8, wall=100334
2022-03-07 16:54:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:56:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:56:27 | INFO | valid | epoch 730 | valid on 'valid' subset | loss 14.239 | nll_loss 14.062 | ppl 17097.8 | wps 42868.7 | wpb 510.9 | bsz 1 | num_updates 35537 | best_loss 8.318
2022-03-07 16:56:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 730 @ 35537 updates
2022-03-07 16:56:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:56:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:56:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 730 @ 35537 updates, score 14.239) (writing took 2.542902644723654 seconds)
2022-03-07 16:56:30 | INFO | fairseq_cli.train | end of epoch 730 (average epoch stats below)
2022-03-07 16:56:30 | INFO | train | epoch 730 | loss 0.664 | nll_loss 0.134 | ppl 1.1 | wps 23127.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 35537 | lr 0.000167749 | gnorm 0.295 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 100440
2022-03-07 16:56:30 | INFO | fairseq.trainer | begin training epoch 731
2022-03-07 16:56:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:58:43 | INFO | valid | epoch 731 | valid on 'valid' subset | loss 14.294 | nll_loss 14.119 | ppl 17796.1 | wps 40020 | wpb 510.9 | bsz 1 | num_updates 35586 | best_loss 8.318
2022-03-07 16:58:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 731 @ 35586 updates
2022-03-07 16:58:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:58:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:58:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 731 @ 35586 updates, score 14.294) (writing took 2.5406006798148155 seconds)
2022-03-07 16:58:45 | INFO | fairseq_cli.train | end of epoch 731 (average epoch stats below)
2022-03-07 16:58:45 | INFO | train | epoch 731 | loss 0.664 | nll_loss 0.133 | ppl 1.1 | wps 23444.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35586 | lr 0.000167633 | gnorm 0.291 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 100576
2022-03-07 16:58:45 | INFO | fairseq.trainer | begin training epoch 732
2022-03-07 16:58:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:59:23 | INFO | train_inner | epoch 732:     14 / 49 loss=0.664, nll_loss=0.133, ppl=1.1, wps=23256.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=35600, lr=0.0001676, gnorm=0.293, loss_scale=64, train_wall=238, gb_free=8.8, wall=100613
2022-03-07 17:00:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:00:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:01:00 | INFO | valid | epoch 732 | valid on 'valid' subset | loss 14.289 | nll_loss 14.114 | ppl 17729.4 | wps 41456.4 | wpb 510.9 | bsz 1 | num_updates 35634 | best_loss 8.318
2022-03-07 17:01:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 732 @ 35634 updates
2022-03-07 17:01:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:01:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:01:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 732 @ 35634 updates, score 14.289) (writing took 2.529974414035678 seconds)
2022-03-07 17:01:02 | INFO | fairseq_cli.train | end of epoch 732 (average epoch stats below)
2022-03-07 17:01:02 | INFO | train | epoch 732 | loss 0.664 | nll_loss 0.133 | ppl 1.1 | wps 22742.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 35634 | lr 0.00016752 | gnorm 0.293 | loss_scale 64 | train_wall 117 | gb_free 8.8 | wall 100713
2022-03-07 17:01:02 | INFO | fairseq.trainer | begin training epoch 733
2022-03-07 17:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:03:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:03:17 | INFO | valid | epoch 733 | valid on 'valid' subset | loss 14.252 | nll_loss 14.076 | ppl 17267.5 | wps 41456.9 | wpb 510.9 | bsz 1 | num_updates 35683 | best_loss 8.318
2022-03-07 17:03:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 733 @ 35683 updates
2022-03-07 17:03:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:03:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:03:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 733 @ 35683 updates, score 14.252) (writing took 2.5625406559556723 seconds)
2022-03-07 17:03:19 | INFO | fairseq_cli.train | end of epoch 733 (average epoch stats below)
2022-03-07 17:03:19 | INFO | train | epoch 733 | loss 0.664 | nll_loss 0.133 | ppl 1.1 | wps 23174.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35683 | lr 0.000167405 | gnorm 0.294 | loss_scale 64 | train_wall 117 | gb_free 8.8 | wall 100850
2022-03-07 17:03:19 | INFO | fairseq.trainer | begin training epoch 734
2022-03-07 17:03:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:04:05 | INFO | train_inner | epoch 734:     17 / 49 loss=0.663, nll_loss=0.133, ppl=1.1, wps=22978.3, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=35700, lr=0.000167365, gnorm=0.293, loss_scale=64, train_wall=241, gb_free=8.8, wall=100896
2022-03-07 17:05:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:05:30 | INFO | valid | epoch 734 | valid on 'valid' subset | loss 14.251 | nll_loss 14.076 | ppl 17269.2 | wps 45587.7 | wpb 510.9 | bsz 1 | num_updates 35732 | best_loss 8.318
2022-03-07 17:05:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 734 @ 35732 updates
2022-03-07 17:05:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:05:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:05:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 734 @ 35732 updates, score 14.251) (writing took 2.5444163847714663 seconds)
2022-03-07 17:05:32 | INFO | fairseq_cli.train | end of epoch 734 (average epoch stats below)
2022-03-07 17:05:32 | INFO | train | epoch 734 | loss 0.664 | nll_loss 0.134 | ppl 1.1 | wps 23928.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35732 | lr 0.000167291 | gnorm 0.292 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 100983
2022-03-07 17:05:32 | INFO | fairseq.trainer | begin training epoch 735
2022-03-07 17:05:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:06:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:07:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:07:39 | INFO | valid | epoch 735 | valid on 'valid' subset | loss 14.377 | nll_loss 14.204 | ppl 18877.5 | wps 46073.9 | wpb 510.9 | bsz 1 | num_updates 35780 | best_loss 8.318
2022-03-07 17:07:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 735 @ 35780 updates
2022-03-07 17:07:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:07:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:07:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 735 @ 35780 updates, score 14.377) (writing took 2.51356640458107 seconds)
2022-03-07 17:07:42 | INFO | fairseq_cli.train | end of epoch 735 (average epoch stats below)
2022-03-07 17:07:42 | INFO | train | epoch 735 | loss 0.663 | nll_loss 0.133 | ppl 1.1 | wps 24068.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 35780 | lr 0.000167178 | gnorm 0.293 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 101112
2022-03-07 17:07:42 | INFO | fairseq.trainer | begin training epoch 736
2022-03-07 17:07:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:08:32 | INFO | train_inner | epoch 736:     20 / 49 loss=0.664, nll_loss=0.133, ppl=1.1, wps=24318.1, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=35800, lr=0.000167132, gnorm=0.293, loss_scale=64, train_wall=228, gb_free=8.8, wall=101162
2022-03-07 17:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:09:48 | INFO | valid | epoch 736 | valid on 'valid' subset | loss 14.194 | nll_loss 14.018 | ppl 16585.9 | wps 46021.9 | wpb 510.9 | bsz 1 | num_updates 35829 | best_loss 8.318
2022-03-07 17:09:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 736 @ 35829 updates
2022-03-07 17:09:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:09:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:09:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 736 @ 35829 updates, score 14.194) (writing took 2.53662439994514 seconds)
2022-03-07 17:09:51 | INFO | fairseq_cli.train | end of epoch 736 (average epoch stats below)
2022-03-07 17:09:51 | INFO | train | epoch 736 | loss 0.664 | nll_loss 0.133 | ppl 1.1 | wps 24597.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35829 | lr 0.000167064 | gnorm 0.293 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 101241
2022-03-07 17:09:51 | INFO | fairseq.trainer | begin training epoch 737
2022-03-07 17:09:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:11:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:11:58 | INFO | valid | epoch 737 | valid on 'valid' subset | loss 14.312 | nll_loss 14.138 | ppl 18030.1 | wps 44797.4 | wpb 510.9 | bsz 1 | num_updates 35878 | best_loss 8.318
2022-03-07 17:11:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 737 @ 35878 updates
2022-03-07 17:11:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:12:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:12:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 737 @ 35878 updates, score 14.312) (writing took 2.508579159155488 seconds)
2022-03-07 17:12:00 | INFO | fairseq_cli.train | end of epoch 737 (average epoch stats below)
2022-03-07 17:12:00 | INFO | train | epoch 737 | loss 0.664 | nll_loss 0.133 | ppl 1.1 | wps 24526 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35878 | lr 0.00016695 | gnorm 0.293 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 101371
2022-03-07 17:12:00 | INFO | fairseq.trainer | begin training epoch 738
2022-03-07 17:12:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:12:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:12:58 | INFO | train_inner | epoch 738:     23 / 49 loss=0.663, nll_loss=0.133, ppl=1.1, wps=24363.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=35900, lr=0.000166899, gnorm=0.293, loss_scale=64, train_wall=227, gb_free=8.8, wall=101429
2022-03-07 17:14:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:14:07 | INFO | valid | epoch 738 | valid on 'valid' subset | loss 14.27 | nll_loss 14.095 | ppl 17494 | wps 45949.2 | wpb 510.9 | bsz 1 | num_updates 35926 | best_loss 8.318
2022-03-07 17:14:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 738 @ 35926 updates
2022-03-07 17:14:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:14:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:14:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 738 @ 35926 updates, score 14.27) (writing took 2.5506924279034138 seconds)
2022-03-07 17:14:10 | INFO | fairseq_cli.train | end of epoch 738 (average epoch stats below)
2022-03-07 17:14:10 | INFO | train | epoch 738 | loss 0.663 | nll_loss 0.133 | ppl 1.1 | wps 24036.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 35926 | lr 0.000166838 | gnorm 0.294 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 101500
2022-03-07 17:14:10 | INFO | fairseq.trainer | begin training epoch 739
2022-03-07 17:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:16:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:16:17 | INFO | valid | epoch 739 | valid on 'valid' subset | loss 14.388 | nll_loss 14.214 | ppl 19005.2 | wps 45475.3 | wpb 510.9 | bsz 1 | num_updates 35975 | best_loss 8.318
2022-03-07 17:16:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 739 @ 35975 updates
2022-03-07 17:16:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:16:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:16:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 739 @ 35975 updates, score 14.388) (writing took 2.517141953110695 seconds)
2022-03-07 17:16:19 | INFO | fairseq_cli.train | end of epoch 739 (average epoch stats below)
2022-03-07 17:16:19 | INFO | train | epoch 739 | loss 0.663 | nll_loss 0.133 | ppl 1.1 | wps 24589.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35975 | lr 0.000166725 | gnorm 0.294 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 101629
2022-03-07 17:16:19 | INFO | fairseq.trainer | begin training epoch 740
2022-03-07 17:16:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:17:22 | INFO | train_inner | epoch 740:     25 / 49 loss=0.663, nll_loss=0.133, ppl=1.1, wps=24636, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=36000, lr=0.000166667, gnorm=0.295, loss_scale=64, train_wall=224, gb_free=8.8, wall=101692
2022-03-07 17:18:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:18:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:18:25 | INFO | valid | epoch 740 | valid on 'valid' subset | loss 14.29 | nll_loss 14.115 | ppl 17748.6 | wps 46506.3 | wpb 510.9 | bsz 1 | num_updates 36023 | best_loss 8.318
2022-03-07 17:18:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 740 @ 36023 updates
2022-03-07 17:18:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:18:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:18:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 740 @ 36023 updates, score 14.29) (writing took 2.545126151293516 seconds)
2022-03-07 17:18:28 | INFO | fairseq_cli.train | end of epoch 740 (average epoch stats below)
2022-03-07 17:18:28 | INFO | train | epoch 740 | loss 0.663 | nll_loss 0.133 | ppl 1.1 | wps 24206.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 36023 | lr 0.000166613 | gnorm 0.293 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 101758
2022-03-07 17:18:28 | INFO | fairseq.trainer | begin training epoch 741
2022-03-07 17:18:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:20:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:20:34 | INFO | valid | epoch 741 | valid on 'valid' subset | loss 14.307 | nll_loss 14.131 | ppl 17939.7 | wps 46191.3 | wpb 510.9 | bsz 1 | num_updates 36072 | best_loss 8.318
2022-03-07 17:20:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 741 @ 36072 updates
2022-03-07 17:20:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:20:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:20:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 741 @ 36072 updates, score 14.307) (writing took 2.5338909830898046 seconds)
2022-03-07 17:20:36 | INFO | fairseq_cli.train | end of epoch 741 (average epoch stats below)
2022-03-07 17:20:36 | INFO | train | epoch 741 | loss 0.662 | nll_loss 0.132 | ppl 1.1 | wps 24674.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36072 | lr 0.0001665 | gnorm 0.29 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 101887
2022-03-07 17:20:36 | INFO | fairseq.trainer | begin training epoch 742
2022-03-07 17:20:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:21:47 | INFO | train_inner | epoch 742:     28 / 49 loss=0.662, nll_loss=0.132, ppl=1.1, wps=24445.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=36100, lr=0.000166436, gnorm=0.291, loss_scale=64, train_wall=226, gb_free=8.8, wall=101957
2022-03-07 17:22:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:22:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:22:43 | INFO | valid | epoch 742 | valid on 'valid' subset | loss 14.286 | nll_loss 14.111 | ppl 17693.6 | wps 45911.8 | wpb 510.9 | bsz 1 | num_updates 36120 | best_loss 8.318
2022-03-07 17:22:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 742 @ 36120 updates
2022-03-07 17:22:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:22:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:22:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 742 @ 36120 updates, score 14.286) (writing took 2.505588199943304 seconds)
2022-03-07 17:22:46 | INFO | fairseq_cli.train | end of epoch 742 (average epoch stats below)
2022-03-07 17:22:46 | INFO | train | epoch 742 | loss 0.662 | nll_loss 0.132 | ppl 1.1 | wps 24053.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 36120 | lr 0.00016639 | gnorm 0.291 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 102016
2022-03-07 17:22:46 | INFO | fairseq.trainer | begin training epoch 743
2022-03-07 17:22:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:24:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:24:53 | INFO | valid | epoch 743 | valid on 'valid' subset | loss 14.245 | nll_loss 14.069 | ppl 17181.2 | wps 45832.9 | wpb 510.9 | bsz 1 | num_updates 36169 | best_loss 8.318
2022-03-07 17:24:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 743 @ 36169 updates
2022-03-07 17:24:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:24:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:24:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 743 @ 36169 updates, score 14.245) (writing took 2.39619748480618 seconds)
2022-03-07 17:24:56 | INFO | fairseq_cli.train | end of epoch 743 (average epoch stats below)
2022-03-07 17:24:56 | INFO | train | epoch 743 | loss 0.663 | nll_loss 0.133 | ppl 1.1 | wps 24501.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36169 | lr 0.000166277 | gnorm 0.293 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 102146
2022-03-07 17:24:56 | INFO | fairseq.trainer | begin training epoch 744
2022-03-07 17:24:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:26:14 | INFO | train_inner | epoch 744:     31 / 49 loss=0.662, nll_loss=0.132, ppl=1.1, wps=24325.2, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=36200, lr=0.000166206, gnorm=0.291, loss_scale=32, train_wall=228, gb_free=8.8, wall=102224
2022-03-07 17:26:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:27:03 | INFO | valid | epoch 744 | valid on 'valid' subset | loss 14.239 | nll_loss 14.063 | ppl 17112.9 | wps 45821.8 | wpb 510.9 | bsz 1 | num_updates 36218 | best_loss 8.318
2022-03-07 17:27:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 744 @ 36218 updates
2022-03-07 17:27:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:27:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:27:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 744 @ 36218 updates, score 14.239) (writing took 2.5699966475367546 seconds)
2022-03-07 17:27:05 | INFO | fairseq_cli.train | end of epoch 744 (average epoch stats below)
2022-03-07 17:27:05 | INFO | train | epoch 744 | loss 0.662 | nll_loss 0.132 | ppl 1.1 | wps 24524.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36218 | lr 0.000166164 | gnorm 0.29 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 102275
2022-03-07 17:27:05 | INFO | fairseq.trainer | begin training epoch 745
2022-03-07 17:27:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:29:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:29:12 | INFO | valid | epoch 745 | valid on 'valid' subset | loss 14.16 | nll_loss 13.982 | ppl 16183.7 | wps 45789.8 | wpb 510.9 | bsz 1 | num_updates 36267 | best_loss 8.318
2022-03-07 17:29:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 745 @ 36267 updates
2022-03-07 17:29:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:29:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:29:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 745 @ 36267 updates, score 14.16) (writing took 2.4638704489916563 seconds)
2022-03-07 17:29:15 | INFO | fairseq_cli.train | end of epoch 745 (average epoch stats below)
2022-03-07 17:29:15 | INFO | train | epoch 745 | loss 0.663 | nll_loss 0.133 | ppl 1.1 | wps 24500.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36267 | lr 0.000166052 | gnorm 0.292 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 102405
2022-03-07 17:29:15 | INFO | fairseq.trainer | begin training epoch 746
2022-03-07 17:29:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:30:38 | INFO | train_inner | epoch 746:     33 / 49 loss=0.662, nll_loss=0.132, ppl=1.1, wps=24536, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=36300, lr=0.000165977, gnorm=0.292, loss_scale=64, train_wall=225, gb_free=8.8, wall=102488
2022-03-07 17:31:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:31:22 | INFO | valid | epoch 746 | valid on 'valid' subset | loss 14.247 | nll_loss 14.071 | ppl 17206.5 | wps 44814.4 | wpb 510.9 | bsz 1 | num_updates 36316 | best_loss 8.318
2022-03-07 17:31:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 746 @ 36316 updates
2022-03-07 17:31:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:31:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:31:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 746 @ 36316 updates, score 14.247) (writing took 2.462844830006361 seconds)
2022-03-07 17:31:24 | INFO | fairseq_cli.train | end of epoch 746 (average epoch stats below)
2022-03-07 17:31:24 | INFO | train | epoch 746 | loss 0.662 | nll_loss 0.132 | ppl 1.1 | wps 24532.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36316 | lr 0.00016594 | gnorm 0.291 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 102535
2022-03-07 17:31:24 | INFO | fairseq.trainer | begin training epoch 747
2022-03-07 17:31:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:32:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:33:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:33:32 | INFO | valid | epoch 747 | valid on 'valid' subset | loss 14.242 | nll_loss 14.066 | ppl 17156.2 | wps 45659.9 | wpb 510.9 | bsz 1 | num_updates 36364 | best_loss 8.318
2022-03-07 17:33:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 747 @ 36364 updates
2022-03-07 17:33:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:33:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:33:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 747 @ 36364 updates, score 14.242) (writing took 2.4595705065876245 seconds)
2022-03-07 17:33:34 | INFO | fairseq_cli.train | end of epoch 747 (average epoch stats below)
2022-03-07 17:33:34 | INFO | train | epoch 747 | loss 0.662 | nll_loss 0.132 | ppl 1.1 | wps 24022 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 36364 | lr 0.00016583 | gnorm 0.292 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 102664
2022-03-07 17:33:34 | INFO | fairseq.trainer | begin training epoch 748
2022-03-07 17:33:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:35:05 | INFO | train_inner | epoch 748:     36 / 49 loss=0.662, nll_loss=0.132, ppl=1.1, wps=24309.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=36400, lr=0.000165748, gnorm=0.291, loss_scale=32, train_wall=228, gb_free=8.8, wall=102755
2022-03-07 17:35:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:35:41 | INFO | valid | epoch 748 | valid on 'valid' subset | loss 14.221 | nll_loss 14.043 | ppl 16875 | wps 46041.1 | wpb 510.9 | bsz 1 | num_updates 36413 | best_loss 8.318
2022-03-07 17:35:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 748 @ 36413 updates
2022-03-07 17:35:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:35:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:35:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 748 @ 36413 updates, score 14.221) (writing took 2.4806335736066103 seconds)
2022-03-07 17:35:44 | INFO | fairseq_cli.train | end of epoch 748 (average epoch stats below)
2022-03-07 17:35:44 | INFO | train | epoch 748 | loss 0.661 | nll_loss 0.132 | ppl 1.1 | wps 24500.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36413 | lr 0.000165719 | gnorm 0.289 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 102794
2022-03-07 17:35:44 | INFO | fairseq.trainer | begin training epoch 749
2022-03-07 17:35:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:37:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:37:51 | INFO | valid | epoch 749 | valid on 'valid' subset | loss 14.228 | nll_loss 14.05 | ppl 16967.6 | wps 45570.8 | wpb 510.9 | bsz 1 | num_updates 36462 | best_loss 8.318
2022-03-07 17:37:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 749 @ 36462 updates
2022-03-07 17:37:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:37:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:37:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 749 @ 36462 updates, score 14.228) (writing took 2.545823186635971 seconds)
2022-03-07 17:37:53 | INFO | fairseq_cli.train | end of epoch 749 (average epoch stats below)
2022-03-07 17:37:53 | INFO | train | epoch 749 | loss 0.661 | nll_loss 0.131 | ppl 1.1 | wps 24520.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36462 | lr 0.000165607 | gnorm 0.29 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 102924
2022-03-07 17:37:53 | INFO | fairseq.trainer | begin training epoch 750
2022-03-07 17:37:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:39:29 | INFO | train_inner | epoch 750:     38 / 49 loss=0.661, nll_loss=0.131, ppl=1.1, wps=24588.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=36500, lr=0.000165521, gnorm=0.289, loss_scale=64, train_wall=225, gb_free=8.8, wall=103019
2022-03-07 17:39:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:40:00 | INFO | valid | epoch 750 | valid on 'valid' subset | loss 14.293 | nll_loss 14.118 | ppl 17778.3 | wps 45596.5 | wpb 510.9 | bsz 1 | num_updates 36511 | best_loss 8.318
2022-03-07 17:40:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 750 @ 36511 updates
2022-03-07 17:40:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:40:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:40:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 750 @ 36511 updates, score 14.293) (writing took 2.5126076955348253 seconds)
2022-03-07 17:40:03 | INFO | fairseq_cli.train | end of epoch 750 (average epoch stats below)
2022-03-07 17:40:03 | INFO | train | epoch 750 | loss 0.661 | nll_loss 0.131 | ppl 1.1 | wps 24572.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36511 | lr 0.000165496 | gnorm 0.289 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 103053
2022-03-07 17:40:03 | INFO | fairseq.trainer | begin training epoch 751
2022-03-07 17:40:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:42:10 | INFO | valid | epoch 751 | valid on 'valid' subset | loss 14.254 | nll_loss 14.078 | ppl 17289.8 | wps 45438.8 | wpb 510.9 | bsz 1 | num_updates 36560 | best_loss 8.318
2022-03-07 17:42:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 751 @ 36560 updates
2022-03-07 17:42:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:42:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:42:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 751 @ 36560 updates, score 14.254) (writing took 2.502646777778864 seconds)
2022-03-07 17:42:12 | INFO | fairseq_cli.train | end of epoch 751 (average epoch stats below)
2022-03-07 17:42:12 | INFO | train | epoch 751 | loss 0.661 | nll_loss 0.131 | ppl 1.1 | wps 24479.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36560 | lr 0.000165385 | gnorm 0.291 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 103183
2022-03-07 17:42:12 | INFO | fairseq.trainer | begin training epoch 752
2022-03-07 17:42:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:43:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:43:56 | INFO | train_inner | epoch 752:     41 / 49 loss=0.661, nll_loss=0.132, ppl=1.1, wps=24297.3, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=36600, lr=0.000165295, gnorm=0.291, loss_scale=64, train_wall=228, gb_free=8.8, wall=103286
2022-03-07 17:44:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:44:20 | INFO | valid | epoch 752 | valid on 'valid' subset | loss 14.269 | nll_loss 14.093 | ppl 17479 | wps 45223.2 | wpb 510.9 | bsz 1 | num_updates 36608 | best_loss 8.318
2022-03-07 17:44:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 752 @ 36608 updates
2022-03-07 17:44:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:44:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:44:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 752 @ 36608 updates, score 14.269) (writing took 2.5326866526156664 seconds)
2022-03-07 17:44:22 | INFO | fairseq_cli.train | end of epoch 752 (average epoch stats below)
2022-03-07 17:44:22 | INFO | train | epoch 752 | loss 0.662 | nll_loss 0.132 | ppl 1.1 | wps 24002.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 36608 | lr 0.000165277 | gnorm 0.293 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 103312
2022-03-07 17:44:22 | INFO | fairseq.trainer | begin training epoch 753
2022-03-07 17:44:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:46:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:46:29 | INFO | valid | epoch 753 | valid on 'valid' subset | loss 14.295 | nll_loss 14.121 | ppl 17822.1 | wps 44567.1 | wpb 510.9 | bsz 1 | num_updates 36657 | best_loss 8.318
2022-03-07 17:46:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 753 @ 36657 updates
2022-03-07 17:46:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:46:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:46:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 753 @ 36657 updates, score 14.295) (writing took 2.5255524776875973 seconds)
2022-03-07 17:46:32 | INFO | fairseq_cli.train | end of epoch 753 (average epoch stats below)
2022-03-07 17:46:32 | INFO | train | epoch 753 | loss 0.661 | nll_loss 0.131 | ppl 1.1 | wps 24541.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36657 | lr 0.000165166 | gnorm 0.292 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 103442
2022-03-07 17:46:32 | INFO | fairseq.trainer | begin training epoch 754
2022-03-07 17:46:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:48:20 | INFO | train_inner | epoch 754:     43 / 49 loss=0.661, nll_loss=0.131, ppl=1.1, wps=24534.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=36700, lr=0.00016507, gnorm=0.291, loss_scale=64, train_wall=225, gb_free=8.8, wall=103550
2022-03-07 17:48:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:48:39 | INFO | valid | epoch 754 | valid on 'valid' subset | loss 14.306 | nll_loss 14.131 | ppl 17943.8 | wps 45058.2 | wpb 510.9 | bsz 1 | num_updates 36706 | best_loss 8.318
2022-03-07 17:48:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 754 @ 36706 updates
2022-03-07 17:48:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:48:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:48:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 754 @ 36706 updates, score 14.306) (writing took 2.4791200514882803 seconds)
2022-03-07 17:48:41 | INFO | fairseq_cli.train | end of epoch 754 (average epoch stats below)
2022-03-07 17:48:41 | INFO | train | epoch 754 | loss 0.661 | nll_loss 0.131 | ppl 1.1 | wps 24493.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36706 | lr 0.000165056 | gnorm 0.289 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 103572
2022-03-07 17:48:41 | INFO | fairseq.trainer | begin training epoch 755
2022-03-07 17:48:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:49:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:50:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:50:48 | INFO | valid | epoch 755 | valid on 'valid' subset | loss 14.27 | nll_loss 14.095 | ppl 17497.4 | wps 45151.7 | wpb 510.9 | bsz 1 | num_updates 36754 | best_loss 8.318
2022-03-07 17:50:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 755 @ 36754 updates
2022-03-07 17:50:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:50:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:50:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 755 @ 36754 updates, score 14.27) (writing took 2.4773567970842123 seconds)
2022-03-07 17:50:51 | INFO | fairseq_cli.train | end of epoch 755 (average epoch stats below)
2022-03-07 17:50:51 | INFO | train | epoch 755 | loss 0.661 | nll_loss 0.131 | ppl 1.1 | wps 24040.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 36754 | lr 0.000164948 | gnorm 0.291 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 103701
2022-03-07 17:50:51 | INFO | fairseq.trainer | begin training epoch 756
2022-03-07 17:50:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:52:51 | INFO | train_inner | epoch 756:     46 / 49 loss=0.661, nll_loss=0.131, ppl=1.1, wps=23978.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=36800, lr=0.000164845, gnorm=0.291, loss_scale=64, train_wall=231, gb_free=8.8, wall=103821
2022-03-07 17:52:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:53:02 | INFO | valid | epoch 756 | valid on 'valid' subset | loss 14.312 | nll_loss 14.138 | ppl 18033.2 | wps 43466.6 | wpb 510.9 | bsz 1 | num_updates 36803 | best_loss 8.318
2022-03-07 17:53:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 756 @ 36803 updates
2022-03-07 17:53:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:53:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:53:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 756 @ 36803 updates, score 14.312) (writing took 2.397254839539528 seconds)
2022-03-07 17:53:05 | INFO | fairseq_cli.train | end of epoch 756 (average epoch stats below)
2022-03-07 17:53:05 | INFO | train | epoch 756 | loss 0.661 | nll_loss 0.131 | ppl 1.1 | wps 23749 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 36803 | lr 0.000164838 | gnorm 0.291 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 103835
2022-03-07 17:53:05 | INFO | fairseq.trainer | begin training epoch 757
2022-03-07 17:53:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:55:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:55:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:55:17 | INFO | valid | epoch 757 | valid on 'valid' subset | loss 14.311 | nll_loss 14.137 | ppl 18015 | wps 42223.8 | wpb 510.9 | bsz 1 | num_updates 36851 | best_loss 8.318
2022-03-07 17:55:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 757 @ 36851 updates
2022-03-07 17:55:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:55:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:55:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 757 @ 36851 updates, score 14.311) (writing took 2.6933909319341183 seconds)
2022-03-07 17:55:19 | INFO | fairseq_cli.train | end of epoch 757 (average epoch stats below)
2022-03-07 17:55:19 | INFO | train | epoch 757 | loss 0.66 | nll_loss 0.131 | ppl 1.1 | wps 23088.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 36851 | lr 0.000164731 | gnorm 0.289 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 103970
2022-03-07 17:55:19 | INFO | fairseq.trainer | begin training epoch 758
2022-03-07 17:55:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:56:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:57:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:57:27 | INFO | valid | epoch 758 | valid on 'valid' subset | loss 14.281 | nll_loss 14.106 | ppl 17635.9 | wps 45271.6 | wpb 510.9 | bsz 1 | num_updates 36899 | best_loss 8.318
2022-03-07 17:57:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 758 @ 36899 updates
2022-03-07 17:57:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:57:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:57:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 758 @ 36899 updates, score 14.281) (writing took 2.5413435995578766 seconds)
2022-03-07 17:57:30 | INFO | fairseq_cli.train | end of epoch 758 (average epoch stats below)
2022-03-07 17:57:30 | INFO | train | epoch 758 | loss 0.66 | nll_loss 0.131 | ppl 1.1 | wps 23911.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 36899 | lr 0.000164624 | gnorm 0.289 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 104100
2022-03-07 17:57:30 | INFO | fairseq.trainer | begin training epoch 759
2022-03-07 17:57:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:57:32 | INFO | train_inner | epoch 759:      1 / 49 loss=0.66, nll_loss=0.131, ppl=1.1, wps=22924.5, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=36900, lr=0.000164622, gnorm=0.29, loss_scale=32, train_wall=234, gb_free=8.8, wall=104103
2022-03-07 17:59:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:59:37 | INFO | valid | epoch 759 | valid on 'valid' subset | loss 14.247 | nll_loss 14.073 | ppl 17229.3 | wps 45379 | wpb 510.9 | bsz 1 | num_updates 36948 | best_loss 8.318
2022-03-07 17:59:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 759 @ 36948 updates
2022-03-07 17:59:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:59:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:59:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 759 @ 36948 updates, score 14.247) (writing took 2.4908212553709745 seconds)
2022-03-07 17:59:39 | INFO | fairseq_cli.train | end of epoch 759 (average epoch stats below)
2022-03-07 17:59:39 | INFO | train | epoch 759 | loss 0.66 | nll_loss 0.131 | ppl 1.09 | wps 24537.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36948 | lr 0.000164515 | gnorm 0.29 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 104229
2022-03-07 17:59:39 | INFO | fairseq.trainer | begin training epoch 760
2022-03-07 17:59:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:01:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:01:46 | INFO | valid | epoch 760 | valid on 'valid' subset | loss 14.276 | nll_loss 14.1 | ppl 17564.4 | wps 45698.1 | wpb 510.9 | bsz 1 | num_updates 36997 | best_loss 8.318
2022-03-07 18:01:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 760 @ 36997 updates
2022-03-07 18:01:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:01:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:01:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 760 @ 36997 updates, score 14.276) (writing took 2.479027722030878 seconds)
2022-03-07 18:01:49 | INFO | fairseq_cli.train | end of epoch 760 (average epoch stats below)
2022-03-07 18:01:49 | INFO | train | epoch 760 | loss 0.66 | nll_loss 0.131 | ppl 1.09 | wps 24541.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36997 | lr 0.000164406 | gnorm 0.292 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 104359
2022-03-07 18:01:49 | INFO | fairseq.trainer | begin training epoch 761
2022-03-07 18:01:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:01:56 | INFO | train_inner | epoch 761:      3 / 49 loss=0.66, nll_loss=0.131, ppl=1.09, wps=24566.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=37000, lr=0.000164399, gnorm=0.291, loss_scale=32, train_wall=225, gb_free=8.8, wall=104367
2022-03-07 18:03:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:03:56 | INFO | valid | epoch 761 | valid on 'valid' subset | loss 14.248 | nll_loss 14.072 | ppl 17225.3 | wps 45471.6 | wpb 510.9 | bsz 1 | num_updates 37046 | best_loss 8.318
2022-03-07 18:03:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 761 @ 37046 updates
2022-03-07 18:03:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:03:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:03:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 761 @ 37046 updates, score 14.248) (writing took 2.502491481602192 seconds)
2022-03-07 18:03:58 | INFO | fairseq_cli.train | end of epoch 761 (average epoch stats below)
2022-03-07 18:03:58 | INFO | train | epoch 761 | loss 0.66 | nll_loss 0.131 | ppl 1.09 | wps 24513.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37046 | lr 0.000164297 | gnorm 0.29 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 104489
2022-03-07 18:03:58 | INFO | fairseq.trainer | begin training epoch 762
2022-03-07 18:03:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:06:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:06:05 | INFO | valid | epoch 762 | valid on 'valid' subset | loss 14.204 | nll_loss 14.028 | ppl 16700 | wps 45983.9 | wpb 510.9 | bsz 1 | num_updates 37095 | best_loss 8.318
2022-03-07 18:06:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 762 @ 37095 updates
2022-03-07 18:06:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:06:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:06:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 762 @ 37095 updates, score 14.204) (writing took 2.5156350024044514 seconds)
2022-03-07 18:06:08 | INFO | fairseq_cli.train | end of epoch 762 (average epoch stats below)
2022-03-07 18:06:08 | INFO | train | epoch 762 | loss 0.66 | nll_loss 0.13 | ppl 1.09 | wps 24545.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37095 | lr 0.000164188 | gnorm 0.29 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 104618
2022-03-07 18:06:08 | INFO | fairseq.trainer | begin training epoch 763
2022-03-07 18:06:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:06:20 | INFO | train_inner | epoch 763:      5 / 49 loss=0.66, nll_loss=0.131, ppl=1.09, wps=24564.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=37100, lr=0.000164177, gnorm=0.29, loss_scale=64, train_wall=225, gb_free=8.8, wall=104631
2022-03-07 18:06:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:08:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:08:15 | INFO | valid | epoch 763 | valid on 'valid' subset | loss 14.283 | nll_loss 14.108 | ppl 17656.5 | wps 45730.4 | wpb 510.9 | bsz 1 | num_updates 37143 | best_loss 8.318
2022-03-07 18:08:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 763 @ 37143 updates
2022-03-07 18:08:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:08:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:08:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 763 @ 37143 updates, score 14.283) (writing took 2.4268750604242086 seconds)
2022-03-07 18:08:17 | INFO | fairseq_cli.train | end of epoch 763 (average epoch stats below)
2022-03-07 18:08:17 | INFO | train | epoch 763 | loss 0.66 | nll_loss 0.131 | ppl 1.09 | wps 24055.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 37143 | lr 0.000164082 | gnorm 0.292 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 104747
2022-03-07 18:08:17 | INFO | fairseq.trainer | begin training epoch 764
2022-03-07 18:08:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:10:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:10:25 | INFO | valid | epoch 764 | valid on 'valid' subset | loss 14.292 | nll_loss 14.117 | ppl 17769.6 | wps 44616.6 | wpb 510.9 | bsz 1 | num_updates 37192 | best_loss 8.318
2022-03-07 18:10:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 764 @ 37192 updates
2022-03-07 18:10:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:10:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:10:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 764 @ 37192 updates, score 14.292) (writing took 2.44162967056036 seconds)
2022-03-07 18:10:27 | INFO | fairseq_cli.train | end of epoch 764 (average epoch stats below)
2022-03-07 18:10:27 | INFO | train | epoch 764 | loss 0.659 | nll_loss 0.13 | ppl 1.09 | wps 24426.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37192 | lr 0.000163974 | gnorm 0.29 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 104878
2022-03-07 18:10:27 | INFO | fairseq.trainer | begin training epoch 765
2022-03-07 18:10:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:10:48 | INFO | train_inner | epoch 765:      8 / 49 loss=0.659, nll_loss=0.13, ppl=1.09, wps=24288.1, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=37200, lr=0.000163956, gnorm=0.29, loss_scale=32, train_wall=228, gb_free=8.8, wall=104898
2022-03-07 18:12:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:12:35 | INFO | valid | epoch 765 | valid on 'valid' subset | loss 14.303 | nll_loss 14.128 | ppl 17904.7 | wps 45903.9 | wpb 510.9 | bsz 1 | num_updates 37241 | best_loss 8.318
2022-03-07 18:12:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 765 @ 37241 updates
2022-03-07 18:12:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:12:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:12:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 765 @ 37241 updates, score 14.303) (writing took 2.490628093481064 seconds)
2022-03-07 18:12:38 | INFO | fairseq_cli.train | end of epoch 765 (average epoch stats below)
2022-03-07 18:12:38 | INFO | train | epoch 765 | loss 0.659 | nll_loss 0.131 | ppl 1.09 | wps 24375.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37241 | lr 0.000163866 | gnorm 0.289 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 105008
2022-03-07 18:12:38 | INFO | fairseq.trainer | begin training epoch 766
2022-03-07 18:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:14:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:14:45 | INFO | valid | epoch 766 | valid on 'valid' subset | loss 14.256 | nll_loss 14.082 | ppl 17346.3 | wps 44115.2 | wpb 510.9 | bsz 1 | num_updates 37290 | best_loss 8.318
2022-03-07 18:14:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 766 @ 37290 updates
2022-03-07 18:14:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:14:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:14:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 766 @ 37290 updates, score 14.256) (writing took 2.5011229924857616 seconds)
2022-03-07 18:14:47 | INFO | fairseq_cli.train | end of epoch 766 (average epoch stats below)
2022-03-07 18:14:47 | INFO | train | epoch 766 | loss 0.66 | nll_loss 0.131 | ppl 1.09 | wps 24478.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37290 | lr 0.000163758 | gnorm 0.292 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 105138
2022-03-07 18:14:47 | INFO | fairseq.trainer | begin training epoch 767
2022-03-07 18:14:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:15:13 | INFO | train_inner | epoch 767:     10 / 49 loss=0.66, nll_loss=0.131, ppl=1.09, wps=24451.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=37300, lr=0.000163737, gnorm=0.29, loss_scale=64, train_wall=226, gb_free=8.8, wall=105163
2022-03-07 18:16:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:16:55 | INFO | valid | epoch 767 | valid on 'valid' subset | loss 14.34 | nll_loss 14.166 | ppl 18387.4 | wps 45727.7 | wpb 510.9 | bsz 1 | num_updates 37339 | best_loss 8.318
2022-03-07 18:16:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 767 @ 37339 updates
2022-03-07 18:16:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:16:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:16:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 767 @ 37339 updates, score 14.34) (writing took 2.5031483434140682 seconds)
2022-03-07 18:16:57 | INFO | fairseq_cli.train | end of epoch 767 (average epoch stats below)
2022-03-07 18:16:57 | INFO | train | epoch 767 | loss 0.659 | nll_loss 0.13 | ppl 1.09 | wps 24500.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37339 | lr 0.000163651 | gnorm 0.289 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 105267
2022-03-07 18:16:57 | INFO | fairseq.trainer | begin training epoch 768
2022-03-07 18:16:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:18:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:19:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:19:06 | INFO | valid | epoch 768 | valid on 'valid' subset | loss 14.317 | nll_loss 14.143 | ppl 18091 | wps 42255.7 | wpb 510.9 | bsz 1 | num_updates 37387 | best_loss 8.318
2022-03-07 18:19:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 768 @ 37387 updates
2022-03-07 18:19:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:19:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:19:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 768 @ 37387 updates, score 14.317) (writing took 2.451475467532873 seconds)
2022-03-07 18:19:09 | INFO | fairseq_cli.train | end of epoch 768 (average epoch stats below)
2022-03-07 18:19:09 | INFO | train | epoch 768 | loss 0.659 | nll_loss 0.13 | ppl 1.09 | wps 23693.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 37387 | lr 0.000163546 | gnorm 0.291 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 105399
2022-03-07 18:19:09 | INFO | fairseq.trainer | begin training epoch 769
2022-03-07 18:19:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:19:43 | INFO | train_inner | epoch 769:     13 / 49 loss=0.659, nll_loss=0.13, ppl=1.09, wps=24039.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=37400, lr=0.000163517, gnorm=0.289, loss_scale=64, train_wall=230, gb_free=8.8, wall=105433
2022-03-07 18:21:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:21:20 | INFO | valid | epoch 769 | valid on 'valid' subset | loss 14.295 | nll_loss 14.121 | ppl 17813 | wps 42616.1 | wpb 510.9 | bsz 1 | num_updates 37436 | best_loss 8.318
2022-03-07 18:21:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 769 @ 37436 updates
2022-03-07 18:21:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:21:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:21:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 769 @ 37436 updates, score 14.295) (writing took 2.4236169196665287 seconds)
2022-03-07 18:21:22 | INFO | fairseq_cli.train | end of epoch 769 (average epoch stats below)
2022-03-07 18:21:22 | INFO | train | epoch 769 | loss 0.659 | nll_loss 0.13 | ppl 1.09 | wps 23795.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 37436 | lr 0.000163439 | gnorm 0.287 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 105532
2022-03-07 18:21:22 | INFO | fairseq.trainer | begin training epoch 770
2022-03-07 18:21:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:23:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:23:33 | INFO | valid | epoch 770 | valid on 'valid' subset | loss 14.209 | nll_loss 14.034 | ppl 16778.2 | wps 45616.2 | wpb 510.9 | bsz 1 | num_updates 37485 | best_loss 8.318
2022-03-07 18:23:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 770 @ 37485 updates
2022-03-07 18:23:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:23:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:23:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 770 @ 37485 updates, score 14.209) (writing took 2.4621409233659506 seconds)
2022-03-07 18:23:35 | INFO | fairseq_cli.train | end of epoch 770 (average epoch stats below)
2022-03-07 18:23:35 | INFO | train | epoch 770 | loss 0.659 | nll_loss 0.13 | ppl 1.09 | wps 23884.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 37485 | lr 0.000163332 | gnorm 0.287 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 105665
2022-03-07 18:23:35 | INFO | fairseq.trainer | begin training epoch 771
2022-03-07 18:23:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:24:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:24:15 | INFO | train_inner | epoch 771:     16 / 49 loss=0.659, nll_loss=0.13, ppl=1.09, wps=23778.3, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=37500, lr=0.000163299, gnorm=0.288, loss_scale=64, train_wall=233, gb_free=8.8, wall=105706
2022-03-07 18:25:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:25:42 | INFO | valid | epoch 771 | valid on 'valid' subset | loss 14.234 | nll_loss 14.058 | ppl 17060.3 | wps 46405.8 | wpb 510.9 | bsz 1 | num_updates 37533 | best_loss 8.318
2022-03-07 18:25:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 771 @ 37533 updates
2022-03-07 18:25:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:25:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:25:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 771 @ 37533 updates, score 14.234) (writing took 2.449123417958617 seconds)
2022-03-07 18:25:45 | INFO | fairseq_cli.train | end of epoch 771 (average epoch stats below)
2022-03-07 18:25:45 | INFO | train | epoch 771 | loss 0.659 | nll_loss 0.13 | ppl 1.09 | wps 24061.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 37533 | lr 0.000163228 | gnorm 0.288 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 105795
2022-03-07 18:25:45 | INFO | fairseq.trainer | begin training epoch 772
2022-03-07 18:25:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:27:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:27:51 | INFO | valid | epoch 772 | valid on 'valid' subset | loss 14.278 | nll_loss 14.102 | ppl 17589 | wps 46193.6 | wpb 510.9 | bsz 1 | num_updates 37582 | best_loss 8.318
2022-03-07 18:27:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 772 @ 37582 updates
2022-03-07 18:27:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:27:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:27:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 772 @ 37582 updates, score 14.278) (writing took 2.47899510897696 seconds)
2022-03-07 18:27:54 | INFO | fairseq_cli.train | end of epoch 772 (average epoch stats below)
2022-03-07 18:27:54 | INFO | train | epoch 772 | loss 0.658 | nll_loss 0.13 | ppl 1.09 | wps 24570.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37582 | lr 0.000163121 | gnorm 0.29 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 105924
2022-03-07 18:27:54 | INFO | fairseq.trainer | begin training epoch 773
2022-03-07 18:27:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:28:39 | INFO | train_inner | epoch 773:     18 / 49 loss=0.658, nll_loss=0.129, ppl=1.09, wps=24577.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=37600, lr=0.000163082, gnorm=0.289, loss_scale=64, train_wall=225, gb_free=8.8, wall=105970
2022-03-07 18:29:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:30:02 | INFO | valid | epoch 773 | valid on 'valid' subset | loss 14.303 | nll_loss 14.128 | ppl 17905.3 | wps 45110.2 | wpb 510.9 | bsz 1 | num_updates 37630 | best_loss 8.318
2022-03-07 18:30:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 773 @ 37630 updates
2022-03-07 18:30:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:30:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:30:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 773 @ 37630 updates, score 14.303) (writing took 2.477835776284337 seconds)
2022-03-07 18:30:04 | INFO | fairseq_cli.train | end of epoch 773 (average epoch stats below)
2022-03-07 18:30:04 | INFO | train | epoch 773 | loss 0.658 | nll_loss 0.129 | ppl 1.09 | wps 23895.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 37630 | lr 0.000163017 | gnorm 0.287 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 106054
2022-03-07 18:30:04 | INFO | fairseq.trainer | begin training epoch 774
2022-03-07 18:30:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:32:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:32:11 | INFO | valid | epoch 774 | valid on 'valid' subset | loss 14.243 | nll_loss 14.068 | ppl 17178.2 | wps 44973.9 | wpb 510.9 | bsz 1 | num_updates 37679 | best_loss 8.318
2022-03-07 18:32:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 774 @ 37679 updates
2022-03-07 18:32:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:32:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:32:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 774 @ 37679 updates, score 14.243) (writing took 2.474731797352433 seconds)
2022-03-07 18:32:14 | INFO | fairseq_cli.train | end of epoch 774 (average epoch stats below)
2022-03-07 18:32:14 | INFO | train | epoch 774 | loss 0.659 | nll_loss 0.13 | ppl 1.09 | wps 24528.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37679 | lr 0.000162911 | gnorm 0.291 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 106184
2022-03-07 18:32:14 | INFO | fairseq.trainer | begin training epoch 775
2022-03-07 18:32:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:33:07 | INFO | train_inner | epoch 775:     21 / 49 loss=0.658, nll_loss=0.13, ppl=1.09, wps=24278.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=37700, lr=0.000162866, gnorm=0.289, loss_scale=64, train_wall=228, gb_free=8.8, wall=106237
2022-03-07 18:34:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:34:21 | INFO | valid | epoch 775 | valid on 'valid' subset | loss 14.224 | nll_loss 14.049 | ppl 16945.5 | wps 45883.2 | wpb 510.9 | bsz 1 | num_updates 37728 | best_loss 8.318
2022-03-07 18:34:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 775 @ 37728 updates
2022-03-07 18:34:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:34:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:34:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 775 @ 37728 updates, score 14.224) (writing took 2.514289930462837 seconds)
2022-03-07 18:34:23 | INFO | fairseq_cli.train | end of epoch 775 (average epoch stats below)
2022-03-07 18:34:23 | INFO | train | epoch 775 | loss 0.658 | nll_loss 0.129 | ppl 1.09 | wps 24527.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37728 | lr 0.000162805 | gnorm 0.289 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 106314
2022-03-07 18:34:23 | INFO | fairseq.trainer | begin training epoch 776
2022-03-07 18:34:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:35:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:36:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:36:31 | INFO | valid | epoch 776 | valid on 'valid' subset | loss 14.209 | nll_loss 14.035 | ppl 16788 | wps 45406.7 | wpb 510.9 | bsz 1 | num_updates 37776 | best_loss 8.318
2022-03-07 18:36:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 776 @ 37776 updates
2022-03-07 18:36:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:36:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:36:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 776 @ 37776 updates, score 14.209) (writing took 2.509390080347657 seconds)
2022-03-07 18:36:33 | INFO | fairseq_cli.train | end of epoch 776 (average epoch stats below)
2022-03-07 18:36:33 | INFO | train | epoch 776 | loss 0.658 | nll_loss 0.129 | ppl 1.09 | wps 23954.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 37776 | lr 0.000162702 | gnorm 0.286 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 106444
2022-03-07 18:36:33 | INFO | fairseq.trainer | begin training epoch 777
2022-03-07 18:36:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:37:35 | INFO | train_inner | epoch 777:     24 / 49 loss=0.658, nll_loss=0.129, ppl=1.09, wps=24171.1, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=37800, lr=0.00016265, gnorm=0.288, loss_scale=64, train_wall=229, gb_free=8.8, wall=106505
2022-03-07 18:38:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:38:44 | INFO | valid | epoch 777 | valid on 'valid' subset | loss 14.299 | nll_loss 14.127 | ppl 17889 | wps 43188.1 | wpb 510.9 | bsz 1 | num_updates 37825 | best_loss 8.318
2022-03-07 18:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 777 @ 37825 updates
2022-03-07 18:38:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:38:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:38:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 777 @ 37825 updates, score 14.299) (writing took 2.4244595505297184 seconds)
2022-03-07 18:38:46 | INFO | fairseq_cli.train | end of epoch 777 (average epoch stats below)
2022-03-07 18:38:46 | INFO | train | epoch 777 | loss 0.658 | nll_loss 0.129 | ppl 1.09 | wps 23902.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 37825 | lr 0.000162596 | gnorm 0.287 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 106576
2022-03-07 18:38:46 | INFO | fairseq.trainer | begin training epoch 778
2022-03-07 18:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:40:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:40:57 | INFO | valid | epoch 778 | valid on 'valid' subset | loss 14.324 | nll_loss 14.15 | ppl 18184.7 | wps 45178 | wpb 510.9 | bsz 1 | num_updates 37874 | best_loss 8.318
2022-03-07 18:40:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 778 @ 37874 updates
2022-03-07 18:40:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:40:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:40:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 778 @ 37874 updates, score 14.324) (writing took 2.5302864238619804 seconds)
2022-03-07 18:40:59 | INFO | fairseq_cli.train | end of epoch 778 (average epoch stats below)
2022-03-07 18:40:59 | INFO | train | epoch 778 | loss 0.658 | nll_loss 0.129 | ppl 1.09 | wps 23867.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 37874 | lr 0.000162491 | gnorm 0.289 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 106710
2022-03-07 18:40:59 | INFO | fairseq.trainer | begin training epoch 779
2022-03-07 18:40:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:41:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:42:07 | INFO | train_inner | epoch 779:     27 / 49 loss=0.658, nll_loss=0.129, ppl=1.09, wps=23865.2, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=37900, lr=0.000162435, gnorm=0.288, loss_scale=64, train_wall=232, gb_free=8.8, wall=106777
2022-03-07 18:43:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:43:05 | INFO | valid | epoch 779 | valid on 'valid' subset | loss 14.274 | nll_loss 14.098 | ppl 17534.2 | wps 46761.5 | wpb 510.9 | bsz 1 | num_updates 37922 | best_loss 8.318
2022-03-07 18:43:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 779 @ 37922 updates
2022-03-07 18:43:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:43:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:43:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 779 @ 37922 updates, score 14.274) (writing took 2.4947816990315914 seconds)
2022-03-07 18:43:08 | INFO | fairseq_cli.train | end of epoch 779 (average epoch stats below)
2022-03-07 18:43:08 | INFO | train | epoch 779 | loss 0.658 | nll_loss 0.129 | ppl 1.09 | wps 24241.1 | ups 0.37 | wpb 64853.3 | bsz 126.7 | num_updates 37922 | lr 0.000162388 | gnorm 0.287 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 106838
2022-03-07 18:43:08 | INFO | fairseq.trainer | begin training epoch 780
2022-03-07 18:43:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:45:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:45:14 | INFO | valid | epoch 780 | valid on 'valid' subset | loss 14.239 | nll_loss 14.065 | ppl 17134.5 | wps 46144.3 | wpb 510.9 | bsz 1 | num_updates 37971 | best_loss 8.318
2022-03-07 18:45:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 780 @ 37971 updates
2022-03-07 18:45:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:45:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:45:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 780 @ 37971 updates, score 14.239) (writing took 2.518711283802986 seconds)
2022-03-07 18:45:16 | INFO | fairseq_cli.train | end of epoch 780 (average epoch stats below)
2022-03-07 18:45:16 | INFO | train | epoch 780 | loss 0.658 | nll_loss 0.129 | ppl 1.09 | wps 24699.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37971 | lr 0.000162283 | gnorm 0.289 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 106967
2022-03-07 18:45:16 | INFO | fairseq.trainer | begin training epoch 781
2022-03-07 18:45:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:46:29 | INFO | train_inner | epoch 781:     29 / 49 loss=0.657, nll_loss=0.129, ppl=1.09, wps=24758.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38000, lr=0.000162221, gnorm=0.287, loss_scale=64, train_wall=223, gb_free=8.8, wall=107039
2022-03-07 18:46:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:47:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:47:22 | INFO | valid | epoch 781 | valid on 'valid' subset | loss 14.29 | nll_loss 14.115 | ppl 17743.8 | wps 46612.5 | wpb 510.9 | bsz 1 | num_updates 38019 | best_loss 8.318
2022-03-07 18:47:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 781 @ 38019 updates
2022-03-07 18:47:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:47:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:47:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 781 @ 38019 updates, score 14.29) (writing took 2.557085644453764 seconds)
2022-03-07 18:47:25 | INFO | fairseq_cli.train | end of epoch 781 (average epoch stats below)
2022-03-07 18:47:25 | INFO | train | epoch 781 | loss 0.657 | nll_loss 0.128 | ppl 1.09 | wps 24217.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 38019 | lr 0.000162181 | gnorm 0.285 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 107095
2022-03-07 18:47:25 | INFO | fairseq.trainer | begin training epoch 782
2022-03-07 18:47:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:49:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:49:31 | INFO | valid | epoch 782 | valid on 'valid' subset | loss 14.292 | nll_loss 14.118 | ppl 17782 | wps 45807.9 | wpb 510.9 | bsz 1 | num_updates 38068 | best_loss 8.318
2022-03-07 18:49:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 782 @ 38068 updates
2022-03-07 18:49:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:49:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:49:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 782 @ 38068 updates, score 14.292) (writing took 2.5531154572963715 seconds)
2022-03-07 18:49:34 | INFO | fairseq_cli.train | end of epoch 782 (average epoch stats below)
2022-03-07 18:49:34 | INFO | train | epoch 782 | loss 0.657 | nll_loss 0.129 | ppl 1.09 | wps 24693.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38068 | lr 0.000162076 | gnorm 0.287 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 107224
2022-03-07 18:49:34 | INFO | fairseq.trainer | begin training epoch 783
2022-03-07 18:49:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:50:54 | INFO | train_inner | epoch 783:     32 / 49 loss=0.657, nll_loss=0.129, ppl=1.09, wps=24501.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38100, lr=0.000162008, gnorm=0.286, loss_scale=64, train_wall=226, gb_free=8.8, wall=107304
2022-03-07 18:51:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:51:40 | INFO | valid | epoch 783 | valid on 'valid' subset | loss 14.238 | nll_loss 14.062 | ppl 17103.4 | wps 46610 | wpb 510.9 | bsz 1 | num_updates 38117 | best_loss 8.318
2022-03-07 18:51:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 783 @ 38117 updates
2022-03-07 18:51:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:51:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:51:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 783 @ 38117 updates, score 14.238) (writing took 2.5017304085195065 seconds)
2022-03-07 18:51:42 | INFO | fairseq_cli.train | end of epoch 783 (average epoch stats below)
2022-03-07 18:51:42 | INFO | train | epoch 783 | loss 0.657 | nll_loss 0.129 | ppl 1.09 | wps 24733.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38117 | lr 0.000161972 | gnorm 0.285 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 107352
2022-03-07 18:51:42 | INFO | fairseq.trainer | begin training epoch 784
2022-03-07 18:51:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:51:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:53:48 | INFO | valid | epoch 784 | valid on 'valid' subset | loss 14.346 | nll_loss 14.174 | ppl 18483.8 | wps 46547 | wpb 510.9 | bsz 1 | num_updates 38165 | best_loss 8.318
2022-03-07 18:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 784 @ 38165 updates
2022-03-07 18:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:53:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:53:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 784 @ 38165 updates, score 14.346) (writing took 2.502632161602378 seconds)
2022-03-07 18:53:51 | INFO | fairseq_cli.train | end of epoch 784 (average epoch stats below)
2022-03-07 18:53:51 | INFO | train | epoch 784 | loss 0.656 | nll_loss 0.128 | ppl 1.09 | wps 24207.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 38165 | lr 0.00016187 | gnorm 0.285 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 107481
2022-03-07 18:53:51 | INFO | fairseq.trainer | begin training epoch 785
2022-03-07 18:53:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:55:18 | INFO | train_inner | epoch 785:     35 / 49 loss=0.657, nll_loss=0.128, ppl=1.09, wps=24522.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=38200, lr=0.000161796, gnorm=0.286, loss_scale=32, train_wall=226, gb_free=8.8, wall=107569
2022-03-07 18:55:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:55:57 | INFO | valid | epoch 785 | valid on 'valid' subset | loss 14.228 | nll_loss 14.051 | ppl 16979.1 | wps 46555.5 | wpb 510.9 | bsz 1 | num_updates 38214 | best_loss 8.318
2022-03-07 18:55:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 785 @ 38214 updates
2022-03-07 18:55:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:55:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:55:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 785 @ 38214 updates, score 14.228) (writing took 2.537969274446368 seconds)
2022-03-07 18:55:59 | INFO | fairseq_cli.train | end of epoch 785 (average epoch stats below)
2022-03-07 18:55:59 | INFO | train | epoch 785 | loss 0.657 | nll_loss 0.129 | ppl 1.09 | wps 24727 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38214 | lr 0.000161767 | gnorm 0.287 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 107610
2022-03-07 18:55:59 | INFO | fairseq.trainer | begin training epoch 786
2022-03-07 18:55:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:58:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:58:05 | INFO | valid | epoch 786 | valid on 'valid' subset | loss 14.255 | nll_loss 14.081 | ppl 17331.3 | wps 46525.9 | wpb 510.9 | bsz 1 | num_updates 38263 | best_loss 8.318
2022-03-07 18:58:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 786 @ 38263 updates
2022-03-07 18:58:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:58:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:58:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 786 @ 38263 updates, score 14.255) (writing took 2.522134855389595 seconds)
2022-03-07 18:58:08 | INFO | fairseq_cli.train | end of epoch 786 (average epoch stats below)
2022-03-07 18:58:08 | INFO | train | epoch 786 | loss 0.657 | nll_loss 0.129 | ppl 1.09 | wps 24715.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38263 | lr 0.000161663 | gnorm 0.29 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 107738
2022-03-07 18:58:08 | INFO | fairseq.trainer | begin training epoch 787
2022-03-07 18:58:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:59:41 | INFO | train_inner | epoch 787:     37 / 49 loss=0.657, nll_loss=0.129, ppl=1.09, wps=24644.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=38300, lr=0.000161585, gnorm=0.289, loss_scale=64, train_wall=224, gb_free=8.8, wall=107832
2022-03-07 19:00:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:00:16 | INFO | valid | epoch 787 | valid on 'valid' subset | loss 14.218 | nll_loss 14.043 | ppl 16882.2 | wps 43713 | wpb 510.9 | bsz 1 | num_updates 38312 | best_loss 8.318
2022-03-07 19:00:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 787 @ 38312 updates
2022-03-07 19:00:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:00:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:00:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 787 @ 38312 updates, score 14.218) (writing took 2.421956865116954 seconds)
2022-03-07 19:00:18 | INFO | fairseq_cli.train | end of epoch 787 (average epoch stats below)
2022-03-07 19:00:18 | INFO | train | epoch 787 | loss 0.657 | nll_loss 0.128 | ppl 1.09 | wps 24320.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 38312 | lr 0.00016156 | gnorm 0.288 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 107869
2022-03-07 19:00:19 | INFO | fairseq.trainer | begin training epoch 788
2022-03-07 19:00:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:02:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:02:30 | INFO | valid | epoch 788 | valid on 'valid' subset | loss 14.309 | nll_loss 14.136 | ppl 18005.9 | wps 42066.7 | wpb 510.9 | bsz 1 | num_updates 38361 | best_loss 8.318
2022-03-07 19:02:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 788 @ 38361 updates
2022-03-07 19:02:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:02:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:02:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 788 @ 38361 updates, score 14.309) (writing took 2.4199832305312157 seconds)
2022-03-07 19:02:32 | INFO | fairseq_cli.train | end of epoch 788 (average epoch stats below)
2022-03-07 19:02:32 | INFO | train | epoch 788 | loss 0.657 | nll_loss 0.129 | ppl 1.09 | wps 23753 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 38361 | lr 0.000161456 | gnorm 0.287 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 108003
2022-03-07 19:02:32 | INFO | fairseq.trainer | begin training epoch 789
2022-03-07 19:02:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:03:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:04:17 | INFO | train_inner | epoch 789:     40 / 49 loss=0.656, nll_loss=0.128, ppl=1.09, wps=23568.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=38400, lr=0.000161374, gnorm=0.286, loss_scale=64, train_wall=235, gb_free=8.8, wall=108107
2022-03-07 19:04:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:04:44 | INFO | valid | epoch 789 | valid on 'valid' subset | loss 14.29 | nll_loss 14.115 | ppl 17740.9 | wps 42238.8 | wpb 510.9 | bsz 1 | num_updates 38409 | best_loss 8.318
2022-03-07 19:04:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 789 @ 38409 updates
2022-03-07 19:04:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:04:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:04:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 789 @ 38409 updates, score 14.29) (writing took 2.645325429737568 seconds)
2022-03-07 19:04:47 | INFO | fairseq_cli.train | end of epoch 789 (average epoch stats below)
2022-03-07 19:04:47 | INFO | train | epoch 789 | loss 0.656 | nll_loss 0.128 | ppl 1.09 | wps 23154.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 38409 | lr 0.000161355 | gnorm 0.284 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 108137
2022-03-07 19:04:47 | INFO | fairseq.trainer | begin training epoch 790
2022-03-07 19:04:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:06:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:06:59 | INFO | valid | epoch 790 | valid on 'valid' subset | loss 14.272 | nll_loss 14.097 | ppl 17526.2 | wps 41576.8 | wpb 510.9 | bsz 1 | num_updates 38458 | best_loss 8.318
2022-03-07 19:06:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 790 @ 38458 updates
2022-03-07 19:06:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:07:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:07:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 790 @ 38458 updates, score 14.272) (writing took 2.552156485617161 seconds)
2022-03-07 19:07:01 | INFO | fairseq_cli.train | end of epoch 790 (average epoch stats below)
2022-03-07 19:07:01 | INFO | train | epoch 790 | loss 0.656 | nll_loss 0.128 | ppl 1.09 | wps 23623.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 38458 | lr 0.000161253 | gnorm 0.285 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 108272
2022-03-07 19:07:01 | INFO | fairseq.trainer | begin training epoch 791
2022-03-07 19:07:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:07:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:08:53 | INFO | train_inner | epoch 791:     43 / 49 loss=0.656, nll_loss=0.128, ppl=1.09, wps=23444.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=38500, lr=0.000161165, gnorm=0.288, loss_scale=32, train_wall=236, gb_free=8.8, wall=108384
2022-03-07 19:09:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:09:13 | INFO | valid | epoch 791 | valid on 'valid' subset | loss 14.273 | nll_loss 14.099 | ppl 17548.7 | wps 42189.5 | wpb 510.9 | bsz 1 | num_updates 38506 | best_loss 8.318
2022-03-07 19:09:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 791 @ 38506 updates
2022-03-07 19:09:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:09:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:09:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 791 @ 38506 updates, score 14.273) (writing took 2.5701517686247826 seconds)
2022-03-07 19:09:16 | INFO | fairseq_cli.train | end of epoch 791 (average epoch stats below)
2022-03-07 19:09:16 | INFO | train | epoch 791 | loss 0.657 | nll_loss 0.128 | ppl 1.09 | wps 23150.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 38506 | lr 0.000161152 | gnorm 0.291 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 108406
2022-03-07 19:09:16 | INFO | fairseq.trainer | begin training epoch 792
2022-03-07 19:09:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:11:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:11:27 | INFO | valid | epoch 792 | valid on 'valid' subset | loss 14.221 | nll_loss 14.047 | ppl 16921.5 | wps 41619.7 | wpb 510.9 | bsz 1 | num_updates 38555 | best_loss 8.318
2022-03-07 19:11:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 792 @ 38555 updates
2022-03-07 19:11:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:11:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:11:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 792 @ 38555 updates, score 14.221) (writing took 2.575800307095051 seconds)
2022-03-07 19:11:30 | INFO | fairseq_cli.train | end of epoch 792 (average epoch stats below)
2022-03-07 19:11:30 | INFO | train | epoch 792 | loss 0.656 | nll_loss 0.128 | ppl 1.09 | wps 23659.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 38555 | lr 0.00016105 | gnorm 0.283 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 108540
2022-03-07 19:11:30 | INFO | fairseq.trainer | begin training epoch 793
2022-03-07 19:11:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:13:28 | INFO | train_inner | epoch 793:     45 / 49 loss=0.656, nll_loss=0.128, ppl=1.09, wps=23665.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=38600, lr=0.000160956, gnorm=0.284, loss_scale=64, train_wall=234, gb_free=8.8, wall=108658
2022-03-07 19:13:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:13:42 | INFO | valid | epoch 793 | valid on 'valid' subset | loss 14.242 | nll_loss 14.067 | ppl 17164.2 | wps 42705.3 | wpb 510.9 | bsz 1 | num_updates 38604 | best_loss 8.318
2022-03-07 19:13:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 793 @ 38604 updates
2022-03-07 19:13:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:13:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:13:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 793 @ 38604 updates, score 14.242) (writing took 2.5786316245794296 seconds)
2022-03-07 19:13:44 | INFO | fairseq_cli.train | end of epoch 793 (average epoch stats below)
2022-03-07 19:13:44 | INFO | train | epoch 793 | loss 0.656 | nll_loss 0.128 | ppl 1.09 | wps 23644.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 38604 | lr 0.000160947 | gnorm 0.285 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 108675
2022-03-07 19:13:44 | INFO | fairseq.trainer | begin training epoch 794
2022-03-07 19:13:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:15:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:15:56 | INFO | valid | epoch 794 | valid on 'valid' subset | loss 14.133 | nll_loss 13.955 | ppl 15885.8 | wps 42466.2 | wpb 510.9 | bsz 1 | num_updates 38653 | best_loss 8.318
2022-03-07 19:15:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 794 @ 38653 updates
2022-03-07 19:15:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:15:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:15:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 794 @ 38653 updates, score 14.133) (writing took 2.547213966026902 seconds)
2022-03-07 19:15:59 | INFO | fairseq_cli.train | end of epoch 794 (average epoch stats below)
2022-03-07 19:15:59 | INFO | train | epoch 794 | loss 0.656 | nll_loss 0.128 | ppl 1.09 | wps 23612.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 38653 | lr 0.000160845 | gnorm 0.284 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 108809
2022-03-07 19:15:59 | INFO | fairseq.trainer | begin training epoch 795
2022-03-07 19:15:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:18:02 | INFO | train_inner | epoch 795:     47 / 49 loss=0.656, nll_loss=0.128, ppl=1.09, wps=23669, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=38700, lr=0.000160748, gnorm=0.286, loss_scale=64, train_wall=234, gb_free=8.8, wall=108932
2022-03-07 19:18:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:18:11 | INFO | valid | epoch 795 | valid on 'valid' subset | loss 14.269 | nll_loss 14.095 | ppl 17498 | wps 42303.8 | wpb 510.9 | bsz 1 | num_updates 38702 | best_loss 8.318
2022-03-07 19:18:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 795 @ 38702 updates
2022-03-07 19:18:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:18:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:18:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 795 @ 38702 updates, score 14.269) (writing took 2.558369889855385 seconds)
2022-03-07 19:18:13 | INFO | fairseq_cli.train | end of epoch 795 (average epoch stats below)
2022-03-07 19:18:13 | INFO | train | epoch 795 | loss 0.656 | nll_loss 0.128 | ppl 1.09 | wps 23671.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 38702 | lr 0.000160743 | gnorm 0.288 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 108944
2022-03-07 19:18:13 | INFO | fairseq.trainer | begin training epoch 796
2022-03-07 19:18:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:19:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:20:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:20:25 | INFO | valid | epoch 796 | valid on 'valid' subset | loss 14.184 | nll_loss 14.01 | ppl 16492.7 | wps 43081.4 | wpb 510.9 | bsz 1 | num_updates 38750 | best_loss 8.318
2022-03-07 19:20:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 796 @ 38750 updates
2022-03-07 19:20:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:20:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:20:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 796 @ 38750 updates, score 14.184) (writing took 2.615647815167904 seconds)
2022-03-07 19:20:28 | INFO | fairseq_cli.train | end of epoch 796 (average epoch stats below)
2022-03-07 19:20:28 | INFO | train | epoch 796 | loss 0.656 | nll_loss 0.128 | ppl 1.09 | wps 23178.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 38750 | lr 0.000160644 | gnorm 0.286 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 109078
2022-03-07 19:20:28 | INFO | fairseq.trainer | begin training epoch 797
2022-03-07 19:20:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:22:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:22:39 | INFO | valid | epoch 797 | valid on 'valid' subset | loss 14.268 | nll_loss 14.094 | ppl 17481.2 | wps 42413.4 | wpb 510.9 | bsz 1 | num_updates 38799 | best_loss 8.318
2022-03-07 19:22:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 797 @ 38799 updates
2022-03-07 19:22:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:22:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:22:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 797 @ 38799 updates, score 14.268) (writing took 2.574748305603862 seconds)
2022-03-07 19:22:42 | INFO | fairseq_cli.train | end of epoch 797 (average epoch stats below)
2022-03-07 19:22:42 | INFO | train | epoch 797 | loss 0.656 | nll_loss 0.128 | ppl 1.09 | wps 23697.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 38799 | lr 0.000160542 | gnorm 0.283 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 109212
2022-03-07 19:22:42 | INFO | fairseq.trainer | begin training epoch 798
2022-03-07 19:22:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:22:44 | INFO | train_inner | epoch 798:      1 / 49 loss=0.656, nll_loss=0.128, ppl=1.09, wps=22818.8, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=38800, lr=0.00016054, gnorm=0.286, loss_scale=64, train_wall=235, gb_free=8.8, wall=109215
2022-03-07 19:24:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:24:54 | INFO | valid | epoch 798 | valid on 'valid' subset | loss 14.241 | nll_loss 14.065 | ppl 17134.2 | wps 41798.7 | wpb 510.9 | bsz 1 | num_updates 38848 | best_loss 8.318
2022-03-07 19:24:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 798 @ 38848 updates
2022-03-07 19:24:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:24:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:24:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 798 @ 38848 updates, score 14.241) (writing took 2.54295252636075 seconds)
2022-03-07 19:24:56 | INFO | fairseq_cli.train | end of epoch 798 (average epoch stats below)
2022-03-07 19:24:56 | INFO | train | epoch 798 | loss 0.655 | nll_loss 0.128 | ppl 1.09 | wps 23594.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 38848 | lr 0.000160441 | gnorm 0.285 | loss_scale 128 | train_wall 115 | gb_free 8.8 | wall 109347
2022-03-07 19:24:56 | INFO | fairseq.trainer | begin training epoch 799
2022-03-07 19:24:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:24:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:27:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:27:08 | INFO | valid | epoch 799 | valid on 'valid' subset | loss 14.35 | nll_loss 14.177 | ppl 18525.7 | wps 42228.3 | wpb 510.9 | bsz 1 | num_updates 38896 | best_loss 8.318
2022-03-07 19:27:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 799 @ 38896 updates
2022-03-07 19:27:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:27:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:27:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 799 @ 38896 updates, score 14.35) (writing took 2.5699333511292934 seconds)
2022-03-07 19:27:11 | INFO | fairseq_cli.train | end of epoch 799 (average epoch stats below)
2022-03-07 19:27:11 | INFO | train | epoch 799 | loss 0.655 | nll_loss 0.127 | ppl 1.09 | wps 23156.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 38896 | lr 0.000160342 | gnorm 0.284 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 109481
2022-03-07 19:27:11 | INFO | fairseq.trainer | begin training epoch 800
2022-03-07 19:27:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:27:21 | INFO | train_inner | epoch 800:      4 / 49 loss=0.655, nll_loss=0.127, ppl=1.09, wps=23427.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=38900, lr=0.000160334, gnorm=0.285, loss_scale=64, train_wall=236, gb_free=8.8, wall=109492
2022-03-07 19:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:29:23 | INFO | valid | epoch 800 | valid on 'valid' subset | loss 14.221 | nll_loss 14.046 | ppl 16916.5 | wps 42761.7 | wpb 510.9 | bsz 1 | num_updates 38945 | best_loss 8.318
2022-03-07 19:29:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 800 @ 38945 updates
2022-03-07 19:29:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:29:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:29:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 800 @ 38945 updates, score 14.221) (writing took 2.6104500461369753 seconds)
2022-03-07 19:29:25 | INFO | fairseq_cli.train | end of epoch 800 (average epoch stats below)
2022-03-07 19:29:25 | INFO | train | epoch 800 | loss 0.655 | nll_loss 0.127 | ppl 1.09 | wps 23628.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 38945 | lr 0.000160241 | gnorm 0.283 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 109616
2022-03-07 19:29:25 | INFO | fairseq.trainer | begin training epoch 801
2022-03-07 19:29:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:30:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:31:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:31:37 | INFO | valid | epoch 801 | valid on 'valid' subset | loss 14.318 | nll_loss 14.145 | ppl 18120.3 | wps 42284.4 | wpb 510.9 | bsz 1 | num_updates 38993 | best_loss 8.318
2022-03-07 19:31:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 801 @ 38993 updates
2022-03-07 19:31:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:31:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:31:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 801 @ 38993 updates, score 14.318) (writing took 2.590913102030754 seconds)
2022-03-07 19:31:40 | INFO | fairseq_cli.train | end of epoch 801 (average epoch stats below)
2022-03-07 19:31:40 | INFO | train | epoch 801 | loss 0.655 | nll_loss 0.127 | ppl 1.09 | wps 23179.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 38993 | lr 0.000160143 | gnorm 0.285 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 109750
2022-03-07 19:31:40 | INFO | fairseq.trainer | begin training epoch 802
2022-03-07 19:31:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:31:58 | INFO | train_inner | epoch 802:      7 / 49 loss=0.655, nll_loss=0.127, ppl=1.09, wps=23454.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=39000, lr=0.000160128, gnorm=0.284, loss_scale=64, train_wall=236, gb_free=8.8, wall=109768
2022-03-07 19:33:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:33:52 | INFO | valid | epoch 802 | valid on 'valid' subset | loss 14.273 | nll_loss 14.1 | ppl 17562.4 | wps 41957.3 | wpb 510.9 | bsz 1 | num_updates 39042 | best_loss 8.318
2022-03-07 19:33:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 802 @ 39042 updates
2022-03-07 19:33:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:33:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:33:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 802 @ 39042 updates, score 14.273) (writing took 2.576033964753151 seconds)
2022-03-07 19:33:54 | INFO | fairseq_cli.train | end of epoch 802 (average epoch stats below)
2022-03-07 19:33:54 | INFO | train | epoch 802 | loss 0.655 | nll_loss 0.127 | ppl 1.09 | wps 23624.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 39042 | lr 0.000160042 | gnorm 0.285 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 109884
2022-03-07 19:33:54 | INFO | fairseq.trainer | begin training epoch 803
2022-03-07 19:33:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:36:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:36:06 | INFO | valid | epoch 803 | valid on 'valid' subset | loss 14.36 | nll_loss 14.189 | ppl 18674 | wps 42147.8 | wpb 510.9 | bsz 1 | num_updates 39091 | best_loss 8.318
2022-03-07 19:36:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 803 @ 39091 updates
2022-03-07 19:36:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:36:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:36:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 803 @ 39091 updates, score 14.36) (writing took 2.5636255629360676 seconds)
2022-03-07 19:36:09 | INFO | fairseq_cli.train | end of epoch 803 (average epoch stats below)
2022-03-07 19:36:09 | INFO | train | epoch 803 | loss 0.655 | nll_loss 0.127 | ppl 1.09 | wps 23635.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 39091 | lr 0.000159942 | gnorm 0.285 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 110019
2022-03-07 19:36:09 | INFO | fairseq.trainer | begin training epoch 804
2022-03-07 19:36:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:36:32 | INFO | train_inner | epoch 804:      9 / 49 loss=0.655, nll_loss=0.127, ppl=1.09, wps=23656.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=39100, lr=0.000159923, gnorm=0.285, loss_scale=64, train_wall=234, gb_free=8.8, wall=110042
2022-03-07 19:36:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:38:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:38:21 | INFO | valid | epoch 804 | valid on 'valid' subset | loss 14.287 | nll_loss 14.114 | ppl 17726.8 | wps 41780.3 | wpb 510.9 | bsz 1 | num_updates 39139 | best_loss 8.318
2022-03-07 19:38:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 804 @ 39139 updates
2022-03-07 19:38:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:38:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:38:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 804 @ 39139 updates, score 14.287) (writing took 2.6112771909683943 seconds)
2022-03-07 19:38:23 | INFO | fairseq_cli.train | end of epoch 804 (average epoch stats below)
2022-03-07 19:38:23 | INFO | train | epoch 804 | loss 0.654 | nll_loss 0.127 | ppl 1.09 | wps 23111.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 39139 | lr 0.000159844 | gnorm 0.283 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 110154
2022-03-07 19:38:23 | INFO | fairseq.trainer | begin training epoch 805
2022-03-07 19:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:40:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:40:35 | INFO | valid | epoch 805 | valid on 'valid' subset | loss 14.278 | nll_loss 14.103 | ppl 17596.9 | wps 41962.6 | wpb 510.9 | bsz 1 | num_updates 39188 | best_loss 8.318
2022-03-07 19:40:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 805 @ 39188 updates
2022-03-07 19:40:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:40:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:40:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 805 @ 39188 updates, score 14.278) (writing took 2.5712453089654446 seconds)
2022-03-07 19:40:38 | INFO | fairseq_cli.train | end of epoch 805 (average epoch stats below)
2022-03-07 19:40:38 | INFO | train | epoch 805 | loss 0.654 | nll_loss 0.127 | ppl 1.09 | wps 23587.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 39188 | lr 0.000159744 | gnorm 0.284 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 110288
2022-03-07 19:40:38 | INFO | fairseq.trainer | begin training epoch 806
2022-03-07 19:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:41:09 | INFO | train_inner | epoch 806:     12 / 49 loss=0.654, nll_loss=0.127, ppl=1.09, wps=23410.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=39200, lr=0.000159719, gnorm=0.284, loss_scale=64, train_wall=237, gb_free=8.8, wall=110320
2022-03-07 19:42:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:42:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:42:46 | INFO | valid | epoch 806 | valid on 'valid' subset | loss 14.257 | nll_loss 14.082 | ppl 17345.3 | wps 46423.4 | wpb 510.9 | bsz 1 | num_updates 39236 | best_loss 8.318
2022-03-07 19:42:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 806 @ 39236 updates
2022-03-07 19:42:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:42:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:42:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 806 @ 39236 updates, score 14.257) (writing took 2.553499322384596 seconds)
2022-03-07 19:42:49 | INFO | fairseq_cli.train | end of epoch 806 (average epoch stats below)
2022-03-07 19:42:49 | INFO | train | epoch 806 | loss 0.655 | nll_loss 0.127 | ppl 1.09 | wps 23751.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 39236 | lr 0.000159646 | gnorm 0.286 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 110419
2022-03-07 19:42:49 | INFO | fairseq.trainer | begin training epoch 807
2022-03-07 19:42:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:44:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:44:55 | INFO | valid | epoch 807 | valid on 'valid' subset | loss 14.238 | nll_loss 14.063 | ppl 17120.1 | wps 46440.8 | wpb 510.9 | bsz 1 | num_updates 39285 | best_loss 8.318
2022-03-07 19:44:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 807 @ 39285 updates
2022-03-07 19:44:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:44:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:44:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 807 @ 39285 updates, score 14.238) (writing took 2.5187812857329845 seconds)
2022-03-07 19:44:58 | INFO | fairseq_cli.train | end of epoch 807 (average epoch stats below)
2022-03-07 19:44:58 | INFO | train | epoch 807 | loss 0.654 | nll_loss 0.127 | ppl 1.09 | wps 24699.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39285 | lr 0.000159546 | gnorm 0.283 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 110548
2022-03-07 19:44:58 | INFO | fairseq.trainer | begin training epoch 808
2022-03-07 19:44:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:45:35 | INFO | train_inner | epoch 808:     15 / 49 loss=0.654, nll_loss=0.127, ppl=1.09, wps=24392.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=39300, lr=0.000159516, gnorm=0.284, loss_scale=64, train_wall=227, gb_free=8.8, wall=110585
2022-03-07 19:47:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:47:06 | INFO | valid | epoch 808 | valid on 'valid' subset | loss 14.201 | nll_loss 14.026 | ppl 16684 | wps 42734.5 | wpb 510.9 | bsz 1 | num_updates 39334 | best_loss 8.318
2022-03-07 19:47:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 808 @ 39334 updates
2022-03-07 19:47:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:47:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:47:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 808 @ 39334 updates, score 14.201) (writing took 2.4332233276218176 seconds)
2022-03-07 19:47:08 | INFO | fairseq_cli.train | end of epoch 808 (average epoch stats below)
2022-03-07 19:47:08 | INFO | train | epoch 808 | loss 0.654 | nll_loss 0.127 | ppl 1.09 | wps 24392.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39334 | lr 0.000159447 | gnorm 0.285 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 110678
2022-03-07 19:47:08 | INFO | fairseq.trainer | begin training epoch 809
2022-03-07 19:47:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:48:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:49:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:49:20 | INFO | valid | epoch 809 | valid on 'valid' subset | loss 14.305 | nll_loss 14.131 | ppl 17947.2 | wps 42584.6 | wpb 510.9 | bsz 1 | num_updates 39382 | best_loss 8.318
2022-03-07 19:49:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 809 @ 39382 updates
2022-03-07 19:49:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:49:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:49:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 809 @ 39382 updates, score 14.305) (writing took 2.575434932485223 seconds)
2022-03-07 19:49:22 | INFO | fairseq_cli.train | end of epoch 809 (average epoch stats below)
2022-03-07 19:49:22 | INFO | train | epoch 809 | loss 0.654 | nll_loss 0.127 | ppl 1.09 | wps 23179.5 | ups 0.36 | wpb 64853.3 | bsz 126.7 | num_updates 39382 | lr 0.00015935 | gnorm 0.281 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 110813
2022-03-07 19:49:22 | INFO | fairseq.trainer | begin training epoch 810
2022-03-07 19:49:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:50:09 | INFO | train_inner | epoch 810:     18 / 49 loss=0.654, nll_loss=0.127, ppl=1.09, wps=23672.3, ups=0.36, wpb=64880.6, bsz=126.7, num_updates=39400, lr=0.000159313, gnorm=0.283, loss_scale=64, train_wall=234, gb_free=8.8, wall=110860
2022-03-07 19:51:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:51:34 | INFO | valid | epoch 810 | valid on 'valid' subset | loss 14.321 | nll_loss 14.148 | ppl 18154.9 | wps 41935.9 | wpb 510.9 | bsz 1 | num_updates 39431 | best_loss 8.318
2022-03-07 19:51:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 810 @ 39431 updates
2022-03-07 19:51:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:51:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:51:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 810 @ 39431 updates, score 14.321) (writing took 2.5264301132410765 seconds)
2022-03-07 19:51:37 | INFO | fairseq_cli.train | end of epoch 810 (average epoch stats below)
2022-03-07 19:51:37 | INFO | train | epoch 810 | loss 0.654 | nll_loss 0.126 | ppl 1.09 | wps 23643 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 39431 | lr 0.000159251 | gnorm 0.284 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 110947
2022-03-07 19:51:37 | INFO | fairseq.trainer | begin training epoch 811
2022-03-07 19:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:53:48 | INFO | valid | epoch 811 | valid on 'valid' subset | loss 14.305 | nll_loss 14.132 | ppl 17956.7 | wps 42151.2 | wpb 510.9 | bsz 1 | num_updates 39480 | best_loss 8.318
2022-03-07 19:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 811 @ 39480 updates
2022-03-07 19:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:53:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:53:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 811 @ 39480 updates, score 14.305) (writing took 2.577912012115121 seconds)
2022-03-07 19:53:51 | INFO | fairseq_cli.train | end of epoch 811 (average epoch stats below)
2022-03-07 19:53:51 | INFO | train | epoch 811 | loss 0.654 | nll_loss 0.126 | ppl 1.09 | wps 23657.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 39480 | lr 0.000159152 | gnorm 0.283 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 111081
2022-03-07 19:53:51 | INFO | fairseq.trainer | begin training epoch 812
2022-03-07 19:53:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:54:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:54:46 | INFO | train_inner | epoch 812:     21 / 49 loss=0.654, nll_loss=0.126, ppl=1.09, wps=23444.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=39500, lr=0.000159111, gnorm=0.283, loss_scale=64, train_wall=236, gb_free=8.8, wall=111136
2022-03-07 19:55:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:56:03 | INFO | valid | epoch 812 | valid on 'valid' subset | loss 14.28 | nll_loss 14.106 | ppl 17631.8 | wps 43591.4 | wpb 510.9 | bsz 1 | num_updates 39528 | best_loss 8.318
2022-03-07 19:56:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 812 @ 39528 updates
2022-03-07 19:56:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:56:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:56:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 812 @ 39528 updates, score 14.28) (writing took 2.500022007152438 seconds)
2022-03-07 19:56:05 | INFO | fairseq_cli.train | end of epoch 812 (average epoch stats below)
2022-03-07 19:56:05 | INFO | train | epoch 812 | loss 0.654 | nll_loss 0.126 | ppl 1.09 | wps 23220.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 39528 | lr 0.000159055 | gnorm 0.283 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 111215
2022-03-07 19:56:05 | INFO | fairseq.trainer | begin training epoch 813
2022-03-07 19:56:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:58:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:58:16 | INFO | valid | epoch 813 | valid on 'valid' subset | loss 14.341 | nll_loss 14.168 | ppl 18413.2 | wps 41692.9 | wpb 510.9 | bsz 1 | num_updates 39577 | best_loss 8.318
2022-03-07 19:58:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 813 @ 39577 updates
2022-03-07 19:58:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:58:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:58:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 813 @ 39577 updates, score 14.341) (writing took 2.5899881832301617 seconds)
2022-03-07 19:58:18 | INFO | fairseq_cli.train | end of epoch 813 (average epoch stats below)
2022-03-07 19:58:18 | INFO | train | epoch 813 | loss 0.653 | nll_loss 0.126 | ppl 1.09 | wps 23832.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 39577 | lr 0.000158957 | gnorm 0.283 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 111349
2022-03-07 19:58:18 | INFO | fairseq.trainer | begin training epoch 814
2022-03-07 19:58:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:59:18 | INFO | train_inner | epoch 814:     23 / 49 loss=0.653, nll_loss=0.126, ppl=1.09, wps=23828.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=39600, lr=0.00015891, gnorm=0.283, loss_scale=64, train_wall=232, gb_free=8.8, wall=111409
2022-03-07 20:00:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:00:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:00:29 | INFO | valid | epoch 814 | valid on 'valid' subset | loss 14.316 | nll_loss 14.145 | ppl 18120.6 | wps 42858.2 | wpb 510.9 | bsz 1 | num_updates 39625 | best_loss 8.318
2022-03-07 20:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 814 @ 39625 updates
2022-03-07 20:00:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:00:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:00:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 814 @ 39625 updates, score 14.316) (writing took 2.548580888658762 seconds)
2022-03-07 20:00:32 | INFO | fairseq_cli.train | end of epoch 814 (average epoch stats below)
2022-03-07 20:00:32 | INFO | train | epoch 814 | loss 0.653 | nll_loss 0.126 | ppl 1.09 | wps 23368.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 39625 | lr 0.00015886 | gnorm 0.282 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 111482
2022-03-07 20:00:32 | INFO | fairseq.trainer | begin training epoch 815
2022-03-07 20:00:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:02:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:02:43 | INFO | valid | epoch 815 | valid on 'valid' subset | loss 14.254 | nll_loss 14.08 | ppl 17319.8 | wps 42125.5 | wpb 510.9 | bsz 1 | num_updates 39674 | best_loss 8.318
2022-03-07 20:02:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 815 @ 39674 updates
2022-03-07 20:02:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:02:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:02:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 815 @ 39674 updates, score 14.254) (writing took 2.6110176350921392 seconds)
2022-03-07 20:02:45 | INFO | fairseq_cli.train | end of epoch 815 (average epoch stats below)
2022-03-07 20:02:45 | INFO | train | epoch 815 | loss 0.654 | nll_loss 0.127 | ppl 1.09 | wps 23736.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 39674 | lr 0.000158762 | gnorm 0.285 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 111616
2022-03-07 20:02:45 | INFO | fairseq.trainer | begin training epoch 816
2022-03-07 20:02:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:03:53 | INFO | train_inner | epoch 816:     26 / 49 loss=0.654, nll_loss=0.126, ppl=1.09, wps=23611.1, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=39700, lr=0.00015871, gnorm=0.283, loss_scale=64, train_wall=234, gb_free=8.8, wall=111683
2022-03-07 20:04:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:04:57 | INFO | valid | epoch 816 | valid on 'valid' subset | loss 14.23 | nll_loss 14.055 | ppl 17020.6 | wps 42340.5 | wpb 510.9 | bsz 1 | num_updates 39723 | best_loss 8.318
2022-03-07 20:04:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 816 @ 39723 updates
2022-03-07 20:04:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:04:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:04:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 816 @ 39723 updates, score 14.23) (writing took 2.520219534635544 seconds)
2022-03-07 20:04:59 | INFO | fairseq_cli.train | end of epoch 816 (average epoch stats below)
2022-03-07 20:04:59 | INFO | train | epoch 816 | loss 0.653 | nll_loss 0.126 | ppl 1.09 | wps 23719.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 39723 | lr 0.000158664 | gnorm 0.283 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 111750
2022-03-07 20:04:59 | INFO | fairseq.trainer | begin training epoch 817
2022-03-07 20:04:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:06:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:07:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:07:11 | INFO | valid | epoch 817 | valid on 'valid' subset | loss 14.217 | nll_loss 14.044 | ppl 16886.7 | wps 42181.2 | wpb 510.9 | bsz 1 | num_updates 39771 | best_loss 8.318
2022-03-07 20:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 817 @ 39771 updates
2022-03-07 20:07:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:07:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:07:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 817 @ 39771 updates, score 14.217) (writing took 2.5816013868898153 seconds)
2022-03-07 20:07:14 | INFO | fairseq_cli.train | end of epoch 817 (average epoch stats below)
2022-03-07 20:07:14 | INFO | train | epoch 817 | loss 0.653 | nll_loss 0.126 | ppl 1.09 | wps 23195.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 39771 | lr 0.000158568 | gnorm 0.282 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 111884
2022-03-07 20:07:14 | INFO | fairseq.trainer | begin training epoch 818
2022-03-07 20:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:08:29 | INFO | train_inner | epoch 818:     29 / 49 loss=0.653, nll_loss=0.126, ppl=1.09, wps=23475.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=39800, lr=0.000158511, gnorm=0.283, loss_scale=64, train_wall=236, gb_free=8.8, wall=111960
2022-03-07 20:09:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:09:25 | INFO | valid | epoch 818 | valid on 'valid' subset | loss 14.245 | nll_loss 14.071 | ppl 17205 | wps 42144.9 | wpb 510.9 | bsz 1 | num_updates 39820 | best_loss 8.318
2022-03-07 20:09:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 818 @ 39820 updates
2022-03-07 20:09:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:09:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:09:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 818 @ 39820 updates, score 14.245) (writing took 2.571732223033905 seconds)
2022-03-07 20:09:28 | INFO | fairseq_cli.train | end of epoch 818 (average epoch stats below)
2022-03-07 20:09:28 | INFO | train | epoch 818 | loss 0.653 | nll_loss 0.126 | ppl 1.09 | wps 23670.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 39820 | lr 0.000158471 | gnorm 0.284 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 112018
2022-03-07 20:09:28 | INFO | fairseq.trainer | begin training epoch 819
2022-03-07 20:09:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:11:40 | INFO | valid | epoch 819 | valid on 'valid' subset | loss 14.269 | nll_loss 14.097 | ppl 17521.8 | wps 42413.9 | wpb 510.9 | bsz 1 | num_updates 39869 | best_loss 8.318
2022-03-07 20:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 819 @ 39869 updates
2022-03-07 20:11:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:11:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:11:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 819 @ 39869 updates, score 14.269) (writing took 2.5735156442970037 seconds)
2022-03-07 20:11:42 | INFO | fairseq_cli.train | end of epoch 819 (average epoch stats below)
2022-03-07 20:11:42 | INFO | train | epoch 819 | loss 0.653 | nll_loss 0.126 | ppl 1.09 | wps 23637.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 39869 | lr 0.000158373 | gnorm 0.284 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 112153
2022-03-07 20:11:42 | INFO | fairseq.trainer | begin training epoch 820
2022-03-07 20:11:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:12:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:13:06 | INFO | train_inner | epoch 820:     32 / 49 loss=0.653, nll_loss=0.126, ppl=1.09, wps=23453.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=39900, lr=0.000158312, gnorm=0.282, loss_scale=64, train_wall=236, gb_free=8.8, wall=112236
2022-03-07 20:13:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:13:54 | INFO | valid | epoch 820 | valid on 'valid' subset | loss 14.215 | nll_loss 14.043 | ppl 16880.1 | wps 43033.9 | wpb 510.9 | bsz 1 | num_updates 39917 | best_loss 8.318
2022-03-07 20:13:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 820 @ 39917 updates
2022-03-07 20:13:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:13:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:13:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 820 @ 39917 updates, score 14.215) (writing took 2.5493750125169754 seconds)
2022-03-07 20:13:57 | INFO | fairseq_cli.train | end of epoch 820 (average epoch stats below)
2022-03-07 20:13:57 | INFO | train | epoch 820 | loss 0.652 | nll_loss 0.125 | ppl 1.09 | wps 23176.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 39917 | lr 0.000158278 | gnorm 0.279 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 112287
2022-03-07 20:13:57 | INFO | fairseq.trainer | begin training epoch 821
2022-03-07 20:13:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:16:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:16:09 | INFO | valid | epoch 821 | valid on 'valid' subset | loss 14.251 | nll_loss 14.079 | ppl 17300.5 | wps 42109.5 | wpb 510.9 | bsz 1 | num_updates 39966 | best_loss 8.318
2022-03-07 20:16:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 821 @ 39966 updates
2022-03-07 20:16:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:16:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:16:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 821 @ 39966 updates, score 14.251) (writing took 2.546546643599868 seconds)
2022-03-07 20:16:11 | INFO | fairseq_cli.train | end of epoch 821 (average epoch stats below)
2022-03-07 20:16:11 | INFO | train | epoch 821 | loss 0.652 | nll_loss 0.125 | ppl 1.09 | wps 23634.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 39966 | lr 0.000158181 | gnorm 0.28 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 112421
2022-03-07 20:16:11 | INFO | fairseq.trainer | begin training epoch 822
2022-03-07 20:16:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:17:40 | INFO | train_inner | epoch 822:     34 / 49 loss=0.652, nll_loss=0.125, ppl=1.09, wps=23681.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=40000, lr=0.000158114, gnorm=0.28, loss_scale=64, train_wall=234, gb_free=8.8, wall=112510
2022-03-07 20:18:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:18:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:18:23 | INFO | valid | epoch 822 | valid on 'valid' subset | loss 14.327 | nll_loss 14.153 | ppl 18221.3 | wps 42377.2 | wpb 510.9 | bsz 1 | num_updates 40014 | best_loss 8.318
2022-03-07 20:18:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 822 @ 40014 updates
2022-03-07 20:18:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:18:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:18:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 822 @ 40014 updates, score 14.327) (writing took 2.5138334538787603 seconds)
2022-03-07 20:18:25 | INFO | fairseq_cli.train | end of epoch 822 (average epoch stats below)
2022-03-07 20:18:25 | INFO | train | epoch 822 | loss 0.653 | nll_loss 0.126 | ppl 1.09 | wps 23192.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 40014 | lr 0.000158086 | gnorm 0.282 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 112556
2022-03-07 20:18:25 | INFO | fairseq.trainer | begin training epoch 823
2022-03-07 20:18:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:20:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:20:37 | INFO | valid | epoch 823 | valid on 'valid' subset | loss 14.229 | nll_loss 14.055 | ppl 17017.5 | wps 42389.2 | wpb 510.9 | bsz 1 | num_updates 40063 | best_loss 8.318
2022-03-07 20:20:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 823 @ 40063 updates
2022-03-07 20:20:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:20:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:20:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 823 @ 40063 updates, score 14.229) (writing took 2.55502668954432 seconds)
2022-03-07 20:20:40 | INFO | fairseq_cli.train | end of epoch 823 (average epoch stats below)
2022-03-07 20:20:40 | INFO | train | epoch 823 | loss 0.652 | nll_loss 0.125 | ppl 1.09 | wps 23645.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 40063 | lr 0.00015799 | gnorm 0.281 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 112690
2022-03-07 20:20:40 | INFO | fairseq.trainer | begin training epoch 824
2022-03-07 20:20:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:22:16 | INFO | train_inner | epoch 824:     37 / 49 loss=0.652, nll_loss=0.126, ppl=1.09, wps=23461.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=40100, lr=0.000157917, gnorm=0.282, loss_scale=64, train_wall=236, gb_free=8.8, wall=112787
2022-03-07 20:22:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:22:51 | INFO | valid | epoch 824 | valid on 'valid' subset | loss 14.24 | nll_loss 14.065 | ppl 17137.1 | wps 46464.5 | wpb 510.9 | bsz 1 | num_updates 40112 | best_loss 8.318
2022-03-07 20:22:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 824 @ 40112 updates
2022-03-07 20:22:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:22:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:22:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 824 @ 40112 updates, score 14.24) (writing took 2.5732935704290867 seconds)
2022-03-07 20:22:53 | INFO | fairseq_cli.train | end of epoch 824 (average epoch stats below)
2022-03-07 20:22:53 | INFO | train | epoch 824 | loss 0.652 | nll_loss 0.125 | ppl 1.09 | wps 23822.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 40112 | lr 0.000157893 | gnorm 0.283 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 112823
2022-03-07 20:22:53 | INFO | fairseq.trainer | begin training epoch 825
2022-03-07 20:22:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:23:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:24:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:25:00 | INFO | valid | epoch 825 | valid on 'valid' subset | loss 14.19 | nll_loss 14.016 | ppl 16565.7 | wps 46229.8 | wpb 510.9 | bsz 1 | num_updates 40160 | best_loss 8.318
2022-03-07 20:25:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 825 @ 40160 updates
2022-03-07 20:25:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:25:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:25:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 825 @ 40160 updates, score 14.19) (writing took 2.515027616173029 seconds)
2022-03-07 20:25:03 | INFO | fairseq_cli.train | end of epoch 825 (average epoch stats below)
2022-03-07 20:25:03 | INFO | train | epoch 825 | loss 0.652 | nll_loss 0.126 | ppl 1.09 | wps 24044.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 40160 | lr 0.000157799 | gnorm 0.285 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 112953
2022-03-07 20:25:03 | INFO | fairseq.trainer | begin training epoch 826
2022-03-07 20:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:26:43 | INFO | train_inner | epoch 826:     40 / 49 loss=0.652, nll_loss=0.125, ppl=1.09, wps=24340.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40200, lr=0.00015772, gnorm=0.283, loss_scale=64, train_wall=227, gb_free=8.8, wall=113053
2022-03-07 20:27:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:27:09 | INFO | valid | epoch 826 | valid on 'valid' subset | loss 14.271 | nll_loss 14.099 | ppl 17541.9 | wps 46144.5 | wpb 510.9 | bsz 1 | num_updates 40209 | best_loss 8.318
2022-03-07 20:27:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 826 @ 40209 updates
2022-03-07 20:27:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:27:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:27:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 826 @ 40209 updates, score 14.271) (writing took 2.537591913715005 seconds)
2022-03-07 20:27:11 | INFO | fairseq_cli.train | end of epoch 826 (average epoch stats below)
2022-03-07 20:27:11 | INFO | train | epoch 826 | loss 0.652 | nll_loss 0.125 | ppl 1.09 | wps 24680.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40209 | lr 0.000157702 | gnorm 0.28 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 113082
2022-03-07 20:27:11 | INFO | fairseq.trainer | begin training epoch 827
2022-03-07 20:27:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:29:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:29:17 | INFO | valid | epoch 827 | valid on 'valid' subset | loss 14.254 | nll_loss 14.081 | ppl 17333.5 | wps 46285.6 | wpb 510.9 | bsz 1 | num_updates 40258 | best_loss 8.318
2022-03-07 20:29:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 827 @ 40258 updates
2022-03-07 20:29:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:29:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:29:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 827 @ 40258 updates, score 14.254) (writing took 2.514710709452629 seconds)
2022-03-07 20:29:20 | INFO | fairseq_cli.train | end of epoch 827 (average epoch stats below)
2022-03-07 20:29:20 | INFO | train | epoch 827 | loss 0.652 | nll_loss 0.125 | ppl 1.09 | wps 24715.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40258 | lr 0.000157606 | gnorm 0.282 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 113210
2022-03-07 20:29:20 | INFO | fairseq.trainer | begin training epoch 828
2022-03-07 20:29:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:29:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:31:08 | INFO | train_inner | epoch 828:     43 / 49 loss=0.652, nll_loss=0.125, ppl=1.09, wps=24500.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=40300, lr=0.000157524, gnorm=0.282, loss_scale=64, train_wall=226, gb_free=8.8, wall=113318
2022-03-07 20:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:31:26 | INFO | valid | epoch 828 | valid on 'valid' subset | loss 14.221 | nll_loss 14.047 | ppl 16930.4 | wps 46449.5 | wpb 510.9 | bsz 1 | num_updates 40306 | best_loss 8.318
2022-03-07 20:31:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 828 @ 40306 updates
2022-03-07 20:31:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:31:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:31:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 828 @ 40306 updates, score 14.221) (writing took 2.54441193677485 seconds)
2022-03-07 20:31:29 | INFO | fairseq_cli.train | end of epoch 828 (average epoch stats below)
2022-03-07 20:31:29 | INFO | train | epoch 828 | loss 0.652 | nll_loss 0.125 | ppl 1.09 | wps 24182.2 | ups 0.37 | wpb 64853.3 | bsz 126.7 | num_updates 40306 | lr 0.000157513 | gnorm 0.282 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 113339
2022-03-07 20:31:29 | INFO | fairseq.trainer | begin training epoch 829
2022-03-07 20:31:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:33:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:33:39 | INFO | valid | epoch 829 | valid on 'valid' subset | loss 14.243 | nll_loss 14.069 | ppl 17184.3 | wps 42961.6 | wpb 510.9 | bsz 1 | num_updates 40355 | best_loss 8.318
2022-03-07 20:33:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 829 @ 40355 updates
2022-03-07 20:33:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:33:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:33:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 829 @ 40355 updates, score 14.243) (writing took 2.4390404745936394 seconds)
2022-03-07 20:33:42 | INFO | fairseq_cli.train | end of epoch 829 (average epoch stats below)
2022-03-07 20:33:42 | INFO | train | epoch 829 | loss 0.652 | nll_loss 0.125 | ppl 1.09 | wps 23893.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 40355 | lr 0.000157417 | gnorm 0.283 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 113472
2022-03-07 20:33:42 | INFO | fairseq.trainer | begin training epoch 830
2022-03-07 20:33:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:35:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:35:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:35:44 | INFO | train_inner | epoch 830:     47 / 49 loss=0.652, nll_loss=0.125, ppl=1.09, wps=23473.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=40400, lr=0.000157329, gnorm=0.282, loss_scale=32, train_wall=236, gb_free=8.8, wall=113594
2022-03-07 20:35:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:35:53 | INFO | valid | epoch 830 | valid on 'valid' subset | loss 14.192 | nll_loss 14.017 | ppl 16579.8 | wps 42802.8 | wpb 510.9 | bsz 1 | num_updates 40402 | best_loss 8.318
2022-03-07 20:35:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 830 @ 40402 updates
2022-03-07 20:35:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:35:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:35:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 830 @ 40402 updates, score 14.192) (writing took 2.4714092407375574 seconds)
2022-03-07 20:35:56 | INFO | fairseq_cli.train | end of epoch 830 (average epoch stats below)
2022-03-07 20:35:56 | INFO | train | epoch 830 | loss 0.652 | nll_loss 0.125 | ppl 1.09 | wps 22761.2 | ups 0.35 | wpb 64829.4 | bsz 126.6 | num_updates 40402 | lr 0.000157325 | gnorm 0.282 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 113606
2022-03-07 20:35:56 | INFO | fairseq.trainer | begin training epoch 831
2022-03-07 20:35:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:38:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:38:05 | INFO | valid | epoch 831 | valid on 'valid' subset | loss 14.286 | nll_loss 14.113 | ppl 17716.7 | wps 46384.1 | wpb 510.9 | bsz 1 | num_updates 40451 | best_loss 8.318
2022-03-07 20:38:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 831 @ 40451 updates
2022-03-07 20:38:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:38:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:38:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 831 @ 40451 updates, score 14.286) (writing took 2.5261140428483486 seconds)
2022-03-07 20:38:08 | INFO | fairseq_cli.train | end of epoch 831 (average epoch stats below)
2022-03-07 20:38:08 | INFO | train | epoch 831 | loss 0.652 | nll_loss 0.125 | ppl 1.09 | wps 24060.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 40451 | lr 0.00015723 | gnorm 0.284 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 113738
2022-03-07 20:38:08 | INFO | fairseq.trainer | begin training epoch 832
2022-03-07 20:38:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:40:09 | INFO | train_inner | epoch 832:     49 / 49 loss=0.651, nll_loss=0.125, ppl=1.09, wps=24361.8, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=40500, lr=0.000157135, gnorm=0.284, loss_scale=32, train_wall=226, gb_free=8.8, wall=113859
2022-03-07 20:40:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:40:14 | INFO | valid | epoch 832 | valid on 'valid' subset | loss 14.288 | nll_loss 14.115 | ppl 17749 | wps 46748.1 | wpb 510.9 | bsz 1 | num_updates 40500 | best_loss 8.318
2022-03-07 20:40:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 832 @ 40500 updates
2022-03-07 20:40:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:40:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:40:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 832 @ 40500 updates, score 14.288) (writing took 2.5340104307979345 seconds)
2022-03-07 20:40:16 | INFO | fairseq_cli.train | end of epoch 832 (average epoch stats below)
2022-03-07 20:40:16 | INFO | train | epoch 832 | loss 0.651 | nll_loss 0.125 | ppl 1.09 | wps 24716.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40500 | lr 0.000157135 | gnorm 0.282 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 113867
2022-03-07 20:40:16 | INFO | fairseq.trainer | begin training epoch 833
2022-03-07 20:40:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:42:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:42:22 | INFO | valid | epoch 833 | valid on 'valid' subset | loss 14.332 | nll_loss 14.16 | ppl 18307.3 | wps 46245.9 | wpb 510.9 | bsz 1 | num_updates 40549 | best_loss 8.318
2022-03-07 20:42:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 833 @ 40549 updates
2022-03-07 20:42:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:42:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:42:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 833 @ 40549 updates, score 14.332) (writing took 2.529734369367361 seconds)
2022-03-07 20:42:25 | INFO | fairseq_cli.train | end of epoch 833 (average epoch stats below)
2022-03-07 20:42:25 | INFO | train | epoch 833 | loss 0.651 | nll_loss 0.125 | ppl 1.09 | wps 24708.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40549 | lr 0.00015704 | gnorm 0.28 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 113995
2022-03-07 20:42:25 | INFO | fairseq.trainer | begin training epoch 834
2022-03-07 20:42:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:44:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:44:35 | INFO | valid | epoch 834 | valid on 'valid' subset | loss 14.292 | nll_loss 14.121 | ppl 17813.4 | wps 43287.8 | wpb 510.9 | bsz 1 | num_updates 40598 | best_loss 8.318
2022-03-07 20:44:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 834 @ 40598 updates
2022-03-07 20:44:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:44:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:44:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 834 @ 40598 updates, score 14.292) (writing took 2.5550496000796556 seconds)
2022-03-07 20:44:38 | INFO | fairseq_cli.train | end of epoch 834 (average epoch stats below)
2022-03-07 20:44:38 | INFO | train | epoch 834 | loss 0.651 | nll_loss 0.124 | ppl 1.09 | wps 23914.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 40598 | lr 0.000156945 | gnorm 0.28 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 114128
2022-03-07 20:44:38 | INFO | fairseq.trainer | begin training epoch 835
2022-03-07 20:44:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:44:43 | INFO | train_inner | epoch 835:      2 / 49 loss=0.651, nll_loss=0.124, ppl=1.09, wps=23672.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=40600, lr=0.000156941, gnorm=0.28, loss_scale=64, train_wall=227, gb_free=8.8, wall=114133
2022-03-07 20:46:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:46:44 | INFO | valid | epoch 835 | valid on 'valid' subset | loss 14.214 | nll_loss 14.041 | ppl 16860.4 | wps 46673.5 | wpb 510.9 | bsz 1 | num_updates 40647 | best_loss 8.318
2022-03-07 20:46:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 835 @ 40647 updates
2022-03-07 20:46:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:46:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:46:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 835 @ 40647 updates, score 14.214) (writing took 2.5186504051089287 seconds)
2022-03-07 20:46:47 | INFO | fairseq_cli.train | end of epoch 835 (average epoch stats below)
2022-03-07 20:46:47 | INFO | train | epoch 835 | loss 0.651 | nll_loss 0.124 | ppl 1.09 | wps 24597.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40647 | lr 0.00015685 | gnorm 0.281 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 114257
2022-03-07 20:46:47 | INFO | fairseq.trainer | begin training epoch 836
2022-03-07 20:46:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:47:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:48:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:48:53 | INFO | valid | epoch 836 | valid on 'valid' subset | loss 14.26 | nll_loss 14.087 | ppl 17400 | wps 46642.8 | wpb 510.9 | bsz 1 | num_updates 40695 | best_loss 8.318
2022-03-07 20:48:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 836 @ 40695 updates
2022-03-07 20:48:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:48:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:48:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 836 @ 40695 updates, score 14.26) (writing took 2.5613351352512836 seconds)
2022-03-07 20:48:56 | INFO | fairseq_cli.train | end of epoch 836 (average epoch stats below)
2022-03-07 20:48:56 | INFO | train | epoch 836 | loss 0.651 | nll_loss 0.125 | ppl 1.09 | wps 24207.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 40695 | lr 0.000156758 | gnorm 0.284 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 114386
2022-03-07 20:48:56 | INFO | fairseq.trainer | begin training epoch 837
2022-03-07 20:48:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:49:08 | INFO | train_inner | epoch 837:      5 / 49 loss=0.651, nll_loss=0.124, ppl=1.09, wps=24462.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40700, lr=0.000156748, gnorm=0.282, loss_scale=64, train_wall=226, gb_free=8.8, wall=114398
2022-03-07 20:51:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:51:06 | INFO | valid | epoch 837 | valid on 'valid' subset | loss 14.292 | nll_loss 14.119 | ppl 17792.2 | wps 42435 | wpb 510.9 | bsz 1 | num_updates 40744 | best_loss 8.318
2022-03-07 20:51:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 837 @ 40744 updates
2022-03-07 20:51:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:51:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:51:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 837 @ 40744 updates, score 14.292) (writing took 2.4212531931698322 seconds)
2022-03-07 20:51:09 | INFO | fairseq_cli.train | end of epoch 837 (average epoch stats below)
2022-03-07 20:51:09 | INFO | train | epoch 837 | loss 0.651 | nll_loss 0.124 | ppl 1.09 | wps 23880.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 40744 | lr 0.000156664 | gnorm 0.281 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 114519
2022-03-07 20:51:09 | INFO | fairseq.trainer | begin training epoch 838
2022-03-07 20:51:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:52:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:53:20 | INFO | valid | epoch 838 | valid on 'valid' subset | loss 14.187 | nll_loss 14.012 | ppl 16521.1 | wps 42469.9 | wpb 510.9 | bsz 1 | num_updates 40792 | best_loss 8.318
2022-03-07 20:53:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 838 @ 40792 updates
2022-03-07 20:53:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:53:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:53:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 838 @ 40792 updates, score 14.187) (writing took 2.5639814641326666 seconds)
2022-03-07 20:53:23 | INFO | fairseq_cli.train | end of epoch 838 (average epoch stats below)
2022-03-07 20:53:23 | INFO | train | epoch 838 | loss 0.651 | nll_loss 0.124 | ppl 1.09 | wps 23218.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 40792 | lr 0.000156571 | gnorm 0.282 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 114653
2022-03-07 20:53:23 | INFO | fairseq.trainer | begin training epoch 839
2022-03-07 20:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:53:44 | INFO | train_inner | epoch 839:      8 / 49 loss=0.651, nll_loss=0.124, ppl=1.09, wps=23549, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=40800, lr=0.000156556, gnorm=0.282, loss_scale=64, train_wall=235, gb_free=8.8, wall=114674
2022-03-07 20:55:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:55:34 | INFO | valid | epoch 839 | valid on 'valid' subset | loss 14.153 | nll_loss 13.978 | ppl 16141.2 | wps 43402 | wpb 510.9 | bsz 1 | num_updates 40841 | best_loss 8.318
2022-03-07 20:55:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 839 @ 40841 updates
2022-03-07 20:55:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:55:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:55:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 839 @ 40841 updates, score 14.153) (writing took 2.5633621644228697 seconds)
2022-03-07 20:55:37 | INFO | fairseq_cli.train | end of epoch 839 (average epoch stats below)
2022-03-07 20:55:37 | INFO | train | epoch 839 | loss 0.65 | nll_loss 0.124 | ppl 1.09 | wps 23701.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 40841 | lr 0.000156477 | gnorm 0.28 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 114787
2022-03-07 20:55:37 | INFO | fairseq.trainer | begin training epoch 840
2022-03-07 20:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:57:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:57:48 | INFO | valid | epoch 840 | valid on 'valid' subset | loss 14.257 | nll_loss 14.084 | ppl 17370.1 | wps 42919.8 | wpb 510.9 | bsz 1 | num_updates 40890 | best_loss 8.318
2022-03-07 20:57:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 840 @ 40890 updates
2022-03-07 20:57:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:57:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:57:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 840 @ 40890 updates, score 14.257) (writing took 2.5381145793944597 seconds)
2022-03-07 20:57:51 | INFO | fairseq_cli.train | end of epoch 840 (average epoch stats below)
2022-03-07 20:57:51 | INFO | train | epoch 840 | loss 0.65 | nll_loss 0.124 | ppl 1.09 | wps 23709.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 40890 | lr 0.000156384 | gnorm 0.282 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 114921
2022-03-07 20:57:51 | INFO | fairseq.trainer | begin training epoch 841
2022-03-07 20:57:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:58:17 | INFO | train_inner | epoch 841:     10 / 49 loss=0.651, nll_loss=0.124, ppl=1.09, wps=23729.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=40900, lr=0.000156365, gnorm=0.281, loss_scale=64, train_wall=234, gb_free=8.8, wall=114947
2022-03-07 20:58:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:59:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:00:02 | INFO | valid | epoch 841 | valid on 'valid' subset | loss 14.206 | nll_loss 14.032 | ppl 16754.5 | wps 43642.8 | wpb 510.9 | bsz 1 | num_updates 40938 | best_loss 8.318
2022-03-07 21:00:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 841 @ 40938 updates
2022-03-07 21:00:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:00:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:00:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 841 @ 40938 updates, score 14.206) (writing took 2.555979959666729 seconds)
2022-03-07 21:00:05 | INFO | fairseq_cli.train | end of epoch 841 (average epoch stats below)
2022-03-07 21:00:05 | INFO | train | epoch 841 | loss 0.651 | nll_loss 0.124 | ppl 1.09 | wps 23256.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 40938 | lr 0.000156292 | gnorm 0.28 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 115055
2022-03-07 21:00:05 | INFO | fairseq.trainer | begin training epoch 842
2022-03-07 21:00:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:02:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:02:16 | INFO | valid | epoch 842 | valid on 'valid' subset | loss 14.271 | nll_loss 14.098 | ppl 17539 | wps 42385.7 | wpb 510.9 | bsz 1 | num_updates 40987 | best_loss 8.318
2022-03-07 21:02:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 842 @ 40987 updates
2022-03-07 21:02:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:02:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:02:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 842 @ 40987 updates, score 14.271) (writing took 2.5771133434027433 seconds)
2022-03-07 21:02:18 | INFO | fairseq_cli.train | end of epoch 842 (average epoch stats below)
2022-03-07 21:02:18 | INFO | train | epoch 842 | loss 0.65 | nll_loss 0.124 | ppl 1.09 | wps 23770.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 40987 | lr 0.000156199 | gnorm 0.279 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 115189
2022-03-07 21:02:18 | INFO | fairseq.trainer | begin training epoch 843
2022-03-07 21:02:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:02:52 | INFO | train_inner | epoch 843:     13 / 49 loss=0.65, nll_loss=0.124, ppl=1.09, wps=23571.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=41000, lr=0.000156174, gnorm=0.28, loss_scale=64, train_wall=235, gb_free=8.8, wall=115223
2022-03-07 21:04:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:04:30 | INFO | valid | epoch 843 | valid on 'valid' subset | loss 14.221 | nll_loss 14.047 | ppl 16924.7 | wps 42156.9 | wpb 510.9 | bsz 1 | num_updates 41036 | best_loss 8.318
2022-03-07 21:04:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 843 @ 41036 updates
2022-03-07 21:04:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:04:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:04:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 843 @ 41036 updates, score 14.221) (writing took 2.523996302857995 seconds)
2022-03-07 21:04:32 | INFO | fairseq_cli.train | end of epoch 843 (average epoch stats below)
2022-03-07 21:04:33 | INFO | train | epoch 843 | loss 0.651 | nll_loss 0.124 | ppl 1.09 | wps 23684.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 41036 | lr 0.000156105 | gnorm 0.281 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 115323
2022-03-07 21:04:33 | INFO | fairseq.trainer | begin training epoch 844
2022-03-07 21:04:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:04:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:06:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:06:44 | INFO | valid | epoch 844 | valid on 'valid' subset | loss 14.226 | nll_loss 14.052 | ppl 16981.6 | wps 42473.8 | wpb 510.9 | bsz 1 | num_updates 41084 | best_loss 8.318
2022-03-07 21:06:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 844 @ 41084 updates
2022-03-07 21:06:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:06:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:06:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 844 @ 41084 updates, score 14.226) (writing took 2.5947739724069834 seconds)
2022-03-07 21:06:47 | INFO | fairseq_cli.train | end of epoch 844 (average epoch stats below)
2022-03-07 21:06:47 | INFO | train | epoch 844 | loss 0.65 | nll_loss 0.124 | ppl 1.09 | wps 23220.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 41084 | lr 0.000156014 | gnorm 0.279 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 115457
2022-03-07 21:06:47 | INFO | fairseq.trainer | begin training epoch 845
2022-03-07 21:06:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:07:28 | INFO | train_inner | epoch 845:     16 / 49 loss=0.65, nll_loss=0.124, ppl=1.09, wps=23492.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=41100, lr=0.000155984, gnorm=0.28, loss_scale=64, train_wall=236, gb_free=8.8, wall=115499
2022-03-07 21:08:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:08:58 | INFO | valid | epoch 845 | valid on 'valid' subset | loss 14.33 | nll_loss 14.157 | ppl 18268.9 | wps 42842.3 | wpb 510.9 | bsz 1 | num_updates 41133 | best_loss 8.318
2022-03-07 21:08:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 845 @ 41133 updates
2022-03-07 21:08:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:09:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:09:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 845 @ 41133 updates, score 14.33) (writing took 2.5338788870722055 seconds)
2022-03-07 21:09:01 | INFO | fairseq_cli.train | end of epoch 845 (average epoch stats below)
2022-03-07 21:09:01 | INFO | train | epoch 845 | loss 0.65 | nll_loss 0.124 | ppl 1.09 | wps 23707.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 41133 | lr 0.000155921 | gnorm 0.281 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 115591
2022-03-07 21:09:01 | INFO | fairseq.trainer | begin training epoch 846
2022-03-07 21:09:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:10:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:11:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:11:09 | INFO | valid | epoch 846 | valid on 'valid' subset | loss 14.251 | nll_loss 14.078 | ppl 17292.9 | wps 45745.1 | wpb 510.9 | bsz 1 | num_updates 41181 | best_loss 8.318
2022-03-07 21:11:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 846 @ 41181 updates
2022-03-07 21:11:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:11:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:11:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 846 @ 41181 updates, score 14.251) (writing took 2.570364370942116 seconds)
2022-03-07 21:11:12 | INFO | fairseq_cli.train | end of epoch 846 (average epoch stats below)
2022-03-07 21:11:12 | INFO | train | epoch 846 | loss 0.65 | nll_loss 0.124 | ppl 1.09 | wps 23744.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 41181 | lr 0.00015583 | gnorm 0.278 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 115722
2022-03-07 21:11:12 | INFO | fairseq.trainer | begin training epoch 847
2022-03-07 21:11:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:12:01 | INFO | train_inner | epoch 847:     19 / 49 loss=0.65, nll_loss=0.124, ppl=1.09, wps=23773, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=41200, lr=0.000155794, gnorm=0.278, loss_scale=64, train_wall=233, gb_free=8.8, wall=115772
2022-03-07 21:13:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:13:23 | INFO | valid | epoch 847 | valid on 'valid' subset | loss 14.324 | nll_loss 14.152 | ppl 18202.1 | wps 42622.5 | wpb 510.9 | bsz 1 | num_updates 41230 | best_loss 8.318
2022-03-07 21:13:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 847 @ 41230 updates
2022-03-07 21:13:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:13:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:13:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 847 @ 41230 updates, score 14.324) (writing took 2.5467476304620504 seconds)
2022-03-07 21:13:26 | INFO | fairseq_cli.train | end of epoch 847 (average epoch stats below)
2022-03-07 21:13:26 | INFO | train | epoch 847 | loss 0.65 | nll_loss 0.124 | ppl 1.09 | wps 23702.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 41230 | lr 0.000155738 | gnorm 0.28 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 115856
2022-03-07 21:13:26 | INFO | fairseq.trainer | begin training epoch 848
2022-03-07 21:13:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:15:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:15:37 | INFO | valid | epoch 848 | valid on 'valid' subset | loss 14.258 | nll_loss 14.085 | ppl 17374.9 | wps 42554.1 | wpb 510.9 | bsz 1 | num_updates 41279 | best_loss 8.318
2022-03-07 21:15:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 848 @ 41279 updates
2022-03-07 21:15:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:15:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:15:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 848 @ 41279 updates, score 14.258) (writing took 2.616721235215664 seconds)
2022-03-07 21:15:40 | INFO | fairseq_cli.train | end of epoch 848 (average epoch stats below)
2022-03-07 21:15:40 | INFO | train | epoch 848 | loss 0.65 | nll_loss 0.124 | ppl 1.09 | wps 23674.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 41279 | lr 0.000155645 | gnorm 0.281 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 115990
2022-03-07 21:15:40 | INFO | fairseq.trainer | begin training epoch 849
2022-03-07 21:15:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:16:34 | INFO | train_inner | epoch 849:     21 / 49 loss=0.65, nll_loss=0.124, ppl=1.09, wps=23753.6, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=41300, lr=0.000155606, gnorm=0.281, loss_scale=64, train_wall=233, gb_free=8.8, wall=116045
2022-03-07 21:16:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:17:50 | INFO | valid | epoch 849 | valid on 'valid' subset | loss 14.249 | nll_loss 14.076 | ppl 17270.2 | wps 42344 | wpb 510.9 | bsz 1 | num_updates 41327 | best_loss 8.318
2022-03-07 21:17:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 849 @ 41327 updates
2022-03-07 21:17:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:17:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 849 @ 41327 updates, score 14.249) (writing took 2.582385193556547 seconds)
2022-03-07 21:17:53 | INFO | fairseq_cli.train | end of epoch 849 (average epoch stats below)
2022-03-07 21:17:53 | INFO | train | epoch 849 | loss 0.649 | nll_loss 0.123 | ppl 1.09 | wps 23465.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 41327 | lr 0.000155555 | gnorm 0.281 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 116123
2022-03-07 21:17:53 | INFO | fairseq.trainer | begin training epoch 850
2022-03-07 21:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:19:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:20:04 | INFO | valid | epoch 850 | valid on 'valid' subset | loss 14.206 | nll_loss 14.032 | ppl 16757.1 | wps 42615.9 | wpb 510.9 | bsz 1 | num_updates 41376 | best_loss 8.318
2022-03-07 21:20:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 850 @ 41376 updates
2022-03-07 21:20:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:20:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:20:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 850 @ 41376 updates, score 14.206) (writing took 2.4751528836786747 seconds)
2022-03-07 21:20:07 | INFO | fairseq_cli.train | end of epoch 850 (average epoch stats below)
2022-03-07 21:20:07 | INFO | train | epoch 850 | loss 0.649 | nll_loss 0.124 | ppl 1.09 | wps 23722.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 41376 | lr 0.000155463 | gnorm 0.278 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 116257
2022-03-07 21:20:07 | INFO | fairseq.trainer | begin training epoch 851
2022-03-07 21:20:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:21:09 | INFO | train_inner | epoch 851:     24 / 49 loss=0.649, nll_loss=0.124, ppl=1.09, wps=23595.6, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=41400, lr=0.000155417, gnorm=0.278, loss_scale=64, train_wall=235, gb_free=8.8, wall=116320
2022-03-07 21:22:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:22:18 | INFO | valid | epoch 851 | valid on 'valid' subset | loss 14.193 | nll_loss 14.019 | ppl 16602.1 | wps 42680.7 | wpb 510.9 | bsz 1 | num_updates 41425 | best_loss 8.318
2022-03-07 21:22:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 851 @ 41425 updates
2022-03-07 21:22:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:22:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:22:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 851 @ 41425 updates, score 14.193) (writing took 2.6279586013406515 seconds)
2022-03-07 21:22:21 | INFO | fairseq_cli.train | end of epoch 851 (average epoch stats below)
2022-03-07 21:22:21 | INFO | train | epoch 851 | loss 0.649 | nll_loss 0.123 | ppl 1.09 | wps 23698 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 41425 | lr 0.000155371 | gnorm 0.279 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 116391
2022-03-07 21:22:21 | INFO | fairseq.trainer | begin training epoch 852
2022-03-07 21:22:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:22:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:24:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:24:30 | INFO | valid | epoch 852 | valid on 'valid' subset | loss 14.314 | nll_loss 14.141 | ppl 18072.1 | wps 46549.5 | wpb 510.9 | bsz 1 | num_updates 41473 | best_loss 8.318
2022-03-07 21:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 852 @ 41473 updates
2022-03-07 21:24:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:24:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:24:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 852 @ 41473 updates, score 14.314) (writing took 2.5142867621034384 seconds)
2022-03-07 21:24:33 | INFO | fairseq_cli.train | end of epoch 852 (average epoch stats below)
2022-03-07 21:24:33 | INFO | train | epoch 852 | loss 0.649 | nll_loss 0.123 | ppl 1.09 | wps 23558.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 41473 | lr 0.000155281 | gnorm 0.28 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 116523
2022-03-07 21:24:33 | INFO | fairseq.trainer | begin training epoch 853
2022-03-07 21:24:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:25:40 | INFO | train_inner | epoch 853:     27 / 49 loss=0.649, nll_loss=0.123, ppl=1.09, wps=23926.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=41500, lr=0.00015523, gnorm=0.279, loss_scale=64, train_wall=231, gb_free=8.8, wall=116591
2022-03-07 21:26:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:26:40 | INFO | valid | epoch 853 | valid on 'valid' subset | loss 14.176 | nll_loss 14.002 | ppl 16410 | wps 44514.2 | wpb 510.9 | bsz 1 | num_updates 41522 | best_loss 8.318
2022-03-07 21:26:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 853 @ 41522 updates
2022-03-07 21:26:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:26:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:26:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 853 @ 41522 updates, score 14.176) (writing took 2.5544123370200396 seconds)
2022-03-07 21:26:43 | INFO | fairseq_cli.train | end of epoch 853 (average epoch stats below)
2022-03-07 21:26:43 | INFO | train | epoch 853 | loss 0.649 | nll_loss 0.123 | ppl 1.09 | wps 24447.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41522 | lr 0.000155189 | gnorm 0.278 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 116653
2022-03-07 21:26:43 | INFO | fairseq.trainer | begin training epoch 854
2022-03-07 21:26:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:28:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:28:52 | INFO | valid | epoch 854 | valid on 'valid' subset | loss 14.255 | nll_loss 14.083 | ppl 17348.8 | wps 44308.6 | wpb 510.9 | bsz 1 | num_updates 41570 | best_loss 8.318
2022-03-07 21:28:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 854 @ 41570 updates
2022-03-07 21:28:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:28:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:28:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 854 @ 41570 updates, score 14.255) (writing took 2.590874258428812 seconds)
2022-03-07 21:28:55 | INFO | fairseq_cli.train | end of epoch 854 (average epoch stats below)
2022-03-07 21:28:55 | INFO | train | epoch 854 | loss 0.649 | nll_loss 0.123 | ppl 1.09 | wps 23542.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 41570 | lr 0.000155099 | gnorm 0.284 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 116785
2022-03-07 21:28:55 | INFO | fairseq.trainer | begin training epoch 855
2022-03-07 21:28:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:30:12 | INFO | train_inner | epoch 855:     30 / 49 loss=0.649, nll_loss=0.123, ppl=1.09, wps=23867.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=41600, lr=0.000155043, gnorm=0.282, loss_scale=64, train_wall=232, gb_free=8.8, wall=116862
2022-03-07 21:31:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:31:05 | INFO | valid | epoch 855 | valid on 'valid' subset | loss 14.257 | nll_loss 14.083 | ppl 17358.1 | wps 43823.2 | wpb 510.9 | bsz 1 | num_updates 41619 | best_loss 8.318
2022-03-07 21:31:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 855 @ 41619 updates
2022-03-07 21:31:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:31:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:31:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 855 @ 41619 updates, score 14.257) (writing took 2.5803596302866936 seconds)
2022-03-07 21:31:07 | INFO | fairseq_cli.train | end of epoch 855 (average epoch stats below)
2022-03-07 21:31:07 | INFO | train | epoch 855 | loss 0.649 | nll_loss 0.123 | ppl 1.09 | wps 24034.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 41619 | lr 0.000155008 | gnorm 0.28 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 116918
2022-03-07 21:31:07 | INFO | fairseq.trainer | begin training epoch 856
2022-03-07 21:31:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:33:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:33:17 | INFO | valid | epoch 856 | valid on 'valid' subset | loss 14.271 | nll_loss 14.098 | ppl 17531.4 | wps 43892.6 | wpb 510.9 | bsz 1 | num_updates 41668 | best_loss 8.318
2022-03-07 21:33:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 856 @ 41668 updates
2022-03-07 21:33:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:33:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:33:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 856 @ 41668 updates, score 14.271) (writing took 2.4793142899870872 seconds)
2022-03-07 21:33:20 | INFO | fairseq_cli.train | end of epoch 856 (average epoch stats below)
2022-03-07 21:33:20 | INFO | train | epoch 856 | loss 0.649 | nll_loss 0.123 | ppl 1.09 | wps 24016 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 41668 | lr 0.000154917 | gnorm 0.279 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 117050
2022-03-07 21:33:20 | INFO | fairseq.trainer | begin training epoch 857
2022-03-07 21:33:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:34:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:34:45 | INFO | train_inner | epoch 857:     33 / 49 loss=0.649, nll_loss=0.123, ppl=1.09, wps=23823.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=41700, lr=0.000154857, gnorm=0.278, loss_scale=64, train_wall=232, gb_free=8.8, wall=117135
2022-03-07 21:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:35:29 | INFO | valid | epoch 857 | valid on 'valid' subset | loss 14.258 | nll_loss 14.086 | ppl 17395.1 | wps 44052.5 | wpb 510.9 | bsz 1 | num_updates 41716 | best_loss 8.318
2022-03-07 21:35:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 857 @ 41716 updates
2022-03-07 21:35:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:35:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:35:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 857 @ 41716 updates, score 14.258) (writing took 2.536772698163986 seconds)
2022-03-07 21:35:32 | INFO | fairseq_cli.train | end of epoch 857 (average epoch stats below)
2022-03-07 21:35:32 | INFO | train | epoch 857 | loss 0.649 | nll_loss 0.123 | ppl 1.09 | wps 23527 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 41716 | lr 0.000154828 | gnorm 0.277 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 117182
2022-03-07 21:35:32 | INFO | fairseq.trainer | begin training epoch 858
2022-03-07 21:35:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:37:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:37:42 | INFO | valid | epoch 858 | valid on 'valid' subset | loss 14.256 | nll_loss 14.084 | ppl 17362.1 | wps 44712.8 | wpb 510.9 | bsz 1 | num_updates 41765 | best_loss 8.318
2022-03-07 21:37:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 858 @ 41765 updates
2022-03-07 21:37:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:37:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:37:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 858 @ 41765 updates, score 14.256) (writing took 2.5435493495315313 seconds)
2022-03-07 21:37:44 | INFO | fairseq_cli.train | end of epoch 858 (average epoch stats below)
2022-03-07 21:37:44 | INFO | train | epoch 858 | loss 0.649 | nll_loss 0.123 | ppl 1.09 | wps 24043 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 41765 | lr 0.000154737 | gnorm 0.276 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 117314
2022-03-07 21:37:44 | INFO | fairseq.trainer | begin training epoch 859
2022-03-07 21:37:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:39:13 | INFO | train_inner | epoch 859:     35 / 49 loss=0.649, nll_loss=0.123, ppl=1.09, wps=24170.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=41800, lr=0.000154672, gnorm=0.277, loss_scale=64, train_wall=229, gb_free=8.8, wall=117403
2022-03-07 21:39:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:39:51 | INFO | valid | epoch 859 | valid on 'valid' subset | loss 14.158 | nll_loss 13.983 | ppl 16192.7 | wps 46667.4 | wpb 510.9 | bsz 1 | num_updates 41814 | best_loss 8.318
2022-03-07 21:39:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 859 @ 41814 updates
2022-03-07 21:39:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:39:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:39:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 859 @ 41814 updates, score 14.158) (writing took 2.4826539363712072 seconds)
2022-03-07 21:39:54 | INFO | fairseq_cli.train | end of epoch 859 (average epoch stats below)
2022-03-07 21:39:54 | INFO | train | epoch 859 | loss 0.649 | nll_loss 0.123 | ppl 1.09 | wps 24481.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41814 | lr 0.000154646 | gnorm 0.279 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 117444
2022-03-07 21:39:54 | INFO | fairseq.trainer | begin training epoch 860
2022-03-07 21:39:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:40:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:41:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:42:00 | INFO | valid | epoch 860 | valid on 'valid' subset | loss 14.335 | nll_loss 14.164 | ppl 18360.2 | wps 46444.2 | wpb 510.9 | bsz 1 | num_updates 41862 | best_loss 8.318
2022-03-07 21:42:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 860 @ 41862 updates
2022-03-07 21:42:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:42:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:42:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 860 @ 41862 updates, score 14.335) (writing took 2.551834262907505 seconds)
2022-03-07 21:42:02 | INFO | fairseq_cli.train | end of epoch 860 (average epoch stats below)
2022-03-07 21:42:02 | INFO | train | epoch 860 | loss 0.648 | nll_loss 0.123 | ppl 1.09 | wps 24211.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 41862 | lr 0.000154557 | gnorm 0.282 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 117573
2022-03-07 21:42:02 | INFO | fairseq.trainer | begin training epoch 861
2022-03-07 21:42:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:43:38 | INFO | train_inner | epoch 861:     38 / 49 loss=0.648, nll_loss=0.123, ppl=1.09, wps=24513.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41900, lr=0.000154487, gnorm=0.279, loss_scale=64, train_wall=226, gb_free=8.8, wall=117668
2022-03-07 21:44:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:44:09 | INFO | valid | epoch 861 | valid on 'valid' subset | loss 14.283 | nll_loss 14.112 | ppl 17702 | wps 45384.4 | wpb 510.9 | bsz 1 | num_updates 41911 | best_loss 8.318
2022-03-07 21:44:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 861 @ 41911 updates
2022-03-07 21:44:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:44:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:44:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 861 @ 41911 updates, score 14.283) (writing took 2.5022790990769863 seconds)
2022-03-07 21:44:11 | INFO | fairseq_cli.train | end of epoch 861 (average epoch stats below)
2022-03-07 21:44:11 | INFO | train | epoch 861 | loss 0.648 | nll_loss 0.122 | ppl 1.09 | wps 24699.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41911 | lr 0.000154467 | gnorm 0.276 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 117701
2022-03-07 21:44:11 | INFO | fairseq.trainer | begin training epoch 862
2022-03-07 21:44:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:45:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:46:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:46:17 | INFO | valid | epoch 862 | valid on 'valid' subset | loss 14.293 | nll_loss 14.123 | ppl 17839.2 | wps 45664.4 | wpb 510.9 | bsz 1 | num_updates 41959 | best_loss 8.318
2022-03-07 21:46:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 862 @ 41959 updates
2022-03-07 21:46:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:46:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:46:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 862 @ 41959 updates, score 14.293) (writing took 2.5370334181934595 seconds)
2022-03-07 21:46:20 | INFO | fairseq_cli.train | end of epoch 862 (average epoch stats below)
2022-03-07 21:46:20 | INFO | train | epoch 862 | loss 0.648 | nll_loss 0.122 | ppl 1.09 | wps 24188.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 41959 | lr 0.000154379 | gnorm 0.279 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 117830
2022-03-07 21:46:20 | INFO | fairseq.trainer | begin training epoch 863
2022-03-07 21:46:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:47:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:48:05 | INFO | train_inner | epoch 863:     42 / 49 loss=0.648, nll_loss=0.123, ppl=1.09, wps=24269.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=42000, lr=0.000154303, gnorm=0.278, loss_scale=32, train_wall=228, gb_free=8.8, wall=117935
2022-03-07 21:48:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:48:26 | INFO | valid | epoch 863 | valid on 'valid' subset | loss 14.255 | nll_loss 14.083 | ppl 17353.4 | wps 46300.9 | wpb 510.9 | bsz 1 | num_updates 42007 | best_loss 8.318
2022-03-07 21:48:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 863 @ 42007 updates
2022-03-07 21:48:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:48:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:48:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 863 @ 42007 updates, score 14.255) (writing took 2.5253417156636715 seconds)
2022-03-07 21:48:28 | INFO | fairseq_cli.train | end of epoch 863 (average epoch stats below)
2022-03-07 21:48:28 | INFO | train | epoch 863 | loss 0.648 | nll_loss 0.122 | ppl 1.09 | wps 24210.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 42007 | lr 0.00015429 | gnorm 0.279 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 117959
2022-03-07 21:48:28 | INFO | fairseq.trainer | begin training epoch 864
2022-03-07 21:48:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:50:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:50:34 | INFO | valid | epoch 864 | valid on 'valid' subset | loss 14.239 | nll_loss 14.065 | ppl 17140.2 | wps 46515.3 | wpb 510.9 | bsz 1 | num_updates 42056 | best_loss 8.318
2022-03-07 21:50:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 864 @ 42056 updates
2022-03-07 21:50:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:50:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:50:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 864 @ 42056 updates, score 14.239) (writing took 2.5692186448723078 seconds)
2022-03-07 21:50:37 | INFO | fairseq_cli.train | end of epoch 864 (average epoch stats below)
2022-03-07 21:50:37 | INFO | train | epoch 864 | loss 0.649 | nll_loss 0.123 | ppl 1.09 | wps 24703.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42056 | lr 0.000154201 | gnorm 0.278 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 118087
2022-03-07 21:50:37 | INFO | fairseq.trainer | begin training epoch 865
2022-03-07 21:50:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:52:27 | INFO | train_inner | epoch 865:     44 / 49 loss=0.648, nll_loss=0.123, ppl=1.09, wps=24736.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42100, lr=0.00015412, gnorm=0.278, loss_scale=32, train_wall=223, gb_free=8.8, wall=118197
2022-03-07 21:52:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:52:44 | INFO | valid | epoch 865 | valid on 'valid' subset | loss 14.302 | nll_loss 14.131 | ppl 17944.5 | wps 43475.8 | wpb 510.9 | bsz 1 | num_updates 42105 | best_loss 8.318
2022-03-07 21:52:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 865 @ 42105 updates
2022-03-07 21:52:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:52:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:52:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 865 @ 42105 updates, score 14.302) (writing took 2.46983833424747 seconds)
2022-03-07 21:52:46 | INFO | fairseq_cli.train | end of epoch 865 (average epoch stats below)
2022-03-07 21:52:46 | INFO | train | epoch 865 | loss 0.648 | nll_loss 0.122 | ppl 1.09 | wps 24574.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42105 | lr 0.000154111 | gnorm 0.278 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 118217
2022-03-07 21:52:46 | INFO | fairseq.trainer | begin training epoch 866
2022-03-07 21:52:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:54:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:54:58 | INFO | valid | epoch 866 | valid on 'valid' subset | loss 14.24 | nll_loss 14.067 | ppl 17163.2 | wps 42406.2 | wpb 510.9 | bsz 1 | num_updates 42154 | best_loss 8.318
2022-03-07 21:54:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 866 @ 42154 updates
2022-03-07 21:54:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:55:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:55:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 866 @ 42154 updates, score 14.24) (writing took 2.480457004159689 seconds)
2022-03-07 21:55:00 | INFO | fairseq_cli.train | end of epoch 866 (average epoch stats below)
2022-03-07 21:55:00 | INFO | train | epoch 866 | loss 0.648 | nll_loss 0.122 | ppl 1.09 | wps 23710.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 42154 | lr 0.000154021 | gnorm 0.278 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 118351
2022-03-07 21:55:00 | INFO | fairseq.trainer | begin training epoch 867
2022-03-07 21:55:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:57:00 | INFO | train_inner | epoch 867:     46 / 49 loss=0.648, nll_loss=0.122, ppl=1.09, wps=23760.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=42200, lr=0.000153937, gnorm=0.279, loss_scale=64, train_wall=233, gb_free=8.8, wall=118470
2022-03-07 21:57:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:57:12 | INFO | valid | epoch 867 | valid on 'valid' subset | loss 14.295 | nll_loss 14.122 | ppl 17831.9 | wps 42036.4 | wpb 510.9 | bsz 1 | num_updates 42203 | best_loss 8.318
2022-03-07 21:57:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 867 @ 42203 updates
2022-03-07 21:57:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:57:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:57:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 867 @ 42203 updates, score 14.295) (writing took 2.4498903919011354 seconds)
2022-03-07 21:57:14 | INFO | fairseq_cli.train | end of epoch 867 (average epoch stats below)
2022-03-07 21:57:14 | INFO | train | epoch 867 | loss 0.648 | nll_loss 0.123 | ppl 1.09 | wps 23721.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 42203 | lr 0.000153932 | gnorm 0.279 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 118485
2022-03-07 21:57:14 | INFO | fairseq.trainer | begin training epoch 868
2022-03-07 21:57:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:59:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:59:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:59:21 | INFO | valid | epoch 868 | valid on 'valid' subset | loss 14.213 | nll_loss 14.039 | ppl 16838.2 | wps 46504.6 | wpb 510.9 | bsz 1 | num_updates 42251 | best_loss 8.318
2022-03-07 21:59:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 868 @ 42251 updates
2022-03-07 21:59:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:59:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:59:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 868 @ 42251 updates, score 14.213) (writing took 2.510232148692012 seconds)
2022-03-07 21:59:24 | INFO | fairseq_cli.train | end of epoch 868 (average epoch stats below)
2022-03-07 21:59:24 | INFO | train | epoch 868 | loss 0.647 | nll_loss 0.122 | ppl 1.09 | wps 24025.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 42251 | lr 0.000153844 | gnorm 0.275 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 118614
2022-03-07 21:59:24 | INFO | fairseq.trainer | begin training epoch 869
2022-03-07 21:59:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:01:26 | INFO | train_inner | epoch 869:     49 / 49 loss=0.647, nll_loss=0.122, ppl=1.09, wps=24275.3, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=42300, lr=0.000153755, gnorm=0.277, loss_scale=64, train_wall=227, gb_free=8.8, wall=118736
2022-03-07 22:01:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:01:31 | INFO | valid | epoch 869 | valid on 'valid' subset | loss 14.253 | nll_loss 14.08 | ppl 17322.6 | wps 46107.9 | wpb 510.9 | bsz 1 | num_updates 42300 | best_loss 8.318
2022-03-07 22:01:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 869 @ 42300 updates
2022-03-07 22:01:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:01:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:01:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 869 @ 42300 updates, score 14.253) (writing took 2.5017967633903027 seconds)
2022-03-07 22:01:33 | INFO | fairseq_cli.train | end of epoch 869 (average epoch stats below)
2022-03-07 22:01:33 | INFO | train | epoch 869 | loss 0.648 | nll_loss 0.122 | ppl 1.09 | wps 24554.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42300 | lr 0.000153755 | gnorm 0.278 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 118744
2022-03-07 22:01:33 | INFO | fairseq.trainer | begin training epoch 870
2022-03-07 22:01:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:03:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:03:40 | INFO | valid | epoch 870 | valid on 'valid' subset | loss 14.254 | nll_loss 14.082 | ppl 17340 | wps 42545.6 | wpb 510.9 | bsz 1 | num_updates 42349 | best_loss 8.318
2022-03-07 22:03:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 870 @ 42349 updates
2022-03-07 22:03:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:03:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:03:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 870 @ 42349 updates, score 14.254) (writing took 2.5516527127474546 seconds)
2022-03-07 22:03:43 | INFO | fairseq_cli.train | end of epoch 870 (average epoch stats below)
2022-03-07 22:03:43 | INFO | train | epoch 870 | loss 0.647 | nll_loss 0.122 | ppl 1.09 | wps 24555.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42349 | lr 0.000153666 | gnorm 0.278 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 118873
2022-03-07 22:03:43 | INFO | fairseq.trainer | begin training epoch 871
2022-03-07 22:03:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:04:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:05:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:05:49 | INFO | valid | epoch 871 | valid on 'valid' subset | loss 14.306 | nll_loss 14.134 | ppl 17983.5 | wps 46748 | wpb 510.9 | bsz 1 | num_updates 42397 | best_loss 8.318
2022-03-07 22:05:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 871 @ 42397 updates
2022-03-07 22:05:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:05:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:05:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 871 @ 42397 updates, score 14.306) (writing took 2.515335252508521 seconds)
2022-03-07 22:05:52 | INFO | fairseq_cli.train | end of epoch 871 (average epoch stats below)
2022-03-07 22:05:52 | INFO | train | epoch 871 | loss 0.647 | nll_loss 0.122 | ppl 1.09 | wps 24083.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 42397 | lr 0.000153579 | gnorm 0.278 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 119002
2022-03-07 22:05:52 | INFO | fairseq.trainer | begin training epoch 872
2022-03-07 22:05:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:06:00 | INFO | train_inner | epoch 872:      3 / 49 loss=0.647, nll_loss=0.122, ppl=1.09, wps=23712.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=42400, lr=0.000153574, gnorm=0.278, loss_scale=64, train_wall=227, gb_free=8.8, wall=119010
2022-03-07 22:07:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:08:00 | INFO | valid | epoch 872 | valid on 'valid' subset | loss 14.256 | nll_loss 14.085 | ppl 17378.9 | wps 42365.9 | wpb 510.9 | bsz 1 | num_updates 42446 | best_loss 8.318
2022-03-07 22:08:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 872 @ 42446 updates
2022-03-07 22:08:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:08:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:08:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 872 @ 42446 updates, score 14.256) (writing took 2.4704722557216883 seconds)
2022-03-07 22:08:02 | INFO | fairseq_cli.train | end of epoch 872 (average epoch stats below)
2022-03-07 22:08:02 | INFO | train | epoch 872 | loss 0.647 | nll_loss 0.122 | ppl 1.09 | wps 24374.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42446 | lr 0.000153491 | gnorm 0.277 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 119133
2022-03-07 22:08:02 | INFO | fairseq.trainer | begin training epoch 873
2022-03-07 22:08:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:10:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:10:14 | INFO | valid | epoch 873 | valid on 'valid' subset | loss 14.203 | nll_loss 14.03 | ppl 16733.4 | wps 43099.7 | wpb 510.9 | bsz 1 | num_updates 42495 | best_loss 8.318
2022-03-07 22:10:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 873 @ 42495 updates
2022-03-07 22:10:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:10:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:10:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 873 @ 42495 updates, score 14.203) (writing took 2.4327530656009912 seconds)
2022-03-07 22:10:16 | INFO | fairseq_cli.train | end of epoch 873 (average epoch stats below)
2022-03-07 22:10:16 | INFO | train | epoch 873 | loss 0.647 | nll_loss 0.122 | ppl 1.09 | wps 23719.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 42495 | lr 0.000153402 | gnorm 0.277 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 119267
2022-03-07 22:10:16 | INFO | fairseq.trainer | begin training epoch 874
2022-03-07 22:10:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:10:29 | INFO | train_inner | epoch 874:      5 / 49 loss=0.647, nll_loss=0.122, ppl=1.09, wps=24040.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=42500, lr=0.000153393, gnorm=0.277, loss_scale=64, train_wall=230, gb_free=8.8, wall=119280
2022-03-07 22:10:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:12:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:12:28 | INFO | valid | epoch 874 | valid on 'valid' subset | loss 14.25 | nll_loss 14.078 | ppl 17295.3 | wps 41706 | wpb 510.9 | bsz 1 | num_updates 42543 | best_loss 8.318
2022-03-07 22:12:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 874 @ 42543 updates
2022-03-07 22:12:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:12:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:12:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 874 @ 42543 updates, score 14.25) (writing took 2.4661886114627123 seconds)
2022-03-07 22:12:30 | INFO | fairseq_cli.train | end of epoch 874 (average epoch stats below)
2022-03-07 22:12:30 | INFO | train | epoch 874 | loss 0.647 | nll_loss 0.122 | ppl 1.09 | wps 23217.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 42543 | lr 0.000153315 | gnorm 0.275 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 119401
2022-03-07 22:12:30 | INFO | fairseq.trainer | begin training epoch 875
2022-03-07 22:12:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:14:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:14:38 | INFO | valid | epoch 875 | valid on 'valid' subset | loss 14.24 | nll_loss 14.067 | ppl 17160.9 | wps 43018.1 | wpb 510.9 | bsz 1 | num_updates 42592 | best_loss 8.318
2022-03-07 22:14:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 875 @ 42592 updates
2022-03-07 22:14:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:14:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:14:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 875 @ 42592 updates, score 14.24) (writing took 2.599485944956541 seconds)
2022-03-07 22:14:40 | INFO | fairseq_cli.train | end of epoch 875 (average epoch stats below)
2022-03-07 22:14:40 | INFO | train | epoch 875 | loss 0.646 | nll_loss 0.121 | ppl 1.09 | wps 24440.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42592 | lr 0.000153227 | gnorm 0.275 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 119531
2022-03-07 22:14:40 | INFO | fairseq.trainer | begin training epoch 876
2022-03-07 22:14:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:15:01 | INFO | train_inner | epoch 876:      8 / 49 loss=0.647, nll_loss=0.122, ppl=1.09, wps=23863.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=42600, lr=0.000153213, gnorm=0.275, loss_scale=64, train_wall=232, gb_free=8.8, wall=119552
2022-03-07 22:16:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:16:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:16:52 | INFO | valid | epoch 876 | valid on 'valid' subset | loss 14.232 | nll_loss 14.06 | ppl 17076.7 | wps 42917.5 | wpb 510.9 | bsz 1 | num_updates 42640 | best_loss 8.318
2022-03-07 22:16:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 876 @ 42640 updates
2022-03-07 22:16:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:16:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:16:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 876 @ 42640 updates, score 14.232) (writing took 2.563377469778061 seconds)
2022-03-07 22:16:55 | INFO | fairseq_cli.train | end of epoch 876 (average epoch stats below)
2022-03-07 22:16:55 | INFO | train | epoch 876 | loss 0.647 | nll_loss 0.122 | ppl 1.09 | wps 23199.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 42640 | lr 0.000153141 | gnorm 0.276 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 119665
2022-03-07 22:16:55 | INFO | fairseq.trainer | begin training epoch 877
2022-03-07 22:16:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:19:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:19:06 | INFO | valid | epoch 877 | valid on 'valid' subset | loss 14.301 | nll_loss 14.132 | ppl 17949.2 | wps 42816.6 | wpb 510.9 | bsz 1 | num_updates 42689 | best_loss 8.318
2022-03-07 22:19:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 877 @ 42689 updates
2022-03-07 22:19:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:19:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:19:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 877 @ 42689 updates, score 14.301) (writing took 2.5770586114376783 seconds)
2022-03-07 22:19:09 | INFO | fairseq_cli.train | end of epoch 877 (average epoch stats below)
2022-03-07 22:19:09 | INFO | train | epoch 877 | loss 0.647 | nll_loss 0.122 | ppl 1.09 | wps 23655.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 42689 | lr 0.000153053 | gnorm 0.276 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 119799
2022-03-07 22:19:09 | INFO | fairseq.trainer | begin training epoch 878
2022-03-07 22:19:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:19:38 | INFO | train_inner | epoch 878:     11 / 49 loss=0.647, nll_loss=0.122, ppl=1.09, wps=23462.6, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=42700, lr=0.000153033, gnorm=0.276, loss_scale=64, train_wall=236, gb_free=8.8, wall=119828
2022-03-07 22:20:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:21:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:21:20 | INFO | valid | epoch 878 | valid on 'valid' subset | loss 14.296 | nll_loss 14.126 | ppl 17882.3 | wps 42937.3 | wpb 510.9 | bsz 1 | num_updates 42737 | best_loss 8.318
2022-03-07 22:21:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 878 @ 42737 updates
2022-03-07 22:21:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:21:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:21:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 878 @ 42737 updates, score 14.296) (writing took 2.5402578599750996 seconds)
2022-03-07 22:21:23 | INFO | fairseq_cli.train | end of epoch 878 (average epoch stats below)
2022-03-07 22:21:23 | INFO | train | epoch 878 | loss 0.647 | nll_loss 0.122 | ppl 1.09 | wps 23220.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 42737 | lr 0.000152967 | gnorm 0.279 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 119933
2022-03-07 22:21:23 | INFO | fairseq.trainer | begin training epoch 879
2022-03-07 22:21:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:23:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:23:35 | INFO | valid | epoch 879 | valid on 'valid' subset | loss 14.191 | nll_loss 14.018 | ppl 16592 | wps 42298.6 | wpb 510.9 | bsz 1 | num_updates 42786 | best_loss 8.318
2022-03-07 22:23:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 879 @ 42786 updates
2022-03-07 22:23:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:23:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:23:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 879 @ 42786 updates, score 14.191) (writing took 2.479771563783288 seconds)
2022-03-07 22:23:37 | INFO | fairseq_cli.train | end of epoch 879 (average epoch stats below)
2022-03-07 22:23:37 | INFO | train | epoch 879 | loss 0.646 | nll_loss 0.121 | ppl 1.09 | wps 23685.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 42786 | lr 0.000152879 | gnorm 0.274 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 120067
2022-03-07 22:23:37 | INFO | fairseq.trainer | begin training epoch 880
2022-03-07 22:23:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:24:14 | INFO | train_inner | epoch 880:     14 / 49 loss=0.647, nll_loss=0.122, ppl=1.09, wps=23506.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=42800, lr=0.000152854, gnorm=0.276, loss_scale=32, train_wall=235, gb_free=8.8, wall=120104
2022-03-07 22:25:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:25:49 | INFO | valid | epoch 880 | valid on 'valid' subset | loss 14.276 | nll_loss 14.105 | ppl 17625.1 | wps 42818.3 | wpb 510.9 | bsz 1 | num_updates 42835 | best_loss 8.318
2022-03-07 22:25:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 880 @ 42835 updates
2022-03-07 22:25:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:25:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:25:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 880 @ 42835 updates, score 14.276) (writing took 2.440673539415002 seconds)
2022-03-07 22:25:51 | INFO | fairseq_cli.train | end of epoch 880 (average epoch stats below)
2022-03-07 22:25:51 | INFO | train | epoch 880 | loss 0.646 | nll_loss 0.122 | ppl 1.09 | wps 23706 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 42835 | lr 0.000152792 | gnorm 0.276 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 120202
2022-03-07 22:25:51 | INFO | fairseq.trainer | begin training epoch 881
2022-03-07 22:25:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:27:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:28:03 | INFO | valid | epoch 881 | valid on 'valid' subset | loss 14.213 | nll_loss 14.042 | ppl 16862.6 | wps 42726.8 | wpb 510.9 | bsz 1 | num_updates 42884 | best_loss 8.318
2022-03-07 22:28:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 881 @ 42884 updates
2022-03-07 22:28:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:28:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:28:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 881 @ 42884 updates, score 14.213) (writing took 2.4288552589714527 seconds)
2022-03-07 22:28:06 | INFO | fairseq_cli.train | end of epoch 881 (average epoch stats below)
2022-03-07 22:28:06 | INFO | train | epoch 881 | loss 0.646 | nll_loss 0.121 | ppl 1.09 | wps 23649.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 42884 | lr 0.000152705 | gnorm 0.274 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 120336
2022-03-07 22:28:06 | INFO | fairseq.trainer | begin training epoch 882
2022-03-07 22:28:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:28:47 | INFO | train_inner | epoch 882:     16 / 49 loss=0.646, nll_loss=0.121, ppl=1.09, wps=23700.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=42900, lr=0.000152676, gnorm=0.275, loss_scale=64, train_wall=234, gb_free=8.8, wall=120378
2022-03-07 22:30:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:30:18 | INFO | valid | epoch 882 | valid on 'valid' subset | loss 14.26 | nll_loss 14.088 | ppl 17411.4 | wps 41180.5 | wpb 510.9 | bsz 1 | num_updates 42933 | best_loss 8.318
2022-03-07 22:30:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 882 @ 42933 updates
2022-03-07 22:30:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:30:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:30:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 882 @ 42933 updates, score 14.26) (writing took 2.4713669531047344 seconds)
2022-03-07 22:30:21 | INFO | fairseq_cli.train | end of epoch 882 (average epoch stats below)
2022-03-07 22:30:21 | INFO | train | epoch 882 | loss 0.646 | nll_loss 0.121 | ppl 1.09 | wps 23558 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 42933 | lr 0.000152618 | gnorm 0.277 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 120471
2022-03-07 22:30:21 | INFO | fairseq.trainer | begin training epoch 883
2022-03-07 22:30:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:32:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:32:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:32:34 | INFO | valid | epoch 883 | valid on 'valid' subset | loss 14.201 | nll_loss 14.03 | ppl 16730.3 | wps 41444.9 | wpb 510.9 | bsz 1 | num_updates 42981 | best_loss 8.318
2022-03-07 22:32:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 883 @ 42981 updates
2022-03-07 22:32:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:32:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:32:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 883 @ 42981 updates, score 14.201) (writing took 2.4217678513377905 seconds)
2022-03-07 22:32:37 | INFO | fairseq_cli.train | end of epoch 883 (average epoch stats below)
2022-03-07 22:32:37 | INFO | train | epoch 883 | loss 0.646 | nll_loss 0.121 | ppl 1.09 | wps 22884.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 42981 | lr 0.000152532 | gnorm 0.275 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 120607
2022-03-07 22:32:37 | INFO | fairseq.trainer | begin training epoch 884
2022-03-07 22:32:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:33:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:33:29 | INFO | train_inner | epoch 884:     20 / 49 loss=0.646, nll_loss=0.121, ppl=1.09, wps=23013.6, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=43000, lr=0.000152499, gnorm=0.275, loss_scale=32, train_wall=241, gb_free=8.8, wall=120660
2022-03-07 22:34:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:34:49 | INFO | valid | epoch 884 | valid on 'valid' subset | loss 14.162 | nll_loss 13.99 | ppl 16268.9 | wps 42522.7 | wpb 510.9 | bsz 1 | num_updates 43029 | best_loss 8.318
2022-03-07 22:34:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 884 @ 43029 updates
2022-03-07 22:34:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:34:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:34:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 884 @ 43029 updates, score 14.162) (writing took 2.4310262203216553 seconds)
2022-03-07 22:34:52 | INFO | fairseq_cli.train | end of epoch 884 (average epoch stats below)
2022-03-07 22:34:52 | INFO | train | epoch 884 | loss 0.646 | nll_loss 0.121 | ppl 1.09 | wps 23045.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 43029 | lr 0.000152447 | gnorm 0.277 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 120742
2022-03-07 22:34:52 | INFO | fairseq.trainer | begin training epoch 885
2022-03-07 22:34:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:37:03 | INFO | valid | epoch 885 | valid on 'valid' subset | loss 14.14 | nll_loss 13.967 | ppl 16016.3 | wps 42886 | wpb 510.9 | bsz 1 | num_updates 43078 | best_loss 8.318
2022-03-07 22:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 885 @ 43078 updates
2022-03-07 22:37:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:37:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:37:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 885 @ 43078 updates, score 14.14) (writing took 2.4021155647933483 seconds)
2022-03-07 22:37:06 | INFO | fairseq_cli.train | end of epoch 885 (average epoch stats below)
2022-03-07 22:37:06 | INFO | train | epoch 885 | loss 0.645 | nll_loss 0.121 | ppl 1.09 | wps 23705.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 43078 | lr 0.00015236 | gnorm 0.274 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 120876
2022-03-07 22:37:06 | INFO | fairseq.trainer | begin training epoch 886
2022-03-07 22:37:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:38:03 | INFO | train_inner | epoch 886:     22 / 49 loss=0.646, nll_loss=0.121, ppl=1.09, wps=23689.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=43100, lr=0.000152322, gnorm=0.276, loss_scale=32, train_wall=234, gb_free=8.8, wall=120933
2022-03-07 22:39:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:39:17 | INFO | valid | epoch 886 | valid on 'valid' subset | loss 14.236 | nll_loss 14.063 | ppl 17119.6 | wps 42751.3 | wpb 510.9 | bsz 1 | num_updates 43127 | best_loss 8.318
2022-03-07 22:39:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 886 @ 43127 updates
2022-03-07 22:39:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:39:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:39:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 886 @ 43127 updates, score 14.236) (writing took 2.4206879306584597 seconds)
2022-03-07 22:39:20 | INFO | fairseq_cli.train | end of epoch 886 (average epoch stats below)
2022-03-07 22:39:20 | INFO | train | epoch 886 | loss 0.646 | nll_loss 0.121 | ppl 1.09 | wps 23673.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 43127 | lr 0.000152274 | gnorm 0.279 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 121010
2022-03-07 22:39:20 | INFO | fairseq.trainer | begin training epoch 887
2022-03-07 22:39:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:41:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:41:32 | INFO | valid | epoch 887 | valid on 'valid' subset | loss 14.248 | nll_loss 14.076 | ppl 17273.5 | wps 42540.1 | wpb 510.9 | bsz 1 | num_updates 43176 | best_loss 8.318
2022-03-07 22:41:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 887 @ 43176 updates
2022-03-07 22:41:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:41:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:41:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 887 @ 43176 updates, score 14.248) (writing took 2.4421540889889 seconds)
2022-03-07 22:41:34 | INFO | fairseq_cli.train | end of epoch 887 (average epoch stats below)
2022-03-07 22:41:34 | INFO | train | epoch 887 | loss 0.645 | nll_loss 0.121 | ppl 1.09 | wps 23687.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 43176 | lr 0.000152187 | gnorm 0.273 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 121144
2022-03-07 22:41:34 | INFO | fairseq.trainer | begin training epoch 888
2022-03-07 22:41:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:42:37 | INFO | train_inner | epoch 888:     24 / 49 loss=0.645, nll_loss=0.121, ppl=1.09, wps=23706.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=43200, lr=0.000152145, gnorm=0.274, loss_scale=64, train_wall=234, gb_free=8.8, wall=121207
2022-03-07 22:43:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:43:46 | INFO | valid | epoch 888 | valid on 'valid' subset | loss 14.301 | nll_loss 14.131 | ppl 17940 | wps 42113.6 | wpb 510.9 | bsz 1 | num_updates 43225 | best_loss 8.318
2022-03-07 22:43:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 888 @ 43225 updates
2022-03-07 22:43:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:43:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:43:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 888 @ 43225 updates, score 14.301) (writing took 2.403741365298629 seconds)
2022-03-07 22:43:48 | INFO | fairseq_cli.train | end of epoch 888 (average epoch stats below)
2022-03-07 22:43:48 | INFO | train | epoch 888 | loss 0.645 | nll_loss 0.121 | ppl 1.09 | wps 23680.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 43225 | lr 0.000152101 | gnorm 0.275 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 121279
2022-03-07 22:43:48 | INFO | fairseq.trainer | begin training epoch 889
2022-03-07 22:43:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:44:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:45:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:45:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:45:59 | INFO | valid | epoch 889 | valid on 'valid' subset | loss 14.297 | nll_loss 14.126 | ppl 17884.5 | wps 43341.3 | wpb 510.9 | bsz 1 | num_updates 43272 | best_loss 8.318
2022-03-07 22:45:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 889 @ 43272 updates
2022-03-07 22:45:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:46:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:46:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 889 @ 43272 updates, score 14.297) (writing took 2.4625442009419203 seconds)
2022-03-07 22:46:02 | INFO | fairseq_cli.train | end of epoch 889 (average epoch stats below)
2022-03-07 22:46:02 | INFO | train | epoch 889 | loss 0.645 | nll_loss 0.121 | ppl 1.09 | wps 22792.3 | ups 0.35 | wpb 64829.4 | bsz 126.6 | num_updates 43272 | lr 0.000152019 | gnorm 0.279 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 121412
2022-03-07 22:46:02 | INFO | fairseq.trainer | begin training epoch 890
2022-03-07 22:46:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:47:15 | INFO | train_inner | epoch 890:     28 / 49 loss=0.646, nll_loss=0.121, ppl=1.09, wps=23352.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=43300, lr=0.000151969, gnorm=0.278, loss_scale=32, train_wall=237, gb_free=8.8, wall=121485
2022-03-07 22:48:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:48:13 | INFO | valid | epoch 890 | valid on 'valid' subset | loss 14.235 | nll_loss 14.063 | ppl 17110.6 | wps 42221.9 | wpb 510.9 | bsz 1 | num_updates 43321 | best_loss 8.318
2022-03-07 22:48:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 890 @ 43321 updates
2022-03-07 22:48:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:48:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:48:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 890 @ 43321 updates, score 14.235) (writing took 2.414432719349861 seconds)
2022-03-07 22:48:16 | INFO | fairseq_cli.train | end of epoch 890 (average epoch stats below)
2022-03-07 22:48:16 | INFO | train | epoch 890 | loss 0.645 | nll_loss 0.12 | ppl 1.09 | wps 23778.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 43321 | lr 0.000151933 | gnorm 0.276 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 121546
2022-03-07 22:48:16 | INFO | fairseq.trainer | begin training epoch 891
2022-03-07 22:48:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:50:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:50:28 | INFO | valid | epoch 891 | valid on 'valid' subset | loss 14.254 | nll_loss 14.082 | ppl 17338.7 | wps 41940.3 | wpb 510.9 | bsz 1 | num_updates 43370 | best_loss 8.318
2022-03-07 22:50:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 891 @ 43370 updates
2022-03-07 22:50:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:50:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:50:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 891 @ 43370 updates, score 14.254) (writing took 2.4064734242856503 seconds)
2022-03-07 22:50:30 | INFO | fairseq_cli.train | end of epoch 891 (average epoch stats below)
2022-03-07 22:50:30 | INFO | train | epoch 891 | loss 0.645 | nll_loss 0.121 | ppl 1.09 | wps 23599.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 43370 | lr 0.000151847 | gnorm 0.273 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 121681
2022-03-07 22:50:30 | INFO | fairseq.trainer | begin training epoch 892
2022-03-07 22:50:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:51:49 | INFO | train_inner | epoch 892:     30 / 49 loss=0.645, nll_loss=0.12, ppl=1.09, wps=23655.8, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=43400, lr=0.000151794, gnorm=0.273, loss_scale=64, train_wall=234, gb_free=8.8, wall=121759
2022-03-07 22:52:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:52:43 | INFO | valid | epoch 892 | valid on 'valid' subset | loss 14.232 | nll_loss 14.06 | ppl 17080 | wps 42638.1 | wpb 510.9 | bsz 1 | num_updates 43419 | best_loss 8.318
2022-03-07 22:52:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 892 @ 43419 updates
2022-03-07 22:52:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:52:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:52:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 892 @ 43419 updates, score 14.232) (writing took 2.4603396225720644 seconds)
2022-03-07 22:52:45 | INFO | fairseq_cli.train | end of epoch 892 (average epoch stats below)
2022-03-07 22:52:45 | INFO | train | epoch 892 | loss 0.645 | nll_loss 0.12 | ppl 1.09 | wps 23588.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 43419 | lr 0.000151761 | gnorm 0.274 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 121815
2022-03-07 22:52:45 | INFO | fairseq.trainer | begin training epoch 893
2022-03-07 22:52:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:54:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:54:57 | INFO | valid | epoch 893 | valid on 'valid' subset | loss 14.16 | nll_loss 13.986 | ppl 16226.7 | wps 42291.3 | wpb 510.9 | bsz 1 | num_updates 43468 | best_loss 8.318
2022-03-07 22:54:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 893 @ 43468 updates
2022-03-07 22:54:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:54:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:54:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 893 @ 43468 updates, score 14.16) (writing took 2.4119813088327646 seconds)
2022-03-07 22:54:59 | INFO | fairseq_cli.train | end of epoch 893 (average epoch stats below)
2022-03-07 22:54:59 | INFO | train | epoch 893 | loss 0.645 | nll_loss 0.12 | ppl 1.09 | wps 23629.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 43468 | lr 0.000151675 | gnorm 0.275 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 121950
2022-03-07 22:54:59 | INFO | fairseq.trainer | begin training epoch 894
2022-03-07 22:54:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:56:23 | INFO | train_inner | epoch 894:     32 / 49 loss=0.645, nll_loss=0.12, ppl=1.09, wps=23649.2, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=43500, lr=0.00015162, gnorm=0.274, loss_scale=64, train_wall=234, gb_free=8.8, wall=122033
2022-03-07 22:56:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:57:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:57:11 | INFO | valid | epoch 894 | valid on 'valid' subset | loss 14.25 | nll_loss 14.077 | ppl 17285.6 | wps 42723.6 | wpb 510.9 | bsz 1 | num_updates 43516 | best_loss 8.318
2022-03-07 22:57:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 894 @ 43516 updates
2022-03-07 22:57:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:57:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:57:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 894 @ 43516 updates, score 14.25) (writing took 2.4050756450742483 seconds)
2022-03-07 22:57:14 | INFO | fairseq_cli.train | end of epoch 894 (average epoch stats below)
2022-03-07 22:57:14 | INFO | train | epoch 894 | loss 0.645 | nll_loss 0.12 | ppl 1.09 | wps 23169.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 43516 | lr 0.000151592 | gnorm 0.271 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 122084
2022-03-07 22:57:14 | INFO | fairseq.trainer | begin training epoch 895
2022-03-07 22:57:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:59:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:59:25 | INFO | valid | epoch 895 | valid on 'valid' subset | loss 14.296 | nll_loss 14.125 | ppl 17872.3 | wps 42794.3 | wpb 510.9 | bsz 1 | num_updates 43565 | best_loss 8.318
2022-03-07 22:59:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 895 @ 43565 updates
2022-03-07 22:59:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:59:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:59:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 895 @ 43565 updates, score 14.296) (writing took 2.44744173809886 seconds)
2022-03-07 22:59:28 | INFO | fairseq_cli.train | end of epoch 895 (average epoch stats below)
2022-03-07 22:59:28 | INFO | train | epoch 895 | loss 0.644 | nll_loss 0.12 | ppl 1.09 | wps 23728.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 43565 | lr 0.000151506 | gnorm 0.272 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 122218
2022-03-07 22:59:28 | INFO | fairseq.trainer | begin training epoch 896
2022-03-07 22:59:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:00:59 | INFO | train_inner | epoch 896:     35 / 49 loss=0.644, nll_loss=0.12, ppl=1.09, wps=23537.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=43600, lr=0.000151446, gnorm=0.271, loss_scale=64, train_wall=235, gb_free=8.8, wall=122309
2022-03-07 23:01:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:01:39 | INFO | valid | epoch 896 | valid on 'valid' subset | loss 14.248 | nll_loss 14.076 | ppl 17272.9 | wps 43378.7 | wpb 510.9 | bsz 1 | num_updates 43614 | best_loss 8.318
2022-03-07 23:01:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 896 @ 43614 updates
2022-03-07 23:01:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:01:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:01:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 896 @ 43614 updates, score 14.248) (writing took 2.440011663362384 seconds)
2022-03-07 23:01:41 | INFO | fairseq_cli.train | end of epoch 896 (average epoch stats below)
2022-03-07 23:01:41 | INFO | train | epoch 896 | loss 0.644 | nll_loss 0.12 | ppl 1.09 | wps 23792.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 43614 | lr 0.000151421 | gnorm 0.27 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 122352
2022-03-07 23:01:41 | INFO | fairseq.trainer | begin training epoch 897
2022-03-07 23:01:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:02:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:03:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:03:52 | INFO | valid | epoch 897 | valid on 'valid' subset | loss 14.24 | nll_loss 14.068 | ppl 17178.9 | wps 43059.8 | wpb 510.9 | bsz 1 | num_updates 43662 | best_loss 8.318
2022-03-07 23:03:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 897 @ 43662 updates
2022-03-07 23:03:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:03:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:03:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 897 @ 43662 updates, score 14.24) (writing took 2.469197863712907 seconds)
2022-03-07 23:03:55 | INFO | fairseq_cli.train | end of epoch 897 (average epoch stats below)
2022-03-07 23:03:55 | INFO | train | epoch 897 | loss 0.645 | nll_loss 0.121 | ppl 1.09 | wps 23329.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 43662 | lr 0.000151338 | gnorm 0.275 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 122485
2022-03-07 23:03:55 | INFO | fairseq.trainer | begin training epoch 898
2022-03-07 23:03:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:05:33 | INFO | train_inner | epoch 898:     38 / 49 loss=0.645, nll_loss=0.12, ppl=1.09, wps=23622, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=43700, lr=0.000151272, gnorm=0.273, loss_scale=64, train_wall=234, gb_free=8.8, wall=122584
2022-03-07 23:06:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:06:06 | INFO | valid | epoch 898 | valid on 'valid' subset | loss 14.235 | nll_loss 14.063 | ppl 17121.2 | wps 43200.7 | wpb 510.9 | bsz 1 | num_updates 43711 | best_loss 8.318
2022-03-07 23:06:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 898 @ 43711 updates
2022-03-07 23:06:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:06:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:06:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 898 @ 43711 updates, score 14.235) (writing took 2.413696451112628 seconds)
2022-03-07 23:06:08 | INFO | fairseq_cli.train | end of epoch 898 (average epoch stats below)
2022-03-07 23:06:08 | INFO | train | epoch 898 | loss 0.644 | nll_loss 0.12 | ppl 1.09 | wps 23832.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 43711 | lr 0.000151253 | gnorm 0.273 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 122618
2022-03-07 23:06:08 | INFO | fairseq.trainer | begin training epoch 899
2022-03-07 23:06:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:08:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:08:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:08:19 | INFO | valid | epoch 899 | valid on 'valid' subset | loss 14.181 | nll_loss 14.007 | ppl 16466.5 | wps 42989.1 | wpb 510.9 | bsz 1 | num_updates 43759 | best_loss 8.318
2022-03-07 23:08:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 899 @ 43759 updates
2022-03-07 23:08:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:08:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:08:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 899 @ 43759 updates, score 14.181) (writing took 2.423913972452283 seconds)
2022-03-07 23:08:22 | INFO | fairseq_cli.train | end of epoch 899 (average epoch stats below)
2022-03-07 23:08:22 | INFO | train | epoch 899 | loss 0.645 | nll_loss 0.12 | ppl 1.09 | wps 23286 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 43759 | lr 0.00015117 | gnorm 0.277 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 122752
2022-03-07 23:08:22 | INFO | fairseq.trainer | begin training epoch 900
2022-03-07 23:08:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:10:08 | INFO | train_inner | epoch 900:     41 / 49 loss=0.645, nll_loss=0.12, ppl=1.09, wps=23596.4, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=43800, lr=0.000151099, gnorm=0.276, loss_scale=32, train_wall=235, gb_free=8.8, wall=122859
2022-03-07 23:10:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:10:33 | INFO | valid | epoch 900 | valid on 'valid' subset | loss 14.212 | nll_loss 14.039 | ppl 16837 | wps 42996.4 | wpb 510.9 | bsz 1 | num_updates 43808 | best_loss 8.318
2022-03-07 23:10:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 900 @ 43808 updates
2022-03-07 23:10:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:10:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:10:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 900 @ 43808 updates, score 14.212) (writing took 2.414455996826291 seconds)
2022-03-07 23:10:35 | INFO | fairseq_cli.train | end of epoch 900 (average epoch stats below)
2022-03-07 23:10:35 | INFO | train | epoch 900 | loss 0.644 | nll_loss 0.12 | ppl 1.09 | wps 23799.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 43808 | lr 0.000151086 | gnorm 0.274 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 122886
2022-03-07 23:10:35 | INFO | fairseq.trainer | begin training epoch 901
2022-03-07 23:10:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:12:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:12:46 | INFO | valid | epoch 901 | valid on 'valid' subset | loss 14.235 | nll_loss 14.064 | ppl 17125.6 | wps 43012.5 | wpb 510.9 | bsz 1 | num_updates 43857 | best_loss 8.318
2022-03-07 23:12:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 901 @ 43857 updates
2022-03-07 23:12:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:12:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:12:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 901 @ 43857 updates, score 14.235) (writing took 2.464818177744746 seconds)
2022-03-07 23:12:49 | INFO | fairseq_cli.train | end of epoch 901 (average epoch stats below)
2022-03-07 23:12:49 | INFO | train | epoch 901 | loss 0.644 | nll_loss 0.12 | ppl 1.09 | wps 23782.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 43857 | lr 0.000151001 | gnorm 0.273 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 123019
2022-03-07 23:12:49 | INFO | fairseq.trainer | begin training epoch 902
2022-03-07 23:12:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:14:41 | INFO | train_inner | epoch 902:     43 / 49 loss=0.644, nll_loss=0.12, ppl=1.09, wps=23828.5, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=43900, lr=0.000150927, gnorm=0.273, loss_scale=64, train_wall=232, gb_free=8.8, wall=123131
2022-03-07 23:14:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:15:00 | INFO | valid | epoch 902 | valid on 'valid' subset | loss 14.315 | nll_loss 14.145 | ppl 18116 | wps 43198.9 | wpb 510.9 | bsz 1 | num_updates 43906 | best_loss 8.318
2022-03-07 23:15:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 902 @ 43906 updates
2022-03-07 23:15:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:15:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:15:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 902 @ 43906 updates, score 14.315) (writing took 2.4409767612814903 seconds)
2022-03-07 23:15:02 | INFO | fairseq_cli.train | end of epoch 902 (average epoch stats below)
2022-03-07 23:15:02 | INFO | train | epoch 902 | loss 0.644 | nll_loss 0.12 | ppl 1.09 | wps 23826 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 43906 | lr 0.000150917 | gnorm 0.274 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 123153
2022-03-07 23:15:02 | INFO | fairseq.trainer | begin training epoch 903
2022-03-07 23:15:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:17:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:17:12 | INFO | valid | epoch 903 | valid on 'valid' subset | loss 14.26 | nll_loss 14.088 | ppl 17413.3 | wps 43287.7 | wpb 510.9 | bsz 1 | num_updates 43955 | best_loss 8.318
2022-03-07 23:17:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 903 @ 43955 updates
2022-03-07 23:17:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:17:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:17:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 903 @ 43955 updates, score 14.26) (writing took 2.4539321418851614 seconds)
2022-03-07 23:17:15 | INFO | fairseq_cli.train | end of epoch 903 (average epoch stats below)
2022-03-07 23:17:15 | INFO | train | epoch 903 | loss 0.644 | nll_loss 0.12 | ppl 1.09 | wps 23986.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 43955 | lr 0.000150833 | gnorm 0.274 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 123285
2022-03-07 23:17:15 | INFO | fairseq.trainer | begin training epoch 904
2022-03-07 23:17:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:19:11 | INFO | train_inner | epoch 904:     45 / 49 loss=0.644, nll_loss=0.12, ppl=1.09, wps=23950.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=44000, lr=0.000150756, gnorm=0.275, loss_scale=64, train_wall=231, gb_free=8.8, wall=123402
2022-03-07 23:19:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:19:26 | INFO | valid | epoch 904 | valid on 'valid' subset | loss 14.189 | nll_loss 14.016 | ppl 16569.2 | wps 41279 | wpb 510.9 | bsz 1 | num_updates 44004 | best_loss 8.318
2022-03-07 23:19:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 904 @ 44004 updates
2022-03-07 23:19:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:19:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:19:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 904 @ 44004 updates, score 14.189) (writing took 2.4241420160979033 seconds)
2022-03-07 23:19:28 | INFO | fairseq_cli.train | end of epoch 904 (average epoch stats below)
2022-03-07 23:19:28 | INFO | train | epoch 904 | loss 0.644 | nll_loss 0.12 | ppl 1.09 | wps 23782.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 44004 | lr 0.000150749 | gnorm 0.273 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 123419
2022-03-07 23:19:28 | INFO | fairseq.trainer | begin training epoch 905
2022-03-07 23:19:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:20:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:21:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:21:40 | INFO | valid | epoch 905 | valid on 'valid' subset | loss 14.228 | nll_loss 14.056 | ppl 17028.8 | wps 42575.3 | wpb 510.9 | bsz 1 | num_updates 44052 | best_loss 8.318
2022-03-07 23:21:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 905 @ 44052 updates
2022-03-07 23:21:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:21:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:21:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 905 @ 44052 updates, score 14.228) (writing took 2.466142987832427 seconds)
2022-03-07 23:21:43 | INFO | fairseq_cli.train | end of epoch 905 (average epoch stats below)
2022-03-07 23:21:43 | INFO | train | epoch 905 | loss 0.644 | nll_loss 0.12 | ppl 1.09 | wps 23169.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 44052 | lr 0.000150667 | gnorm 0.275 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 123553
2022-03-07 23:21:43 | INFO | fairseq.trainer | begin training epoch 906
2022-03-07 23:21:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:23:48 | INFO | train_inner | epoch 906:     48 / 49 loss=0.644, nll_loss=0.12, ppl=1.09, wps=23471.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=44100, lr=0.000150585, gnorm=0.274, loss_scale=64, train_wall=236, gb_free=8.8, wall=123678
2022-03-07 23:23:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:23:54 | INFO | valid | epoch 906 | valid on 'valid' subset | loss 14.189 | nll_loss 14.016 | ppl 16563.6 | wps 43170.5 | wpb 510.9 | bsz 1 | num_updates 44101 | best_loss 8.318
2022-03-07 23:23:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 906 @ 44101 updates
2022-03-07 23:23:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:23:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:23:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 906 @ 44101 updates, score 14.189) (writing took 2.4377351235598326 seconds)
2022-03-07 23:23:57 | INFO | fairseq_cli.train | end of epoch 906 (average epoch stats below)
2022-03-07 23:23:57 | INFO | train | epoch 906 | loss 0.644 | nll_loss 0.12 | ppl 1.09 | wps 23740.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 44101 | lr 0.000150583 | gnorm 0.274 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 123687
2022-03-07 23:23:57 | INFO | fairseq.trainer | begin training epoch 907
2022-03-07 23:23:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:25:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:26:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:26:08 | INFO | valid | epoch 907 | valid on 'valid' subset | loss 14.277 | nll_loss 14.107 | ppl 17647.4 | wps 43068.4 | wpb 510.9 | bsz 1 | num_updates 44149 | best_loss 8.318
2022-03-07 23:26:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 907 @ 44149 updates
2022-03-07 23:26:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:26:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:26:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 907 @ 44149 updates, score 14.277) (writing took 2.4571205843240023 seconds)
2022-03-07 23:26:10 | INFO | fairseq_cli.train | end of epoch 907 (average epoch stats below)
2022-03-07 23:26:10 | INFO | train | epoch 907 | loss 0.644 | nll_loss 0.12 | ppl 1.09 | wps 23326.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 44149 | lr 0.000150501 | gnorm 0.275 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 123820
2022-03-07 23:26:10 | INFO | fairseq.trainer | begin training epoch 908
2022-03-07 23:26:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:26:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:28:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:28:22 | INFO | valid | epoch 908 | valid on 'valid' subset | loss 14.171 | nll_loss 13.997 | ppl 16352.6 | wps 42332.9 | wpb 510.9 | bsz 1 | num_updates 44197 | best_loss 8.318
2022-03-07 23:28:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 908 @ 44197 updates
2022-03-07 23:28:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:28:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:28:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 908 @ 44197 updates, score 14.171) (writing took 2.422733899205923 seconds)
2022-03-07 23:28:24 | INFO | fairseq_cli.train | end of epoch 908 (average epoch stats below)
2022-03-07 23:28:24 | INFO | train | epoch 908 | loss 0.643 | nll_loss 0.119 | ppl 1.09 | wps 23164.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 44197 | lr 0.000150419 | gnorm 0.271 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 123955
2022-03-07 23:28:24 | INFO | fairseq.trainer | begin training epoch 909
2022-03-07 23:28:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:28:32 | INFO | train_inner | epoch 909:      3 / 49 loss=0.644, nll_loss=0.12, ppl=1.09, wps=22675.9, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=44200, lr=0.000150414, gnorm=0.274, loss_scale=32, train_wall=237, gb_free=8.8, wall=123963
2022-03-07 23:30:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:30:36 | INFO | valid | epoch 909 | valid on 'valid' subset | loss 14.221 | nll_loss 14.049 | ppl 16948.6 | wps 43163.8 | wpb 510.9 | bsz 1 | num_updates 44246 | best_loss 8.318
2022-03-07 23:30:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 909 @ 44246 updates
2022-03-07 23:30:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:30:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:30:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 909 @ 44246 updates, score 14.221) (writing took 2.45744819752872 seconds)
2022-03-07 23:30:39 | INFO | fairseq_cli.train | end of epoch 909 (average epoch stats below)
2022-03-07 23:30:39 | INFO | train | epoch 909 | loss 0.643 | nll_loss 0.119 | ppl 1.09 | wps 23650.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 44246 | lr 0.000150336 | gnorm 0.274 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 124089
2022-03-07 23:30:39 | INFO | fairseq.trainer | begin training epoch 910
2022-03-07 23:30:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:32:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:32:50 | INFO | valid | epoch 910 | valid on 'valid' subset | loss 14.258 | nll_loss 14.087 | ppl 17406.3 | wps 42256.3 | wpb 510.9 | bsz 1 | num_updates 44295 | best_loss 8.318
2022-03-07 23:32:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 910 @ 44295 updates
2022-03-07 23:32:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:32:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:32:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 910 @ 44295 updates, score 14.258) (writing took 2.4095235485583544 seconds)
2022-03-07 23:32:53 | INFO | fairseq_cli.train | end of epoch 910 (average epoch stats below)
2022-03-07 23:32:53 | INFO | train | epoch 910 | loss 0.643 | nll_loss 0.119 | ppl 1.09 | wps 23770.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 44295 | lr 0.000150253 | gnorm 0.269 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 124223
2022-03-07 23:32:53 | INFO | fairseq.trainer | begin training epoch 911
2022-03-07 23:32:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:33:06 | INFO | train_inner | epoch 911:      5 / 49 loss=0.643, nll_loss=0.119, ppl=1.09, wps=23747.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=44300, lr=0.000150244, gnorm=0.272, loss_scale=64, train_wall=233, gb_free=8.8, wall=124236
2022-03-07 23:34:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:35:04 | INFO | valid | epoch 911 | valid on 'valid' subset | loss 14.185 | nll_loss 14.012 | ppl 16515.4 | wps 43298 | wpb 510.9 | bsz 1 | num_updates 44344 | best_loss 8.318
2022-03-07 23:35:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 911 @ 44344 updates
2022-03-07 23:35:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:35:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:35:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 911 @ 44344 updates, score 14.185) (writing took 2.4441918302327394 seconds)
2022-03-07 23:35:06 | INFO | fairseq_cli.train | end of epoch 911 (average epoch stats below)
2022-03-07 23:35:06 | INFO | train | epoch 911 | loss 0.644 | nll_loss 0.12 | ppl 1.09 | wps 23807.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 44344 | lr 0.00015017 | gnorm 0.273 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 124356
2022-03-07 23:35:06 | INFO | fairseq.trainer | begin training epoch 912
2022-03-07 23:35:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:37:17 | INFO | valid | epoch 912 | valid on 'valid' subset | loss 14.287 | nll_loss 14.116 | ppl 17759.5 | wps 42962 | wpb 510.9 | bsz 1 | num_updates 44393 | best_loss 8.318
2022-03-07 23:37:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 912 @ 44393 updates
2022-03-07 23:37:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:37:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:37:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 912 @ 44393 updates, score 14.287) (writing took 2.4233176168054342 seconds)
2022-03-07 23:37:20 | INFO | fairseq_cli.train | end of epoch 912 (average epoch stats below)
2022-03-07 23:37:20 | INFO | train | epoch 912 | loss 0.644 | nll_loss 0.12 | ppl 1.09 | wps 23763.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 44393 | lr 0.000150087 | gnorm 0.271 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 124490
2022-03-07 23:37:20 | INFO | fairseq.trainer | begin training epoch 913
2022-03-07 23:37:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:37:38 | INFO | train_inner | epoch 913:      7 / 49 loss=0.644, nll_loss=0.12, ppl=1.09, wps=23805.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=44400, lr=0.000150075, gnorm=0.272, loss_scale=64, train_wall=233, gb_free=8.8, wall=124508
2022-03-07 23:38:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:39:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:39:31 | INFO | valid | epoch 913 | valid on 'valid' subset | loss 14.201 | nll_loss 14.029 | ppl 16720.5 | wps 43350.9 | wpb 510.9 | bsz 1 | num_updates 44441 | best_loss 8.318
2022-03-07 23:39:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 913 @ 44441 updates
2022-03-07 23:39:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:39:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:39:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 913 @ 44441 updates, score 14.201) (writing took 2.4606698509305716 seconds)
2022-03-07 23:39:33 | INFO | fairseq_cli.train | end of epoch 913 (average epoch stats below)
2022-03-07 23:39:33 | INFO | train | epoch 913 | loss 0.643 | nll_loss 0.119 | ppl 1.09 | wps 23298.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 44441 | lr 0.000150006 | gnorm 0.272 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 124624
2022-03-07 23:39:33 | INFO | fairseq.trainer | begin training epoch 914
2022-03-07 23:39:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:41:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:41:44 | INFO | valid | epoch 914 | valid on 'valid' subset | loss 14.171 | nll_loss 13.998 | ppl 16357.6 | wps 42723.3 | wpb 510.9 | bsz 1 | num_updates 44490 | best_loss 8.318
2022-03-07 23:41:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 914 @ 44490 updates
2022-03-07 23:41:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:41:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:41:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 914 @ 44490 updates, score 14.171) (writing took 2.492842487990856 seconds)
2022-03-07 23:41:47 | INFO | fairseq_cli.train | end of epoch 914 (average epoch stats below)
2022-03-07 23:41:47 | INFO | train | epoch 914 | loss 0.643 | nll_loss 0.119 | ppl 1.09 | wps 23790 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 44490 | lr 0.000149923 | gnorm 0.271 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 124757
2022-03-07 23:41:47 | INFO | fairseq.trainer | begin training epoch 915
2022-03-07 23:41:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:42:13 | INFO | train_inner | epoch 915:     10 / 49 loss=0.643, nll_loss=0.119, ppl=1.09, wps=23603.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=44500, lr=0.000149906, gnorm=0.271, loss_scale=64, train_wall=235, gb_free=8.8, wall=124783
2022-03-07 23:43:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:43:59 | INFO | valid | epoch 915 | valid on 'valid' subset | loss 14.3 | nll_loss 14.129 | ppl 17922.3 | wps 42212.2 | wpb 510.9 | bsz 1 | num_updates 44539 | best_loss 8.318
2022-03-07 23:43:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 915 @ 44539 updates
2022-03-07 23:43:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:44:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:44:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 915 @ 44539 updates, score 14.3) (writing took 2.414967577904463 seconds)
2022-03-07 23:44:01 | INFO | fairseq_cli.train | end of epoch 915 (average epoch stats below)
2022-03-07 23:44:01 | INFO | train | epoch 915 | loss 0.643 | nll_loss 0.119 | ppl 1.09 | wps 23654 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 44539 | lr 0.000149841 | gnorm 0.275 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 124892
2022-03-07 23:44:01 | INFO | fairseq.trainer | begin training epoch 916
2022-03-07 23:44:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:44:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:46:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:46:13 | INFO | valid | epoch 916 | valid on 'valid' subset | loss 14.277 | nll_loss 14.106 | ppl 17632.7 | wps 42751.9 | wpb 510.9 | bsz 1 | num_updates 44587 | best_loss 8.318
2022-03-07 23:46:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 916 @ 44587 updates
2022-03-07 23:46:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:46:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:46:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 916 @ 44587 updates, score 14.277) (writing took 2.425186676904559 seconds)
2022-03-07 23:46:15 | INFO | fairseq_cli.train | end of epoch 916 (average epoch stats below)
2022-03-07 23:46:15 | INFO | train | epoch 916 | loss 0.643 | nll_loss 0.119 | ppl 1.09 | wps 23211.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 44587 | lr 0.00014976 | gnorm 0.273 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 125026
2022-03-07 23:46:15 | INFO | fairseq.trainer | begin training epoch 917
2022-03-07 23:46:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:46:49 | INFO | train_inner | epoch 917:     13 / 49 loss=0.643, nll_loss=0.119, ppl=1.09, wps=23480.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=44600, lr=0.000149738, gnorm=0.274, loss_scale=64, train_wall=236, gb_free=8.8, wall=125060
2022-03-07 23:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:48:27 | INFO | valid | epoch 917 | valid on 'valid' subset | loss 14.271 | nll_loss 14.101 | ppl 17570.4 | wps 42533.2 | wpb 510.9 | bsz 1 | num_updates 44636 | best_loss 8.318
2022-03-07 23:48:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 917 @ 44636 updates
2022-03-07 23:48:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:48:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:48:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 917 @ 44636 updates, score 14.271) (writing took 2.4231225922703743 seconds)
2022-03-07 23:48:29 | INFO | fairseq_cli.train | end of epoch 917 (average epoch stats below)
2022-03-07 23:48:29 | INFO | train | epoch 917 | loss 0.643 | nll_loss 0.119 | ppl 1.09 | wps 23758.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 44636 | lr 0.000149678 | gnorm 0.272 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 125159
2022-03-07 23:48:29 | INFO | fairseq.trainer | begin training epoch 918
2022-03-07 23:48:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:50:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:50:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:50:40 | INFO | valid | epoch 918 | valid on 'valid' subset | loss 14.267 | nll_loss 14.095 | ppl 17501.1 | wps 42899.1 | wpb 510.9 | bsz 1 | num_updates 44684 | best_loss 8.318
2022-03-07 23:50:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 918 @ 44684 updates
2022-03-07 23:50:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:50:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:50:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 918 @ 44684 updates, score 14.267) (writing took 2.432171620428562 seconds)
2022-03-07 23:50:42 | INFO | fairseq_cli.train | end of epoch 918 (average epoch stats below)
2022-03-07 23:50:42 | INFO | train | epoch 918 | loss 0.643 | nll_loss 0.119 | ppl 1.09 | wps 23351 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 44684 | lr 0.000149597 | gnorm 0.274 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 125293
2022-03-07 23:50:42 | INFO | fairseq.trainer | begin training epoch 919
2022-03-07 23:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:51:24 | INFO | train_inner | epoch 919:     16 / 49 loss=0.643, nll_loss=0.119, ppl=1.09, wps=23606.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=44700, lr=0.000149571, gnorm=0.272, loss_scale=64, train_wall=235, gb_free=8.8, wall=125334
2022-03-07 23:52:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:52:54 | INFO | valid | epoch 919 | valid on 'valid' subset | loss 14.207 | nll_loss 14.035 | ppl 16787.5 | wps 42637.9 | wpb 510.9 | bsz 1 | num_updates 44733 | best_loss 8.318
2022-03-07 23:52:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 919 @ 44733 updates
2022-03-07 23:52:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:52:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:52:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 919 @ 44733 updates, score 14.207) (writing took 2.419941246509552 seconds)
2022-03-07 23:52:56 | INFO | fairseq_cli.train | end of epoch 919 (average epoch stats below)
2022-03-07 23:52:56 | INFO | train | epoch 919 | loss 0.643 | nll_loss 0.119 | ppl 1.09 | wps 23786.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 44733 | lr 0.000149515 | gnorm 0.272 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 125426
2022-03-07 23:52:56 | INFO | fairseq.trainer | begin training epoch 920
2022-03-07 23:52:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:55:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:55:07 | INFO | valid | epoch 920 | valid on 'valid' subset | loss 14.291 | nll_loss 14.121 | ppl 17821.2 | wps 42856.1 | wpb 510.9 | bsz 1 | num_updates 44782 | best_loss 8.318
2022-03-07 23:55:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 920 @ 44782 updates
2022-03-07 23:55:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:55:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:55:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 920 @ 44782 updates, score 14.291) (writing took 2.4846452213823795 seconds)
2022-03-07 23:55:10 | INFO | fairseq_cli.train | end of epoch 920 (average epoch stats below)
2022-03-07 23:55:10 | INFO | train | epoch 920 | loss 0.643 | nll_loss 0.119 | ppl 1.09 | wps 23754.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 44782 | lr 0.000149434 | gnorm 0.272 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 125560
2022-03-07 23:55:10 | INFO | fairseq.trainer | begin training epoch 921
2022-03-07 23:55:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:55:57 | INFO | train_inner | epoch 921:     18 / 49 loss=0.643, nll_loss=0.119, ppl=1.09, wps=23795.1, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=44800, lr=0.000149404, gnorm=0.272, loss_scale=64, train_wall=233, gb_free=8.8, wall=125607
2022-03-07 23:56:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:57:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:57:21 | INFO | valid | epoch 921 | valid on 'valid' subset | loss 14.226 | nll_loss 14.055 | ppl 17021.8 | wps 43304.4 | wpb 510.9 | bsz 1 | num_updates 44830 | best_loss 8.318
2022-03-07 23:57:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 921 @ 44830 updates
2022-03-07 23:57:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:57:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:57:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 921 @ 44830 updates, score 14.226) (writing took 2.4921607114374638 seconds)
2022-03-07 23:57:23 | INFO | fairseq_cli.train | end of epoch 921 (average epoch stats below)
2022-03-07 23:57:23 | INFO | train | epoch 921 | loss 0.642 | nll_loss 0.118 | ppl 1.09 | wps 23300 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 44830 | lr 0.000149354 | gnorm 0.271 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 125694
2022-03-07 23:57:23 | INFO | fairseq.trainer | begin training epoch 922
2022-03-07 23:57:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:59:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:59:35 | INFO | valid | epoch 922 | valid on 'valid' subset | loss 14.269 | nll_loss 14.097 | ppl 17527.9 | wps 42726.1 | wpb 510.9 | bsz 1 | num_updates 44879 | best_loss 8.318
2022-03-07 23:59:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 922 @ 44879 updates
2022-03-07 23:59:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:59:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:59:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 922 @ 44879 updates, score 14.269) (writing took 2.411516323685646 seconds)
2022-03-07 23:59:37 | INFO | fairseq_cli.train | end of epoch 922 (average epoch stats below)
2022-03-07 23:59:37 | INFO | train | epoch 922 | loss 0.643 | nll_loss 0.119 | ppl 1.09 | wps 23774.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 44879 | lr 0.000149272 | gnorm 0.273 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 125827
2022-03-07 23:59:37 | INFO | fairseq.trainer | begin training epoch 923
2022-03-07 23:59:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:00:32 | INFO | train_inner | epoch 923:     21 / 49 loss=0.643, nll_loss=0.119, ppl=1.09, wps=23584.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=44900, lr=0.000149237, gnorm=0.273, loss_scale=64, train_wall=235, gb_free=8.8, wall=125882
2022-03-08 00:01:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:01:48 | INFO | valid | epoch 923 | valid on 'valid' subset | loss 14.213 | nll_loss 14.042 | ppl 16866.1 | wps 43113.6 | wpb 510.9 | bsz 1 | num_updates 44928 | best_loss 8.318
2022-03-08 00:01:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 923 @ 44928 updates
2022-03-08 00:01:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:01:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:01:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 923 @ 44928 updates, score 14.213) (writing took 2.459220428019762 seconds)
2022-03-08 00:01:51 | INFO | fairseq_cli.train | end of epoch 923 (average epoch stats below)
2022-03-08 00:01:51 | INFO | train | epoch 923 | loss 0.643 | nll_loss 0.119 | ppl 1.09 | wps 23783.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 44928 | lr 0.000149191 | gnorm 0.272 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 125961
2022-03-08 00:01:51 | INFO | fairseq.trainer | begin training epoch 924
2022-03-08 00:01:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:02:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:03:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:04:04 | INFO | valid | epoch 924 | valid on 'valid' subset | loss 14.272 | nll_loss 14.103 | ppl 17597.8 | wps 41596.4 | wpb 510.9 | bsz 1 | num_updates 44976 | best_loss 8.318
2022-03-08 00:04:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 924 @ 44976 updates
2022-03-08 00:04:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:04:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:04:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 924 @ 44976 updates, score 14.272) (writing took 2.3705813735723495 seconds)
2022-03-08 00:04:07 | INFO | fairseq_cli.train | end of epoch 924 (average epoch stats below)
2022-03-08 00:04:07 | INFO | train | epoch 924 | loss 0.642 | nll_loss 0.119 | ppl 1.09 | wps 22901 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 44976 | lr 0.000149111 | gnorm 0.271 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 126097
2022-03-08 00:04:07 | INFO | fairseq.trainer | begin training epoch 925
2022-03-08 00:04:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:05:10 | INFO | train_inner | epoch 925:     24 / 49 loss=0.642, nll_loss=0.119, ppl=1.09, wps=23286.4, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=45000, lr=0.000149071, gnorm=0.271, loss_scale=64, train_wall=238, gb_free=8.8, wall=126161
2022-03-08 00:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:06:20 | INFO | valid | epoch 925 | valid on 'valid' subset | loss 14.273 | nll_loss 14.101 | ppl 17568.2 | wps 40725.1 | wpb 510.9 | bsz 1 | num_updates 45025 | best_loss 8.318
2022-03-08 00:06:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 925 @ 45025 updates
2022-03-08 00:06:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:06:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:06:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 925 @ 45025 updates, score 14.273) (writing took 2.426903935149312 seconds)
2022-03-08 00:06:22 | INFO | fairseq_cli.train | end of epoch 925 (average epoch stats below)
2022-03-08 00:06:22 | INFO | train | epoch 925 | loss 0.642 | nll_loss 0.118 | ppl 1.09 | wps 23468.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 45025 | lr 0.00014903 | gnorm 0.27 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 126232
2022-03-08 00:06:22 | INFO | fairseq.trainer | begin training epoch 926
2022-03-08 00:06:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:08:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:08:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:08:36 | INFO | valid | epoch 926 | valid on 'valid' subset | loss 14.178 | nll_loss 14.006 | ppl 16456 | wps 41695.9 | wpb 510.9 | bsz 1 | num_updates 45073 | best_loss 8.318
2022-03-08 00:08:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 926 @ 45073 updates
2022-03-08 00:08:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:08:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:08:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 926 @ 45073 updates, score 14.178) (writing took 2.276249071583152 seconds)
2022-03-08 00:08:38 | INFO | fairseq_cli.train | end of epoch 926 (average epoch stats below)
2022-03-08 00:08:38 | INFO | train | epoch 926 | loss 0.643 | nll_loss 0.119 | ppl 1.09 | wps 22911.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 45073 | lr 0.00014895 | gnorm 0.273 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 126368
2022-03-08 00:08:38 | INFO | fairseq.trainer | begin training epoch 927
2022-03-08 00:08:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:09:49 | INFO | train_inner | epoch 927:     27 / 49 loss=0.642, nll_loss=0.119, ppl=1.09, wps=23291.2, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=45100, lr=0.000148906, gnorm=0.272, loss_scale=64, train_wall=238, gb_free=8.8, wall=126439
2022-03-08 00:10:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:10:51 | INFO | valid | epoch 927 | valid on 'valid' subset | loss 14.268 | nll_loss 14.096 | ppl 17507.5 | wps 41919.5 | wpb 510.9 | bsz 1 | num_updates 45122 | best_loss 8.318
2022-03-08 00:10:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 927 @ 45122 updates
2022-03-08 00:10:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:10:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:10:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 927 @ 45122 updates, score 14.268) (writing took 2.237772408872843 seconds)
2022-03-08 00:10:53 | INFO | fairseq_cli.train | end of epoch 927 (average epoch stats below)
2022-03-08 00:10:53 | INFO | train | epoch 927 | loss 0.642 | nll_loss 0.119 | ppl 1.09 | wps 23540.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 45122 | lr 0.00014887 | gnorm 0.271 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 126503
2022-03-08 00:10:53 | INFO | fairseq.trainer | begin training epoch 928
2022-03-08 00:10:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:12:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:13:04 | INFO | valid | epoch 928 | valid on 'valid' subset | loss 14.253 | nll_loss 14.082 | ppl 17337.1 | wps 43261.1 | wpb 510.9 | bsz 1 | num_updates 45171 | best_loss 8.318
2022-03-08 00:13:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 928 @ 45171 updates
2022-03-08 00:13:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:13:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:13:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 928 @ 45171 updates, score 14.253) (writing took 2.3990832921117544 seconds)
2022-03-08 00:13:07 | INFO | fairseq_cli.train | end of epoch 928 (average epoch stats below)
2022-03-08 00:13:07 | INFO | train | epoch 928 | loss 0.642 | nll_loss 0.119 | ppl 1.09 | wps 23749.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 45171 | lr 0.000148789 | gnorm 0.274 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 126637
2022-03-08 00:13:07 | INFO | fairseq.trainer | begin training epoch 929
2022-03-08 00:13:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:14:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:14:25 | INFO | train_inner | epoch 929:     30 / 49 loss=0.642, nll_loss=0.118, ppl=1.09, wps=23521.4, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=45200, lr=0.000148741, gnorm=0.272, loss_scale=64, train_wall=236, gb_free=8.8, wall=126715
2022-03-08 00:15:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:15:18 | INFO | valid | epoch 929 | valid on 'valid' subset | loss 14.235 | nll_loss 14.064 | ppl 17124.3 | wps 43239.2 | wpb 510.9 | bsz 1 | num_updates 45219 | best_loss 8.318
2022-03-08 00:15:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 929 @ 45219 updates
2022-03-08 00:15:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:15:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:15:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 929 @ 45219 updates, score 14.235) (writing took 2.441929839551449 seconds)
2022-03-08 00:15:20 | INFO | fairseq_cli.train | end of epoch 929 (average epoch stats below)
2022-03-08 00:15:20 | INFO | train | epoch 929 | loss 0.642 | nll_loss 0.118 | ppl 1.09 | wps 23331.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 45219 | lr 0.00014871 | gnorm 0.272 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 126770
2022-03-08 00:15:20 | INFO | fairseq.trainer | begin training epoch 930
2022-03-08 00:15:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:17:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:17:33 | INFO | valid | epoch 930 | valid on 'valid' subset | loss 14.171 | nll_loss 13.999 | ppl 16371.7 | wps 41872.2 | wpb 510.9 | bsz 1 | num_updates 45268 | best_loss 8.318
2022-03-08 00:17:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 930 @ 45268 updates
2022-03-08 00:17:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:17:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:17:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 930 @ 45268 updates, score 14.171) (writing took 2.339610382914543 seconds)
2022-03-08 00:17:36 | INFO | fairseq_cli.train | end of epoch 930 (average epoch stats below)
2022-03-08 00:17:36 | INFO | train | epoch 930 | loss 0.641 | nll_loss 0.118 | ppl 1.08 | wps 23443.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 45268 | lr 0.000148629 | gnorm 0.267 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 126906
2022-03-08 00:17:36 | INFO | fairseq.trainer | begin training epoch 931
2022-03-08 00:17:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:19:00 | INFO | train_inner | epoch 931:     32 / 49 loss=0.641, nll_loss=0.118, ppl=1.09, wps=23576.9, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=45300, lr=0.000148577, gnorm=0.27, loss_scale=64, train_wall=235, gb_free=8.8, wall=126990
2022-03-08 00:19:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:19:49 | INFO | valid | epoch 931 | valid on 'valid' subset | loss 14.224 | nll_loss 14.052 | ppl 16984.1 | wps 41403.6 | wpb 510.9 | bsz 1 | num_updates 45317 | best_loss 8.318
2022-03-08 00:19:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 931 @ 45317 updates
2022-03-08 00:19:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:19:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:19:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 931 @ 45317 updates, score 14.224) (writing took 2.267306800931692 seconds)
2022-03-08 00:19:51 | INFO | fairseq_cli.train | end of epoch 931 (average epoch stats below)
2022-03-08 00:19:51 | INFO | train | epoch 931 | loss 0.642 | nll_loss 0.118 | ppl 1.09 | wps 23514.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 45317 | lr 0.000148549 | gnorm 0.271 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 127041
2022-03-08 00:19:51 | INFO | fairseq.trainer | begin training epoch 932
2022-03-08 00:19:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:20:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:21:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:22:04 | INFO | valid | epoch 932 | valid on 'valid' subset | loss 14.196 | nll_loss 14.024 | ppl 16662.6 | wps 42163.5 | wpb 510.9 | bsz 1 | num_updates 45365 | best_loss 8.318
2022-03-08 00:22:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 932 @ 45365 updates
2022-03-08 00:22:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:22:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:22:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 932 @ 45365 updates, score 14.196) (writing took 2.330721376463771 seconds)
2022-03-08 00:22:06 | INFO | fairseq_cli.train | end of epoch 932 (average epoch stats below)
2022-03-08 00:22:06 | INFO | train | epoch 932 | loss 0.642 | nll_loss 0.118 | ppl 1.09 | wps 23029.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 45365 | lr 0.00014847 | gnorm 0.271 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 127176
2022-03-08 00:22:06 | INFO | fairseq.trainer | begin training epoch 933
2022-03-08 00:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:23:38 | INFO | train_inner | epoch 933:     35 / 49 loss=0.641, nll_loss=0.118, ppl=1.09, wps=23298.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=45400, lr=0.000148413, gnorm=0.271, loss_scale=64, train_wall=238, gb_free=8.8, wall=127268
2022-03-08 00:24:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:24:19 | INFO | valid | epoch 933 | valid on 'valid' subset | loss 14.307 | nll_loss 14.138 | ppl 18024.6 | wps 42194 | wpb 510.9 | bsz 1 | num_updates 45414 | best_loss 8.318
2022-03-08 00:24:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 933 @ 45414 updates
2022-03-08 00:24:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:24:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:24:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 933 @ 45414 updates, score 14.307) (writing took 2.294481836259365 seconds)
2022-03-08 00:24:21 | INFO | fairseq_cli.train | end of epoch 933 (average epoch stats below)
2022-03-08 00:24:21 | INFO | train | epoch 933 | loss 0.641 | nll_loss 0.118 | ppl 1.09 | wps 23498 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 45414 | lr 0.00014839 | gnorm 0.271 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 127312
2022-03-08 00:24:21 | INFO | fairseq.trainer | begin training epoch 934
2022-03-08 00:24:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:26:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:26:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:26:34 | INFO | valid | epoch 934 | valid on 'valid' subset | loss 14.175 | nll_loss 14.002 | ppl 16403.8 | wps 41865.8 | wpb 510.9 | bsz 1 | num_updates 45462 | best_loss 8.318
2022-03-08 00:26:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 934 @ 45462 updates
2022-03-08 00:26:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:26:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:26:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 934 @ 45462 updates, score 14.175) (writing took 2.3327119816094637 seconds)
2022-03-08 00:26:36 | INFO | fairseq_cli.train | end of epoch 934 (average epoch stats below)
2022-03-08 00:26:36 | INFO | train | epoch 934 | loss 0.642 | nll_loss 0.118 | ppl 1.09 | wps 23022.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 45462 | lr 0.000148312 | gnorm 0.271 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 127447
2022-03-08 00:26:36 | INFO | fairseq.trainer | begin training epoch 935
2022-03-08 00:26:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:28:16 | INFO | train_inner | epoch 935:     38 / 49 loss=0.641, nll_loss=0.118, ppl=1.09, wps=23317, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=45500, lr=0.00014825, gnorm=0.27, loss_scale=64, train_wall=238, gb_free=8.8, wall=127547
2022-03-08 00:28:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:28:49 | INFO | valid | epoch 935 | valid on 'valid' subset | loss 14.273 | nll_loss 14.103 | ppl 17591.5 | wps 42031 | wpb 510.9 | bsz 1 | num_updates 45511 | best_loss 8.318
2022-03-08 00:28:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 935 @ 45511 updates
2022-03-08 00:28:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:28:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:28:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 935 @ 45511 updates, score 14.273) (writing took 2.277953354641795 seconds)
2022-03-08 00:28:52 | INFO | fairseq_cli.train | end of epoch 935 (average epoch stats below)
2022-03-08 00:28:52 | INFO | train | epoch 935 | loss 0.641 | nll_loss 0.117 | ppl 1.08 | wps 23508.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 45511 | lr 0.000148232 | gnorm 0.269 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 127582
2022-03-08 00:28:52 | INFO | fairseq.trainer | begin training epoch 936
2022-03-08 00:28:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:31:04 | INFO | valid | epoch 936 | valid on 'valid' subset | loss 14.172 | nll_loss 13.999 | ppl 16372.1 | wps 42117.7 | wpb 510.9 | bsz 1 | num_updates 45560 | best_loss 8.318
2022-03-08 00:31:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 936 @ 45560 updates
2022-03-08 00:31:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:31:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:31:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 936 @ 45560 updates, score 14.172) (writing took 2.322286816313863 seconds)
2022-03-08 00:31:07 | INFO | fairseq_cli.train | end of epoch 936 (average epoch stats below)
2022-03-08 00:31:07 | INFO | train | epoch 936 | loss 0.641 | nll_loss 0.118 | ppl 1.08 | wps 23516.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 45560 | lr 0.000148152 | gnorm 0.269 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 127717
2022-03-08 00:31:07 | INFO | fairseq.trainer | begin training epoch 937
2022-03-08 00:31:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:32:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:32:55 | INFO | train_inner | epoch 937:     41 / 49 loss=0.641, nll_loss=0.118, ppl=1.08, wps=23310.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=45600, lr=0.000148087, gnorm=0.269, loss_scale=64, train_wall=238, gb_free=8.8, wall=127825
2022-03-08 00:33:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:33:20 | INFO | valid | epoch 937 | valid on 'valid' subset | loss 14.248 | nll_loss 14.076 | ppl 17273.2 | wps 42051.6 | wpb 510.9 | bsz 1 | num_updates 45608 | best_loss 8.318
2022-03-08 00:33:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 937 @ 45608 updates
2022-03-08 00:33:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:33:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:33:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 937 @ 45608 updates, score 14.248) (writing took 2.3366593942046165 seconds)
2022-03-08 00:33:22 | INFO | fairseq_cli.train | end of epoch 937 (average epoch stats below)
2022-03-08 00:33:22 | INFO | train | epoch 937 | loss 0.641 | nll_loss 0.118 | ppl 1.08 | wps 23004.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 45608 | lr 0.000148074 | gnorm 0.27 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 127852
2022-03-08 00:33:22 | INFO | fairseq.trainer | begin training epoch 938
2022-03-08 00:33:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:35:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:35:35 | INFO | valid | epoch 938 | valid on 'valid' subset | loss 14.216 | nll_loss 14.045 | ppl 16903.1 | wps 41955 | wpb 510.9 | bsz 1 | num_updates 45657 | best_loss 8.318
2022-03-08 00:35:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 938 @ 45657 updates
2022-03-08 00:35:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:35:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:35:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 938 @ 45657 updates, score 14.216) (writing took 2.334025226533413 seconds)
2022-03-08 00:35:37 | INFO | fairseq_cli.train | end of epoch 938 (average epoch stats below)
2022-03-08 00:35:37 | INFO | train | epoch 938 | loss 0.641 | nll_loss 0.118 | ppl 1.09 | wps 23491.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 45657 | lr 0.000147995 | gnorm 0.273 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 127988
2022-03-08 00:35:37 | INFO | fairseq.trainer | begin training epoch 939
2022-03-08 00:35:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:37:30 | INFO | train_inner | epoch 939:     43 / 49 loss=0.641, nll_loss=0.118, ppl=1.09, wps=23523.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=45700, lr=0.000147925, gnorm=0.271, loss_scale=64, train_wall=236, gb_free=8.8, wall=128101
2022-03-08 00:37:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:37:50 | INFO | valid | epoch 939 | valid on 'valid' subset | loss 14.262 | nll_loss 14.092 | ppl 17459.2 | wps 41752.6 | wpb 510.9 | bsz 1 | num_updates 45706 | best_loss 8.318
2022-03-08 00:37:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 939 @ 45706 updates
2022-03-08 00:37:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:37:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:37:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 939 @ 45706 updates, score 14.262) (writing took 2.320886420086026 seconds)
2022-03-08 00:37:53 | INFO | fairseq_cli.train | end of epoch 939 (average epoch stats below)
2022-03-08 00:37:53 | INFO | train | epoch 939 | loss 0.641 | nll_loss 0.118 | ppl 1.09 | wps 23498.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 45706 | lr 0.000147915 | gnorm 0.268 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 128123
2022-03-08 00:37:53 | INFO | fairseq.trainer | begin training epoch 940
2022-03-08 00:37:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:38:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:40:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:40:06 | INFO | valid | epoch 940 | valid on 'valid' subset | loss 14.257 | nll_loss 14.085 | ppl 17382.6 | wps 41899.7 | wpb 510.9 | bsz 1 | num_updates 45754 | best_loss 8.318
2022-03-08 00:40:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 940 @ 45754 updates
2022-03-08 00:40:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:40:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:40:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 940 @ 45754 updates, score 14.257) (writing took 2.339585781097412 seconds)
2022-03-08 00:40:08 | INFO | fairseq_cli.train | end of epoch 940 (average epoch stats below)
2022-03-08 00:40:08 | INFO | train | epoch 940 | loss 0.641 | nll_loss 0.118 | ppl 1.09 | wps 23008.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 45754 | lr 0.000147838 | gnorm 0.27 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 128258
2022-03-08 00:40:08 | INFO | fairseq.trainer | begin training epoch 941
2022-03-08 00:40:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:42:09 | INFO | train_inner | epoch 941:     46 / 49 loss=0.641, nll_loss=0.118, ppl=1.09, wps=23301, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=45800, lr=0.000147764, gnorm=0.271, loss_scale=64, train_wall=238, gb_free=8.8, wall=128379
2022-03-08 00:42:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:42:21 | INFO | valid | epoch 941 | valid on 'valid' subset | loss 14.193 | nll_loss 14.022 | ppl 16636.7 | wps 41371.2 | wpb 510.9 | bsz 1 | num_updates 45803 | best_loss 8.318
2022-03-08 00:42:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 941 @ 45803 updates
2022-03-08 00:42:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:42:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:42:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 941 @ 45803 updates, score 14.193) (writing took 2.438506707549095 seconds)
2022-03-08 00:42:23 | INFO | fairseq_cli.train | end of epoch 941 (average epoch stats below)
2022-03-08 00:42:23 | INFO | train | epoch 941 | loss 0.641 | nll_loss 0.118 | ppl 1.09 | wps 23469.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 45803 | lr 0.000147759 | gnorm 0.272 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 128394
2022-03-08 00:42:23 | INFO | fairseq.trainer | begin training epoch 942
2022-03-08 00:42:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:43:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:44:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:44:36 | INFO | valid | epoch 942 | valid on 'valid' subset | loss 14.258 | nll_loss 14.089 | ppl 17426 | wps 41879.3 | wpb 510.9 | bsz 1 | num_updates 45851 | best_loss 8.318
2022-03-08 00:44:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 942 @ 45851 updates
2022-03-08 00:44:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:44:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:44:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 942 @ 45851 updates, score 14.258) (writing took 2.377073323354125 seconds)
2022-03-08 00:44:39 | INFO | fairseq_cli.train | end of epoch 942 (average epoch stats below)
2022-03-08 00:44:39 | INFO | train | epoch 942 | loss 0.641 | nll_loss 0.118 | ppl 1.08 | wps 23001.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 45851 | lr 0.000147681 | gnorm 0.27 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 128529
2022-03-08 00:44:39 | INFO | fairseq.trainer | begin training epoch 943
2022-03-08 00:44:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:46:46 | INFO | train_inner | epoch 943:     49 / 49 loss=0.64, nll_loss=0.117, ppl=1.08, wps=23279.4, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=45900, lr=0.000147602, gnorm=0.271, loss_scale=64, train_wall=237, gb_free=8.8, wall=128656
2022-03-08 00:46:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:46:51 | INFO | valid | epoch 943 | valid on 'valid' subset | loss 14.224 | nll_loss 14.053 | ppl 16995.4 | wps 42140.5 | wpb 510.9 | bsz 1 | num_updates 45900 | best_loss 8.318
2022-03-08 00:46:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 943 @ 45900 updates
2022-03-08 00:46:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:46:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:46:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 943 @ 45900 updates, score 14.224) (writing took 2.473608100786805 seconds)
2022-03-08 00:46:54 | INFO | fairseq_cli.train | end of epoch 943 (average epoch stats below)
2022-03-08 00:46:54 | INFO | train | epoch 943 | loss 0.64 | nll_loss 0.117 | ppl 1.08 | wps 23491.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 45900 | lr 0.000147602 | gnorm 0.269 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 128664
2022-03-08 00:46:54 | INFO | fairseq.trainer | begin training epoch 944
2022-03-08 00:46:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:49:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:49:07 | INFO | valid | epoch 944 | valid on 'valid' subset | loss 14.168 | nll_loss 13.995 | ppl 16329.4 | wps 41920.1 | wpb 510.9 | bsz 1 | num_updates 45949 | best_loss 8.318
2022-03-08 00:49:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 944 @ 45949 updates
2022-03-08 00:49:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:49:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:49:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 944 @ 45949 updates, score 14.168) (writing took 2.2637313567101955 seconds)
2022-03-08 00:49:09 | INFO | fairseq_cli.train | end of epoch 944 (average epoch stats below)
2022-03-08 00:49:09 | INFO | train | epoch 944 | loss 0.641 | nll_loss 0.118 | ppl 1.08 | wps 23502.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 45949 | lr 0.000147524 | gnorm 0.27 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 128799
2022-03-08 00:49:09 | INFO | fairseq.trainer | begin training epoch 945
2022-03-08 00:49:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:49:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:51:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:51:22 | INFO | valid | epoch 945 | valid on 'valid' subset | loss 14.26 | nll_loss 14.089 | ppl 17430.2 | wps 41984.4 | wpb 510.9 | bsz 1 | num_updates 45997 | best_loss 8.318
2022-03-08 00:51:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 945 @ 45997 updates
2022-03-08 00:51:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:51:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:51:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 945 @ 45997 updates, score 14.26) (writing took 2.5416519567370415 seconds)
2022-03-08 00:51:25 | INFO | fairseq_cli.train | end of epoch 945 (average epoch stats below)
2022-03-08 00:51:25 | INFO | train | epoch 945 | loss 0.64 | nll_loss 0.117 | ppl 1.08 | wps 22967.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 45997 | lr 0.000147447 | gnorm 0.272 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 128935
2022-03-08 00:51:25 | INFO | fairseq.trainer | begin training epoch 946
2022-03-08 00:51:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:51:33 | INFO | train_inner | epoch 946:      3 / 49 loss=0.64, nll_loss=0.117, ppl=1.08, wps=22643.7, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=46000, lr=0.000147442, gnorm=0.271, loss_scale=64, train_wall=238, gb_free=8.8, wall=128943
2022-03-08 00:53:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:53:38 | INFO | valid | epoch 946 | valid on 'valid' subset | loss 14.209 | nll_loss 14.038 | ppl 16823.8 | wps 42071.6 | wpb 510.9 | bsz 1 | num_updates 46046 | best_loss 8.318
2022-03-08 00:53:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 946 @ 46046 updates
2022-03-08 00:53:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:53:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:53:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 946 @ 46046 updates, score 14.209) (writing took 2.312875561416149 seconds)
2022-03-08 00:53:40 | INFO | fairseq_cli.train | end of epoch 946 (average epoch stats below)
2022-03-08 00:53:40 | INFO | train | epoch 946 | loss 0.64 | nll_loss 0.117 | ppl 1.08 | wps 23493.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 46046 | lr 0.000147368 | gnorm 0.27 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 129070
2022-03-08 00:53:40 | INFO | fairseq.trainer | begin training epoch 947
2022-03-08 00:53:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:55:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:55:53 | INFO | valid | epoch 947 | valid on 'valid' subset | loss 14.23 | nll_loss 14.058 | ppl 17053.1 | wps 42027.2 | wpb 510.9 | bsz 1 | num_updates 46095 | best_loss 8.318
2022-03-08 00:55:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 947 @ 46095 updates
2022-03-08 00:55:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:55:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:55:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 947 @ 46095 updates, score 14.23) (writing took 2.3720561303198338 seconds)
2022-03-08 00:55:55 | INFO | fairseq_cli.train | end of epoch 947 (average epoch stats below)
2022-03-08 00:55:55 | INFO | train | epoch 947 | loss 0.64 | nll_loss 0.117 | ppl 1.08 | wps 23499.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 46095 | lr 0.00014729 | gnorm 0.268 | loss_scale 128 | train_wall 115 | gb_free 8.8 | wall 129205
2022-03-08 00:55:55 | INFO | fairseq.trainer | begin training epoch 948
2022-03-08 00:55:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:56:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:56:11 | INFO | train_inner | epoch 948:      6 / 49 loss=0.64, nll_loss=0.117, ppl=1.08, wps=23306.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=46100, lr=0.000147282, gnorm=0.269, loss_scale=64, train_wall=238, gb_free=8.8, wall=129221
2022-03-08 00:58:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:58:08 | INFO | valid | epoch 948 | valid on 'valid' subset | loss 14.292 | nll_loss 14.122 | ppl 17827.6 | wps 41815.5 | wpb 510.9 | bsz 1 | num_updates 46143 | best_loss 8.318
2022-03-08 00:58:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 948 @ 46143 updates
2022-03-08 00:58:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:58:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:58:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 948 @ 46143 updates, score 14.292) (writing took 2.262474777176976 seconds)
2022-03-08 00:58:10 | INFO | fairseq_cli.train | end of epoch 948 (average epoch stats below)
2022-03-08 00:58:10 | INFO | train | epoch 948 | loss 0.64 | nll_loss 0.117 | ppl 1.08 | wps 23025.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 46143 | lr 0.000147213 | gnorm 0.27 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 129341
2022-03-08 00:58:10 | INFO | fairseq.trainer | begin training epoch 949
2022-03-08 00:58:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:58:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:00:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:00:23 | INFO | valid | epoch 949 | valid on 'valid' subset | loss 14.23 | nll_loss 14.058 | ppl 17058 | wps 41976.4 | wpb 510.9 | bsz 1 | num_updates 46191 | best_loss 8.318
2022-03-08 01:00:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 949 @ 46191 updates
2022-03-08 01:00:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:00:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:00:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 949 @ 46191 updates, score 14.23) (writing took 2.3116355165839195 seconds)
2022-03-08 01:00:26 | INFO | fairseq_cli.train | end of epoch 949 (average epoch stats below)
2022-03-08 01:00:26 | INFO | train | epoch 949 | loss 0.64 | nll_loss 0.117 | ppl 1.08 | wps 23013.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 46191 | lr 0.000147137 | gnorm 0.269 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 129476
2022-03-08 01:00:26 | INFO | fairseq.trainer | begin training epoch 950
2022-03-08 01:00:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:00:49 | INFO | train_inner | epoch 950:      9 / 49 loss=0.64, nll_loss=0.117, ppl=1.08, wps=23308, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=46200, lr=0.000147122, gnorm=0.269, loss_scale=32, train_wall=238, gb_free=8.8, wall=129500
2022-03-08 01:02:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:02:39 | INFO | valid | epoch 950 | valid on 'valid' subset | loss 14.237 | nll_loss 14.067 | ppl 17164.2 | wps 42134.4 | wpb 510.9 | bsz 1 | num_updates 46240 | best_loss 8.318
2022-03-08 01:02:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 950 @ 46240 updates
2022-03-08 01:02:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:02:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:02:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 950 @ 46240 updates, score 14.237) (writing took 2.311392828822136 seconds)
2022-03-08 01:02:41 | INFO | fairseq_cli.train | end of epoch 950 (average epoch stats below)
2022-03-08 01:02:41 | INFO | train | epoch 950 | loss 0.64 | nll_loss 0.117 | ppl 1.08 | wps 23496.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 46240 | lr 0.000147059 | gnorm 0.268 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 129611
2022-03-08 01:02:41 | INFO | fairseq.trainer | begin training epoch 951
2022-03-08 01:02:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:04:54 | INFO | valid | epoch 951 | valid on 'valid' subset | loss 14.151 | nll_loss 13.978 | ppl 16136.3 | wps 41993.6 | wpb 510.9 | bsz 1 | num_updates 46289 | best_loss 8.318
2022-03-08 01:04:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 951 @ 46289 updates
2022-03-08 01:04:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:04:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:04:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 951 @ 46289 updates, score 14.151) (writing took 2.348963985219598 seconds)
2022-03-08 01:04:56 | INFO | fairseq_cli.train | end of epoch 951 (average epoch stats below)
2022-03-08 01:04:56 | INFO | train | epoch 951 | loss 0.64 | nll_loss 0.117 | ppl 1.08 | wps 23457.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 46289 | lr 0.000146981 | gnorm 0.269 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 129747
2022-03-08 01:04:56 | INFO | fairseq.trainer | begin training epoch 952
2022-03-08 01:04:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:05:25 | INFO | train_inner | epoch 952:     11 / 49 loss=0.64, nll_loss=0.117, ppl=1.08, wps=23496.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=46300, lr=0.000146964, gnorm=0.268, loss_scale=64, train_wall=236, gb_free=8.8, wall=129776
2022-03-08 01:07:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:07:09 | INFO | valid | epoch 952 | valid on 'valid' subset | loss 14.19 | nll_loss 14.018 | ppl 16591 | wps 41538.2 | wpb 510.9 | bsz 1 | num_updates 46338 | best_loss 8.318
2022-03-08 01:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 952 @ 46338 updates
2022-03-08 01:07:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 952 @ 46338 updates, score 14.19) (writing took 2.2996590081602335 seconds)
2022-03-08 01:07:12 | INFO | fairseq_cli.train | end of epoch 952 (average epoch stats below)
2022-03-08 01:07:12 | INFO | train | epoch 952 | loss 0.64 | nll_loss 0.117 | ppl 1.08 | wps 23473.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 46338 | lr 0.000146903 | gnorm 0.268 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 129882
2022-03-08 01:07:12 | INFO | fairseq.trainer | begin training epoch 953
2022-03-08 01:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:09:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:09:25 | INFO | valid | epoch 953 | valid on 'valid' subset | loss 14.297 | nll_loss 14.127 | ppl 17896.4 | wps 42117.3 | wpb 510.9 | bsz 1 | num_updates 46387 | best_loss 8.318
2022-03-08 01:09:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 953 @ 46387 updates
2022-03-08 01:09:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:09:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:09:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 953 @ 46387 updates, score 14.297) (writing took 2.339245645329356 seconds)
2022-03-08 01:09:27 | INFO | fairseq_cli.train | end of epoch 953 (average epoch stats below)
2022-03-08 01:09:27 | INFO | train | epoch 953 | loss 0.64 | nll_loss 0.117 | ppl 1.08 | wps 23485.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 46387 | lr 0.000146826 | gnorm 0.269 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 130017
2022-03-08 01:09:27 | INFO | fairseq.trainer | begin training epoch 954
2022-03-08 01:09:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:10:01 | INFO | train_inner | epoch 954:     13 / 49 loss=0.64, nll_loss=0.117, ppl=1.08, wps=23511, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=46400, lr=0.000146805, gnorm=0.269, loss_scale=64, train_wall=236, gb_free=8.8, wall=130052
2022-03-08 01:10:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:11:40 | INFO | valid | epoch 954 | valid on 'valid' subset | loss 14.254 | nll_loss 14.084 | ppl 17368.9 | wps 42078.1 | wpb 510.9 | bsz 1 | num_updates 46435 | best_loss 8.318
2022-03-08 01:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 954 @ 46435 updates
2022-03-08 01:11:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:11:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:11:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 954 @ 46435 updates, score 14.254) (writing took 2.309999942779541 seconds)
2022-03-08 01:11:42 | INFO | fairseq_cli.train | end of epoch 954 (average epoch stats below)
2022-03-08 01:11:42 | INFO | train | epoch 954 | loss 0.639 | nll_loss 0.117 | ppl 1.08 | wps 23003.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 46435 | lr 0.00014675 | gnorm 0.266 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 130153
2022-03-08 01:11:42 | INFO | fairseq.trainer | begin training epoch 955
2022-03-08 01:11:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:13:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:13:55 | INFO | valid | epoch 955 | valid on 'valid' subset | loss 14.215 | nll_loss 14.044 | ppl 16888.1 | wps 42017 | wpb 510.9 | bsz 1 | num_updates 46484 | best_loss 8.318
2022-03-08 01:13:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 955 @ 46484 updates
2022-03-08 01:13:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:13:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:13:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 955 @ 46484 updates, score 14.215) (writing took 2.3643928356468678 seconds)
2022-03-08 01:13:58 | INFO | fairseq_cli.train | end of epoch 955 (average epoch stats below)
2022-03-08 01:13:58 | INFO | train | epoch 955 | loss 0.639 | nll_loss 0.117 | ppl 1.08 | wps 23468.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 46484 | lr 0.000146672 | gnorm 0.267 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 130288
2022-03-08 01:13:58 | INFO | fairseq.trainer | begin training epoch 956
2022-03-08 01:13:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:14:40 | INFO | train_inner | epoch 956:     16 / 49 loss=0.639, nll_loss=0.117, ppl=1.08, wps=23293.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=46500, lr=0.000146647, gnorm=0.267, loss_scale=64, train_wall=238, gb_free=8.8, wall=130330
2022-03-08 01:16:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:16:11 | INFO | valid | epoch 956 | valid on 'valid' subset | loss 14.32 | nll_loss 14.15 | ppl 18178.1 | wps 41801.4 | wpb 510.9 | bsz 1 | num_updates 46533 | best_loss 8.318
2022-03-08 01:16:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 956 @ 46533 updates
2022-03-08 01:16:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:16:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:16:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 956 @ 46533 updates, score 14.32) (writing took 2.5327641796320677 seconds)
2022-03-08 01:16:13 | INFO | fairseq_cli.train | end of epoch 956 (average epoch stats below)
2022-03-08 01:16:13 | INFO | train | epoch 956 | loss 0.639 | nll_loss 0.117 | ppl 1.08 | wps 23460.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 46533 | lr 0.000146595 | gnorm 0.267 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 130423
2022-03-08 01:16:13 | INFO | fairseq.trainer | begin training epoch 957
2022-03-08 01:16:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:16:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:18:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:18:26 | INFO | valid | epoch 957 | valid on 'valid' subset | loss 14.219 | nll_loss 14.047 | ppl 16923 | wps 41975.3 | wpb 510.9 | bsz 1 | num_updates 46581 | best_loss 8.318
2022-03-08 01:18:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 957 @ 46581 updates
2022-03-08 01:18:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:18:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:18:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 957 @ 46581 updates, score 14.219) (writing took 2.319105362519622 seconds)
2022-03-08 01:18:29 | INFO | fairseq_cli.train | end of epoch 957 (average epoch stats below)
2022-03-08 01:18:29 | INFO | train | epoch 957 | loss 0.639 | nll_loss 0.116 | ppl 1.08 | wps 22986.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 46581 | lr 0.00014652 | gnorm 0.269 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 130559
2022-03-08 01:18:29 | INFO | fairseq.trainer | begin training epoch 958
2022-03-08 01:18:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:19:19 | INFO | train_inner | epoch 958:     19 / 49 loss=0.639, nll_loss=0.117, ppl=1.08, wps=23271.5, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=46600, lr=0.00014649, gnorm=0.268, loss_scale=64, train_wall=238, gb_free=8.8, wall=130609
2022-03-08 01:20:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:20:41 | INFO | valid | epoch 958 | valid on 'valid' subset | loss 14.219 | nll_loss 14.047 | ppl 16923.1 | wps 41978.5 | wpb 510.9 | bsz 1 | num_updates 46630 | best_loss 8.318
2022-03-08 01:20:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 958 @ 46630 updates
2022-03-08 01:20:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:20:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:20:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 958 @ 46630 updates, score 14.219) (writing took 2.446678802371025 seconds)
2022-03-08 01:20:44 | INFO | fairseq_cli.train | end of epoch 958 (average epoch stats below)
2022-03-08 01:20:44 | INFO | train | epoch 958 | loss 0.639 | nll_loss 0.116 | ppl 1.08 | wps 23521.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 46630 | lr 0.000146443 | gnorm 0.267 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 130694
2022-03-08 01:20:44 | INFO | fairseq.trainer | begin training epoch 959
2022-03-08 01:20:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:22:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:22:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:22:57 | INFO | valid | epoch 959 | valid on 'valid' subset | loss 14.232 | nll_loss 14.061 | ppl 17090 | wps 41825.1 | wpb 510.9 | bsz 1 | num_updates 46678 | best_loss 8.318
2022-03-08 01:22:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 959 @ 46678 updates
2022-03-08 01:22:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:22:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:22:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 959 @ 46678 updates, score 14.232) (writing took 2.3353973031044006 seconds)
2022-03-08 01:22:59 | INFO | fairseq_cli.train | end of epoch 959 (average epoch stats below)
2022-03-08 01:22:59 | INFO | train | epoch 959 | loss 0.639 | nll_loss 0.116 | ppl 1.08 | wps 23021.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 46678 | lr 0.000146367 | gnorm 0.268 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 130829
2022-03-08 01:22:59 | INFO | fairseq.trainer | begin training epoch 960
2022-03-08 01:22:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:23:57 | INFO | train_inner | epoch 960:     22 / 49 loss=0.639, nll_loss=0.116, ppl=1.08, wps=23304.9, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=46700, lr=0.000146333, gnorm=0.268, loss_scale=64, train_wall=238, gb_free=8.8, wall=130887
2022-03-08 01:25:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:25:12 | INFO | valid | epoch 960 | valid on 'valid' subset | loss 14.254 | nll_loss 14.083 | ppl 17358.6 | wps 41977.7 | wpb 510.9 | bsz 1 | num_updates 46727 | best_loss 8.318
2022-03-08 01:25:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 960 @ 46727 updates
2022-03-08 01:25:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:25:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:25:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 960 @ 46727 updates, score 14.254) (writing took 2.491693304851651 seconds)
2022-03-08 01:25:14 | INFO | fairseq_cli.train | end of epoch 960 (average epoch stats below)
2022-03-08 01:25:14 | INFO | train | epoch 960 | loss 0.639 | nll_loss 0.116 | ppl 1.08 | wps 23460 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 46727 | lr 0.00014629 | gnorm 0.269 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 130965
2022-03-08 01:25:14 | INFO | fairseq.trainer | begin training epoch 961
2022-03-08 01:25:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:27:27 | INFO | valid | epoch 961 | valid on 'valid' subset | loss 14.248 | nll_loss 14.078 | ppl 17289.8 | wps 41179.9 | wpb 510.9 | bsz 1 | num_updates 46776 | best_loss 8.318
2022-03-08 01:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 961 @ 46776 updates
2022-03-08 01:27:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:27:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:27:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 961 @ 46776 updates, score 14.248) (writing took 2.3500514682382345 seconds)
2022-03-08 01:27:30 | INFO | fairseq_cli.train | end of epoch 961 (average epoch stats below)
2022-03-08 01:27:30 | INFO | train | epoch 961 | loss 0.639 | nll_loss 0.117 | ppl 1.08 | wps 23499.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 46776 | lr 0.000146214 | gnorm 0.269 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 131100
2022-03-08 01:27:30 | INFO | fairseq.trainer | begin training epoch 962
2022-03-08 01:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:28:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:28:35 | INFO | train_inner | epoch 962:     25 / 49 loss=0.639, nll_loss=0.116, ppl=1.08, wps=23296.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=46800, lr=0.000146176, gnorm=0.269, loss_scale=64, train_wall=238, gb_free=8.8, wall=131166
2022-03-08 01:29:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:29:42 | INFO | valid | epoch 962 | valid on 'valid' subset | loss 14.246 | nll_loss 14.076 | ppl 17269.6 | wps 41949.9 | wpb 510.9 | bsz 1 | num_updates 46824 | best_loss 8.318
2022-03-08 01:29:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 962 @ 46824 updates
2022-03-08 01:29:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:29:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:29:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 962 @ 46824 updates, score 14.246) (writing took 2.4360732436180115 seconds)
2022-03-08 01:29:45 | INFO | fairseq_cli.train | end of epoch 962 (average epoch stats below)
2022-03-08 01:29:45 | INFO | train | epoch 962 | loss 0.639 | nll_loss 0.116 | ppl 1.08 | wps 23016.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 46824 | lr 0.000146139 | gnorm 0.27 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 131235
2022-03-08 01:29:45 | INFO | fairseq.trainer | begin training epoch 963
2022-03-08 01:29:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:31:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:31:58 | INFO | valid | epoch 963 | valid on 'valid' subset | loss 14.249 | nll_loss 14.079 | ppl 17304.5 | wps 42035.2 | wpb 510.9 | bsz 1 | num_updates 46873 | best_loss 8.318
2022-03-08 01:31:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 963 @ 46873 updates
2022-03-08 01:31:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:32:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:32:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 963 @ 46873 updates, score 14.249) (writing took 2.3494142591953278 seconds)
2022-03-08 01:32:00 | INFO | fairseq_cli.train | end of epoch 963 (average epoch stats below)
2022-03-08 01:32:00 | INFO | train | epoch 963 | loss 0.639 | nll_loss 0.116 | ppl 1.08 | wps 23485.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 46873 | lr 0.000146062 | gnorm 0.265 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 131370
2022-03-08 01:32:00 | INFO | fairseq.trainer | begin training epoch 964
2022-03-08 01:32:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:32:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:33:14 | INFO | train_inner | epoch 964:     28 / 49 loss=0.639, nll_loss=0.116, ppl=1.08, wps=23291.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=46900, lr=0.00014602, gnorm=0.268, loss_scale=32, train_wall=238, gb_free=8.8, wall=131444
2022-03-08 01:34:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:34:13 | INFO | valid | epoch 964 | valid on 'valid' subset | loss 14.203 | nll_loss 14.032 | ppl 16750.2 | wps 42194.6 | wpb 510.9 | bsz 1 | num_updates 46921 | best_loss 8.318
2022-03-08 01:34:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 964 @ 46921 updates
2022-03-08 01:34:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:34:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:34:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 964 @ 46921 updates, score 14.203) (writing took 2.502380609512329 seconds)
2022-03-08 01:34:16 | INFO | fairseq_cli.train | end of epoch 964 (average epoch stats below)
2022-03-08 01:34:16 | INFO | train | epoch 964 | loss 0.639 | nll_loss 0.117 | ppl 1.08 | wps 22991.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 46921 | lr 0.000145988 | gnorm 0.272 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 131506
2022-03-08 01:34:16 | INFO | fairseq.trainer | begin training epoch 965
2022-03-08 01:34:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:36:29 | INFO | valid | epoch 965 | valid on 'valid' subset | loss 14.175 | nll_loss 14.004 | ppl 16427.8 | wps 41649.8 | wpb 510.9 | bsz 1 | num_updates 46970 | best_loss 8.318
2022-03-08 01:36:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 965 @ 46970 updates
2022-03-08 01:36:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:36:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:36:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 965 @ 46970 updates, score 14.175) (writing took 2.343140173703432 seconds)
2022-03-08 01:36:31 | INFO | fairseq_cli.train | end of epoch 965 (average epoch stats below)
2022-03-08 01:36:31 | INFO | train | epoch 965 | loss 0.639 | nll_loss 0.117 | ppl 1.08 | wps 23473.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 46970 | lr 0.000145912 | gnorm 0.269 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 131641
2022-03-08 01:36:31 | INFO | fairseq.trainer | begin training epoch 966
2022-03-08 01:36:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:37:50 | INFO | train_inner | epoch 966:     30 / 49 loss=0.639, nll_loss=0.116, ppl=1.08, wps=23499.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=47000, lr=0.000145865, gnorm=0.268, loss_scale=32, train_wall=236, gb_free=8.8, wall=131720
2022-03-08 01:38:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:38:44 | INFO | valid | epoch 966 | valid on 'valid' subset | loss 14.235 | nll_loss 14.065 | ppl 17141.8 | wps 42229.7 | wpb 510.9 | bsz 1 | num_updates 47019 | best_loss 8.318
2022-03-08 01:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 966 @ 47019 updates
2022-03-08 01:38:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:38:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:38:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 966 @ 47019 updates, score 14.235) (writing took 2.4575871750712395 seconds)
2022-03-08 01:38:46 | INFO | fairseq_cli.train | end of epoch 966 (average epoch stats below)
2022-03-08 01:38:46 | INFO | train | epoch 966 | loss 0.638 | nll_loss 0.116 | ppl 1.08 | wps 23460.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47019 | lr 0.000145836 | gnorm 0.269 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 131777
2022-03-08 01:38:46 | INFO | fairseq.trainer | begin training epoch 967
2022-03-08 01:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:40:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:40:59 | INFO | valid | epoch 967 | valid on 'valid' subset | loss 14.306 | nll_loss 14.137 | ppl 18020.7 | wps 41792.9 | wpb 510.9 | bsz 1 | num_updates 47068 | best_loss 8.318
2022-03-08 01:40:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 967 @ 47068 updates
2022-03-08 01:40:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:41:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:41:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 967 @ 47068 updates, score 14.306) (writing took 2.318965796381235 seconds)
2022-03-08 01:41:02 | INFO | fairseq_cli.train | end of epoch 967 (average epoch stats below)
2022-03-08 01:41:02 | INFO | train | epoch 967 | loss 0.638 | nll_loss 0.116 | ppl 1.08 | wps 23518.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47068 | lr 0.00014576 | gnorm 0.267 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 131912
2022-03-08 01:41:02 | INFO | fairseq.trainer | begin training epoch 968
2022-03-08 01:41:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:42:26 | INFO | train_inner | epoch 968:     32 / 49 loss=0.638, nll_loss=0.116, ppl=1.08, wps=23524.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=47100, lr=0.00014571, gnorm=0.268, loss_scale=64, train_wall=236, gb_free=8.8, wall=131996
2022-03-08 01:43:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:43:14 | INFO | valid | epoch 968 | valid on 'valid' subset | loss 14.173 | nll_loss 14.001 | ppl 16396.5 | wps 41255.2 | wpb 510.9 | bsz 1 | num_updates 47117 | best_loss 8.318
2022-03-08 01:43:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 968 @ 47117 updates
2022-03-08 01:43:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:43:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:43:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 968 @ 47117 updates, score 14.173) (writing took 2.4470595326274633 seconds)
2022-03-08 01:43:17 | INFO | fairseq_cli.train | end of epoch 968 (average epoch stats below)
2022-03-08 01:43:17 | INFO | train | epoch 968 | loss 0.638 | nll_loss 0.116 | ppl 1.08 | wps 23468.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47117 | lr 0.000145684 | gnorm 0.267 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 132047
2022-03-08 01:43:17 | INFO | fairseq.trainer | begin training epoch 969
2022-03-08 01:43:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:44:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:45:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:45:30 | INFO | valid | epoch 969 | valid on 'valid' subset | loss 14.198 | nll_loss 14.025 | ppl 16671 | wps 41765.5 | wpb 510.9 | bsz 1 | num_updates 47165 | best_loss 8.318
2022-03-08 01:45:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 969 @ 47165 updates
2022-03-08 01:45:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:45:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:45:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 969 @ 47165 updates, score 14.198) (writing took 2.331895375624299 seconds)
2022-03-08 01:45:32 | INFO | fairseq_cli.train | end of epoch 969 (average epoch stats below)
2022-03-08 01:45:32 | INFO | train | epoch 969 | loss 0.638 | nll_loss 0.116 | ppl 1.08 | wps 23014.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 47165 | lr 0.00014561 | gnorm 0.268 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 132182
2022-03-08 01:45:32 | INFO | fairseq.trainer | begin training epoch 970
2022-03-08 01:45:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:47:04 | INFO | train_inner | epoch 970:     35 / 49 loss=0.638, nll_loss=0.116, ppl=1.08, wps=23297.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=47200, lr=0.000145556, gnorm=0.268, loss_scale=64, train_wall=238, gb_free=8.8, wall=132274
2022-03-08 01:47:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:47:45 | INFO | valid | epoch 970 | valid on 'valid' subset | loss 14.222 | nll_loss 14.051 | ppl 16978.9 | wps 42064.7 | wpb 510.9 | bsz 1 | num_updates 47214 | best_loss 8.318
2022-03-08 01:47:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 970 @ 47214 updates
2022-03-08 01:47:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:47:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:47:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 970 @ 47214 updates, score 14.222) (writing took 2.456333978101611 seconds)
2022-03-08 01:47:47 | INFO | fairseq_cli.train | end of epoch 970 (average epoch stats below)
2022-03-08 01:47:47 | INFO | train | epoch 970 | loss 0.638 | nll_loss 0.116 | ppl 1.08 | wps 23497.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47214 | lr 0.000145534 | gnorm 0.267 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 132318
2022-03-08 01:47:47 | INFO | fairseq.trainer | begin training epoch 971
2022-03-08 01:47:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:49:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:50:00 | INFO | valid | epoch 971 | valid on 'valid' subset | loss 14.123 | nll_loss 13.951 | ppl 15832.3 | wps 42280.8 | wpb 510.9 | bsz 1 | num_updates 47263 | best_loss 8.318
2022-03-08 01:50:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 971 @ 47263 updates
2022-03-08 01:50:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:50:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:50:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 971 @ 47263 updates, score 14.123) (writing took 2.327153453603387 seconds)
2022-03-08 01:50:02 | INFO | fairseq_cli.train | end of epoch 971 (average epoch stats below)
2022-03-08 01:50:02 | INFO | train | epoch 971 | loss 0.638 | nll_loss 0.115 | ppl 1.08 | wps 23531.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47263 | lr 0.000145459 | gnorm 0.267 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 132453
2022-03-08 01:50:03 | INFO | fairseq.trainer | begin training epoch 972
2022-03-08 01:50:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:50:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:51:42 | INFO | train_inner | epoch 972:     38 / 49 loss=0.638, nll_loss=0.116, ppl=1.08, wps=23318.8, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=47300, lr=0.000145402, gnorm=0.267, loss_scale=64, train_wall=238, gb_free=8.8, wall=132553
2022-03-08 01:52:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:52:15 | INFO | valid | epoch 972 | valid on 'valid' subset | loss 14.133 | nll_loss 13.962 | ppl 15952.7 | wps 42177.2 | wpb 510.9 | bsz 1 | num_updates 47311 | best_loss 8.318
2022-03-08 01:52:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 972 @ 47311 updates
2022-03-08 01:52:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:52:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:52:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 972 @ 47311 updates, score 14.133) (writing took 2.477686895057559 seconds)
2022-03-08 01:52:18 | INFO | fairseq_cli.train | end of epoch 972 (average epoch stats below)
2022-03-08 01:52:18 | INFO | train | epoch 972 | loss 0.638 | nll_loss 0.116 | ppl 1.08 | wps 23005.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 47311 | lr 0.000145385 | gnorm 0.266 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 132588
2022-03-08 01:52:18 | INFO | fairseq.trainer | begin training epoch 973
2022-03-08 01:52:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:54:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:54:31 | INFO | valid | epoch 973 | valid on 'valid' subset | loss 14.177 | nll_loss 14.005 | ppl 16441 | wps 42139.1 | wpb 510.9 | bsz 1 | num_updates 47360 | best_loss 8.318
2022-03-08 01:54:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 973 @ 47360 updates
2022-03-08 01:54:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:54:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:54:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 973 @ 47360 updates, score 14.177) (writing took 2.355462422594428 seconds)
2022-03-08 01:54:33 | INFO | fairseq_cli.train | end of epoch 973 (average epoch stats below)
2022-03-08 01:54:33 | INFO | train | epoch 973 | loss 0.638 | nll_loss 0.115 | ppl 1.08 | wps 23501 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47360 | lr 0.00014531 | gnorm 0.267 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 132723
2022-03-08 01:54:33 | INFO | fairseq.trainer | begin training epoch 974
2022-03-08 01:54:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:56:18 | INFO | train_inner | epoch 974:     40 / 49 loss=0.638, nll_loss=0.116, ppl=1.08, wps=23505.3, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=47400, lr=0.000145248, gnorm=0.268, loss_scale=64, train_wall=236, gb_free=8.8, wall=132829
2022-03-08 01:56:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:56:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:56:46 | INFO | valid | epoch 974 | valid on 'valid' subset | loss 14.251 | nll_loss 14.081 | ppl 17328.8 | wps 42130.3 | wpb 510.9 | bsz 1 | num_updates 47408 | best_loss 8.318
2022-03-08 01:56:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 974 @ 47408 updates
2022-03-08 01:56:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:56:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:56:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 974 @ 47408 updates, score 14.251) (writing took 2.4702016226947308 seconds)
2022-03-08 01:56:48 | INFO | fairseq_cli.train | end of epoch 974 (average epoch stats below)
2022-03-08 01:56:48 | INFO | train | epoch 974 | loss 0.638 | nll_loss 0.116 | ppl 1.08 | wps 22988.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 47408 | lr 0.000145236 | gnorm 0.269 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 132859
2022-03-08 01:56:48 | INFO | fairseq.trainer | begin training epoch 975
2022-03-08 01:56:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:58:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:59:01 | INFO | valid | epoch 975 | valid on 'valid' subset | loss 14.142 | nll_loss 13.97 | ppl 16042.9 | wps 42008.9 | wpb 510.9 | bsz 1 | num_updates 47457 | best_loss 8.318
2022-03-08 01:59:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 975 @ 47457 updates
2022-03-08 01:59:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:59:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:59:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 975 @ 47457 updates, score 14.142) (writing took 2.329819217324257 seconds)
2022-03-08 01:59:04 | INFO | fairseq_cli.train | end of epoch 975 (average epoch stats below)
2022-03-08 01:59:04 | INFO | train | epoch 975 | loss 0.638 | nll_loss 0.116 | ppl 1.08 | wps 23473.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47457 | lr 0.000145161 | gnorm 0.269 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 132994
2022-03-08 01:59:04 | INFO | fairseq.trainer | begin training epoch 976
2022-03-08 01:59:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:00:57 | INFO | train_inner | epoch 976:     43 / 49 loss=0.638, nll_loss=0.116, ppl=1.08, wps=23273.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=47500, lr=0.000145095, gnorm=0.268, loss_scale=64, train_wall=238, gb_free=8.8, wall=133107
2022-03-08 02:01:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:01:17 | INFO | valid | epoch 976 | valid on 'valid' subset | loss 14.215 | nll_loss 14.044 | ppl 16893.6 | wps 42084.6 | wpb 510.9 | bsz 1 | num_updates 47506 | best_loss 8.318
2022-03-08 02:01:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 976 @ 47506 updates
2022-03-08 02:01:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:01:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:01:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 976 @ 47506 updates, score 14.215) (writing took 2.4453851487487555 seconds)
2022-03-08 02:01:19 | INFO | fairseq_cli.train | end of epoch 976 (average epoch stats below)
2022-03-08 02:01:19 | INFO | train | epoch 976 | loss 0.638 | nll_loss 0.116 | ppl 1.08 | wps 23458.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47506 | lr 0.000145086 | gnorm 0.268 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 133130
2022-03-08 02:01:19 | INFO | fairseq.trainer | begin training epoch 977
2022-03-08 02:01:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:02:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:03:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:03:32 | INFO | valid | epoch 977 | valid on 'valid' subset | loss 14.253 | nll_loss 14.083 | ppl 17357.5 | wps 41754.4 | wpb 510.9 | bsz 1 | num_updates 47554 | best_loss 8.318
2022-03-08 02:03:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 977 @ 47554 updates
2022-03-08 02:03:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:03:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:03:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 977 @ 47554 updates, score 14.253) (writing took 2.323047263547778 seconds)
2022-03-08 02:03:35 | INFO | fairseq_cli.train | end of epoch 977 (average epoch stats below)
2022-03-08 02:03:35 | INFO | train | epoch 977 | loss 0.638 | nll_loss 0.115 | ppl 1.08 | wps 22999 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 47554 | lr 0.000145013 | gnorm 0.271 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 133265
2022-03-08 02:03:35 | INFO | fairseq.trainer | begin training epoch 978
2022-03-08 02:03:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:05:36 | INFO | train_inner | epoch 978:     46 / 49 loss=0.638, nll_loss=0.115, ppl=1.08, wps=23283.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=47600, lr=0.000144943, gnorm=0.268, loss_scale=64, train_wall=238, gb_free=8.8, wall=133386
2022-03-08 02:05:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:05:47 | INFO | valid | epoch 978 | valid on 'valid' subset | loss 14.147 | nll_loss 13.974 | ppl 16092.4 | wps 42332 | wpb 510.9 | bsz 1 | num_updates 47603 | best_loss 8.318
2022-03-08 02:05:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 978 @ 47603 updates
2022-03-08 02:05:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:05:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:05:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 978 @ 47603 updates, score 14.147) (writing took 2.448229245841503 seconds)
2022-03-08 02:05:50 | INFO | fairseq_cli.train | end of epoch 978 (average epoch stats below)
2022-03-08 02:05:50 | INFO | train | epoch 978 | loss 0.637 | nll_loss 0.115 | ppl 1.08 | wps 23483.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47603 | lr 0.000144938 | gnorm 0.264 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 133400
2022-03-08 02:05:50 | INFO | fairseq.trainer | begin training epoch 979
2022-03-08 02:05:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:07:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:08:03 | INFO | valid | epoch 979 | valid on 'valid' subset | loss 14.251 | nll_loss 14.08 | ppl 17318.2 | wps 41882.7 | wpb 510.9 | bsz 1 | num_updates 47652 | best_loss 8.318
2022-03-08 02:08:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 979 @ 47652 updates
2022-03-08 02:08:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:08:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:08:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 979 @ 47652 updates, score 14.251) (writing took 2.38742321357131 seconds)
2022-03-08 02:08:05 | INFO | fairseq_cli.train | end of epoch 979 (average epoch stats below)
2022-03-08 02:08:05 | INFO | train | epoch 979 | loss 0.637 | nll_loss 0.115 | ppl 1.08 | wps 23481.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47652 | lr 0.000144864 | gnorm 0.267 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 133536
2022-03-08 02:08:05 | INFO | fairseq.trainer | begin training epoch 980
2022-03-08 02:08:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:08:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:10:13 | INFO | train_inner | epoch 980:     49 / 49 loss=0.637, nll_loss=0.115, ppl=1.08, wps=23308.9, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=47700, lr=0.000144791, gnorm=0.268, loss_scale=64, train_wall=237, gb_free=8.8, wall=133663
2022-03-08 02:10:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:10:18 | INFO | valid | epoch 980 | valid on 'valid' subset | loss 14.21 | nll_loss 14.039 | ppl 16833.5 | wps 42095.5 | wpb 510.9 | bsz 1 | num_updates 47700 | best_loss 8.318
2022-03-08 02:10:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 980 @ 47700 updates
2022-03-08 02:10:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:10:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:10:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 980 @ 47700 updates, score 14.21) (writing took 2.40969698689878 seconds)
2022-03-08 02:10:20 | INFO | fairseq_cli.train | end of epoch 980 (average epoch stats below)
2022-03-08 02:10:20 | INFO | train | epoch 980 | loss 0.637 | nll_loss 0.115 | ppl 1.08 | wps 23053.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 47700 | lr 0.000144791 | gnorm 0.267 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 133671
2022-03-08 02:10:20 | INFO | fairseq.trainer | begin training epoch 981
2022-03-08 02:10:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:12:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:12:33 | INFO | valid | epoch 981 | valid on 'valid' subset | loss 14.204 | nll_loss 14.033 | ppl 16760 | wps 42148.8 | wpb 510.9 | bsz 1 | num_updates 47749 | best_loss 8.318
2022-03-08 02:12:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 981 @ 47749 updates
2022-03-08 02:12:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:12:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 981 @ 47749 updates, score 14.204) (writing took 2.3897817712277174 seconds)
2022-03-08 02:12:36 | INFO | fairseq_cli.train | end of epoch 981 (average epoch stats below)
2022-03-08 02:12:36 | INFO | train | epoch 981 | loss 0.638 | nll_loss 0.116 | ppl 1.08 | wps 23506.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47749 | lr 0.000144716 | gnorm 0.269 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 133806
2022-03-08 02:12:36 | INFO | fairseq.trainer | begin training epoch 982
2022-03-08 02:12:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:14:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:14:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:14:48 | INFO | valid | epoch 982 | valid on 'valid' subset | loss 14.204 | nll_loss 14.034 | ppl 16773.8 | wps 42189.2 | wpb 510.9 | bsz 1 | num_updates 47797 | best_loss 8.318
2022-03-08 02:14:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 982 @ 47797 updates
2022-03-08 02:14:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:14:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:14:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 982 @ 47797 updates, score 14.204) (writing took 2.4493648279458284 seconds)
2022-03-08 02:14:51 | INFO | fairseq_cli.train | end of epoch 982 (average epoch stats below)
2022-03-08 02:14:51 | INFO | train | epoch 982 | loss 0.637 | nll_loss 0.115 | ppl 1.08 | wps 23003.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 47797 | lr 0.000144644 | gnorm 0.264 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 133941
2022-03-08 02:14:51 | INFO | fairseq.trainer | begin training epoch 983
2022-03-08 02:14:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:14:59 | INFO | train_inner | epoch 983:      3 / 49 loss=0.637, nll_loss=0.115, ppl=1.08, wps=22671.2, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=47800, lr=0.000144639, gnorm=0.267, loss_scale=64, train_wall=238, gb_free=8.8, wall=133949
2022-03-08 02:16:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:17:04 | INFO | valid | epoch 983 | valid on 'valid' subset | loss 14.194 | nll_loss 14.025 | ppl 16669.7 | wps 41933.3 | wpb 510.9 | bsz 1 | num_updates 47846 | best_loss 8.318
2022-03-08 02:17:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 983 @ 47846 updates
2022-03-08 02:17:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:17:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:17:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 983 @ 47846 updates, score 14.194) (writing took 2.380508728325367 seconds)
2022-03-08 02:17:06 | INFO | fairseq_cli.train | end of epoch 983 (average epoch stats below)
2022-03-08 02:17:06 | INFO | train | epoch 983 | loss 0.637 | nll_loss 0.115 | ppl 1.08 | wps 23501.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47846 | lr 0.00014457 | gnorm 0.268 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 134076
2022-03-08 02:17:06 | INFO | fairseq.trainer | begin training epoch 984
2022-03-08 02:17:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:19:19 | INFO | valid | epoch 984 | valid on 'valid' subset | loss 14.247 | nll_loss 14.077 | ppl 17285.5 | wps 42383.1 | wpb 510.9 | bsz 1 | num_updates 47895 | best_loss 8.318
2022-03-08 02:19:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 984 @ 47895 updates
2022-03-08 02:19:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:19:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:19:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 984 @ 47895 updates, score 14.247) (writing took 2.4482306987047195 seconds)
2022-03-08 02:19:21 | INFO | fairseq_cli.train | end of epoch 984 (average epoch stats below)
2022-03-08 02:19:21 | INFO | train | epoch 984 | loss 0.637 | nll_loss 0.115 | ppl 1.08 | wps 23480.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47895 | lr 0.000144496 | gnorm 0.265 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 134212
2022-03-08 02:19:21 | INFO | fairseq.trainer | begin training epoch 985
2022-03-08 02:19:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:19:35 | INFO | train_inner | epoch 985:      5 / 49 loss=0.637, nll_loss=0.115, ppl=1.08, wps=23517.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=47900, lr=0.000144488, gnorm=0.266, loss_scale=64, train_wall=236, gb_free=8.8, wall=134225
2022-03-08 02:20:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:21:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:21:34 | INFO | valid | epoch 985 | valid on 'valid' subset | loss 14.22 | nll_loss 14.05 | ppl 16961.1 | wps 42031 | wpb 510.9 | bsz 1 | num_updates 47943 | best_loss 8.318
2022-03-08 02:21:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 985 @ 47943 updates
2022-03-08 02:21:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:21:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:21:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 985 @ 47943 updates, score 14.22) (writing took 2.383308943361044 seconds)
2022-03-08 02:21:37 | INFO | fairseq_cli.train | end of epoch 985 (average epoch stats below)
2022-03-08 02:21:37 | INFO | train | epoch 985 | loss 0.637 | nll_loss 0.115 | ppl 1.08 | wps 23025.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 47943 | lr 0.000144423 | gnorm 0.266 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 134347
2022-03-08 02:21:37 | INFO | fairseq.trainer | begin training epoch 986
2022-03-08 02:21:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:23:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:23:50 | INFO | valid | epoch 986 | valid on 'valid' subset | loss 14.267 | nll_loss 14.098 | ppl 17540.6 | wps 41999.4 | wpb 510.9 | bsz 1 | num_updates 47992 | best_loss 8.318
2022-03-08 02:23:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 986 @ 47992 updates
2022-03-08 02:23:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:23:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:23:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 986 @ 47992 updates, score 14.267) (writing took 2.432033156976104 seconds)
2022-03-08 02:23:52 | INFO | fairseq_cli.train | end of epoch 986 (average epoch stats below)
2022-03-08 02:23:52 | INFO | train | epoch 986 | loss 0.637 | nll_loss 0.115 | ppl 1.08 | wps 23477.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47992 | lr 0.00014435 | gnorm 0.264 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 134482
2022-03-08 02:23:52 | INFO | fairseq.trainer | begin training epoch 987
2022-03-08 02:23:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:24:13 | INFO | train_inner | epoch 987:      8 / 49 loss=0.637, nll_loss=0.115, ppl=1.08, wps=23297.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=48000, lr=0.000144338, gnorm=0.265, loss_scale=64, train_wall=238, gb_free=8.8, wall=134503
2022-03-08 02:26:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:26:05 | INFO | valid | epoch 987 | valid on 'valid' subset | loss 14.158 | nll_loss 13.986 | ppl 16228.8 | wps 42060.4 | wpb 510.9 | bsz 1 | num_updates 48041 | best_loss 8.318
2022-03-08 02:26:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 987 @ 48041 updates
2022-03-08 02:26:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:26:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:26:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 987 @ 48041 updates, score 14.158) (writing took 2.394623475149274 seconds)
2022-03-08 02:26:07 | INFO | fairseq_cli.train | end of epoch 987 (average epoch stats below)
2022-03-08 02:26:07 | INFO | train | epoch 987 | loss 0.637 | nll_loss 0.115 | ppl 1.08 | wps 23481.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 48041 | lr 0.000144276 | gnorm 0.265 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 134618
2022-03-08 02:26:07 | INFO | fairseq.trainer | begin training epoch 988
2022-03-08 02:26:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:26:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:28:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:28:20 | INFO | valid | epoch 988 | valid on 'valid' subset | loss 14.201 | nll_loss 14.03 | ppl 16724 | wps 42151.4 | wpb 510.9 | bsz 1 | num_updates 48089 | best_loss 8.318
2022-03-08 02:28:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 988 @ 48089 updates
2022-03-08 02:28:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:28:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:28:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 988 @ 48089 updates, score 14.201) (writing took 2.409649197012186 seconds)
2022-03-08 02:28:23 | INFO | fairseq_cli.train | end of epoch 988 (average epoch stats below)
2022-03-08 02:28:23 | INFO | train | epoch 988 | loss 0.637 | nll_loss 0.115 | ppl 1.08 | wps 23016.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 48089 | lr 0.000144204 | gnorm 0.266 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 134753
2022-03-08 02:28:23 | INFO | fairseq.trainer | begin training epoch 989
2022-03-08 02:28:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:28:52 | INFO | train_inner | epoch 989:     11 / 49 loss=0.637, nll_loss=0.115, ppl=1.08, wps=23293.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=48100, lr=0.000144187, gnorm=0.265, loss_scale=64, train_wall=238, gb_free=8.8, wall=134782
2022-03-08 02:30:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:30:35 | INFO | valid | epoch 989 | valid on 'valid' subset | loss 14.182 | nll_loss 14.01 | ppl 16501.5 | wps 41872.6 | wpb 510.9 | bsz 1 | num_updates 48138 | best_loss 8.318
2022-03-08 02:30:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 989 @ 48138 updates
2022-03-08 02:30:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:30:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:30:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 989 @ 48138 updates, score 14.182) (writing took 2.362812679260969 seconds)
2022-03-08 02:30:38 | INFO | fairseq_cli.train | end of epoch 989 (average epoch stats below)
2022-03-08 02:30:38 | INFO | train | epoch 989 | loss 0.637 | nll_loss 0.115 | ppl 1.08 | wps 23485.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 48138 | lr 0.000144131 | gnorm 0.264 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 134888
2022-03-08 02:30:38 | INFO | fairseq.trainer | begin training epoch 990
2022-03-08 02:30:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:32:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:32:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:32:51 | INFO | valid | epoch 990 | valid on 'valid' subset | loss 14.131 | nll_loss 13.96 | ppl 15935 | wps 42031 | wpb 510.9 | bsz 1 | num_updates 48186 | best_loss 8.318
2022-03-08 02:32:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 990 @ 48186 updates
2022-03-08 02:32:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:32:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:32:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 990 @ 48186 updates, score 14.131) (writing took 2.446285320445895 seconds)
2022-03-08 02:32:53 | INFO | fairseq_cli.train | end of epoch 990 (average epoch stats below)
2022-03-08 02:32:53 | INFO | train | epoch 990 | loss 0.636 | nll_loss 0.115 | ppl 1.08 | wps 22976.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 48186 | lr 0.000144059 | gnorm 0.265 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 135024
2022-03-08 02:32:53 | INFO | fairseq.trainer | begin training epoch 991
2022-03-08 02:32:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:33:30 | INFO | train_inner | epoch 991:     14 / 49 loss=0.637, nll_loss=0.115, ppl=1.08, wps=23278.4, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=48200, lr=0.000144038, gnorm=0.265, loss_scale=64, train_wall=238, gb_free=8.8, wall=135061
2022-03-08 02:35:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:35:06 | INFO | valid | epoch 991 | valid on 'valid' subset | loss 14.161 | nll_loss 13.99 | ppl 16266.9 | wps 41952.8 | wpb 510.9 | bsz 1 | num_updates 48235 | best_loss 8.318
2022-03-08 02:35:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 991 @ 48235 updates
2022-03-08 02:35:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:35:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:35:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 991 @ 48235 updates, score 14.161) (writing took 2.3784203194081783 seconds)
2022-03-08 02:35:09 | INFO | fairseq_cli.train | end of epoch 991 (average epoch stats below)
2022-03-08 02:35:09 | INFO | train | epoch 991 | loss 0.637 | nll_loss 0.115 | ppl 1.08 | wps 23460.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 48235 | lr 0.000143986 | gnorm 0.266 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 135159
2022-03-08 02:35:09 | INFO | fairseq.trainer | begin training epoch 992
2022-03-08 02:35:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:37:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:37:22 | INFO | valid | epoch 992 | valid on 'valid' subset | loss 14.135 | nll_loss 13.963 | ppl 15963.6 | wps 42058.6 | wpb 510.9 | bsz 1 | num_updates 48284 | best_loss 8.318
2022-03-08 02:37:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 992 @ 48284 updates
2022-03-08 02:37:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:37:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:37:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 992 @ 48284 updates, score 14.135) (writing took 2.4429288841784 seconds)
2022-03-08 02:37:24 | INFO | fairseq_cli.train | end of epoch 992 (average epoch stats below)
2022-03-08 02:37:24 | INFO | train | epoch 992 | loss 0.637 | nll_loss 0.115 | ppl 1.08 | wps 23474.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 48284 | lr 0.000143912 | gnorm 0.267 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 135294
2022-03-08 02:37:24 | INFO | fairseq.trainer | begin training epoch 993
2022-03-08 02:37:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:38:06 | INFO | train_inner | epoch 993:     16 / 49 loss=0.637, nll_loss=0.115, ppl=1.08, wps=23506.4, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=48300, lr=0.000143889, gnorm=0.267, loss_scale=64, train_wall=236, gb_free=8.8, wall=135337
2022-03-08 02:38:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:39:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:39:37 | INFO | valid | epoch 993 | valid on 'valid' subset | loss 14.245 | nll_loss 14.077 | ppl 17280.4 | wps 42016 | wpb 510.9 | bsz 1 | num_updates 48332 | best_loss 8.318
2022-03-08 02:39:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 993 @ 48332 updates
2022-03-08 02:39:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:39:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:39:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 993 @ 48332 updates, score 14.245) (writing took 2.3082007355988026 seconds)
2022-03-08 02:39:39 | INFO | fairseq_cli.train | end of epoch 993 (average epoch stats below)
2022-03-08 02:39:39 | INFO | train | epoch 993 | loss 0.636 | nll_loss 0.115 | ppl 1.08 | wps 23033.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 48332 | lr 0.000143841 | gnorm 0.264 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 135430
2022-03-08 02:39:39 | INFO | fairseq.trainer | begin training epoch 994
2022-03-08 02:39:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:41:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:41:52 | INFO | valid | epoch 994 | valid on 'valid' subset | loss 14.182 | nll_loss 14.012 | ppl 16518 | wps 41739.9 | wpb 510.9 | bsz 1 | num_updates 48381 | best_loss 8.318
2022-03-08 02:41:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 994 @ 48381 updates
2022-03-08 02:41:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:41:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:41:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 994 @ 48381 updates, score 14.182) (writing took 2.464044861495495 seconds)
2022-03-08 02:41:55 | INFO | fairseq_cli.train | end of epoch 994 (average epoch stats below)
2022-03-08 02:41:55 | INFO | train | epoch 994 | loss 0.636 | nll_loss 0.115 | ppl 1.08 | wps 23465.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 48381 | lr 0.000143768 | gnorm 0.265 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 135565
2022-03-08 02:41:55 | INFO | fairseq.trainer | begin training epoch 995
2022-03-08 02:41:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:42:45 | INFO | train_inner | epoch 995:     19 / 49 loss=0.636, nll_loss=0.115, ppl=1.08, wps=23296.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=48400, lr=0.00014374, gnorm=0.263, loss_scale=64, train_wall=238, gb_free=8.8, wall=135615
2022-03-08 02:44:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:44:08 | INFO | valid | epoch 995 | valid on 'valid' subset | loss 14.257 | nll_loss 14.088 | ppl 17414.5 | wps 42146.3 | wpb 510.9 | bsz 1 | num_updates 48430 | best_loss 8.318
2022-03-08 02:44:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 995 @ 48430 updates
2022-03-08 02:44:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:44:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:44:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 995 @ 48430 updates, score 14.257) (writing took 2.447166159749031 seconds)
2022-03-08 02:44:10 | INFO | fairseq_cli.train | end of epoch 995 (average epoch stats below)
2022-03-08 02:44:10 | INFO | train | epoch 995 | loss 0.636 | nll_loss 0.115 | ppl 1.08 | wps 23488.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 48430 | lr 0.000143695 | gnorm 0.264 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 135700
2022-03-08 02:44:10 | INFO | fairseq.trainer | begin training epoch 996
2022-03-08 02:44:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:44:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:46:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:46:23 | INFO | valid | epoch 996 | valid on 'valid' subset | loss 14.147 | nll_loss 13.974 | ppl 16096.5 | wps 41961.8 | wpb 510.9 | bsz 1 | num_updates 48478 | best_loss 8.318
2022-03-08 02:46:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 996 @ 48478 updates
2022-03-08 02:46:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:46:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:46:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 996 @ 48478 updates, score 14.147) (writing took 2.4824233632534742 seconds)
2022-03-08 02:46:25 | INFO | fairseq_cli.train | end of epoch 996 (average epoch stats below)
2022-03-08 02:46:25 | INFO | train | epoch 996 | loss 0.636 | nll_loss 0.115 | ppl 1.08 | wps 23003 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 48478 | lr 0.000143624 | gnorm 0.267 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 135836
2022-03-08 02:46:25 | INFO | fairseq.trainer | begin training epoch 997
2022-03-08 02:46:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:47:23 | INFO | train_inner | epoch 997:     22 / 49 loss=0.637, nll_loss=0.115, ppl=1.08, wps=23282.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=48500, lr=0.000143592, gnorm=0.267, loss_scale=64, train_wall=238, gb_free=8.8, wall=135894
2022-03-08 02:48:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:48:38 | INFO | valid | epoch 997 | valid on 'valid' subset | loss 14.227 | nll_loss 14.057 | ppl 17048.8 | wps 42276.7 | wpb 510.9 | bsz 1 | num_updates 48527 | best_loss 8.318
2022-03-08 02:48:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 997 @ 48527 updates
2022-03-08 02:48:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:48:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:48:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 997 @ 48527 updates, score 14.227) (writing took 2.3916001208126545 seconds)
2022-03-08 02:48:41 | INFO | fairseq_cli.train | end of epoch 997 (average epoch stats below)
2022-03-08 02:48:41 | INFO | train | epoch 997 | loss 0.637 | nll_loss 0.115 | ppl 1.08 | wps 23486.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 48527 | lr 0.000143552 | gnorm 0.265 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 135971
2022-03-08 02:48:41 | INFO | fairseq.trainer | begin training epoch 998
2022-03-08 02:48:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:50:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:50:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:50:54 | INFO | valid | epoch 998 | valid on 'valid' subset | loss 14.188 | nll_loss 14.018 | ppl 16591.2 | wps 41604.2 | wpb 510.9 | bsz 1 | num_updates 48575 | best_loss 8.318
2022-03-08 02:50:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 998 @ 48575 updates
2022-03-08 02:50:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:50:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:50:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 998 @ 48575 updates, score 14.188) (writing took 2.449087666347623 seconds)
2022-03-08 02:50:56 | INFO | fairseq_cli.train | end of epoch 998 (average epoch stats below)
2022-03-08 02:50:56 | INFO | train | epoch 998 | loss 0.636 | nll_loss 0.115 | ppl 1.08 | wps 22997.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 48575 | lr 0.000143481 | gnorm 0.265 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 136106
2022-03-08 02:50:56 | INFO | fairseq.trainer | begin training epoch 999
2022-03-08 02:50:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:52:02 | INFO | train_inner | epoch 999:     25 / 49 loss=0.636, nll_loss=0.115, ppl=1.08, wps=23300.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=48600, lr=0.000143444, gnorm=0.264, loss_scale=64, train_wall=238, gb_free=8.8, wall=136172
2022-03-08 02:53:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:53:09 | INFO | valid | epoch 999 | valid on 'valid' subset | loss 14.132 | nll_loss 13.96 | ppl 15934.5 | wps 42038.4 | wpb 510.9 | bsz 1 | num_updates 48624 | best_loss 8.318
2022-03-08 02:53:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 999 @ 48624 updates
2022-03-08 02:53:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:53:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:53:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 999 @ 48624 updates, score 14.132) (writing took 2.3713842816650867 seconds)
2022-03-08 02:53:11 | INFO | fairseq_cli.train | end of epoch 999 (average epoch stats below)
2022-03-08 02:53:11 | INFO | train | epoch 999 | loss 0.636 | nll_loss 0.115 | ppl 1.08 | wps 23497.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 48624 | lr 0.000143408 | gnorm 0.265 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 136242
2022-03-08 02:53:11 | INFO | fairseq.trainer | begin training epoch 1000
2022-03-08 02:53:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:55:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:55:24 | INFO | valid | epoch 1000 | valid on 'valid' subset | loss 14.122 | nll_loss 13.949 | ppl 15815.4 | wps 41699.7 | wpb 510.9 | bsz 1 | num_updates 48673 | best_loss 8.318
2022-03-08 02:55:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1000 @ 48673 updates
2022-03-08 02:55:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:55:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:55:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1000 @ 48673 updates, score 14.122) (writing took 2.464620992541313 seconds)
2022-03-08 02:55:27 | INFO | fairseq_cli.train | end of epoch 1000 (average epoch stats below)
2022-03-08 02:55:27 | INFO | train | epoch 1000 | loss 0.636 | nll_loss 0.114 | ppl 1.08 | wps 23444.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 48673 | lr 0.000143336 | gnorm 0.265 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 136377
2022-03-08 02:55:27 | INFO | fairseq.trainer | begin training epoch 1001
2022-03-08 02:55:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:56:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:56:41 | INFO | train_inner | epoch 1001:     28 / 49 loss=0.636, nll_loss=0.114, ppl=1.08, wps=23261.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=48700, lr=0.000143296, gnorm=0.266, loss_scale=64, train_wall=238, gb_free=8.8, wall=136451
2022-03-08 02:57:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:57:40 | INFO | valid | epoch 1001 | valid on 'valid' subset | loss 14.252 | nll_loss 14.083 | ppl 17353.5 | wps 41775.2 | wpb 510.9 | bsz 1 | num_updates 48721 | best_loss 8.318
2022-03-08 02:57:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1001 @ 48721 updates
2022-03-08 02:57:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:57:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:57:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1001 @ 48721 updates, score 14.252) (writing took 2.3333406411111355 seconds)
2022-03-08 02:57:42 | INFO | fairseq_cli.train | end of epoch 1001 (average epoch stats below)
2022-03-08 02:57:42 | INFO | train | epoch 1001 | loss 0.636 | nll_loss 0.114 | ppl 1.08 | wps 22983.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 48721 | lr 0.000143266 | gnorm 0.266 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 136512
2022-03-08 02:57:42 | INFO | fairseq.trainer | begin training epoch 1002
2022-03-08 02:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:59:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:59:55 | INFO | valid | epoch 1002 | valid on 'valid' subset | loss 14.199 | nll_loss 14.03 | ppl 16731.6 | wps 41963.1 | wpb 510.9 | bsz 1 | num_updates 48770 | best_loss 8.318
2022-03-08 02:59:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1002 @ 48770 updates
2022-03-08 02:59:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:59:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:59:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1002 @ 48770 updates, score 14.199) (writing took 2.2734229918569326 seconds)
2022-03-08 02:59:57 | INFO | fairseq_cli.train | end of epoch 1002 (average epoch stats below)
2022-03-08 02:59:57 | INFO | train | epoch 1002 | loss 0.636 | nll_loss 0.114 | ppl 1.08 | wps 23495.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 48770 | lr 0.000143194 | gnorm 0.264 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 136648
2022-03-08 02:59:57 | INFO | fairseq.trainer | begin training epoch 1003
2022-03-08 02:59:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:01:16 | INFO | train_inner | epoch 1003:     30 / 49 loss=0.636, nll_loss=0.114, ppl=1.08, wps=23522.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=48800, lr=0.00014315, gnorm=0.264, loss_scale=64, train_wall=236, gb_free=8.8, wall=136727
2022-03-08 03:02:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:02:10 | INFO | valid | epoch 1003 | valid on 'valid' subset | loss 14.191 | nll_loss 14.02 | ppl 16614 | wps 42070.8 | wpb 510.9 | bsz 1 | num_updates 48819 | best_loss 8.318
2022-03-08 03:02:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1003 @ 48819 updates
2022-03-08 03:02:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:02:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:02:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1003 @ 48819 updates, score 14.191) (writing took 2.3302883449941874 seconds)
2022-03-08 03:02:13 | INFO | fairseq_cli.train | end of epoch 1003 (average epoch stats below)
2022-03-08 03:02:13 | INFO | train | epoch 1003 | loss 0.636 | nll_loss 0.114 | ppl 1.08 | wps 23530 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 48819 | lr 0.000143122 | gnorm 0.265 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 136783
2022-03-08 03:02:13 | INFO | fairseq.trainer | begin training epoch 1004
2022-03-08 03:02:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:02:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:04:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:04:25 | INFO | valid | epoch 1004 | valid on 'valid' subset | loss 14.215 | nll_loss 14.043 | ppl 16880.9 | wps 41929.8 | wpb 510.9 | bsz 1 | num_updates 48867 | best_loss 8.318
2022-03-08 03:04:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1004 @ 48867 updates
2022-03-08 03:04:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:04:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:04:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1004 @ 48867 updates, score 14.215) (writing took 2.2723619304597378 seconds)
2022-03-08 03:04:28 | INFO | fairseq_cli.train | end of epoch 1004 (average epoch stats below)
2022-03-08 03:04:28 | INFO | train | epoch 1004 | loss 0.636 | nll_loss 0.114 | ppl 1.08 | wps 23035.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 48867 | lr 0.000143051 | gnorm 0.267 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 136918
2022-03-08 03:04:28 | INFO | fairseq.trainer | begin training epoch 1005
2022-03-08 03:04:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:05:54 | INFO | train_inner | epoch 1005:     33 / 49 loss=0.635, nll_loss=0.114, ppl=1.08, wps=23332.4, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=48900, lr=0.000143003, gnorm=0.265, loss_scale=64, train_wall=238, gb_free=8.8, wall=137005
2022-03-08 03:06:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:06:40 | INFO | valid | epoch 1005 | valid on 'valid' subset | loss 14.184 | nll_loss 14.013 | ppl 16537.5 | wps 41957.7 | wpb 510.9 | bsz 1 | num_updates 48916 | best_loss 8.318
2022-03-08 03:06:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1005 @ 48916 updates
2022-03-08 03:06:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:06:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:06:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1005 @ 48916 updates, score 14.184) (writing took 2.366472451016307 seconds)
2022-03-08 03:06:43 | INFO | fairseq_cli.train | end of epoch 1005 (average epoch stats below)
2022-03-08 03:06:43 | INFO | train | epoch 1005 | loss 0.636 | nll_loss 0.114 | ppl 1.08 | wps 23506.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 48916 | lr 0.00014298 | gnorm 0.264 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 137053
2022-03-08 03:06:43 | INFO | fairseq.trainer | begin training epoch 1006
2022-03-08 03:06:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:08:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:08:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:08:56 | INFO | valid | epoch 1006 | valid on 'valid' subset | loss 14.237 | nll_loss 14.066 | ppl 17155.2 | wps 41182.4 | wpb 510.9 | bsz 1 | num_updates 48964 | best_loss 8.318
2022-03-08 03:08:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1006 @ 48964 updates
2022-03-08 03:08:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:08:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:08:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1006 @ 48964 updates, score 14.237) (writing took 2.4460272323340178 seconds)
2022-03-08 03:08:58 | INFO | fairseq_cli.train | end of epoch 1006 (average epoch stats below)
2022-03-08 03:08:58 | INFO | train | epoch 1006 | loss 0.635 | nll_loss 0.114 | ppl 1.08 | wps 22974.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 48964 | lr 0.00014291 | gnorm 0.263 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 137189
2022-03-08 03:08:58 | INFO | fairseq.trainer | begin training epoch 1007
2022-03-08 03:08:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:10:33 | INFO | train_inner | epoch 1007:     36 / 49 loss=0.635, nll_loss=0.114, ppl=1.08, wps=23288.9, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=49000, lr=0.000142857, gnorm=0.265, loss_scale=64, train_wall=238, gb_free=8.8, wall=137283
2022-03-08 03:11:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:11:11 | INFO | valid | epoch 1007 | valid on 'valid' subset | loss 14.18 | nll_loss 14.01 | ppl 16501.3 | wps 42258.3 | wpb 510.9 | bsz 1 | num_updates 49013 | best_loss 8.318
2022-03-08 03:11:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1007 @ 49013 updates
2022-03-08 03:11:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:11:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:11:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1007 @ 49013 updates, score 14.18) (writing took 2.7642333321273327 seconds)
2022-03-08 03:11:14 | INFO | fairseq_cli.train | end of epoch 1007 (average epoch stats below)
2022-03-08 03:11:14 | INFO | train | epoch 1007 | loss 0.635 | nll_loss 0.114 | ppl 1.08 | wps 23452.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49013 | lr 0.000142838 | gnorm 0.265 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 137324
2022-03-08 03:11:14 | INFO | fairseq.trainer | begin training epoch 1008
2022-03-08 03:11:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:13:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:13:27 | INFO | valid | epoch 1008 | valid on 'valid' subset | loss 14.321 | nll_loss 14.154 | ppl 18228.6 | wps 41550.5 | wpb 510.9 | bsz 1 | num_updates 49062 | best_loss 8.318
2022-03-08 03:13:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1008 @ 49062 updates
2022-03-08 03:13:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:13:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:13:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1008 @ 49062 updates, score 14.321) (writing took 2.415035165846348 seconds)
2022-03-08 03:13:29 | INFO | fairseq_cli.train | end of epoch 1008 (average epoch stats below)
2022-03-08 03:13:29 | INFO | train | epoch 1008 | loss 0.635 | nll_loss 0.114 | ppl 1.08 | wps 23466 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49062 | lr 0.000142767 | gnorm 0.261 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 137460
2022-03-08 03:13:29 | INFO | fairseq.trainer | begin training epoch 1009
2022-03-08 03:13:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:14:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:15:12 | INFO | train_inner | epoch 1009:     39 / 49 loss=0.635, nll_loss=0.114, ppl=1.08, wps=23262.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=49100, lr=0.000142712, gnorm=0.263, loss_scale=64, train_wall=238, gb_free=8.8, wall=137562
2022-03-08 03:15:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:15:42 | INFO | valid | epoch 1009 | valid on 'valid' subset | loss 14.184 | nll_loss 14.013 | ppl 16529.9 | wps 41543.6 | wpb 510.9 | bsz 1 | num_updates 49110 | best_loss 8.318
2022-03-08 03:15:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1009 @ 49110 updates
2022-03-08 03:15:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:15:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:15:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1009 @ 49110 updates, score 14.184) (writing took 2.3869534377008677 seconds)
2022-03-08 03:15:45 | INFO | fairseq_cli.train | end of epoch 1009 (average epoch stats below)
2022-03-08 03:15:45 | INFO | train | epoch 1009 | loss 0.635 | nll_loss 0.114 | ppl 1.08 | wps 23013.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 49110 | lr 0.000142697 | gnorm 0.264 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 137595
2022-03-08 03:15:45 | INFO | fairseq.trainer | begin training epoch 1010
2022-03-08 03:15:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:17:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:17:57 | INFO | valid | epoch 1010 | valid on 'valid' subset | loss 14.154 | nll_loss 13.983 | ppl 16191.6 | wps 41924.5 | wpb 510.9 | bsz 1 | num_updates 49159 | best_loss 8.318
2022-03-08 03:17:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1010 @ 49159 updates
2022-03-08 03:17:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:18:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:18:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1010 @ 49159 updates, score 14.154) (writing took 2.4469051398336887 seconds)
2022-03-08 03:18:00 | INFO | fairseq_cli.train | end of epoch 1010 (average epoch stats below)
2022-03-08 03:18:00 | INFO | train | epoch 1010 | loss 0.635 | nll_loss 0.114 | ppl 1.08 | wps 23469.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49159 | lr 0.000142626 | gnorm 0.263 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 137730
2022-03-08 03:18:00 | INFO | fairseq.trainer | begin training epoch 1011
2022-03-08 03:18:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:19:48 | INFO | train_inner | epoch 1011:     41 / 49 loss=0.635, nll_loss=0.114, ppl=1.08, wps=23500.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=49200, lr=0.000142566, gnorm=0.264, loss_scale=64, train_wall=236, gb_free=8.8, wall=137838
2022-03-08 03:20:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:20:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:20:13 | INFO | valid | epoch 1011 | valid on 'valid' subset | loss 14.282 | nll_loss 14.112 | ppl 17711.6 | wps 41910 | wpb 510.9 | bsz 1 | num_updates 49207 | best_loss 8.318
2022-03-08 03:20:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1011 @ 49207 updates
2022-03-08 03:20:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:20:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:20:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1011 @ 49207 updates, score 14.282) (writing took 2.343341764062643 seconds)
2022-03-08 03:20:15 | INFO | fairseq_cli.train | end of epoch 1011 (average epoch stats below)
2022-03-08 03:20:15 | INFO | train | epoch 1011 | loss 0.635 | nll_loss 0.114 | ppl 1.08 | wps 23002.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 49207 | lr 0.000142556 | gnorm 0.267 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 137866
2022-03-08 03:20:15 | INFO | fairseq.trainer | begin training epoch 1012
2022-03-08 03:20:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:22:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:22:28 | INFO | valid | epoch 1012 | valid on 'valid' subset | loss 14.172 | nll_loss 14 | ppl 16388.6 | wps 41330 | wpb 510.9 | bsz 1 | num_updates 49256 | best_loss 8.318
2022-03-08 03:22:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1012 @ 49256 updates
2022-03-08 03:22:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:22:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:22:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1012 @ 49256 updates, score 14.172) (writing took 2.4476870391517878 seconds)
2022-03-08 03:22:31 | INFO | fairseq_cli.train | end of epoch 1012 (average epoch stats below)
2022-03-08 03:22:31 | INFO | train | epoch 1012 | loss 0.635 | nll_loss 0.114 | ppl 1.08 | wps 23488.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49256 | lr 0.000142485 | gnorm 0.264 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 138001
2022-03-08 03:22:31 | INFO | fairseq.trainer | begin training epoch 1013
2022-03-08 03:22:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:24:26 | INFO | train_inner | epoch 1013:     44 / 49 loss=0.635, nll_loss=0.114, ppl=1.08, wps=23287.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=49300, lr=0.000142422, gnorm=0.264, loss_scale=64, train_wall=238, gb_free=8.8, wall=138117
2022-03-08 03:24:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:24:44 | INFO | valid | epoch 1013 | valid on 'valid' subset | loss 14.228 | nll_loss 14.059 | ppl 17069.3 | wps 42056 | wpb 510.9 | bsz 1 | num_updates 49305 | best_loss 8.318
2022-03-08 03:24:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1013 @ 49305 updates
2022-03-08 03:24:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:24:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:24:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1013 @ 49305 updates, score 14.228) (writing took 2.3298613149672747 seconds)
2022-03-08 03:24:46 | INFO | fairseq_cli.train | end of epoch 1013 (average epoch stats below)
2022-03-08 03:24:46 | INFO | train | epoch 1013 | loss 0.635 | nll_loss 0.113 | ppl 1.08 | wps 23484.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49305 | lr 0.000142415 | gnorm 0.263 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 138136
2022-03-08 03:24:46 | INFO | fairseq.trainer | begin training epoch 1014
2022-03-08 03:24:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:26:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:26:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:26:59 | INFO | valid | epoch 1014 | valid on 'valid' subset | loss 14.168 | nll_loss 13.998 | ppl 16363.1 | wps 41477.6 | wpb 510.9 | bsz 1 | num_updates 49353 | best_loss 8.318
2022-03-08 03:26:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1014 @ 49353 updates
2022-03-08 03:26:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:27:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:27:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1014 @ 49353 updates, score 14.168) (writing took 2.414615496993065 seconds)
2022-03-08 03:27:01 | INFO | fairseq_cli.train | end of epoch 1014 (average epoch stats below)
2022-03-08 03:27:01 | INFO | train | epoch 1014 | loss 0.635 | nll_loss 0.114 | ppl 1.08 | wps 23020.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 49353 | lr 0.000142345 | gnorm 0.264 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 138271
2022-03-08 03:27:01 | INFO | fairseq.trainer | begin training epoch 1015
2022-03-08 03:27:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:29:05 | INFO | train_inner | epoch 1015:     47 / 49 loss=0.635, nll_loss=0.113, ppl=1.08, wps=23303.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=49400, lr=0.000142278, gnorm=0.263, loss_scale=64, train_wall=238, gb_free=8.8, wall=138395
2022-03-08 03:29:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:29:14 | INFO | valid | epoch 1015 | valid on 'valid' subset | loss 14.175 | nll_loss 14.006 | ppl 16448.9 | wps 41367.6 | wpb 510.9 | bsz 1 | num_updates 49402 | best_loss 8.318
2022-03-08 03:29:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1015 @ 49402 updates
2022-03-08 03:29:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:29:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:29:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1015 @ 49402 updates, score 14.175) (writing took 2.367143465206027 seconds)
2022-03-08 03:29:17 | INFO | fairseq_cli.train | end of epoch 1015 (average epoch stats below)
2022-03-08 03:29:17 | INFO | train | epoch 1015 | loss 0.634 | nll_loss 0.113 | ppl 1.08 | wps 23462.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49402 | lr 0.000142275 | gnorm 0.262 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 138407
2022-03-08 03:29:17 | INFO | fairseq.trainer | begin training epoch 1016
2022-03-08 03:29:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:31:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:31:29 | INFO | valid | epoch 1016 | valid on 'valid' subset | loss 14.286 | nll_loss 14.117 | ppl 17771.5 | wps 41927.4 | wpb 510.9 | bsz 1 | num_updates 49451 | best_loss 8.318
2022-03-08 03:31:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1016 @ 49451 updates
2022-03-08 03:31:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:31:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:31:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1016 @ 49451 updates, score 14.286) (writing took 2.438282309100032 seconds)
2022-03-08 03:31:32 | INFO | fairseq_cli.train | end of epoch 1016 (average epoch stats below)
2022-03-08 03:31:32 | INFO | train | epoch 1016 | loss 0.635 | nll_loss 0.114 | ppl 1.08 | wps 23501 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49451 | lr 0.000142204 | gnorm 0.264 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 138542
2022-03-08 03:31:32 | INFO | fairseq.trainer | begin training epoch 1017
2022-03-08 03:31:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:32:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:33:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:33:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:33:45 | INFO | valid | epoch 1017 | valid on 'valid' subset | loss 14.188 | nll_loss 14.017 | ppl 16574.6 | wps 42104.2 | wpb 510.9 | bsz 1 | num_updates 49498 | best_loss 8.318
2022-03-08 03:33:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1017 @ 49498 updates
2022-03-08 03:33:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:33:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:33:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1017 @ 49498 updates, score 14.188) (writing took 2.345584958791733 seconds)
2022-03-08 03:33:47 | INFO | fairseq_cli.train | end of epoch 1017 (average epoch stats below)
2022-03-08 03:33:47 | INFO | train | epoch 1017 | loss 0.634 | nll_loss 0.113 | ppl 1.08 | wps 22535.3 | ups 0.35 | wpb 64829.4 | bsz 126.6 | num_updates 49498 | lr 0.000142137 | gnorm 0.264 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 138677
2022-03-08 03:33:47 | INFO | fairseq.trainer | begin training epoch 1018
2022-03-08 03:33:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:33:52 | INFO | train_inner | epoch 1018:      2 / 49 loss=0.634, nll_loss=0.113, ppl=1.08, wps=22452.1, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=49500, lr=0.000142134, gnorm=0.265, loss_scale=32, train_wall=239, gb_free=8.8, wall=138683
2022-03-08 03:35:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:36:00 | INFO | valid | epoch 1018 | valid on 'valid' subset | loss 14.195 | nll_loss 14.024 | ppl 16658.8 | wps 42086.8 | wpb 510.9 | bsz 1 | num_updates 49547 | best_loss 8.318
2022-03-08 03:36:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1018 @ 49547 updates
2022-03-08 03:36:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:36:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:36:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1018 @ 49547 updates, score 14.195) (writing took 2.429276680573821 seconds)
2022-03-08 03:36:02 | INFO | fairseq_cli.train | end of epoch 1018 (average epoch stats below)
2022-03-08 03:36:02 | INFO | train | epoch 1018 | loss 0.635 | nll_loss 0.113 | ppl 1.08 | wps 23477.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49547 | lr 0.000142066 | gnorm 0.265 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 138813
2022-03-08 03:36:02 | INFO | fairseq.trainer | begin training epoch 1019
2022-03-08 03:36:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:38:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:38:15 | INFO | valid | epoch 1019 | valid on 'valid' subset | loss 14.15 | nll_loss 13.978 | ppl 16141.6 | wps 41904.1 | wpb 510.9 | bsz 1 | num_updates 49596 | best_loss 8.318
2022-03-08 03:38:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1019 @ 49596 updates
2022-03-08 03:38:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:38:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:38:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1019 @ 49596 updates, score 14.15) (writing took 2.338790288195014 seconds)
2022-03-08 03:38:18 | INFO | fairseq_cli.train | end of epoch 1019 (average epoch stats below)
2022-03-08 03:38:18 | INFO | train | epoch 1019 | loss 0.634 | nll_loss 0.113 | ppl 1.08 | wps 23495.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49596 | lr 0.000141996 | gnorm 0.262 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 138948
2022-03-08 03:38:18 | INFO | fairseq.trainer | begin training epoch 1020
2022-03-08 03:38:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:38:28 | INFO | train_inner | epoch 1020:      4 / 49 loss=0.634, nll_loss=0.113, ppl=1.08, wps=23511.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=49600, lr=0.00014199, gnorm=0.263, loss_scale=32, train_wall=236, gb_free=8.8, wall=138959
2022-03-08 03:40:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:40:31 | INFO | valid | epoch 1020 | valid on 'valid' subset | loss 14.185 | nll_loss 14.014 | ppl 16549.5 | wps 42223.6 | wpb 510.9 | bsz 1 | num_updates 49645 | best_loss 8.318
2022-03-08 03:40:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1020 @ 49645 updates
2022-03-08 03:40:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:40:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:40:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1020 @ 49645 updates, score 14.185) (writing took 2.430891675874591 seconds)
2022-03-08 03:40:33 | INFO | fairseq_cli.train | end of epoch 1020 (average epoch stats below)
2022-03-08 03:40:33 | INFO | train | epoch 1020 | loss 0.635 | nll_loss 0.114 | ppl 1.08 | wps 23466.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49645 | lr 0.000141926 | gnorm 0.265 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 139083
2022-03-08 03:40:33 | INFO | fairseq.trainer | begin training epoch 1021
2022-03-08 03:40:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:42:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:42:46 | INFO | valid | epoch 1021 | valid on 'valid' subset | loss 14.156 | nll_loss 13.986 | ppl 16223.2 | wps 42137.7 | wpb 510.9 | bsz 1 | num_updates 49694 | best_loss 8.318
2022-03-08 03:42:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1021 @ 49694 updates
2022-03-08 03:42:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:42:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:42:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1021 @ 49694 updates, score 14.156) (writing took 2.356349667534232 seconds)
2022-03-08 03:42:48 | INFO | fairseq_cli.train | end of epoch 1021 (average epoch stats below)
2022-03-08 03:42:48 | INFO | train | epoch 1021 | loss 0.635 | nll_loss 0.114 | ppl 1.08 | wps 23529.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49694 | lr 0.000141856 | gnorm 0.265 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 139218
2022-03-08 03:42:48 | INFO | fairseq.trainer | begin training epoch 1022
2022-03-08 03:42:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:43:04 | INFO | train_inner | epoch 1022:      6 / 49 loss=0.635, nll_loss=0.114, ppl=1.08, wps=23520.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=49700, lr=0.000141848, gnorm=0.265, loss_scale=64, train_wall=236, gb_free=8.8, wall=139234
2022-03-08 03:44:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:45:01 | INFO | valid | epoch 1022 | valid on 'valid' subset | loss 14.143 | nll_loss 13.971 | ppl 16055.6 | wps 42271.6 | wpb 510.9 | bsz 1 | num_updates 49743 | best_loss 8.318
2022-03-08 03:45:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1022 @ 49743 updates
2022-03-08 03:45:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:45:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:45:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1022 @ 49743 updates, score 14.143) (writing took 2.496542504057288 seconds)
2022-03-08 03:45:04 | INFO | fairseq_cli.train | end of epoch 1022 (average epoch stats below)
2022-03-08 03:45:04 | INFO | train | epoch 1022 | loss 0.634 | nll_loss 0.113 | ppl 1.08 | wps 23451.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49743 | lr 0.000141786 | gnorm 0.265 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 139354
2022-03-08 03:45:04 | INFO | fairseq.trainer | begin training epoch 1023
2022-03-08 03:45:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:45:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:47:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:47:16 | INFO | valid | epoch 1023 | valid on 'valid' subset | loss 14.134 | nll_loss 13.964 | ppl 15975.3 | wps 42124.1 | wpb 510.9 | bsz 1 | num_updates 49791 | best_loss 8.318
2022-03-08 03:47:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1023 @ 49791 updates
2022-03-08 03:47:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:47:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:47:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1023 @ 49791 updates, score 14.134) (writing took 2.335496136918664 seconds)
2022-03-08 03:47:19 | INFO | fairseq_cli.train | end of epoch 1023 (average epoch stats below)
2022-03-08 03:47:19 | INFO | train | epoch 1023 | loss 0.634 | nll_loss 0.113 | ppl 1.08 | wps 23035.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 49791 | lr 0.000141718 | gnorm 0.264 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 139489
2022-03-08 03:47:19 | INFO | fairseq.trainer | begin training epoch 1024
2022-03-08 03:47:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:47:43 | INFO | train_inner | epoch 1024:      9 / 49 loss=0.634, nll_loss=0.113, ppl=1.08, wps=23292.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=49800, lr=0.000141705, gnorm=0.264, loss_scale=64, train_wall=238, gb_free=8.8, wall=139513
2022-03-08 03:49:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:49:32 | INFO | valid | epoch 1024 | valid on 'valid' subset | loss 14.185 | nll_loss 14.015 | ppl 16554.9 | wps 42037.5 | wpb 510.9 | bsz 1 | num_updates 49840 | best_loss 8.318
2022-03-08 03:49:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1024 @ 49840 updates
2022-03-08 03:49:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:49:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:49:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1024 @ 49840 updates, score 14.185) (writing took 2.418883452191949 seconds)
2022-03-08 03:49:34 | INFO | fairseq_cli.train | end of epoch 1024 (average epoch stats below)
2022-03-08 03:49:34 | INFO | train | epoch 1024 | loss 0.634 | nll_loss 0.113 | ppl 1.08 | wps 23454 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49840 | lr 0.000141648 | gnorm 0.263 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 139625
2022-03-08 03:49:34 | INFO | fairseq.trainer | begin training epoch 1025
2022-03-08 03:49:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:51:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:51:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:51:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:51:47 | INFO | valid | epoch 1025 | valid on 'valid' subset | loss 14.106 | nll_loss 13.935 | ppl 15656.9 | wps 41715.5 | wpb 510.9 | bsz 1 | num_updates 49887 | best_loss 8.318
2022-03-08 03:51:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1025 @ 49887 updates
2022-03-08 03:51:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:51:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:51:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1025 @ 49887 updates, score 14.106) (writing took 2.331615215167403 seconds)
2022-03-08 03:51:49 | INFO | fairseq_cli.train | end of epoch 1025 (average epoch stats below)
2022-03-08 03:51:49 | INFO | train | epoch 1025 | loss 0.634 | nll_loss 0.113 | ppl 1.08 | wps 22534.3 | ups 0.35 | wpb 64829.4 | bsz 126.6 | num_updates 49887 | lr 0.000141581 | gnorm 0.267 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 139760
2022-03-08 03:51:49 | INFO | fairseq.trainer | begin training epoch 1026
2022-03-08 03:51:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:52:24 | INFO | train_inner | epoch 1026:     13 / 49 loss=0.634, nll_loss=0.113, ppl=1.08, wps=23072.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=49900, lr=0.000141563, gnorm=0.265, loss_scale=32, train_wall=240, gb_free=8.8, wall=139794
2022-03-08 03:53:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:54:02 | INFO | valid | epoch 1026 | valid on 'valid' subset | loss 14.237 | nll_loss 14.067 | ppl 17165.8 | wps 41883.9 | wpb 510.9 | bsz 1 | num_updates 49936 | best_loss 8.318
2022-03-08 03:54:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1026 @ 49936 updates
2022-03-08 03:54:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:54:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:54:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1026 @ 49936 updates, score 14.237) (writing took 2.4615911319851875 seconds)
2022-03-08 03:54:05 | INFO | fairseq_cli.train | end of epoch 1026 (average epoch stats below)
2022-03-08 03:54:05 | INFO | train | epoch 1026 | loss 0.634 | nll_loss 0.113 | ppl 1.08 | wps 23489.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49936 | lr 0.000141512 | gnorm 0.263 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 139895
2022-03-08 03:54:05 | INFO | fairseq.trainer | begin training epoch 1027
2022-03-08 03:54:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:56:18 | INFO | valid | epoch 1027 | valid on 'valid' subset | loss 14.22 | nll_loss 14.051 | ppl 16976.6 | wps 42065.9 | wpb 510.9 | bsz 1 | num_updates 49985 | best_loss 8.318
2022-03-08 03:56:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1027 @ 49985 updates
2022-03-08 03:56:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:56:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:56:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1027 @ 49985 updates, score 14.22) (writing took 2.304929729551077 seconds)
2022-03-08 03:56:20 | INFO | fairseq_cli.train | end of epoch 1027 (average epoch stats below)
2022-03-08 03:56:20 | INFO | train | epoch 1027 | loss 0.634 | nll_loss 0.113 | ppl 1.08 | wps 23516.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 49985 | lr 0.000141443 | gnorm 0.261 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 140030
2022-03-08 03:56:20 | INFO | fairseq.trainer | begin training epoch 1028
2022-03-08 03:56:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:56:59 | INFO | train_inner | epoch 1028:     15 / 49 loss=0.634, nll_loss=0.113, ppl=1.08, wps=23532, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=50000, lr=0.000141421, gnorm=0.262, loss_scale=32, train_wall=236, gb_free=8.8, wall=140070
2022-03-08 03:56:59 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2022-03-08 03:56:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:57:05 | INFO | valid | epoch 1028 | valid on 'valid' subset | loss 14.188 | nll_loss 14.019 | ppl 16603 | wps 42070.6 | wpb 510.9 | bsz 1 | num_updates 50000 | best_loss 8.318
2022-03-08 03:57:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1028 @ 50000 updates
2022-03-08 03:57:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:57:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:57:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 1028 @ 50000 updates, score 14.188) (writing took 2.282023036852479 seconds)
2022-03-08 03:57:07 | INFO | fairseq_cli.train | end of epoch 1028 (average epoch stats below)
2022-03-08 03:57:07 | INFO | train | epoch 1028 | loss 0.633 | nll_loss 0.112 | ppl 1.08 | wps 20898.1 | ups 0.32 | wpb 65536 | bsz 128 | num_updates 50000 | lr 0.000141421 | gnorm 0.259 | loss_scale 32 | train_wall 36 | gb_free 8.8 | wall 140077
2022-03-08 03:57:07 | INFO | fairseq_cli.train | done training in 140077.1 seconds
