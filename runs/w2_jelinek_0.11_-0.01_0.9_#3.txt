Sender: LSF System <lsfadmin@eu-g2-08>
Subject: Job 202625084: <w2_jelinek_0.11_-0.01_0.9_#3> in cluster <euler> Exited

Job <w2_jelinek_0.11_-0.01_0.9_#3> was submitted from host <eu-login-14> by user <andriusb> in cluster <euler> at Mon Jan 31 08:48:10 2022
Job was executed on host(s) <eu-g2-08>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Mon Jan 31 08:48:42 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Jan 31 08:48:42 2022
Terminated at Tue Feb  1 04:48:50 2022
Results reported at Tue Feb  1 04:48:50 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.11, -0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72900.00 sec.
    Max Memory :                                 4961 MB
    Average Memory :                             2607.24 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15039.00 MB
    Max Swap :                                   103 MB
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72008 sec.
    Turnaround time :                            72040 sec.

The output (if any) follows:

2022-01-31 08:48:47 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.11, -0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-31 08:48:47 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-31 08:48:48 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1383/36718 [00:00<00:02, 13819.47it/s]  8%|▊         | 2765/36718 [00:00<00:02, 13005.31it/s] 12%|█▏        | 4249/36718 [00:00<00:02, 13810.02it/s] 16%|█▌        | 5879/36718 [00:00<00:02, 14753.53it/s] 20%|██        | 7359/36718 [00:00<00:02, 14050.76it/s] 24%|██▍       | 8772/36718 [00:00<00:02, 13812.91it/s] 28%|██▊       | 10261/36718 [00:00<00:01, 14149.81it/s] 32%|███▏      | 11681/36718 [00:00<00:01, 13775.15it/s] 36%|███▌      | 13134/36718 [00:00<00:01, 13998.50it/s] 40%|███▉      | 14538/36718 [00:01<00:01, 13990.95it/s] 43%|████▎     | 15940/36718 [00:01<00:01, 13770.85it/s] 47%|████▋     | 17320/36718 [00:01<00:01, 13663.17it/s] 51%|█████     | 18746/36718 [00:01<00:01, 13836.17it/s] 55%|█████▌    | 20243/36718 [00:01<00:01, 14163.73it/s] 59%|█████▉    | 21661/36718 [00:01<00:01, 13702.33it/s] 63%|██████▎   | 23150/36718 [00:01<00:00, 14044.78it/s] 67%|██████▋   | 24763/36718 [00:01<00:00, 14644.32it/s] 71%|███████▏  | 26232/36718 [00:01<00:00, 14033.19it/s] 75%|███████▌  | 27643/36718 [00:01<00:00, 13407.47it/s] 79%|███████▉  | 28999/36718 [00:02<00:00, 13449.73it/s] 83%|████████▎ | 30351/36718 [00:02<00:00, 13324.56it/s] 86%|████████▋ | 31688/36718 [00:02<00:00, 13089.51it/s] 90%|████████▉ | 33001/36718 [00:02<00:00, 12926.47it/s] 93%|█████████▎| 34296/36718 [00:02<00:00, 12854.97it/s] 97%|█████████▋| 35697/36718 [00:02<00:00, 13190.49it/s]100%|██████████| 36718/36718 [00:02<00:00, 13672.44it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  8%|▊         | 2767/36718 [00:00<00:01, 27656.84it/s] 16%|█▌        | 5926/36718 [00:00<00:01, 29951.97it/s] 24%|██▍       | 8922/36718 [00:00<00:00, 28056.12it/s] 32%|███▏      | 11741/36718 [00:00<00:00, 27496.68it/s] 40%|███▉      | 14542/36718 [00:00<00:00, 27673.75it/s] 47%|████▋     | 17316/36718 [00:00<00:00, 27548.65it/s] 55%|█████▌    | 20202/36718 [00:00<00:00, 27964.74it/s] 63%|██████▎   | 23002/36718 [00:00<00:00, 27563.43it/s] 71%|███████   | 25991/36718 [00:00<00:00, 28274.37it/s] 78%|███████▊  | 28822/36718 [00:01<00:00, 28060.81it/s] 86%|████████▌ | 31631/36718 [00:01<00:00, 27434.43it/s] 94%|█████████▎| 34379/36718 [00:01<00:00, 26791.90it/s]100%|██████████| 36718/36718 [00:01<00:00, 27638.99it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 198.57it/s]2022-01-31 08:48:57 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-31 08:48:57 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-31 08:48:57 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-31 08:48:57 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-31 08:48:57 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-31 08:48:57 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-31 08:48:57 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-31 08:48:57 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-31 08:48:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:48:57 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-01-31 08:48:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:48:57 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-31 08:48:57 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-31 08:48:57 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint_last.pt
2022-01-31 08:48:57 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint_last.pt
2022-01-31 08:48:57 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-31 08:48:57 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-31 08:48:57 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-31 08:48:57 | INFO | fairseq.trainer | begin training epoch 1
2022-01-31 08:48:57 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-31 08:54:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-31 08:54:51 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.719 | ppl 26972.1 | wps 7974.4 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-31 08:54:51 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-31 08:54:51 | INFO | train | epoch 001 | loss 16.136 | ppl 71992.6 | wps 5932 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.202 | train_wall 324 | gb_free 6.1 | wall 353
KL Stats: Epoch 1 Divergences: Uniform: 0.5171106382047024 Unigram: 3.6858789449895797
2022-01-31 08:54:51 | INFO | fairseq.trainer | begin training epoch 2
2022-01-31 08:54:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 08:57:54 | INFO | train_inner | epoch 002:     36 / 64 loss=15.602, ppl=49731.4, wps=6106.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.623, train_wall=507, gb_free=6.1, wall=537
2022-01-31 09:00:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:00:42 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.729 | ppl 13581.3 | wps 8005.3 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-31 09:00:42 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-31 09:00:42 | INFO | train | epoch 002 | loss 14.447 | ppl 22336.3 | wps 5945.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.477 | train_wall 323 | gb_free 6.1 | wall 705
KL Stats: Epoch 2 Divergences: Uniform: 0.533560633236072 Unigram: 2.4169236367086384
2022-01-31 09:00:42 | INFO | fairseq.trainer | begin training epoch 3
2022-01-31 09:00:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:06:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:06:30 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.917 | ppl 7734.78 | wps 8101.5 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-31 09:06:30 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-31 09:06:30 | INFO | train | epoch 003 | loss 13.555 | ppl 12038 | wps 5998.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.19 | train_wall 320 | gb_free 6.1 | wall 1053
KL Stats: Epoch 3 Divergences: Uniform: 0.5162869045801074 Unigram: 1.7356846949496483
2022-01-31 09:06:30 | INFO | fairseq.trainer | begin training epoch 4
2022-01-31 09:06:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:07:10 | INFO | train_inner | epoch 004:      8 / 64 loss=13.687, ppl=13186.1, wps=5857.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.219, train_wall=501, gb_free=6.1, wall=1093
2022-01-31 09:11:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:12:18 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.084 | ppl 4340.64 | wps 7991.6 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-31 09:12:18 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-31 09:12:18 | INFO | train | epoch 004 | loss 12.618 | ppl 6284.38 | wps 5993.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.947 | train_wall 320 | gb_free 6.1 | wall 1401
KL Stats: Epoch 4 Divergences: Uniform: 0.5977791940112988 Unigram: 1.1260147594738896
2022-01-31 09:12:18 | INFO | fairseq.trainer | begin training epoch 5
2022-01-31 09:12:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:16:02 | INFO | train_inner | epoch 005:     44 / 64 loss=12.274, ppl=4951.8, wps=6148.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.834, train_wall=503, gb_free=6.1, wall=1625
2022-01-31 09:17:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:18:09 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.571 | ppl 3042.87 | wps 7990.7 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-31 09:18:09 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-31 09:18:09 | INFO | train | epoch 005 | loss 11.834 | ppl 3651.25 | wps 5951.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.681 | train_wall 323 | gb_free 6.1 | wall 1752
KL Stats: Epoch 5 Divergences: Uniform: 0.8302719691463222 Unigram: 0.6766878780237157
2022-01-31 09:18:09 | INFO | fairseq.trainer | begin training epoch 6
2022-01-31 09:18:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:23:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:24:00 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.325 | ppl 2565.28 | wps 7998.2 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-31 09:24:00 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-31 09:24:00 | INFO | train | epoch 006 | loss 11.408 | ppl 2718.18 | wps 5954.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.581 | train_wall 323 | gb_free 6.1 | wall 2103
KL Stats: Epoch 6 Divergences: Uniform: 1.1180389069262155 Unigram: 0.4816152227226491
2022-01-31 09:24:00 | INFO | fairseq.trainer | begin training epoch 7
2022-01-31 09:24:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:25:21 | INFO | train_inner | epoch 007:     16 / 64 loss=11.431, ppl=2760.11, wps=5824.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.579, train_wall=504, gb_free=6.1, wall=2184
2022-01-31 09:29:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:29:51 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.179 | ppl 2318.3 | wps 7984.7 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-31 09:29:51 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-31 09:29:51 | INFO | train | epoch 007 | loss 11.209 | ppl 2366.67 | wps 5949.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.523 | train_wall 323 | gb_free 6.1 | wall 2454
KL Stats: Epoch 7 Divergences: Uniform: 1.3326223716701977 Unigram: 0.4965568794391444
2022-01-31 09:29:51 | INFO | fairseq.trainer | begin training epoch 8
2022-01-31 09:29:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:34:15 | INFO | train_inner | epoch 008:     52 / 64 loss=11.147, ppl=2267.25, wps=6122.5, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.517, train_wall=505, gb_free=6.1, wall=2718
2022-01-31 09:35:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:35:42 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.072 | ppl 2152.22 | wps 7979.2 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-31 09:35:42 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-31 09:35:42 | INFO | train | epoch 008 | loss 11.094 | ppl 2186.43 | wps 5947.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.512 | train_wall 323 | gb_free 6.1 | wall 2805
KL Stats: Epoch 8 Divergences: Uniform: 1.441088107761361 Unigram: 0.5781758444816125
2022-01-31 09:35:42 | INFO | fairseq.trainer | begin training epoch 9
2022-01-31 09:35:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:41:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:41:34 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.953 | ppl 1981.77 | wps 7997 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-31 09:41:34 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-31 09:41:34 | INFO | train | epoch 009 | loss 10.986 | ppl 2027.84 | wps 5937.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.485 | train_wall 323 | gb_free 6.1 | wall 3157
KL Stats: Epoch 9 Divergences: Uniform: 1.48232923694785 Unigram: 0.6909154184225449
2022-01-31 09:41:34 | INFO | fairseq.trainer | begin training epoch 10
2022-01-31 09:41:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:43:36 | INFO | train_inner | epoch 010:     24 / 64 loss=10.976, ppl=2014.52, wps=5814.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.487, train_wall=504, gb_free=6.1, wall=3279
2022-01-31 09:46:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:47:25 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.845 | ppl 1839.79 | wps 7988.7 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-31 09:47:25 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-31 09:47:25 | INFO | train | epoch 010 | loss 10.873 | ppl 1875.96 | wps 5948.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.483 | train_wall 323 | gb_free 6.1 | wall 3508
KL Stats: Epoch 10 Divergences: Uniform: 1.5051192626707617 Unigram: 0.815548152644212
2022-01-31 09:47:25 | INFO | fairseq.trainer | begin training epoch 11
2022-01-31 09:47:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:52:30 | INFO | train_inner | epoch 011:     60 / 64 loss=10.796, ppl=1777.34, wps=6114.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.494, train_wall=506, gb_free=6.1, wall=3813
2022-01-31 09:52:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:53:17 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.736 | ppl 1705.87 | wps 7958.4 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-31 09:53:17 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-31 09:53:17 | INFO | train | epoch 011 | loss 10.755 | ppl 1727.8 | wps 5939.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.498 | train_wall 323 | gb_free 6.1 | wall 3860
KL Stats: Epoch 11 Divergences: Uniform: 1.5223130737470618 Unigram: 0.9408259592847829
2022-01-31 09:53:17 | INFO | fairseq.trainer | begin training epoch 12
2022-01-31 09:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:58:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:59:09 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.625 | ppl 1579.34 | wps 7962.9 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-31 09:59:09 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-31 09:59:09 | INFO | train | epoch 012 | loss 10.636 | ppl 1591.2 | wps 5929.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.482 | train_wall 324 | gb_free 6.1 | wall 4212
KL Stats: Epoch 12 Divergences: Uniform: 1.5328654112733315 Unigram: 1.0622536844536299
2022-01-31 09:59:09 | INFO | fairseq.trainer | begin training epoch 13
2022-01-31 09:59:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:01:52 | INFO | train_inner | epoch 013:     32 / 64 loss=10.612, ppl=1564.61, wps=5800.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.496, train_wall=506, gb_free=6.1, wall=4375
2022-01-31 10:04:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:05:02 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.535 | ppl 1483.58 | wps 7951.2 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-31 10:05:02 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-31 10:05:02 | INFO | train | epoch 013 | loss 10.52 | ppl 1468.57 | wps 5924 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.517 | train_wall 324 | gb_free 6.1 | wall 4565
KL Stats: Epoch 13 Divergences: Uniform: 1.557062515511917 Unigram: 1.1693127984424936
2022-01-31 10:05:02 | INFO | fairseq.trainer | begin training epoch 14
2022-01-31 10:05:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:10:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:10:53 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.439 | ppl 1388.02 | wps 7950 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-31 10:10:53 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-31 10:10:53 | INFO | train | epoch 014 | loss 10.409 | ppl 1359.25 | wps 5939.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.56 | train_wall 323 | gb_free 6.1 | wall 4916
KL Stats: Epoch 14 Divergences: Uniform: 1.5836099849189593 Unigram: 1.2676935243543073
2022-01-31 10:10:53 | INFO | fairseq.trainer | begin training epoch 15
2022-01-31 10:10:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:11:14 | INFO | train_inner | epoch 015:      4 / 64 loss=10.431, ppl=1380.83, wps=5805.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.538, train_wall=505, gb_free=6.1, wall=4937
2022-01-31 10:16:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:16:45 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.369 | ppl 1322.21 | wps 7976.3 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-31 10:16:45 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-31 10:16:45 | INFO | train | epoch 015 | loss 10.296 | ppl 1257.56 | wps 5942.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.541 | train_wall 323 | gb_free 6.1 | wall 5268
KL Stats: Epoch 15 Divergences: Uniform: 1.604885217723347 Unigram: 1.3585080924798159
2022-01-31 10:16:45 | INFO | fairseq.trainer | begin training epoch 16
2022-01-31 10:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:20:08 | INFO | train_inner | epoch 016:     40 / 64 loss=10.255, ppl=1221.97, wps=6114.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.56, train_wall=506, gb_free=6.1, wall=5471
2022-01-31 10:22:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:22:37 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.289 | ppl 1250.83 | wps 7932.1 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-31 10:22:37 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-31 10:22:37 | INFO | train | epoch 016 | loss 10.19 | ppl 1167.96 | wps 5934 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.557 | train_wall 324 | gb_free 6.1 | wall 5620
KL Stats: Epoch 16 Divergences: Uniform: 1.6324820278276087 Unigram: 1.4446118608136946
2022-01-31 10:22:37 | INFO | fairseq.trainer | begin training epoch 17
2022-01-31 10:22:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:28:28 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.194 | ppl 1171.03 | wps 8069 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-31 10:28:28 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-31 10:28:28 | INFO | train | epoch 017 | loss 10.083 | ppl 1084.72 | wps 5951.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.548 | train_wall 323 | gb_free 6.1 | wall 5971
KL Stats: Epoch 17 Divergences: Uniform: 1.666492520836899 Unigram: 1.5197929693654648
2022-01-31 10:28:28 | INFO | fairseq.trainer | begin training epoch 18
2022-01-31 10:28:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:29:28 | INFO | train_inner | epoch 018:     12 / 64 loss=10.097, ppl=1095.43, wps=5819.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.551, train_wall=504, gb_free=6.1, wall=6031
2022-01-31 10:33:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:34:15 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.134 | ppl 1123.53 | wps 8127.2 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-31 10:34:15 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-31 10:34:15 | INFO | train | epoch 018 | loss 9.983 | ppl 1011.78 | wps 6016.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.569 | train_wall 319 | gb_free 6.1 | wall 6318
KL Stats: Epoch 18 Divergences: Uniform: 1.6990609249431612 Unigram: 1.594492043593805
2022-01-31 10:34:15 | INFO | fairseq.trainer | begin training epoch 19
2022-01-31 10:34:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:38:16 | INFO | train_inner | epoch 019:     48 / 64 loss=9.933, ppl=977.65, wps=6191.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.54, train_wall=500, gb_free=6.1, wall=6559
2022-01-31 10:39:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:40:03 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.057 | ppl 1065.24 | wps 8058.7 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-31 10:40:03 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-31 10:40:03 | INFO | train | epoch 019 | loss 9.879 | ppl 941.9 | wps 6003.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.528 | train_wall 320 | gb_free 6.1 | wall 6666
KL Stats: Epoch 19 Divergences: Uniform: 1.7271330018494322 Unigram: 1.6682365866592075
2022-01-31 10:40:03 | INFO | fairseq.trainer | begin training epoch 20
2022-01-31 10:40:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:45:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:45:52 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.973 | ppl 1004.87 | wps 8116.4 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-31 10:45:52 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-31 10:45:52 | INFO | train | epoch 020 | loss 9.783 | ppl 880.93 | wps 5979.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.548 | train_wall 321 | gb_free 6.1 | wall 7015
KL Stats: Epoch 20 Divergences: Uniform: 1.7575968569032996 Unigram: 1.7355260210888046
2022-01-31 10:45:52 | INFO | fairseq.trainer | begin training epoch 21
2022-01-31 10:45:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:47:33 | INFO | train_inner | epoch 021:     20 / 64 loss=9.778, ppl=877.87, wps=5853.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.545, train_wall=501, gb_free=6.1, wall=7116
2022-01-31 10:51:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:51:42 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.931 | ppl 976.06 | wps 8026.2 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-31 10:51:42 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-31 10:51:42 | INFO | train | epoch 021 | loss 9.689 | ppl 825.32 | wps 5976.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.53 | train_wall 321 | gb_free 6.1 | wall 7364
KL Stats: Epoch 21 Divergences: Uniform: 1.7872851899185553 Unigram: 1.8023461702925017
2022-01-31 10:51:42 | INFO | fairseq.trainer | begin training epoch 22
2022-01-31 10:51:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:56:24 | INFO | train_inner | epoch 022:     56 / 64 loss=9.636, ppl=795.86, wps=6152.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.541, train_wall=503, gb_free=6.1, wall=7647
2022-01-31 10:57:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:57:31 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.867 | ppl 933.84 | wps 8053.2 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-31 10:57:31 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-31 10:57:31 | INFO | train | epoch 022 | loss 9.6 | ppl 775.94 | wps 5981.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.55 | train_wall 321 | gb_free 6.1 | wall 7714
KL Stats: Epoch 22 Divergences: Uniform: 1.8113941170615828 Unigram: 1.8674924177854684
2022-01-31 10:57:31 | INFO | fairseq.trainer | begin training epoch 23
2022-01-31 10:57:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:02:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:03:20 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.803 | ppl 893.61 | wps 8032.6 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-31 11:03:20 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-31 11:03:20 | INFO | train | epoch 023 | loss 9.513 | ppl 730.66 | wps 5980.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.516 | train_wall 321 | gb_free 6.1 | wall 8063
KL Stats: Epoch 23 Divergences: Uniform: 1.839375828670175 Unigram: 1.9252475437142296
2022-01-31 11:03:20 | INFO | fairseq.trainer | begin training epoch 24
2022-01-31 11:03:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:05:42 | INFO | train_inner | epoch 024:     28 / 64 loss=9.498, ppl=723.12, wps=5851.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.531, train_wall=501, gb_free=6.1, wall=8204
2022-01-31 11:08:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:09:10 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.745 | ppl 857.85 | wps 8067.4 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-31 11:09:10 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-31 11:09:10 | INFO | train | epoch 024 | loss 9.43 | ppl 689.88 | wps 5972.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.564 | train_wall 322 | gb_free 6.1 | wall 8412
KL Stats: Epoch 24 Divergences: Uniform: 1.8600812712828954 Unigram: 1.978621486976207
2022-01-31 11:09:10 | INFO | fairseq.trainer | begin training epoch 25
2022-01-31 11:09:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:14:31 | INFO | train_inner | epoch 025:     64 / 64 loss=9.376, ppl=664.63, wps=6157.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.545, train_wall=501, gb_free=6.1, wall=8734
2022-01-31 11:14:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:14:58 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.715 | ppl 840.18 | wps 8094.2 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-31 11:14:58 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-31 11:14:58 | INFO | train | epoch 025 | loss 9.349 | ppl 651.95 | wps 5997 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.53 | train_wall 320 | gb_free 6.1 | wall 8761
KL Stats: Epoch 25 Divergences: Uniform: 1.88861118038125 Unigram: 2.0342098927952903
2022-01-31 11:14:58 | INFO | fairseq.trainer | begin training epoch 26
2022-01-31 11:14:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:20:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:20:47 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.664 | ppl 811.31 | wps 8079.6 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-31 11:20:47 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-31 11:20:47 | INFO | train | epoch 026 | loss 9.268 | ppl 616.35 | wps 5989.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.545 | train_wall 321 | gb_free 6.1 | wall 9109
KL Stats: Epoch 26 Divergences: Uniform: 1.9008871858722096 Unigram: 2.0835399930338516
2022-01-31 11:20:47 | INFO | fairseq.trainer | begin training epoch 27
2022-01-31 11:20:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:23:48 | INFO | train_inner | epoch 027:     36 / 64 loss=9.24, ppl=604.67, wps=5864.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.54, train_wall=502, gb_free=6.1, wall=9291
2022-01-31 11:26:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:26:36 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.631 | ppl 792.98 | wps 8018.8 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-31 11:26:36 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-31 11:26:36 | INFO | train | epoch 027 | loss 9.188 | ppl 583.25 | wps 5986.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.533 | train_wall 321 | gb_free 6.1 | wall 9458
KL Stats: Epoch 27 Divergences: Uniform: 1.9268720136236943 Unigram: 2.1285420285295604
2022-01-31 11:26:36 | INFO | fairseq.trainer | begin training epoch 28
2022-01-31 11:26:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:31:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:32:24 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.604 | ppl 778.42 | wps 8038 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-31 11:32:24 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-31 11:32:24 | INFO | train | epoch 028 | loss 9.11 | ppl 552.5 | wps 5988.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.527 | train_wall 321 | gb_free 6.1 | wall 9807
KL Stats: Epoch 28 Divergences: Uniform: 1.9558787386098861 Unigram: 2.1766612490600235
2022-01-31 11:32:24 | INFO | fairseq.trainer | begin training epoch 29
2022-01-31 11:32:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:33:05 | INFO | train_inner | epoch 029:      8 / 64 loss=9.125, ppl=558.51, wps=5856.2, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.532, train_wall=501, gb_free=6.1, wall=9848
2022-01-31 11:37:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:38:13 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.567 | ppl 758.66 | wps 8053.1 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-31 11:38:13 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-31 11:38:13 | INFO | train | epoch 029 | loss 9.031 | ppl 523.09 | wps 5989.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.525 | train_wall 321 | gb_free 6.1 | wall 10156
KL Stats: Epoch 29 Divergences: Uniform: 1.9760192409918353 Unigram: 2.2196457963808873
2022-01-31 11:38:13 | INFO | fairseq.trainer | begin training epoch 30
2022-01-31 11:38:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:41:56 | INFO | train_inner | epoch 030:     44 / 64 loss=8.998, ppl=511.29, wps=6156.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.516, train_wall=502, gb_free=6.1, wall=10378
2022-01-31 11:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:44:02 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.544 | ppl 746.67 | wps 8058.5 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-31 11:44:02 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-31 11:44:02 | INFO | train | epoch 030 | loss 8.954 | ppl 495.79 | wps 5977.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.523 | train_wall 321 | gb_free 6.1 | wall 10505
KL Stats: Epoch 30 Divergences: Uniform: 1.993195625183268 Unigram: 2.2669259936768267
2022-01-31 11:44:02 | INFO | fairseq.trainer | begin training epoch 31
2022-01-31 11:44:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:49:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:49:51 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.494 | ppl 720.96 | wps 8088.5 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-31 11:49:51 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-31 11:49:51 | INFO | train | epoch 031 | loss 8.874 | ppl 469.22 | wps 5986.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.5 | train_wall 321 | gb_free 6.1 | wall 10854
KL Stats: Epoch 31 Divergences: Uniform: 2.0115572472863126 Unigram: 2.3072716586599338
2022-01-31 11:49:51 | INFO | fairseq.trainer | begin training epoch 32
2022-01-31 11:49:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:51:12 | INFO | train_inner | epoch 032:     16 / 64 loss=8.875, ppl=469.65, wps=5856.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.508, train_wall=501, gb_free=6.1, wall=10935
2022-01-31 11:55:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:55:40 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.46 | ppl 704.15 | wps 8108.6 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-31 11:55:40 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-31 11:55:40 | INFO | train | epoch 032 | loss 8.801 | ppl 445.89 | wps 5987.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.512 | train_wall 321 | gb_free 6.1 | wall 11203
KL Stats: Epoch 32 Divergences: Uniform: 2.039364226489823 Unigram: 2.349113817485872
2022-01-31 11:55:40 | INFO | fairseq.trainer | begin training epoch 33
2022-01-31 11:55:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:00:02 | INFO | train_inner | epoch 033:     52 / 64 loss=8.764, ppl=434.62, wps=6168.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.515, train_wall=502, gb_free=6.1, wall=11465
2022-01-31 12:01:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:01:28 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.444 | ppl 696.27 | wps 8141.1 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-31 12:01:28 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-31 12:01:28 | INFO | train | epoch 033 | loss 8.726 | ppl 423.47 | wps 6008 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.514 | train_wall 320 | gb_free 6.1 | wall 11551
KL Stats: Epoch 33 Divergences: Uniform: 2.0618618398150814 Unigram: 2.397358807785163
2022-01-31 12:01:28 | INFO | fairseq.trainer | begin training epoch 34
2022-01-31 12:01:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:07:14 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.424 | ppl 686.89 | wps 8148.6 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-31 12:07:14 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-31 12:07:14 | INFO | train | epoch 034 | loss 8.65 | ppl 401.83 | wps 6036.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.516 | train_wall 318 | gb_free 6.1 | wall 11897
KL Stats: Epoch 34 Divergences: Uniform: 2.082294738509631 Unigram: 2.4387711432051034
2022-01-31 12:07:14 | INFO | fairseq.trainer | begin training epoch 35
2022-01-31 12:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:09:14 | INFO | train_inner | epoch 035:     24 / 64 loss=8.638, ppl=398.25, wps=5905.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.515, train_wall=497, gb_free=6.1, wall=12017
2022-01-31 12:12:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:13:02 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.396 | ppl 673.88 | wps 8078.9 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-31 12:13:02 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-31 12:13:02 | INFO | train | epoch 035 | loss 8.578 | ppl 382.13 | wps 6006.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.509 | train_wall 320 | gb_free 6.1 | wall 12244
KL Stats: Epoch 35 Divergences: Uniform: 2.103809158483506 Unigram: 2.475979529853614
2022-01-31 12:13:02 | INFO | fairseq.trainer | begin training epoch 36
2022-01-31 12:13:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:18:05 | INFO | train_inner | epoch 036:     60 / 64 loss=8.534, ppl=370.75, wps=6152.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.51, train_wall=503, gb_free=6.1, wall=12548
2022-01-31 12:18:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:18:51 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.37 | ppl 661.76 | wps 8071 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-31 12:18:51 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-31 12:18:51 | INFO | train | epoch 036 | loss 8.505 | ppl 363.21 | wps 5972.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.51 | train_wall 322 | gb_free 6.1 | wall 12594
KL Stats: Epoch 36 Divergences: Uniform: 2.1246713908365233 Unigram: 2.5216195951606557
2022-01-31 12:18:51 | INFO | fairseq.trainer | begin training epoch 37
2022-01-31 12:18:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:24:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:24:40 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.39 | ppl 670.9 | wps 8053 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-31 12:24:40 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-31 12:24:40 | INFO | train | epoch 037 | loss 8.435 | ppl 346.1 | wps 5988.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.513 | train_wall 321 | gb_free 6.1 | wall 12943
KL Stats: Epoch 37 Divergences: Uniform: 2.1425923121224177 Unigram: 2.564022273420494
2022-01-31 12:24:40 | INFO | fairseq.trainer | begin training epoch 38
2022-01-31 12:24:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:27:22 | INFO | train_inner | epoch 038:     32 / 64 loss=8.414, ppl=341.01, wps=5857.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.511, train_wall=501, gb_free=6.1, wall=13105
2022-01-31 12:30:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:30:30 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.369 | ppl 661.03 | wps 8040.9 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-31 12:30:30 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-31 12:30:30 | INFO | train | epoch 038 | loss 8.367 | ppl 330.06 | wps 5975 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.512 | train_wall 321 | gb_free 6.1 | wall 13292
KL Stats: Epoch 38 Divergences: Uniform: 2.171568709799728 Unigram: 2.5955388278258518
2022-01-31 12:30:30 | INFO | fairseq.trainer | begin training epoch 39
2022-01-31 12:30:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:35:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:36:19 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.347 | ppl 651.15 | wps 8075.2 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-31 12:36:19 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-31 12:36:19 | INFO | train | epoch 039 | loss 8.298 | ppl 314.65 | wps 5985.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.504 | train_wall 321 | gb_free 6.1 | wall 13641
KL Stats: Epoch 39 Divergences: Uniform: 2.1804200416663146 Unigram: 2.640163408085552
2022-01-31 12:36:19 | INFO | fairseq.trainer | begin training epoch 40
2022-01-31 12:36:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:36:39 | INFO | train_inner | epoch 040:      4 / 64 loss=8.319, ppl=319.43, wps=5851.6, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.508, train_wall=501, gb_free=6.1, wall=13662
2022-01-31 12:41:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:42:07 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.326 | ppl 641.68 | wps 8075 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-31 12:42:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-31 12:42:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint40.pt
2022-01-31 12:42:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint40.pt
2022-01-31 12:42:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.326) (writing took 5.382050199434161 seconds)
2022-01-31 12:42:12 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-31 12:42:12 | INFO | train | epoch 040 | loss 8.229 | ppl 300.03 | wps 5903.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.508 | train_wall 320 | gb_free 6.1 | wall 13995
KL Stats: Epoch 40 Divergences: Uniform: 2.2076651354763066 Unigram: 2.67738658187128
2022-01-31 12:42:12 | INFO | fairseq.trainer | begin training epoch 41
2022-01-31 12:42:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:45:35 | INFO | train_inner | epoch 041:     40 / 64 loss=8.205, ppl=295.15, wps=6100.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.506, train_wall=502, gb_free=6.1, wall=14197
2022-01-31 12:47:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:48:02 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.317 | ppl 637.77 | wps 8080.8 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.317
2022-01-31 12:48:02 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-31 12:48:02 | INFO | train | epoch 041 | loss 8.165 | ppl 286.96 | wps 5977.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.505 | train_wall 321 | gb_free 6.1 | wall 14344
KL Stats: Epoch 41 Divergences: Uniform: 2.221443738611444 Unigram: 2.712206682521822
2022-01-31 12:48:02 | INFO | fairseq.trainer | begin training epoch 42
2022-01-31 12:48:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:53:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:53:51 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.294 | ppl 627.71 | wps 8080.2 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.294
2022-01-31 12:53:51 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-31 12:53:51 | INFO | train | epoch 042 | loss 8.101 | ppl 274.49 | wps 5978.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.515 | train_wall 321 | gb_free 6.1 | wall 14694
KL Stats: Epoch 42 Divergences: Uniform: 2.237935346230051 Unigram: 2.7540435213223597
2022-01-31 12:53:51 | INFO | fairseq.trainer | begin training epoch 43
2022-01-31 12:53:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:54:52 | INFO | train_inner | epoch 043:     12 / 64 loss=8.107, ppl=275.71, wps=5852.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.514, train_wall=501, gb_free=6.1, wall=14754
2022-01-31 12:59:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:59:39 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.327 | ppl 642.05 | wps 8086.2 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.326
2022-01-31 12:59:39 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-31 12:59:39 | INFO | train | epoch 043 | loss 8.036 | ppl 262.4 | wps 5996.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.507 | train_wall 320 | gb_free 6.1 | wall 15042
KL Stats: Epoch 43 Divergences: Uniform: 2.261333200701914 Unigram: 2.7913128920147487
2022-01-31 12:59:39 | INFO | fairseq.trainer | begin training epoch 44
2022-01-31 12:59:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:03:42 | INFO | train_inner | epoch 044:     48 / 64 loss=8.002, ppl=256.33, wps=6164, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.513, train_wall=502, gb_free=6.1, wall=15285
2022-01-31 13:05:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:05:28 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.34 | ppl 648.11 | wps 8045 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.326
2022-01-31 13:05:28 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-31 13:05:28 | INFO | train | epoch 044 | loss 7.976 | ppl 251.79 | wps 5982.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.513 | train_wall 321 | gb_free 6.1 | wall 15391
KL Stats: Epoch 44 Divergences: Uniform: 2.2775280908431363 Unigram: 2.826799115233034
2022-01-31 13:05:29 | INFO | fairseq.trainer | begin training epoch 45
2022-01-31 13:05:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:11:18 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.316 | ppl 637.33 | wps 8083.4 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.316
2022-01-31 13:11:18 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-31 13:11:18 | INFO | train | epoch 045 | loss 7.913 | ppl 241.04 | wps 5981.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.515 | train_wall 321 | gb_free 6.1 | wall 15740
KL Stats: Epoch 45 Divergences: Uniform: 2.294562090570219 Unigram: 2.869581372061677
2022-01-31 13:11:18 | INFO | fairseq.trainer | begin training epoch 46
2022-01-31 13:11:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:12:59 | INFO | train_inner | epoch 046:     20 / 64 loss=7.913, ppl=240.97, wps=5853.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.514, train_wall=501, gb_free=6.1, wall=15842
2022-01-31 13:16:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:17:07 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.313 | ppl 635.98 | wps 8041.8 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.313
2022-01-31 13:17:07 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-31 13:17:07 | INFO | train | epoch 046 | loss 7.854 | ppl 231.41 | wps 5985.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.523 | train_wall 321 | gb_free 6.1 | wall 16089
KL Stats: Epoch 46 Divergences: Uniform: 2.3092151561208794 Unigram: 2.894159442310697
2022-01-31 13:17:07 | INFO | fairseq.trainer | begin training epoch 47
2022-01-31 13:17:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:21:49 | INFO | train_inner | epoch 047:     56 / 64 loss=7.823, ppl=226.49, wps=6157.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.51, train_wall=502, gb_free=6.1, wall=16372
2022-01-31 13:22:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:22:56 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.302 | ppl 631.18 | wps 8045.1 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.302
2022-01-31 13:22:56 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-31 13:22:56 | INFO | train | epoch 047 | loss 7.796 | ppl 222.18 | wps 5978.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.506 | train_wall 321 | gb_free 6.1 | wall 16439
KL Stats: Epoch 47 Divergences: Uniform: 2.3318123438598524 Unigram: 2.925511145136698
2022-01-31 13:22:56 | INFO | fairseq.trainer | begin training epoch 48
2022-01-31 13:22:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:28:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:28:46 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.294 | ppl 627.78 | wps 8064.4 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.294
2022-01-31 13:28:46 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-31 13:28:46 | INFO | train | epoch 048 | loss 7.739 | ppl 213.6 | wps 5969.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.518 | train_wall 322 | gb_free 6.1 | wall 16789
KL Stats: Epoch 48 Divergences: Uniform: 2.347705015858914 Unigram: 2.963357710594926
2022-01-31 13:28:46 | INFO | fairseq.trainer | begin training epoch 49
2022-01-31 13:28:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:31:07 | INFO | train_inner | epoch 049:     28 / 64 loss=7.721, ppl=211.01, wps=5844.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.517, train_wall=502, gb_free=6.1, wall=16930
2022-01-31 13:34:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:34:34 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.333 | ppl 645.13 | wps 8138.2 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.326
2022-01-31 13:34:34 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-31 13:34:34 | INFO | train | epoch 049 | loss 7.682 | ppl 205.3 | wps 6005.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.518 | train_wall 320 | gb_free 6.1 | wall 17136
KL Stats: Epoch 49 Divergences: Uniform: 2.3515043399411204 Unigram: 2.9950348147804133
2022-01-31 13:34:34 | INFO | fairseq.trainer | begin training epoch 50
2022-01-31 13:34:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:39:54 | INFO | train_inner | epoch 050:     64 / 64 loss=7.657, ppl=201.84, wps=6192.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.529, train_wall=498, gb_free=6.1, wall=17456
2022-01-31 13:39:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:40:21 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.347 | ppl 651.01 | wps 8111.3 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.326
2022-01-31 13:40:21 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-31 13:40:21 | INFO | train | epoch 050 | loss 7.63 | ppl 198.14 | wps 6021.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.534 | train_wall 319 | gb_free 6.1 | wall 17483
KL Stats: Epoch 50 Divergences: Uniform: 2.3674361136453816 Unigram: 3.0203142879382803
2022-01-31 13:40:21 | INFO | fairseq.trainer | begin training epoch 51
2022-01-31 13:40:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:45:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:46:09 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.355 | ppl 654.97 | wps 8066 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.326
2022-01-31 13:46:09 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-31 13:46:09 | INFO | train | epoch 051 | loss 7.574 | ppl 190.59 | wps 5986.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.519 | train_wall 321 | gb_free 6.1 | wall 17832
KL Stats: Epoch 51 Divergences: Uniform: 2.394050767778345 Unigram: 3.0478396800905134
2022-01-31 13:46:09 | INFO | fairseq.trainer | begin training epoch 52
2022-01-31 13:46:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:49:11 | INFO | train_inner | epoch 052:     36 / 64 loss=7.55, ppl=187.46, wps=5859.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.52, train_wall=502, gb_free=6.1, wall=18014
2022-01-31 13:51:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:51:59 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.344 | ppl 650.08 | wps 8053 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.326
2022-01-31 13:51:59 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-31 13:51:59 | INFO | train | epoch 052 | loss 7.522 | ppl 183.8 | wps 5980.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.525 | train_wall 321 | gb_free 6.1 | wall 18182
KL Stats: Epoch 52 Divergences: Uniform: 2.407123674882871 Unigram: 3.0920985578908637
2022-01-31 13:51:59 | INFO | fairseq.trainer | begin training epoch 53
2022-01-31 13:51:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:57:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:57:47 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.331 | ppl 644.16 | wps 8095.3 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.326
2022-01-31 13:57:47 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-31 13:57:47 | INFO | train | epoch 053 | loss 7.471 | ppl 177.37 | wps 5999.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.518 | train_wall 320 | gb_free 6.1 | wall 18530
KL Stats: Epoch 53 Divergences: Uniform: 2.4222252122360075 Unigram: 3.1153657475525254
2022-01-31 13:57:47 | INFO | fairseq.trainer | begin training epoch 54
2022-01-31 13:57:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:58:27 | INFO | train_inner | epoch 054:      8 / 64 loss=7.483, ppl=178.96, wps=5862.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.525, train_wall=500, gb_free=6.1, wall=18570
2022-01-31 14:03:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:03:37 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.364 | ppl 658.91 | wps 8037.3 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.326
2022-01-31 14:03:37 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-31 14:03:37 | INFO | train | epoch 054 | loss 7.42 | ppl 171.3 | wps 5959.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.526 | train_wall 322 | gb_free 6.1 | wall 18880
KL Stats: Epoch 54 Divergences: Uniform: 2.431386707625916 Unigram: 3.1426068885666076
2022-01-31 14:03:37 | INFO | fairseq.trainer | begin training epoch 55
2022-01-31 14:03:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:07:20 | INFO | train_inner | epoch 055:     44 / 64 loss=7.393, ppl=168.11, wps=6138.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.527, train_wall=504, gb_free=6.1, wall=19103
2022-01-31 14:09:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:09:27 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.382 | ppl 667.26 | wps 8068.4 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.326
2022-01-31 14:09:27 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-31 14:09:27 | INFO | train | epoch 055 | loss 7.374 | ppl 165.85 | wps 5979.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.54 | train_wall 321 | gb_free 6.1 | wall 19229
KL Stats: Epoch 55 Divergences: Uniform: 2.4412968343911676 Unigram: 3.177885878313609
2022-01-31 14:09:27 | INFO | fairseq.trainer | begin training epoch 56
2022-01-31 14:09:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:14:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:15:16 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.465 | ppl 706.55 | wps 8015.9 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.326
2022-01-31 14:15:16 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-31 14:15:16 | INFO | train | epoch 056 | loss 7.324 | ppl 160.22 | wps 5975.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.529 | train_wall 321 | gb_free 6.1 | wall 19579
KL Stats: Epoch 56 Divergences: Uniform: 2.4449243932843365 Unigram: 3.1982874194093136
2022-01-31 14:15:16 | INFO | fairseq.trainer | begin training epoch 57
2022-01-31 14:15:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:16:37 | INFO | train_inner | epoch 057:     16 / 64 loss=7.328, ppl=160.69, wps=5849.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.537, train_wall=501, gb_free=6.1, wall=19660
2022-01-31 14:20:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:21:06 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.471 | ppl 709.45 | wps 8042.3 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.326
2022-01-31 14:21:06 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-31 14:21:06 | INFO | train | epoch 057 | loss 7.277 | ppl 155.09 | wps 5976.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.541 | train_wall 321 | gb_free 6.1 | wall 19928
KL Stats: Epoch 57 Divergences: Uniform: 2.4738395278632668 Unigram: 3.235402570953911
2022-01-31 14:21:06 | INFO | fairseq.trainer | begin training epoch 58
2022-01-31 14:21:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:25:29 | INFO | train_inner | epoch 058:     52 / 64 loss=7.252, ppl=152.45, wps=6142.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.536, train_wall=503, gb_free=6.1, wall=20192
2022-01-31 14:26:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:26:55 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.49 | ppl 719.27 | wps 8061.4 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.326
2022-01-31 14:26:55 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-31 14:26:55 | INFO | train | epoch 058 | loss 7.232 | ppl 150.32 | wps 5969.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.539 | train_wall 322 | gb_free 6.1 | wall 20278
KL Stats: Epoch 58 Divergences: Uniform: 2.482570292629034 Unigram: 3.261137688260474
2022-01-31 14:26:55 | INFO | fairseq.trainer | begin training epoch 59
2022-01-31 14:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:32:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:32:44 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.54 | ppl 744.53 | wps 8063.2 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.326
2022-01-31 14:32:44 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-31 14:32:44 | INFO | train | epoch 059 | loss 7.186 | ppl 145.64 | wps 5989.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.538 | train_wall 321 | gb_free 6.1 | wall 20627
KL Stats: Epoch 59 Divergences: Uniform: 2.4963397731052948 Unigram: 3.288185482177531
2022-01-31 14:32:44 | INFO | fairseq.trainer | begin training epoch 60
2022-01-31 14:32:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:34:46 | INFO | train_inner | epoch 060:     24 / 64 loss=7.18, ppl=145.01, wps=5853.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.541, train_wall=501, gb_free=6.1, wall=20749
2022-01-31 14:38:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:38:35 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.494 | ppl 720.97 | wps 8048.6 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.326
2022-01-31 14:38:35 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-31 14:38:35 | INFO | train | epoch 060 | loss 7.141 | ppl 141.18 | wps 5959.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.55 | train_wall 322 | gb_free 6.1 | wall 20977
KL Stats: Epoch 60 Divergences: Uniform: 2.5131464301878434 Unigram: 3.3220301948543978
2022-01-31 14:38:35 | INFO | fairseq.trainer | begin training epoch 61
2022-01-31 14:38:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:43:38 | INFO | train_inner | epoch 061:     60 / 64 loss=7.122, ppl=139.32, wps=6141, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.552, train_wall=504, gb_free=6.1, wall=21281
2022-01-31 14:43:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:44:24 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.549 | ppl 748.88 | wps 8084.6 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.326
2022-01-31 14:44:24 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-31 14:44:24 | INFO | train | epoch 061 | loss 7.099 | ppl 137.1 | wps 5977.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.553 | train_wall 321 | gb_free 6.1 | wall 21327
KL Stats: Epoch 61 Divergences: Uniform: 2.525891462538542 Unigram: 3.3346169889105512
2022-01-31 14:44:24 | INFO | fairseq.trainer | begin training epoch 62
2022-01-31 14:44:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:49:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:50:13 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.514 | ppl 731.26 | wps 8061.3 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.326
2022-01-31 14:50:13 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-31 14:50:13 | INFO | train | epoch 062 | loss 7.058 | ppl 133.27 | wps 5983.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.557 | train_wall 321 | gb_free 6.1 | wall 21676
KL Stats: Epoch 62 Divergences: Uniform: 2.528594754930607 Unigram: 3.373237554412178
2022-01-31 14:50:13 | INFO | fairseq.trainer | begin training epoch 63
2022-01-31 14:50:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:52:55 | INFO | train_inner | epoch 063:     32 / 64 loss=7.032, ppl=130.88, wps=5854.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.554, train_wall=501, gb_free=6.1, wall=21838
2022-01-31 14:55:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:56:03 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.547 | ppl 748.13 | wps 8033.5 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.326
2022-01-31 14:56:03 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-31 14:56:03 | INFO | train | epoch 063 | loss 7.014 | ppl 129.21 | wps 5975.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.551 | train_wall 321 | gb_free 6.1 | wall 22025
KL Stats: Epoch 63 Divergences: Uniform: 2.549045492901148 Unigram: 3.4021279169515246
2022-01-31 14:56:03 | INFO | fairseq.trainer | begin training epoch 64
2022-01-31 14:56:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:01:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:01:52 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.615 | ppl 784.25 | wps 8069.7 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.326
2022-01-31 15:01:52 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-31 15:01:52 | INFO | train | epoch 064 | loss 6.972 | ppl 125.53 | wps 5979.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.564 | train_wall 321 | gb_free 6.1 | wall 22375
KL Stats: Epoch 64 Divergences: Uniform: 2.5551295953489017 Unigram: 3.4205264833520586
2022-01-31 15:01:52 | INFO | fairseq.trainer | begin training epoch 65
2022-01-31 15:01:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:02:12 | INFO | train_inner | epoch 065:      4 / 64 loss=6.998, ppl=127.86, wps=5851.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.562, train_wall=501, gb_free=6.1, wall=22395
2022-01-31 15:07:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:07:39 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.627 | ppl 790.78 | wps 8130.9 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.326
2022-01-31 15:07:39 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-31 15:07:39 | INFO | train | epoch 065 | loss 6.928 | ppl 121.77 | wps 6026.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.562 | train_wall 319 | gb_free 6.1 | wall 22721
KL Stats: Epoch 65 Divergences: Uniform: 2.563942976226502 Unigram: 3.445737368680613
2022-01-31 15:07:39 | INFO | fairseq.trainer | begin training epoch 66
2022-01-31 15:07:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:11:00 | INFO | train_inner | epoch 066:     40 / 64 loss=6.904, ppl=119.75, wps=6188.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.567, train_wall=500, gb_free=6.1, wall=22923
2022-01-31 15:13:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:13:27 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.639 | ppl 797.29 | wps 8112.1 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.326
2022-01-31 15:13:27 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-31 15:13:27 | INFO | train | epoch 066 | loss 6.888 | ppl 118.46 | wps 5999.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.563 | train_wall 320 | gb_free 6.1 | wall 23069
KL Stats: Epoch 66 Divergences: Uniform: 2.5772898308287924 Unigram: 3.471961225872827
2022-01-31 15:13:27 | INFO | fairseq.trainer | begin training epoch 67
2022-01-31 15:13:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:18:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:19:16 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.638 | ppl 796.8 | wps 8065 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.326
2022-01-31 15:19:16 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-31 15:19:16 | INFO | train | epoch 067 | loss 6.847 | ppl 115.1 | wps 5980.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.569 | train_wall 321 | gb_free 6.1 | wall 23419
KL Stats: Epoch 67 Divergences: Uniform: 2.5950305911630087 Unigram: 3.507518799528248
2022-01-31 15:19:16 | INFO | fairseq.trainer | begin training epoch 68
2022-01-31 15:19:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:20:17 | INFO | train_inner | epoch 068:     12 / 64 loss=6.856, ppl=115.81, wps=5859.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.563, train_wall=501, gb_free=6.1, wall=23479
2022-01-31 15:24:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:25:05 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.681 | ppl 820.87 | wps 8074.7 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.326
2022-01-31 15:25:05 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-31 15:25:05 | INFO | train | epoch 068 | loss 6.81 | ppl 112.18 | wps 5982.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.582 | train_wall 321 | gb_free 6.1 | wall 23768
KL Stats: Epoch 68 Divergences: Uniform: 2.6060593442497813 Unigram: 3.5349998447665416
2022-01-31 15:25:05 | INFO | fairseq.trainer | begin training epoch 69
2022-01-31 15:25:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:29:08 | INFO | train_inner | epoch 069:     48 / 64 loss=6.792, ppl=110.8, wps=6153.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.581, train_wall=503, gb_free=6.1, wall=24010
2022-01-31 15:30:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:30:54 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.681 | ppl 820.85 | wps 8063.5 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.326
2022-01-31 15:30:54 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-31 15:30:54 | INFO | train | epoch 069 | loss 6.772 | ppl 109.27 | wps 5979.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.582 | train_wall 321 | gb_free 6.1 | wall 24117
KL Stats: Epoch 69 Divergences: Uniform: 2.618332367180402 Unigram: 3.5546142788288915
2022-01-31 15:30:54 | INFO | fairseq.trainer | begin training epoch 70
2022-01-31 15:30:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:36:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:36:44 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.785 | ppl 882.26 | wps 8079.6 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.326
2022-01-31 15:36:44 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-31 15:36:44 | INFO | train | epoch 070 | loss 6.736 | ppl 106.58 | wps 5975.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.575 | train_wall 322 | gb_free 6.1 | wall 24467
KL Stats: Epoch 70 Divergences: Uniform: 2.6226714181201594 Unigram: 3.571775430475295
2022-01-31 15:36:44 | INFO | fairseq.trainer | begin training epoch 71
2022-01-31 15:36:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:38:25 | INFO | train_inner | epoch 071:     20 / 64 loss=6.73, ppl=106.18, wps=5850, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.58, train_wall=502, gb_free=6.1, wall=24568
2022-01-31 15:42:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:42:33 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.776 | ppl 876.47 | wps 8044.3 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.326
2022-01-31 15:42:33 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-31 15:42:33 | INFO | train | epoch 071 | loss 6.701 | ppl 104.07 | wps 5978.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.588 | train_wall 321 | gb_free 6.1 | wall 24816
KL Stats: Epoch 71 Divergences: Uniform: 2.635696134088942 Unigram: 3.5959790520174897
2022-01-31 15:42:33 | INFO | fairseq.trainer | begin training epoch 72
2022-01-31 15:42:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:47:17 | INFO | train_inner | epoch 072:     56 / 64 loss=6.686, ppl=102.96, wps=6146.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.584, train_wall=503, gb_free=6.1, wall=25099
2022-01-31 15:47:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:48:23 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.668 | ppl 813.59 | wps 8035.5 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.326
2022-01-31 15:48:23 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-31 15:48:23 | INFO | train | epoch 072 | loss 6.666 | ppl 101.56 | wps 5973.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.583 | train_wall 322 | gb_free 6.1 | wall 25166
KL Stats: Epoch 72 Divergences: Uniform: 2.6509674567939228 Unigram: 3.627942886767364
2022-01-31 15:48:23 | INFO | fairseq.trainer | begin training epoch 73
2022-01-31 15:48:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:53:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:54:12 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.777 | ppl 877.34 | wps 8067.5 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.326
2022-01-31 15:54:12 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-31 15:54:12 | INFO | train | epoch 073 | loss 6.634 | ppl 99.29 | wps 5981.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.582 | train_wall 321 | gb_free 6.1 | wall 25515
KL Stats: Epoch 73 Divergences: Uniform: 2.6515154245954804 Unigram: 3.641509598538551
2022-01-31 15:54:12 | INFO | fairseq.trainer | begin training epoch 74
2022-01-31 15:54:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:56:34 | INFO | train_inner | epoch 074:     28 / 64 loss=6.622, ppl=98.52, wps=5850.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.584, train_wall=501, gb_free=6.1, wall=25657
2022-01-31 15:59:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:00:02 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.728 | ppl 847.88 | wps 8071.5 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.326
2022-01-31 16:00:02 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-31 16:00:02 | INFO | train | epoch 074 | loss 6.6 | ppl 97.02 | wps 5973.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.585 | train_wall 322 | gb_free 6.1 | wall 25865
KL Stats: Epoch 74 Divergences: Uniform: 2.6599145195931793 Unigram: 3.6727161269901174
2022-01-31 16:00:02 | INFO | fairseq.trainer | begin training epoch 75
2022-01-31 16:00:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:05:24 | INFO | train_inner | epoch 075:     64 / 64 loss=6.592, ppl=96.45, wps=6151.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.592, train_wall=502, gb_free=6.1, wall=26187
2022-01-31 16:05:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:05:51 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.859 | ppl 928.85 | wps 8034.7 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.326
2022-01-31 16:05:51 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-31 16:05:51 | INFO | train | epoch 075 | loss 6.572 | ppl 95.13 | wps 5980.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.597 | train_wall 321 | gb_free 6.1 | wall 26214
KL Stats: Epoch 75 Divergences: Uniform: 2.6677873147311764 Unigram: 3.6916189951416234
2022-01-31 16:05:51 | INFO | fairseq.trainer | begin training epoch 76
2022-01-31 16:05:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:11:41 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.804 | ppl 893.85 | wps 8050 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.326
2022-01-31 16:11:41 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-31 16:11:41 | INFO | train | epoch 076 | loss 6.541 | ppl 93.14 | wps 5968.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.607 | train_wall 322 | gb_free 6.1 | wall 26564
KL Stats: Epoch 76 Divergences: Uniform: 2.676770203705105 Unigram: 3.7220396256901878
2022-01-31 16:11:41 | INFO | fairseq.trainer | begin training epoch 77
2022-01-31 16:11:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:14:43 | INFO | train_inner | epoch 077:     36 / 64 loss=6.516, ppl=91.54, wps=5845.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.606, train_wall=503, gb_free=6.1, wall=26746
2022-01-31 16:17:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:17:30 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.758 | ppl 865.93 | wps 8036 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.326
2022-01-31 16:17:30 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-31 16:17:30 | INFO | train | epoch 077 | loss 6.511 | ppl 91.23 | wps 5981.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.616 | train_wall 321 | gb_free 6.1 | wall 26913
KL Stats: Epoch 77 Divergences: Uniform: 2.6854287922990836 Unigram: 3.751392547575252
2022-01-31 16:17:30 | INFO | fairseq.trainer | begin training epoch 78
2022-01-31 16:17:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:22:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:23:20 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.805 | ppl 894.51 | wps 8076.2 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.326
2022-01-31 16:23:20 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-31 16:23:20 | INFO | train | epoch 078 | loss 6.483 | ppl 89.43 | wps 5966.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.613 | train_wall 322 | gb_free 6.1 | wall 27263
KL Stats: Epoch 78 Divergences: Uniform: 2.691453206607939 Unigram: 3.766316553036266
2022-01-31 16:23:20 | INFO | fairseq.trainer | begin training epoch 79
2022-01-31 16:23:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:24:01 | INFO | train_inner | epoch 079:      8 / 64 loss=6.497, ppl=90.33, wps=5842.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.617, train_wall=502, gb_free=6.1, wall=27304
2022-01-31 16:28:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:29:10 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.889 | ppl 948.02 | wps 8047.9 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.326
2022-01-31 16:29:10 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-31 16:29:10 | INFO | train | epoch 079 | loss 6.451 | ppl 87.51 | wps 5971.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.601 | train_wall 322 | gb_free 6.1 | wall 27613
KL Stats: Epoch 79 Divergences: Uniform: 2.6939372343324948 Unigram: 3.78126672993646
2022-01-31 16:29:10 | INFO | fairseq.trainer | begin training epoch 80
2022-01-31 16:29:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:32:52 | INFO | train_inner | epoch 080:     44 / 64 loss=6.435, ppl=86.53, wps=6146, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.601, train_wall=503, gb_free=6.1, wall=27835
2022-01-31 16:34:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:34:58 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.808 | ppl 896.48 | wps 8152 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.326
2022-01-31 16:34:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-31 16:34:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint80.pt
2022-01-31 16:35:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint80.pt
2022-01-31 16:35:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.808) (writing took 3.5303898584097624 seconds)
2022-01-31 16:35:02 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-31 16:35:02 | INFO | train | epoch 080 | loss 6.427 | ppl 86.02 | wps 5932.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.609 | train_wall 321 | gb_free 6.1 | wall 27965
KL Stats: Epoch 80 Divergences: Uniform: 2.7024125311039207 Unigram: 3.807613960436276
2022-01-31 16:35:02 | INFO | fairseq.trainer | begin training epoch 81
2022-01-31 16:35:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:40:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:40:48 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.903 | ppl 957.55 | wps 8151.8 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.326
2022-01-31 16:40:48 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-31 16:40:48 | INFO | train | epoch 081 | loss 6.401 | ppl 84.53 | wps 6029.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.622 | train_wall 319 | gb_free 6.1 | wall 28311
KL Stats: Epoch 81 Divergences: Uniform: 2.7187858859645067 Unigram: 3.8318851558145184
2022-01-31 16:40:48 | INFO | fairseq.trainer | begin training epoch 82
2022-01-31 16:40:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:42:09 | INFO | train_inner | epoch 082:     16 / 64 loss=6.408, ppl=84.92, wps=5859, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.625, train_wall=498, gb_free=6.1, wall=28392
2022-01-31 16:46:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:46:37 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.839 | ppl 915.94 | wps 8048.4 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.326
2022-01-31 16:46:37 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-31 16:46:37 | INFO | train | epoch 082 | loss 6.374 | ppl 82.95 | wps 5990.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.617 | train_wall 321 | gb_free 6.1 | wall 28660
KL Stats: Epoch 82 Divergences: Uniform: 2.723287194768852 Unigram: 3.8658415518810205
2022-01-31 16:46:37 | INFO | fairseq.trainer | begin training epoch 83
2022-01-31 16:46:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:51:00 | INFO | train_inner | epoch 083:     52 / 64 loss=6.36, ppl=82.13, wps=6158.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.627, train_wall=502, gb_free=6.1, wall=28922
2022-01-31 16:51:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:52:26 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.775 | ppl 876.01 | wps 8063.5 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.326
2022-01-31 16:52:26 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-31 16:52:26 | INFO | train | epoch 083 | loss 6.35 | ppl 81.55 | wps 5985.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.639 | train_wall 321 | gb_free 6.1 | wall 29009
KL Stats: Epoch 83 Divergences: Uniform: 2.733066352271949 Unigram: 3.8812998243823773
2022-01-31 16:52:26 | INFO | fairseq.trainer | begin training epoch 84
2022-01-31 16:52:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:57:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:58:16 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.843 | ppl 918.37 | wps 8057.1 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.326
2022-01-31 16:58:16 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-31 16:58:16 | INFO | train | epoch 084 | loss 6.323 | ppl 80.07 | wps 5970.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.625 | train_wall 322 | gb_free 6.1 | wall 29359
KL Stats: Epoch 84 Divergences: Uniform: 2.7399716252387494 Unigram: 3.8974870511599766
2022-01-31 16:58:16 | INFO | fairseq.trainer | begin training epoch 85
2022-01-31 16:58:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:00:17 | INFO | train_inner | epoch 085:     24 / 64 loss=6.312, ppl=79.48, wps=5848, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.626, train_wall=502, gb_free=6.1, wall=29480
2022-01-31 17:03:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:04:05 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.882 | ppl 943.79 | wps 8010.4 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.326
2022-01-31 17:04:05 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-31 17:04:05 | INFO | train | epoch 085 | loss 6.3 | ppl 78.79 | wps 5985.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.635 | train_wall 321 | gb_free 6.1 | wall 29708
KL Stats: Epoch 85 Divergences: Uniform: 2.7499357247638323 Unigram: 3.920821769577209
2022-01-31 17:04:05 | INFO | fairseq.trainer | begin training epoch 86
2022-01-31 17:04:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:09:08 | INFO | train_inner | epoch 086:     60 / 64 loss=6.297, ppl=78.64, wps=6157.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.638, train_wall=502, gb_free=6.1, wall=30011
2022-01-31 17:09:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:09:54 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.933 | ppl 977.34 | wps 8027 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.326
2022-01-31 17:09:54 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-31 17:09:54 | INFO | train | epoch 086 | loss 6.276 | ppl 77.47 | wps 5981.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.639 | train_wall 321 | gb_free 6.1 | wall 30057
KL Stats: Epoch 86 Divergences: Uniform: 2.749816638440277 Unigram: 3.9447428747330355
2022-01-31 17:09:54 | INFO | fairseq.trainer | begin training epoch 87
2022-01-31 17:09:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:15:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:15:44 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.93 | ppl 975.62 | wps 8024.2 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.326
2022-01-31 17:15:44 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-31 17:15:44 | INFO | train | epoch 087 | loss 6.254 | ppl 76.3 | wps 5967 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.656 | train_wall 322 | gb_free 6.1 | wall 30407
KL Stats: Epoch 87 Divergences: Uniform: 2.7570176675909104 Unigram: 3.9567084475405947
2022-01-31 17:15:44 | INFO | fairseq.trainer | begin training epoch 88
2022-01-31 17:15:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:18:26 | INFO | train_inner | epoch 088:     32 / 64 loss=6.24, ppl=75.6, wps=5844.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.653, train_wall=502, gb_free=6.1, wall=30568
2022-01-31 17:21:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:21:33 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.901 | ppl 955.9 | wps 8096.3 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.326
2022-01-31 17:21:33 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-31 17:21:33 | INFO | train | epoch 088 | loss 6.231 | ppl 75.1 | wps 5988.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.651 | train_wall 321 | gb_free 6.1 | wall 30756
KL Stats: Epoch 88 Divergences: Uniform: 2.763481384587193 Unigram: 3.9818362478568616
2022-01-31 17:21:33 | INFO | fairseq.trainer | begin training epoch 89
2022-01-31 17:21:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:27:22 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.911 | ppl 962.89 | wps 8046.3 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.326
2022-01-31 17:27:22 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-31 17:27:22 | INFO | train | epoch 089 | loss 6.213 | ppl 74.2 | wps 5979.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.674 | train_wall 321 | gb_free 6.1 | wall 31105
KL Stats: Epoch 89 Divergences: Uniform: 2.772029917556553 Unigram: 3.9957191701788295
2022-01-31 17:27:22 | INFO | fairseq.trainer | begin training epoch 90
2022-01-31 17:27:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:27:42 | INFO | train_inner | epoch 090:      4 / 64 loss=6.224, ppl=74.73, wps=5853.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.667, train_wall=501, gb_free=6.1, wall=31125
2022-01-31 17:32:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:33:12 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.974 | ppl 1005.38 | wps 8059.9 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.326
2022-01-31 17:33:12 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-31 17:33:12 | INFO | train | epoch 090 | loss 6.188 | ppl 72.91 | wps 5970.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.655 | train_wall 322 | gb_free 6.1 | wall 31455
KL Stats: Epoch 90 Divergences: Uniform: 2.7743925227094532 Unigram: 4.011171219457905
2022-01-31 17:33:12 | INFO | fairseq.trainer | begin training epoch 91
2022-01-31 17:33:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:36:34 | INFO | train_inner | epoch 091:     40 / 64 loss=6.17, ppl=71.99, wps=6147.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.653, train_wall=503, gb_free=6.1, wall=31657
2022-01-31 17:38:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:39:01 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.945 | ppl 985.5 | wps 8035.2 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.326
2022-01-31 17:39:01 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-31 17:39:01 | INFO | train | epoch 091 | loss 6.166 | ppl 71.78 | wps 5978.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.657 | train_wall 321 | gb_free 6.1 | wall 31804
KL Stats: Epoch 91 Divergences: Uniform: 2.7827876296722778 Unigram: 4.044986030868144
2022-01-31 17:39:01 | INFO | fairseq.trainer | begin training epoch 92
2022-01-31 17:39:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:44:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:44:50 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.98 | ppl 1010.04 | wps 8066.1 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.326
2022-01-31 17:44:50 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-31 17:44:50 | INFO | train | epoch 092 | loss 6.147 | ppl 70.88 | wps 5980.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.681 | train_wall 321 | gb_free 6.1 | wall 32153
KL Stats: Epoch 92 Divergences: Uniform: 2.789062773022607 Unigram: 4.062267832792022
2022-01-31 17:44:50 | INFO | fairseq.trainer | begin training epoch 93
2022-01-31 17:44:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:45:51 | INFO | train_inner | epoch 093:     12 / 64 loss=6.156, ppl=71.32, wps=5851.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.674, train_wall=501, gb_free=6.1, wall=32214
2022-01-31 17:50:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:50:39 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.911 | ppl 962.51 | wps 8068.5 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.326
2022-01-31 17:50:39 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-31 17:50:39 | INFO | train | epoch 093 | loss 6.129 | ppl 70 | wps 5983.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.677 | train_wall 321 | gb_free 6.1 | wall 32502
KL Stats: Epoch 93 Divergences: Uniform: 2.7930974417456613 Unigram: 4.082826242518859
2022-01-31 17:50:40 | INFO | fairseq.trainer | begin training epoch 94
2022-01-31 17:50:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:54:41 | INFO | train_inner | epoch 094:     48 / 64 loss=6.115, ppl=69.29, wps=6162.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.68, train_wall=502, gb_free=6.1, wall=32744
2022-01-31 17:56:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:56:28 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 10.009 | ppl 1030.45 | wps 8068.4 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.326
2022-01-31 17:56:28 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-31 17:56:28 | INFO | train | epoch 094 | loss 6.108 | ppl 68.96 | wps 5994.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.679 | train_wall 320 | gb_free 6.1 | wall 32851
KL Stats: Epoch 94 Divergences: Uniform: 2.794718596335257 Unigram: 4.100380602911532
2022-01-31 17:56:28 | INFO | fairseq.trainer | begin training epoch 95
2022-01-31 17:56:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:01:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:02:17 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 10.034 | ppl 1048.51 | wps 8070.3 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.326
2022-01-31 18:02:17 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-31 18:02:17 | INFO | train | epoch 095 | loss 6.088 | ppl 68.01 | wps 5982.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.671 | train_wall 321 | gb_free 6.1 | wall 33200
KL Stats: Epoch 95 Divergences: Uniform: 2.798401115843311 Unigram: 4.116616116594432
2022-01-31 18:02:17 | INFO | fairseq.trainer | begin training epoch 96
2022-01-31 18:02:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:03:58 | INFO | train_inner | epoch 096:     20 / 64 loss=6.087, ppl=67.98, wps=5857, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.679, train_wall=501, gb_free=6.1, wall=33301
2022-01-31 18:07:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:08:05 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.938 | ppl 981.04 | wps 8144.3 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.326
2022-01-31 18:08:05 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-31 18:08:05 | INFO | train | epoch 096 | loss 6.071 | ppl 67.21 | wps 6005 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.698 | train_wall 320 | gb_free 6.1 | wall 33548
KL Stats: Epoch 96 Divergences: Uniform: 2.8145845751205765 Unigram: 4.132888318801318
2022-01-31 18:08:05 | INFO | fairseq.trainer | begin training epoch 97
2022-01-31 18:08:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:12:46 | INFO | train_inner | epoch 097:     56 / 64 loss=6.065, ppl=66.94, wps=6187.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.693, train_wall=500, gb_free=6.1, wall=33829
2022-01-31 18:13:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:13:53 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 10.029 | ppl 1044.88 | wps 8033.5 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.326
2022-01-31 18:13:53 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-31 18:13:53 | INFO | train | epoch 097 | loss 6.054 | ppl 66.42 | wps 6004.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.694 | train_wall 320 | gb_free 6.1 | wall 33896
KL Stats: Epoch 97 Divergences: Uniform: 2.8203055707285576 Unigram: 4.15749548320711
2022-01-31 18:13:53 | INFO | fairseq.trainer | begin training epoch 98
2022-01-31 18:13:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:19:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:19:43 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.983 | ppl 1012.16 | wps 8034.8 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.326
2022-01-31 18:19:43 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-31 18:19:43 | INFO | train | epoch 098 | loss 6.034 | ppl 65.54 | wps 5969.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.722 | train_wall 322 | gb_free 6.1 | wall 34245
KL Stats: Epoch 98 Divergences: Uniform: 2.8204585626503125 Unigram: 4.162579997613385
2022-01-31 18:19:43 | INFO | fairseq.trainer | begin training epoch 99
2022-01-31 18:19:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:22:03 | INFO | train_inner | epoch 099:     28 / 64 loss=6.025, ppl=65.13, wps=5851.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.724, train_wall=501, gb_free=6.1, wall=34386
2022-01-31 18:25:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:25:31 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 10.008 | ppl 1029.95 | wps 8074.2 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.326
2022-01-31 18:25:31 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-31 18:25:31 | INFO | train | epoch 099 | loss 6.016 | ppl 64.72 | wps 5990.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.722 | train_wall 321 | gb_free 6.1 | wall 34594
KL Stats: Epoch 99 Divergences: Uniform: 2.826178525640231 Unigram: 4.1873297947436185
2022-01-31 18:25:31 | INFO | fairseq.trainer | begin training epoch 100
2022-01-31 18:25:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:30:53 | INFO | train_inner | epoch 100:     64 / 64 loss=6.019, ppl=64.83, wps=6154.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.723, train_wall=501, gb_free=6.1, wall=34916
2022-01-31 18:30:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:31:20 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 10.007 | ppl 1028.75 | wps 8068.4 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.326
2022-01-31 18:31:20 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-31 18:31:20 | INFO | train | epoch 100 | loss 6.001 | ppl 64.04 | wps 5986.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.727 | train_wall 321 | gb_free 6.1 | wall 34943
KL Stats: Epoch 100 Divergences: Uniform: 2.824272446985833 Unigram: 4.195015192349328
2022-01-31 18:31:20 | INFO | fairseq.trainer | begin training epoch 101
2022-01-31 18:31:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:36:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:37:09 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 10.07 | ppl 1075.1 | wps 7988.1 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.326
2022-01-31 18:37:09 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-31 18:37:09 | INFO | train | epoch 101 | loss 5.983 | ppl 63.23 | wps 5987 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.731 | train_wall 321 | gb_free 6.1 | wall 35292
KL Stats: Epoch 101 Divergences: Uniform: 2.8393487423407042 Unigram: 4.218693767713537
2022-01-31 18:37:09 | INFO | fairseq.trainer | begin training epoch 102
2022-01-31 18:37:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:40:12 | INFO | train_inner | epoch 102:     36 / 64 loss=5.968, ppl=62.61, wps=5851.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.731, train_wall=503, gb_free=6.1, wall=35474
2022-01-31 18:42:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:42:58 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 10.079 | ppl 1081.82 | wps 8079 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.326
2022-01-31 18:42:58 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-31 18:42:58 | INFO | train | epoch 102 | loss 5.968 | ppl 62.57 | wps 5978.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.729 | train_wall 321 | gb_free 6.1 | wall 35641
KL Stats: Epoch 102 Divergences: Uniform: 2.839530661642631 Unigram: 4.2357347550203786
2022-01-31 18:42:58 | INFO | fairseq.trainer | begin training epoch 103
2022-01-31 18:42:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:48:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:48:48 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 10.091 | ppl 1090.82 | wps 8070.2 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.326
2022-01-31 18:48:48 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-31 18:48:48 | INFO | train | epoch 103 | loss 5.949 | ppl 61.78 | wps 5966.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.721 | train_wall 322 | gb_free 6.1 | wall 35991
KL Stats: Epoch 103 Divergences: Uniform: 2.8518920019897314 Unigram: 4.2535451524161365
2022-01-31 18:48:48 | INFO | fairseq.trainer | begin training epoch 104
2022-01-31 18:48:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:49:29 | INFO | train_inner | epoch 104:      8 / 64 loss=5.957, ppl=62.11, wps=5848.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.722, train_wall=502, gb_free=6.1, wall=36032
2022-01-31 18:54:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:54:37 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 10.078 | ppl 1080.67 | wps 8067.2 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.326
2022-01-31 18:54:37 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-31 18:54:37 | INFO | train | epoch 104 | loss 5.936 | ppl 61.23 | wps 5991.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.735 | train_wall 321 | gb_free 6.1 | wall 36340
KL Stats: Epoch 104 Divergences: Uniform: 2.846316067525878 Unigram: 4.271676171900059
2022-01-31 18:54:37 | INFO | fairseq.trainer | begin training epoch 105
2022-01-31 18:54:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:58:19 | INFO | train_inner | epoch 105:     44 / 64 loss=5.924, ppl=60.72, wps=6163.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.741, train_wall=502, gb_free=6.1, wall=36562
2022-01-31 18:59:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:00:26 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 10.029 | ppl 1044.78 | wps 8074.6 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.326
2022-01-31 19:00:26 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-31 19:00:26 | INFO | train | epoch 105 | loss 5.921 | ppl 60.57 | wps 5986.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.745 | train_wall 321 | gb_free 6.1 | wall 36689
KL Stats: Epoch 105 Divergences: Uniform: 2.853214934408744 Unigram: 4.285304926894688
2022-01-31 19:00:26 | INFO | fairseq.trainer | begin training epoch 106
2022-01-31 19:00:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:05:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:06:15 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 10.108 | ppl 1103.91 | wps 8093.7 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.326
2022-01-31 19:06:15 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-31 19:06:15 | INFO | train | epoch 106 | loss 5.903 | ppl 59.84 | wps 5986.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.729 | train_wall 321 | gb_free 6.1 | wall 37038
KL Stats: Epoch 106 Divergences: Uniform: 2.8544577686616277 Unigram: 4.292459220183567
2022-01-31 19:06:15 | INFO | fairseq.trainer | begin training epoch 107
2022-01-31 19:06:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:07:36 | INFO | train_inner | epoch 107:     16 / 64 loss=5.907, ppl=60, wps=5857.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.737, train_wall=501, gb_free=6.1, wall=37118
2022-01-31 19:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:12:03 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 10.11 | ppl 1105.39 | wps 8066.9 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.326
2022-01-31 19:12:03 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-31 19:12:03 | INFO | train | epoch 107 | loss 5.887 | ppl 59.19 | wps 5991.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.745 | train_wall 321 | gb_free 6.1 | wall 37386
KL Stats: Epoch 107 Divergences: Uniform: 2.8634388464797724 Unigram: 4.313897806964236
2022-01-31 19:12:03 | INFO | fairseq.trainer | begin training epoch 108
2022-01-31 19:12:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:16:27 | INFO | train_inner | epoch 108:     52 / 64 loss=5.883, ppl=59, wps=6156.5, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.756, train_wall=502, gb_free=6.1, wall=37649
2022-01-31 19:17:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:17:53 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 10.112 | ppl 1106.8 | wps 8045.8 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.326
2022-01-31 19:17:53 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-31 19:17:53 | INFO | train | epoch 108 | loss 5.876 | ppl 58.74 | wps 5974.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.777 | train_wall 321 | gb_free 6.1 | wall 37736
KL Stats: Epoch 108 Divergences: Uniform: 2.867727607078569 Unigram: 4.324856370171599
2022-01-31 19:17:53 | INFO | fairseq.trainer | begin training epoch 109
2022-01-31 19:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:23:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:23:42 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 10.121 | ppl 1113.86 | wps 8075.5 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.326
2022-01-31 19:23:42 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-31 19:23:42 | INFO | train | epoch 109 | loss 5.86 | ppl 58.09 | wps 5982 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.763 | train_wall 321 | gb_free 6.1 | wall 38085
KL Stats: Epoch 109 Divergences: Uniform: 2.8681110768544635 Unigram: 4.346300518147637
2022-01-31 19:23:42 | INFO | fairseq.trainer | begin training epoch 110
2022-01-31 19:23:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:25:44 | INFO | train_inner | epoch 110:     24 / 64 loss=5.854, ppl=57.86, wps=5850.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.769, train_wall=501, gb_free=6.1, wall=38206
2022-01-31 19:29:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:29:32 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.166 | ppl 1148.73 | wps 8107.4 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.326
2022-01-31 19:29:32 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-31 19:29:32 | INFO | train | epoch 110 | loss 5.847 | ppl 57.54 | wps 5978.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.769 | train_wall 322 | gb_free 6.1 | wall 38434
KL Stats: Epoch 110 Divergences: Uniform: 2.8757373250647222 Unigram: 4.360464246337592
2022-01-31 19:29:32 | INFO | fairseq.trainer | begin training epoch 111
2022-01-31 19:29:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:34:32 | INFO | train_inner | epoch 111:     60 / 64 loss=5.846, ppl=57.51, wps=6190.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.778, train_wall=500, gb_free=6.1, wall=38734
2022-01-31 19:34:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:35:17 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 10.132 | ppl 1121.93 | wps 8176.7 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.326
2022-01-31 19:35:17 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-31 19:35:17 | INFO | train | epoch 111 | loss 5.833 | ppl 57 | wps 6043.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.783 | train_wall 318 | gb_free 6.1 | wall 38780
KL Stats: Epoch 111 Divergences: Uniform: 2.8757006983412037 Unigram: 4.379962283666537
2022-01-31 19:35:17 | INFO | fairseq.trainer | begin training epoch 112
2022-01-31 19:35:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:40:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:41:04 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.18 | ppl 1159.82 | wps 8032 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.326
2022-01-31 19:41:04 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-31 19:41:04 | INFO | train | epoch 112 | loss 5.818 | ppl 56.42 | wps 6016.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.779 | train_wall 319 | gb_free 6.1 | wall 39127
KL Stats: Epoch 112 Divergences: Uniform: 2.879814677591912 Unigram: 4.395338171490341
2022-01-31 19:41:04 | INFO | fairseq.trainer | begin training epoch 113
2022-01-31 19:41:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:43:46 | INFO | train_inner | epoch 113:     32 / 64 loss=5.806, ppl=55.96, wps=5877.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.778, train_wall=499, gb_free=6.1, wall=39289
2022-01-31 19:46:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:46:54 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.134 | ppl 1123.32 | wps 8039.3 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.326
2022-01-31 19:46:54 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-31 19:46:54 | INFO | train | epoch 113 | loss 5.803 | ppl 55.84 | wps 5972.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.773 | train_wall 322 | gb_free 6.1 | wall 39477
KL Stats: Epoch 113 Divergences: Uniform: 2.887484484654345 Unigram: 4.408567771877758
2022-01-31 19:46:54 | INFO | fairseq.trainer | begin training epoch 114
2022-01-31 19:46:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:52:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:52:44 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 10.158 | ppl 1142.84 | wps 8082.6 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.326
2022-01-31 19:52:44 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-31 19:52:44 | INFO | train | epoch 114 | loss 5.791 | ppl 55.37 | wps 5974.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.791 | train_wall 322 | gb_free 6.1 | wall 39826
KL Stats: Epoch 114 Divergences: Uniform: 2.888618008486176 Unigram: 4.419617988774367
2022-01-31 19:52:44 | INFO | fairseq.trainer | begin training epoch 115
2022-01-31 19:52:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:53:04 | INFO | train_inner | epoch 115:      4 / 64 loss=5.803, ppl=55.84, wps=5846.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.789, train_wall=502, gb_free=6.1, wall=39847
2022-01-31 19:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:58:32 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.163 | ppl 1146.61 | wps 8017.3 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.326
2022-01-31 19:58:32 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-31 19:58:32 | INFO | train | epoch 115 | loss 5.779 | ppl 54.9 | wps 5991 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.8 | train_wall 320 | gb_free 6.1 | wall 40175
KL Stats: Epoch 115 Divergences: Uniform: 2.893427841725796 Unigram: 4.43073827533578
2022-01-31 19:58:32 | INFO | fairseq.trainer | begin training epoch 116
2022-01-31 19:58:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:01:54 | INFO | train_inner | epoch 116:     40 / 64 loss=5.764, ppl=54.35, wps=6162.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.791, train_wall=502, gb_free=6.1, wall=40377
2022-01-31 20:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:04:21 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.127 | ppl 1118.07 | wps 8052 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.326
2022-01-31 20:04:21 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-31 20:04:21 | INFO | train | epoch 116 | loss 5.765 | ppl 54.38 | wps 5986.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.788 | train_wall 321 | gb_free 6.1 | wall 40524
KL Stats: Epoch 116 Divergences: Uniform: 2.8974294330192256 Unigram: 4.437428403736695
2022-01-31 20:04:21 | INFO | fairseq.trainer | begin training epoch 117
2022-01-31 20:04:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:10:10 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.225 | ppl 1196.82 | wps 8084.3 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.326
2022-01-31 20:10:10 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-31 20:10:10 | INFO | train | epoch 117 | loss 5.754 | ppl 53.98 | wps 5981.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.801 | train_wall 321 | gb_free 6.1 | wall 40873
KL Stats: Epoch 117 Divergences: Uniform: 2.896982778298606 Unigram: 4.461594135032143
2022-01-31 20:10:10 | INFO | fairseq.trainer | begin training epoch 118
2022-01-31 20:10:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:11:11 | INFO | train_inner | epoch 118:     12 / 64 loss=5.76, ppl=54.18, wps=5854.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.808, train_wall=501, gb_free=6.1, wall=40934
2022-01-31 20:15:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:16:00 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.171 | ppl 1153.16 | wps 8050.8 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.326
2022-01-31 20:16:00 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-31 20:16:00 | INFO | train | epoch 118 | loss 5.742 | ppl 53.5 | wps 5980.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.812 | train_wall 321 | gb_free 6.1 | wall 41222
KL Stats: Epoch 118 Divergences: Uniform: 2.90852886467471 Unigram: 4.4740443212743655
2022-01-31 20:16:00 | INFO | fairseq.trainer | begin training epoch 119
2022-01-31 20:16:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:20:02 | INFO | train_inner | epoch 119:     48 / 64 loss=5.73, ppl=53.08, wps=6153.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.795, train_wall=503, gb_free=6.1, wall=41465
2022-01-31 20:21:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:21:49 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.157 | ppl 1141.33 | wps 8028.2 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.326
2022-01-31 20:21:49 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-31 20:21:49 | INFO | train | epoch 119 | loss 5.727 | ppl 52.97 | wps 5979.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.795 | train_wall 321 | gb_free 6.1 | wall 41572
KL Stats: Epoch 119 Divergences: Uniform: 2.9090011743138326 Unigram: 4.493895493027797
2022-01-31 20:21:49 | INFO | fairseq.trainer | begin training epoch 120
2022-01-31 20:21:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:27:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:27:39 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.224 | ppl 1196.03 | wps 8035.3 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.326
2022-01-31 20:27:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-31 20:27:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint120.pt
2022-01-31 20:27:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint120.pt
2022-01-31 20:27:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.224) (writing took 4.3352886736392975 seconds)
2022-01-31 20:27:43 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-31 20:27:43 | INFO | train | epoch 120 | loss 5.718 | ppl 52.65 | wps 5899.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.841 | train_wall 322 | gb_free 6.1 | wall 41926
KL Stats: Epoch 120 Divergences: Uniform: 2.913523930948785 Unigram: 4.500055369619682
2022-01-31 20:27:43 | INFO | fairseq.trainer | begin training epoch 121
2022-01-31 20:27:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:29:24 | INFO | train_inner | epoch 121:     20 / 64 loss=5.72, ppl=52.72, wps=5801, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.843, train_wall=502, gb_free=6.1, wall=42027
2022-01-31 20:33:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:33:32 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.202 | ppl 1178.1 | wps 8058 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.326
2022-01-31 20:33:32 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-31 20:33:32 | INFO | train | epoch 121 | loss 5.708 | ppl 52.27 | wps 5976.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.832 | train_wall 321 | gb_free 6.1 | wall 42275
KL Stats: Epoch 121 Divergences: Uniform: 2.9143809572728645 Unigram: 4.514382908834228
2022-01-31 20:33:32 | INFO | fairseq.trainer | begin training epoch 122
2022-01-31 20:33:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:38:15 | INFO | train_inner | epoch 122:     56 / 64 loss=5.704, ppl=52.12, wps=6157.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.825, train_wall=502, gb_free=6.1, wall=42558
2022-01-31 20:38:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:39:21 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.184 | ppl 1163.16 | wps 8071.3 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.326
2022-01-31 20:39:21 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-31 20:39:21 | INFO | train | epoch 122 | loss 5.696 | ppl 51.83 | wps 5992.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.833 | train_wall 321 | gb_free 6.1 | wall 42624
KL Stats: Epoch 122 Divergences: Uniform: 2.91664986985025 Unigram: 4.526332197218961
2022-01-31 20:39:21 | INFO | fairseq.trainer | begin training epoch 123
2022-01-31 20:39:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:44:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:45:10 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.226 | ppl 1197.87 | wps 8089.5 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.326
2022-01-31 20:45:10 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-31 20:45:10 | INFO | train | epoch 123 | loss 5.682 | ppl 51.35 | wps 5985.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.835 | train_wall 321 | gb_free 6.1 | wall 42973
KL Stats: Epoch 123 Divergences: Uniform: 2.9160364511221504 Unigram: 4.544041454553922
2022-01-31 20:45:10 | INFO | fairseq.trainer | begin training epoch 124
2022-01-31 20:45:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:47:31 | INFO | train_inner | epoch 124:     28 / 64 loss=5.675, ppl=51.1, wps=5862.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.827, train_wall=501, gb_free=6.1, wall=43114
2022-01-31 20:50:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:50:58 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.217 | ppl 1190.37 | wps 8047.3 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.326
2022-01-31 20:50:58 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-31 20:50:58 | INFO | train | epoch 124 | loss 5.67 | ppl 50.93 | wps 5994.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.824 | train_wall 320 | gb_free 6.1 | wall 43321
KL Stats: Epoch 124 Divergences: Uniform: 2.915198025362681 Unigram: 4.5475545003580296
2022-01-31 20:50:58 | INFO | fairseq.trainer | begin training epoch 125
2022-01-31 20:50:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:56:18 | INFO | train_inner | epoch 125:     64 / 64 loss=5.675, ppl=51.09, wps=6186.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.834, train_wall=498, gb_free=6.1, wall=43641
2022-01-31 20:56:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:56:45 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.261 | ppl 1227.09 | wps 8136.5 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.326
2022-01-31 20:56:45 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-31 20:56:45 | INFO | train | epoch 125 | loss 5.661 | ppl 50.59 | wps 6030.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.831 | train_wall 319 | gb_free 6.1 | wall 43667
KL Stats: Epoch 125 Divergences: Uniform: 2.9228282789627396 Unigram: 4.566401216859982
2022-01-31 20:56:45 | INFO | fairseq.trainer | begin training epoch 126
2022-01-31 20:56:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:02:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:02:32 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.196 | ppl 1173.32 | wps 8074.4 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.326
2022-01-31 21:02:32 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-31 21:02:32 | INFO | train | epoch 126 | loss 5.65 | ppl 50.21 | wps 6016.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.825 | train_wall 319 | gb_free 6.1 | wall 44015
KL Stats: Epoch 126 Divergences: Uniform: 2.931145260506506 Unigram: 4.583903470570598
2022-01-31 21:02:32 | INFO | fairseq.trainer | begin training epoch 127
2022-01-31 21:02:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:05:34 | INFO | train_inner | epoch 127:     36 / 64 loss=5.638, ppl=49.81, wps=5879.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.851, train_wall=500, gb_free=6.1, wall=44196
2022-01-31 21:07:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:08:21 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.195 | ppl 1172.5 | wps 8061.8 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.326
2022-01-31 21:08:21 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-31 21:08:21 | INFO | train | epoch 127 | loss 5.641 | ppl 49.91 | wps 5983.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.877 | train_wall 321 | gb_free 6.1 | wall 44364
KL Stats: Epoch 127 Divergences: Uniform: 2.9329548366748117 Unigram: 4.585434422617852
2022-01-31 21:08:21 | INFO | fairseq.trainer | begin training epoch 128
2022-01-31 21:08:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:13:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:14:10 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.228 | ppl 1198.91 | wps 8048.9 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.326
2022-01-31 21:14:10 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-31 21:14:10 | INFO | train | epoch 128 | loss 5.629 | ppl 49.48 | wps 5982.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.868 | train_wall 321 | gb_free 6.1 | wall 44713
KL Stats: Epoch 128 Divergences: Uniform: 2.923145826054424 Unigram: 4.595537100375836
2022-01-31 21:14:10 | INFO | fairseq.trainer | begin training epoch 129
2022-01-31 21:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:14:51 | INFO | train_inner | epoch 129:      8 / 64 loss=5.636, ppl=49.74, wps=5852.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.866, train_wall=501, gb_free=6.1, wall=44753
2022-01-31 21:19:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:19:59 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.189 | ppl 1167.42 | wps 8081.5 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.326
2022-01-31 21:19:59 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-31 21:19:59 | INFO | train | epoch 129 | loss 5.622 | ppl 49.25 | wps 5984.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.888 | train_wall 321 | gb_free 6.1 | wall 45062
KL Stats: Epoch 129 Divergences: Uniform: 2.929744821625501 Unigram: 4.607004362268021
2022-01-31 21:19:59 | INFO | fairseq.trainer | begin training epoch 130
2022-01-31 21:19:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:23:42 | INFO | train_inner | epoch 130:     44 / 64 loss=5.609, ppl=48.82, wps=6154.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.875, train_wall=503, gb_free=6.1, wall=45284
2022-01-31 21:25:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:25:49 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.288 | ppl 1250.45 | wps 8044.4 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.326
2022-01-31 21:25:49 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-31 21:25:49 | INFO | train | epoch 130 | loss 5.608 | ppl 48.79 | wps 5974.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.865 | train_wall 321 | gb_free 6.1 | wall 45411
KL Stats: Epoch 130 Divergences: Uniform: 2.9330096932659666 Unigram: 4.628320513647819
2022-01-31 21:25:49 | INFO | fairseq.trainer | begin training epoch 131
2022-01-31 21:25:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:31:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:31:38 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.251 | ppl 1218.75 | wps 8043 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.326
2022-01-31 21:31:38 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-31 21:31:38 | INFO | train | epoch 131 | loss 5.601 | ppl 48.52 | wps 5983.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.894 | train_wall 321 | gb_free 6.1 | wall 45760
KL Stats: Epoch 131 Divergences: Uniform: 2.934985056698084 Unigram: 4.629325769765611
2022-01-31 21:31:38 | INFO | fairseq.trainer | begin training epoch 132
2022-01-31 21:31:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:32:59 | INFO | train_inner | epoch 132:     16 / 64 loss=5.603, ppl=48.6, wps=5852, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.882, train_wall=501, gb_free=6.1, wall=45841
2022-01-31 21:37:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:37:27 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.265 | ppl 1230.66 | wps 8103.4 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.326
2022-01-31 21:37:27 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-31 21:37:27 | INFO | train | epoch 132 | loss 5.589 | ppl 48.14 | wps 5977.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.885 | train_wall 322 | gb_free 6.1 | wall 46110
KL Stats: Epoch 132 Divergences: Uniform: 2.9356706579473353 Unigram: 4.653152776304161
2022-01-31 21:37:27 | INFO | fairseq.trainer | begin training epoch 133
2022-01-31 21:37:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:41:50 | INFO | train_inner | epoch 133:     52 / 64 loss=5.584, ppl=47.97, wps=6150.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.904, train_wall=503, gb_free=6.1, wall=46373
2022-01-31 21:42:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:43:16 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.282 | ppl 1245.27 | wps 8062.1 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.326
2022-01-31 21:43:16 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-31 21:43:16 | INFO | train | epoch 133 | loss 5.58 | ppl 47.84 | wps 5977.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.912 | train_wall 321 | gb_free 6.1 | wall 46459
KL Stats: Epoch 133 Divergences: Uniform: 2.947139322413797 Unigram: 4.658479379644619
2022-01-31 21:43:16 | INFO | fairseq.trainer | begin training epoch 134
2022-01-31 21:43:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:49:05 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.317 | ppl 1275.84 | wps 8051.6 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.326
2022-01-31 21:49:05 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-31 21:49:05 | INFO | train | epoch 134 | loss 5.571 | ppl 47.55 | wps 5993.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.926 | train_wall 320 | gb_free 6.1 | wall 46808
KL Stats: Epoch 134 Divergences: Uniform: 2.9411135552673406 Unigram: 4.677324379702118
2022-01-31 21:49:05 | INFO | fairseq.trainer | begin training epoch 135
2022-01-31 21:49:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:51:06 | INFO | train_inner | epoch 135:     24 / 64 loss=5.571, ppl=47.53, wps=5862.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.924, train_wall=500, gb_free=6.1, wall=46929
2022-01-31 21:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:54:54 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.251 | ppl 1218.18 | wps 8090.4 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.326
2022-01-31 21:54:54 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-31 21:54:54 | INFO | train | epoch 135 | loss 5.56 | ppl 47.19 | wps 5982.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.884 | train_wall 321 | gb_free 6.1 | wall 47157
KL Stats: Epoch 135 Divergences: Uniform: 2.950843291657266 Unigram: 4.686307114280704
2022-01-31 21:54:54 | INFO | fairseq.trainer | begin training epoch 136
2022-01-31 21:54:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:59:58 | INFO | train_inner | epoch 136:     60 / 64 loss=5.562, ppl=47.24, wps=6147, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.901, train_wall=503, gb_free=6.1, wall=47460
2022-01-31 22:00:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:00:44 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.327 | ppl 1284.9 | wps 8012.4 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.326
2022-01-31 22:00:44 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-31 22:00:44 | INFO | train | epoch 136 | loss 5.554 | ppl 46.97 | wps 5969.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.924 | train_wall 322 | gb_free 6.1 | wall 47507
KL Stats: Epoch 136 Divergences: Uniform: 2.944617387616682 Unigram: 4.688226809884727
2022-01-31 22:00:44 | INFO | fairseq.trainer | begin training epoch 137
2022-01-31 22:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:06:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:06:34 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.411 | ppl 1361.73 | wps 8058.3 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.326
2022-01-31 22:06:34 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-31 22:06:34 | INFO | train | epoch 137 | loss 5.543 | ppl 46.62 | wps 5965.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.913 | train_wall 322 | gb_free 6.1 | wall 47857
KL Stats: Epoch 137 Divergences: Uniform: 2.946300688395223 Unigram: 4.705965392175802
2022-01-31 22:06:34 | INFO | fairseq.trainer | begin training epoch 138
2022-01-31 22:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:09:16 | INFO | train_inner | epoch 138:     32 / 64 loss=5.534, ppl=46.34, wps=5834.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.913, train_wall=503, gb_free=6.1, wall=48019
2022-01-31 22:11:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:12:24 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.385 | ppl 1337.12 | wps 8046.8 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.326
2022-01-31 22:12:24 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-31 22:12:24 | INFO | train | epoch 138 | loss 5.534 | ppl 46.32 | wps 5971.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.932 | train_wall 322 | gb_free 6.1 | wall 48207
KL Stats: Epoch 138 Divergences: Uniform: 2.9470303372917734 Unigram: 4.708562935610321
2022-01-31 22:12:24 | INFO | fairseq.trainer | begin training epoch 139
2022-01-31 22:12:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:18:12 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.315 | ppl 1274.14 | wps 8142.8 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.326
2022-01-31 22:18:12 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-31 22:18:12 | INFO | train | epoch 139 | loss 5.525 | ppl 46.04 | wps 6004.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.94 | train_wall 320 | gb_free 6.1 | wall 48555
KL Stats: Epoch 139 Divergences: Uniform: 2.951840734883938 Unigram: 4.724573653060703
2022-01-31 22:18:12 | INFO | fairseq.trainer | begin training epoch 140
2022-01-31 22:18:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:18:32 | INFO | train_inner | epoch 140:      4 / 64 loss=5.533, ppl=46.29, wps=5870.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.946, train_wall=500, gb_free=6.1, wall=48575
2022-01-31 22:23:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:23:57 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.317 | ppl 1275.93 | wps 8139.4 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.326
2022-01-31 22:23:57 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-31 22:23:57 | INFO | train | epoch 140 | loss 5.518 | ppl 45.83 | wps 6049.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.956 | train_wall 318 | gb_free 6.1 | wall 48900
KL Stats: Epoch 140 Divergences: Uniform: 2.951970174690379 Unigram: 4.729392544407343
2022-01-31 22:23:57 | INFO | fairseq.trainer | begin training epoch 141
2022-01-31 22:23:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:27:18 | INFO | train_inner | epoch 141:     40 / 64 loss=5.509, ppl=45.54, wps=6205.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.949, train_wall=498, gb_free=6.1, wall=49101
2022-01-31 22:29:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:29:45 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.319 | ppl 1277.59 | wps 8078.8 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.326
2022-01-31 22:29:45 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-31 22:29:45 | INFO | train | epoch 141 | loss 5.508 | ppl 45.5 | wps 5997.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.936 | train_wall 320 | gb_free 6.1 | wall 49248
KL Stats: Epoch 141 Divergences: Uniform: 2.9578667965350127 Unigram: 4.747178242992836
2022-01-31 22:29:45 | INFO | fairseq.trainer | begin training epoch 142
2022-01-31 22:29:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:35:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:35:34 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.308 | ppl 1267.72 | wps 8069.2 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.326
2022-01-31 22:35:34 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-31 22:35:34 | INFO | train | epoch 142 | loss 5.499 | ppl 45.22 | wps 5991.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.949 | train_wall 321 | gb_free 6.1 | wall 49597
KL Stats: Epoch 142 Divergences: Uniform: 2.9559981076917383 Unigram: 4.753810440652697
2022-01-31 22:35:34 | INFO | fairseq.trainer | begin training epoch 143
2022-01-31 22:35:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:36:34 | INFO | train_inner | epoch 143:     12 / 64 loss=5.501, ppl=45.28, wps=5863.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.945, train_wall=500, gb_free=6.1, wall=49657
2022-01-31 22:40:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:41:23 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.365 | ppl 1318.93 | wps 8075 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.326
2022-01-31 22:41:23 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-31 22:41:23 | INFO | train | epoch 143 | loss 5.494 | ppl 45.06 | wps 5983.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.967 | train_wall 321 | gb_free 6.1 | wall 49946
KL Stats: Epoch 143 Divergences: Uniform: 2.9670587138393114 Unigram: 4.763425698769235
2022-01-31 22:41:23 | INFO | fairseq.trainer | begin training epoch 144
2022-01-31 22:41:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:45:26 | INFO | train_inner | epoch 144:     48 / 64 loss=5.489, ppl=44.92, wps=6151.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.967, train_wall=503, gb_free=6.1, wall=50188
2022-01-31 22:46:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:47:12 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.39 | ppl 1342.29 | wps 8036.7 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.326
2022-01-31 22:47:12 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-31 22:47:12 | INFO | train | epoch 144 | loss 5.485 | ppl 44.8 | wps 5975.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.965 | train_wall 321 | gb_free 6.1 | wall 50295
KL Stats: Epoch 144 Divergences: Uniform: 2.9577879231609985 Unigram: 4.7651672522015325
2022-01-31 22:47:12 | INFO | fairseq.trainer | begin training epoch 145
2022-01-31 22:47:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:52:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:53:02 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.422 | ppl 1371.71 | wps 8069 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.326
2022-01-31 22:53:02 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-31 22:53:02 | INFO | train | epoch 145 | loss 5.476 | ppl 44.51 | wps 5979 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.951 | train_wall 321 | gb_free 6.1 | wall 50644
KL Stats: Epoch 145 Divergences: Uniform: 2.967391096111726 Unigram: 4.781376787889179
2022-01-31 22:53:02 | INFO | fairseq.trainer | begin training epoch 146
2022-01-31 22:53:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:54:43 | INFO | train_inner | epoch 146:     20 / 64 loss=5.473, ppl=44.43, wps=5851.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.961, train_wall=501, gb_free=6.1, wall=50746
2022-01-31 22:58:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:58:51 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.347 | ppl 1302.37 | wps 8050.5 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.326
2022-01-31 22:58:51 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-31 22:58:51 | INFO | train | epoch 146 | loss 5.468 | ppl 44.26 | wps 5988.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.988 | train_wall 321 | gb_free 6.1 | wall 50993
KL Stats: Epoch 146 Divergences: Uniform: 2.963370392600854 Unigram: 4.788961304699745
2022-01-31 22:58:51 | INFO | fairseq.trainer | begin training epoch 147
2022-01-31 22:58:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:03:33 | INFO | train_inner | epoch 147:     56 / 64 loss=5.47, ppl=44.31, wps=6159.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.992, train_wall=502, gb_free=6.1, wall=51276
2022-01-31 23:04:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:04:39 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.319 | ppl 1277.7 | wps 8096.1 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.326
2022-01-31 23:04:39 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-31 23:04:39 | INFO | train | epoch 147 | loss 5.461 | ppl 44.03 | wps 5984.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.998 | train_wall 321 | gb_free 6.1 | wall 51342
KL Stats: Epoch 147 Divergences: Uniform: 2.968024547503252 Unigram: 4.795234353395235
2022-01-31 23:04:39 | INFO | fairseq.trainer | begin training epoch 148
2022-01-31 23:04:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:10:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:10:29 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.344 | ppl 1300.1 | wps 8090.8 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.326
2022-01-31 23:10:29 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-31 23:10:29 | INFO | train | epoch 148 | loss 5.451 | ppl 43.74 | wps 5983.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.981 | train_wall 321 | gb_free 6.1 | wall 51691
KL Stats: Epoch 148 Divergences: Uniform: 2.970875453483355 Unigram: 4.814836934678458
2022-01-31 23:10:29 | INFO | fairseq.trainer | begin training epoch 149
2022-01-31 23:10:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:12:50 | INFO | train_inner | epoch 149:     28 / 64 loss=5.447, ppl=43.62, wps=5856.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.99, train_wall=501, gb_free=6.1, wall=51833
2022-01-31 23:15:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:16:17 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.364 | ppl 1317.92 | wps 8079.1 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.326
2022-01-31 23:16:17 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-31 23:16:17 | INFO | train | epoch 149 | loss 5.447 | ppl 43.63 | wps 5990.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 1.03 | train_wall 321 | gb_free 6.1 | wall 52040
KL Stats: Epoch 149 Divergences: Uniform: 2.9728071771089204 Unigram: 4.820278068674547
2022-01-31 23:16:17 | INFO | fairseq.trainer | begin training epoch 150
2022-01-31 23:16:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:21:39 | INFO | train_inner | epoch 150:     64 / 64 loss=5.449, ppl=43.67, wps=6162.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=1.017, train_wall=501, gb_free=6.1, wall=52362
2022-01-31 23:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:22:06 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.406 | ppl 1356.62 | wps 8088.2 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.326
2022-01-31 23:22:06 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-31 23:22:06 | INFO | train | epoch 150 | loss 5.437 | ppl 43.32 | wps 5987.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.999 | train_wall 321 | gb_free 6.1 | wall 52389
KL Stats: Epoch 150 Divergences: Uniform: 2.973089248087477 Unigram: 4.815940756613659
2022-01-31 23:22:06 | INFO | fairseq.trainer | begin training epoch 151
2022-01-31 23:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:27:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:27:55 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.395 | ppl 1346.83 | wps 8093.1 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.326
2022-01-31 23:27:55 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-31 23:27:55 | INFO | train | epoch 151 | loss 5.429 | ppl 43.07 | wps 5991.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 1.012 | train_wall 321 | gb_free 6.1 | wall 52737
KL Stats: Epoch 151 Divergences: Uniform: 2.9696210993696095 Unigram: 4.833747653182327
2022-01-31 23:27:55 | INFO | fairseq.trainer | begin training epoch 152
2022-01-31 23:27:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:30:56 | INFO | train_inner | epoch 152:     36 / 64 loss=5.416, ppl=42.7, wps=5868.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=1.018, train_wall=501, gb_free=6.1, wall=52919
2022-01-31 23:33:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:33:41 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.405 | ppl 1355.57 | wps 8172.8 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.326
2022-01-31 23:33:41 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-31 23:33:41 | INFO | train | epoch 152 | loss 5.422 | ppl 42.86 | wps 6034.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.016 | train_wall 319 | gb_free 6.1 | wall 53084
KL Stats: Epoch 152 Divergences: Uniform: 2.9755798518472494 Unigram: 4.846741600138211
2022-01-31 23:33:41 | INFO | fairseq.trainer | begin training epoch 153
2022-01-31 23:33:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:38:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:39:26 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.447 | ppl 1396.14 | wps 8147 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.326
2022-01-31 23:39:26 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-01-31 23:39:26 | INFO | train | epoch 153 | loss 5.413 | ppl 42.61 | wps 6046.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.992 | train_wall 318 | gb_free 6.1 | wall 53429
KL Stats: Epoch 153 Divergences: Uniform: 2.976073612597483 Unigram: 4.856112391695784
2022-01-31 23:39:26 | INFO | fairseq.trainer | begin training epoch 154
2022-01-31 23:39:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:40:06 | INFO | train_inner | epoch 154:      8 / 64 loss=5.421, ppl=42.85, wps=5922.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.998, train_wall=495, gb_free=6.1, wall=53469
2022-01-31 23:44:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:45:11 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.436 | ppl 1385.55 | wps 8179.9 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.326
2022-01-31 23:45:11 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-01-31 23:45:11 | INFO | train | epoch 154 | loss 5.408 | ppl 42.46 | wps 6059.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.035 | train_wall 317 | gb_free 6.1 | wall 53774
KL Stats: Epoch 154 Divergences: Uniform: 2.9810862469239283 Unigram: 4.857268663601933
2022-01-31 23:45:11 | INFO | fairseq.trainer | begin training epoch 155
2022-01-31 23:45:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:48:51 | INFO | train_inner | epoch 155:     44 / 64 loss=5.399, ppl=42.2, wps=6233.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=1.036, train_wall=496, gb_free=6.1, wall=53993
2022-01-31 23:50:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:50:56 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.385 | ppl 1336.99 | wps 8174.2 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.326
2022-01-31 23:50:56 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-01-31 23:50:56 | INFO | train | epoch 155 | loss 5.401 | ppl 42.25 | wps 6051.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.044 | train_wall 318 | gb_free 6.1 | wall 54119
KL Stats: Epoch 155 Divergences: Uniform: 2.9841395142974716 Unigram: 4.877648546174004
2022-01-31 23:50:56 | INFO | fairseq.trainer | begin training epoch 156
2022-01-31 23:50:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:56:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:56:41 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.458 | ppl 1406.57 | wps 8171.8 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.326
2022-01-31 23:56:41 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-01-31 23:56:41 | INFO | train | epoch 156 | loss 5.394 | ppl 42.05 | wps 6047.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.054 | train_wall 318 | gb_free 6.1 | wall 54464
KL Stats: Epoch 156 Divergences: Uniform: 2.9802092739702912 Unigram: 4.878030227757643
2022-01-31 23:56:41 | INFO | fairseq.trainer | begin training epoch 157
2022-01-31 23:56:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:58:01 | INFO | train_inner | epoch 157:     16 / 64 loss=5.399, ppl=42.21, wps=5919.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.046, train_wall=496, gb_free=6.1, wall=54544
2022-02-01 00:01:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:02:26 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.442 | ppl 1391.18 | wps 8189.3 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.326
2022-02-01 00:02:26 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-01 00:02:26 | INFO | train | epoch 157 | loss 5.386 | ppl 41.82 | wps 6064.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.024 | train_wall 317 | gb_free 6.1 | wall 54809
KL Stats: Epoch 157 Divergences: Uniform: 2.984939463234879 Unigram: 4.8915829757981655
2022-02-01 00:02:26 | INFO | fairseq.trainer | begin training epoch 158
2022-02-01 00:02:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:06:45 | INFO | train_inner | epoch 158:     52 / 64 loss=5.38, ppl=41.65, wps=6240.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.047, train_wall=496, gb_free=6.1, wall=55068
2022-02-01 00:07:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:08:10 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.44 | ppl 1389.46 | wps 8179.2 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.326
2022-02-01 00:08:10 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-01 00:08:10 | INFO | train | epoch 158 | loss 5.382 | ppl 41.69 | wps 6063 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.068 | train_wall 317 | gb_free 6.1 | wall 55153
KL Stats: Epoch 158 Divergences: Uniform: 2.981100016469909 Unigram: 4.895714819510672
2022-02-01 00:08:10 | INFO | fairseq.trainer | begin training epoch 159
2022-02-01 00:08:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:13:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:13:55 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.457 | ppl 1405.15 | wps 8235.2 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.326
2022-02-01 00:13:55 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-01 00:13:55 | INFO | train | epoch 159 | loss 5.373 | ppl 41.44 | wps 6065.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.075 | train_wall 317 | gb_free 6.1 | wall 55497
KL Stats: Epoch 159 Divergences: Uniform: 2.9847001847403876 Unigram: 4.912320133637599
2022-02-01 00:13:55 | INFO | fairseq.trainer | begin training epoch 160
2022-02-01 00:13:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:15:54 | INFO | train_inner | epoch 160:     24 / 64 loss=5.372, ppl=41.43, wps=5935.3, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.076, train_wall=494, gb_free=6.1, wall=55617
2022-02-01 00:19:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:19:38 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.473 | ppl 1421.17 | wps 8247.9 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.326
2022-02-01 00:19:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-01 00:19:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint160.pt
2022-02-01 00:19:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint160.pt
2022-02-01 00:19:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.473) (writing took 3.5922768525779247 seconds)
2022-02-01 00:19:42 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-01 00:19:42 | INFO | train | epoch 160 | loss 5.367 | ppl 41.26 | wps 6016.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.041 | train_wall 316 | gb_free 6.1 | wall 55845
KL Stats: Epoch 160 Divergences: Uniform: 2.9856770664016987 Unigram: 4.922376669516735
2022-02-01 00:19:42 | INFO | fairseq.trainer | begin training epoch 161
2022-02-01 00:19:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:24:41 | INFO | train_inner | epoch 161:     60 / 64 loss=5.368, ppl=41.3, wps=6197.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.051, train_wall=496, gb_free=6.1, wall=56144
2022-02-01 00:25:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:25:27 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.374 | ppl 1327.43 | wps 8120.9 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.326
2022-02-01 00:25:27 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-01 00:25:27 | INFO | train | epoch 161 | loss 5.361 | ppl 41.09 | wps 6046.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.066 | train_wall 318 | gb_free 6.1 | wall 56190
KL Stats: Epoch 161 Divergences: Uniform: 2.988834571372759 Unigram: 4.92429793933948
2022-02-01 00:25:27 | INFO | fairseq.trainer | begin training epoch 162
2022-02-01 00:25:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:30:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:31:11 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.457 | ppl 1405.7 | wps 8164 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.326
2022-02-01 00:31:11 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-01 00:31:11 | INFO | train | epoch 162 | loss 5.352 | ppl 40.86 | wps 6070.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.046 | train_wall 316 | gb_free 6.1 | wall 56534
KL Stats: Epoch 162 Divergences: Uniform: 2.9962826371986604 Unigram: 4.934040904521307
2022-02-01 00:31:11 | INFO | fairseq.trainer | begin training epoch 163
2022-02-01 00:31:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:33:51 | INFO | train_inner | epoch 163:     32 / 64 loss=5.34, ppl=40.5, wps=5929.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.057, train_wall=495, gb_free=6.1, wall=56694
2022-02-01 00:36:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:36:56 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.522 | ppl 1470.1 | wps 8192.1 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.326
2022-02-01 00:36:56 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-01 00:36:56 | INFO | train | epoch 163 | loss 5.35 | ppl 40.78 | wps 6058.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.093 | train_wall 317 | gb_free 6.1 | wall 56879
KL Stats: Epoch 163 Divergences: Uniform: 2.9887244471750205 Unigram: 4.947805474506079
2022-02-01 00:36:56 | INFO | fairseq.trainer | begin training epoch 164
2022-02-01 00:36:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:42:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:42:40 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.417 | ppl 1367.5 | wps 8137 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.326
2022-02-01 00:42:40 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-01 00:42:40 | INFO | train | epoch 164 | loss 5.341 | ppl 40.54 | wps 6073.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.1 | train_wall 316 | gb_free 6.1 | wall 57223
KL Stats: Epoch 164 Divergences: Uniform: 2.9881662757355425 Unigram: 4.949558263771067
2022-02-01 00:42:40 | INFO | fairseq.trainer | begin training epoch 165
2022-02-01 00:42:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:43:00 | INFO | train_inner | epoch 165:      4 / 64 loss=5.356, ppl=40.97, wps=5941.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.1, train_wall=494, gb_free=6.1, wall=57243
2022-02-01 00:47:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:48:25 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.468 | ppl 1416.63 | wps 8204.5 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.326
2022-02-01 00:48:25 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-01 00:48:25 | INFO | train | epoch 165 | loss 5.333 | ppl 40.31 | wps 6054.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.079 | train_wall 317 | gb_free 6.1 | wall 57568
KL Stats: Epoch 165 Divergences: Uniform: 2.994881500628489 Unigram: 4.9666141733507345
2022-02-01 00:48:25 | INFO | fairseq.trainer | begin training epoch 166
2022-02-01 00:48:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:51:44 | INFO | train_inner | epoch 166:     40 / 64 loss=5.327, ppl=40.14, wps=6234.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.102, train_wall=496, gb_free=6.1, wall=57767
2022-02-01 00:53:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:54:09 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.363 | ppl 1317.33 | wps 8208.8 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.326
2022-02-01 00:54:09 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-01 00:54:09 | INFO | train | epoch 166 | loss 5.33 | ppl 40.23 | wps 6068.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.122 | train_wall 317 | gb_free 6.1 | wall 57912
KL Stats: Epoch 166 Divergences: Uniform: 2.9992728981504 Unigram: 4.971394016326823
2022-02-01 00:54:09 | INFO | fairseq.trainer | begin training epoch 167
2022-02-01 00:54:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:59:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:59:55 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.359 | ppl 1313.38 | wps 8232 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.326
2022-02-01 00:59:55 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-01 00:59:55 | INFO | train | epoch 167 | loss 5.323 | ppl 40.03 | wps 6041 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.121 | train_wall 318 | gb_free 6.1 | wall 58258
KL Stats: Epoch 167 Divergences: Uniform: 2.9950113051000087 Unigram: 4.9742442550947015
2022-02-01 00:59:55 | INFO | fairseq.trainer | begin training epoch 168
2022-02-01 00:59:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:00:55 | INFO | train_inner | epoch 168:     12 / 64 loss=5.325, ppl=40.09, wps=5921.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.117, train_wall=496, gb_free=6.1, wall=58317
2022-02-01 01:05:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:05:39 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.485 | ppl 1432.75 | wps 8212.4 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.326
2022-02-01 01:05:39 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-01 01:05:39 | INFO | train | epoch 168 | loss 5.318 | ppl 39.89 | wps 6070.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.128 | train_wall 317 | gb_free 6.1 | wall 58602
KL Stats: Epoch 168 Divergences: Uniform: 3.000312554799235 Unigram: 4.978208199639454
2022-02-01 01:05:39 | INFO | fairseq.trainer | begin training epoch 169
2022-02-01 01:05:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:09:38 | INFO | train_inner | epoch 169:     48 / 64 loss=5.317, ppl=39.86, wps=6239.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.124, train_wall=496, gb_free=6.1, wall=58841
2022-02-01 01:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:11:24 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.442 | ppl 1390.67 | wps 8197.4 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.326
2022-02-01 01:11:24 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-01 01:11:24 | INFO | train | epoch 169 | loss 5.312 | ppl 39.71 | wps 6058.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.118 | train_wall 317 | gb_free 6.1 | wall 58946
KL Stats: Epoch 169 Divergences: Uniform: 2.9983674913737386 Unigram: 4.990433999394714
2022-02-01 01:11:24 | INFO | fairseq.trainer | begin training epoch 170
2022-02-01 01:11:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:16:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:17:08 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.483 | ppl 1431.53 | wps 8194.8 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.326
2022-02-01 01:17:08 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-01 01:17:08 | INFO | train | epoch 170 | loss 5.306 | ppl 39.55 | wps 6071.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.128 | train_wall 316 | gb_free 6.1 | wall 59290
KL Stats: Epoch 170 Divergences: Uniform: 3.0005937742223963 Unigram: 4.998865152537638
2022-02-01 01:17:08 | INFO | fairseq.trainer | begin training epoch 171
2022-02-01 01:17:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:18:47 | INFO | train_inner | epoch 171:     20 / 64 loss=5.3, ppl=39.4, wps=5937.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.137, train_wall=494, gb_free=6.1, wall=59390
2022-02-01 01:22:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:22:53 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.471 | ppl 1419.8 | wps 8187 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.326
2022-02-01 01:22:53 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-01 01:22:53 | INFO | train | epoch 171 | loss 5.3 | ppl 39.4 | wps 6053.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.181 | train_wall 317 | gb_free 6.1 | wall 59635
KL Stats: Epoch 171 Divergences: Uniform: 3.000937250419241 Unigram: 5.008228403168469
2022-02-01 01:22:53 | INFO | fairseq.trainer | begin training epoch 172
2022-02-01 01:22:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:27:31 | INFO | train_inner | epoch 172:     56 / 64 loss=5.303, ppl=39.48, wps=6237.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.167, train_wall=496, gb_free=6.1, wall=59914
2022-02-01 01:28:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:28:37 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.458 | ppl 1406.26 | wps 8187.5 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.326
2022-02-01 01:28:37 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-01 01:28:37 | INFO | train | epoch 172 | loss 5.294 | ppl 39.23 | wps 6074.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.164 | train_wall 316 | gb_free 6.1 | wall 59979
KL Stats: Epoch 172 Divergences: Uniform: 3.0039760474887784 Unigram: 5.011681364315963
2022-02-01 01:28:37 | INFO | fairseq.trainer | begin training epoch 173
2022-02-01 01:28:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:33:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:34:22 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.395 | ppl 1346.09 | wps 8182.4 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.326
2022-02-01 01:34:22 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-01 01:34:22 | INFO | train | epoch 173 | loss 5.287 | ppl 39.05 | wps 6037.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.175 | train_wall 318 | gb_free 6.1 | wall 60325
KL Stats: Epoch 173 Divergences: Uniform: 3.00334954737982 Unigram: 5.0166818895606635
2022-02-01 01:34:22 | INFO | fairseq.trainer | begin training epoch 174
2022-02-01 01:34:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:36:42 | INFO | train_inner | epoch 174:     28 / 64 loss=5.281, ppl=38.88, wps=5921.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.163, train_wall=496, gb_free=6.1, wall=60465
2022-02-01 01:39:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:40:06 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.473 | ppl 1421.64 | wps 8179.6 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.326
2022-02-01 01:40:06 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-01 01:40:06 | INFO | train | epoch 174 | loss 5.283 | ppl 38.93 | wps 6073.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.165 | train_wall 316 | gb_free 6.1 | wall 60669
KL Stats: Epoch 174 Divergences: Uniform: 3.0051567015836254 Unigram: 5.029634433378922
2022-02-01 01:40:06 | INFO | fairseq.trainer | begin training epoch 175
2022-02-01 01:40:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:45:25 | INFO | train_inner | epoch 175:     64 / 64 loss=5.287, ppl=39.03, wps=6237.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.177, train_wall=495, gb_free=6.1, wall=60987
2022-02-01 01:45:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:45:51 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.534 | ppl 1482.38 | wps 8214.2 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.326
2022-02-01 01:45:51 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-01 01:45:51 | INFO | train | epoch 175 | loss 5.275 | ppl 38.73 | wps 6056.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.165 | train_wall 317 | gb_free 6.1 | wall 61014
KL Stats: Epoch 175 Divergences: Uniform: 3.015325232606118 Unigram: 5.039678662076189
2022-02-01 01:45:51 | INFO | fairseq.trainer | begin training epoch 176
2022-02-01 01:45:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:51:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:51:35 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.52 | ppl 1468.83 | wps 8241.4 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.326
2022-02-01 01:51:35 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-01 01:51:35 | INFO | train | epoch 176 | loss 5.271 | ppl 38.62 | wps 6075.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.18 | train_wall 316 | gb_free 6.1 | wall 61358
KL Stats: Epoch 176 Divergences: Uniform: 3.0099425586763084 Unigram: 5.046631055147024
2022-02-01 01:51:35 | INFO | fairseq.trainer | begin training epoch 177
2022-02-01 01:51:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:54:35 | INFO | train_inner | epoch 177:     36 / 64 loss=5.258, ppl=38.27, wps=5941.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.187, train_wall=495, gb_free=6.1, wall=61537
2022-02-01 01:56:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:57:20 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.424 | ppl 1373.76 | wps 8195.8 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.326
2022-02-01 01:57:20 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-01 01:57:20 | INFO | train | epoch 177 | loss 5.265 | ppl 38.45 | wps 6055.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.217 | train_wall 317 | gb_free 6.1 | wall 61703
KL Stats: Epoch 177 Divergences: Uniform: 3.0112642756156056 Unigram: 5.050980110777996
2022-02-01 01:57:20 | INFO | fairseq.trainer | begin training epoch 178
2022-02-01 01:57:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:02:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:03:04 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.498 | ppl 1446.53 | wps 8221.3 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.326
2022-02-01 02:03:04 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-01 02:03:04 | INFO | train | epoch 178 | loss 5.262 | ppl 38.38 | wps 6072.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.203 | train_wall 316 | gb_free 6.1 | wall 62047
KL Stats: Epoch 178 Divergences: Uniform: 3.0118346679914385 Unigram: 5.055410763553868
2022-02-01 02:03:04 | INFO | fairseq.trainer | begin training epoch 179
2022-02-01 02:03:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:03:44 | INFO | train_inner | epoch 179:      8 / 64 loss=5.269, ppl=38.57, wps=5934.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.21, train_wall=495, gb_free=6.1, wall=62087
2022-02-01 02:08:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:08:49 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.44 | ppl 1388.73 | wps 8223.7 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.326
2022-02-01 02:08:49 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-01 02:08:49 | INFO | train | epoch 179 | loss 5.255 | ppl 38.19 | wps 6044.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.198 | train_wall 318 | gb_free 6.1 | wall 62392
KL Stats: Epoch 179 Divergences: Uniform: 3.0139144278609695 Unigram: 5.063057981593525
2022-02-01 02:08:49 | INFO | fairseq.trainer | begin training epoch 180
2022-02-01 02:08:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:12:28 | INFO | train_inner | epoch 180:     44 / 64 loss=5.25, ppl=38.06, wps=6230.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.203, train_wall=497, gb_free=6.1, wall=62611
2022-02-01 02:14:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:14:33 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.422 | ppl 1372.27 | wps 8198.8 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.326
2022-02-01 02:14:33 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-01 02:14:33 | INFO | train | epoch 180 | loss 5.251 | ppl 38.09 | wps 6075 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.222 | train_wall 316 | gb_free 6.1 | wall 62736
KL Stats: Epoch 180 Divergences: Uniform: 3.015776991050507 Unigram: 5.070970856979377
2022-02-01 02:14:33 | INFO | fairseq.trainer | begin training epoch 181
2022-02-01 02:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:19:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:20:18 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.488 | ppl 1436.01 | wps 8210.6 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.326
2022-02-01 02:20:18 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-01 02:20:18 | INFO | train | epoch 181 | loss 5.243 | ppl 37.87 | wps 6055.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.216 | train_wall 317 | gb_free 6.1 | wall 63081
KL Stats: Epoch 181 Divergences: Uniform: 3.0187921644685747 Unigram: 5.081654839657489
2022-02-01 02:20:18 | INFO | fairseq.trainer | begin training epoch 182
2022-02-01 02:20:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:21:38 | INFO | train_inner | epoch 182:     16 / 64 loss=5.244, ppl=37.91, wps=5933.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.23, train_wall=495, gb_free=6.1, wall=63161
2022-02-01 02:25:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:26:02 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.41 | ppl 1360.67 | wps 8187.9 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.326
2022-02-01 02:26:02 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-01 02:26:02 | INFO | train | epoch 182 | loss 5.241 | ppl 37.82 | wps 6074.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.241 | train_wall 316 | gb_free 6.1 | wall 63425
KL Stats: Epoch 182 Divergences: Uniform: 3.019154154032112 Unigram: 5.0797379849701
2022-02-01 02:26:02 | INFO | fairseq.trainer | begin training epoch 183
2022-02-01 02:26:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:30:21 | INFO | train_inner | epoch 183:     52 / 64 loss=5.239, ppl=37.77, wps=6242.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.262, train_wall=496, gb_free=6.1, wall=63684
2022-02-01 02:31:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:31:47 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.437 | ppl 1386.39 | wps 8185.5 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.326
2022-02-01 02:31:47 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-01 02:31:47 | INFO | train | epoch 183 | loss 5.236 | ppl 37.68 | wps 6058.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.274 | train_wall 317 | gb_free 6.1 | wall 63769
KL Stats: Epoch 183 Divergences: Uniform: 3.019949897151495 Unigram: 5.095525725492096
2022-02-01 02:31:47 | INFO | fairseq.trainer | begin training epoch 184
2022-02-01 02:31:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:37:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:37:31 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.43 | ppl 1379.62 | wps 8196.9 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.326
2022-02-01 02:37:31 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-01 02:37:31 | INFO | train | epoch 184 | loss 5.231 | ppl 37.55 | wps 6067.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.235 | train_wall 317 | gb_free 6.1 | wall 64114
KL Stats: Epoch 184 Divergences: Uniform: 3.0190379417477002 Unigram: 5.096809579381083
2022-02-01 02:37:31 | INFO | fairseq.trainer | begin training epoch 185
2022-02-01 02:37:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:39:31 | INFO | train_inner | epoch 185:     24 / 64 loss=5.231, ppl=37.54, wps=5933.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.241, train_wall=495, gb_free=6.1, wall=64234
2022-02-01 02:42:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:43:16 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.48 | ppl 1427.78 | wps 8160.4 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.326
2022-02-01 02:43:16 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-01 02:43:16 | INFO | train | epoch 185 | loss 5.226 | ppl 37.44 | wps 6051.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.283 | train_wall 317 | gb_free 6.1 | wall 64459
KL Stats: Epoch 185 Divergences: Uniform: 3.016914206825253 Unigram: 5.106786464195065
2022-02-01 02:43:16 | INFO | fairseq.trainer | begin training epoch 186
2022-02-01 02:43:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:48:15 | INFO | train_inner | epoch 186:     60 / 64 loss=5.227, ppl=37.46, wps=6238.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.292, train_wall=496, gb_free=6.1, wall=64757
2022-02-01 02:48:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:49:00 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.411 | ppl 1361.39 | wps 8191.2 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.326
2022-02-01 02:49:00 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-01 02:49:00 | INFO | train | epoch 186 | loss 5.223 | ppl 37.34 | wps 6073.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.29 | train_wall 316 | gb_free 6.1 | wall 64803
KL Stats: Epoch 186 Divergences: Uniform: 3.017672078005219 Unigram: 5.110796530723995
2022-02-01 02:49:00 | INFO | fairseq.trainer | begin training epoch 187
2022-02-01 02:49:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:54:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:54:45 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.482 | ppl 1430.5 | wps 8154.2 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.326
2022-02-01 02:54:45 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-01 02:54:45 | INFO | train | epoch 187 | loss 5.217 | ppl 37.2 | wps 6059.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.263 | train_wall 317 | gb_free 6.1 | wall 65147
KL Stats: Epoch 187 Divergences: Uniform: 3.020967771358295 Unigram: 5.118241081542562
2022-02-01 02:54:45 | INFO | fairseq.trainer | begin training epoch 188
2022-02-01 02:54:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:57:24 | INFO | train_inner | epoch 188:     32 / 64 loss=5.21, ppl=37.01, wps=5931.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.272, train_wall=495, gb_free=6.1, wall=65307
2022-02-01 03:00:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:00:29 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.476 | ppl 1424.66 | wps 8211.7 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.326
2022-02-01 03:00:29 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-01 03:00:29 | INFO | train | epoch 188 | loss 5.209 | ppl 37 | wps 6068.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.279 | train_wall 317 | gb_free 6.1 | wall 65492
KL Stats: Epoch 188 Divergences: Uniform: 3.019819845583933 Unigram: 5.126205599260394
2022-02-01 03:00:29 | INFO | fairseq.trainer | begin training epoch 189
2022-02-01 03:00:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:05:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:06:13 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.441 | ppl 1390.09 | wps 8163.4 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.326
2022-02-01 03:06:13 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-01 03:06:13 | INFO | train | epoch 189 | loss 5.207 | ppl 36.95 | wps 6063.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.335 | train_wall 317 | gb_free 6.1 | wall 65836
KL Stats: Epoch 189 Divergences: Uniform: 3.0199039292451917 Unigram: 5.1277280512038095
2022-02-01 03:06:13 | INFO | fairseq.trainer | begin training epoch 190
2022-02-01 03:06:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:06:33 | INFO | train_inner | epoch 190:      4 / 64 loss=5.213, ppl=37.08, wps=5935.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.313, train_wall=494, gb_free=6.1, wall=65856
2022-02-01 03:11:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:11:58 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.454 | ppl 1403.15 | wps 8184.8 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.326
2022-02-01 03:11:58 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-01 03:11:58 | INFO | train | epoch 190 | loss 5.201 | ppl 36.78 | wps 6063 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.3 | train_wall 317 | gb_free 6.1 | wall 66181
KL Stats: Epoch 190 Divergences: Uniform: 3.0226450112466012 Unigram: 5.1327704773761935
2022-02-01 03:11:58 | INFO | fairseq.trainer | begin training epoch 191
2022-02-01 03:11:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:15:18 | INFO | train_inner | epoch 191:     40 / 64 loss=5.19, ppl=36.5, wps=6231.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.293, train_wall=496, gb_free=6.1, wall=66381
2022-02-01 03:17:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:17:44 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.454 | ppl 1402.27 | wps 8152.9 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.326
2022-02-01 03:17:44 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-01 03:17:44 | INFO | train | epoch 191 | loss 5.196 | ppl 36.66 | wps 6040.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.277 | train_wall 318 | gb_free 6.1 | wall 66526
KL Stats: Epoch 191 Divergences: Uniform: 3.023339571446987 Unigram: 5.142581513866657
2022-02-01 03:17:44 | INFO | fairseq.trainer | begin training epoch 192
2022-02-01 03:17:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:23:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:23:28 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.476 | ppl 1424.34 | wps 8195.2 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.326
2022-02-01 03:23:28 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-01 03:23:28 | INFO | train | epoch 192 | loss 5.193 | ppl 36.58 | wps 6068.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.338 | train_wall 317 | gb_free 6.1 | wall 66871
KL Stats: Epoch 192 Divergences: Uniform: 3.0228202068906227 Unigram: 5.143725730237356
2022-02-01 03:23:28 | INFO | fairseq.trainer | begin training epoch 193
2022-02-01 03:23:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:24:28 | INFO | train_inner | epoch 193:     12 / 64 loss=5.199, ppl=36.74, wps=5928.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.328, train_wall=495, gb_free=6.1, wall=66930
2022-02-01 03:28:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:29:13 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.466 | ppl 1414.78 | wps 8163.5 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.326
2022-02-01 03:29:13 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-01 03:29:13 | INFO | train | epoch 193 | loss 5.19 | ppl 36.5 | wps 6056.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.343 | train_wall 317 | gb_free 6.1 | wall 67215
KL Stats: Epoch 193 Divergences: Uniform: 3.026802161403407 Unigram: 5.153601186729461
2022-02-01 03:29:13 | INFO | fairseq.trainer | begin training epoch 194
2022-02-01 03:29:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:33:12 | INFO | train_inner | epoch 194:     48 / 64 loss=5.186, ppl=36.39, wps=6237.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.348, train_wall=496, gb_free=6.1, wall=67454
2022-02-01 03:34:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:34:57 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.435 | ppl 1384.71 | wps 8208.6 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.326
2022-02-01 03:34:57 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-01 03:34:57 | INFO | train | epoch 194 | loss 5.184 | ppl 36.36 | wps 6070.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.369 | train_wall 317 | gb_free 6.1 | wall 67559
KL Stats: Epoch 194 Divergences: Uniform: 3.0267364787251165 Unigram: 5.155686279005651
2022-02-01 03:34:57 | INFO | fairseq.trainer | begin training epoch 195
2022-02-01 03:34:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:40:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:40:41 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.464 | ppl 1412.64 | wps 8158.1 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.326
2022-02-01 03:40:41 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-01 03:40:41 | INFO | train | epoch 195 | loss 5.18 | ppl 36.25 | wps 6063.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.361 | train_wall 317 | gb_free 6.1 | wall 67904
KL Stats: Epoch 195 Divergences: Uniform: 3.0246999717742877 Unigram: 5.161739679955399
2022-02-01 03:40:41 | INFO | fairseq.trainer | begin training epoch 196
2022-02-01 03:40:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:42:21 | INFO | train_inner | epoch 196:     20 / 64 loss=5.178, ppl=36.2, wps=5933.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.356, train_wall=495, gb_free=6.1, wall=68004
2022-02-01 03:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:46:26 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.431 | ppl 1380.96 | wps 8117.1 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.326
2022-02-01 03:46:26 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-01 03:46:26 | INFO | train | epoch 196 | loss 5.176 | ppl 36.15 | wps 6061.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.352 | train_wall 317 | gb_free 6.1 | wall 68248
KL Stats: Epoch 196 Divergences: Uniform: 3.0263476945324257 Unigram: 5.169377428131848
2022-02-01 03:46:26 | INFO | fairseq.trainer | begin training epoch 197
2022-02-01 03:46:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:51:05 | INFO | train_inner | epoch 197:     56 / 64 loss=5.176, ppl=36.16, wps=6240.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.379, train_wall=495, gb_free=6.1, wall=68528
2022-02-01 03:51:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:52:10 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.515 | ppl 1462.97 | wps 8160.4 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.326
2022-02-01 03:52:10 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-01 03:52:10 | INFO | train | epoch 197 | loss 5.171 | ppl 36.04 | wps 6061.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.395 | train_wall 317 | gb_free 6.1 | wall 68593
KL Stats: Epoch 197 Divergences: Uniform: 3.0288804799675466 Unigram: 5.171969335448514
2022-02-01 03:52:10 | INFO | fairseq.trainer | begin training epoch 198
2022-02-01 03:52:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:57:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:57:55 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.461 | ppl 1409.24 | wps 8189.9 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.326
2022-02-01 03:57:55 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-01 03:57:55 | INFO | train | epoch 198 | loss 5.167 | ppl 35.94 | wps 6062 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.414 | train_wall 317 | gb_free 6.1 | wall 68938
KL Stats: Epoch 198 Divergences: Uniform: 3.030845318695624 Unigram: 5.185619835106468
2022-02-01 03:57:55 | INFO | fairseq.trainer | begin training epoch 199
2022-02-01 03:57:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:00:14 | INFO | train_inner | epoch 199:     28 / 64 loss=5.162, ppl=35.79, wps=5933.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.397, train_wall=495, gb_free=6.1, wall=69077
2022-02-01 04:03:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:03:39 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.437 | ppl 1386.43 | wps 8190.4 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.326
2022-02-01 04:03:39 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-01 04:03:39 | INFO | train | epoch 199 | loss 5.16 | ppl 35.76 | wps 6067.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.355 | train_wall 317 | gb_free 6.1 | wall 69282
KL Stats: Epoch 199 Divergences: Uniform: 3.0302740565628885 Unigram: 5.193646351813847
2022-02-01 04:03:39 | INFO | fairseq.trainer | begin training epoch 200
2022-02-01 04:03:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:08:57 | INFO | train_inner | epoch 200:     64 / 64 loss=5.17, ppl=35.99, wps=6238.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.39, train_wall=495, gb_free=6.1, wall=69599
2022-02-01 04:08:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:09:23 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.491 | ppl 1438.71 | wps 8186 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.326
2022-02-01 04:09:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-01 04:09:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint200.pt
2022-02-01 04:09:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint200.pt
2022-02-01 04:09:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.491) (writing took 3.4729939233511686 seconds)
2022-02-01 04:09:27 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-01 04:09:27 | INFO | train | epoch 200 | loss 5.158 | ppl 35.7 | wps 6004.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.404 | train_wall 317 | gb_free 6.1 | wall 69630
KL Stats: Epoch 200 Divergences: Uniform: 3.0285782648942443 Unigram: 5.1993120202370555
2022-02-01 04:09:27 | INFO | fairseq.trainer | begin training epoch 201
2022-02-01 04:09:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:14:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:15:11 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.494 | ppl 1441.79 | wps 8174.5 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.326
2022-02-01 04:15:11 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-01 04:15:11 | INFO | train | epoch 201 | loss 5.155 | ppl 35.63 | wps 6065.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.418 | train_wall 317 | gb_free 6.1 | wall 69974
KL Stats: Epoch 201 Divergences: Uniform: 3.027663156396804 Unigram: 5.1950693989773615
2022-02-01 04:15:11 | INFO | fairseq.trainer | begin training epoch 202
2022-02-01 04:15:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:18:11 | INFO | train_inner | epoch 202:     36 / 64 loss=5.14, ppl=35.27, wps=5897.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.419, train_wall=496, gb_free=6.1, wall=70154
2022-02-01 04:20:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:20:56 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.484 | ppl 1432.59 | wps 8173.2 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.326
2022-02-01 04:20:56 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-02-01 04:20:56 | INFO | train | epoch 202 | loss 5.148 | ppl 35.46 | wps 6051.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.405 | train_wall 318 | gb_free 6.1 | wall 70319
KL Stats: Epoch 202 Divergences: Uniform: 3.028541582190509 Unigram: 5.210616738014204
2022-02-01 04:20:56 | INFO | fairseq.trainer | begin training epoch 203
2022-02-01 04:20:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:26:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:26:41 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.443 | ppl 1391.83 | wps 8157.7 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.326
2022-02-01 04:26:41 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-02-01 04:26:41 | INFO | train | epoch 203 | loss 5.145 | ppl 35.37 | wps 6062 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.455 | train_wall 317 | gb_free 6.1 | wall 70664
KL Stats: Epoch 203 Divergences: Uniform: 3.0285699207730894 Unigram: 5.2168153046609245
2022-02-01 04:26:41 | INFO | fairseq.trainer | begin training epoch 204
2022-02-01 04:26:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:27:21 | INFO | train_inner | epoch 204:      8 / 64 loss=5.153, ppl=35.58, wps=5925.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.431, train_wall=495, gb_free=6.1, wall=70704
2022-02-01 04:31:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:32:25 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.483 | ppl 1431.1 | wps 8222.2 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.326
2022-02-01 04:32:25 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-02-01 04:32:25 | INFO | train | epoch 204 | loss 5.139 | ppl 35.25 | wps 6065 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.438 | train_wall 317 | gb_free 6.1 | wall 71008
KL Stats: Epoch 204 Divergences: Uniform: 3.035448135083059 Unigram: 5.221081664283911
2022-02-01 04:32:25 | INFO | fairseq.trainer | begin training epoch 205
2022-02-01 04:32:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:36:04 | INFO | train_inner | epoch 205:     44 / 64 loss=5.135, ppl=35.13, wps=6246.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.448, train_wall=495, gb_free=6.1, wall=71227
2022-02-01 04:37:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:38:10 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 10.495 | ppl 1443.33 | wps 8150.3 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.326
2022-02-01 04:38:10 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-02-01 04:38:10 | INFO | train | epoch 205 | loss 5.135 | ppl 35.14 | wps 6066.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.457 | train_wall 317 | gb_free 6.1 | wall 71352
KL Stats: Epoch 205 Divergences: Uniform: 3.0338626720616406 Unigram: 5.231691087027735
2022-02-01 04:38:10 | INFO | fairseq.trainer | begin training epoch 206
2022-02-01 04:38:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:43:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:43:54 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 10.496 | ppl 1444.49 | wps 8217.6 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.326
2022-02-01 04:43:54 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-02-01 04:43:54 | INFO | train | epoch 206 | loss 5.132 | ppl 35.06 | wps 6062.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.43 | train_wall 317 | gb_free 6.1 | wall 71697
KL Stats: Epoch 206 Divergences: Uniform: 3.031974173840871 Unigram: 5.23500968824743
2022-02-01 04:43:54 | INFO | fairseq.trainer | begin training epoch 207
2022-02-01 04:43:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:45:14 | INFO | train_inner | epoch 207:     16 / 64 loss=5.133, ppl=35.1, wps=5930.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.439, train_wall=495, gb_free=6.1, wall=71777
User defined signal 2
Sender: LSF System <lsfadmin@eu-g2-08>
Subject: Job 202993328: <w2_jelinek_0.11_-0.01_0.9_#3> in cluster <euler> Exited

Job <w2_jelinek_0.11_-0.01_0.9_#3> was submitted from host <eu-login-26> by user <andriusb> in cluster <euler> at Wed Feb  2 06:06:08 2022
Job was executed on host(s) <eu-g2-08>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Wed Feb  2 06:06:34 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Feb  2 06:06:34 2022
Terminated at Thu Feb  3 02:06:37 2022
Results reported at Thu Feb  3 02:06:37 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.11, -0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --seed 302 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72885.00 sec.
    Max Memory :                                 5068 MB
    Average Memory :                             2697.29 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14932.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72003 sec.
    Turnaround time :                            72029 sec.

The output (if any) follows:

2022-02-02 06:06:39 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 302, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 302, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.11, -0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-02-02 06:06:39 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-02-02 06:06:40 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1410/36718 [00:00<00:02, 14089.36it/s]  8%|▊         | 2819/36718 [00:00<00:02, 13542.83it/s] 12%|█▏        | 4379/36718 [00:00<00:02, 14460.67it/s] 16%|█▋        | 5993/36718 [00:00<00:02, 15111.02it/s] 20%|██        | 7507/36718 [00:00<00:02, 14364.97it/s] 24%|██▍       | 8951/36718 [00:00<00:01, 14094.35it/s] 28%|██▊       | 10381/36718 [00:00<00:01, 14153.02it/s] 32%|███▏      | 11800/36718 [00:00<00:01, 13903.85it/s] 36%|███▌      | 13292/36718 [00:00<00:01, 14210.58it/s] 40%|████      | 14728/36718 [00:01<00:01, 14253.57it/s] 44%|████▍     | 16156/36718 [00:01<00:01, 14036.21it/s] 48%|████▊     | 17562/36718 [00:01<00:01, 14014.95it/s] 52%|█████▏    | 19081/36718 [00:01<00:01, 14363.94it/s] 56%|█████▌    | 20519/36718 [00:01<00:01, 14358.80it/s] 60%|█████▉    | 21956/36718 [00:01<00:01, 14110.70it/s] 64%|██████▍   | 23478/36718 [00:01<00:00, 14436.27it/s] 69%|██████▊   | 25190/36718 [00:01<00:00, 15231.00it/s] 73%|███████▎  | 26716/36718 [00:01<00:00, 14609.65it/s] 77%|███████▋  | 28184/36718 [00:01<00:00, 14192.15it/s] 81%|████████  | 29649/36718 [00:02<00:00, 14319.07it/s] 85%|████████▍ | 31086/36718 [00:02<00:00, 13774.30it/s] 88%|████████▊ | 32486/36718 [00:02<00:00, 13833.99it/s] 92%|█████████▏| 33875/36718 [00:02<00:00, 13695.32it/s] 96%|█████████▌| 35310/36718 [00:02<00:00, 13878.98it/s]100%|█████████▉| 36710/36718 [00:02<00:00, 13910.90it/s]100%|██████████| 36718/36718 [00:02<00:00, 14169.84it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  7%|▋         | 2747/36718 [00:00<00:01, 27444.77it/s] 16%|█▌        | 5928/36718 [00:00<00:01, 29994.82it/s] 24%|██▍       | 8928/36718 [00:00<00:00, 28574.68it/s] 32%|███▏      | 11793/36718 [00:00<00:00, 28180.27it/s] 40%|████      | 14715/36718 [00:00<00:00, 28540.27it/s] 48%|████▊     | 17573/36718 [00:00<00:00, 28355.62it/s] 56%|█████▌    | 20513/36718 [00:00<00:00, 28690.22it/s] 64%|██████▎   | 23385/36718 [00:00<00:00, 28611.10it/s] 72%|███████▏  | 26417/36718 [00:00<00:00, 29134.73it/s] 80%|███████▉  | 29333/36718 [00:01<00:00, 28738.78it/s] 88%|████████▊ | 32209/36718 [00:01<00:00, 28260.62it/s] 95%|█████████▌| 35050/36718 [00:01<00:00, 28302.42it/s]100%|██████████| 36718/36718 [00:01<00:00, 28505.04it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 206.84it/s]2022-02-02 06:06:49 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-02-02 06:06:49 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-02-02 06:06:49 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-02-02 06:06:49 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-02-02 06:06:49 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-02-02 06:06:49 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-02-02 06:06:49 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-02-02 06:06:49 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-02-02 06:06:49 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:06:49 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-02-02 06:06:49 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:06:49 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-02-02 06:06:49 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-02-02 06:06:49 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint_last.pt
2022-02-02 06:06:49 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint_last.pt
2022-02-02 06:06:49 | INFO | fairseq.trainer | loading train data for epoch 1
2022-02-02 06:06:49 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-02-02 06:06:49 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-02-02 06:06:49 | INFO | fairseq.trainer | begin training epoch 1
2022-02-02 06:06:49 | INFO | fairseq_cli.train | Start iterating over samples

2022-02-02 06:12:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-02-02 06:12:33 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.688 | ppl 26404.3 | wps 8203.1 | wpb 2034.1 | bsz 4 | num_updates 64
2022-02-02 06:12:33 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-02-02 06:12:33 | INFO | train | epoch 001 | loss 15.979 | ppl 64576.3 | wps 6081.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.241 | train_wall 316 | gb_free 6.1 | wall 345
KL Stats: Epoch 1 Divergences: Uniform: 0.5316109501463648 Unigram: 3.581620127266902
2022-02-02 06:12:33 | INFO | fairseq.trainer | begin training epoch 2
2022-02-02 06:12:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:15:32 | INFO | train_inner | epoch 002:     36 / 64 loss=15.468, ppl=45325.5, wps=6253.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.623, train_wall=495, gb_free=6.1, wall=524
2022-02-02 06:17:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:18:17 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.674 | ppl 13070.8 | wps 8235.1 | wpb 2034.1 | bsz 4 | num_updates 128
2022-02-02 06:18:17 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-02-02 06:18:17 | INFO | train | epoch 002 | loss 14.353 | ppl 20932.1 | wps 6069.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.414 | train_wall 317 | gb_free 6.1 | wall 689
KL Stats: Epoch 2 Divergences: Uniform: 0.5423219587820877 Unigram: 2.34828589410185
2022-02-02 06:18:17 | INFO | fairseq.trainer | begin training epoch 3
2022-02-02 06:18:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:23:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:24:00 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.881 | ppl 7543.16 | wps 8210.3 | wpb 2034.1 | bsz 4 | num_updates 192
2022-02-02 06:24:00 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-02-02 06:24:00 | INFO | train | epoch 003 | loss 13.487 | ppl 11478.1 | wps 6091.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.114 | train_wall 315 | gb_free 6.1 | wall 1032
KL Stats: Epoch 3 Divergences: Uniform: 0.5308158540535227 Unigram: 1.6859996255323508
2022-02-02 06:24:00 | INFO | fairseq.trainer | begin training epoch 4
2022-02-02 06:24:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:24:40 | INFO | train_inner | epoch 004:      8 / 64 loss=13.613, ppl=12525.4, wps=5953.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.147, train_wall=493, gb_free=6.1, wall=1071
2022-02-02 06:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:29:44 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.095 | ppl 4373.55 | wps 8229.1 | wpb 2034.1 | bsz 4 | num_updates 256
2022-02-02 06:29:44 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-02-02 06:29:44 | INFO | train | epoch 004 | loss 12.584 | ppl 6139.79 | wps 6074.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.859 | train_wall 316 | gb_free 6.1 | wall 1375
KL Stats: Epoch 4 Divergences: Uniform: 0.6177155693213356 Unigram: 1.103904171329681
2022-02-02 06:29:44 | INFO | fairseq.trainer | begin training epoch 5
2022-02-02 06:29:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:33:22 | INFO | train_inner | epoch 005:     44 / 64 loss=12.254, ppl=4885.8, wps=6256.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.775, train_wall=494, gb_free=6.1, wall=1594
2022-02-02 06:35:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:35:27 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.574 | ppl 3048.25 | wps 8183.9 | wpb 2034.1 | bsz 4 | num_updates 320
2022-02-02 06:35:27 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-02-02 06:35:27 | INFO | train | epoch 005 | loss 11.83 | ppl 3639.96 | wps 6083.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.689 | train_wall 316 | gb_free 6.1 | wall 1719
KL Stats: Epoch 5 Divergences: Uniform: 0.8366163517706033 Unigram: 0.6746034831192247
2022-02-02 06:35:27 | INFO | fairseq.trainer | begin training epoch 6
2022-02-02 06:35:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:40:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:41:11 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.311 | ppl 2541.33 | wps 8232.5 | wpb 2034.1 | bsz 4 | num_updates 384
2022-02-02 06:41:11 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-02-02 06:41:11 | INFO | train | epoch 006 | loss 11.405 | ppl 2711.4 | wps 6080.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.63 | train_wall 316 | gb_free 6.1 | wall 2062
KL Stats: Epoch 6 Divergences: Uniform: 1.1146440207032273 Unigram: 0.479303108087604
2022-02-02 06:41:11 | INFO | fairseq.trainer | begin training epoch 7
2022-02-02 06:41:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:42:30 | INFO | train_inner | epoch 007:     16 / 64 loss=11.43, ppl=2758.54, wps=5948.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.63, train_wall=493, gb_free=6.1, wall=2142
2022-02-02 06:46:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:46:55 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.17 | ppl 2304.67 | wps 8193.9 | wpb 2034.1 | bsz 4 | num_updates 448
2022-02-02 06:46:55 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-02-02 06:46:55 | INFO | train | epoch 007 | loss 11.21 | ppl 2368.73 | wps 6074.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.52 | train_wall 316 | gb_free 6.1 | wall 2406
KL Stats: Epoch 7 Divergences: Uniform: 1.3326340402119752 Unigram: 0.4881385329083977
2022-02-02 06:46:55 | INFO | fairseq.trainer | begin training epoch 8
2022-02-02 06:46:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:51:13 | INFO | train_inner | epoch 008:     52 / 64 loss=11.146, ppl=2266.07, wps=6249.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.493, train_wall=495, gb_free=6.1, wall=2665
2022-02-02 06:52:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:52:38 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.072 | ppl 2152.36 | wps 8178.2 | wpb 2034.1 | bsz 4 | num_updates 512
2022-02-02 06:52:38 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-02-02 06:52:38 | INFO | train | epoch 008 | loss 11.093 | ppl 2185 | wps 6076.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.491 | train_wall 316 | gb_free 6.1 | wall 2750
KL Stats: Epoch 8 Divergences: Uniform: 1.4441657974304118 Unigram: 0.5705985434574918
2022-02-02 06:52:38 | INFO | fairseq.trainer | begin training epoch 9
2022-02-02 06:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:57:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:58:21 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.966 | ppl 2000.24 | wps 8198.1 | wpb 2034.1 | bsz 4 | num_updates 576
2022-02-02 06:58:21 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-02-02 06:58:21 | INFO | train | epoch 009 | loss 10.985 | ppl 2026.84 | wps 6088.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.498 | train_wall 316 | gb_free 6.1 | wall 3093
KL Stats: Epoch 9 Divergences: Uniform: 1.4872098842092583 Unigram: 0.6819431248686867
2022-02-02 06:58:21 | INFO | fairseq.trainer | begin training epoch 10
2022-02-02 06:58:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:00:21 | INFO | train_inner | epoch 010:     24 / 64 loss=10.975, ppl=2013.01, wps=5954, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.511, train_wall=493, gb_free=6.1, wall=3212
2022-02-02 07:03:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:04:06 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.843 | ppl 1837.25 | wps 8194.2 | wpb 2034.1 | bsz 4 | num_updates 640
2022-02-02 07:04:06 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-02-02 07:04:06 | INFO | train | epoch 010 | loss 10.871 | ppl 1872.32 | wps 6064.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.49 | train_wall 317 | gb_free 6.1 | wall 3437
KL Stats: Epoch 10 Divergences: Uniform: 1.5059721567236048 Unigram: 0.8075278220153416
2022-02-02 07:04:06 | INFO | fairseq.trainer | begin training epoch 11
2022-02-02 07:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:09:04 | INFO | train_inner | epoch 011:     60 / 64 loss=10.791, ppl=1771.39, wps=6242.1, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.487, train_wall=496, gb_free=6.1, wall=3736
2022-02-02 07:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:09:50 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.733 | ppl 1701.5 | wps 8212.5 | wpb 2034.1 | bsz 4 | num_updates 704
2022-02-02 07:09:50 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-02-02 07:09:50 | INFO | train | epoch 011 | loss 10.752 | ppl 1724.9 | wps 6073 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.501 | train_wall 316 | gb_free 6.1 | wall 3781
KL Stats: Epoch 11 Divergences: Uniform: 1.52429925839847 Unigram: 0.9343025976956499
2022-02-02 07:09:50 | INFO | fairseq.trainer | begin training epoch 12
2022-02-02 07:09:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:15:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:15:34 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.638 | ppl 1594.04 | wps 8202.4 | wpb 2034.1 | bsz 4 | num_updates 768
2022-02-02 07:15:34 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-02-02 07:15:34 | INFO | train | epoch 012 | loss 10.636 | ppl 1591.09 | wps 6067.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.51 | train_wall 317 | gb_free 6.1 | wall 4125
KL Stats: Epoch 12 Divergences: Uniform: 1.5372071304270494 Unigram: 1.0546606432529115
2022-02-02 07:15:34 | INFO | fairseq.trainer | begin training epoch 13
2022-02-02 07:15:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:18:13 | INFO | train_inner | epoch 013:     32 / 64 loss=10.608, ppl=1560.67, wps=5942.8, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.493, train_wall=494, gb_free=6.1, wall=4284
2022-02-02 07:20:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:21:17 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.536 | ppl 1484.61 | wps 8235.7 | wpb 2034.1 | bsz 4 | num_updates 832
2022-02-02 07:21:17 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-02-02 07:21:17 | INFO | train | epoch 013 | loss 10.52 | ppl 1468.17 | wps 6087.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.471 | train_wall 316 | gb_free 6.1 | wall 4468
KL Stats: Epoch 13 Divergences: Uniform: 1.5562645756187727 Unigram: 1.16127967458802
2022-02-02 07:21:17 | INFO | fairseq.trainer | begin training epoch 14
2022-02-02 07:21:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:26:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:27:02 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.444 | ppl 1392.97 | wps 8201.4 | wpb 2034.1 | bsz 4 | num_updates 896
2022-02-02 07:27:02 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-02-02 07:27:02 | INFO | train | epoch 014 | loss 10.406 | ppl 1356.9 | wps 6057.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.496 | train_wall 317 | gb_free 6.1 | wall 4813
KL Stats: Epoch 14 Divergences: Uniform: 1.5827598264891467 Unigram: 1.2572762382014613
2022-02-02 07:27:02 | INFO | fairseq.trainer | begin training epoch 15
2022-02-02 07:27:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:27:22 | INFO | train_inner | epoch 015:      4 / 64 loss=10.434, ppl=1383.64, wps=5939.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.491, train_wall=494, gb_free=6.1, wall=4833
2022-02-02 07:32:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:32:45 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.359 | ppl 1312.99 | wps 8215.2 | wpb 2034.1 | bsz 4 | num_updates 960
2022-02-02 07:32:45 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-02-02 07:32:45 | INFO | train | epoch 015 | loss 10.295 | ppl 1256.21 | wps 6084.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.511 | train_wall 316 | gb_free 6.1 | wall 5157
KL Stats: Epoch 15 Divergences: Uniform: 1.60902071173753 Unigram: 1.3488070765866527
2022-02-02 07:32:45 | INFO | fairseq.trainer | begin training epoch 16
2022-02-02 07:32:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:36:04 | INFO | train_inner | epoch 016:     40 / 64 loss=10.255, ppl=1222.39, wps=6257.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.515, train_wall=494, gb_free=6.1, wall=5355
2022-02-02 07:38:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:38:29 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.274 | ppl 1237.97 | wps 8186.2 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-02-02 07:38:29 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-02-02 07:38:29 | INFO | train | epoch 016 | loss 10.184 | ppl 1163.3 | wps 6077.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.526 | train_wall 316 | gb_free 6.1 | wall 5500
KL Stats: Epoch 16 Divergences: Uniform: 1.6390849594746069 Unigram: 1.4310666178260123
2022-02-02 07:38:29 | INFO | fairseq.trainer | begin training epoch 17
2022-02-02 07:38:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:43:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:44:12 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.195 | ppl 1171.88 | wps 8234.8 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-02-02 07:44:12 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-02-02 07:44:12 | INFO | train | epoch 017 | loss 10.077 | ppl 1080.11 | wps 6079.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.541 | train_wall 316 | gb_free 6.1 | wall 5844
KL Stats: Epoch 17 Divergences: Uniform: 1.6705293679734732 Unigram: 1.507441900277
2022-02-02 07:44:12 | INFO | fairseq.trainer | begin training epoch 18
2022-02-02 07:44:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:45:12 | INFO | train_inner | epoch 018:     12 / 64 loss=10.085, ppl=1085.85, wps=5948.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.546, train_wall=493, gb_free=6.1, wall=5903
2022-02-02 07:49:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:49:56 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.123 | ppl 1115.21 | wps 8201.7 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-02-02 07:49:56 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-02-02 07:49:56 | INFO | train | epoch 018 | loss 9.973 | ppl 1004.71 | wps 6071.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.559 | train_wall 317 | gb_free 6.1 | wall 6188
KL Stats: Epoch 18 Divergences: Uniform: 1.69929135210822 Unigram: 1.5798597415182467
2022-02-02 07:49:56 | INFO | fairseq.trainer | begin training epoch 19
2022-02-02 07:49:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:53:55 | INFO | train_inner | epoch 019:     48 / 64 loss=9.922, ppl=969.94, wps=6253.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.547, train_wall=495, gb_free=6.1, wall=6426
2022-02-02 07:55:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:55:40 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.061 | ppl 1068.56 | wps 8204 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-02-02 07:55:40 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-02-02 07:55:40 | INFO | train | epoch 019 | loss 9.872 | ppl 936.75 | wps 6085 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.545 | train_wall 316 | gb_free 6.1 | wall 6531
KL Stats: Epoch 19 Divergences: Uniform: 1.72929210468128 Unigram: 1.6564425054360536
2022-02-02 07:55:40 | INFO | fairseq.trainer | begin training epoch 20
2022-02-02 07:55:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:00:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:01:24 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.989 | ppl 1016.46 | wps 8215.5 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-02-02 08:01:24 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-02-02 08:01:24 | INFO | train | epoch 020 | loss 9.776 | ppl 877 | wps 6064.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.571 | train_wall 317 | gb_free 6.1 | wall 6875
KL Stats: Epoch 20 Divergences: Uniform: 1.757576621324816 Unigram: 1.7260285857196813
2022-02-02 08:01:24 | INFO | fairseq.trainer | begin training epoch 21
2022-02-02 08:01:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:03:03 | INFO | train_inner | epoch 021:     20 / 64 loss=9.777, ppl=877.19, wps=5942.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.563, train_wall=494, gb_free=6.1, wall=6975
2022-02-02 08:06:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:07:07 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.94 | ppl 982.15 | wps 8223.6 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-02-02 08:07:07 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-02-02 08:07:07 | INFO | train | epoch 021 | loss 9.685 | ppl 822.98 | wps 6092.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.535 | train_wall 315 | gb_free 6.1 | wall 7218
KL Stats: Epoch 21 Divergences: Uniform: 1.787139090441938 Unigram: 1.7934234597341145
2022-02-02 08:07:07 | INFO | fairseq.trainer | begin training epoch 22
2022-02-02 08:07:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:11:45 | INFO | train_inner | epoch 022:     56 / 64 loss=9.635, ppl=795, wps=6261.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.537, train_wall=494, gb_free=6.1, wall=7497
2022-02-02 08:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:12:51 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.877 | ppl 940.02 | wps 8198.2 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-02-02 08:12:51 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-02-02 08:12:51 | INFO | train | epoch 022 | loss 9.598 | ppl 774.96 | wps 6076.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.548 | train_wall 316 | gb_free 6.1 | wall 7562
KL Stats: Epoch 22 Divergences: Uniform: 1.8117066012770664 Unigram: 1.8580443879206658
2022-02-02 08:12:51 | INFO | fairseq.trainer | begin training epoch 23
2022-02-02 08:12:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:18:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:18:34 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.819 | ppl 903.35 | wps 8199.6 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-02-02 08:18:34 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-02-02 08:18:34 | INFO | train | epoch 023 | loss 9.511 | ppl 729.67 | wps 6086.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.541 | train_wall 316 | gb_free 6.1 | wall 7905
KL Stats: Epoch 23 Divergences: Uniform: 1.8378336446527581 Unigram: 1.9153141249459
2022-02-02 08:18:34 | INFO | fairseq.trainer | begin training epoch 24
2022-02-02 08:18:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:20:53 | INFO | train_inner | epoch 024:     28 / 64 loss=9.493, ppl=720.34, wps=5952.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.554, train_wall=493, gb_free=6.1, wall=8044
2022-02-02 08:23:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:24:18 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.773 | ppl 874.87 | wps 8148.3 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-02-02 08:24:18 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-02-02 08:24:18 | INFO | train | epoch 024 | loss 9.43 | ppl 689.54 | wps 6067.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.569 | train_wall 317 | gb_free 6.1 | wall 8249
KL Stats: Epoch 24 Divergences: Uniform: 1.857978710956802 Unigram: 1.969667158918385
2022-02-02 08:24:18 | INFO | fairseq.trainer | begin training epoch 25
2022-02-02 08:24:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:29:35 | INFO | train_inner | epoch 025:     64 / 64 loss=9.377, ppl=664.71, wps=6245.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.559, train_wall=494, gb_free=6.1, wall=8566
2022-02-02 08:29:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:30:01 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.735 | ppl 852.17 | wps 8222.4 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-02-02 08:30:01 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-02-02 08:30:01 | INFO | train | epoch 025 | loss 9.347 | ppl 651.1 | wps 6080.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.554 | train_wall 316 | gb_free 6.1 | wall 8593
KL Stats: Epoch 25 Divergences: Uniform: 1.88512545535684 Unigram: 2.0222598837578607
2022-02-02 08:30:01 | INFO | fairseq.trainer | begin training epoch 26
2022-02-02 08:30:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:35:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:35:45 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.694 | ppl 828.04 | wps 8163.6 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-02-02 08:35:45 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-02-02 08:35:45 | INFO | train | epoch 026 | loss 9.269 | ppl 617.14 | wps 6071.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.575 | train_wall 316 | gb_free 6.1 | wall 8937
KL Stats: Epoch 26 Divergences: Uniform: 1.9115775353211166 Unigram: 2.073580041124299
2022-02-02 08:35:45 | INFO | fairseq.trainer | begin training epoch 27
2022-02-02 08:35:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:38:45 | INFO | train_inner | epoch 027:     36 / 64 loss=9.242, ppl=605.69, wps=5943.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.56, train_wall=495, gb_free=6.1, wall=9116
2022-02-02 08:41:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:41:29 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.653 | ppl 804.82 | wps 8225.1 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-02-02 08:41:29 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-02-02 08:41:29 | INFO | train | epoch 027 | loss 9.19 | ppl 583.95 | wps 6076 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.538 | train_wall 316 | gb_free 6.1 | wall 9281
KL Stats: Epoch 27 Divergences: Uniform: 1.9308768722993026 Unigram: 2.1188389066585267
2022-02-02 08:41:29 | INFO | fairseq.trainer | begin training epoch 28
2022-02-02 08:41:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:46:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:47:13 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.615 | ppl 784.13 | wps 8176.8 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-02-02 08:47:13 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-02-02 08:47:13 | INFO | train | epoch 028 | loss 9.111 | ppl 553.06 | wps 6071.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.547 | train_wall 316 | gb_free 6.1 | wall 9625
KL Stats: Epoch 28 Divergences: Uniform: 1.9577058969049839 Unigram: 2.167563340529515
2022-02-02 08:47:13 | INFO | fairseq.trainer | begin training epoch 29
2022-02-02 08:47:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:47:53 | INFO | train_inner | epoch 029:      8 / 64 loss=9.126, ppl=558.9, wps=5943.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.548, train_wall=494, gb_free=6.1, wall=9665
2022-02-02 08:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:52:57 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.576 | ppl 763.46 | wps 8229 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-02-02 08:52:57 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-02-02 08:52:57 | INFO | train | epoch 029 | loss 9.033 | ppl 523.97 | wps 6081 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.547 | train_wall 316 | gb_free 6.1 | wall 9968
KL Stats: Epoch 29 Divergences: Uniform: 1.9775991734006486 Unigram: 2.2108305583146217
2022-02-02 08:52:57 | INFO | fairseq.trainer | begin training epoch 30
2022-02-02 08:52:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:56:35 | INFO | train_inner | epoch 030:     44 / 64 loss=9.001, ppl=512.45, wps=6259.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.54, train_wall=494, gb_free=6.1, wall=10187
2022-02-02 08:58:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:58:41 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.541 | ppl 744.76 | wps 8057.6 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-02-02 08:58:41 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-02-02 08:58:41 | INFO | train | epoch 030 | loss 8.957 | ppl 497.07 | wps 6070.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.538 | train_wall 316 | gb_free 6.1 | wall 10312
KL Stats: Epoch 30 Divergences: Uniform: 1.9970487376821342 Unigram: 2.2540493717312127
2022-02-02 08:58:41 | INFO | fairseq.trainer | begin training epoch 31
2022-02-02 08:58:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:03:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:04:24 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.525 | ppl 736.95 | wps 8194.4 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-02-02 09:04:24 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-02-02 09:04:24 | INFO | train | epoch 031 | loss 8.881 | ppl 471.6 | wps 6081 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.53 | train_wall 316 | gb_free 6.1 | wall 10656
KL Stats: Epoch 31 Divergences: Uniform: 2.0161315368325563 Unigram: 2.3016636834057818
2022-02-02 09:04:24 | INFO | fairseq.trainer | begin training epoch 32
2022-02-02 09:04:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:05:44 | INFO | train_inner | epoch 032:     16 / 64 loss=8.881, ppl=471.33, wps=5943.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.54, train_wall=493, gb_free=6.1, wall=10735
2022-02-02 09:09:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:10:08 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.48 | ppl 714.34 | wps 8174.1 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-02-02 09:10:08 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-02-02 09:10:08 | INFO | train | epoch 032 | loss 8.807 | ppl 447.78 | wps 6070.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.542 | train_wall 316 | gb_free 6.1 | wall 11000
KL Stats: Epoch 32 Divergences: Uniform: 2.0370546798943097 Unigram: 2.3388457545903965
2022-02-02 09:10:08 | INFO | fairseq.trainer | begin training epoch 33
2022-02-02 09:10:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:14:28 | INFO | train_inner | epoch 033:     52 / 64 loss=8.768, ppl=435.86, wps=6236.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.529, train_wall=496, gb_free=6.1, wall=11259
2022-02-02 09:15:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:15:53 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.467 | ppl 707.62 | wps 8208.1 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-02-02 09:15:53 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-02-02 09:15:53 | INFO | train | epoch 033 | loss 8.732 | ppl 425.29 | wps 6061.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.528 | train_wall 317 | gb_free 6.1 | wall 11344
KL Stats: Epoch 33 Divergences: Uniform: 2.060256397041595 Unigram: 2.380281685195496
2022-02-02 09:15:53 | INFO | fairseq.trainer | begin training epoch 34
2022-02-02 09:15:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:21:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:21:36 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.438 | ppl 693.5 | wps 8173.5 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-02-02 09:21:36 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-02-02 09:21:36 | INFO | train | epoch 034 | loss 8.658 | ppl 404.04 | wps 6080 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.51 | train_wall 316 | gb_free 6.1 | wall 11688
KL Stats: Epoch 34 Divergences: Uniform: 2.0820159693056355 Unigram: 2.4233521299789706
2022-02-02 09:21:36 | INFO | fairseq.trainer | begin training epoch 35
2022-02-02 09:21:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:23:36 | INFO | train_inner | epoch 035:     24 / 64 loss=8.646, ppl=400.67, wps=5946.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.514, train_wall=493, gb_free=6.1, wall=11807
2022-02-02 09:26:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:27:20 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.412 | ppl 681.41 | wps 8213 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-02-02 09:27:20 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-02-02 09:27:20 | INFO | train | epoch 035 | loss 8.588 | ppl 384.72 | wps 6079.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.509 | train_wall 316 | gb_free 6.1 | wall 12031
KL Stats: Epoch 35 Divergences: Uniform: 2.102558831664863 Unigram: 2.46136617914497
2022-02-02 09:27:20 | INFO | fairseq.trainer | begin training epoch 36
2022-02-02 09:27:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:32:18 | INFO | train_inner | epoch 036:     60 / 64 loss=8.553, ppl=375.54, wps=6254.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.517, train_wall=495, gb_free=6.1, wall=12330
2022-02-02 09:32:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:33:04 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.399 | ppl 674.94 | wps 8146.2 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-02-02 09:33:04 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-02-02 09:33:04 | INFO | train | epoch 036 | loss 8.518 | ppl 366.65 | wps 6070.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.525 | train_wall 316 | gb_free 6.1 | wall 12375
KL Stats: Epoch 36 Divergences: Uniform: 2.118670675524912 Unigram: 2.501162882757039
2022-02-02 09:33:04 | INFO | fairseq.trainer | begin training epoch 37
2022-02-02 09:33:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:38:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:38:47 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.381 | ppl 666.64 | wps 8192.4 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-02-02 09:38:47 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-02-02 09:38:47 | INFO | train | epoch 037 | loss 8.447 | ppl 349.02 | wps 6084.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.515 | train_wall 316 | gb_free 6.1 | wall 12719
KL Stats: Epoch 37 Divergences: Uniform: 2.1467790693587006 Unigram: 2.5387522501253414
2022-02-02 09:38:47 | INFO | fairseq.trainer | begin training epoch 38
2022-02-02 09:38:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:41:26 | INFO | train_inner | epoch 038:     32 / 64 loss=8.424, ppl=343.51, wps=5948.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.52, train_wall=493, gb_free=6.1, wall=12878
2022-02-02 09:44:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:44:31 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.363 | ppl 658.63 | wps 8183.9 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-02-02 09:44:31 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-02-02 09:44:31 | INFO | train | epoch 038 | loss 8.38 | ppl 333.17 | wps 6071.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.517 | train_wall 316 | gb_free 6.1 | wall 13063
KL Stats: Epoch 38 Divergences: Uniform: 2.1638172269661164 Unigram: 2.580149277442834
2022-02-02 09:44:31 | INFO | fairseq.trainer | begin training epoch 39
2022-02-02 09:44:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:49:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:50:15 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.34 | ppl 647.93 | wps 8179.6 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-02-02 09:50:15 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-02-02 09:50:15 | INFO | train | epoch 039 | loss 8.312 | ppl 317.85 | wps 6078.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.51 | train_wall 316 | gb_free 6.1 | wall 13406
KL Stats: Epoch 39 Divergences: Uniform: 2.1838158071173384 Unigram: 2.6221632216699486
2022-02-02 09:50:15 | INFO | fairseq.trainer | begin training epoch 40
2022-02-02 09:50:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:50:35 | INFO | train_inner | epoch 040:      4 / 64 loss=8.332, ppl=322.19, wps=5944.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.511, train_wall=494, gb_free=6.1, wall=13426
2022-02-02 09:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:55:59 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.325 | ppl 641.17 | wps 8158.5 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-02-02 09:55:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-02-02 09:55:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint40.pt
2022-02-02 09:56:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint40.pt
2022-02-02 09:56:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.325) (writing took 4.945981917902827 seconds)
2022-02-02 09:56:04 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-02-02 09:56:04 | INFO | train | epoch 040 | loss 8.244 | ppl 303.18 | wps 5982.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.503 | train_wall 316 | gb_free 6.1 | wall 13755
KL Stats: Epoch 40 Divergences: Uniform: 2.2061184154210807 Unigram: 2.6562562655513675
2022-02-02 09:56:04 | INFO | fairseq.trainer | begin training epoch 41
2022-02-02 09:56:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:59:23 | INFO | train_inner | epoch 041:     40 / 64 loss=8.218, ppl=297.66, wps=6186.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.508, train_wall=495, gb_free=6.1, wall=13954
2022-02-02 10:01:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:01:48 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.318 | ppl 638.34 | wps 8209.1 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.318
2022-02-02 10:01:48 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-02-02 10:01:48 | INFO | train | epoch 041 | loss 8.182 | ppl 290.46 | wps 6074.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.508 | train_wall 316 | gb_free 6.1 | wall 14099
KL Stats: Epoch 41 Divergences: Uniform: 2.220337209836991 Unigram: 2.6939105293351813
2022-02-02 10:01:48 | INFO | fairseq.trainer | begin training epoch 42
2022-02-02 10:01:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:07:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:07:32 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.319 | ppl 638.8 | wps 8172.6 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.319
2022-02-02 10:07:32 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-02-02 10:07:32 | INFO | train | epoch 042 | loss 8.119 | ppl 277.96 | wps 6076.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.507 | train_wall 316 | gb_free 6.1 | wall 14443
KL Stats: Epoch 42 Divergences: Uniform: 2.243547460528093 Unigram: 2.733838457030505
2022-02-02 10:07:32 | INFO | fairseq.trainer | begin training epoch 43
2022-02-02 10:07:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:08:31 | INFO | train_inner | epoch 043:     12 / 64 loss=8.128, ppl=279.72, wps=5944.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.503, train_wall=494, gb_free=6.1, wall=14503
2022-02-02 10:12:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:13:15 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.301 | ppl 630.7 | wps 8219 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.301
2022-02-02 10:13:15 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-02-02 10:13:15 | INFO | train | epoch 043 | loss 8.055 | ppl 266.01 | wps 6080.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.515 | train_wall 316 | gb_free 6.1 | wall 14786
KL Stats: Epoch 43 Divergences: Uniform: 2.270486772827609 Unigram: 2.7695393104104533
2022-02-02 10:13:15 | INFO | fairseq.trainer | begin training epoch 44
2022-02-02 10:13:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:17:13 | INFO | train_inner | epoch 044:     48 / 64 loss=8.023, ppl=260.1, wps=6260.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.519, train_wall=494, gb_free=6.1, wall=15025
2022-02-02 10:18:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:18:59 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.298 | ppl 629.33 | wps 8165.6 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.298
2022-02-02 10:18:59 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-02-02 10:18:59 | INFO | train | epoch 044 | loss 7.996 | ppl 255.29 | wps 6077 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.524 | train_wall 316 | gb_free 6.1 | wall 15130
KL Stats: Epoch 44 Divergences: Uniform: 2.285052763849589 Unigram: 2.8030513783745694
2022-02-02 10:18:59 | INFO | fairseq.trainer | begin training epoch 45
2022-02-02 10:18:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:24:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:24:42 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.275 | ppl 619.49 | wps 8193.7 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.275
2022-02-02 10:24:42 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-02-02 10:24:42 | INFO | train | epoch 045 | loss 7.934 | ppl 244.58 | wps 6079.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.515 | train_wall 316 | gb_free 6.1 | wall 15474
KL Stats: Epoch 45 Divergences: Uniform: 2.3009712355326295 Unigram: 2.840178383227406
2022-02-02 10:24:42 | INFO | fairseq.trainer | begin training epoch 46
2022-02-02 10:24:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:26:22 | INFO | train_inner | epoch 046:     20 / 64 loss=7.932, ppl=244.2, wps=5946.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.522, train_wall=493, gb_free=6.1, wall=15573
2022-02-02 10:29:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:30:26 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.273 | ppl 618.5 | wps 8160.2 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.273
2022-02-02 10:30:26 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-02-02 10:30:26 | INFO | train | epoch 046 | loss 7.874 | ppl 234.57 | wps 6081.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.518 | train_wall 316 | gb_free 6.1 | wall 15817
KL Stats: Epoch 46 Divergences: Uniform: 2.317369660112099 Unigram: 2.8724626260919144
2022-02-02 10:30:26 | INFO | fairseq.trainer | begin training epoch 47
2022-02-02 10:30:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:35:05 | INFO | train_inner | epoch 047:     56 / 64 loss=7.845, ppl=229.85, wps=6247.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.522, train_wall=495, gb_free=6.1, wall=16096
2022-02-02 10:35:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:36:10 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.268 | ppl 616.61 | wps 8216.1 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.268
2022-02-02 10:36:10 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-02-02 10:36:10 | INFO | train | epoch 047 | loss 7.818 | ppl 225.59 | wps 6070.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.527 | train_wall 317 | gb_free 6.1 | wall 16161
KL Stats: Epoch 47 Divergences: Uniform: 2.3365020664120273 Unigram: 2.9051217275146266
2022-02-02 10:36:10 | INFO | fairseq.trainer | begin training epoch 48
2022-02-02 10:36:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:41:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:41:54 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.275 | ppl 619.41 | wps 8172.1 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.275
2022-02-02 10:41:54 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-02-02 10:41:54 | INFO | train | epoch 048 | loss 7.757 | ppl 216.39 | wps 6075.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.5 | train_wall 316 | gb_free 6.1 | wall 16505
KL Stats: Epoch 48 Divergences: Uniform: 2.3539483192704593 Unigram: 2.934245239508401
2022-02-02 10:41:54 | INFO | fairseq.trainer | begin training epoch 49
2022-02-02 10:41:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:44:13 | INFO | train_inner | epoch 049:     28 / 64 loss=7.743, ppl=214.26, wps=5946.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.511, train_wall=493, gb_free=6.1, wall=16644
2022-02-02 10:47:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:47:36 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.288 | ppl 625.34 | wps 8253.2 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.288
2022-02-02 10:47:36 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-02-02 10:47:36 | INFO | train | epoch 049 | loss 7.705 | ppl 208.66 | wps 6099 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.524 | train_wall 315 | gb_free 6.1 | wall 16847
KL Stats: Epoch 49 Divergences: Uniform: 2.3621801381845553 Unigram: 2.972897992364788
2022-02-02 10:47:36 | INFO | fairseq.trainer | begin training epoch 50
2022-02-02 10:47:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:52:51 | INFO | train_inner | epoch 050:     64 / 64 loss=7.676, ppl=204.55, wps=6287.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.517, train_wall=491, gb_free=6.1, wall=17163
2022-02-02 10:52:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:53:18 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.296 | ppl 628.8 | wps 8230 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.296
2022-02-02 10:53:18 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-02-02 10:53:18 | INFO | train | epoch 050 | loss 7.649 | ppl 200.67 | wps 6107.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.518 | train_wall 315 | gb_free 6.1 | wall 17189
KL Stats: Epoch 50 Divergences: Uniform: 2.3915020292513223 Unigram: 3.007286602584087
2022-02-02 10:53:18 | INFO | fairseq.trainer | begin training epoch 51
2022-02-02 10:53:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:58:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:59:00 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.298 | ppl 629.4 | wps 8279.6 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.298
2022-02-02 10:59:00 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-02-02 10:59:00 | INFO | train | epoch 051 | loss 7.595 | ppl 193.32 | wps 6111.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.529 | train_wall 315 | gb_free 6.1 | wall 17531
KL Stats: Epoch 51 Divergences: Uniform: 2.3964333625248257 Unigram: 3.0415138487174573
2022-02-02 10:59:00 | INFO | fairseq.trainer | begin training epoch 52
2022-02-02 10:59:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:01:58 | INFO | train_inner | epoch 052:     36 / 64 loss=7.563, ppl=189.06, wps=5982.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.524, train_wall=492, gb_free=6.1, wall=17709
2022-02-02 11:04:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:04:41 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.331 | ppl 644.21 | wps 8234.7 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.325
2022-02-02 11:04:41 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-02-02 11:04:41 | INFO | train | epoch 052 | loss 7.542 | ppl 186.4 | wps 6112.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.528 | train_wall 314 | gb_free 6.1 | wall 17873
KL Stats: Epoch 52 Divergences: Uniform: 2.4184906638255925 Unigram: 3.0736601768574925
2022-02-02 11:04:41 | INFO | fairseq.trainer | begin training epoch 53
2022-02-02 11:04:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:09:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:10:23 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.287 | ppl 624.8 | wps 8255.8 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.287
2022-02-02 11:10:23 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-02-02 11:10:23 | INFO | train | epoch 053 | loss 7.492 | ppl 179.96 | wps 6110.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.528 | train_wall 314 | gb_free 6.1 | wall 18215
KL Stats: Epoch 53 Divergences: Uniform: 2.430899956784035 Unigram: 3.0988540268452285
2022-02-02 11:10:23 | INFO | fairseq.trainer | begin training epoch 54
2022-02-02 11:10:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:11:03 | INFO | train_inner | epoch 054:      8 / 64 loss=7.514, ppl=182.74, wps=5980.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.533, train_wall=491, gb_free=6.1, wall=18254
2022-02-02 11:15:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:16:05 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.299 | ppl 630.03 | wps 8244.5 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.299
2022-02-02 11:16:05 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-02-02 11:16:05 | INFO | train | epoch 054 | loss 7.44 | ppl 173.67 | wps 6113.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.549 | train_wall 314 | gb_free 6.1 | wall 18556
KL Stats: Epoch 54 Divergences: Uniform: 2.44272966973262 Unigram: 3.134164204028147
2022-02-02 11:16:05 | INFO | fairseq.trainer | begin training epoch 55
2022-02-02 11:16:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:19:43 | INFO | train_inner | epoch 055:     44 / 64 loss=7.415, ppl=170.68, wps=6287.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.548, train_wall=492, gb_free=6.1, wall=18774
2022-02-02 11:21:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:21:47 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.329 | ppl 643.07 | wps 8266.6 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.325
2022-02-02 11:21:47 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-02-02 11:21:47 | INFO | train | epoch 055 | loss 7.393 | ppl 168.04 | wps 6114.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.539 | train_wall 314 | gb_free 6.1 | wall 18898
KL Stats: Epoch 55 Divergences: Uniform: 2.4654922771072894 Unigram: 3.1624799191660737
2022-02-02 11:21:47 | INFO | fairseq.trainer | begin training epoch 56
2022-02-02 11:21:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:27:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:27:28 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.31 | ppl 634.54 | wps 8245.3 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.31
2022-02-02 11:27:28 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-02-02 11:27:28 | INFO | train | epoch 056 | loss 7.341 | ppl 162.18 | wps 6115.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.521 | train_wall 314 | gb_free 6.1 | wall 19239
KL Stats: Epoch 56 Divergences: Uniform: 2.4701958523820995 Unigram: 3.187478790376327
2022-02-02 11:27:28 | INFO | fairseq.trainer | begin training epoch 57
2022-02-02 11:27:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:28:47 | INFO | train_inner | epoch 057:     16 / 64 loss=7.34, ppl=162.07, wps=5984.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.531, train_wall=490, gb_free=6.1, wall=19319
2022-02-02 11:32:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:33:10 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.308 | ppl 633.75 | wps 8240.1 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.308
2022-02-02 11:33:10 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-02-02 11:33:10 | INFO | train | epoch 057 | loss 7.296 | ppl 157.18 | wps 6111.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.555 | train_wall 314 | gb_free 6.1 | wall 19581
KL Stats: Epoch 57 Divergences: Uniform: 2.4916001567298762 Unigram: 3.2155766129440804
2022-02-02 11:33:10 | INFO | fairseq.trainer | begin training epoch 58
2022-02-02 11:33:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:37:27 | INFO | train_inner | epoch 058:     52 / 64 loss=7.272, ppl=154.51, wps=6290, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.549, train_wall=492, gb_free=6.1, wall=19838
2022-02-02 11:38:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:38:51 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.312 | ppl 635.63 | wps 8248.9 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.312
2022-02-02 11:38:51 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-02-02 11:38:51 | INFO | train | epoch 058 | loss 7.246 | ppl 151.8 | wps 6114.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.547 | train_wall 314 | gb_free 6.1 | wall 19923
KL Stats: Epoch 58 Divergences: Uniform: 2.49777575445027 Unigram: 3.2462151275970013
2022-02-02 11:38:51 | INFO | fairseq.trainer | begin training epoch 59
2022-02-02 11:38:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:44:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:44:33 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.386 | ppl 669.02 | wps 8263.6 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.325
2022-02-02 11:44:33 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-02-02 11:44:33 | INFO | train | epoch 059 | loss 7.203 | ppl 147.37 | wps 6108.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.55 | train_wall 315 | gb_free 6.1 | wall 20265
KL Stats: Epoch 59 Divergences: Uniform: 2.514263626103712 Unigram: 3.270612908425566
2022-02-02 11:44:33 | INFO | fairseq.trainer | begin training epoch 60
2022-02-02 11:44:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:46:32 | INFO | train_inner | epoch 060:     24 / 64 loss=7.192, ppl=146.22, wps=5980.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.553, train_wall=491, gb_free=6.1, wall=20383
2022-02-02 11:49:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:50:15 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.364 | ppl 659.08 | wps 8263.3 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.325
2022-02-02 11:50:15 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-02-02 11:50:15 | INFO | train | epoch 060 | loss 7.159 | ppl 142.96 | wps 6118.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.57 | train_wall 314 | gb_free 6.1 | wall 20606
KL Stats: Epoch 60 Divergences: Uniform: 2.524442248168756 Unigram: 3.302971840328076
2022-02-02 11:50:15 | INFO | fairseq.trainer | begin training epoch 61
2022-02-02 11:50:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:55:12 | INFO | train_inner | epoch 061:     60 / 64 loss=7.144, ppl=141.46, wps=6286.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.559, train_wall=492, gb_free=6.1, wall=20903
2022-02-02 11:55:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:55:57 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.366 | ppl 659.72 | wps 8259 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.325
2022-02-02 11:55:57 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-02-02 11:55:57 | INFO | train | epoch 061 | loss 7.115 | ppl 138.65 | wps 6106.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.553 | train_wall 315 | gb_free 6.1 | wall 20948
KL Stats: Epoch 61 Divergences: Uniform: 2.5355832647652927 Unigram: 3.3279993389111016
2022-02-02 11:55:57 | INFO | fairseq.trainer | begin training epoch 62
2022-02-02 11:55:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:01:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:01:38 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.432 | ppl 690.65 | wps 8276.8 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.325
2022-02-02 12:01:38 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-02-02 12:01:38 | INFO | train | epoch 062 | loss 7.072 | ppl 134.59 | wps 6113.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.565 | train_wall 314 | gb_free 6.1 | wall 21290
KL Stats: Epoch 62 Divergences: Uniform: 2.540643028613995 Unigram: 3.351150521901889
2022-02-02 12:01:38 | INFO | fairseq.trainer | begin training epoch 63
2022-02-02 12:01:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:04:17 | INFO | train_inner | epoch 063:     32 / 64 loss=7.052, ppl=132.68, wps=5979.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.566, train_wall=491, gb_free=6.1, wall=21448
2022-02-02 12:06:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:07:21 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.45 | ppl 699.65 | wps 8261.2 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.325
2022-02-02 12:07:21 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-02-02 12:07:21 | INFO | train | epoch 063 | loss 7.029 | ppl 130.64 | wps 6103.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.568 | train_wall 315 | gb_free 6.1 | wall 21632
KL Stats: Epoch 63 Divergences: Uniform: 2.561772650948536 Unigram: 3.385060090675811
2022-02-02 12:07:21 | INFO | fairseq.trainer | begin training epoch 64
2022-02-02 12:07:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:12:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:13:02 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.441 | ppl 695.15 | wps 8238.8 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.325
2022-02-02 12:13:02 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-02-02 12:13:02 | INFO | train | epoch 064 | loss 6.986 | ppl 126.8 | wps 6119.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.566 | train_wall 314 | gb_free 6.1 | wall 21973
KL Stats: Epoch 64 Divergences: Uniform: 2.576452198422225 Unigram: 3.411709207881042
2022-02-02 12:13:02 | INFO | fairseq.trainer | begin training epoch 65
2022-02-02 12:13:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:13:22 | INFO | train_inner | epoch 065:      4 / 64 loss=7.006, ppl=128.58, wps=5984.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.566, train_wall=490, gb_free=6.1, wall=21993
2022-02-02 12:18:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:18:44 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.443 | ppl 695.99 | wps 8275.1 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.325
2022-02-02 12:18:44 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-02-02 12:18:44 | INFO | train | epoch 065 | loss 6.945 | ppl 123.18 | wps 6111.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.569 | train_wall 315 | gb_free 6.1 | wall 22315
KL Stats: Epoch 65 Divergences: Uniform: 2.589762336140043 Unigram: 3.4294549655871975
2022-02-02 12:18:44 | INFO | fairseq.trainer | begin training epoch 66
2022-02-02 12:18:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:22:01 | INFO | train_inner | epoch 066:     40 / 64 loss=6.916, ppl=120.79, wps=6291.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.571, train_wall=492, gb_free=6.1, wall=22513
2022-02-02 12:23:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:24:25 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.464 | ppl 706.36 | wps 8292.2 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.325
2022-02-02 12:24:25 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-02-02 12:24:25 | INFO | train | epoch 066 | loss 6.902 | ppl 119.57 | wps 6121.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.573 | train_wall 314 | gb_free 6.1 | wall 22656
KL Stats: Epoch 66 Divergences: Uniform: 2.5900315205573614 Unigram: 3.459737220235893
2022-02-02 12:24:25 | INFO | fairseq.trainer | begin training epoch 67
2022-02-02 12:24:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:29:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:30:07 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.501 | ppl 724.43 | wps 8270.4 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.325
2022-02-02 12:30:07 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-02-02 12:30:07 | INFO | train | epoch 067 | loss 6.863 | ppl 116.38 | wps 6102.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.582 | train_wall 315 | gb_free 6.1 | wall 22998
KL Stats: Epoch 67 Divergences: Uniform: 2.6123104199165246 Unigram: 3.4933018601845487
2022-02-02 12:30:07 | INFO | fairseq.trainer | begin training epoch 68
2022-02-02 12:30:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:31:06 | INFO | train_inner | epoch 068:     12 / 64 loss=6.874, ppl=117.27, wps=5979.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.579, train_wall=491, gb_free=6.1, wall=23058
2022-02-02 12:35:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:35:48 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.5 | ppl 724.3 | wps 8231 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.325
2022-02-02 12:35:49 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-02-02 12:35:49 | INFO | train | epoch 068 | loss 6.82 | ppl 112.97 | wps 6118.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.565 | train_wall 314 | gb_free 6.1 | wall 23340
KL Stats: Epoch 68 Divergences: Uniform: 2.617972773019864 Unigram: 3.530961206633411
2022-02-02 12:35:49 | INFO | fairseq.trainer | begin training epoch 69
2022-02-02 12:35:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:39:47 | INFO | train_inner | epoch 069:     48 / 64 loss=6.803, ppl=111.65, wps=6276.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.575, train_wall=493, gb_free=6.1, wall=23578
2022-02-02 12:41:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:41:31 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.49 | ppl 718.97 | wps 8252.1 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.325
2022-02-02 12:41:31 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-02-02 12:41:31 | INFO | train | epoch 069 | loss 6.784 | ppl 110.18 | wps 6089.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.589 | train_wall 316 | gb_free 6.1 | wall 23683
KL Stats: Epoch 69 Divergences: Uniform: 2.6237525379081013 Unigram: 3.5511259780795745
2022-02-02 12:41:31 | INFO | fairseq.trainer | begin training epoch 70
2022-02-02 12:41:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:46:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:47:14 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.538 | ppl 743.53 | wps 8231 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.325
2022-02-02 12:47:14 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-02-02 12:47:14 | INFO | train | epoch 070 | loss 6.747 | ppl 107.38 | wps 6105.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.576 | train_wall 315 | gb_free 6.1 | wall 24025
KL Stats: Epoch 70 Divergences: Uniform: 2.6374985290219186 Unigram: 3.5799407119810236
2022-02-02 12:47:14 | INFO | fairseq.trainer | begin training epoch 71
2022-02-02 12:47:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:48:53 | INFO | train_inner | epoch 071:     20 / 64 loss=6.741, ppl=106.97, wps=5976.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.575, train_wall=491, gb_free=6.1, wall=24124
2022-02-02 12:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:52:56 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.585 | ppl 768 | wps 8236.6 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.325
2022-02-02 12:52:56 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-02-02 12:52:56 | INFO | train | epoch 071 | loss 6.71 | ppl 104.72 | wps 6097.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.579 | train_wall 315 | gb_free 6.1 | wall 24367
KL Stats: Epoch 71 Divergences: Uniform: 2.647782968723451 Unigram: 3.6026571951492383
2022-02-02 12:52:56 | INFO | fairseq.trainer | begin training epoch 72
2022-02-02 12:52:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:57:34 | INFO | train_inner | epoch 072:     56 / 64 loss=6.698, ppl=103.8, wps=6271.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.585, train_wall=493, gb_free=6.1, wall=24645
2022-02-02 12:58:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:58:39 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.503 | ppl 725.57 | wps 8232.8 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.325
2022-02-02 12:58:39 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-02-02 12:58:39 | INFO | train | epoch 072 | loss 6.676 | ppl 102.26 | wps 6098.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.583 | train_wall 315 | gb_free 6.1 | wall 24710
KL Stats: Epoch 72 Divergences: Uniform: 2.6603347485826325 Unigram: 3.630604008701289
2022-02-02 12:58:39 | INFO | fairseq.trainer | begin training epoch 73
2022-02-02 12:58:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:03:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:04:21 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.577 | ppl 763.88 | wps 8251.5 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.325
2022-02-02 13:04:21 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-02-02 13:04:21 | INFO | train | epoch 073 | loss 6.644 | ppl 99.98 | wps 6094.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.61 | train_wall 315 | gb_free 6.1 | wall 25053
KL Stats: Epoch 73 Divergences: Uniform: 2.6608178009205905 Unigram: 3.6484479490407984
2022-02-02 13:04:21 | INFO | fairseq.trainer | begin training epoch 74
2022-02-02 13:04:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:06:40 | INFO | train_inner | epoch 074:     28 / 64 loss=6.628, ppl=98.93, wps=5968.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.604, train_wall=492, gb_free=6.1, wall=25191
2022-02-02 13:09:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:10:03 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.632 | ppl 793.62 | wps 8233.4 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.325
2022-02-02 13:10:03 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-02-02 13:10:03 | INFO | train | epoch 074 | loss 6.609 | ppl 97.61 | wps 6105.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.604 | train_wall 315 | gb_free 6.1 | wall 25395
KL Stats: Epoch 74 Divergences: Uniform: 2.670444379316348 Unigram: 3.6776184756333596
2022-02-02 13:10:03 | INFO | fairseq.trainer | begin training epoch 75
2022-02-02 13:10:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:15:20 | INFO | train_inner | epoch 075:     64 / 64 loss=6.602, ppl=97.17, wps=6267.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.621, train_wall=492, gb_free=6.1, wall=25711
2022-02-02 13:15:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:15:46 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.566 | ppl 757.85 | wps 8270.8 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.325
2022-02-02 13:15:46 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-02-02 13:15:46 | INFO | train | epoch 075 | loss 6.58 | ppl 95.68 | wps 6088.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.628 | train_wall 316 | gb_free 6.1 | wall 25738
KL Stats: Epoch 75 Divergences: Uniform: 2.695455343946583 Unigram: 3.703813331263678
2022-02-02 13:15:46 | INFO | fairseq.trainer | begin training epoch 76
2022-02-02 13:15:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:21:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:21:29 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.624 | ppl 789.26 | wps 8240.1 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.325
2022-02-02 13:21:29 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-02-02 13:21:29 | INFO | train | epoch 076 | loss 6.546 | ppl 93.43 | wps 6100.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.607 | train_wall 315 | gb_free 6.1 | wall 26080
KL Stats: Epoch 76 Divergences: Uniform: 2.6940090771627276 Unigram: 3.7248171524000444
2022-02-02 13:21:29 | INFO | fairseq.trainer | begin training epoch 77
2022-02-02 13:21:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:24:27 | INFO | train_inner | epoch 077:     36 / 64 loss=6.52, ppl=91.76, wps=5970.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.61, train_wall=493, gb_free=6.1, wall=26259
2022-02-02 13:26:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:27:12 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.639 | ppl 797.33 | wps 8241 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.325
2022-02-02 13:27:12 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-02-02 13:27:12 | INFO | train | epoch 077 | loss 6.515 | ppl 91.44 | wps 6091.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.603 | train_wall 316 | gb_free 6.1 | wall 26423
KL Stats: Epoch 77 Divergences: Uniform: 2.70405846863284 Unigram: 3.7587429851730083
2022-02-02 13:27:12 | INFO | fairseq.trainer | begin training epoch 78
2022-02-02 13:27:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:32:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:32:54 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.669 | ppl 814.22 | wps 8226.6 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.325
2022-02-02 13:32:54 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-02-02 13:32:54 | INFO | train | epoch 078 | loss 6.49 | ppl 89.89 | wps 6103.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.635 | train_wall 315 | gb_free 6.1 | wall 26765
KL Stats: Epoch 78 Divergences: Uniform: 2.7045624657202127 Unigram: 3.769631261567354
2022-02-02 13:32:54 | INFO | fairseq.trainer | begin training epoch 79
2022-02-02 13:32:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:33:34 | INFO | train_inner | epoch 079:      8 / 64 loss=6.502, ppl=90.64, wps=5968.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.623, train_wall=492, gb_free=6.1, wall=26805
2022-02-02 13:38:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:38:37 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.628 | ppl 791.43 | wps 8206.8 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.325
2022-02-02 13:38:37 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-02-02 13:38:37 | INFO | train | epoch 079 | loss 6.46 | ppl 88.01 | wps 6089.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.633 | train_wall 315 | gb_free 6.1 | wall 27108
KL Stats: Epoch 79 Divergences: Uniform: 2.719834334470408 Unigram: 3.7946047235794507
2022-02-02 13:38:37 | INFO | fairseq.trainer | begin training epoch 80
2022-02-02 13:38:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:42:15 | INFO | train_inner | epoch 080:     44 / 64 loss=6.447, ppl=87.25, wps=6272.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.623, train_wall=493, gb_free=6.1, wall=27326
2022-02-02 13:43:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:44:19 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.632 | ppl 793.62 | wps 8223.7 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.325
2022-02-02 13:44:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-02-02 13:44:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint80.pt
2022-02-02 13:44:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint80.pt
2022-02-02 13:44:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.632) (writing took 3.426564434543252 seconds)
2022-02-02 13:44:22 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-02-02 13:44:22 | INFO | train | epoch 080 | loss 6.433 | ppl 86.4 | wps 6043 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.616 | train_wall 315 | gb_free 6.1 | wall 27454
KL Stats: Epoch 80 Divergences: Uniform: 2.720864298075927 Unigram: 3.821921197456939
2022-02-02 13:44:22 | INFO | fairseq.trainer | begin training epoch 81
2022-02-02 13:44:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:49:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:50:05 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.757 | ppl 865.22 | wps 8235.4 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.325
2022-02-02 13:50:05 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-02-02 13:50:05 | INFO | train | epoch 081 | loss 6.406 | ppl 84.79 | wps 6089.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.644 | train_wall 316 | gb_free 6.1 | wall 27797
KL Stats: Epoch 81 Divergences: Uniform: 2.736117498640796 Unigram: 3.8506560990189214
2022-02-02 13:50:05 | INFO | fairseq.trainer | begin training epoch 82
2022-02-02 13:50:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:51:25 | INFO | train_inner | epoch 082:     16 / 64 loss=6.411, ppl=85.11, wps=5925.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.638, train_wall=492, gb_free=6.1, wall=27876
2022-02-02 13:55:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:55:48 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.694 | ppl 828.29 | wps 8232.9 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.325
2022-02-02 13:55:48 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-02-02 13:55:48 | INFO | train | epoch 082 | loss 6.38 | ppl 83.3 | wps 6102.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.65 | train_wall 315 | gb_free 6.1 | wall 28139
KL Stats: Epoch 82 Divergences: Uniform: 2.7467086929985007 Unigram: 3.8579974301486772
2022-02-02 13:55:48 | INFO | fairseq.trainer | begin training epoch 83
2022-02-02 13:55:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:00:05 | INFO | train_inner | epoch 083:     52 / 64 loss=6.363, ppl=82.28, wps=6277.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.657, train_wall=493, gb_free=6.1, wall=28397
2022-02-02 14:01:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:01:30 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.689 | ppl 825.53 | wps 8195.7 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.325
2022-02-02 14:01:30 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-02-02 14:01:30 | INFO | train | epoch 083 | loss 6.354 | ppl 81.81 | wps 6095.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.658 | train_wall 315 | gb_free 6.1 | wall 28482
KL Stats: Epoch 83 Divergences: Uniform: 2.7574579506199783 Unigram: 3.8908535241551574
2022-02-02 14:01:30 | INFO | fairseq.trainer | begin training epoch 84
2022-02-02 14:01:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:06:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:07:12 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.718 | ppl 842.13 | wps 8236 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.325
2022-02-02 14:07:12 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-02-02 14:07:12 | INFO | train | epoch 084 | loss 6.33 | ppl 80.47 | wps 6105.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.651 | train_wall 315 | gb_free 6.1 | wall 28824
KL Stats: Epoch 84 Divergences: Uniform: 2.753388942213943 Unigram: 3.910576373801674
2022-02-02 14:07:12 | INFO | fairseq.trainer | begin training epoch 85
2022-02-02 14:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:09:11 | INFO | train_inner | epoch 085:     24 / 64 loss=6.325, ppl=80.16, wps=5970.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.656, train_wall=491, gb_free=6.1, wall=28943
2022-02-02 14:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:12:56 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.689 | ppl 825.15 | wps 8207.8 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.325
2022-02-02 14:12:56 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-02-02 14:12:56 | INFO | train | epoch 085 | loss 6.305 | ppl 79.09 | wps 6087.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.657 | train_wall 316 | gb_free 6.1 | wall 29167
KL Stats: Epoch 85 Divergences: Uniform: 2.7617023388015607 Unigram: 3.9371037989047912
2022-02-02 14:12:56 | INFO | fairseq.trainer | begin training epoch 86
2022-02-02 14:12:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:17:53 | INFO | train_inner | epoch 086:     60 / 64 loss=6.299, ppl=78.74, wps=6270.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.654, train_wall=493, gb_free=6.1, wall=29464
2022-02-02 14:18:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:18:38 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.758 | ppl 866 | wps 8233.3 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.325
2022-02-02 14:18:38 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-02-02 14:18:38 | INFO | train | epoch 086 | loss 6.281 | ppl 77.76 | wps 6106.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.656 | train_wall 315 | gb_free 6.1 | wall 29509
KL Stats: Epoch 86 Divergences: Uniform: 2.7673065500475276 Unigram: 3.9525042407733832
2022-02-02 14:18:38 | INFO | fairseq.trainer | begin training epoch 87
2022-02-02 14:18:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:23:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:24:20 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.783 | ppl 881.08 | wps 8231 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.325
2022-02-02 14:24:20 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-02-02 14:24:20 | INFO | train | epoch 087 | loss 6.258 | ppl 76.55 | wps 6097.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.678 | train_wall 315 | gb_free 6.1 | wall 29851
KL Stats: Epoch 87 Divergences: Uniform: 2.772332978047533 Unigram: 3.968787619128949
2022-02-02 14:24:20 | INFO | fairseq.trainer | begin training epoch 88
2022-02-02 14:24:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:26:59 | INFO | train_inner | epoch 088:     32 / 64 loss=6.244, ppl=75.8, wps=5970.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.681, train_wall=492, gb_free=6.1, wall=30010
2022-02-02 14:29:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:30:02 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.78 | ppl 879.31 | wps 8245.6 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.325
2022-02-02 14:30:02 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-02-02 14:30:02 | INFO | train | epoch 088 | loss 6.236 | ppl 75.37 | wps 6105.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.682 | train_wall 315 | gb_free 6.1 | wall 30194
KL Stats: Epoch 88 Divergences: Uniform: 2.7776538461142524 Unigram: 3.9890631230418228
2022-02-02 14:30:02 | INFO | fairseq.trainer | begin training epoch 89
2022-02-02 14:30:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:35:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:35:45 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.772 | ppl 874.02 | wps 8192.7 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.325
2022-02-02 14:35:45 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-02-02 14:35:45 | INFO | train | epoch 089 | loss 6.214 | ppl 74.22 | wps 6101.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.662 | train_wall 315 | gb_free 6.1 | wall 30536
KL Stats: Epoch 89 Divergences: Uniform: 2.783534969587195 Unigram: 4.002841114944952
2022-02-02 14:35:45 | INFO | fairseq.trainer | begin training epoch 90
2022-02-02 14:35:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:36:04 | INFO | train_inner | epoch 090:      4 / 64 loss=6.228, ppl=74.95, wps=5970.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.666, train_wall=491, gb_free=6.1, wall=30556
2022-02-02 14:41:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:41:28 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.814 | ppl 900.2 | wps 8236.5 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.325
2022-02-02 14:41:28 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-02-02 14:41:28 | INFO | train | epoch 090 | loss 6.193 | ppl 73.14 | wps 6089.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.694 | train_wall 316 | gb_free 6.1 | wall 30879
KL Stats: Epoch 90 Divergences: Uniform: 2.7996141502077294 Unigram: 4.030924715362969
2022-02-02 14:41:28 | INFO | fairseq.trainer | begin training epoch 91
2022-02-02 14:41:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:44:45 | INFO | train_inner | epoch 091:     40 / 64 loss=6.175, ppl=72.25, wps=6272.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.688, train_wall=493, gb_free=6.1, wall=31077
2022-02-02 14:46:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:47:10 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.779 | ppl 878.6 | wps 8213.1 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.325
2022-02-02 14:47:10 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-02-02 14:47:10 | INFO | train | epoch 091 | loss 6.17 | ppl 72.02 | wps 6100.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.679 | train_wall 315 | gb_free 6.1 | wall 31221
KL Stats: Epoch 91 Divergences: Uniform: 2.7993090138983527 Unigram: 4.052564928492492
2022-02-02 14:47:10 | INFO | fairseq.trainer | begin training epoch 92
2022-02-02 14:47:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:52:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:52:52 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.795 | ppl 888.18 | wps 8255.4 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.325
2022-02-02 14:52:52 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-02-02 14:52:52 | INFO | train | epoch 092 | loss 6.15 | ppl 71 | wps 6096.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.702 | train_wall 315 | gb_free 6.1 | wall 31564
KL Stats: Epoch 92 Divergences: Uniform: 2.813898136919464 Unigram: 4.077419762922508
2022-02-02 14:52:52 | INFO | fairseq.trainer | begin training epoch 93
2022-02-02 14:52:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:53:52 | INFO | train_inner | epoch 093:     12 / 64 loss=6.158, ppl=71.39, wps=5965.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.698, train_wall=492, gb_free=6.1, wall=31623
2022-02-02 14:58:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:58:35 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.814 | ppl 899.91 | wps 8224.2 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.325
2022-02-02 14:58:35 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-02-02 14:58:35 | INFO | train | epoch 093 | loss 6.132 | ppl 70.13 | wps 6098.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.701 | train_wall 315 | gb_free 6.1 | wall 31906
KL Stats: Epoch 93 Divergences: Uniform: 2.81394471468208 Unigram: 4.091249580865853
2022-02-02 14:58:35 | INFO | fairseq.trainer | begin training epoch 94
2022-02-02 14:58:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:02:33 | INFO | train_inner | epoch 094:     48 / 64 loss=6.114, ppl=69.28, wps=6271.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.704, train_wall=493, gb_free=6.1, wall=32144
2022-02-02 15:03:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:04:17 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.828 | ppl 909.19 | wps 8244.3 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.325
2022-02-02 15:04:17 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-02-02 15:04:17 | INFO | train | epoch 094 | loss 6.109 | ppl 69.02 | wps 6098.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.712 | train_wall 315 | gb_free 6.1 | wall 32249
KL Stats: Epoch 94 Divergences: Uniform: 2.81638715228027 Unigram: 4.118299785212734
2022-02-02 15:04:17 | INFO | fairseq.trainer | begin training epoch 95
2022-02-02 15:04:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:09:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:10:00 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.823 | ppl 906.06 | wps 8205.4 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.325
2022-02-02 15:10:00 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-02-02 15:10:00 | INFO | train | epoch 095 | loss 6.092 | ppl 68.2 | wps 6094.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.696 | train_wall 315 | gb_free 6.1 | wall 32591
KL Stats: Epoch 95 Divergences: Uniform: 2.824464997555275 Unigram: 4.130190530142888
2022-02-02 15:10:00 | INFO | fairseq.trainer | begin training epoch 96
2022-02-02 15:10:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:11:39 | INFO | train_inner | epoch 096:     20 / 64 loss=6.092, ppl=68.22, wps=5967.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.707, train_wall=492, gb_free=6.1, wall=32691
2022-02-02 15:15:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:15:42 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.886 | ppl 946.23 | wps 8269.2 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.325
2022-02-02 15:15:42 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-02-02 15:15:42 | INFO | train | epoch 096 | loss 6.074 | ppl 67.36 | wps 6105 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.713 | train_wall 315 | gb_free 6.1 | wall 32934
KL Stats: Epoch 96 Divergences: Uniform: 2.821836187741093 Unigram: 4.149030506584415
2022-02-02 15:15:42 | INFO | fairseq.trainer | begin training epoch 97
2022-02-02 15:15:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:20:20 | INFO | train_inner | epoch 097:     56 / 64 loss=6.075, ppl=67.41, wps=6271.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.712, train_wall=493, gb_free=6.1, wall=33212
2022-02-02 15:20:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:21:26 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.838 | ppl 915.16 | wps 8220.4 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.325
2022-02-02 15:21:26 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-02-02 15:21:26 | INFO | train | epoch 097 | loss 6.056 | ppl 66.53 | wps 6083.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.722 | train_wall 316 | gb_free 6.1 | wall 33277
KL Stats: Epoch 97 Divergences: Uniform: 2.837440400984993 Unigram: 4.165089918780845
2022-02-02 15:21:26 | INFO | fairseq.trainer | begin training epoch 98
2022-02-02 15:21:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:26:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:27:07 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.913 | ppl 964.35 | wps 8257 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.325
2022-02-02 15:27:07 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-02-02 15:27:07 | INFO | train | epoch 098 | loss 6.036 | ppl 65.59 | wps 6110.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.73 | train_wall 314 | gb_free 6.1 | wall 33619
KL Stats: Epoch 98 Divergences: Uniform: 2.8364405284920533 Unigram: 4.185851356372588
2022-02-02 15:27:07 | INFO | fairseq.trainer | begin training epoch 99
2022-02-02 15:27:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:29:26 | INFO | train_inner | epoch 099:     28 / 64 loss=6.024, ppl=65.07, wps=5976.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.744, train_wall=491, gb_free=6.1, wall=33757
2022-02-02 15:32:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:32:50 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.902 | ppl 956.48 | wps 8193.9 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.325
2022-02-02 15:32:50 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-02-02 15:32:50 | INFO | train | epoch 099 | loss 6.018 | ppl 64.8 | wps 6098.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.741 | train_wall 315 | gb_free 6.1 | wall 33961
KL Stats: Epoch 99 Divergences: Uniform: 2.8453106344725048 Unigram: 4.197252955481152
2022-02-02 15:32:50 | INFO | fairseq.trainer | begin training epoch 100
2022-02-02 15:32:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:38:06 | INFO | train_inner | epoch 100:     64 / 64 loss=6.015, ppl=64.66, wps=6273.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.723, train_wall=492, gb_free=6.1, wall=34277
2022-02-02 15:38:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:38:32 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.842 | ppl 917.54 | wps 8266.8 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.325
2022-02-02 15:38:32 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-02-02 15:38:32 | INFO | train | epoch 100 | loss 6 | ppl 64 | wps 6105.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.729 | train_wall 315 | gb_free 6.1 | wall 34303
KL Stats: Epoch 100 Divergences: Uniform: 2.849219010662514 Unigram: 4.212321579429874
2022-02-02 15:38:32 | INFO | fairseq.trainer | begin training epoch 101
2022-02-02 15:38:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:43:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:44:14 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.896 | ppl 952.98 | wps 8199.2 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.325
2022-02-02 15:44:14 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-02-02 15:44:14 | INFO | train | epoch 101 | loss 5.984 | ppl 63.27 | wps 6099.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.736 | train_wall 315 | gb_free 6.1 | wall 34646
KL Stats: Epoch 101 Divergences: Uniform: 2.8561227961852187 Unigram: 4.240270078102854
2022-02-02 15:44:14 | INFO | fairseq.trainer | begin training epoch 102
2022-02-02 15:44:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:47:13 | INFO | train_inner | epoch 102:     36 / 64 loss=5.965, ppl=62.48, wps=5971, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.735, train_wall=493, gb_free=6.1, wall=34824
2022-02-02 15:49:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:49:57 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.927 | ppl 973.19 | wps 8239.9 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.325
2022-02-02 15:49:57 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-02-02 15:49:57 | INFO | train | epoch 102 | loss 5.968 | ppl 62.58 | wps 6100.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.735 | train_wall 315 | gb_free 6.1 | wall 34988
KL Stats: Epoch 102 Divergences: Uniform: 2.8516505580450024 Unigram: 4.250717891357869
2022-02-02 15:49:57 | INFO | fairseq.trainer | begin training epoch 103
2022-02-02 15:49:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:55:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:55:39 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.915 | ppl 965.09 | wps 8214.6 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.325
2022-02-02 15:55:39 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-02-02 15:55:39 | INFO | train | epoch 103 | loss 5.951 | ppl 61.87 | wps 6099.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.752 | train_wall 315 | gb_free 6.1 | wall 35331
KL Stats: Epoch 103 Divergences: Uniform: 2.8623372944418293 Unigram: 4.2733076557391385
2022-02-02 15:55:39 | INFO | fairseq.trainer | begin training epoch 104
2022-02-02 15:55:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:56:19 | INFO | train_inner | epoch 104:      8 / 64 loss=5.962, ppl=62.35, wps=5969.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.75, train_wall=492, gb_free=6.1, wall=35370
2022-02-02 16:00:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:01:22 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.988 | ppl 1015.54 | wps 8258.9 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.325
2022-02-02 16:01:22 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-02-02 16:01:22 | INFO | train | epoch 104 | loss 5.937 | ppl 61.25 | wps 6101.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.78 | train_wall 315 | gb_free 6.1 | wall 35673
KL Stats: Epoch 104 Divergences: Uniform: 2.856834196166044 Unigram: 4.2793785472790296
2022-02-02 16:01:22 | INFO | fairseq.trainer | begin training epoch 105
2022-02-02 16:01:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:04:59 | INFO | train_inner | epoch 105:     44 / 64 loss=5.925, ppl=60.77, wps=6283.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.77, train_wall=492, gb_free=6.1, wall=35890
2022-02-02 16:06:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:07:04 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.939 | ppl 981.76 | wps 8202.4 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.325
2022-02-02 16:07:04 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-02-02 16:07:04 | INFO | train | epoch 105 | loss 5.918 | ppl 60.48 | wps 6102.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.762 | train_wall 315 | gb_free 6.1 | wall 36015
KL Stats: Epoch 105 Divergences: Uniform: 2.8726211146571825 Unigram: 4.298133872532072
2022-02-02 16:07:04 | INFO | fairseq.trainer | begin training epoch 106
2022-02-02 16:07:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:12:46 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 10.001 | ppl 1024.54 | wps 8246.8 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.325
2022-02-02 16:12:46 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-02-02 16:12:46 | INFO | train | epoch 106 | loss 5.901 | ppl 59.74 | wps 6102.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.747 | train_wall 315 | gb_free 6.1 | wall 36357
KL Stats: Epoch 106 Divergences: Uniform: 2.8690910417664277 Unigram: 4.317053416862098
2022-02-02 16:12:46 | INFO | fairseq.trainer | begin training epoch 107
2022-02-02 16:12:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:14:05 | INFO | train_inner | epoch 107:     16 / 64 loss=5.904, ppl=59.88, wps=5968.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.747, train_wall=492, gb_free=6.1, wall=36437
2022-02-02 16:18:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:18:29 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.976 | ppl 1006.78 | wps 8181.5 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.325
2022-02-02 16:18:29 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-02-02 16:18:29 | INFO | train | epoch 107 | loss 5.889 | ppl 59.25 | wps 6098.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.754 | train_wall 315 | gb_free 6.1 | wall 36700
KL Stats: Epoch 107 Divergences: Uniform: 2.877739663553725 Unigram: 4.334230943621395
2022-02-02 16:18:29 | INFO | fairseq.trainer | begin training epoch 108
2022-02-02 16:18:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:22:47 | INFO | train_inner | epoch 108:     52 / 64 loss=5.881, ppl=58.95, wps=6269.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.771, train_wall=493, gb_free=6.1, wall=36958
2022-02-02 16:23:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:24:11 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.946 | ppl 986.62 | wps 8264.4 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.325
2022-02-02 16:24:11 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-02-02 16:24:11 | INFO | train | epoch 108 | loss 5.876 | ppl 58.72 | wps 6095.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.788 | train_wall 315 | gb_free 6.1 | wall 37043
KL Stats: Epoch 108 Divergences: Uniform: 2.882514979010733 Unigram: 4.344837662594825
2022-02-02 16:24:11 | INFO | fairseq.trainer | begin training epoch 109
2022-02-02 16:24:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:29:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:29:54 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.986 | ppl 1014.21 | wps 8208.3 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.325
2022-02-02 16:29:54 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-02-02 16:29:54 | INFO | train | epoch 109 | loss 5.86 | ppl 58.08 | wps 6092.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.783 | train_wall 315 | gb_free 6.1 | wall 37385
KL Stats: Epoch 109 Divergences: Uniform: 2.8819493658003994 Unigram: 4.36831533247452
2022-02-02 16:29:54 | INFO | fairseq.trainer | begin training epoch 110
2022-02-02 16:29:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:31:53 | INFO | train_inner | epoch 110:     24 / 64 loss=5.857, ppl=57.98, wps=5965.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.795, train_wall=492, gb_free=6.1, wall=37504
2022-02-02 16:35:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:35:36 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.016 | ppl 1035.09 | wps 8261.5 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.325
2022-02-02 16:35:36 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-02-02 16:35:36 | INFO | train | epoch 110 | loss 5.845 | ppl 57.47 | wps 6105.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.783 | train_wall 315 | gb_free 6.1 | wall 37727
KL Stats: Epoch 110 Divergences: Uniform: 2.886089502310044 Unigram: 4.377900449318512
2022-02-02 16:35:36 | INFO | fairseq.trainer | begin training epoch 111
2022-02-02 16:35:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:40:33 | INFO | train_inner | epoch 111:     60 / 64 loss=5.842, ppl=57.36, wps=6284.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.801, train_wall=492, gb_free=6.1, wall=38024
2022-02-02 16:40:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:41:18 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.977 | ppl 1007.79 | wps 8207.2 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.325
2022-02-02 16:41:18 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-02-02 16:41:18 | INFO | train | epoch 111 | loss 5.834 | ppl 57.03 | wps 6103.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.823 | train_wall 315 | gb_free 6.1 | wall 38070
KL Stats: Epoch 111 Divergences: Uniform: 2.8915942327954003 Unigram: 4.392114222764016
2022-02-02 16:41:18 | INFO | fairseq.trainer | begin training epoch 112
2022-02-02 16:41:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:46:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:47:00 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.014 | ppl 1033.64 | wps 8242.2 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.325
2022-02-02 16:47:00 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-02-02 16:47:00 | INFO | train | epoch 112 | loss 5.82 | ppl 56.49 | wps 6104.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.799 | train_wall 315 | gb_free 6.1 | wall 38412
KL Stats: Epoch 112 Divergences: Uniform: 2.8971174069102794 Unigram: 4.404480792552272
2022-02-02 16:47:00 | INFO | fairseq.trainer | begin training epoch 113
2022-02-02 16:47:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:49:39 | INFO | train_inner | epoch 113:     32 / 64 loss=5.806, ppl=55.95, wps=5970.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.8, train_wall=491, gb_free=6.1, wall=38570
2022-02-02 16:52:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:52:43 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.032 | ppl 1047.02 | wps 8207.8 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.325
2022-02-02 16:52:43 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-02-02 16:52:43 | INFO | train | epoch 113 | loss 5.806 | ppl 55.93 | wps 6098.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.805 | train_wall 315 | gb_free 6.1 | wall 38754
KL Stats: Epoch 113 Divergences: Uniform: 2.896535503456871 Unigram: 4.429690811616074
2022-02-02 16:52:43 | INFO | fairseq.trainer | begin training epoch 114
2022-02-02 16:52:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:58:25 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 10.013 | ppl 1033.18 | wps 8268.3 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.325
2022-02-02 16:58:25 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-02-02 16:58:25 | INFO | train | epoch 114 | loss 5.791 | ppl 55.37 | wps 6097.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.815 | train_wall 315 | gb_free 6.1 | wall 39097
KL Stats: Epoch 114 Divergences: Uniform: 2.8973791146352457 Unigram: 4.426918457097283
2022-02-02 16:58:25 | INFO | fairseq.trainer | begin training epoch 115
2022-02-02 16:58:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:58:45 | INFO | train_inner | epoch 115:      4 / 64 loss=5.807, ppl=55.99, wps=5966.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.813, train_wall=492, gb_free=6.1, wall=39117
2022-02-02 17:03:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:04:07 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.075 | ppl 1078.46 | wps 8254.2 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.325
2022-02-02 17:04:07 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-02-02 17:04:07 | INFO | train | epoch 115 | loss 5.776 | ppl 54.79 | wps 6116 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.794 | train_wall 314 | gb_free 6.1 | wall 39438
KL Stats: Epoch 115 Divergences: Uniform: 2.9056273546951163 Unigram: 4.452947037515247
2022-02-02 17:04:07 | INFO | fairseq.trainer | begin training epoch 116
2022-02-02 17:04:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:07:25 | INFO | train_inner | epoch 116:     40 / 64 loss=5.758, ppl=54.12, wps=6289.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.799, train_wall=492, gb_free=6.1, wall=39636
2022-02-02 17:09:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:09:49 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.031 | ppl 1046.36 | wps 8268 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.325
2022-02-02 17:09:49 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-02-02 17:09:49 | INFO | train | epoch 116 | loss 5.765 | ppl 54.39 | wps 6111.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.836 | train_wall 314 | gb_free 6.1 | wall 39780
KL Stats: Epoch 116 Divergences: Uniform: 2.9076770322353536 Unigram: 4.465533463519995
2022-02-02 17:09:49 | INFO | fairseq.trainer | begin training epoch 117
2022-02-02 17:09:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:15:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:15:30 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.072 | ppl 1076.7 | wps 8224.2 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.325
2022-02-02 17:15:30 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-02-02 17:15:30 | INFO | train | epoch 117 | loss 5.752 | ppl 53.88 | wps 6114.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.807 | train_wall 314 | gb_free 6.1 | wall 40122
KL Stats: Epoch 117 Divergences: Uniform: 2.9132949593751842 Unigram: 4.479669940032485
2022-02-02 17:15:30 | INFO | fairseq.trainer | begin training epoch 118
2022-02-02 17:15:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:16:30 | INFO | train_inner | epoch 118:     12 / 64 loss=5.764, ppl=54.34, wps=5982.7, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.839, train_wall=490, gb_free=6.1, wall=40181
2022-02-02 17:20:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:21:12 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.023 | ppl 1040.1 | wps 8248.5 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.325
2022-02-02 17:21:12 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-02-02 17:21:12 | INFO | train | epoch 118 | loss 5.741 | ppl 53.5 | wps 6111.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.861 | train_wall 314 | gb_free 6.1 | wall 40463
KL Stats: Epoch 118 Divergences: Uniform: 2.9186590651221347 Unigram: 4.497085767696023
2022-02-02 17:21:12 | INFO | fairseq.trainer | begin training epoch 119
2022-02-02 17:21:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:25:09 | INFO | train_inner | epoch 119:     48 / 64 loss=5.732, ppl=53.16, wps=6292.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.839, train_wall=492, gb_free=6.1, wall=40701
2022-02-02 17:26:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:26:53 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.028 | ppl 1044.33 | wps 8265.7 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.325
2022-02-02 17:26:53 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-02-02 17:26:53 | INFO | train | epoch 119 | loss 5.727 | ppl 52.97 | wps 6118 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.824 | train_wall 314 | gb_free 6.1 | wall 40805
KL Stats: Epoch 119 Divergences: Uniform: 2.9196864554366693 Unigram: 4.506153137589687
2022-02-02 17:26:53 | INFO | fairseq.trainer | begin training epoch 120
2022-02-02 17:26:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:32:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:32:36 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.051 | ppl 1060.97 | wps 8298.1 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.325
2022-02-02 17:32:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-02-02 17:32:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint120.pt
2022-02-02 17:32:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint120.pt
2022-02-02 17:32:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.051) (writing took 3.4623693767935038 seconds)
2022-02-02 17:32:39 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-02-02 17:32:39 | INFO | train | epoch 120 | loss 5.717 | ppl 52.61 | wps 6035.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.847 | train_wall 315 | gb_free 6.1 | wall 41151
KL Stats: Epoch 120 Divergences: Uniform: 2.9264754437363205 Unigram: 4.522391925004128
2022-02-02 17:32:39 | INFO | fairseq.trainer | begin training epoch 121
2022-02-02 17:32:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:34:18 | INFO | train_inner | epoch 121:     20 / 64 loss=5.712, ppl=52.43, wps=5935.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.842, train_wall=492, gb_free=6.1, wall=41250
2022-02-02 17:37:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:38:21 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.089 | ppl 1089.33 | wps 8247.7 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.325
2022-02-02 17:38:21 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-02-02 17:38:21 | INFO | train | epoch 121 | loss 5.706 | ppl 52.2 | wps 6111.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.869 | train_wall 314 | gb_free 6.1 | wall 41493
KL Stats: Epoch 121 Divergences: Uniform: 2.922603674057691 Unigram: 4.524405731077571
2022-02-02 17:38:21 | INFO | fairseq.trainer | begin training epoch 122
2022-02-02 17:38:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:42:59 | INFO | train_inner | epoch 122:     56 / 64 loss=5.707, ppl=52.23, wps=6274.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.864, train_wall=493, gb_free=6.1, wall=41771
2022-02-02 17:43:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:44:04 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.101 | ppl 1098.23 | wps 8234 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.325
2022-02-02 17:44:04 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-02-02 17:44:04 | INFO | train | epoch 122 | loss 5.693 | ppl 51.75 | wps 6090.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.849 | train_wall 316 | gb_free 6.1 | wall 41835
KL Stats: Epoch 122 Divergences: Uniform: 2.923510015143112 Unigram: 4.537110654184991
2022-02-02 17:44:04 | INFO | fairseq.trainer | begin training epoch 123
2022-02-02 17:44:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:49:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:49:47 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.077 | ppl 1080.16 | wps 8255.9 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.325
2022-02-02 17:49:47 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-02-02 17:49:47 | INFO | train | epoch 123 | loss 5.682 | ppl 51.32 | wps 6099.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.879 | train_wall 315 | gb_free 6.1 | wall 42178
KL Stats: Epoch 123 Divergences: Uniform: 2.928393085427248 Unigram: 4.559291313660711
2022-02-02 17:49:47 | INFO | fairseq.trainer | begin training epoch 124
2022-02-02 17:49:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:52:06 | INFO | train_inner | epoch 124:     28 / 64 loss=5.672, ppl=50.99, wps=5966, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.881, train_wall=492, gb_free=6.1, wall=42317
2022-02-02 17:55:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:55:30 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.058 | ppl 1065.81 | wps 8238.7 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.325
2022-02-02 17:55:30 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-02-02 17:55:30 | INFO | train | epoch 124 | loss 5.672 | ppl 51 | wps 6088.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.89 | train_wall 316 | gb_free 6.1 | wall 42521
KL Stats: Epoch 124 Divergences: Uniform: 2.9346957877642095 Unigram: 4.566921869278801
2022-02-02 17:55:30 | INFO | fairseq.trainer | begin training epoch 125
2022-02-02 17:55:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:00:45 | INFO | train_inner | epoch 125:     64 / 64 loss=5.675, ppl=51.1, wps=6277.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.878, train_wall=492, gb_free=6.1, wall=42836
2022-02-02 18:00:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:01:12 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.113 | ppl 1107.09 | wps 8238.9 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.325
2022-02-02 18:01:12 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-02-02 18:01:12 | INFO | train | epoch 125 | loss 5.659 | ppl 50.54 | wps 6109.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.877 | train_wall 315 | gb_free 6.1 | wall 42863
KL Stats: Epoch 125 Divergences: Uniform: 2.9398217438275793 Unigram: 4.591985915429953
2022-02-02 18:01:12 | INFO | fairseq.trainer | begin training epoch 126
2022-02-02 18:01:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:06:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:06:55 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.169 | ppl 1151.39 | wps 8246.1 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.325
2022-02-02 18:06:55 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-02-02 18:06:55 | INFO | train | epoch 126 | loss 5.65 | ppl 50.21 | wps 6086.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.886 | train_wall 316 | gb_free 6.1 | wall 43206
KL Stats: Epoch 126 Divergences: Uniform: 2.9338872606257995 Unigram: 4.594314254764129
2022-02-02 18:06:55 | INFO | fairseq.trainer | begin training epoch 127
2022-02-02 18:06:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:09:53 | INFO | train_inner | epoch 127:     36 / 64 loss=5.637, ppl=49.76, wps=5964.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.883, train_wall=493, gb_free=6.1, wall=43384
2022-02-02 18:12:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:12:37 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.163 | ppl 1146.72 | wps 8247.4 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.325
2022-02-02 18:12:37 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-02-02 18:12:37 | INFO | train | epoch 127 | loss 5.639 | ppl 49.84 | wps 6105.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.881 | train_wall 315 | gb_free 6.1 | wall 43548
KL Stats: Epoch 127 Divergences: Uniform: 2.9352636369027088 Unigram: 4.604639391342482
2022-02-02 18:12:37 | INFO | fairseq.trainer | begin training epoch 128
2022-02-02 18:12:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:17:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:18:19 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.183 | ppl 1162.43 | wps 8290.7 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.325
2022-02-02 18:18:19 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-02-02 18:18:19 | INFO | train | epoch 128 | loss 5.627 | ppl 49.42 | wps 6097.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.885 | train_wall 315 | gb_free 6.1 | wall 43891
KL Stats: Epoch 128 Divergences: Uniform: 2.938418195346065 Unigram: 4.6133074635566205
2022-02-02 18:18:19 | INFO | fairseq.trainer | begin training epoch 129
2022-02-02 18:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:18:59 | INFO | train_inner | epoch 129:      8 / 64 loss=5.633, ppl=49.62, wps=5971, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.886, train_wall=492, gb_free=6.1, wall=43930
2022-02-02 18:23:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:24:00 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.215 | ppl 1188.57 | wps 8271.1 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.325
2022-02-02 18:24:00 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-02-02 18:24:00 | INFO | train | epoch 129 | loss 5.619 | ppl 49.14 | wps 6124.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.899 | train_wall 314 | gb_free 6.1 | wall 44232
KL Stats: Epoch 129 Divergences: Uniform: 2.940482208583813 Unigram: 4.635216887347496
2022-02-02 18:24:00 | INFO | fairseq.trainer | begin training epoch 130
2022-02-02 18:24:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:27:38 | INFO | train_inner | epoch 130:     44 / 64 loss=5.611, ppl=48.88, wps=6293.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.895, train_wall=492, gb_free=6.1, wall=44449
2022-02-02 18:29:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:29:42 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.159 | ppl 1143.13 | wps 8284.3 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.325
2022-02-02 18:29:42 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-02-02 18:29:42 | INFO | train | epoch 130 | loss 5.607 | ppl 48.74 | wps 6112.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.888 | train_wall 314 | gb_free 6.1 | wall 44573
KL Stats: Epoch 130 Divergences: Uniform: 2.9468856147803364 Unigram: 4.6456935927437195
2022-02-02 18:29:42 | INFO | fairseq.trainer | begin training epoch 131
2022-02-02 18:29:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:34:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:35:23 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.179 | ppl 1159.08 | wps 8227.3 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.325
2022-02-02 18:35:23 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-02-02 18:35:23 | INFO | train | epoch 131 | loss 5.599 | ppl 48.48 | wps 6120.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.91 | train_wall 314 | gb_free 6.1 | wall 44915
KL Stats: Epoch 131 Divergences: Uniform: 2.945122846644876 Unigram: 4.655235563973242
2022-02-02 18:35:23 | INFO | fairseq.trainer | begin training epoch 132
2022-02-02 18:35:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:36:43 | INFO | train_inner | epoch 132:     16 / 64 loss=5.6, ppl=48.49, wps=5987.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.897, train_wall=490, gb_free=6.1, wall=44994
2022-02-02 18:40:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:41:05 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.234 | ppl 1204.59 | wps 8289.5 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.325
2022-02-02 18:41:05 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-02-02 18:41:05 | INFO | train | epoch 132 | loss 5.588 | ppl 48.11 | wps 6108.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.895 | train_wall 315 | gb_free 6.1 | wall 45257
KL Stats: Epoch 132 Divergences: Uniform: 2.9473864282971216 Unigram: 4.673746957706971
2022-02-02 18:41:05 | INFO | fairseq.trainer | begin training epoch 133
2022-02-02 18:41:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:45:22 | INFO | train_inner | epoch 133:     52 / 64 loss=5.587, ppl=48.05, wps=6287.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.93, train_wall=492, gb_free=6.1, wall=45514
2022-02-02 18:46:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:46:47 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.18 | ppl 1159.87 | wps 8265.2 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.325
2022-02-02 18:46:47 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-02-02 18:46:47 | INFO | train | epoch 133 | loss 5.58 | ppl 47.85 | wps 6113.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.945 | train_wall 314 | gb_free 6.1 | wall 45598
KL Stats: Epoch 133 Divergences: Uniform: 2.954297889247239 Unigram: 4.674293139221083
2022-02-02 18:46:47 | INFO | fairseq.trainer | begin training epoch 134
2022-02-02 18:46:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:52:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:52:29 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.275 | ppl 1239.08 | wps 8269.8 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.325
2022-02-02 18:52:29 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-02-02 18:52:29 | INFO | train | epoch 134 | loss 5.571 | ppl 47.53 | wps 6104.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.933 | train_wall 315 | gb_free 6.1 | wall 45940
KL Stats: Epoch 134 Divergences: Uniform: 2.9571534077220636 Unigram: 4.689976019802169
2022-02-02 18:52:29 | INFO | fairseq.trainer | begin training epoch 135
2022-02-02 18:52:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:54:28 | INFO | train_inner | epoch 135:     24 / 64 loss=5.565, ppl=47.33, wps=5980.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.94, train_wall=491, gb_free=6.1, wall=46059
2022-02-02 18:57:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:58:10 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.273 | ppl 1237.15 | wps 8265.2 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.325
2022-02-02 18:58:10 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-02-02 18:58:10 | INFO | train | epoch 135 | loss 5.56 | ppl 47.19 | wps 6124.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.938 | train_wall 314 | gb_free 6.1 | wall 46281
KL Stats: Epoch 135 Divergences: Uniform: 2.954108773577335 Unigram: 4.700535483430134
2022-02-02 18:58:10 | INFO | fairseq.trainer | begin training epoch 136
2022-02-02 18:58:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:03:07 | INFO | train_inner | epoch 136:     60 / 64 loss=5.561, ppl=47.22, wps=6291.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.922, train_wall=492, gb_free=6.1, wall=46578
2022-02-02 19:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:03:52 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.211 | ppl 1185.32 | wps 8295.8 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.325
2022-02-02 19:03:52 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-02-02 19:03:52 | INFO | train | epoch 136 | loss 5.551 | ppl 46.87 | wps 6110.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.929 | train_wall 315 | gb_free 6.1 | wall 46623
KL Stats: Epoch 136 Divergences: Uniform: 2.9583736693546925 Unigram: 4.715315744287429
2022-02-02 19:03:52 | INFO | fairseq.trainer | begin training epoch 137
2022-02-02 19:03:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:09:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:09:33 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.211 | ppl 1185.52 | wps 8265.1 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.325
2022-02-02 19:09:33 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-02-02 19:09:33 | INFO | train | epoch 137 | loss 5.542 | ppl 46.6 | wps 6122.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.961 | train_wall 314 | gb_free 6.1 | wall 46964
KL Stats: Epoch 137 Divergences: Uniform: 2.965291977775293 Unigram: 4.723862960822203
2022-02-02 19:09:33 | INFO | fairseq.trainer | begin training epoch 138
2022-02-02 19:09:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:12:11 | INFO | train_inner | epoch 138:     32 / 64 loss=5.532, ppl=46.27, wps=5987.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.958, train_wall=490, gb_free=6.1, wall=47123
2022-02-02 19:14:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:15:15 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.235 | ppl 1205.54 | wps 8272.5 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.325
2022-02-02 19:15:15 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-02-02 19:15:15 | INFO | train | epoch 138 | loss 5.534 | ppl 46.33 | wps 6107.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.952 | train_wall 315 | gb_free 6.1 | wall 47306
KL Stats: Epoch 138 Divergences: Uniform: 2.969943048897924 Unigram: 4.744684383173916
2022-02-02 19:15:15 | INFO | fairseq.trainer | begin training epoch 139
2022-02-02 19:15:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:20:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:20:59 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.217 | ppl 1190.11 | wps 8101.7 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.325
2022-02-02 19:20:59 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-02-02 19:20:59 | INFO | train | epoch 139 | loss 5.524 | ppl 46.03 | wps 6073.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.959 | train_wall 316 | gb_free 6.1 | wall 47650
KL Stats: Epoch 139 Divergences: Uniform: 2.969104550332426 Unigram: 4.746280792920366
2022-02-02 19:20:59 | INFO | fairseq.trainer | begin training epoch 140
2022-02-02 19:20:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:21:19 | INFO | train_inner | epoch 140:      4 / 64 loss=5.535, ppl=46.35, wps=5954.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.957, train_wall=493, gb_free=6.1, wall=47670
2022-02-02 19:26:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:26:44 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.217 | ppl 1189.82 | wps 8143.7 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.325
2022-02-02 19:26:44 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-02-02 19:26:44 | INFO | train | epoch 140 | loss 5.517 | ppl 45.78 | wps 6051.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.97 | train_wall 317 | gb_free 6.1 | wall 47995
KL Stats: Epoch 140 Divergences: Uniform: 2.9692134416955236 Unigram: 4.749566857887807
2022-02-02 19:26:44 | INFO | fairseq.trainer | begin training epoch 141
2022-02-02 19:26:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:30:03 | INFO | train_inner | epoch 141:     40 / 64 loss=5.505, ppl=45.41, wps=6230.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.961, train_wall=496, gb_free=6.1, wall=48195
2022-02-02 19:32:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:32:28 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.328 | ppl 1285.78 | wps 8174.3 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.325
2022-02-02 19:32:28 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-02-02 19:32:28 | INFO | train | epoch 141 | loss 5.506 | ppl 45.45 | wps 6064.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.963 | train_wall 317 | gb_free 6.1 | wall 48340
KL Stats: Epoch 141 Divergences: Uniform: 2.965818023343008 Unigram: 4.76474288808363
2022-02-02 19:32:28 | INFO | fairseq.trainer | begin training epoch 142
2022-02-02 19:32:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:37:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:38:13 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.304 | ppl 1264.43 | wps 8190.8 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.325
2022-02-02 19:38:13 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-02-02 19:38:13 | INFO | train | epoch 142 | loss 5.497 | ppl 45.17 | wps 6053.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.959 | train_wall 318 | gb_free 6.1 | wall 48685
KL Stats: Epoch 142 Divergences: Uniform: 2.968152170439482 Unigram: 4.773468081706691
2022-02-02 19:38:13 | INFO | fairseq.trainer | begin training epoch 143
2022-02-02 19:38:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:39:13 | INFO | train_inner | epoch 143:     12 / 64 loss=5.5, ppl=45.26, wps=5928.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.975, train_wall=495, gb_free=6.1, wall=48745
2022-02-02 19:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:43:57 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.256 | ppl 1222.88 | wps 8143.3 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.325
2022-02-02 19:43:57 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-02-02 19:43:57 | INFO | train | epoch 143 | loss 5.491 | ppl 44.97 | wps 6071.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.98 | train_wall 316 | gb_free 6.1 | wall 49029
KL Stats: Epoch 143 Divergences: Uniform: 2.9713452894106687 Unigram: 4.785400443324712
2022-02-02 19:43:57 | INFO | fairseq.trainer | begin training epoch 144
2022-02-02 19:43:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:47:57 | INFO | train_inner | epoch 144:     48 / 64 loss=5.49, ppl=44.93, wps=6240, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.977, train_wall=496, gb_free=6.1, wall=49268
2022-02-02 19:49:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:49:43 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.247 | ppl 1215.14 | wps 8189.2 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.325
2022-02-02 19:49:43 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-02-02 19:49:43 | INFO | train | epoch 144 | loss 5.484 | ppl 44.75 | wps 6050.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 1.011 | train_wall 318 | gb_free 6.1 | wall 49374
KL Stats: Epoch 144 Divergences: Uniform: 2.9771137000505945 Unigram: 4.795061206902285
2022-02-02 19:49:43 | INFO | fairseq.trainer | begin training epoch 145
2022-02-02 19:49:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:55:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:55:27 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.257 | ppl 1223.54 | wps 8153.5 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.325
2022-02-02 19:55:27 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-02-02 19:55:27 | INFO | train | epoch 145 | loss 5.475 | ppl 44.47 | wps 6062.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.993 | train_wall 317 | gb_free 6.1 | wall 49719
KL Stats: Epoch 145 Divergences: Uniform: 2.975490946903051 Unigram: 4.804163357124718
2022-02-02 19:55:27 | INFO | fairseq.trainer | begin training epoch 146
2022-02-02 19:55:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:57:07 | INFO | train_inner | epoch 146:     20 / 64 loss=5.476, ppl=44.51, wps=5928.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=1.016, train_wall=495, gb_free=6.1, wall=49818
2022-02-02 20:00:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:01:13 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.275 | ppl 1239.05 | wps 8166.6 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.325
2022-02-02 20:01:13 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-02-02 20:01:13 | INFO | train | epoch 146 | loss 5.469 | ppl 44.3 | wps 6041 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 1.031 | train_wall 318 | gb_free 6.1 | wall 50064
KL Stats: Epoch 146 Divergences: Uniform: 2.9735664583765766 Unigram: 4.812657376580169
2022-02-02 20:01:13 | INFO | fairseq.trainer | begin training epoch 147
2022-02-02 20:01:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:05:53 | INFO | train_inner | epoch 147:     56 / 64 loss=5.465, ppl=44.17, wps=6217.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=1.003, train_wall=498, gb_free=6.1, wall=50344
2022-02-02 20:06:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:06:58 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.263 | ppl 1228.94 | wps 8186.1 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.325
2022-02-02 20:06:58 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-02-02 20:06:58 | INFO | train | epoch 147 | loss 5.457 | ppl 43.93 | wps 6052.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.985 | train_wall 318 | gb_free 6.1 | wall 50409
KL Stats: Epoch 147 Divergences: Uniform: 2.984096874092295 Unigram: 4.829443004784244
2022-02-02 20:06:58 | INFO | fairseq.trainer | begin training epoch 148
2022-02-02 20:06:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:12:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:12:43 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.361 | ppl 1315.59 | wps 8123.8 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.325
2022-02-02 20:12:43 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-02-02 20:12:43 | INFO | train | epoch 148 | loss 5.451 | ppl 43.74 | wps 6058.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 1.028 | train_wall 317 | gb_free 6.1 | wall 50754
KL Stats: Epoch 148 Divergences: Uniform: 2.9827513519097475 Unigram: 4.838625787683344
2022-02-02 20:12:43 | INFO | fairseq.trainer | begin training epoch 149
2022-02-02 20:12:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:15:02 | INFO | train_inner | epoch 149:     28 / 64 loss=5.439, ppl=43.38, wps=5930.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=1.029, train_wall=495, gb_free=6.1, wall=50894
2022-02-02 20:18:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:18:27 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.359 | ppl 1313.55 | wps 8191.4 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.325
2022-02-02 20:18:27 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-02-02 20:18:27 | INFO | train | epoch 149 | loss 5.444 | ppl 43.53 | wps 6067.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 1.033 | train_wall 317 | gb_free 6.1 | wall 51098
KL Stats: Epoch 149 Divergences: Uniform: 2.977014680359557 Unigram: 4.841692643011087
2022-02-02 20:18:27 | INFO | fairseq.trainer | begin training epoch 150
2022-02-02 20:18:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:23:45 | INFO | train_inner | epoch 150:     64 / 64 loss=5.453, ppl=43.81, wps=6234.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=1.045, train_wall=495, gb_free=6.1, wall=51416
2022-02-02 20:23:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:24:12 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.308 | ppl 1267.73 | wps 8191.8 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.325
2022-02-02 20:24:12 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-02-02 20:24:12 | INFO | train | epoch 150 | loss 5.436 | ppl 43.3 | wps 6057.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 1.055 | train_wall 317 | gb_free 6.1 | wall 51443
KL Stats: Epoch 150 Divergences: Uniform: 2.984637712300009 Unigram: 4.855378830745069
2022-02-02 20:24:12 | INFO | fairseq.trainer | begin training epoch 151
2022-02-02 20:24:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:29:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:29:57 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.394 | ppl 1345.46 | wps 8171.4 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.325
2022-02-02 20:29:57 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-02-02 20:29:57 | INFO | train | epoch 151 | loss 5.429 | ppl 43.07 | wps 6050.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 1.02 | train_wall 318 | gb_free 6.1 | wall 51788
KL Stats: Epoch 151 Divergences: Uniform: 2.9802864021160738 Unigram: 4.871661681891863
2022-02-02 20:29:57 | INFO | fairseq.trainer | begin training epoch 152
2022-02-02 20:29:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:32:57 | INFO | train_inner | epoch 152:     36 / 64 loss=5.417, ppl=42.72, wps=5925.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=1.033, train_wall=497, gb_free=6.1, wall=51968
2022-02-02 20:35:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:35:43 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.335 | ppl 1291.59 | wps 8093.1 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.325
2022-02-02 20:35:43 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-02-02 20:35:43 | INFO | train | epoch 152 | loss 5.422 | ppl 42.86 | wps 6044.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.074 | train_wall 318 | gb_free 6.1 | wall 52134
KL Stats: Epoch 152 Divergences: Uniform: 2.9785378242777125 Unigram: 4.869113748146596
2022-02-02 20:35:43 | INFO | fairseq.trainer | begin training epoch 153
2022-02-02 20:35:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:41:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:41:28 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.328 | ppl 1285.2 | wps 8135.6 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.325
2022-02-02 20:41:28 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-02 20:41:28 | INFO | train | epoch 153 | loss 5.415 | ppl 42.65 | wps 6047.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 1.055 | train_wall 318 | gb_free 6.1 | wall 52479
KL Stats: Epoch 153 Divergences: Uniform: 2.9880313658470903 Unigram: 4.8841273356055455
2022-02-02 20:41:28 | INFO | fairseq.trainer | begin training epoch 154
2022-02-02 20:41:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:42:08 | INFO | train_inner | epoch 154:      8 / 64 loss=5.421, ppl=42.84, wps=5916.3, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=1.066, train_wall=496, gb_free=6.1, wall=52519
2022-02-02 20:46:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:47:13 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.31 | ppl 1269.55 | wps 8107.7 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.325
2022-02-02 20:47:13 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-02 20:47:13 | INFO | train | epoch 154 | loss 5.407 | ppl 42.43 | wps 6045.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.068 | train_wall 318 | gb_free 6.1 | wall 52825
KL Stats: Epoch 154 Divergences: Uniform: 2.991464151364668 Unigram: 4.896042270338699
2022-02-02 20:47:13 | INFO | fairseq.trainer | begin training epoch 155
2022-02-02 20:47:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:50:53 | INFO | train_inner | epoch 155:     44 / 64 loss=5.401, ppl=42.25, wps=6220.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=1.062, train_wall=497, gb_free=6.1, wall=53044
2022-02-02 20:52:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:52:58 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.298 | ppl 1258.78 | wps 8201.5 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.325
2022-02-02 20:52:58 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-02 20:52:58 | INFO | train | epoch 155 | loss 5.398 | ppl 42.18 | wps 6059.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.058 | train_wall 317 | gb_free 6.1 | wall 53169
KL Stats: Epoch 155 Divergences: Uniform: 2.992051317170097 Unigram: 4.903735779890525
2022-02-02 20:52:58 | INFO | fairseq.trainer | begin training epoch 156
2022-02-02 20:52:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:58:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:58:43 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.283 | ppl 1245.57 | wps 8111.3 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.325
2022-02-02 20:58:43 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-02 20:58:43 | INFO | train | epoch 156 | loss 5.391 | ppl 41.97 | wps 6051.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.06 | train_wall 317 | gb_free 6.1 | wall 53515
KL Stats: Epoch 156 Divergences: Uniform: 2.997486094818928 Unigram: 4.9140775217461785
2022-02-02 20:58:43 | INFO | fairseq.trainer | begin training epoch 157
2022-02-02 20:58:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:00:03 | INFO | train_inner | epoch 157:     16 / 64 loss=5.393, ppl=42.01, wps=5925.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.076, train_wall=495, gb_free=6.1, wall=53595
2022-02-02 21:04:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:04:28 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.347 | ppl 1302.06 | wps 8169.8 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.325
2022-02-02 21:04:28 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-02 21:04:28 | INFO | train | epoch 157 | loss 5.386 | ppl 41.81 | wps 6060.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.085 | train_wall 317 | gb_free 6.1 | wall 53859
KL Stats: Epoch 157 Divergences: Uniform: 2.99841719185888 Unigram: 4.928338614242425
2022-02-02 21:04:28 | INFO | fairseq.trainer | begin training epoch 158
2022-02-02 21:04:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:08:48 | INFO | train_inner | epoch 158:     52 / 64 loss=5.385, ppl=41.8, wps=6229.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.091, train_wall=497, gb_free=6.1, wall=54119
2022-02-02 21:09:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:10:13 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.401 | ppl 1351.83 | wps 8097.3 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.325
2022-02-02 21:10:13 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-02 21:10:13 | INFO | train | epoch 158 | loss 5.381 | ppl 41.68 | wps 6046.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.112 | train_wall 318 | gb_free 6.1 | wall 54205
KL Stats: Epoch 158 Divergences: Uniform: 2.9986060110135337 Unigram: 4.934787185997419
2022-02-02 21:10:13 | INFO | fairseq.trainer | begin training epoch 159
2022-02-02 21:10:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:15:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:15:58 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.383 | ppl 1335.77 | wps 8182.7 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.325
2022-02-02 21:15:58 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-02 21:15:58 | INFO | train | epoch 159 | loss 5.373 | ppl 41.44 | wps 6065.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.099 | train_wall 317 | gb_free 6.1 | wall 54549
KL Stats: Epoch 159 Divergences: Uniform: 2.9982294471222612 Unigram: 4.94655855634294
2022-02-02 21:15:58 | INFO | fairseq.trainer | begin training epoch 160
2022-02-02 21:15:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:17:57 | INFO | train_inner | epoch 160:     24 / 64 loss=5.369, ppl=41.31, wps=5930.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.094, train_wall=495, gb_free=6.1, wall=54669
2022-02-02 21:21:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:21:43 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.367 | ppl 1320.71 | wps 8092.9 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.325
2022-02-02 21:21:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-02 21:21:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint160.pt
2022-02-02 21:21:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint160.pt
2022-02-02 21:21:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.367) (writing took 3.5974475368857384 seconds)
2022-02-02 21:21:47 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-02 21:21:47 | INFO | train | epoch 160 | loss 5.366 | ppl 41.25 | wps 5981 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.109 | train_wall 318 | gb_free 6.1 | wall 54898
KL Stats: Epoch 160 Divergences: Uniform: 3.0016094495389813 Unigram: 4.946597917525439
2022-02-02 21:21:47 | INFO | fairseq.trainer | begin training epoch 161
2022-02-02 21:21:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:26:46 | INFO | train_inner | epoch 161:     60 / 64 loss=5.366, ppl=41.25, wps=6179.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.104, train_wall=497, gb_free=6.1, wall=55198
2022-02-02 21:27:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:27:32 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.382 | ppl 1334.24 | wps 8191.4 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.325
2022-02-02 21:27:32 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-02 21:27:32 | INFO | train | epoch 161 | loss 5.359 | ppl 41.05 | wps 6056 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.087 | train_wall 317 | gb_free 6.1 | wall 55243
KL Stats: Epoch 161 Divergences: Uniform: 2.998958399599518 Unigram: 4.964729108442162
2022-02-02 21:27:32 | INFO | fairseq.trainer | begin training epoch 162
2022-02-02 21:27:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:32:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:33:17 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.364 | ppl 1318.09 | wps 8131.4 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.325
2022-02-02 21:33:17 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-02 21:33:17 | INFO | train | epoch 162 | loss 5.354 | ppl 40.91 | wps 6051.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.131 | train_wall 317 | gb_free 6.1 | wall 55588
KL Stats: Epoch 162 Divergences: Uniform: 3.0065216749337744 Unigram: 4.97643188196344
2022-02-02 21:33:17 | INFO | fairseq.trainer | begin training epoch 163
2022-02-02 21:33:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:35:57 | INFO | train_inner | epoch 163:     32 / 64 loss=5.347, ppl=40.69, wps=5924.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.128, train_wall=495, gb_free=6.1, wall=55748
2022-02-02 21:38:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:39:01 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.389 | ppl 1340.49 | wps 8172.7 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.325
2022-02-02 21:39:01 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-02 21:39:01 | INFO | train | epoch 163 | loss 5.346 | ppl 40.68 | wps 6064 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.134 | train_wall 317 | gb_free 6.1 | wall 55933
KL Stats: Epoch 163 Divergences: Uniform: 3.0120064682077947 Unigram: 4.980674184908404
2022-02-02 21:39:01 | INFO | fairseq.trainer | begin training epoch 164
2022-02-02 21:39:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:44:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:44:46 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.358 | ppl 1312.17 | wps 8117.2 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.325
2022-02-02 21:44:46 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-02 21:44:46 | INFO | train | epoch 164 | loss 5.341 | ppl 40.54 | wps 6058.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.148 | train_wall 317 | gb_free 6.1 | wall 56277
KL Stats: Epoch 164 Divergences: Uniform: 3.0115298319011066 Unigram: 4.987937344374574
2022-02-02 21:44:46 | INFO | fairseq.trainer | begin training epoch 165
2022-02-02 21:44:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:45:06 | INFO | train_inner | epoch 165:      4 / 64 loss=5.348, ppl=40.74, wps=5931.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.143, train_wall=495, gb_free=6.1, wall=56297
2022-02-02 21:50:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:50:31 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.387 | ppl 1338.63 | wps 8233.9 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.325
2022-02-02 21:50:31 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-02 21:50:31 | INFO | train | epoch 165 | loss 5.334 | ppl 40.33 | wps 6063.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.124 | train_wall 317 | gb_free 6.1 | wall 56622
KL Stats: Epoch 165 Divergences: Uniform: 3.008434692383659 Unigram: 4.99557725133443
2022-02-02 21:50:31 | INFO | fairseq.trainer | begin training epoch 166
2022-02-02 21:50:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:53:50 | INFO | train_inner | epoch 166:     40 / 64 loss=5.326, ppl=40.1, wps=6236.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.126, train_wall=496, gb_free=6.1, wall=56822
2022-02-02 21:55:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:56:16 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.46 | ppl 1408.22 | wps 8150.2 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.325
2022-02-02 21:56:16 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-02 21:56:16 | INFO | train | epoch 166 | loss 5.327 | ppl 40.15 | wps 6047.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.129 | train_wall 318 | gb_free 6.1 | wall 56967
KL Stats: Epoch 166 Divergences: Uniform: 3.0099963314312066 Unigram: 5.00659566744666
2022-02-02 21:56:16 | INFO | fairseq.trainer | begin training epoch 167
2022-02-02 21:56:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:01:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:02:00 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.386 | ppl 1338.11 | wps 8193.5 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.325
2022-02-02 22:02:00 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-02 22:02:00 | INFO | train | epoch 167 | loss 5.324 | ppl 40.07 | wps 6066.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.204 | train_wall 317 | gb_free 6.1 | wall 57312
KL Stats: Epoch 167 Divergences: Uniform: 3.012635891457637 Unigram: 5.012347350266579
2022-02-02 22:02:00 | INFO | fairseq.trainer | begin training epoch 168
2022-02-02 22:02:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:03:00 | INFO | train_inner | epoch 168:     12 / 64 loss=5.325, ppl=40.08, wps=5929.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.176, train_wall=495, gb_free=6.1, wall=57371
2022-02-02 22:07:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:07:45 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.391 | ppl 1342.8 | wps 8144.2 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.325
2022-02-02 22:07:45 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-02 22:07:45 | INFO | train | epoch 168 | loss 5.316 | ppl 39.83 | wps 6056.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.141 | train_wall 317 | gb_free 6.1 | wall 57656
KL Stats: Epoch 168 Divergences: Uniform: 3.0152981998758532 Unigram: 5.0185254571493925
2022-02-02 22:07:45 | INFO | fairseq.trainer | begin training epoch 169
2022-02-02 22:07:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:11:45 | INFO | train_inner | epoch 169:     48 / 64 loss=5.314, ppl=39.77, wps=6229.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.162, train_wall=496, gb_free=6.1, wall=57896
2022-02-02 22:13:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:13:30 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.441 | ppl 1390.03 | wps 8129.4 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.325
2022-02-02 22:13:30 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-02 22:13:30 | INFO | train | epoch 169 | loss 5.311 | ppl 39.69 | wps 6058.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.187 | train_wall 317 | gb_free 6.1 | wall 58001
KL Stats: Epoch 169 Divergences: Uniform: 3.0101963228191 Unigram: 5.030980280754675
2022-02-02 22:13:30 | INFO | fairseq.trainer | begin training epoch 170
2022-02-02 22:13:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:19:14 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.476 | ppl 1424.74 | wps 8124.6 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.325
2022-02-02 22:19:14 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-02 22:19:14 | INFO | train | epoch 170 | loss 5.305 | ppl 39.54 | wps 6060.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.182 | train_wall 317 | gb_free 6.1 | wall 58346
KL Stats: Epoch 170 Divergences: Uniform: 3.0098921978574196 Unigram: 5.036731626000131
2022-02-02 22:19:14 | INFO | fairseq.trainer | begin training epoch 171
2022-02-02 22:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:20:54 | INFO | train_inner | epoch 171:     20 / 64 loss=5.307, ppl=39.58, wps=5930.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.183, train_wall=495, gb_free=6.1, wall=58446
2022-02-02 22:24:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:24:59 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.471 | ppl 1418.9 | wps 8189.1 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.325
2022-02-02 22:24:59 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-02 22:24:59 | INFO | train | epoch 171 | loss 5.3 | ppl 39.41 | wps 6065.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.183 | train_wall 317 | gb_free 6.1 | wall 58690
KL Stats: Epoch 171 Divergences: Uniform: 3.0103531986461762 Unigram: 5.045309006665159
2022-02-02 22:24:59 | INFO | fairseq.trainer | begin training epoch 172
2022-02-02 22:24:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:29:38 | INFO | train_inner | epoch 172:     56 / 64 loss=5.296, ppl=39.29, wps=6245.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.198, train_wall=495, gb_free=6.1, wall=58969
2022-02-02 22:30:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:30:43 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.5 | ppl 1447.91 | wps 8161.8 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.325
2022-02-02 22:30:43 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-02 22:30:43 | INFO | train | epoch 172 | loss 5.295 | ppl 39.25 | wps 6065.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.209 | train_wall 317 | gb_free 6.1 | wall 59034
KL Stats: Epoch 172 Divergences: Uniform: 3.0133154088531238 Unigram: 5.053204671044483
2022-02-02 22:30:43 | INFO | fairseq.trainer | begin training epoch 173
2022-02-02 22:30:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:36:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:36:28 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.497 | ppl 1445.51 | wps 8097.8 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.325
2022-02-02 22:36:28 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-02 22:36:28 | INFO | train | epoch 173 | loss 5.286 | ppl 39.03 | wps 6055 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.174 | train_wall 317 | gb_free 6.1 | wall 59379
KL Stats: Epoch 173 Divergences: Uniform: 3.017085327659773 Unigram: 5.054778782251513
2022-02-02 22:36:28 | INFO | fairseq.trainer | begin training epoch 174
2022-02-02 22:36:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:38:48 | INFO | train_inner | epoch 174:     28 / 64 loss=5.282, ppl=38.92, wps=5925.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.202, train_wall=495, gb_free=6.1, wall=59519
2022-02-02 22:41:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:42:13 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.499 | ppl 1447.64 | wps 8111.3 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.325
2022-02-02 22:42:13 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-02 22:42:13 | INFO | train | epoch 174 | loss 5.284 | ppl 38.97 | wps 6050.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.241 | train_wall 317 | gb_free 6.1 | wall 59725
KL Stats: Epoch 174 Divergences: Uniform: 3.0147064791432605 Unigram: 5.061365855623762
2022-02-02 22:42:13 | INFO | fairseq.trainer | begin training epoch 175
2022-02-02 22:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:47:32 | INFO | train_inner | epoch 175:     64 / 64 loss=5.29, ppl=39.12, wps=6218, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.223, train_wall=496, gb_free=6.1, wall=60043
2022-02-02 22:47:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:47:59 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.499 | ppl 1447.45 | wps 8159.3 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.325
2022-02-02 22:47:59 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-02 22:47:59 | INFO | train | epoch 175 | loss 5.276 | ppl 38.75 | wps 6044.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.218 | train_wall 318 | gb_free 6.1 | wall 60070
KL Stats: Epoch 175 Divergences: Uniform: 3.020016686523749 Unigram: 5.071264071407394
2022-02-02 22:47:59 | INFO | fairseq.trainer | begin training epoch 176
2022-02-02 22:47:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:53:44 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.474 | ppl 1421.85 | wps 8165.6 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.325
2022-02-02 22:53:44 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-02 22:53:44 | INFO | train | epoch 176 | loss 5.273 | ppl 38.66 | wps 6055.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.235 | train_wall 317 | gb_free 6.1 | wall 60415
KL Stats: Epoch 176 Divergences: Uniform: 3.0253529588857653 Unigram: 5.0780902025279495
2022-02-02 22:53:44 | INFO | fairseq.trainer | begin training epoch 177
2022-02-02 22:53:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:56:44 | INFO | train_inner | epoch 177:     36 / 64 loss=5.262, ppl=38.36, wps=5917.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.229, train_wall=497, gb_free=6.1, wall=60596
2022-02-02 22:59:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:59:29 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.511 | ppl 1459.06 | wps 8176.2 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.325
2022-02-02 22:59:29 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-02 22:59:29 | INFO | train | epoch 177 | loss 5.266 | ppl 38.48 | wps 6040.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.24 | train_wall 318 | gb_free 6.1 | wall 60761
KL Stats: Epoch 177 Divergences: Uniform: 3.0206412856334377 Unigram: 5.08617982026264
2022-02-02 22:59:29 | INFO | fairseq.trainer | begin training epoch 178
2022-02-02 22:59:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:04:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:05:14 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.518 | ppl 1466.5 | wps 8144.1 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.325
2022-02-02 23:05:14 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-02 23:05:14 | INFO | train | epoch 178 | loss 5.262 | ppl 38.36 | wps 6058.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.225 | train_wall 317 | gb_free 6.1 | wall 61106
KL Stats: Epoch 178 Divergences: Uniform: 3.018564692931973 Unigram: 5.092525435615739
2022-02-02 23:05:14 | INFO | fairseq.trainer | begin training epoch 179
2022-02-02 23:05:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:05:54 | INFO | train_inner | epoch 179:      8 / 64 loss=5.266, ppl=38.47, wps=5927.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.241, train_wall=495, gb_free=6.1, wall=61146
2022-02-02 23:10:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:11:00 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.54 | ppl 1488.55 | wps 8164.6 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.325
2022-02-02 23:11:00 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-02 23:11:00 | INFO | train | epoch 179 | loss 5.255 | ppl 38.19 | wps 6041.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.251 | train_wall 318 | gb_free 6.1 | wall 61451
KL Stats: Epoch 179 Divergences: Uniform: 3.0263604804562614 Unigram: 5.104182522295847
2022-02-02 23:11:00 | INFO | fairseq.trainer | begin training epoch 180
2022-02-02 23:11:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:14:39 | INFO | train_inner | epoch 180:     44 / 64 loss=5.247, ppl=37.97, wps=6227, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.241, train_wall=497, gb_free=6.1, wall=61670
2022-02-02 23:16:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:16:44 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.504 | ppl 1451.8 | wps 8254.3 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.325
2022-02-02 23:16:44 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-02 23:16:44 | INFO | train | epoch 180 | loss 5.248 | ppl 38 | wps 6074.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.253 | train_wall 316 | gb_free 6.1 | wall 61795
KL Stats: Epoch 180 Divergences: Uniform: 3.024021751447831 Unigram: 5.11112190785008
2022-02-02 23:16:44 | INFO | fairseq.trainer | begin training epoch 181
2022-02-02 23:16:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:22:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:22:28 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.5 | ppl 1448.39 | wps 8168.8 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.325
2022-02-02 23:22:28 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-02 23:22:28 | INFO | train | epoch 181 | loss 5.244 | ppl 37.89 | wps 6058.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.281 | train_wall 317 | gb_free 6.1 | wall 62140
KL Stats: Epoch 181 Divergences: Uniform: 3.024228780257982 Unigram: 5.1148839286841445
2022-02-02 23:22:28 | INFO | fairseq.trainer | begin training epoch 182
2022-02-02 23:22:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:23:48 | INFO | train_inner | epoch 182:     16 / 64 loss=5.247, ppl=37.98, wps=5935, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.282, train_wall=495, gb_free=6.1, wall=62220
2022-02-02 23:27:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:28:13 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.522 | ppl 1469.98 | wps 8186.3 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.325
2022-02-02 23:28:13 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-02 23:28:13 | INFO | train | epoch 182 | loss 5.24 | ppl 37.79 | wps 6068.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.288 | train_wall 317 | gb_free 6.1 | wall 62484
KL Stats: Epoch 182 Divergences: Uniform: 3.0263445897997614 Unigram: 5.12709911547922
2022-02-02 23:28:13 | INFO | fairseq.trainer | begin training epoch 183
2022-02-02 23:28:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:32:32 | INFO | train_inner | epoch 183:     52 / 64 loss=5.238, ppl=37.75, wps=6234.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.303, train_wall=496, gb_free=6.1, wall=62744
2022-02-02 23:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:33:58 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.51 | ppl 1458.42 | wps 8195.3 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.325
2022-02-02 23:33:58 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-02 23:33:58 | INFO | train | epoch 183 | loss 5.234 | ppl 37.63 | wps 6052.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.313 | train_wall 318 | gb_free 6.1 | wall 62829
KL Stats: Epoch 183 Divergences: Uniform: 3.0304450089276447 Unigram: 5.136177252622589
2022-02-02 23:33:58 | INFO | fairseq.trainer | begin training epoch 184
2022-02-02 23:33:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:39:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:39:41 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.508 | ppl 1456.29 | wps 8245.1 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.325
2022-02-02 23:39:41 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-02 23:39:41 | INFO | train | epoch 184 | loss 5.228 | ppl 37.48 | wps 6079.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.274 | train_wall 316 | gb_free 6.1 | wall 63173
KL Stats: Epoch 184 Divergences: Uniform: 3.024791469692496 Unigram: 5.140148074797297
2022-02-02 23:39:41 | INFO | fairseq.trainer | begin training epoch 185
2022-02-02 23:39:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:41:40 | INFO | train_inner | epoch 185:     24 / 64 loss=5.225, ppl=37.41, wps=5950.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.281, train_wall=493, gb_free=6.1, wall=63292
2022-02-02 23:44:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:45:24 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.507 | ppl 1455.68 | wps 8269.8 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.325
2022-02-02 23:45:24 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-02 23:45:24 | INFO | train | epoch 185 | loss 5.226 | ppl 37.42 | wps 6097.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.313 | train_wall 315 | gb_free 6.1 | wall 63515
KL Stats: Epoch 185 Divergences: Uniform: 3.0289898318711037 Unigram: 5.1432395347530875
2022-02-02 23:45:24 | INFO | fairseq.trainer | begin training epoch 186
2022-02-02 23:45:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:50:20 | INFO | train_inner | epoch 186:     60 / 64 loss=5.229, ppl=37.5, wps=6287.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.331, train_wall=492, gb_free=6.1, wall=63812
2022-02-02 23:50:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:51:05 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.523 | ppl 1471.85 | wps 8264.1 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.325
2022-02-02 23:51:05 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-02 23:51:05 | INFO | train | epoch 186 | loss 5.22 | ppl 37.28 | wps 6119.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.33 | train_wall 314 | gb_free 6.1 | wall 63856
KL Stats: Epoch 186 Divergences: Uniform: 3.032295320174771 Unigram: 5.145885180538091
2022-02-02 23:51:05 | INFO | fairseq.trainer | begin training epoch 187
2022-02-02 23:51:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:56:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:56:47 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.512 | ppl 1460.62 | wps 8282.5 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.325
2022-02-02 23:56:47 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-02 23:56:47 | INFO | train | epoch 187 | loss 5.218 | ppl 37.22 | wps 6104.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.358 | train_wall 315 | gb_free 6.1 | wall 64199
KL Stats: Epoch 187 Divergences: Uniform: 3.029199773980626 Unigram: 5.157169475800929
2022-02-02 23:56:47 | INFO | fairseq.trainer | begin training epoch 188
2022-02-02 23:56:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:59:25 | INFO | train_inner | epoch 188:     32 / 64 loss=5.209, ppl=36.98, wps=5981.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.343, train_wall=491, gb_free=6.1, wall=64357
2022-02-03 00:02:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:02:28 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.588 | ppl 1539.48 | wps 8285.6 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.325
2022-02-03 00:02:28 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-03 00:02:28 | INFO | train | epoch 188 | loss 5.211 | ppl 37.03 | wps 6126.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.334 | train_wall 314 | gb_free 6.1 | wall 64540
KL Stats: Epoch 188 Divergences: Uniform: 3.0333236178132728 Unigram: 5.165994287754132
2022-02-03 00:02:28 | INFO | fairseq.trainer | begin training epoch 189
2022-02-03 00:02:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:07:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:08:10 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.565 | ppl 1515.03 | wps 8283.9 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.325
2022-02-03 00:08:10 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-03 00:08:10 | INFO | train | epoch 189 | loss 5.205 | ppl 36.89 | wps 6113.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.311 | train_wall 314 | gb_free 6.1 | wall 64881
KL Stats: Epoch 189 Divergences: Uniform: 3.033693538048613 Unigram: 5.17566779831278
2022-02-03 00:08:10 | INFO | fairseq.trainer | begin training epoch 190
2022-02-03 00:08:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:08:30 | INFO | train_inner | epoch 190:      4 / 64 loss=5.214, ppl=37.11, wps=5986.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.331, train_wall=490, gb_free=6.1, wall=64901
2022-02-03 00:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:13:51 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.547 | ppl 1496.26 | wps 8275.9 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.325
2022-02-03 00:13:51 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-03 00:13:51 | INFO | train | epoch 190 | loss 5.202 | ppl 36.82 | wps 6127.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.356 | train_wall 314 | gb_free 6.1 | wall 65222
KL Stats: Epoch 190 Divergences: Uniform: 3.032385665048666 Unigram: 5.178499798323914
2022-02-03 00:13:51 | INFO | fairseq.trainer | begin training epoch 191
2022-02-03 00:13:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:17:09 | INFO | train_inner | epoch 191:     40 / 64 loss=5.191, ppl=36.54, wps=6297.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.359, train_wall=491, gb_free=6.1, wall=65420
2022-02-03 00:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:19:33 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.531 | ppl 1479.42 | wps 8262.3 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.325
2022-02-03 00:19:33 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-03 00:19:33 | INFO | train | epoch 191 | loss 5.197 | ppl 36.69 | wps 6110.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.356 | train_wall 314 | gb_free 6.1 | wall 65564
KL Stats: Epoch 191 Divergences: Uniform: 3.0363286924637323 Unigram: 5.188638198232841
2022-02-03 00:19:33 | INFO | fairseq.trainer | begin training epoch 192
2022-02-03 00:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:24:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:25:14 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.531 | ppl 1479.38 | wps 8267.2 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.325
2022-02-03 00:25:14 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-03 00:25:14 | INFO | train | epoch 192 | loss 5.197 | ppl 36.68 | wps 6125.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.404 | train_wall 314 | gb_free 6.1 | wall 65905
KL Stats: Epoch 192 Divergences: Uniform: 3.0345147369281484 Unigram: 5.193079776357557
2022-02-03 00:25:14 | INFO | fairseq.trainer | begin training epoch 193
2022-02-03 00:25:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:26:13 | INFO | train_inner | epoch 193:     12 / 64 loss=5.204, ppl=36.86, wps=5991.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.388, train_wall=490, gb_free=6.1, wall=65964
2022-02-03 00:30:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:30:55 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.521 | ppl 1469.37 | wps 8280.6 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.325
2022-02-03 00:30:55 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-03 00:30:55 | INFO | train | epoch 193 | loss 5.188 | ppl 36.46 | wps 6115.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.359 | train_wall 314 | gb_free 6.1 | wall 66246
KL Stats: Epoch 193 Divergences: Uniform: 3.0402503530025693 Unigram: 5.200471607568896
2022-02-03 00:30:55 | INFO | fairseq.trainer | begin training epoch 194
2022-02-03 00:30:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:34:52 | INFO | train_inner | epoch 194:     48 / 64 loss=5.184, ppl=36.35, wps=6293.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.36, train_wall=492, gb_free=6.1, wall=66483
2022-02-03 00:36:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:36:36 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.574 | ppl 1524.58 | wps 8283.9 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.325
2022-02-03 00:36:36 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-03 00:36:36 | INFO | train | epoch 194 | loss 5.184 | ppl 36.36 | wps 6122.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.385 | train_wall 314 | gb_free 6.1 | wall 66588
KL Stats: Epoch 194 Divergences: Uniform: 3.04009975479065 Unigram: 5.206931685216153
2022-02-03 00:36:36 | INFO | fairseq.trainer | begin training epoch 195
2022-02-03 00:36:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:41:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:42:18 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.579 | ppl 1530.1 | wps 8273.6 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.325
2022-02-03 00:42:18 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-03 00:42:18 | INFO | train | epoch 195 | loss 5.179 | ppl 36.22 | wps 6115.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.403 | train_wall 314 | gb_free 6.1 | wall 66929
KL Stats: Epoch 195 Divergences: Uniform: 3.041260113675913 Unigram: 5.216639486990978
2022-02-03 00:42:18 | INFO | fairseq.trainer | begin training epoch 196
2022-02-03 00:42:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:43:56 | INFO | train_inner | epoch 196:     20 / 64 loss=5.176, ppl=36.15, wps=5988.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.405, train_wall=490, gb_free=6.1, wall=67028
2022-02-03 00:47:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:47:59 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.567 | ppl 1516.97 | wps 8273.4 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.325
2022-02-03 00:47:59 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-03 00:47:59 | INFO | train | epoch 196 | loss 5.175 | ppl 36.14 | wps 6124.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.411 | train_wall 314 | gb_free 6.1 | wall 67270
KL Stats: Epoch 196 Divergences: Uniform: 3.0370338540896276 Unigram: 5.214110427785332
2022-02-03 00:47:59 | INFO | fairseq.trainer | begin training epoch 197
2022-02-03 00:47:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:52:36 | INFO | train_inner | epoch 197:     56 / 64 loss=5.178, ppl=36.21, wps=6292.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.414, train_wall=492, gb_free=6.1, wall=67547
2022-02-03 00:53:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:53:41 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.598 | ppl 1550.31 | wps 8265 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.325
2022-02-03 00:53:41 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-03 00:53:41 | INFO | train | epoch 197 | loss 5.173 | ppl 36.07 | wps 6108.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.422 | train_wall 315 | gb_free 6.1 | wall 67612
KL Stats: Epoch 197 Divergences: Uniform: 3.0423686417589386 Unigram: 5.230166901708231
2022-02-03 00:53:41 | INFO | fairseq.trainer | begin training epoch 198
2022-02-03 00:53:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:58:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:59:22 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.619 | ppl 1572.79 | wps 8267.2 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.325
2022-02-03 00:59:22 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-03 00:59:22 | INFO | train | epoch 198 | loss 5.168 | ppl 35.94 | wps 6118.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.426 | train_wall 314 | gb_free 6.1 | wall 67953
KL Stats: Epoch 198 Divergences: Uniform: 3.0362012400078973 Unigram: 5.231100217215601
2022-02-03 00:59:22 | INFO | fairseq.trainer | begin training epoch 199
2022-02-03 00:59:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:01:41 | INFO | train_inner | epoch 199:     28 / 64 loss=5.162, ppl=35.81, wps=5984.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.433, train_wall=490, gb_free=6.1, wall=68092
2022-02-03 01:04:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:05:04 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.593 | ppl 1544.84 | wps 8293.8 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.325
2022-02-03 01:05:04 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-03 01:05:04 | INFO | train | epoch 199 | loss 5.163 | ppl 35.82 | wps 6111.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.441 | train_wall 315 | gb_free 6.1 | wall 68295
KL Stats: Epoch 199 Divergences: Uniform: 3.0425477681877453 Unigram: 5.23801034490532
2022-02-03 01:05:04 | INFO | fairseq.trainer | begin training epoch 200
2022-02-03 01:05:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:10:18 | INFO | train_inner | epoch 200:     64 / 64 loss=5.169, ppl=35.99, wps=6296.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.447, train_wall=490, gb_free=6.1, wall=68610
2022-02-03 01:10:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:10:45 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.551 | ppl 1500.57 | wps 8271.8 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.325
2022-02-03 01:10:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-03 01:10:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint200.pt
2022-02-03 01:10:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint200.pt
2022-02-03 01:10:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#3/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.551) (writing took 3.4474961776286364 seconds)
2022-02-03 01:10:48 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-03 01:10:48 | INFO | train | epoch 200 | loss 5.159 | ppl 35.72 | wps 6063.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.45 | train_wall 314 | gb_free 6.1 | wall 68640
KL Stats: Epoch 200 Divergences: Uniform: 3.045621516595562 Unigram: 5.247135980151465
2022-02-03 01:10:48 | INFO | fairseq.trainer | begin training epoch 201
2022-02-03 01:10:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:16:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:16:30 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.505 | ppl 1452.99 | wps 8251.7 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.325
2022-02-03 01:16:30 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-03 01:16:30 | INFO | train | epoch 201 | loss 5.154 | ppl 35.6 | wps 6107.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.42 | train_wall 315 | gb_free 6.1 | wall 68982
KL Stats: Epoch 201 Divergences: Uniform: 3.044091231443064 Unigram: 5.249604439343869
2022-02-03 01:16:30 | INFO | fairseq.trainer | begin training epoch 202
2022-02-03 01:16:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:19:28 | INFO | train_inner | epoch 202:     36 / 64 loss=5.144, ppl=35.36, wps=5944, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.445, train_wall=492, gb_free=6.1, wall=69159
2022-02-03 01:21:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:22:12 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.589 | ppl 1540.53 | wps 8288.5 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.325
2022-02-03 01:22:12 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-02-03 01:22:12 | INFO | train | epoch 202 | loss 5.153 | ppl 35.57 | wps 6117 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.489 | train_wall 314 | gb_free 6.1 | wall 69323
KL Stats: Epoch 202 Divergences: Uniform: 3.041664464919238 Unigram: 5.250532638534566
2022-02-03 01:22:12 | INFO | fairseq.trainer | begin training epoch 203
2022-02-03 01:22:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:27:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:27:53 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.626 | ppl 1580.67 | wps 8265.5 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.325
2022-02-03 01:27:53 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-02-03 01:27:53 | INFO | train | epoch 203 | loss 5.148 | ppl 35.45 | wps 6115.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.508 | train_wall 314 | gb_free 6.1 | wall 69664
KL Stats: Epoch 203 Divergences: Uniform: 3.045332416131451 Unigram: 5.25489461596574
2022-02-03 01:27:53 | INFO | fairseq.trainer | begin training epoch 204
2022-02-03 01:27:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:28:33 | INFO | train_inner | epoch 204:      8 / 64 loss=5.155, ppl=35.63, wps=5985.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.504, train_wall=490, gb_free=6.1, wall=69704
2022-02-03 01:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:33:35 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.608 | ppl 1560.18 | wps 8271.4 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.325
2022-02-03 01:33:35 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-02-03 01:33:35 | INFO | train | epoch 204 | loss 5.145 | ppl 35.39 | wps 6117.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.491 | train_wall 314 | gb_free 6.1 | wall 70006
KL Stats: Epoch 204 Divergences: Uniform: 3.045573260802139 Unigram: 5.263436785180252
2022-02-03 01:33:35 | INFO | fairseq.trainer | begin training epoch 205
2022-02-03 01:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:37:12 | INFO | train_inner | epoch 205:     44 / 64 loss=5.136, ppl=35.18, wps=6294.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.492, train_wall=491, gb_free=6.1, wall=70223
2022-02-03 01:38:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:39:16 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 10.64 | ppl 1596.11 | wps 8255 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.325
2022-02-03 01:39:16 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-02-03 01:39:16 | INFO | train | epoch 205 | loss 5.14 | ppl 35.25 | wps 6113.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.532 | train_wall 314 | gb_free 6.1 | wall 70348
KL Stats: Epoch 205 Divergences: Uniform: 3.0427740250912128 Unigram: 5.2692900884961
2022-02-03 01:39:16 | INFO | fairseq.trainer | begin training epoch 206
2022-02-03 01:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:44:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:44:58 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 10.61 | ppl 1563.01 | wps 8277 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.325
2022-02-03 01:44:58 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-02-03 01:44:58 | INFO | train | epoch 206 | loss 5.137 | ppl 35.18 | wps 6118.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.526 | train_wall 314 | gb_free 6.1 | wall 70689
KL Stats: Epoch 206 Divergences: Uniform: 3.048941595100372 Unigram: 5.272912824624811
2022-02-03 01:44:58 | INFO | fairseq.trainer | begin training epoch 207
2022-02-03 01:44:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:46:17 | INFO | train_inner | epoch 207:     16 / 64 loss=5.138, ppl=35.21, wps=5984.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.529, train_wall=490, gb_free=6.1, wall=70768
2022-02-03 01:50:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:50:39 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 10.638 | ppl 1593.15 | wps 8231.3 | wpb 2034.1 | bsz 4 | num_updates 13248 | best_loss 9.325
2022-02-03 01:50:39 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-02-03 01:50:39 | INFO | train | epoch 207 | loss 5.131 | ppl 35.05 | wps 6108.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13248 | lr 0.000274742 | gnorm 1.49 | train_wall 315 | gb_free 6.1 | wall 71031
KL Stats: Epoch 207 Divergences: Uniform: 3.046891598081356 Unigram: 5.288112694773735
2022-02-03 01:50:39 | INFO | fairseq.trainer | begin training epoch 208
2022-02-03 01:50:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:54:56 | INFO | train_inner | epoch 208:     52 / 64 loss=5.135, ppl=35.13, wps=6287.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13300, lr=0.000274204, gnorm=1.563, train_wall=492, gb_free=6.1, wall=71288
2022-02-03 01:55:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:56:21 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 10.667 | ppl 1625.35 | wps 8273.7 | wpb 2034.1 | bsz 4 | num_updates 13312 | best_loss 9.325
2022-02-03 01:56:21 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-02-03 01:56:21 | INFO | train | epoch 208 | loss 5.132 | ppl 35.06 | wps 6118.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13312 | lr 0.000274081 | gnorm 1.62 | train_wall 314 | gb_free 6.1 | wall 71372
KL Stats: Epoch 208 Divergences: Uniform: 3.0487886251897427 Unigram: 5.289699067658866
2022-02-03 01:56:21 | INFO | fairseq.trainer | begin training epoch 209
2022-02-03 01:56:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:01:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:02:02 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 10.624 | ppl 1577.83 | wps 8260.7 | wpb 2034.1 | bsz 4 | num_updates 13376 | best_loss 9.325
2022-02-03 02:02:02 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-02-03 02:02:02 | INFO | train | epoch 209 | loss 5.126 | ppl 34.92 | wps 6116.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13376 | lr 0.000273424 | gnorm 1.576 | train_wall 314 | gb_free 6.1 | wall 71714
KL Stats: Epoch 209 Divergences: Uniform: 3.051401144655027 Unigram: 5.289046492409399
2022-02-03 02:02:02 | INFO | fairseq.trainer | begin training epoch 210
2022-02-03 02:02:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:04:01 | INFO | train_inner | epoch 210:     24 / 64 loss=5.119, ppl=34.76, wps=5984.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13400, lr=0.000273179, gnorm=1.574, train_wall=491, gb_free=6.1, wall=71833
User defined signal 2
