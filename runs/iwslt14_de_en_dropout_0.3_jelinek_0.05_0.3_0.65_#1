Sender: LSF System <lsfadmin@eu-g3-062>
Subject: Job 210595560: <iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1> in cluster <euler> Exited

Job <iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 11:36:54 2022
Job was executed on host(s) <eu-g3-062>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 11:37:28 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 11:37:28 2022
Terminated at Wed Mar 23 13:19:01 2022
Results reported at Wed Mar 23 13:19:01 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.05,0.3,0.65\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Exited.


The output (if any) follows:

2022-03-23 11:37:36 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.05,0.3,0.65)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.05,0.3,0.65)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 11:37:36 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 11:37:36 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 11:37:37 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:37:37 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:37:37 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1149/160239 [00:00<00:13, 11488.61it/s]  2%|▏         | 2522/160239 [00:00<00:12, 12798.37it/s]  2%|▏         | 3931/160239 [00:00<00:11, 13387.16it/s]  3%|▎         | 5270/160239 [00:00<00:11, 13214.45it/s]  4%|▍         | 6641/160239 [00:00<00:11, 13391.22it/s]  5%|▍         | 7981/160239 [00:00<00:11, 13073.31it/s]  6%|▌         | 9290/160239 [00:00<00:11, 12970.50it/s]  7%|▋         | 10659/160239 [00:00<00:11, 13190.56it/s]  7%|▋         | 11980/160239 [00:00<00:11, 13125.17it/s]  8%|▊         | 13316/160239 [00:01<00:11, 13196.40it/s]  9%|▉         | 14637/160239 [00:01<00:11, 13079.42it/s] 10%|▉         | 15946/160239 [00:01<00:11, 12949.99it/s] 11%|█         | 17242/160239 [00:01<00:11, 12733.16it/s] 12%|█▏        | 18517/160239 [00:01<00:11, 12686.59it/s] 12%|█▏        | 19928/160239 [00:01<00:10, 13106.50it/s] 13%|█▎        | 21240/160239 [00:01<00:10, 13074.56it/s] 14%|█▍        | 22549/160239 [00:01<00:10, 12976.73it/s] 15%|█▍        | 23848/160239 [00:01<00:10, 12878.34it/s] 16%|█▌        | 25137/160239 [00:01<00:10, 12880.81it/s] 16%|█▋        | 26426/160239 [00:02<00:10, 12781.62it/s] 17%|█▋        | 27736/160239 [00:02<00:10, 12874.05it/s] 18%|█▊        | 29059/160239 [00:02<00:10, 12977.74it/s] 19%|█▉        | 30358/160239 [00:02<00:10, 12660.72it/s] 20%|█▉        | 31769/160239 [00:02<00:09, 13081.80it/s] 21%|██        | 33080/160239 [00:02<00:09, 12949.27it/s] 21%|██▏       | 34377/160239 [00:02<00:09, 12677.10it/s] 22%|██▏       | 35647/160239 [00:02<00:09, 12553.48it/s] 23%|██▎       | 36965/160239 [00:02<00:09, 12729.60it/s] 24%|██▍       | 38304/160239 [00:02<00:09, 12920.05it/s] 25%|██▍       | 39598/160239 [00:03<00:09, 12764.63it/s] 26%|██▌       | 40972/160239 [00:03<00:09, 13046.84it/s] 26%|██▋       | 42279/160239 [00:03<00:09, 12766.93it/s] 27%|██▋       | 43558/160239 [00:03<00:09, 12608.00it/s] 28%|██▊       | 44821/160239 [00:03<00:09, 12454.89it/s] 29%|██▉       | 46201/160239 [00:03<00:08, 12844.11it/s] 30%|██▉       | 47527/160239 [00:03<00:08, 12965.38it/s] 30%|███       | 48826/160239 [00:03<00:08, 12774.01it/s] 31%|███▏      | 50128/160239 [00:03<00:08, 12841.90it/s] 32%|███▏      | 51487/160239 [00:03<00:08, 13061.38it/s] 33%|███▎      | 52815/160239 [00:04<00:08, 13125.01it/s] 34%|███▍      | 54129/160239 [00:04<00:08, 12955.46it/s] 35%|███▍      | 55426/160239 [00:04<00:08, 12836.19it/s] 35%|███▌      | 56796/160239 [00:04<00:07, 13088.22it/s] 36%|███▋      | 58192/160239 [00:04<00:07, 13059.53it/s] 37%|███▋      | 59511/160239 [00:04<00:07, 13095.64it/s] 38%|███▊      | 60825/160239 [00:04<00:07, 13105.47it/s] 39%|███▉      | 62137/160239 [00:04<00:07, 12993.36it/s] 40%|███▉      | 63507/160239 [00:04<00:07, 13200.80it/s] 41%|████      | 65013/160239 [00:05<00:06, 13751.09it/s] 41%|████▏     | 66390/160239 [00:05<00:06, 13735.77it/s] 42%|████▏     | 67765/160239 [00:05<00:06, 13268.48it/s] 43%|████▎     | 69096/160239 [00:05<00:07, 12986.02it/s] 44%|████▍     | 70458/160239 [00:05<00:06, 13168.03it/s] 45%|████▍     | 71778/160239 [00:05<00:06, 13077.25it/s] 46%|████▌     | 73088/160239 [00:05<00:06, 12885.90it/s] 46%|████▋     | 74379/160239 [00:05<00:06, 12887.64it/s] 47%|████▋     | 75669/160239 [00:05<00:06, 12791.71it/s] 48%|████▊     | 77049/160239 [00:05<00:06, 13086.92it/s] 49%|████▉     | 78412/160239 [00:06<00:06, 13245.96it/s] 50%|████▉     | 79738/160239 [00:06<00:06, 13242.99it/s] 51%|█████     | 81225/160239 [00:06<00:05, 13726.50it/s] 52%|█████▏    | 82599/160239 [00:06<00:05, 13423.13it/s] 52%|█████▏    | 83958/160239 [00:06<00:05, 13468.25it/s] 53%|█████▎    | 85307/160239 [00:06<00:05, 13370.81it/s] 54%|█████▍    | 86762/160239 [00:06<00:05, 13716.98it/s] 55%|█████▌    | 88135/160239 [00:06<00:05, 13450.20it/s] 56%|█████▌    | 89513/160239 [00:06<00:05, 13539.31it/s] 57%|█████▋    | 90869/160239 [00:06<00:05, 13432.85it/s] 58%|█████▊    | 92214/160239 [00:07<00:05, 13331.93it/s] 58%|█████▊    | 93548/160239 [00:07<00:05, 13304.07it/s] 59%|█████▉    | 94879/160239 [00:07<00:05, 12941.93it/s] 60%|██████    | 96241/160239 [00:07<00:04, 13137.35it/s] 61%|██████    | 97559/160239 [00:07<00:04, 13146.95it/s] 62%|██████▏   | 98904/160239 [00:07<00:04, 13235.91it/s] 63%|██████▎   | 100287/160239 [00:07<00:04, 13412.10it/s] 63%|██████▎   | 101630/160239 [00:07<00:04, 13035.95it/s] 64%|██████▍   | 102937/160239 [00:07<00:04, 12915.53it/s] 65%|██████▌   | 104308/160239 [00:07<00:04, 13146.20it/s] 66%|██████▌   | 105641/160239 [00:08<00:04, 13199.78it/s] 67%|██████▋   | 106963/160239 [00:08<00:04, 13163.10it/s] 68%|██████▊   | 108281/160239 [00:08<00:04, 12770.05it/s] 68%|██████▊   | 109565/160239 [00:08<00:03, 12788.56it/s] 69%|██████▉   | 110855/160239 [00:08<00:03, 12820.65it/s] 70%|███████   | 112240/160239 [00:08<00:03, 13122.19it/s] 71%|███████   | 113554/160239 [00:08<00:03, 13126.48it/s] 72%|███████▏  | 114868/160239 [00:08<00:03, 13069.33it/s] 73%|███████▎  | 116224/160239 [00:08<00:03, 13213.70it/s] 73%|███████▎  | 117547/160239 [00:09<00:03, 12975.28it/s] 74%|███████▍  | 118924/160239 [00:09<00:03, 13208.14it/s] 75%|███████▌  | 120247/160239 [00:09<00:03, 13205.87it/s] 76%|███████▌  | 121577/160239 [00:09<00:02, 13228.28it/s] 77%|███████▋  | 122991/160239 [00:09<00:02, 13499.53it/s] 78%|███████▊  | 124342/160239 [00:09<00:02, 13263.71it/s] 78%|███████▊  | 125670/160239 [00:09<00:02, 13018.80it/s] 79%|███████▉  | 127002/160239 [00:09<00:02, 13106.14it/s] 80%|████████  | 128354/160239 [00:09<00:02, 13226.80it/s] 81%|████████  | 129678/160239 [00:09<00:02, 13114.07it/s] 82%|████████▏ | 130991/160239 [00:10<00:02, 12779.09it/s] 83%|████████▎ | 132301/160239 [00:10<00:02, 12871.01it/s] 83%|████████▎ | 133590/160239 [00:10<00:02, 12759.97it/s] 84%|████████▍ | 134880/160239 [00:10<00:01, 12797.36it/s] 85%|████████▍ | 136169/160239 [00:10<00:01, 12820.39it/s] 86%|████████▌ | 137509/160239 [00:10<00:01, 12991.06it/s] 87%|████████▋ | 138879/160239 [00:10<00:01, 13201.67it/s] 88%|████████▊ | 140235/160239 [00:10<00:01, 13307.55it/s] 88%|████████▊ | 141595/160239 [00:10<00:01, 13386.14it/s] 89%|████████▉ | 142934/160239 [00:10<00:01, 13084.72it/s] 90%|█████████ | 144245/160239 [00:11<00:01, 12920.31it/s] 91%|█████████ | 145539/160239 [00:11<00:01, 12913.49it/s] 92%|█████████▏| 146832/160239 [00:11<00:01, 12898.76it/s] 92%|█████████▏| 148123/160239 [00:11<00:00, 12808.61it/s] 93%|█████████▎| 149405/160239 [00:11<00:00, 12591.43it/s] 94%|█████████▍| 150765/160239 [00:11<00:00, 12886.11it/s] 95%|█████████▍| 152069/160239 [00:11<00:00, 12930.92it/s] 96%|█████████▌| 153364/160239 [00:11<00:00, 12872.66it/s] 97%|█████████▋| 154710/160239 [00:11<00:00, 13042.50it/s] 97%|█████████▋| 156088/160239 [00:11<00:00, 13261.30it/s] 98%|█████████▊| 157436/160239 [00:12<00:00, 13320.02it/s] 99%|█████████▉| 158769/160239 [00:12<00:00, 13002.73it/s]100%|█████████▉| 160164/160239 [00:12<00:00, 13280.84it/s]100%|██████████| 160239/160239 [00:12<00:00, 13058.39it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3764/160239 [00:00<00:04, 37638.42it/s]  5%|▍         | 7577/160239 [00:00<00:04, 37914.52it/s]  7%|▋         | 11392/160239 [00:00<00:03, 38018.23it/s]  9%|▉         | 15194/160239 [00:00<00:03, 37733.51it/s] 12%|█▏        | 18968/160239 [00:00<00:03, 37409.41it/s] 14%|█▍        | 22797/160239 [00:00<00:03, 37703.62it/s] 17%|█▋        | 26568/160239 [00:00<00:03, 37599.30it/s] 19%|█▉        | 30336/160239 [00:00<00:03, 37622.86it/s] 21%|██▏       | 34099/160239 [00:00<00:03, 37534.22it/s] 24%|██▎       | 37853/160239 [00:01<00:03, 37524.55it/s] 26%|██▌       | 41652/160239 [00:01<00:03, 37661.84it/s] 28%|██▊       | 45419/160239 [00:01<00:03, 37261.80it/s] 31%|███       | 49287/160239 [00:01<00:02, 37686.81it/s] 33%|███▎      | 53075/160239 [00:01<00:02, 37743.45it/s] 35%|███▌      | 56877/160239 [00:01<00:02, 37824.60it/s] 38%|███▊      | 60795/160239 [00:01<00:02, 38229.89it/s] 40%|████      | 64768/160239 [00:01<00:02, 38678.35it/s] 43%|████▎     | 68637/160239 [00:01<00:02, 38300.76it/s] 45%|████▌     | 72478/160239 [00:01<00:02, 38331.41it/s] 48%|████▊     | 76312/160239 [00:02<00:02, 37991.06it/s] 50%|█████     | 80304/160239 [00:02<00:02, 38562.15it/s] 53%|█████▎    | 84205/160239 [00:02<00:01, 38694.47it/s] 55%|█████▌    | 88157/160239 [00:02<00:01, 38938.68it/s] 57%|█████▋    | 92052/160239 [00:02<00:01, 38918.55it/s] 60%|█████▉    | 95945/160239 [00:02<00:01, 38740.25it/s] 62%|██████▏   | 99820/160239 [00:02<00:01, 38608.76it/s] 65%|██████▍   | 103682/160239 [00:02<00:01, 38458.06it/s] 67%|██████▋   | 107543/160239 [00:02<00:01, 38502.35it/s] 70%|██████▉   | 111394/160239 [00:02<00:01, 38165.12it/s] 72%|███████▏  | 115212/160239 [00:03<00:01, 38142.02it/s] 74%|███████▍  | 119048/160239 [00:03<00:01, 38206.27it/s] 77%|███████▋  | 122954/160239 [00:03<00:00, 38457.56it/s] 79%|███████▉  | 126801/160239 [00:03<00:00, 38130.18it/s] 82%|████████▏ | 130615/160239 [00:03<00:00, 37906.92it/s] 84%|████████▍ | 134407/160239 [00:03<00:00, 37713.74it/s] 86%|████████▋ | 138249/160239 [00:03<00:00, 37921.49it/s] 89%|████████▊ | 142205/160239 [00:03<00:00, 38408.61it/s] 91%|█████████ | 146047/160239 [00:03<00:00, 38080.98it/s] 94%|█████████▎| 149857/160239 [00:03<00:00, 37686.14it/s] 96%|█████████▌| 153663/160239 [00:04<00:00, 37795.91it/s] 98%|█████████▊| 157635/160239 [00:04<00:00, 38364.08it/s]100%|██████████| 160239/160239 [00:04<00:00, 38104.07it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2286.97it/s]2022-03-23 11:37:57 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 11:37:57 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 11:37:57 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 11:37:57 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-23 11:37:57 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 11:37:57 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 11:37:57 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 11:37:57 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 11:37:57 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 11:37:57 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 11:37:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:37:57 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 11:37:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:37:57 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 11:37:57 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 11:37:57 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 11:37:57 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 11:37:57 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 11:37:57 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:37:57 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:37:57 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 11:37:58 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 11:37:58 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 11:38:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 11:38:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 11:38:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 11:38:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 11:38:40 | INFO | train_inner | epoch 001:    104 / 157 loss=13.076, ppl=8637.04, wps=66155.8, ups=2.63, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=3.577, loss_scale=8, train_wall=42, gb_free=12.1, wall=43
2022-03-23 11:39:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:39:03 | INFO | fairseq.tasks.translation | example hypothesis: ,,,.....
2022-03-23 11:39:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:39:06 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,......
2022-03-23 11:39:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:39:09 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 11:39:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:39:12 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,
2022-03-23 11:39:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:39:16 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:39:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:39:20 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,
2022-03-23 11:39:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:39:24 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:39:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:39:29 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:39:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:39:35 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:39:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:39:38 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:39:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:39:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.386 | ppl 5351.25 | bleu 0.01 | wps 4756.2 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 11:39:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 11:39:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:39:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:39:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.7215880299918354 seconds)
2022-03-23 11:39:39 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 11:39:39 | INFO | train | epoch 001 | loss 12.577 | ppl 6110.3 | wps 39306 | ups 1.57 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 2.783 | loss_scale 8 | train_wall 61 | gb_free 22.3 | wall 102
KL Stats: Epoch 1 Divergences: Uniform: 0.5761076444183799 Unigram: 1.4290590704213846
2022-03-23 11:39:40 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 11:39:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:39:58 | INFO | train_inner | epoch 002:     47 / 157 loss=11.293, ppl=2510, wps=32684.6, ups=1.29, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=1.151, loss_scale=8, train_wall=37, gb_free=12.9, wall=120
2022-03-23 11:40:36 | INFO | train_inner | epoch 002:    147 / 157 loss=10.738, ppl=1708.42, wps=66246.4, ups=2.63, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=0.998, loss_scale=8, train_wall=38, gb_free=12.2, wall=158
2022-03-23 11:40:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:40:42 | INFO | fairseq.tasks.translation | example hypothesis: we we.
2022-03-23 11:40:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:40:45 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the.
2022-03-23 11:40:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:40:48 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the.
2022-03-23 11:40:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:40:52 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:40:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:40:56 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:40:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:41:01 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:41:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:41:06 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:41:12 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:41:18 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:41:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:41:20 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:41:20 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.511 | ppl 2918.66 | bleu 0.02 | wps 4317.9 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 11:41:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 11:41:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:41:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:41:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.8204494698438793 seconds)
2022-03-23 11:41:22 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 11:41:22 | INFO | train | epoch 002 | loss 10.8 | ppl 1783.35 | wps 38529.7 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.979 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 205
KL Stats: Epoch 2 Divergences: Uniform: 0.8395276375421845 Unigram: 0.2996631330159706
2022-03-23 11:41:22 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 11:41:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:41:56 | INFO | train_inner | epoch 003:     90 / 157 loss=10.457, ppl=1406.02, wps=30537.4, ups=1.24, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=0.746, loss_scale=8, train_wall=36, gb_free=11.8, wall=239
2022-03-23 11:42:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:42:25 | INFO | fairseq.tasks.translation | example hypothesis: we.
2022-03-23 11:42:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:42:28 | INFO | fairseq.tasks.translation | example hypothesis: it's.
2022-03-23 11:42:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:42:31 | INFO | fairseq.tasks.translation | example hypothesis: it's.
2022-03-23 11:42:31 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:42:34 | INFO | fairseq.tasks.translation | example hypothesis: and it's.
2022-03-23 11:42:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:42:38 | INFO | fairseq.tasks.translation | example hypothesis: it's.
2022-03-23 11:42:38 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:42:42 | INFO | fairseq.tasks.translation | example hypothesis: and and the, and the the, and the, and the the the the the, and and and and and and the the the the the the, and and and the the the the the the.
2022-03-23 11:42:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:42:47 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's, it's, it's, and it's, and the the, and the the, and the the the the the the, and the the the the, and the, and the, and the the the, and the the the the the the the the, and it's, and the the the the
2022-03-23 11:42:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:42:53 | INFO | fairseq.tasks.translation | example hypothesis: and we, and the, and we, and the the the the the, and we, and the the, and the the the, and we, and the the the the the, and we, and the the, and we, and we, and the the the the the the the the the the, and we, and the the the the the the the the the the the the the the the the, and the the the the the, and we,
2022-03-23 11:42:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:43:01 | INFO | fairseq.tasks.translation | example hypothesis: it's, the, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:43:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:43:03 | INFO | fairseq.tasks.translation | example hypothesis: it's a, the, and the, and the, we, we, we, we, we, we, we, the, the, the the the the, the, the the, the, the, the, the, the, the the the the the the the the the, the, the, and the, and the, and the, and the, and the the the the the the the the the the the the the the, the the the the the the the the, and the, and the the the the the the, and the, and the, and the, and the, and the, and the, and the, and the, and the the the the the the, the, and the, and the, and the, and the, and the, and the the, and the the the the the, and the, and the, and the, and the, and the, and the, we, we, we, the, the, the, the, the, the, and the, and the,
2022-03-23 11:43:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:43:03 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.396 | ppl 2695.58 | bleu 0.2 | wps 4273.8 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.2
2022-03-23 11:43:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 11:43:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:43:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:43:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.2) (writing took 1.7920642248354852 seconds)
2022-03-23 11:43:05 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 11:43:05 | INFO | train | epoch 003 | loss 10.369 | ppl 1322.41 | wps 38382.1 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.915 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 307
KL Stats: Epoch 3 Divergences: Uniform: 1.2069107109658672 Unigram: 0.1636508112296187
2022-03-23 11:43:05 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 11:43:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:43:18 | INFO | train_inner | epoch 004:     33 / 157 loss=10.282, ppl=1244.78, wps=31086.3, ups=1.22, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.032, loss_scale=8, train_wall=37, gb_free=12, wall=321
2022-03-23 11:43:56 | INFO | train_inner | epoch 004:    133 / 157 loss=10.199, ppl=1175.53, wps=66481.3, ups=2.63, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.026, loss_scale=8, train_wall=38, gb_free=10.8, wall=359
2022-03-23 11:44:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:44:08 | INFO | fairseq.tasks.translation | example hypothesis: and we're the.
2022-03-23 11:44:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:44:12 | INFO | fairseq.tasks.translation | example hypothesis: and this is the that's the world.
2022-03-23 11:44:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:44:15 | INFO | fairseq.tasks.translation | example hypothesis: so, you're a of the.
2022-03-23 11:44:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:44:19 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, and it's a, and it's a.
2022-03-23 11:44:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:44:23 | INFO | fairseq.tasks.translation | example hypothesis: and it's, and it's a that's a that's a that's not not not not not not not not not not not not not.
2022-03-23 11:44:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:44:28 | INFO | fairseq.tasks.translation | example hypothesis: and this is a of the of the of the and this is a of the world of the world, and this is the world.
2022-03-23 11:44:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:44:33 | INFO | fairseq.tasks.translation | example hypothesis: but it's a, but they're a, but they're a, but they're the world, but you're a, but they're a, but they're're a to be be be be be be be, but it's a, but it's a, but it's a, but it's a.
2022-03-23 11:44:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:44:38 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can can see the, and, and we can can can can can can can can can see the of the world, and we're the world, and, and we're the world, and we're the world, and we're the world.
2022-03-23 11:44:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:44:46 | INFO | fairseq.tasks.translation | example hypothesis: and ",", "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 11:44:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:44:48 | INFO | fairseq.tasks.translation | example hypothesis: so, we have to be, and you're a a, and you're a, and you have to be, and you're a to be, and you're a to be a to be, and you have to be, and you're a, and you're a, and you have to be, and you have to be a a a to be, and you're a to be be be be be be be be be a a a a, and it's a, and it's a, and you have to be be to be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be, and it's a, and it's a, and we have to be, and you have to be, and you have to be, and you can can can can can can can can have to be, and you have to be to be to be to be to be be be be be be to be be be be be be be
2022-03-23 11:44:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:44:48 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.151 | ppl 2273.59 | bleu 1.14 | wps 4123.6 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 1.14
2022-03-23 11:44:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 11:44:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:44:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:44:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 1.14) (writing took 1.7819785850588232 seconds)
2022-03-23 11:44:50 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 11:44:50 | INFO | train | epoch 004 | loss 10.195 | ppl 1172.24 | wps 37664.7 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 0.981 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 412
KL Stats: Epoch 4 Divergences: Uniform: 1.2786606283089719 Unigram: 0.23401401692276713
2022-03-23 11:44:50 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 11:44:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:45:19 | INFO | train_inner | epoch 005:     76 / 157 loss=10.145, ppl=1132.5, wps=29615.4, ups=1.21, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.116, loss_scale=8, train_wall=37, gb_free=11.5, wall=442
2022-03-23 11:45:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:45:54 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be in the world in the world, and we're in the world.
2022-03-23 11:45:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:45:59 | INFO | fairseq.tasks.translation | example hypothesis: and this is the
2022-03-23 11:45:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:46:03 | INFO | fairseq.tasks.translation | example hypothesis: so, we're a
2022-03-23 11:46:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:46:08 | INFO | fairseq.tasks.translation | example hypothesis: and there's a
2022-03-23 11:46:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:46:12 | INFO | fairseq.tasks.translation | example hypothesis: and it's what we're not not not not not not not not not going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do it
2022-03-23 11:46:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:46:17 | INFO | fairseq.tasks.translation | example hypothesis: and this is in the
2022-03-23 11:46:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:46:21 | INFO | fairseq.tasks.translation | example hypothesis: but they're not not not not not a lot of the
2022-03-23 11:46:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:46:25 | INFO | fairseq.tasks.translation | example hypothesis: and we have to have the world of the
2022-03-23 11:46:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:46:30 | INFO | fairseq.tasks.translation | example hypothesis: and this is, "" "" "" the first, "" "the," this is the "" "the" this is the first, "" "" "" the "" "" "" "" "" "" "" this is the, "" "this is the," "" "" this is, "" "the" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" this is the, "" "" the first first first, "this is the first first first," this is the first first, "this is the" "" "" "this is," this is the "" "" "" "" "" "" "" ""
2022-03-23 11:46:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:46:32 | INFO | fairseq.tasks.translation | example hypothesis: and we have to have to be the, and we have to have to be the, and we have the, and we have the first, and we have the first first, and we have the first, and we have the the first of the
2022-03-23 11:46:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:46:32 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.982 | ppl 2022.3 | bleu 1.78 | wps 4283.1 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.78
2022-03-23 11:46:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 11:46:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:46:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:46:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.78) (writing took 1.807643803069368 seconds)
2022-03-23 11:46:34 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 11:46:34 | INFO | train | epoch 005 | loss 9.979 | ppl 1009.43 | wps 37851.5 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.039 | loss_scale 8 | train_wall 59 | gb_free 12.3 | wall 517
KL Stats: Epoch 5 Divergences: Uniform: 1.3351447434598867 Unigram: 0.33279271653175385
2022-03-23 11:46:34 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 11:46:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:46:41 | INFO | train_inner | epoch 006:     19 / 157 loss=9.848, ppl=921.6, wps=30733.2, ups=1.21, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=1.023, loss_scale=8, train_wall=37, gb_free=12.7, wall=524
2022-03-23 11:47:19 | INFO | train_inner | epoch 006:    119 / 157 loss=9.785, ppl=882.15, wps=66879.9, ups=2.64, wpb=25320.5, bsz=1021.9, num_updates=900, lr=0.0001125, gnorm=0.98, loss_scale=8, train_wall=38, gb_free=11.9, wall=562
2022-03-23 11:47:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:47:37 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 11:47:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:47:41 | INFO | fairseq.tasks.translation | example hypothesis: this is that's the.
2022-03-23 11:47:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:47:46 | INFO | fairseq.tasks.translation | example hypothesis: we're going to have to be a new new, and two.
2022-03-23 11:47:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:47:51 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of, there's a lot of, and there's a, there's a lot of, and there's, there's a lot of, and there's, and there's a
2022-03-23 11:47:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:47:56 | INFO | fairseq.tasks.translation | example hypothesis: and it's what we're going to do that we're going to do it, and it's going to do it's going to do it, and it's going to do that we're going to do it.
2022-03-23 11:47:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:48:02 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of the world, and in the world, and in the world, and in the world, and in the world, and in the world, and in the world, in the world, in the world, and the world.
2022-03-23 11:48:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:48:07 | INFO | fairseq.tasks.translation | example hypothesis: but they're going to see, but they're going to be a lot of the, but they're going to be a lot of the, but they're going to be, but they're going to be, but they're going to be a lot of the, but they're going to be, but they're not going to be, but they're
2022-03-23 11:48:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:48:13 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to see, and we're going to see, and we're going to see the world, and we can see, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we can see the world, and we're going to see the world, and we're going to see the world, and we're going to see the, and we can see the
2022-03-23 11:48:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:48:21 | INFO | fairseq.tasks.translation | example hypothesis: and, "," i'm going to say, "you know," you know, "you know," you know, "it's," it's going to say, "you know," it's, "," we're going to say, "it's a,", "," it's, ",", "it's,", ",", "," it's going to say, "it's a," it's, ",", "," we're a, "," it's, ",", "it's going to say," it's, ",", "," it's, ",", "it's,", ",", ",", ",", ",", "we're a," "" "" "" "" ""
2022-03-23 11:48:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:48:23 | INFO | fairseq.tasks.translation | example hypothesis: so, we've been a, that we're going to be a lot of the, and that we're going to see the, and that we're going to be a, and we're going to be, and we're going to be a, the, the, the, the, the, the, the, the, the, the, the, the, the, that we have to be a, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, we have to be, that we have to be, that we have to be, that we have to be, that we have to be, that we have to be, that we have to be, that we have to be, that we have to do that we have to be, and we've've been been been been been been been been been been been been been been been been
2022-03-23 11:48:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:48:23 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.741 | ppl 1712.02 | bleu 1.73 | wps 3573.9 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.78
2022-03-23 11:48:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 11:48:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 11:48:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 11:48:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 6 @ 938 updates, score 1.73) (writing took 0.8153551931027323 seconds)
2022-03-23 11:48:24 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 11:48:24 | INFO | train | epoch 006 | loss 9.797 | ppl 889.33 | wps 35920.6 | ups 1.43 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 0.987 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 627
KL Stats: Epoch 6 Divergences: Uniform: 1.3940983370045474 Unigram: 0.41125564856678615
2022-03-23 11:48:24 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 11:48:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:48:48 | INFO | train_inner | epoch 007:     62 / 157 loss=9.696, ppl=829.32, wps=28458.5, ups=1.13, wpb=25195.5, bsz=1022.5, num_updates=1000, lr=0.000125, gnorm=0.883, loss_scale=8, train_wall=37, gb_free=11.6, wall=650
2022-03-23 11:49:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:49:27 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 11:49:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:49:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the.
2022-03-23 11:49:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:49:35 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to be a new new new new new new new new new new.
2022-03-23 11:49:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:49:40 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of, and there's a lot of, there's a lot of.
2022-03-23 11:49:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:49:44 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're going to do, and it's going to do that we're going to do it, and it's going to do it's not not not not not not not not a lot of the world.
2022-03-23 11:49:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:49:49 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, for the people who are a lot of people in the people in the world, for the people for the people.
2022-03-23 11:49:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:49:54 | INFO | fairseq.tasks.translation | example hypothesis: but there are a lot of, you're going to see, but you're going to see, and they're going to get a lot of the.
2022-03-23 11:49:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:50:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to get a lot of the, and we can see that we can see that we're going to be a lot of the world.
2022-03-23 11:50:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:50:06 | INFO | fairseq.tasks.translation | example hypothesis: you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know,"
2022-03-23 11:50:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:50:08 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to be a lot of the world that we're going to be a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is, and it's a lot of the world, which is a lot of the world, which is a lot of the world, and it's a lot of the world, which is a lot of the world, and we're going to be a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, and we're going to
2022-03-23 11:50:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:50:08 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.605 | ppl 1557.67 | bleu 2.64 | wps 4046.5 | wpb 17862.2 | bsz 728.3 | num_updates 1095 | best_bleu 2.64
2022-03-23 11:50:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1095 updates
2022-03-23 11:50:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:50:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:50:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 7 @ 1095 updates, score 2.64) (writing took 1.8281884980387986 seconds)
2022-03-23 11:50:10 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 11:50:10 | INFO | train | epoch 007 | loss 9.624 | ppl 788.81 | wps 37312 | ups 1.48 | wpb 25153.6 | bsz 1020.6 | num_updates 1095 | lr 0.000136875 | gnorm 0.92 | loss_scale 8 | train_wall 58 | gb_free 12.6 | wall 732
KL Stats: Epoch 7 Divergences: Uniform: 1.4334857292896785 Unigram: 0.47351895128454546
2022-03-23 11:50:10 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 11:50:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:50:12 | INFO | train_inner | epoch 008:      5 / 157 loss=9.618, ppl=785.89, wps=29644.1, ups=1.19, wpb=25002.6, bsz=1042.3, num_updates=1100, lr=0.0001375, gnorm=0.908, loss_scale=8, train_wall=37, gb_free=12, wall=735
2022-03-23 11:50:50 | INFO | train_inner | epoch 008:    105 / 157 loss=9.443, ppl=696.01, wps=66742.9, ups=2.66, wpb=25137.5, bsz=1075.3, num_updates=1200, lr=0.00015, gnorm=0.91, loss_scale=8, train_wall=37, gb_free=12.3, wall=772
2022-03-23 11:51:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:51:13 | INFO | fairseq.tasks.translation | example hypothesis: we've got this.
2022-03-23 11:51:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:51:18 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most of the most most most of the most most most most of the most most most most of the most most most most of the
2022-03-23 11:51:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:51:22 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new new new new new new new new new new new new.
2022-03-23 11:51:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:51:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's a
2022-03-23 11:51:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:51:32 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're going to do it, and we're going to do it, and we're going to do that we're going to do it.
2022-03-23 11:51:32 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:51:37 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the in the people who are in the people in the people in the people in the people in the people in the people in the people in the people who have to get for the people in the people in the people in the people for the people.
2022-03-23 11:51:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:51:42 | INFO | fairseq.tasks.translation | example hypothesis: well, some of some of these are, but they're going to get a lot of, but it, but it's not not, but it's not, but it's not, but it's not, but it's a lot of, but it's not, but it's not, but it's not, but it's the same.
2022-03-23 11:51:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:51:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the, and we can see that we can see that we can see that we can see the, we can see that we can see that we can see that we can see that we can see the
2022-03-23 11:51:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:51:55 | INFO | fairseq.tasks.translation | example hypothesis: "one:": "well," you know, "you know," it's a, "it's," it's a, "it's," it's a, "it's," it's a, "it's a," it's a, "and it's a," "" "" "and it's," it's a, "" it's a, "well," well, "well," "" "" "" "" "" "" "" "" "" "" and it's, "it's a," it's a, "" and it's a, "" "" "" "" "" it's a, "it's a," it's a, "it's a," "" "" and it's a, "" "" "" "" "
2022-03-23 11:51:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:51:57 | INFO | fairseq.tasks.translation | example hypothesis: and this is, if we're going to get a, and we're going to be a, and we're going to get a, and that we're going to get a, and we're going to get a, and we're going to get a, and we're going to get a, and we're going to see the, and we're going to see the, that we're going to see that we're going to see the, and the, that we're going to be a, and the, that we're going to get a, and the, that we're going to be a, and we're going to be a little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little, and we're going to see that we're going to see that we're going to see that we're going to see that we're going to get to get to see that we're going to see that we're going to get to see the
2022-03-23 11:51:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:51:57 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.438 | ppl 1387.23 | bleu 3.26 | wps 3722 | wpb 17862.2 | bsz 728.3 | num_updates 1252 | best_bleu 3.26
2022-03-23 11:51:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1252 updates
2022-03-23 11:51:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:51:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:51:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 8 @ 1252 updates, score 3.26) (writing took 1.8307424220256507 seconds)
2022-03-23 11:51:59 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 11:51:59 | INFO | train | epoch 008 | loss 9.482 | ppl 715.24 | wps 36101 | ups 1.44 | wpb 25153.6 | bsz 1020.6 | num_updates 1252 | lr 0.0001565 | gnorm 0.873 | loss_scale 8 | train_wall 58 | gb_free 11.7 | wall 842
KL Stats: Epoch 8 Divergences: Uniform: 1.473321951147413 Unigram: 0.518816558891091
2022-03-23 11:52:00 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 11:52:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:52:18 | INFO | train_inner | epoch 009:     48 / 157 loss=9.374, ppl=663.64, wps=29125.3, ups=1.13, wpb=25702.9, bsz=1011, num_updates=1300, lr=0.0001625, gnorm=0.796, loss_scale=8, train_wall=37, gb_free=12.6, wall=861
2022-03-23 11:52:56 | INFO | train_inner | epoch 009:    148 / 157 loss=9.37, ppl=661.85, wps=66050.3, ups=2.67, wpb=24780.2, bsz=958.6, num_updates=1400, lr=0.000175, gnorm=0.818, loss_scale=8, train_wall=37, gb_free=11.9, wall=898
2022-03-23 11:52:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:53:03 | INFO | fairseq.tasks.translation | example hypothesis: we've got these in this room.
2022-03-23 11:53:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:53:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most most of the most most of the most of the most of the most most most.
2022-03-23 11:53:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:53:11 | INFO | fairseq.tasks.translation | example hypothesis: these are going to new new new new new new new new new new new new new new new new new.
2022-03-23 11:53:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:53:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a
2022-03-23 11:53:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:53:20 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that we're going to do a few years, and what's going to do.
2022-03-23 11:53:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:53:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the middle of people like the people for people who have been for people in the people, and it's a lot of people.
2022-03-23 11:53:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:53:30 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some of the.
2022-03-23 11:53:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:53:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information that we can see the world, and we can see that we can see the brain, and we can see that we can see the brain, and then we can see the brain, and we can see the brain.
2022-03-23 11:53:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:53:41 | INFO | fairseq.tasks.translation | example hypothesis: : yeah, it's a lot of you know, "it says," well, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," well, "well," well, "well," well, "you know," you know, "you know," well, "well," well, "well," well, "you know," well, "you know," you know, "well," well, "well," you know, "you know," you know, "well," you know, "you know," you know, "you know," well, "you know," well, "well," well, "you know," you know, "you know," you know, "
2022-03-23 11:53:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:53:44 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's still still still still still, and if we're going to be a lot of the world, if we're going to be a lot of the world that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a
2022-03-23 11:53:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:53:44 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.214 | ppl 1187.72 | bleu 5.34 | wps 4005.8 | wpb 17862.2 | bsz 728.3 | num_updates 1409 | best_bleu 5.34
2022-03-23 11:53:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1409 updates
2022-03-23 11:53:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:53:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:53:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 9 @ 1409 updates, score 5.34) (writing took 1.8071733647957444 seconds)
2022-03-23 11:53:45 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 11:53:45 | INFO | train | epoch 009 | loss 9.319 | ppl 638.49 | wps 37144 | ups 1.48 | wpb 25153.6 | bsz 1020.6 | num_updates 1409 | lr 0.000176125 | gnorm 0.797 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 948
KL Stats: Epoch 9 Divergences: Uniform: 1.5109914216893596 Unigram: 0.5643361606368947
2022-03-23 11:53:46 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 11:53:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:54:21 | INFO | train_inner | epoch 010:     91 / 157 loss=9.235, ppl=602.39, wps=29586.3, ups=1.18, wpb=25166.5, bsz=1026, num_updates=1500, lr=0.0001875, gnorm=0.77, loss_scale=8, train_wall=37, gb_free=12.6, wall=983
2022-03-23 11:54:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 11:54:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:54:49 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 11:54:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:54:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the.
2022-03-23 11:54:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:54:56 | INFO | fairseq.tasks.translation | example hypothesis: these are going to new new new new new new new new new new.
2022-03-23 11:54:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:54:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a.
2022-03-23 11:54:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:55:03 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just just just just a few years, and what's going to do.
2022-03-23 11:55:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:55:07 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, how people have to make people for people for the
2022-03-23 11:55:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:55:11 | INFO | fairseq.tasks.translation | example hypothesis: first of some of the
2022-03-23 11:55:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:55:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information, we can use this.
2022-03-23 11:55:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:55:20 | INFO | fairseq.tasks.translation | example hypothesis: rb: one of the reasons, and it's interesting, and it's interesting, and it's very interesting for me, and it's going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be
2022-03-23 11:55:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:55:23 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's always always always always a lot of the time, and the time, and if we're going to be a lot of our work, if we're going to get a lot of our work, if we're going to get a lot of our brain, if we're going to be able to be able to get a lot of our brain, if we're going to be able to get a lot of our work, if we're going to be able to get a lot of our work, if we're going to be a lot of the world, if we're going to get a lot of our work, and we're going to be able to get a lot of the brain, if we're going to be able to get a lot of our work, and we're going to be a lot of the system, if we're going to be able to get a lot of our work, if we're going to be able to be able to be able to get a lot of the world, if we're going to be able to
2022-03-23 11:55:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:55:23 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.091 | ppl 1090.74 | bleu 6 | wps 4845.7 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 6
2022-03-23 11:55:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 11:55:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:55:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:55:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 6.0) (writing took 1.7933110010344535 seconds)
2022-03-23 11:55:24 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 11:55:24 | INFO | train | epoch 010 | loss 9.165 | ppl 574.15 | wps 39627.8 | ups 1.58 | wpb 25127.3 | bsz 1014.9 | num_updates 1565 | lr 0.000195625 | gnorm 0.83 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1047
KL Stats: Epoch 10 Divergences: Uniform: 1.5569361430206972 Unigram: 0.6056333079694507
2022-03-23 11:55:25 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 11:55:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:55:38 | INFO | train_inner | epoch 011:     35 / 157 loss=9.148, ppl=567.48, wps=32010.1, ups=1.29, wpb=24781, bsz=994.3, num_updates=1600, lr=0.0002, gnorm=0.855, loss_scale=4, train_wall=37, gb_free=11.5, wall=1061
2022-03-23 11:56:16 | INFO | train_inner | epoch 011:    135 / 157 loss=8.828, ppl=454.31, wps=67354, ups=2.64, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=0.735, loss_scale=4, train_wall=38, gb_free=11.5, wall=1099
2022-03-23 11:56:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:56:28 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 11:56:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:56:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of, most of most of most of most of the most of the most of the most of you know.
2022-03-23 11:56:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:56:36 | INFO | fairseq.tasks.translation | example hypothesis: these are new. the new new new new new new new new new new.
2022-03-23 11:56:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:56:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a chinese chinese, where they're going to be, and they're going to be able to be able to be.
2022-03-23 11:56:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:56:44 | INFO | fairseq.tasks.translation | example hypothesis: it's not sure that we're not just just just a few of his head, and what's going to understand.
2022-03-23 11:56:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:56:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamase of people who have been working for the
2022-03-23 11:56:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:56:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you're going to go out of the, but if you don't need to use the energy, and if you need to use your energy, you need the energy.
2022-03-23 11:56:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:56:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can be able to be able to be able to be able to be able to create a structure of information, and the structure of the information.
2022-03-23 11:56:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:57:01 | INFO | fairseq.tasks.translation | example hypothesis: now, one of the reasons, and it's interesting for me, and i'm going to be able to be able to be able to say, "if we have a lot of women who said," oh, "oh," well, "well," well, "if we've got a lot of you know," well, we have to give you know, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well, we have to be a lot of you know, we have a lot of you know," well, "well," well, "well," well, "well," we have a lot of you know, we have a lot of
2022-03-23 11:57:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:57:03 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still still the mother, and we had a lot of work that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able.
2022-03-23 11:57:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:57:03 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.859 | ppl 928.91 | bleu 9.8 | wps 4742.7 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 9.8
2022-03-23 11:57:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 11:57:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:57:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:57:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 9.8) (writing took 1.8533092951402068 seconds)
2022-03-23 11:57:05 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 11:57:05 | INFO | train | epoch 011 | loss 8.968 | ppl 500.62 | wps 39403.3 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.746 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 1147
KL Stats: Epoch 11 Divergences: Uniform: 1.5929753132720674 Unigram: 0.6392519375665414
2022-03-23 11:57:05 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 11:57:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:57:35 | INFO | train_inner | epoch 012:     78 / 157 loss=8.898, ppl=477.04, wps=31835.5, ups=1.27, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=0.756, loss_scale=4, train_wall=37, gb_free=12.1, wall=1177
2022-03-23 11:58:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:58:08 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 11:58:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:58:12 | INFO | fairseq.tasks.translation | example hypothesis: and this is the right point of ha, most of most of most of the most.
2022-03-23 11:58:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:58:16 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be able to be able to get two new new new new york.
2022-03-23 11:58:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:58:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese, where you're going to get with your legs, and you're going.
2022-03-23 11:58:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:58:24 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just a few ways on the head of his head, and what's going on on on.
2022-03-23 11:58:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:58:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the mama
2022-03-23 11:58:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:58:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the
2022-03-23 11:58:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:58:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information from this information, we can get to a kind of structure, we can start to start with a different structure of the information, and the structure of the structure of the information, and the information that's all the information.
2022-03-23 11:58:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:58:42 | INFO | fairseq.tasks.translation | example hypothesis: now, one of the reasons, it's interesting to be interesting to be interesting for women, and then, "if we've got to say that it's a lot of women," if we're going to say, "well," if we're going to say, "well," if we're going to say, "well," well, "well," well, "if we're going to tell you're going to tell you know that it's a long time," well, "well," if we're going to tell you know, "well," well, "well," well, we've been working with you have a long time, "well," well, "well," well, "well," well, "well," well, "you have a lot of you have a lot of you've been working with you have a lot of
2022-03-23 11:58:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:58:44 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still still the mother, and we had to see a lot of work on the beginning that we had to be able to see that if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to look at a global global global global, or a huge, or a global, or a global, or a very, and we had to see that we had to see that we had to see that we had to see that we had to see that we had to be able to see that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that we had to be able to be able to be able to be able to be able to be able to see the
2022-03-23 11:58:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:58:44 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.656 | ppl 806.92 | bleu 11.39 | wps 4558.4 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 11.39
2022-03-23 11:58:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 11:58:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:58:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 11:58:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 11.39) (writing took 1.8097523029427975 seconds)
2022-03-23 11:58:46 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 11:58:46 | INFO | train | epoch 012 | loss 8.783 | ppl 440.47 | wps 38922.4 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.776 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 1249
KL Stats: Epoch 12 Divergences: Uniform: 1.6345651716077714 Unigram: 0.6662624942346879
2022-03-23 11:58:46 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 11:58:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:58:54 | INFO | train_inner | epoch 013:     21 / 157 loss=8.689, ppl=412.81, wps=31443.4, ups=1.25, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=0.829, loss_scale=4, train_wall=37, gb_free=12, wall=1257
2022-03-23 11:59:32 | INFO | train_inner | epoch 013:    121 / 157 loss=8.625, ppl=394.87, wps=66528, ups=2.63, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=0.74, loss_scale=4, train_wall=38, gb_free=11.7, wall=1295
2022-03-23 11:59:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:59:50 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppk in the clinic clinic.
2022-03-23 11:59:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:59:53 | INFO | fairseq.tasks.translation | example hypothesis: this is the car of doha, most of most of you know here.
2022-03-23 11:59:53 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:59:57 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to make new.
2022-03-23 11:59:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:00:01 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese, where you're going to get with your legs.
2022-03-23 12:00:01 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:00:05 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just a couple of electrop on his head, and what all of his thoughts are on.
2022-03-23 12:00:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:00:09 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamace of people who took the responsibility for the number of animals, and that's a number of animals in terms.
2022-03-23 12:00:09 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:00:13 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are some of the magic lines in the lines, but it doesn't have to move their energy energy, and if they need their energy energy.
2022-03-23 12:00:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:00:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information comes from this reflect, we can start with a traditional traditional form of the.
2022-03-23 12:00:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:00:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and interesting for me, "oh, you know, you know," yeah, it's the best thing to say, "if you've got to say," if you're working in this time. "
2022-03-23 12:00:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:00:22 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's true to the mother of the invention, and part of our work that we had to solve the airplane, and if we had to be a unique system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see it.
2022-03-23 12:00:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:00:22 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.503 | ppl 725.67 | bleu 13.27 | wps 5043.8 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 13.27
2022-03-23 12:00:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 12:00:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:00:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:00:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 13.27) (writing took 1.8255260379519314 seconds)
2022-03-23 12:00:24 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 12:00:24 | INFO | train | epoch 013 | loss 8.594 | ppl 386.29 | wps 40345.6 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.753 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 1347
KL Stats: Epoch 13 Divergences: Uniform: 1.681317612420184 Unigram: 0.6977303389498142
2022-03-23 12:00:24 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 12:00:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:00:49 | INFO | train_inner | epoch 014:     64 / 157 loss=8.505, ppl=363.4, wps=32743.3, ups=1.31, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=0.722, loss_scale=4, train_wall=37, gb_free=12.3, wall=1371
2022-03-23 12:01:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:01:27 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppppk in the clinics.
2022-03-23 12:01:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:01:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of the most of the most of the most of you know.
2022-03-23 12:01:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:01:36 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new.
2022-03-23 12:01:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:01:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where the legs are happy, and they're going.
2022-03-23 12:01:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:01:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electroelectrodes on his head and understand what all of the thoughts are.
2022-03-23 12:01:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:01:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamace of the responsibility for people, the responsibility grew up to the number of animals, and that has become a lot of.
2022-03-23 12:01:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:01:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are the magic of magnetic lines, but in the lines, but when they don't need the energy, and they need their energy.
2022-03-23 12:01:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:01:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information comes from this reflection, we can start with a traditional, we can start to start with a huge structure of information, and the whole structure.
2022-03-23 12:01:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:01:59 | INFO | fairseq.tasks.translation | example hypothesis: fifth: one of the reasons that it's interesting, and it's interesting for me to do, "oh, if you're going to say," if you have a
2022-03-23 12:01:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:02:00 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still the invention of the invention, and the invention of the design that we had to see that if we had to see a unique way to be able to see everything.
2022-03-23 12:02:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:02:00 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.4 | ppl 675.44 | bleu 15.36 | wps 5074.4 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 15.36
2022-03-23 12:02:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 12:02:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:02:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:02:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 15.36) (writing took 1.8503540209494531 seconds)
2022-03-23 12:02:02 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 12:02:02 | INFO | train | epoch 014 | loss 8.4 | ppl 337.68 | wps 40417.9 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.711 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1444
KL Stats: Epoch 14 Divergences: Uniform: 1.7309114447674996 Unigram: 0.720109905687564
2022-03-23 12:02:02 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 12:02:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:02:05 | INFO | train_inner | epoch 015:      7 / 157 loss=8.274, ppl=309.65, wps=33475.2, ups=1.31, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=0.675, loss_scale=4, train_wall=37, gb_free=12, wall=1448
2022-03-23 12:02:43 | INFO | train_inner | epoch 015:    107 / 157 loss=8.238, ppl=301.89, wps=66619.5, ups=2.65, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=0.744, loss_scale=4, train_wall=37, gb_free=12, wall=1485
2022-03-23 12:03:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:03:05 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppills in the clinic clinic clinic clinics.
2022-03-23 12:03:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:03:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of the most of you know.
2022-03-23 12:03:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:03:13 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new dins that are going to create two new.
2022-03-23 12:03:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:03:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese chinese food, where happy legs are, and they're going.
2022-03-23 12:03:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:03:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand what all of the thoughts are on his mind.
2022-03-23 12:03:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:03:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamammals like the responsibility of the responsibility, the number of animals grew up, and this is a number of animals in the way.
2022-03-23 12:03:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:03:31 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the magic lines in the field, but in the way, if you don't need to move it, you don't need your energy energy, you need your energy, and you need your energy.
2022-03-23 12:03:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:03:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflect reflection, we can start with a traditional view of traditional faces that are able to start able to start able to start able to start with the shape of the information, and the whole structure of the structure.
2022-03-23 12:03:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:03:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to do with ted-women -- that's the best time... "yeah, it's the best thing that somebody said," if we're going to support them, "and then we're going to support them."
2022-03-23 12:03:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:03:41 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's the need to see the mother, and one part of the design of our work on our airplane, we had to solve the plane, and if we had to solve a unique result, we had to solve a unique way to solve the ground of the ground.
2022-03-23 12:03:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:03:41 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.184 | ppl 581.51 | bleu 17.05 | wps 4572.4 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 17.05
2022-03-23 12:03:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 12:03:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:03:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:03:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 17.05) (writing took 1.8443303529638797 seconds)
2022-03-23 12:03:43 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 12:03:43 | INFO | train | epoch 015 | loss 8.251 | ppl 304.75 | wps 38925.3 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.718 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1546
KL Stats: Epoch 15 Divergences: Uniform: 1.774173150616805 Unigram: 0.7368911420980497
2022-03-23 12:03:43 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 12:03:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:04:03 | INFO | train_inner | epoch 016:     50 / 157 loss=8.181, ppl=290.28, wps=31678.6, ups=1.25, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=0.691, loss_scale=4, train_wall=37, gb_free=12.4, wall=1566
2022-03-23 12:04:40 | INFO | train_inner | epoch 016:    150 / 157 loss=8.152, ppl=284.46, wps=66035, ups=2.68, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.653, loss_scale=4, train_wall=37, gb_free=12.6, wall=1603
2022-03-23 12:04:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:04:47 | INFO | fairseq.tasks.translation | example hypothesis: we did these pills in the clinic clinics.
2022-03-23 12:04:47 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:04:51 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha.
2022-03-23 12:04:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:04:54 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create the new dinburgh.
2022-03-23 12:04:54 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:04:58 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where happy legs will be.
2022-03-23 12:04:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:05:01 | INFO | fairseq.tasks.translation | example hypothesis: it's not just a few electroelectrodes on his head and understand what all of the thoughts are on his mind.
2022-03-23 12:05:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:05:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals of responsibility, the number of animals grew up, and this is the number of animals.
2022-03-23 12:05:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:05:09 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic lines in the field, but the sulungs don't move, if they don't need their energy, they don't need their energy, and they need their energy.
2022-03-23 12:05:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:05:13 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use information from this reflection, we can start with a traditional face that can begin to start with a traditional face of the face of the face of the face of the face of the face, and there's the face of the information that's a whole structure.
2022-03-23 12:05:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:05:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that we have interesting and measure for me to be here. "
2022-03-23 12:05:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:05:17 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention and a big design that we're going to use on the plane, which was a lot of the plane that we had to solve a result that we had to solve a unique result that we had to solve it.
2022-03-23 12:05:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:05:17 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.138 | ppl 563.45 | bleu 13.26 | wps 5379.1 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 17.05
2022-03-23 12:05:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 12:05:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:05:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:05:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 13.26) (writing took 0.7695804920513183 seconds)
2022-03-23 12:05:18 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 12:05:18 | INFO | train | epoch 016 | loss 8.095 | ppl 273.48 | wps 41574.5 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.683 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 1641
KL Stats: Epoch 16 Divergences: Uniform: 1.8155170255240733 Unigram: 0.7569342087993582
2022-03-23 12:05:18 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 12:05:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:05:54 | INFO | train_inner | epoch 017:     93 / 157 loss=7.98, ppl=252.52, wps=34407.5, ups=1.36, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=0.683, loss_scale=4, train_wall=37, gb_free=13.1, wall=1676
2022-03-23 12:06:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:06:22 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic clinic in the clinic clinic.
2022-03-23 12:06:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:06:26 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably the most of you know.
2022-03-23 12:06:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:06:31 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golf locks that are going to create the two new picks.
2022-03-23 12:06:31 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:06:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are going to be, and salt with salt.
2022-03-23 12:06:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:06:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on the head of his head, and understand what all his thoughts are on the road.
2022-03-23 12:06:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:06:43 | INFO | fairseq.tasks.translation | example hypothesis: and in the ma, like the responsibility for the wild, the number of wild animals grew up, and that's become a foundation in namibia in namibia.
2022-03-23 12:06:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:06:48 | INFO | fairseq.tasks.translation | example hypothesis: first of first, some of the magnetic field of magnetic field, but the superconductor may not move, and if you need to move your energy, you need to move up, and you need some of the sucks.
2022-03-23 12:06:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:06:53 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face of the face of the face of the, and the shape of the information, and the whole structure of the information that we're using it all the structure of the structure, and all the structure of the structure of the structure.
2022-03-23 12:06:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:06:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it interesting for me to be in tedwomen, "that it was in the best way," and someone who said, "if we're going to support you."
2022-03-23 12:06:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:07:01 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, need to be the mother of the invention, and a big part of the design design work that we had to solve in our airplane, that we had to solve the problems that we had to solve the problems that we had to solve it, or if you can be connected to the ground of the ground, you can see everything that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 12:07:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:07:01 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.008 | ppl 515 | bleu 18.13 | wps 4227.4 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 18.13
2022-03-23 12:07:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 12:07:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:07:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:07:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 18.13) (writing took 1.7959388350136578 seconds)
2022-03-23 12:07:02 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 12:07:02 | INFO | train | epoch 017 | loss 7.978 | ppl 252.1 | wps 37856.9 | ups 1.51 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.676 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1745
KL Stats: Epoch 17 Divergences: Uniform: 1.8491152524909453 Unigram: 0.7694579266214588
2022-03-23 12:07:03 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 12:07:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:07:17 | INFO | train_inner | epoch 018:     36 / 157 loss=7.889, ppl=237.06, wps=30504.5, ups=1.21, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.672, loss_scale=4, train_wall=37, gb_free=12.5, wall=1759
2022-03-23 12:07:54 | INFO | train_inner | epoch 018:    136 / 157 loss=7.897, ppl=238.39, wps=65857.9, ups=2.65, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.593, loss_scale=4, train_wall=37, gb_free=12.3, wall=1797
2022-03-23 12:08:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:08:06 | INFO | fairseq.tasks.translation | example hypothesis: we did this pill in the clinic.
2022-03-23 12:08:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:08:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most familiar here.
2022-03-23 12:08:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:08:14 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldians that create the two new pigs.
2022-03-23 12:08:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:08:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food food, where happy legs are going to be salt with salce and fat.
2022-03-23 12:08:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:08:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electroelectrodes on his head, and understand exactly what all the thoughts of his thoughts are.
2022-03-23 12:08:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:08:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammers like the responsibility for the wild, the number of wild animals grew back, and this is a foundation for natural protection.
2022-03-23 12:08:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:08:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are blooded by magnetic field lines, but the susulal conductor doesn't like it, if they don't need their energy, they don't need their energy movements, and so they need the sulungs.
2022-03-23 12:08:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:08:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial facial face that can start with the great face of the face of the face, and the shape, and the shape of the information, the whole structure.
2022-03-23 12:08:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:08:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it for me to be in tedwomen, "is that there's a little bit of silence," and then, "then we've been in the best time to support you."
2022-03-23 12:08:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:08:41 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of the invention, and a big part of the design work that we're going to see in our airplane, is a result that we had to solve the unique problems that we had to solve it in the ground.
2022-03-23 12:08:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:08:41 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.811 | ppl 449.13 | bleu 21.38 | wps 4712.6 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 21.38
2022-03-23 12:08:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 12:08:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:08:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:08:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 21.38) (writing took 1.8133592680096626 seconds)
2022-03-23 12:08:42 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 12:08:42 | INFO | train | epoch 018 | loss 7.834 | ppl 228.24 | wps 39488.7 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.587 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1845
KL Stats: Epoch 18 Divergences: Uniform: 1.8782061235772087 Unigram: 0.7848080277388888
2022-03-23 12:08:43 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 12:08:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:09:13 | INFO | train_inner | epoch 019:     79 / 157 loss=7.738, ppl=213.44, wps=32487.5, ups=1.27, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.58, loss_scale=4, train_wall=38, gb_free=12.2, wall=1876
2022-03-23 12:09:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:09:46 | INFO | fairseq.tasks.translation | example hypothesis: we did this pink clinic in the clinic.
2022-03-23 12:09:46 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:09:50 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most familiar here.
2022-03-23 12:09:50 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:09:54 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that create two new pigs.
2022-03-23 12:09:54 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:09:58 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are, and puppet.
2022-03-23 12:09:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:10:02 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just get a few electrodes on his head and understand exactly what all of his thoughts are on the road.
2022-03-23 12:10:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:10:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals of people like the wild responsibility, the number of wild animals grew again, and this is a foundation of conservation in namibia.
2022-03-23 12:10:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:10:09 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines in the inner field, but the superconductor may not move when they need energy, and so the superconductor of the altitude of magnetic field.
2022-03-23 12:10:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:10:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of the face of the face, and the shape of the information that comes through the whole structure of information, which is the whole structure of these reflection, and the whole structure of these reflection, and we can fold all the structure of the structure, and we can fold.
2022-03-23 12:10:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:10:18 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me here at tedwomen, is that [[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[ano, [[[[[[[[[[[[[[[
2022-03-23 12:10:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:10:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work on our airplane was a result that we had to solve the unique problems in the ground -- it was connected to the ground -- all of us -- and a big part of us, which is that if you can use the power of the continents of the continents of the soil, it's a recycling system, or that we can be a, or that we can be, that we can be able to see that we can be able to use, and that we can be able to see that we can be able to see that we're either, and that it's a
2022-03-23 12:10:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:10:20 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.788 | ppl 441.91 | bleu 22.02 | wps 4746.5 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 22.02
2022-03-23 12:10:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 12:10:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:10:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:10:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 22.02) (writing took 1.8206429998390377 seconds)
2022-03-23 12:10:22 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 12:10:22 | INFO | train | epoch 019 | loss 7.711 | ppl 209.57 | wps 39625.9 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.582 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 1945
KL Stats: Epoch 19 Divergences: Uniform: 1.900065060573492 Unigram: 0.7982653915952206
2022-03-23 12:10:22 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 12:10:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:10:31 | INFO | train_inner | epoch 020:     22 / 157 loss=7.674, ppl=204.18, wps=31871, ups=1.29, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.552, loss_scale=4, train_wall=37, gb_free=12.8, wall=1954
2022-03-23 12:11:09 | INFO | train_inner | epoch 020:    122 / 157 loss=7.533, ppl=185.18, wps=67371.1, ups=2.6, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.518, loss_scale=4, train_wall=38, gb_free=11.8, wall=1992
2022-03-23 12:11:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:11:25 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:11:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:11:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably knows most of you here.
2022-03-23 12:11:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:11:34 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldians that create the two new pigs.
2022-03-23 12:11:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:11:38 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz legs and pills.
2022-03-23 12:11:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:11:42 | INFO | fairseq.tasks.translation | example hypothesis: it's clearly that we don't just bring a few electrodes on his head and understand exactly what all his thoughts are on the distance.
2022-03-23 12:11:42 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:11:46 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people of the wild responsibility, the number of wild animals grew up again, and that's a foundation for the natural conservation conservation in nambia.
2022-03-23 12:11:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:11:50 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic fields are caught in the inside the inner lines, but the sulalconductor doesn't like if they need their energy, and so the superconductor of magnetic field.
2022-03-23 12:11:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:11:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection, the big constructions of the face and the fundamental shape of the face, and through the information, which is the whole structure of this reflection, the whole structure of these reflection, the whole structure of these reflection of this reflection that comes from this reflection, the whole structure of these reflection of these reflection, and
2022-03-23 12:11:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:12:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here at tedwomen in tedwomen, is that... "yes, in the best time, when someone said," you're going to support the men on a table, "and the men in a table and measure it interesting interesting and measure it interesting interesting and measure it interesting and measure it interesting and measure it interesting," if the revolution starts to you know, "
2022-03-23 12:12:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:12:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're in our airplane, was a result that we had to solve the unique problems that were connected to the ground, and it was the the mother of the invention of the invention of the invention of the invention of the invention of the invention of the invention of the invention of the invention of design, and a big part of the design of the design of the design of the design, and a big part of the.
2022-03-23 12:12:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:12:02 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.732 | ppl 425.16 | bleu 23.26 | wps 4490 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 23.26
2022-03-23 12:12:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 12:12:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:12:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:12:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 23.26) (writing took 1.8010747712105513 seconds)
2022-03-23 12:12:04 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 12:12:04 | INFO | train | epoch 020 | loss 7.594 | ppl 193.22 | wps 38831.5 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.546 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 2046
KL Stats: Epoch 20 Divergences: Uniform: 1.9165036014584311 Unigram: 0.8079027520386567
2022-03-23 12:12:04 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 12:12:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:12:29 | INFO | train_inner | epoch 021:     65 / 157 loss=7.495, ppl=180.4, wps=31169.3, ups=1.25, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.563, loss_scale=4, train_wall=36, gb_free=12, wall=2072
2022-03-23 12:13:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:13:08 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic in the clinic.
2022-03-23 12:13:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:13:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of you know.
2022-03-23 12:13:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:13:16 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be new goldicks that create two new pigs.
2022-03-23 12:13:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:13:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pin.
2022-03-23 12:13:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:13:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a few electrodes on his head and understand what all of his thoughts on the road.
2022-03-23 12:13:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:13:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, people like responsibility for the wild animals, the number of wildlife animals, and this is a foundation of conservation in namibia.
2022-03-23 12:13:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:13:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some bber of magnetic field lines in the inside the inner field, but the superconductor doesn't like to move, because their energy needs, and so the superconductor of the superconductor of magnetic field, and the superconductor of magnetic fields in the inside the inside the inner field, but the superconductor.
2022-03-23 12:13:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:13:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of this reflection, we can start with a traditional facial facial facial face and the basic shape of the face, and the basic shape of the information, and through the one that information, which is the whole structure and fold all the structure.
2022-03-23 12:13:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:13:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measured for me to be here at tedwomen, is that... well, when, it was the best, when someone said, "you know," you know, you know, you know, the men on a table, and you know, if the revolution starts to support you. "
2022-03-23 12:13:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:13:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane, was a result of that, we had to solve the unique problems that were connected to the ground, so it was connected to surgery -- and everything from a continually variable system, and it allows us to be able to see that we're going to be able to be able to be able to see, or to use the engine.
2022-03-23 12:13:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:13:44 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.597 | ppl 387.23 | bleu 25.48 | wps 4508.1 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 25.48
2022-03-23 12:13:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 12:13:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:13:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:13:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 21 @ 3292 updates, score 25.48) (writing took 1.876887716818601 seconds)
2022-03-23 12:13:46 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 12:13:46 | INFO | train | epoch 021 | loss 7.513 | ppl 182.64 | wps 38652.4 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.531 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 2149
KL Stats: Epoch 21 Divergences: Uniform: 1.9309002133501203 Unigram: 0.8137114544619525
2022-03-23 12:13:46 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 12:13:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:13:50 | INFO | train_inner | epoch 022:      8 / 157 loss=7.605, ppl=194.63, wps=30806.9, ups=1.24, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.527, loss_scale=4, train_wall=37, gb_free=12, wall=2152
2022-03-23 12:14:27 | INFO | train_inner | epoch 022:    108 / 157 loss=7.527, ppl=184.38, wps=65816.4, ups=2.67, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.547, loss_scale=4, train_wall=37, gb_free=12, wall=2190
2022-03-23 12:14:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:14:50 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:14:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:14:53 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:14:53 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:14:57 | INFO | fairseq.tasks.translation | example hypothesis: stars are created new goldicks that are going to write two new pigs.
2022-03-23 12:14:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:15:01 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served and ppepful.
2022-03-23 12:15:01 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:15:05 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on his head and understanding what all his thoughts are on the track.
2022-03-23 12:15:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:15:09 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, people like the responsibility for the wild, grew up the number of wild animals, and this is a foundation for conservation in namibia.
2022-03-23 12:15:09 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:15:13 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are caught by magnetic field lines in the inside, but they don't like the superconductor when they're moving, and so the superconducting disorder.
2022-03-23 12:15:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:15:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial of the face and the elementary shape of the face, and the basic basic refold it through the sound of the ports that fold all the ports and fold a folding structure.
2022-03-23 12:15:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:15:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one
2022-03-23 12:15:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:15:23 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a big part of the design work that we're in our airplane, was a result that we had to solve the unique problems that were interconnected to the ground -- all of a continually variable system that allows us to refrigered, or that if you can see the refrigerators of a mechanism that allows us to refrigerators to use the aircraft, or the refrigerators to be a mechanism, or the refrigerated to be a mechanism, or the refrigerated to be able to be able to be able to be able to be able to use the refrigerated by a mechanism, or a mechanism, or the aircraft that if you can be able to use the refrigerated to be able to be able to be able to refrigerated to use the refrigerated to use the refrightened to be able to refrigerated to be able to use
2022-03-23 12:15:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:15:23 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.555 | ppl 376.12 | bleu 24.6 | wps 4841.1 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 25.48
2022-03-23 12:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 12:15:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:15:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:15:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 22 @ 3449 updates, score 24.6) (writing took 0.8428694349713624 seconds)
2022-03-23 12:15:24 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 12:15:24 | INFO | train | epoch 022 | loss 7.443 | ppl 173.96 | wps 40175.9 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.515 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2247
KL Stats: Epoch 22 Divergences: Uniform: 1.9363890243030049 Unigram: 0.8185486746552626
2022-03-23 12:15:25 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 12:15:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:15:44 | INFO | train_inner | epoch 023:     51 / 157 loss=7.401, ppl=168.98, wps=33079.9, ups=1.3, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.458, loss_scale=4, train_wall=37, gb_free=11.9, wall=2267
2022-03-23 12:16:22 | INFO | train_inner | epoch 023:    151 / 157 loss=7.248, ppl=152.03, wps=67474.4, ups=2.66, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.48, loss_scale=4, train_wall=37, gb_free=11.9, wall=2304
2022-03-23 12:16:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:16:28 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:16:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:16:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:16:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:16:36 | INFO | fairseq.tasks.translation | example hypothesis: stars become new golden locks that create the two new pigs.
2022-03-23 12:16:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:16:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:16:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:16:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:16:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:16:47 | INFO | fairseq.tasks.translation | example hypothesis: and this is a basis of conservation in namibia.
2022-03-23 12:16:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:16:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some bands of magnetic field are caught in the inside, but the supralegter doesn't like moving when they're moving.
2022-03-23 12:16:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:16:56 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial, the big configuration of the face and the basic basic reform, and through the basic basic reform of the entire portion, which is the whole portion of the entire portion and the entire portion.
2022-03-23 12:16:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:17:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measured to you here at tedwomen, is that... well, when the dinner dinner was the best dinner was put together, when somebody said, "turn you to the men on a table and say," turn you to the men on a table. "
2022-03-23 12:17:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:17:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're in our plane, was a result that we had to solve the unique problems that we had to solve the unique problems that were connected to the unique problems that were interconnected to the ground, so that it was connected to the ground, to a refrigeration of a refrigeration, or the refrigeration of a refrigeration of the refrigeration of a refrigeration of a refrigeration of a refrigeration of the aircraft system that if we had to be able to be able to be able to be able to use to be able to be able to be able to use to use to be able to be able to be able to be able to be able to be able to use it to use the most specific, to use the, or to use the air, to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 12:17:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:17:03 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.528 | ppl 369.14 | bleu 25.9 | wps 4656.9 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 25.9
2022-03-23 12:17:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 12:17:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:17:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:17:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 25.9) (writing took 1.8253415098879486 seconds)
2022-03-23 12:17:05 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 12:17:05 | INFO | train | epoch 023 | loss 7.353 | ppl 163.53 | wps 39314.7 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.473 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2347
KL Stats: Epoch 23 Divergences: Uniform: 1.9434766612358936 Unigram: 0.8247788199143626
2022-03-23 12:17:05 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 12:17:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:17:41 | INFO | train_inner | epoch 024:     94 / 157 loss=7.365, ppl=164.88, wps=31550.8, ups=1.27, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.475, loss_scale=4, train_wall=37, gb_free=11.9, wall=2383
2022-03-23 12:18:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:18:08 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 12:18:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:18:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:18:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:18:16 | INFO | fairseq.tasks.translation | example hypothesis: stars become new goldilocks that create the two new pigs.
2022-03-23 12:18:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:18:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 12:18:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:18:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 12:18:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:18:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people responsibility for the wild, grew up the number of wild animals, and this is a foundation for conservation in namibia.
2022-03-23 12:18:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:18:32 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught in the inside, but the supralegter doesn't like if they move, because their movements need, and so the superconductor disorders.
2022-03-23 12:18:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:18:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big configurations of the face and the basic form, and through the theast of information that folds all the ports and fold.
2022-03-23 12:18:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:18:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it up and measured to me here at tedwomen, is that... tyes, it became best when someone said, "turn to the men on a table and say," then we're going to support them. "
2022-03-23 12:18:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:18:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we're in our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continually variable system that drives us from the aircraft and cooling the aircraft.
2022-03-23 12:18:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:18:40 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.447 | ppl 349.07 | bleu 27.41 | wps 5095.5 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.41
2022-03-23 12:18:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 12:18:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:18:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:18:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 27.41) (writing took 1.8013475560583174 seconds)
2022-03-23 12:18:42 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 12:18:42 | INFO | train | epoch 024 | loss 7.295 | ppl 157 | wps 40532.6 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.447 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2445
KL Stats: Epoch 24 Divergences: Uniform: 1.9504846303948926 Unigram: 0.8299553442745229
2022-03-23 12:18:42 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 12:18:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:18:57 | INFO | train_inner | epoch 025:     37 / 157 loss=7.175, ppl=144.46, wps=33609.3, ups=1.32, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.404, loss_scale=4, train_wall=37, gb_free=12.1, wall=2459
2022-03-23 12:19:34 | INFO | train_inner | epoch 025:    137 / 157 loss=7.266, ppl=153.89, wps=66265.2, ups=2.65, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.462, loss_scale=4, train_wall=37, gb_free=12, wall=2497
2022-03-23 12:19:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:19:45 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 12:19:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:19:50 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows most here.
2022-03-23 12:19:50 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:19:53 | INFO | fairseq.tasks.translation | example hypothesis: stars will be new goldilocks that are going to transcend two new pigs.
2022-03-23 12:19:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:19:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and psuitcase.
2022-03-23 12:19:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:20:01 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:20:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:20:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the makewise, people took responsibility for the wild animals, and that's a basis for conservation in namibia.
2022-03-23 12:20:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:20:09 | INFO | fairseq.tasks.translation | example hypothesis: first, some bars of magnetic field are caught in the inside, but the supraleiter doesn't like moving, because their movements need energy, and so the superconductor disorders.
2022-03-23 12:20:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:20:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial that gives the big configurations of the face and the basic shape, and the basic shape that the whole portion structure and all the folds.
2022-03-23 12:20:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:20:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it up and measured to me here at tedwomen is that... tyes, when someone said, "turn it up to a long time and tell you," then we've already been supporting the future. "
2022-03-23 12:20:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:20:18 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable variables and refrigeration system that allows us to refrigerate the aircraft.
2022-03-23 12:20:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:20:18 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.442 | ppl 347.88 | bleu 26.74 | wps 5160.8 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 27.41
2022-03-23 12:20:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 12:20:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:20:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:20:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 26.74) (writing took 0.8025704009924084 seconds)
2022-03-23 12:20:18 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 12:20:18 | INFO | train | epoch 025 | loss 7.238 | ppl 150.97 | wps 41042.4 | ups 1.63 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.445 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2541
KL Stats: Epoch 25 Divergences: Uniform: 1.9526187918261326 Unigram: 0.832127440993308
2022-03-23 12:20:19 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 12:20:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:20:49 | INFO | train_inner | epoch 026:     80 / 157 loss=7.147, ppl=141.75, wps=33971.2, ups=1.34, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.436, loss_scale=4, train_wall=37, gb_free=12.2, wall=2572
2022-03-23 12:21:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:21:22 | INFO | fairseq.tasks.translation | example hypothesis: we put these pietches in the clinic.
2022-03-23 12:21:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:21:26 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:21:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:21:30 | INFO | fairseq.tasks.translation | example hypothesis: stars will be new goldilocks that create two new pigs.
2022-03-23 12:21:30 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:21:34 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:21:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:21:38 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 12:21:38 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:21:42 | INFO | fairseq.tasks.translation | example hypothesis: and in the corn of how people took responsibility for the wild, the number of wildlife animals grew back, and this is a basis for conservation in namibia.
2022-03-23 12:21:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:21:46 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught in the inner, but the supraleiter doesn't like moving, because they use their energy, and so the superconducting disorder.
2022-03-23 12:21:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:21:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial that gives the big constructions of the face and the basic shape, and through the theft of information that the whole porting structure and all the fits.
2022-03-23 12:21:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:21:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate to be here at tedwomen, is that... tyes, it's been the best summarized when someone said, "turn you to the men in your table and say," if the revolution starts to support you. "the truth is that women, we've already been supported for you."
2022-03-23 12:21:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:21:56 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of the design work that we're on our airplane is the result that we had to solve the unique problems that were connected to operate in the ground -- everything from a continually variable system and refrigeration system that allows us to use liquid traffic, that it allows us to use, and it to use it to grow up to the
2022-03-23 12:21:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:21:56 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.31 | ppl 317.28 | bleu 29.58 | wps 4751 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 29.58
2022-03-23 12:21:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 12:21:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:21:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:21:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 29.58) (writing took 1.815262553980574 seconds)
2022-03-23 12:21:58 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 12:21:58 | INFO | train | epoch 026 | loss 7.189 | ppl 145.95 | wps 39545.4 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.438 | loss_scale 4 | train_wall 58 | gb_free 12.4 | wall 2641
KL Stats: Epoch 26 Divergences: Uniform: 1.95517641236192 Unigram: 0.8321581646510497
2022-03-23 12:21:59 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 12:21:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:22:08 | INFO | train_inner | epoch 027:     23 / 157 loss=7.208, ppl=147.82, wps=31809.4, ups=1.27, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.417, loss_scale=4, train_wall=37, gb_free=12.9, wall=2650
2022-03-23 12:22:45 | INFO | train_inner | epoch 027:    123 / 157 loss=7.149, ppl=141.95, wps=66543.6, ups=2.66, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.423, loss_scale=4, train_wall=37, gb_free=11.7, wall=2688
2022-03-23 12:22:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:23:02 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 12:23:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:23:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:23:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:23:10 | INFO | fairseq.tasks.translation | example hypothesis: stars will be new goldilocks that create two new pigs.
2022-03-23 12:23:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:23:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:23:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:23:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:23:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:23:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people responsibility for wildlife, the number of wildlife grew again, and this is a foundation for conservation in namibia.
2022-03-23 12:23:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:23:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught in the inside, but the superconductor doesn't like when you move, because your movements are using energy, and so the superconducting disorder.
2022-03-23 12:23:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:23:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that repeat the great constructions of the face and the basic shape, which is the whole portion structure.
2022-03-23 12:23:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:23:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate for me to be here at tedwomen is that... tyes, when somebody said, "turn to the men in your table and say," if the revolution is already supporting you for a long time, "the truth is that women are already supporting you,"
2022-03-23 12:23:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:23:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at the stumest toes, was a result that we had to do the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to see in the aircraft, that allows us to use the.
2022-03-23 12:23:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:23:36 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.342 | ppl 324.52 | bleu 28.93 | wps 4759.2 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.58
2022-03-23 12:23:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 12:23:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:23:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:23:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 27 @ 4234 updates, score 28.93) (writing took 0.8043654500506818 seconds)
2022-03-23 12:23:37 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 12:23:37 | INFO | train | epoch 027 | loss 7.135 | ppl 140.59 | wps 39954.7 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.412 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 2740
KL Stats: Epoch 27 Divergences: Uniform: 1.9580023228907648 Unigram: 0.838039093220504
2022-03-23 12:23:37 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 12:23:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:24:02 | INFO | train_inner | epoch 028:     66 / 157 loss=7.162, ppl=143.23, wps=32296.9, ups=1.3, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.405, loss_scale=4, train_wall=37, gb_free=12.8, wall=2765
2022-03-23 12:24:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:24:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepter in the clinic.
2022-03-23 12:24:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:24:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:24:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:24:48 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that are going to write two new pigs.
2022-03-23 12:24:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:24:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:24:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:24:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:24:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:25:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wild animals grew back again, and this is a basis for conservation in namibia.
2022-03-23 12:25:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:25:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught in the inside, but the superconductor doesn't like if they move, because their movements need energy, and so the superconductor disorders.
2022-03-23 12:25:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:25:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can begin to recover the big constructions of the face and the basic form, and through the one that information, which includes the whole portion structure and all the folds.
2022-03-23 12:25:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:25:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen, is that... tyes, when dinner was done best, when someone said, "turn to the men on your table and say," if the revolution starts to support you, "then we've already been supporting," the truth is that we've been supporting you for a long time. "
2022-03-23 12:25:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:25:14 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, and a big part of the design work that we're on our airplane on the crust, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to see in our aircraft, or if you can't see the
2022-03-23 12:25:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:25:14 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.268 | ppl 308.17 | bleu 30.3 | wps 4837 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.3
2022-03-23 12:25:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 12:25:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:25:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:25:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.3) (writing took 1.8023002950940281 seconds)
2022-03-23 12:25:16 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 12:25:16 | INFO | train | epoch 028 | loss 7.092 | ppl 136.41 | wps 39843.2 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.408 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 2839
KL Stats: Epoch 28 Divergences: Uniform: 1.9607982273112037 Unigram: 0.8387059813745382
2022-03-23 12:25:17 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 12:25:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:25:20 | INFO | train_inner | epoch 029:      9 / 157 loss=7.056, ppl=133.03, wps=32508, ups=1.29, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.428, loss_scale=4, train_wall=37, gb_free=11.8, wall=2843
2022-03-23 12:25:58 | INFO | train_inner | epoch 029:    109 / 157 loss=7.069, ppl=134.24, wps=66497.8, ups=2.65, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.388, loss_scale=4, train_wall=37, gb_free=11.7, wall=2880
2022-03-23 12:26:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:26:20 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:26:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:26:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of you know here.
2022-03-23 12:26:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:26:28 | INFO | fairseq.tasks.translation | example hypothesis: stars will be new goldilocks that will create two new pigs.
2022-03-23 12:26:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:26:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:26:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:26:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:26:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:26:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like the people for the wild, the number of wild animals grew back again, and that's become a foundation for conservation in namibia.
2022-03-23 12:26:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:26:44 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught in the inside, but the superconductor doesn't like when they move, because their movements are using their energy, and so the superconducting disorder.
2022-03-23 12:26:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:26:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial that gives the big configurations of the face and the basic shape, and through the theast of information that refuses the whole portion structure and all folds up a fold.
2022-03-23 12:26:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:26:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... tyes, when you were stripped together best, when someone said, "turn to the men on your table and tell you," if the revolution starts to support you. "
2022-03-23 12:26:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:26:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our airplane on the stest, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and a refrigerator system that allows us to see a mechanism, or if you're able to use the propmacy, or a mechanism that allows us to use the propelled by a mechanism, or if you're either you can see the propelled to use the propelled to use the propellers, or the, or the mechanism, all of a mechanism, all of a mechanism, all of a mechanism, all of a mechanism, until you can see the mechanism, all of a mechanism, or if you can see the promotors, until you can't see the mechanism, until you can see the mechanism.
2022-03-23 12:26:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:26:55 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.228 | ppl 299.83 | bleu 30.48 | wps 4652.5 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.48
2022-03-23 12:26:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 12:26:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:26:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:26:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.48) (writing took 1.8448647879995406 seconds)
2022-03-23 12:26:57 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 12:26:57 | INFO | train | epoch 029 | loss 7.052 | ppl 132.69 | wps 39255.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.398 | loss_scale 4 | train_wall 59 | gb_free 11.5 | wall 2939
KL Stats: Epoch 29 Divergences: Uniform: 1.9600228704561886 Unigram: 0.8383615685130975
2022-03-23 12:26:57 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 12:26:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:27:17 | INFO | train_inner | epoch 030:     52 / 157 loss=7.061, ppl=133.55, wps=31662.1, ups=1.26, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.391, loss_scale=4, train_wall=37, gb_free=12.1, wall=2960
2022-03-23 12:27:55 | INFO | train_inner | epoch 030:    152 / 157 loss=6.973, ppl=125.62, wps=67178.2, ups=2.65, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.342, loss_scale=4, train_wall=37, gb_free=12.9, wall=2997
2022-03-23 12:27:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:28:01 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:28:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:28:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:28:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:28:09 | INFO | fairseq.tasks.translation | example hypothesis: stars will be new goldilocks that will create two new pigs.
2022-03-23 12:28:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:28:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are served with salz and ppepper.
2022-03-23 12:28:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:28:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on your head and understanding exactly what all of its thoughts are on the track.
2022-03-23 12:28:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:28:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the, like people's responsibility for the wild, the number of wildlife animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 12:28:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:28:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught in the inner, but the superconductor doesn't like when they move, because their movements are using energy, and so the superconducting disorder.
2022-03-23 12:28:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:28:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big constructions of the face and the basic form of the face, and through the one that information that refuses all the ports structure and all the fits a fold.
2022-03-23 12:28:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:28:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... tyes, when dinner was stripped up best, when someone said, "turn to the men on your table and say," if the revolution starts to support you for a long time, we've already started with silly carried. "
2022-03-23 12:28:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:28:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we're on our aircraft was a result of that we had to solve the unique problems that were associated to operate it on the ground -- everything from a continuous variation and a refrigeration system that allows us to use in the aircraft until a particular solution.
2022-03-23 12:28:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:28:35 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.185 | ppl 290.99 | bleu 30.77 | wps 4859.3 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.77
2022-03-23 12:28:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 12:28:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:28:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:28:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.77) (writing took 1.8412951428908855 seconds)
2022-03-23 12:28:36 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 12:28:36 | INFO | train | epoch 030 | loss 6.996 | ppl 127.61 | wps 39645.9 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.354 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3039
KL Stats: Epoch 30 Divergences: Uniform: 1.9605097588731761 Unigram: 0.8410293514034087
2022-03-23 12:28:37 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 12:28:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:29:13 | INFO | train_inner | epoch 031:     95 / 157 loss=6.933, ppl=122.21, wps=32533, ups=1.27, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.389, loss_scale=4, train_wall=38, gb_free=11.7, wall=3076
2022-03-23 12:29:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:29:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:29:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:29:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most people know here.
2022-03-23 12:29:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:29:48 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to write two new pigs.
2022-03-23 12:29:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:29:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salt and ppesuitcase.
2022-03-23 12:29:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:29:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:29:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:30:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife animals grew back again, and that's become a foundation for conservation in namibia.
2022-03-23 12:30:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:30:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are caught inside, but the superconductor doesn't like it if you move, because you use your movements, and so the superconductor disorder.
2022-03-23 12:30:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:30:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which gives the big constructions of the face and restores the basic shape, and put it through the theft structure and all the fine folds.
2022-03-23 12:30:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:30:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it high-interesting and appropriate to me here at tedwomen is that... tyes, when you're striking dinner, it's been best summarized when someone said, "turn you to the men at your table and tell you," if the revolution begins to support you, then we support you. "the truth is that we've already been supporting you for this topic for a long time, we've been supporting you,"
2022-03-23 12:30:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:30:15 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of the design work that we're on our airplane on the stump, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable operating and a refrigerator system that allows us to use an aircraft in the aircraft, until you're either able to use the aircraft, or when you see the aircraft, you see the aircraft, you're going to be a mechanism, or if you're going to run the aircraft, you're either you're in a mechanism, you see the aircraft, you're going to the aircraft, you're in a mechanism, you're going to the aircraft, you're going to use a mechanism, you're going to go to the way, you're going to do it, you're going to be able to do it, you can see, you're going to use a mechanism, you
2022-03-23 12:30:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:30:15 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.182 | ppl 290.49 | bleu 31.65 | wps 4673.8 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.65
2022-03-23 12:30:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 12:30:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:30:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:30:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.65) (writing took 1.8627896388061345 seconds)
2022-03-23 12:30:17 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 12:30:17 | INFO | train | epoch 031 | loss 6.98 | ppl 126.22 | wps 39340.4 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.378 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3139
KL Stats: Epoch 31 Divergences: Uniform: 1.9586626634473978 Unigram: 0.8431681589032903
2022-03-23 12:30:17 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 12:30:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:30:32 | INFO | train_inner | epoch 032:     38 / 157 loss=6.99, ppl=127.08, wps=31658.2, ups=1.27, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.344, loss_scale=4, train_wall=37, gb_free=12.5, wall=3154
2022-03-23 12:31:10 | INFO | train_inner | epoch 032:    138 / 157 loss=6.899, ppl=119.37, wps=66894.6, ups=2.65, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.371, loss_scale=4, train_wall=37, gb_free=12.5, wall=3192
2022-03-23 12:31:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:31:20 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:31:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:31:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline that probably most of you know.
2022-03-23 12:31:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:31:28 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will be two new pigs.
2022-03-23 12:31:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:31:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salce and pills.
2022-03-23 12:31:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:31:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 12:31:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:31:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife animals grew back. and that's a basis for conservation in namibia.
2022-03-23 12:31:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:31:44 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are trapped inside, but the superconductor doesn't like moving, because their movements are using their energy, and so the superconductor disorders.
2022-03-23 12:31:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:31:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that gives the big constructions of the face and restores the basic shape, and puts it through the one that refers the whole porch structure and all the folds.
2022-03-23 12:31:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:31:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's interesting and appropriate to me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn to men on your table and say," if the revolution begins, we support you. '"the truth is that we've already supported you.
2022-03-23 12:31:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:31:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane is stumbling, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continually variable system with refrigeration that allows us to use an aircraft in the traffic and gogossip until a specialized drive, or if you're either the propellant, or you can see it's either the propelled to a particular vehicle, until you see it, you see it, you can see it, you can see it, you see it, you can see it, you can see it, you can see it in the propellyield, you can see it, you can see it, you can see it, you can see it, you can see it, you can see it, you can see it in the propellyield mechanism, you can see it, you can see it, you can
2022-03-23 12:31:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:31:55 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.21 | ppl 296.06 | bleu 31.02 | wps 4773.4 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.65
2022-03-23 12:31:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 12:31:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:31:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:31:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.02) (writing took 0.8728807978332043 seconds)
2022-03-23 12:31:55 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 12:31:55 | INFO | train | epoch 032 | loss 6.936 | ppl 122.47 | wps 40011.9 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.354 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 3238
KL Stats: Epoch 32 Divergences: Uniform: 1.9620143152610883 Unigram: 0.850024169828688
2022-03-23 12:31:56 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 12:31:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:32:27 | INFO | train_inner | epoch 033:     81 / 157 loss=6.917, ppl=120.86, wps=32537.9, ups=1.3, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.351, loss_scale=4, train_wall=37, gb_free=12.1, wall=3269
2022-03-23 12:32:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:32:59 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:32:59 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:33:03 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably know most of the people here.
2022-03-23 12:33:03 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:33:07 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks, the two new pigs are going to transcend.
2022-03-23 12:33:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:33:11 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:33:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:33:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of its thoughts are on the track.
2022-03-23 12:33:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:33:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of the people's responsibility for the wild, the number of wildlife animals grew back, and that's become a foundation for conservation in namibia.
2022-03-23 12:33:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:33:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are trapped inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconductor disrupts.
2022-03-23 12:33:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:33:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection from this reflection, we can start with a traditional facial can that restore the big constructures of the face and the basic shape, and recover it through the theft of information, which refers the whole porter structure and all the fine folds.
2022-03-23 12:33:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:33:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... tyes, in the striking dinner, it was best summarized when someone said, "turn you to the men on your table and say," if the revolution starts, we're supporting you, "the truth is that we've already been supporting you for a long time with raspring,"
2022-03-23 12:33:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:33:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our airplane is a result of that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation of the design process, and a cooling system, allowing us to stop a aircraft in the aircraft and a particular vehicle, or when you're going to be able to do it.
2022-03-23 12:33:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:33:34 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.123 | ppl 278.75 | bleu 32.53 | wps 4616.9 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.53
2022-03-23 12:33:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 12:33:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:33:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:33:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.53) (writing took 1.8326210861559957 seconds)
2022-03-23 12:33:36 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 12:33:36 | INFO | train | epoch 033 | loss 6.907 | ppl 120.02 | wps 39154.9 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.346 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 3339
KL Stats: Epoch 33 Divergences: Uniform: 1.961263405107054 Unigram: 0.8471471225663257
2022-03-23 12:33:37 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 12:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:33:46 | INFO | train_inner | epoch 034:     24 / 157 loss=6.931, ppl=122.02, wps=31621.4, ups=1.26, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.359, loss_scale=4, train_wall=37, gb_free=12, wall=3349
2022-03-23 12:34:24 | INFO | train_inner | epoch 034:    124 / 157 loss=6.879, ppl=117.7, wps=66587, ups=2.65, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.34, loss_scale=4, train_wall=37, gb_free=11.8, wall=3387
2022-03-23 12:34:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:34:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:34:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:34:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:34:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:34:48 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:34:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:34:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pepper.
2022-03-23 12:34:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:34:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 12:34:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:35:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wildlife, the number of wild animals grew back again, and that's become a foundation of conservation in namibia.
2022-03-23 12:35:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:35:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are captured in the inside, but the superconductor doesn't like moving, because their movements are using energy, and so the superconductor is disturbing.
2022-03-23 12:35:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:35:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection from this reflection, we can start with a traditional facial can, which gives the big contextures of the face and restores the basic shape, and through the one who refuses the whole porter structure and all the folds.
2022-03-23 12:35:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:35:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... well, when dinner was stripped, it was best summarized, when someone said, "turn to the men at your table and tell you," if the revolution begins, we support you. "the truth is that we've already supported you for a long time,"
2022-03-23 12:35:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:35:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're most proud of at our plane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable system, and a cooling system with fluid that allows us to use in the aircraft, until a specially, until you see the most specific vehicle, if you can see the flying mechanism, or if you're going to the car, if you're going to be able to see the most responsible for a particular vehicle, if you can see the security system, if you're going to see the most responsible for a flying mechanism, you're going to the security system.
2022-03-23 12:35:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:35:15 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.133 | ppl 280.76 | bleu 32.38 | wps 4660.8 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.53
2022-03-23 12:35:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 12:35:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:35:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:35:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 34 @ 5333 updates, score 32.38) (writing took 0.8144175061024725 seconds)
2022-03-23 12:35:16 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 12:35:16 | INFO | train | epoch 034 | loss 6.882 | ppl 117.93 | wps 39707.8 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.363 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 3438
KL Stats: Epoch 34 Divergences: Uniform: 1.9625500375489953 Unigram: 0.8479644716366034
2022-03-23 12:35:16 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 12:35:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:35:41 | INFO | train_inner | epoch 035:     67 / 157 loss=6.829, ppl=113.72, wps=32424.2, ups=1.29, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.361, loss_scale=4, train_wall=37, gb_free=12.9, wall=3464
2022-03-23 12:36:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:36:19 | INFO | fairseq.tasks.translation | example hypothesis: we put these pietters in the clinic.
2022-03-23 12:36:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:36:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:36:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:36:27 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks beds that will generate two new pigs.
2022-03-23 12:36:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:36:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salt and pepper.
2022-03-23 12:36:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:36:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:36:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:36:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wildlife, the number of wildlife animals grew back, and that's become a foundation for conservation in namibia.
2022-03-23 12:36:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:36:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field strands are trapped inside, but the superconductor doesn't like moving, because their movements are using energy, and so the superconductor.
2022-03-23 12:36:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:36:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection from this reflection, we can start with a traditional facial can start to restore the big constructions of the face and the basic shape, and through the thief information that refers the whole por-structure and all the fine folds.
2022-03-23 12:36:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:36:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here at tedwomen is that... tyes, when dinner was best summarized, when someone said, "turn you to the men on your table and say," if the revolution starts to support you. "the truth is that we've already supported you for a long time with silspring."
2022-03-23 12:36:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:36:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane is the result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously variable and a cooling system that allows us to use an aircraft in the traffic to a particular vehicle, or when you fly to the propeller, until you fly to the ground.
2022-03-23 12:36:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:36:53 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.107 | ppl 275.75 | bleu 32.42 | wps 4958.9 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.53
2022-03-23 12:36:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 12:36:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:36:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:36:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 35 @ 5490 updates, score 32.42) (writing took 0.8222713028080761 seconds)
2022-03-23 12:36:53 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 12:36:53 | INFO | train | epoch 035 | loss 6.852 | ppl 115.49 | wps 40460.9 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.331 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3536
KL Stats: Epoch 35 Divergences: Uniform: 1.9617469727462327 Unigram: 0.8515296384503993
2022-03-23 12:36:54 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 12:36:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:36:58 | INFO | train_inner | epoch 036:     10 / 157 loss=6.928, ppl=121.76, wps=32486.5, ups=1.3, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.318, loss_scale=4, train_wall=37, gb_free=12.8, wall=3541
2022-03-23 12:37:36 | INFO | train_inner | epoch 036:    110 / 157 loss=6.811, ppl=112.29, wps=66618.3, ups=2.63, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.328, loss_scale=4, train_wall=38, gb_free=12.9, wall=3579
2022-03-23 12:37:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:37:57 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 12:37:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:38:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:38:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:38:05 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks beds that will transcend two new pigs.
2022-03-23 12:38:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:38:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:38:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:38:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:38:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:38:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 12:38:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:38:21 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like it, if you move, because your movements use your energy, and so the superconductor disturbs.
2022-03-23 12:38:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:38:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can start with a traditional face that restore the big constructions of the face and the basic shape, and through the thief of the information that refers the whole porter structure and all the fine.
2022-03-23 12:38:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:38:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... tja, when i was striking dinner, it became best summarized when someone said, "turn to the men on your desk and tell you," 'if the revolution begins, "'" '"' the truth is that we already have supported you in this topic for a long time."
2022-03-23 12:38:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:38:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our airplane is staggering, which is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continual variables and a refrigerator system with fluid that allows us to use an aircraft in the closest, until a stop traffic, and a result of it was a little bit of a little bit of a trajectory that's a little bit of a rubbish that's a little bit of a rubbish that's a little bit like, until you see it, you can see it, until you can see it, you can see it, you can see, you know, you can see it, you can see it, you can see it, you know, you can see it, you can see, you can see, you can see, you know, you know, you know, and you can see,
2022-03-23 12:38:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:38:33 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.112 | ppl 276.65 | bleu 32.82 | wps 4585.8 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.82
2022-03-23 12:38:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 12:38:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:38:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:38:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.82) (writing took 1.9135730599518865 seconds)
2022-03-23 12:38:35 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 12:38:35 | INFO | train | epoch 036 | loss 6.84 | ppl 114.55 | wps 38860.3 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.363 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 3638
KL Stats: Epoch 36 Divergences: Uniform: 1.9641550239098913 Unigram: 0.8514429010199542
2022-03-23 12:38:35 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 12:38:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:38:56 | INFO | train_inner | epoch 037:     53 / 157 loss=6.716, ppl=105.16, wps=32124.6, ups=1.26, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.372, loss_scale=4, train_wall=37, gb_free=12.8, wall=3658
2022-03-23 12:39:33 | INFO | train_inner | epoch 037:    153 / 157 loss=6.915, ppl=120.7, wps=66183.6, ups=2.67, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.331, loss_scale=4, train_wall=37, gb_free=11.7, wall=3696
2022-03-23 12:39:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:39:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 12:39:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:39:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:39:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:39:46 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks beds that will transcend two new pigs.
2022-03-23 12:39:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:39:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:39:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:39:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of the thoughts are on the track.
2022-03-23 12:39:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:39:58 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots of how people have taken responsibility for the wildlife, the number of wildlife returned, and this has become a foundation for conservation in namibia.
2022-03-23 12:39:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:40:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field lines are trapped inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconductor disturbs.
2022-03-23 12:40:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:40:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructures of the face and the basic shape, and recover it through the thief information that refers the whole porch structure and all the fence.
2022-03-23 12:40:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:40:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to me here at tedwomen is that -- well, when the striking dinner was best summarized, when someone said, "turn you to the men on your table and say," if the revolution starts, we support you. "the truth is, women, we've already supported you at this topic for a long time, we've already supported you, and we've already supported you with raceo carbono carriage,"
2022-03-23 12:40:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:40:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on on our plane is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable system, and a cooling system with fluid, that allows us to use an aircraft on our airplane in the stumber traffic, until a specialist traffic, to a specialty, to a specialist vehicle vehicle vehicle mechanism, or a flying mechanism, if you can see it's all the way you can see it's connected to the vehicle vehicle vehicle vehicle mechanism, to the way you can run it is to the way you can see it is to the car deploy, or a car deployment, to the car deployment, if you can see it is that you can see it is that you can run it's all the same.
2022-03-23 12:40:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:40:14 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.084 | ppl 271.33 | bleu 33.11 | wps 4623.9 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 33.11
2022-03-23 12:40:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 12:40:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:40:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:40:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 33.11) (writing took 1.9233788051642478 seconds)
2022-03-23 12:40:16 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 12:40:16 | INFO | train | epoch 037 | loss 6.808 | ppl 112.04 | wps 39234.7 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.321 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 3738
KL Stats: Epoch 37 Divergences: Uniform: 1.9652614059789695 Unigram: 0.8547612783306029
2022-03-23 12:40:16 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 12:40:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:40:52 | INFO | train_inner | epoch 038:     96 / 157 loss=6.935, ppl=122.36, wps=30997.2, ups=1.26, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.321, loss_scale=4, train_wall=37, gb_free=12.6, wall=3775
2022-03-23 12:41:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:41:19 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters in the clinic.
2022-03-23 12:41:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:41:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:41:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:41:27 | INFO | fairseq.tasks.translation | example hypothesis: stars will be new goldilocks that will create two new pigs.
2022-03-23 12:41:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:41:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:41:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:41:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:41:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:41:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people have taken responsibility for wildlife, the number of wild animals grew back, and this has become a foundation for conservation in namibia.
2022-03-23 12:41:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:41:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy and disturb the superconductor.
2022-03-23 12:41:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:41:47 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape, and recover it through the one that refuses the whole porch structure and all the fine folds.
2022-03-23 12:41:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:41:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it
2022-03-23 12:41:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:41:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane on the stumble, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation of liquid, that allows us to use an aircraft in the aircraft in the stop and traffic to a particular vehicle, until we can either see the way that you can see the way that you can see the way that you can see the way that you can see the way that we're going to use the propelled to the propelled to see the ground, all the way that you can see the way that you can see, all the way that you can see, all the way that you can see the way that you can see, all the way that you can see the way that you can see the way that you can see the way that you can see in the way that you can see, all the way that you can see the way that you can see
2022-03-23 12:41:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:41:54 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.062 | ppl 267.25 | bleu 32.79 | wps 4712.6 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 33.11
2022-03-23 12:41:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 12:41:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:41:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:41:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 32.79) (writing took 0.8374571308959275 seconds)
2022-03-23 12:41:55 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 12:41:55 | INFO | train | epoch 038 | loss 6.791 | ppl 110.74 | wps 39910.7 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.329 | loss_scale 4 | train_wall 58 | gb_free 13.1 | wall 3837
KL Stats: Epoch 38 Divergences: Uniform: 1.964478560390502 Unigram: 0.8546910154484603
2022-03-23 12:41:55 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 12:41:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:42:10 | INFO | train_inner | epoch 039:     39 / 157 loss=6.57, ppl=94.99, wps=33581.8, ups=1.29, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.312, loss_scale=4, train_wall=37, gb_free=11.8, wall=3853
2022-03-23 12:42:48 | INFO | train_inner | epoch 039:    139 / 157 loss=6.83, ppl=113.76, wps=66110.1, ups=2.66, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.368, loss_scale=4, train_wall=37, gb_free=12.8, wall=3890
2022-03-23 12:42:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:42:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:42:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:43:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you know here.
2022-03-23 12:43:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:43:06 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:43:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:43:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:43:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:43:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:43:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:43:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the. it's like people's responsibility for wildlife, the number of wildlife animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 12:43:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:43:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconductor disrupts.
2022-03-23 12:43:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:43:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which restores the big contextures of the face and the basic shape, and recover it through the one that removes the whole porch structure and all the fine folds.
2022-03-23 12:43:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:43:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... well, when you're striking dinner, it's been best summarized when someone said, "turn to the men on your table and tell you," when the revolution begins, then we support you. "'the truth, love is that we've already supported you in this topic for a long time."
2022-03-23 12:43:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:43:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable, and a refrigerator system with fluid, that allows us to use an aircraft in the stop-go-traffic aircraft traffic, to a specially appropriate vehicle, or if you can see the car vehicle vehicle vehicle vehicle, to the ground.
2022-03-23 12:43:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:43:33 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.054 | ppl 265.71 | bleu 33.32 | wps 4685.3 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.32
2022-03-23 12:43:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 12:43:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:43:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:43:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 33.32) (writing took 1.8224806520156562 seconds)
2022-03-23 12:43:35 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 12:43:35 | INFO | train | epoch 039 | loss 6.774 | ppl 109.42 | wps 39402.5 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.337 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 3937
KL Stats: Epoch 39 Divergences: Uniform: 1.9646185865866725 Unigram: 0.8559957647795277
2022-03-23 12:43:35 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 12:43:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:44:06 | INFO | train_inner | epoch 040:     82 / 157 loss=6.826, ppl=113.49, wps=31511.4, ups=1.27, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.307, loss_scale=4, train_wall=37, gb_free=12.2, wall=3969
2022-03-23 12:44:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:44:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:44:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:44:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you know here.
2022-03-23 12:44:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:44:46 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to transcend two new pigs.
2022-03-23 12:44:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:44:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:44:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:44:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:44:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:44:58 | INFO | fairseq.tasks.translation | example hypothesis: and in the, like people's responsibility for wildlife revenues, the number of wild animals grew back, and that has become a foundation for conservation in namibia.
2022-03-23 12:44:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:45:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and that's how the superconductor disturbs.
2022-03-23 12:45:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:45:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that resembles the big constraints of the face and the basic shape, and recover it by the one who refuses the whole pore structure and all the fine folds.
2022-03-23 12:45:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:45:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when you're striking dinner, it was best summarized when someone said, "turn to men at your table and tell them, 'when the revolution begins, we support you," the truth is that we've already supported you for a long time. "
2022-03-23 12:45:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:45:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a large part of the design work that we're on our airplane is stumbling was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable, and a refrigerator system that allows us to use an aircraft in the stopand traffic to a particular vehicle.
2022-03-23 12:45:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:45:12 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.048 | ppl 264.71 | bleu 33.11 | wps 4918.7 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.32
2022-03-23 12:45:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 12:45:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:45:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:45:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 33.11) (writing took 0.8489185641519725 seconds)
2022-03-23 12:45:13 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 12:45:13 | INFO | train | epoch 040 | loss 6.75 | ppl 107.64 | wps 40427.7 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.32 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 4035
KL Stats: Epoch 40 Divergences: Uniform: 1.966852943066579 Unigram: 0.8579019831167483
2022-03-23 12:45:13 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 12:45:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:45:22 | INFO | train_inner | epoch 041:     25 / 157 loss=6.716, ppl=105.16, wps=33476, ups=1.31, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.326, loss_scale=4, train_wall=37, gb_free=12.6, wall=4045
2022-03-23 12:46:00 | INFO | train_inner | epoch 041:    125 / 157 loss=6.747, ppl=107.45, wps=65860.5, ups=2.64, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.327, loss_scale=4, train_wall=38, gb_free=12, wall=4083
2022-03-23 12:46:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:46:16 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 12:46:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:46:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:46:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:46:24 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of india that will transcend two new pigs.
2022-03-23 12:46:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:46:28 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 12:46:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:46:32 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on your head and understanding exactly what all of his thoughts are on the track.
2022-03-23 12:46:32 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:46:36 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife animals grew back, and that's become a foundation for conservation in namibia.
2022-03-23 12:46:36 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:46:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like moving because their movements use energy, and so the superconductor disrupts.
2022-03-23 12:46:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:46:44 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructures of the face and restore the basic shape, and through the one that information that refers the whole porch structure and all the fine folds.
2022-03-23 12:46:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:46:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to me here at tedwomen is that... well, when i was striking dinner, it was best summarized when someone said, "turn to the men on your table and tell them," if the revolution starts, then we support you. "the truth, women love, is that we've already supported you for a long time."
2022-03-23 12:46:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:46:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a large part of the design work that we're on on our airplane is a result of the fact that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation, and a refrigerator system that allows us to use an aircraft in the stop-go-traffic, to a specially appropriate vehicle, to a specially appropriate driver's flight, or when you fly it's all the way to the ground, all the way to the way to the way you see it's a plane, all the way to the way you see it's going to the way you can see it's going to the way you can see it's going to the way you can see it, all the way you fly in the way you can see it, all the way you fly in the way you can see it, all the way, all the way, all the way, all the way, all the way, all the
2022-03-23 12:46:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:46:51 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.035 | ppl 262.21 | bleu 33.65 | wps 4667.5 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.65
2022-03-23 12:46:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 12:46:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:46:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:46:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 33.65) (writing took 1.891089488985017 seconds)
2022-03-23 12:46:53 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 12:46:53 | INFO | train | epoch 041 | loss 6.735 | ppl 106.52 | wps 39251.3 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.318 | loss_scale 4 | train_wall 59 | gb_free 11.7 | wall 4136
KL Stats: Epoch 41 Divergences: Uniform: 1.9645195266333746 Unigram: 0.8586517612601623
2022-03-23 12:46:53 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 12:46:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:47:19 | INFO | train_inner | epoch 042:     68 / 157 loss=6.694, ppl=103.56, wps=31861.9, ups=1.27, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.309, loss_scale=4, train_wall=37, gb_free=22.3, wall=4162
2022-03-23 12:47:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:47:57 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pietters in the clinic.
2022-03-23 12:47:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:48:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:48:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:48:04 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks.
2022-03-23 12:48:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:48:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-23 12:48:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:48:12 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:48:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:48:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the, like people's responsibility for wildlife revenues, the number of wildlife animals grew up again, and this has become a foundation for conservation in namibia.
2022-03-23 12:48:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:48:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like when they move, because their movements are using energy, and so the superconductor disrupts.
2022-03-23 12:48:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:48:25 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape, and the information that the whole por-structure and all the fine folds.
2022-03-23 12:48:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:48:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to me here at tedwomen is that... well, when dinner is best summarized, when someone said, "turn to men at your table and tell them," when the revolution begins, we support you. 'the truth is that we've already supported you at this topic for a long time. carchel. "
2022-03-23 12:48:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:48:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we're on on on our airplane is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable drivers and a cooling system with liquid fluid that allows us to use an aircraft in the stop-go-traffic, to a particular bicycle, to either fly the ground, all the way down to the air, or if you look at the aircraft, to the ground, to the aircraft.
2022-03-23 12:48:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:48:31 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.035 | ppl 262.23 | bleu 33.43 | wps 4754.9 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.65
2022-03-23 12:48:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 12:48:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:48:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:48:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 42 @ 6589 updates, score 33.43) (writing took 0.8270301178563386 seconds)
2022-03-23 12:48:32 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 12:48:32 | INFO | train | epoch 042 | loss 6.714 | ppl 104.96 | wps 39995.9 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.308 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 4234
KL Stats: Epoch 42 Divergences: Uniform: 1.9655043856335461 Unigram: 0.8606982132774211
2022-03-23 12:48:32 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 12:48:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:48:37 | INFO | train_inner | epoch 043:     11 / 157 loss=6.678, ppl=102.4, wps=32976.1, ups=1.29, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.298, loss_scale=4, train_wall=37, gb_free=12.1, wall=4239
2022-03-23 12:49:14 | INFO | train_inner | epoch 043:    111 / 157 loss=6.737, ppl=106.65, wps=66139.2, ups=2.66, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.318, loss_scale=4, train_wall=37, gb_free=11.9, wall=4277
2022-03-23 12:49:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:49:35 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beetles in the clinic.
2022-03-23 12:49:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:49:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you know here.
2022-03-23 12:49:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:49:43 | INFO | fairseq.tasks.translation | example hypothesis: stars will be new goldilocks beds that will create two new pigs.
2022-03-23 12:49:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:49:47 | INFO | fairseq.tasks.translation | example hypothesis: for instance, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:49:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:49:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:49:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:49:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for wildlife revenues, the number of wildlife animals grew back, and that has become a basis for conservation in namibia.
2022-03-23 12:49:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:49:59 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are captured inside, but the superconductor doesn't like moving, because their movements use energy and disturb the superconductor.
2022-03-23 12:49:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:50:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constructions of the face and the basic shape, and recovers it through the one that refuses the whole porch structure and all the fine folds.
2022-03-23 12:50:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:50:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to me here at tedwomen is that... well, when teen dinner was best summarized, when someone said, "turn to the men at your table and tell them," when the revolution starts to support you. "the truth, love is that we've already been supporting you with this topic for a long time.
2022-03-23 12:50:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:50:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still necessary, and a large part of the design work that we're on on on on our airplane on the most staggering toe was a result of that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable drive and a refrigerator system that allows us to use an aircraft in the stop-traffic to a specially appropriate vehicle, or if you run the propelled, or if you look at the soil, all the mechanism, all the way down to the way you can see the way you can see it's going to the vehicle vehicle vehicle vehicle vehicle vehicle vehicle, to the same.
2022-03-23 12:50:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:50:10 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.038 | ppl 262.82 | bleu 33.87 | wps 4704 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.87
2022-03-23 12:50:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 12:50:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:50:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:50:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 43 @ 6746 updates, score 33.87) (writing took 1.8204399030655622 seconds)
2022-03-23 12:50:12 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 12:50:12 | INFO | train | epoch 043 | loss 6.698 | ppl 103.84 | wps 39448.7 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.309 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 4335
KL Stats: Epoch 43 Divergences: Uniform: 1.9655351057461292 Unigram: 0.8622613001899595
2022-03-23 12:50:12 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 12:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:50:33 | INFO | train_inner | epoch 044:     54 / 157 loss=6.754, ppl=107.93, wps=31585.4, ups=1.27, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.338, loss_scale=4, train_wall=37, gb_free=12.3, wall=4356
2022-03-23 12:51:10 | INFO | train_inner | epoch 044:    154 / 157 loss=6.618, ppl=98.23, wps=68123.3, ups=2.67, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.292, loss_scale=4, train_wall=37, gb_free=12, wall=4393
2022-03-23 12:51:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:51:15 | INFO | fairseq.tasks.translation | example hypothesis: we put these pietters in the clinic.
2022-03-23 12:51:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:51:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you know here.
2022-03-23 12:51:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:51:23 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:51:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:51:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 12:51:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:51:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:51:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:51:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for wildlife, the number of wildlife animals grew back, and this has become a foundation for conservation in namibia.
2022-03-23 12:51:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:51:39 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor doesn't like it, when they move, it may use their movements, and that's how the superconducting boxes disrupt.
2022-03-23 12:51:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:51:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which is the big constructions of the face and the basic shape, and recover it through the one that refuses the whole porch structure and all the fine folds.
2022-03-23 12:51:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:51:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to me here at tedwomen is that... well, when i was striking dinner, it was best summarized when someone said, "turn to the men at your table and say," if the revolution begins, then we support you. "the truth, women love, is that we've already supported you for a long time.
2022-03-23 12:51:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:51:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still necessary, and a large part of the design work that we're on our airplane on the stumbling toe was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously varied varieties and a cooling system that allows us to use an aircraft in the stop-go-traffic, to a specific driver's specialist drive, either floating the propelled, to the ground, to the safety mechanism, to the ground, to the safety system, to the security system, to the ground, to the safety system.
2022-03-23 12:51:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:51:49 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.03 | ppl 261.46 | bleu 33.78 | wps 4883.7 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.87
2022-03-23 12:51:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 12:51:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:51:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:51:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 44 @ 6903 updates, score 33.78) (writing took 0.8382972709368914 seconds)
2022-03-23 12:51:50 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 12:51:50 | INFO | train | epoch 044 | loss 6.688 | ppl 103.1 | wps 40312.3 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.32 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 4433
KL Stats: Epoch 44 Divergences: Uniform: 1.9665423152685888 Unigram: 0.8640452333412281
2022-03-23 12:51:50 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 12:51:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:52:28 | INFO | train_inner | epoch 045:     97 / 157 loss=6.577, ppl=95.5, wps=33158.8, ups=1.29, wpb=25640.8, bsz=1040.4, num_updates=7000, lr=0.000377964, gnorm=0.305, loss_scale=4, train_wall=37, gb_free=12.7, wall=4470
2022-03-23 12:52:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:52:55 | INFO | fairseq.tasks.translation | example hypothesis: we put up these bleep in the clinic.
2022-03-23 12:52:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:52:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:52:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:53:03 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks beds that will transcend two new pigs.
2022-03-23 12:53:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:53:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 12:53:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:53:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:53:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:53:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the measure of how people take responsibility for wildlife, the number of wildlife animals grew back up again, and this has become a basis for conservation in namibia.
2022-03-23 12:53:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:53:19 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like moving because their movements are consuming energy, so the superconductor is disturbing.
2022-03-23 12:53:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:53:23 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constructions of the face and reproduce the basic shape, and recover it through the information that refers the whole pore structure and all the fine folds.
2022-03-23 12:53:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:53:27 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, when i was striking dinner, it was best summarized when someone said, "turn to men at your table and tell them," when the revolution begins, then we support you. 'the truth is that we've already supported you in this topic for a long time, "the future of sandra's" downstream "
2022-03-23 12:53:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:53:29 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still necessary, and a large part of the design work that we're on on on our airplane is a result of the fact that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable drive and a cooling system that allows us to use an aircraft in the stop-go-traffic machine to a particular drill, or when you fly it down to the ground -- everything from a continuously variable vehicle, all the way down the ground, all the way down to a mechanism is to the ground, all the space, to the way you can see a mechanical deploy, to the ground, to the ground, all the space, all the space, to the way you can see a mechanism is to the ground, to the ground, to the ground, to the car deploy.
2022-03-23 12:53:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:53:29 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.008 | ppl 257.48 | bleu 33.93 | wps 4782.7 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.93
2022-03-23 12:53:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 12:53:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:53:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:53:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 45 @ 7060 updates, score 33.93) (writing took 1.8297582189552486 seconds)
2022-03-23 12:53:31 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 12:53:31 | INFO | train | epoch 045 | loss 6.672 | ppl 101.99 | wps 38995.7 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.315 | loss_scale 4 | train_wall 58 | gb_free 13.2 | wall 4534
KL Stats: Epoch 45 Divergences: Uniform: 1.9651903600771572 Unigram: 0.8622875547607501
2022-03-23 12:53:32 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 12:53:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:53:47 | INFO | train_inner | epoch 046:     40 / 157 loss=6.827, ppl=113.57, wps=30799.6, ups=1.27, wpb=24304.7, bsz=957.9, num_updates=7100, lr=0.000375293, gnorm=0.331, loss_scale=4, train_wall=37, gb_free=12.4, wall=4549
2022-03-23 12:54:25 | INFO | train_inner | epoch 046:    140 / 157 loss=6.604, ppl=97.3, wps=67152.4, ups=2.64, wpb=25441.7, bsz=1021.5, num_updates=7200, lr=0.000372678, gnorm=0.303, loss_scale=4, train_wall=37, gb_free=11.7, wall=4587
2022-03-23 12:54:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:54:35 | INFO | fairseq.tasks.translation | example hypothesis: we put up these bleep in the clinic.
2022-03-23 12:54:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:54:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline that probably most of you know here.
2022-03-23 12:54:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:54:43 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:54:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:54:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 12:54:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:54:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:54:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:54:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the measure of how people took responsibility for wildlife, the number of wildlife grew back, and that has become a basis for conservation in namibia.
2022-03-23 12:54:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:54:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like moving, because their movements are consuming energy and disturbing the superconducting.
2022-03-23 12:54:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:55:03 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can restore the big contextures of the face and the basic shape and recover it through the information that refuses the whole pore structure and all the fine folds.
2022-03-23 12:55:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:55:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when you're striking dinner, it was best summarized when someone said, "turn to men at your table and say to them," if the revolution begins, then we support you. "the truth, women love, is that we've already supported you with this topic for a long time."
2022-03-23 12:55:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:55:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention and a great part of the design work that we're most proud of on our airplane was a result of the fact that we had to solve the unique problems that were linked to operate on the ground -- everything from a continuously variable drive and a refrigeration system with refrigeration that allows us to use a machine at the stop-go-traffic, to a particularly appropriate driver, or if you fly it to the ground, or if you see the mechanism in the same.
2022-03-23 12:55:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:55:08 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.027 | ppl 260.93 | bleu 33.51 | wps 5017.2 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 33.93
2022-03-23 12:55:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-23 12:55:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:55:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:55:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 46 @ 7217 updates, score 33.51) (writing took 0.8228212159592658 seconds)
2022-03-23 12:55:09 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 12:55:09 | INFO | train | epoch 046 | loss 6.658 | ppl 100.99 | wps 40474 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.319 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 4631
KL Stats: Epoch 46 Divergences: Uniform: 1.9673606795491678 Unigram: 0.866163036051868
2022-03-23 12:55:09 | INFO | fairseq.trainer | begin training epoch 47
2022-03-23 12:55:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:55:41 | INFO | train_inner | epoch 047:     83 / 157 loss=6.644, ppl=100, wps=32990.6, ups=1.31, wpb=25147.5, bsz=1057.7, num_updates=7300, lr=0.000370117, gnorm=0.314, loss_scale=4, train_wall=37, gb_free=11.9, wall=4663
2022-03-23 12:56:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:56:12 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepters in the clinic.
2022-03-23 12:56:12 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:56:17 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline that probably most of you know here.
2022-03-23 12:56:17 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:56:21 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:56:21 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:56:25 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:56:25 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:56:29 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:56:29 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:56:33 | INFO | fairseq.tasks.translation | example hypothesis: and in the measure of how people take responsibility for wildlife, the number of wildlife wildlife grew back, and this has become a foundation for conservation in namibia.
2022-03-23 12:56:33 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:56:37 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it, if you move, because your movements use energy, and that's how the superconductor disrupts.
2022-03-23 12:56:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:56:41 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that regives the big contextures of the face and the basic shape, and we add it through the information that refuses the whole por-structure and all the fine folds.
2022-03-23 12:56:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:56:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... well, when the strict dinner, it was best summarized when someone said, "turn you to the men at your table and tell them," 'when the revolution begins, then we support you.' "the truth, love is that we've already supported you for a long time.
2022-03-23 12:56:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:56:46 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our plane on the most stumbling, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously variable, and a cooling system with fluid, that allows us to use an aircraft in the stop-traffic, to a specially appropriate driver's flight, either when you run it, or you see the propeller on the ground.
2022-03-23 12:56:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:56:46 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.007 | ppl 257.16 | bleu 34 | wps 4855.5 | wpb 17862.2 | bsz 728.3 | num_updates 7374 | best_bleu 34
2022-03-23 12:56:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 7374 updates
2022-03-23 12:56:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:56:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 12:56:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 47 @ 7374 updates, score 34.0) (writing took 1.8686025370843709 seconds)
2022-03-23 12:56:48 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-23 12:56:48 | INFO | train | epoch 047 | loss 6.643 | ppl 99.94 | wps 39797.7 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 7374 | lr 0.000368255 | gnorm 0.305 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 4731
KL Stats: Epoch 47 Divergences: Uniform: 1.967540764450596 Unigram: 0.8664382309091512
2022-03-23 12:56:48 | INFO | fairseq.trainer | begin training epoch 48
2022-03-23 12:56:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:56:58 | INFO | train_inner | epoch 048:     26 / 157 loss=6.615, ppl=98.02, wps=32454, ups=1.29, wpb=25089, bsz=1043, num_updates=7400, lr=0.000367607, gnorm=0.322, loss_scale=4, train_wall=37, gb_free=11.7, wall=4741
2022-03-23 12:57:37 | INFO | train_inner | epoch 048:    126 / 157 loss=6.604, ppl=97.29, wps=66737.4, ups=2.6, wpb=25678, bsz=966, num_updates=7500, lr=0.000365148, gnorm=0.286, loss_scale=4, train_wall=38, gb_free=12.3, wall=4779
2022-03-23 12:57:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:57:52 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepters in the clinic.
2022-03-23 12:57:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:57:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:57:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:57:59 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks conditions that will transcend two new pigs.
2022-03-23 12:57:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:58:04 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 12:58:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:58:08 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:58:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:58:12 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent that people have taken responsibility for wildlife, the number of wildlife grew back, and that has become a basis for conservation in namibia.
2022-03-23 12:58:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:58:16 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because they use their movements to use their energy and disturb the superconductor.
2022-03-23 12:58:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:58:20 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and reproduce the basic shape, and restore it through the one that removes the whole por-structure and all the fine folds.
2022-03-23 12:58:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:58:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to me here at tedwomen is that... well, when someone said, "turn you to a table and say," well, if the revolution begins, then we support you for a long time. "
2022-03-23 12:58:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:58:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we are on our airplane use of stumbling traffic to a particular result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variable drive and a refrigerator system that allows us to use an aircraft on our aircraft to use a stumbling cup.
2022-03-23 12:58:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:58:26 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.013 | ppl 258.24 | bleu 33.84 | wps 4738.1 | wpb 17862.2 | bsz 728.3 | num_updates 7531 | best_bleu 34
2022-03-23 12:58:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 7531 updates
2022-03-23 12:58:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:58:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 12:58:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 48 @ 7531 updates, score 33.84) (writing took 0.8330734570045024 seconds)
2022-03-23 12:58:27 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-23 12:58:27 | INFO | train | epoch 048 | loss 6.637 | ppl 99.53 | wps 39892 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 7531 | lr 0.000364396 | gnorm 0.33 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 4830
KL Stats: Epoch 48 Divergences: Uniform: 1.9677015962395243 Unigram: 0.8655225025733174
2022-03-23 12:58:27 | INFO | fairseq.trainer | begin training epoch 49
2022-03-23 12:58:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:58:54 | INFO | train_inner | epoch 049:     69 / 157 loss=6.755, ppl=107.99, wps=31682.3, ups=1.3, wpb=24399, bsz=1004.6, num_updates=7600, lr=0.000362738, gnorm=0.346, loss_scale=4, train_wall=37, gb_free=12.2, wall=4856
2022-03-23 12:59:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:59:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 12:59:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:59:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:59:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:59:38 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:59:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:59:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 12:59:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:59:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:59:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:59:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the size of the people's responsibility for wildlife, the number of wildlife grew again, and this has become a foundation for conservation in namibia.
2022-03-23 12:59:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:59:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements are consuming their energy and disturbing the superconductor.
2022-03-23 12:59:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:59:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which regives the big constructions of the face and restore the basic shape, and adding it through the information that refers the whole pore structure and all the fine folds.
2022-03-23 12:59:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:00:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... well, when i'm having a dinner, it was best summarized when someone said, "turn you to the men at your table and say to them, 'when the revolution begins, we support you.' the truth, women love is that we've already supported you for a long time.
2022-03-23 13:00:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:00:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention and a large part of the design work that we're on on on on our airplane is a result of the fact that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variables and a refrigerator system that allows us to use a machine in stop-go-traffic, to a special appropriate vehicle, either when you run the flying space, or when you see the flying space on the ground.
2022-03-23 13:00:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:00:04 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 7.989 | ppl 254.05 | bleu 34.02 | wps 4850.5 | wpb 17862.2 | bsz 728.3 | num_updates 7688 | best_bleu 34.02
2022-03-23 13:00:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 7688 updates
2022-03-23 13:00:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 13:00:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 13:00:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 49 @ 7688 updates, score 34.02) (writing took 1.8652609181590378 seconds)
2022-03-23 13:00:06 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-23 13:00:06 | INFO | train | epoch 049 | loss 6.62 | ppl 98.38 | wps 39829.6 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 7688 | lr 0.000360656 | gnorm 0.301 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 4929
KL Stats: Epoch 49 Divergences: Uniform: 1.9675051073361502 Unigram: 0.8671485964927723
2022-03-23 13:00:06 | INFO | fairseq.trainer | begin training epoch 50
2022-03-23 13:00:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:00:11 | INFO | train_inner | epoch 050:     12 / 157 loss=6.551, ppl=93.73, wps=32953, ups=1.29, wpb=25586.8, bsz=1069, num_updates=7700, lr=0.000360375, gnorm=0.301, loss_scale=4, train_wall=37, gb_free=12.9, wall=4934
2022-03-23 13:00:49 | INFO | train_inner | epoch 050:    112 / 157 loss=6.557, ppl=94.13, wps=67251.4, ups=2.65, wpb=25420, bsz=1059.8, num_updates=7800, lr=0.000358057, gnorm=0.306, loss_scale=4, train_wall=37, gb_free=11.9, wall=4972
2022-03-23 13:01:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:01:09 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 13:01:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:01:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 13:01:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:01:17 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 13:01:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:01:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:01:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:01:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:01:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:01:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife grew up again, and this has become a foundation for conservation in namibia.
2022-03-23 13:01:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:01:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor may not be able to move because their movements are consuming their energy, disturbing the superconductor.
2022-03-23 13:01:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:01:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection from this reflection, we can start with a traditional facial can to restore the big constructures of the face and the basic shape, and add it through the one that information that refers the whole pore structure and all the fine wrinkles.
2022-03-23 13:01:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:01:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, in the strict dinner, it was best summarized when someone said, "turn you to the men at your table and say," if the revolution begins, then we support you. "the truth, love is that we've already supported you in this topic for a long time." in rachel carson's "spring theo's" borne's "borne, future, borne,"
2022-03-23 13:01:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:01:45 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention is still the mother of the invention, and a large part of the design work that we're on our plane is a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously variable drivers and a cooling system that allows us to use an aircraft in stop-go-traffic, to a particularly appropriate driver's ride either when you run it on the ground -- all the way to the propelled to the ground -- all the way down to the safety system, to the mechanism, to the ground, to the point where you can see trajectory mechanism is, to the point where you can get rid of an aircraft, to the point where you can see, to the point where you're going on the point where you're going to the point where you're going to be done when you're going to the point where you're going on the point where you're going on the point where you're going on the
2022-03-23 13:01:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:01:45 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 7.997 | ppl 255.48 | bleu 34.43 | wps 4646.3 | wpb 17862.2 | bsz 728.3 | num_updates 7845 | best_bleu 34.43
2022-03-23 13:01:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 7845 updates
2022-03-23 13:01:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 13:01:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 13:01:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 50 @ 7845 updates, score 34.43) (writing took 1.8632109011523426 seconds)
2022-03-23 13:01:47 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-23 13:01:47 | INFO | train | epoch 050 | loss 6.607 | ppl 97.51 | wps 39308.1 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 7845 | lr 0.000357029 | gnorm 0.303 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 5029
KL Stats: Epoch 50 Divergences: Uniform: 1.9681552933380875 Unigram: 0.8680200706639492
2022-03-23 13:01:47 | INFO | fairseq.trainer | begin training epoch 51
2022-03-23 13:01:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:02:08 | INFO | train_inner | epoch 051:     55 / 157 loss=6.671, ppl=101.91, wps=31536.7, ups=1.27, wpb=24912.1, bsz=989.4, num_updates=7900, lr=0.000355784, gnorm=0.295, loss_scale=4, train_wall=37, gb_free=12.9, wall=5051
2022-03-23 13:02:45 | INFO | train_inner | epoch 051:    155 / 157 loss=6.559, ppl=94.32, wps=67522.9, ups=2.68, wpb=25169.7, bsz=1006.8, num_updates=8000, lr=0.000353553, gnorm=0.312, loss_scale=4, train_wall=37, gb_free=11.6, wall=5088
2022-03-23 13:02:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:02:50 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 13:02:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:02:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of you know about this.
2022-03-23 13:02:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:02:58 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 13:02:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:03:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:03:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:03:06 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 13:03:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:03:10 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wild animals grew up again, and that's become a foundation for conservation in namibia.
2022-03-23 13:03:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:03:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they're moving, because their movements are consuming their energy, disturbing the superconducting.
2022-03-23 13:03:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:03:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big contextures of the face and the basic shape, and then add it through that information that refers the whole por-structure and all the fine folds.
2022-03-23 13:03:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:03:22 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, when i was striking dinner, it was best summarized when someone said, "turn to the men in your desk and tell them, 'if the revolution begins, then we support you.'" 'the truth, love is that we've already supported you in this topic for a long time.
2022-03-23 13:03:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:03:24 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a big part of the design work that we're on on our airplane was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously variable storm and a cooling system that allows us to use an aircraft in the stop-go-traffic, to a specific passage, which is either drive the propeller to the ground, to the safety system, to see the same mechanism, to the ground, to the safety system, to see a mechanism.
2022-03-23 13:03:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:03:24 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 7.983 | ppl 252.96 | bleu 34.21 | wps 4865.2 | wpb 17862.2 | bsz 728.3 | num_updates 8002 | best_bleu 34.43
2022-03-23 13:03:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 8002 updates
2022-03-23 13:03:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 13:03:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 13:03:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 51 @ 8002 updates, score 34.21) (writing took 0.8941449930425733 seconds)
2022-03-23 13:03:25 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-23 13:03:25 | INFO | train | epoch 051 | loss 6.594 | ppl 96.58 | wps 40330.9 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 8002 | lr 0.000353509 | gnorm 0.305 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 5127
KL Stats: Epoch 51 Divergences: Uniform: 1.9696494049747388 Unigram: 0.8687285367618809
2022-03-23 13:03:25 | INFO | fairseq.trainer | begin training epoch 52
2022-03-23 13:03:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:04:02 | INFO | train_inner | epoch 052:     98 / 157 loss=6.568, ppl=94.9, wps=32702.1, ups=1.31, wpb=25057.5, bsz=1065.7, num_updates=8100, lr=0.000351364, gnorm=0.31, loss_scale=4, train_wall=37, gb_free=11.7, wall=5165
2022-03-23 13:04:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:04:28 | INFO | fairseq.tasks.translation | example hypothesis: we put up these piepters in the clinic.
2022-03-23 13:04:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:04:33 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, which probably most of you know here.
2022-03-23 13:04:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:04:36 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 13:04:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:04:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:04:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:04:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 13:04:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:04:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for wildlife, the number of wildlife grew back, and this has become a basis for conservation in namibia.
2022-03-23 13:04:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:04:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor doesn't like to move, because they use their movements to use energy, and they're disturbing the superconducting.
2022-03-23 13:04:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:04:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constructions of the face and recover the basic shape, and then we add it through the information that refers the whole por-structure and all the fine folds.
2022-03-23 13:04:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:05:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when i sat down, it was best summarized when someone said, "turn to the men at your table and say to them," if the revolution begins, then we support you. '"the truth, love is that we've already supported you at this topic for a long time."
2022-03-23 13:05:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:05:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the most staggering design work that we are on our plane was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously variable, and a cooling system with fluid that allows us to use a vehicle on the stop-go-traffic aircraft to a specially appropriate driver.
2022-03-23 13:05:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:05:02 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 7.977 | ppl 251.89 | bleu 34.31 | wps 4972 | wpb 17862.2 | bsz 728.3 | num_updates 8159 | best_bleu 34.43
2022-03-23 13:05:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 8159 updates
2022-03-23 13:05:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 13:05:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 13:05:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 52 @ 8159 updates, score 34.31) (writing took 0.9071990649681538 seconds)
2022-03-23 13:05:03 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-23 13:05:03 | INFO | train | epoch 052 | loss 6.59 | ppl 96.34 | wps 40272.5 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 8159 | lr 0.000350091 | gnorm 0.308 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 5225
KL Stats: Epoch 52 Divergences: Uniform: 1.9689963679975864 Unigram: 0.8694492378241511
2022-03-23 13:05:03 | INFO | fairseq.trainer | begin training epoch 53
2022-03-23 13:05:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:05:18 | INFO | train_inner | epoch 053:     41 / 157 loss=6.606, ppl=97.39, wps=32921.5, ups=1.31, wpb=25151.3, bsz=978.2, num_updates=8200, lr=0.000349215, gnorm=0.305, loss_scale=4, train_wall=37, gb_free=12, wall=5241
2022-03-23 13:05:56 | INFO | train_inner | epoch 053:    141 / 157 loss=6.634, ppl=99.32, wps=65939.1, ups=2.65, wpb=24894.4, bsz=1025.6, num_updates=8300, lr=0.000347105, gnorm=0.314, loss_scale=4, train_wall=37, gb_free=12.2, wall=5279
2022-03-23 13:06:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:06:06 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 13:06:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:06:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you know here.
2022-03-23 13:06:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:06:14 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 13:06:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:06:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:06:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:06:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of us are thinking on the track.
2022-03-23 13:06:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:06:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the sauce of how people took responsibility for wildlife, the number of wildlife grew back up again, and this has become a basis for conservation in namibia.
2022-03-23 13:06:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:06:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements consume energy, and that's how the superconductor disturbs.
2022-03-23 13:06:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:06:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection from this mirror reflection, we can start with a traditional facial can that restores the big constructions of the face and the basic shape, and recovers it through that information that refers the whole pore structure and all the fine folds.
2022-03-23 13:06:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:06:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... well, when i was striking dinner, it was best summarized when someone said, "turn to men at your table and tell them," if the revolution begins, then we support you. 'the truth, love is that we've already supported you in this topic for a long time. at rachel carthe
2022-03-23 13:06:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:06:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're the most proud of our airplane was a result of that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variation of the drivers and a refrigerator system that allows us to use an aircraft at the stop-go-traffic, to a specially appropriate driver's drivers, either pushing the propeller, to the ground, to the ground, to see a continuously variable vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle, to the ground, to the ground, to see the safety system that we're about.
2022-03-23 13:06:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:06:40 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 7.961 | ppl 249.19 | bleu 34.62 | wps 4837.6 | wpb 17862.2 | bsz 728.3 | num_updates 8316 | best_bleu 34.62
2022-03-23 13:06:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 8316 updates
2022-03-23 13:06:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 13:06:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt
2022-03-23 13:06:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_best.pt (epoch 53 @ 8316 updates, score 34.62) (writing took 2.038226878968999 seconds)
2022-03-23 13:06:42 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-23 13:06:42 | INFO | train | epoch 053 | loss 6.578 | ppl 95.52 | wps 39835.5 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 8316 | lr 0.000346771 | gnorm 0.307 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 5324
KL Stats: Epoch 53 Divergences: Uniform: 1.969600093474252 Unigram: 0.8699100576070172
2022-03-23 13:06:42 | INFO | fairseq.trainer | begin training epoch 54
2022-03-23 13:06:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:07:14 | INFO | train_inner | epoch 054:     84 / 157 loss=6.488, ppl=89.76, wps=32774.8, ups=1.29, wpb=25481.9, bsz=991, num_updates=8400, lr=0.000345033, gnorm=0.309, loss_scale=4, train_wall=37, gb_free=11.9, wall=5356
2022-03-23 13:07:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:07:45 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters in the clinic.
2022-03-23 13:07:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:07:49 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most people know here.
2022-03-23 13:07:49 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:07:53 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 13:07:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:07:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:07:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:08:01 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:08:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:08:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the sauce of people's responsibility for wildlife revenues, the number of wildlife animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 13:08:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:08:09 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they're moving, because their movements are using energy and disturbing the superconductor.
2022-03-23 13:08:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:08:13 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can restore the big contextures of the face and the basic shape, and add it through that information that refers the whole por-structure and all the fine wrinkles.
2022-03-23 13:08:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:08:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that... well, when i argued dinner, it was best summarized when someone said, "turn to men at your table and say," if the revolution begins, then we support you. 'the truth, love is that we've already supported you for a long time.
2022-03-23 13:08:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:08:19 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we are on our airplane with refrigerators was a result that we had to solve the unique problems that were linked to operate on the ground -- everything, from a continuously variable drivers and a coolness system that allows us to use an aircraft in stop-go-traffic, to a special passage vehicle, or propeller space, to the ground.
2022-03-23 13:08:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:08:19 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 7.989 | ppl 254.04 | bleu 34.3 | wps 4902 | wpb 17862.2 | bsz 728.3 | num_updates 8473 | best_bleu 34.62
2022-03-23 13:08:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 8473 updates
2022-03-23 13:08:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 13:08:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt
2022-03-23 13:08:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.05_0.3_0.65_#1/checkpoint_last.pt (epoch 54 @ 8473 updates, score 34.3) (writing took 0.8984483140520751 seconds)
2022-03-23 13:08:19 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-23 13:08:19 | INFO | train | epoch 054 | loss 6.569 | ppl 94.95 | wps 40393.6 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 8473 | lr 0.000343543 | gnorm 0.315 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 5422
KL Stats: Epoch 54 Divergences: Uniform: 1.9714713949215659 Unigram: 0.8722046780675573
2022-03-23 13:08:20 | INFO | fairseq.trainer | begin training epoch 55
2022-03-23 13:08:20 | INFO | fairseq_cli.train | Start iterating over samples
