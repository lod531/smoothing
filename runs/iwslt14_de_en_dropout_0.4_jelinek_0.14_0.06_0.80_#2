Sender: LSF System <lsfadmin@eu-g3-049>
Subject: Job 209984134: <iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2> in cluster <euler> Exited

Job <iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2> was submitted from host <eu-login-04> by user <andriusb> in cluster <euler> at Sun Mar 20 09:05:10 2022
Job was executed on host(s) <eu-g3-049>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Sun Mar 20 09:05:36 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar 20 09:05:36 2022
Terminated at Sun Mar 20 09:07:46 2022
Results reported at Sun Mar 20 09:07:46 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.4 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.14,0.06,0.80\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575612 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   123.06 sec.
    Max Memory :                                 3343 MB
    Average Memory :                             2383.14 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               16657.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   129 sec.
    Turnaround time :                            156 sec.

The output (if any) follows:

2022-03-20 09:05:42 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575612, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.14,0.06,0.80)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.4, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575612, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.14,0.06,0.80)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-20 09:05:42 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-20 09:05:42 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-20 09:05:43 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-20 09:05:43 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-20 09:05:43 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1117/160239 [00:00<00:14, 11169.45it/s]  2%|▏         | 2452/160239 [00:00<00:12, 12450.19it/s]  2%|▏         | 3821/160239 [00:00<00:12, 13013.57it/s]  3%|▎         | 5123/160239 [00:00<00:12, 12923.39it/s]  4%|▍         | 6416/160239 [00:00<00:12, 12746.84it/s]  5%|▍         | 7692/160239 [00:00<00:12, 12626.99it/s]  6%|▌         | 8956/160239 [00:00<00:12, 12525.10it/s]  6%|▋         | 10279/160239 [00:00<00:11, 12740.70it/s]  7%|▋         | 11573/160239 [00:00<00:11, 12798.15it/s]  8%|▊         | 12854/160239 [00:01<00:11, 12785.19it/s]  9%|▉         | 14135/160239 [00:01<00:11, 12785.84it/s] 10%|▉         | 15414/160239 [00:01<00:11, 12604.16it/s] 10%|█         | 16676/160239 [00:01<00:11, 12438.94it/s] 11%|█         | 17933/160239 [00:01<00:11, 12474.14it/s] 12%|█▏        | 19207/160239 [00:01<00:11, 12552.63it/s] 13%|█▎        | 20590/160239 [00:01<00:10, 12932.01it/s] 14%|█▎        | 21884/160239 [00:01<00:11, 12512.33it/s] 14%|█▍        | 23139/160239 [00:01<00:11, 12456.09it/s] 15%|█▌        | 24412/160239 [00:01<00:10, 12535.55it/s] 16%|█▌        | 25706/160239 [00:02<00:10, 12654.62it/s] 17%|█▋        | 26973/160239 [00:02<00:10, 12468.03it/s] 18%|█▊        | 28321/160239 [00:02<00:10, 12761.34it/s] 18%|█▊        | 29599/160239 [00:02<00:10, 12654.75it/s] 19%|█▉        | 30866/160239 [00:02<00:10, 12382.53it/s] 20%|██        | 32227/160239 [00:02<00:10, 12737.63it/s] 21%|██        | 33503/160239 [00:02<00:10, 12493.32it/s] 22%|██▏       | 34755/160239 [00:02<00:10, 12302.19it/s] 23%|██▎       | 36064/160239 [00:02<00:09, 12529.53it/s] 23%|██▎       | 37319/160239 [00:02<00:09, 12411.77it/s] 24%|██▍       | 38616/160239 [00:03<00:09, 12573.28it/s] 25%|██▍       | 39875/160239 [00:03<00:09, 12518.84it/s] 26%|██▌       | 41184/160239 [00:03<00:09, 12679.83it/s] 26%|██▋       | 42453/160239 [00:03<00:09, 12336.03it/s] 27%|██▋       | 43689/160239 [00:03<00:09, 12288.98it/s] 28%|██▊       | 44920/160239 [00:03<00:09, 12175.94it/s] 29%|██▉       | 46256/160239 [00:03<00:09, 12515.91it/s] 30%|██▉       | 47579/160239 [00:03<00:08, 12725.55it/s] 30%|███       | 48853/160239 [00:03<00:08, 12498.33it/s] 31%|███▏      | 50123/160239 [00:03<00:08, 12556.73it/s] 32%|███▏      | 51450/160239 [00:04<00:08, 12767.28it/s] 33%|███▎      | 52753/160239 [00:04<00:08, 12843.78it/s] 34%|███▎      | 54039/160239 [00:04<00:08, 12722.54it/s] 35%|███▍      | 55313/160239 [00:04<00:08, 12631.36it/s] 35%|███▌      | 56644/160239 [00:04<00:08, 12831.09it/s] 36%|███▌      | 57971/160239 [00:04<00:07, 12958.90it/s] 37%|███▋      | 59296/160239 [00:04<00:07, 13043.46it/s] 38%|███▊      | 60601/160239 [00:04<00:07, 12984.21it/s] 39%|███▊      | 61900/160239 [00:04<00:07, 12496.54it/s] 39%|███▉      | 63252/160239 [00:05<00:07, 12793.42it/s] 40%|████      | 64687/160239 [00:05<00:07, 13249.79it/s] 41%|████      | 66029/160239 [00:05<00:07, 13297.60it/s] 42%|████▏     | 67362/160239 [00:05<00:07, 12866.94it/s] 43%|████▎     | 68654/160239 [00:05<00:07, 12683.87it/s] 44%|████▎     | 69926/160239 [00:05<00:07, 12689.43it/s] 44%|████▍     | 71255/160239 [00:05<00:06, 12865.13it/s] 45%|████▌     | 72544/160239 [00:05<00:06, 12679.73it/s] 46%|████▌     | 73814/160239 [00:05<00:06, 12584.96it/s] 47%|████▋     | 75074/160239 [00:05<00:06, 12500.18it/s] 48%|████▊     | 76325/160239 [00:06<00:06, 12473.37it/s] 48%|████▊     | 77707/160239 [00:06<00:06, 12870.05it/s] 49%|████▉     | 79004/160239 [00:06<00:06, 12897.41it/s] 50%|█████     | 80356/160239 [00:06<00:06, 13081.72it/s] 51%|█████     | 81721/160239 [00:06<00:05, 13250.04it/s] 52%|█████▏    | 83047/160239 [00:06<00:05, 13200.51it/s] 53%|█████▎    | 84368/160239 [00:06<00:05, 13016.59it/s] 54%|█████▎    | 85748/160239 [00:06<00:05, 13245.96it/s] 54%|█████▍    | 87090/160239 [00:06<00:05, 13293.93it/s] 55%|█████▌    | 88421/160239 [00:06<00:05, 13084.51it/s] 56%|█████▌    | 89790/160239 [00:07<00:05, 13258.28it/s] 57%|█████▋    | 91117/160239 [00:07<00:05, 13038.60it/s] 58%|█████▊    | 92423/160239 [00:07<00:05, 13003.97it/s] 58%|█████▊    | 93725/160239 [00:07<00:05, 12842.44it/s] 59%|█████▉    | 95011/160239 [00:07<00:05, 12640.27it/s] 60%|██████    | 96315/160239 [00:07<00:05, 12755.22it/s] 61%|██████    | 97600/160239 [00:07<00:04, 12779.94it/s] 62%|██████▏   | 98924/160239 [00:07<00:04, 12914.38it/s] 63%|██████▎   | 100276/160239 [00:07<00:04, 13092.39it/s] 63%|██████▎   | 101586/160239 [00:07<00:04, 13016.04it/s] 64%|██████▍   | 102889/160239 [00:08<00:04, 12809.14it/s] 65%|██████▌   | 104171/160239 [00:08<00:04, 12692.38it/s] 66%|██████▌   | 105500/160239 [00:08<00:04, 12863.64it/s] 67%|██████▋   | 106788/160239 [00:08<00:04, 12822.74it/s] 67%|██████▋   | 108071/160239 [00:08<00:04, 12471.32it/s] 68%|██████▊   | 109321/160239 [00:08<00:04, 12351.79it/s] 69%|██████▉   | 110590/160239 [00:08<00:03, 12449.53it/s] 70%|██████▉   | 111945/160239 [00:08<00:03, 12770.65it/s] 71%|███████   | 113224/160239 [00:08<00:03, 12679.45it/s] 71%|███████▏  | 114537/160239 [00:08<00:03, 12810.49it/s] 72%|███████▏  | 115821/160239 [00:09<00:03, 12817.94it/s] 73%|███████▎  | 117104/160239 [00:09<00:03, 12667.24it/s] 74%|███████▍  | 118396/160239 [00:09<00:03, 12740.25it/s] 75%|███████▍  | 119776/160239 [00:09<00:03, 13054.46it/s] 76%|███████▌  | 121083/160239 [00:09<00:03, 12735.65it/s] 76%|███████▋  | 122526/160239 [00:09<00:02, 13231.03it/s] 77%|███████▋  | 123852/160239 [00:09<00:02, 12988.70it/s] 78%|███████▊  | 125154/160239 [00:09<00:02, 12643.10it/s] 79%|███████▉  | 126455/160239 [00:09<00:02, 12747.56it/s] 80%|███████▉  | 127764/160239 [00:10<00:02, 12847.50it/s] 81%|████████  | 129051/160239 [00:10<00:02, 12776.68it/s] 81%|████████▏ | 130331/160239 [00:10<00:02, 12511.73it/s] 82%|████████▏ | 131584/160239 [00:10<00:02, 12498.19it/s] 83%|████████▎ | 132844/160239 [00:10<00:02, 12526.53it/s] 84%|████████▎ | 134098/160239 [00:10<00:02, 12232.43it/s] 84%|████████▍ | 135372/160239 [00:10<00:02, 12378.61it/s] 85%|████████▌ | 136691/160239 [00:10<00:01, 12614.26it/s] 86%|████████▌ | 138013/160239 [00:10<00:01, 12792.63it/s] 87%|████████▋ | 139350/160239 [00:10<00:01, 12962.75it/s] 88%|████████▊ | 140692/160239 [00:11<00:01, 13096.54it/s] 89%|████████▊ | 142003/160239 [00:11<00:01, 12886.10it/s] 89%|████████▉ | 143293/160239 [00:11<00:01, 12836.01it/s] 90%|█████████ | 144578/160239 [00:11<00:01, 12767.22it/s] 91%|█████████ | 145856/160239 [00:11<00:01, 12684.51it/s] 92%|█████████▏| 147125/160239 [00:11<00:01, 12480.84it/s] 93%|█████████▎| 148374/160239 [00:11<00:00, 12470.40it/s] 93%|█████████▎| 149622/160239 [00:11<00:00, 12245.36it/s] 94%|█████████▍| 150915/160239 [00:11<00:00, 12443.76it/s] 95%|█████████▍| 152196/160239 [00:11<00:00, 12548.33it/s] 96%|█████████▌| 153457/160239 [00:12<00:00, 12563.38it/s] 97%|█████████▋| 154744/160239 [00:12<00:00, 12652.27it/s] 97%|█████████▋| 156099/160239 [00:12<00:00, 12918.59it/s] 98%|█████████▊| 157423/160239 [00:12<00:00, 13014.17it/s] 99%|█████████▉| 158725/160239 [00:12<00:00, 12608.23it/s]100%|█████████▉| 160082/160239 [00:12<00:00, 12885.61it/s]100%|██████████| 160239/160239 [00:12<00:00, 12726.81it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3859/160239 [00:00<00:04, 38582.13it/s]  5%|▍         | 7718/160239 [00:00<00:03, 38522.98it/s]  7%|▋         | 11636/160239 [00:00<00:03, 38819.98it/s] 10%|▉         | 15521/160239 [00:00<00:03, 38830.81it/s] 12%|█▏        | 19405/160239 [00:00<00:03, 38533.12it/s] 15%|█▍        | 23259/160239 [00:00<00:03, 38516.61it/s] 17%|█▋        | 27111/160239 [00:00<00:03, 38459.26it/s] 19%|█▉        | 31018/160239 [00:00<00:03, 38648.45it/s] 22%|██▏       | 34891/160239 [00:00<00:03, 38670.92it/s] 24%|██▍       | 38795/160239 [00:01<00:03, 38782.92it/s] 27%|██▋       | 42674/160239 [00:01<00:03, 38638.43it/s] 29%|██▉       | 46550/160239 [00:01<00:02, 38673.51it/s] 32%|███▏      | 50487/160239 [00:01<00:02, 38881.48it/s] 34%|███▍      | 54503/160239 [00:01<00:02, 39265.96it/s] 37%|███▋      | 58550/160239 [00:01<00:02, 39626.53it/s] 39%|███▉      | 62513/160239 [00:01<00:02, 39589.86it/s] 42%|████▏     | 66699/160239 [00:01<00:02, 40268.35it/s] 44%|████▍     | 70726/160239 [00:01<00:02, 39734.88it/s] 47%|████▋     | 74702/160239 [00:01<00:02, 39524.59it/s] 49%|████▉     | 78724/160239 [00:02<00:02, 39730.46it/s] 52%|█████▏    | 82866/160239 [00:02<00:01, 40231.95it/s] 54%|█████▍    | 86939/160239 [00:02<00:01, 40377.38it/s] 57%|█████▋    | 90978/160239 [00:02<00:01, 40253.61it/s] 59%|█████▉    | 95005/160239 [00:02<00:01, 39879.15it/s] 62%|██████▏   | 99089/160239 [00:02<00:01, 40162.71it/s] 64%|██████▍   | 103107/160239 [00:02<00:01, 40165.59it/s] 67%|██████▋   | 107142/160239 [00:02<00:01, 40218.96it/s] 69%|██████▉   | 111165/160239 [00:02<00:01, 39508.20it/s] 72%|███████▏  | 115249/160239 [00:02<00:01, 39901.03it/s] 74%|███████▍  | 119260/160239 [00:03<00:01, 39961.80it/s] 77%|███████▋  | 123294/160239 [00:03<00:00, 40068.63it/s] 79%|███████▉  | 127303/160239 [00:03<00:00, 39731.48it/s] 82%|████████▏ | 131278/160239 [00:03<00:00, 39401.03it/s] 84%|████████▍ | 135220/160239 [00:03<00:00, 39110.52it/s] 87%|████████▋ | 139336/160239 [00:03<00:00, 39711.97it/s] 89%|████████▉ | 143315/160239 [00:03<00:00, 39733.36it/s] 92%|█████████▏| 147290/160239 [00:03<00:00, 39366.30it/s] 94%|█████████▍| 151228/160239 [00:03<00:00, 38833.15it/s] 97%|█████████▋| 155265/160239 [00:03<00:00, 39285.36it/s] 99%|█████████▉| 159297/160239 [00:04<00:00, 39590.29it/s]100%|██████████| 160239/160239 [00:04<00:00, 39450.64it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2316.02it/s]2022-03-20 09:06:02 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-20 09:06:02 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-20 09:06:02 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-20 09:06:02 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-20 09:06:02 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-20 09:06:02 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-20 09:06:02 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-20 09:06:02 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-20 09:06:02 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-20 09:06:02 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-20 09:06:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-20 09:06:02 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-20 09:06:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-20 09:06:02 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-20 09:06:02 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-20 09:06:02 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:06:02 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:06:02 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-20 09:06:02 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-20 09:06:02 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-20 09:06:02 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-20 09:06:03 | INFO | fairseq.trainer | begin training epoch 1
2022-03-20 09:06:03 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-20 09:06:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-20 09:06:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-20 09:06:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-20 09:06:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-20 09:06:48 | INFO | train_inner | epoch 001:    104 / 157 loss=12.845, ppl=7355.43, wps=66149.4, ups=2.61, wpb=25305.7, bsz=1024.9, num_updates=100, lr=1.25e-05, gnorm=2.943, loss_scale=8, train_wall=45, gb_free=12.2, wall=46
2022-03-20 09:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:07:11 | INFO | fairseq.tasks.translation | example hypothesis: ..
2022-03-20 09:07:11 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:07:13 | INFO | fairseq.tasks.translation | example hypothesis: ..
2022-03-20 09:07:13 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:07:16 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-20 09:07:16 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:07:18 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,
2022-03-20 09:07:18 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:07:21 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-20 09:07:21 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:07:24 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:07:24 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:07:29 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:07:29 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:07:34 | INFO | fairseq.tasks.translation | example hypothesis: the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:07:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:07:42 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:07:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:07:44 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:07:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:07:44 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.007 | ppl 4117.26 | bleu 0.01 | wps 4934.3 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-20 09:07:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-20 09:07:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 342, in train
    valid_losses, should_stop = validate_and_save(
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 435, in validate_and_save
    checkpoint_utils.save_checkpoint(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/checkpoint_utils.py", line 117, in save_checkpoint
    trainer.save_checkpoint(checkpoints[0], extra_state)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 434, in save_checkpoint
    checkpoint_utils.torch_persistent_save(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/checkpoint_utils.py", line 522, in torch_persistent_save
    PathManager.rename(filename + ".tmp", filename)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/file_io.py", line 150, in rename
    os.rename(src, dst)
FileNotFoundError: [Errno 2] No such file or directory: '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt.tmp' -> '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt'
Sender: LSF System <lsfadmin@eu-g3-049>
Subject: Job 209984151: <iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2> was submitted from host <eu-login-04> by user <andriusb> in cluster <euler> at Sun Mar 20 09:05:15 2022
Job was executed on host(s) <eu-g3-049>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Sun Mar 20 09:05:36 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar 20 09:05:36 2022
Terminated at Sun Mar 20 10:38:53 2022
Results reported at Sun Mar 20 10:38:53 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.4 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.14,0.06,0.80\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575612 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5587.59 sec.
    Max Memory :                                 5192 MB
    Average Memory :                             3930.05 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14808.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   5596 sec.
    Turnaround time :                            5618 sec.

The output (if any) follows:

2022-03-20 09:05:42 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575612, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.14,0.06,0.80)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.4, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575612, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.14,0.06,0.80)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-20 09:05:42 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-20 09:05:42 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-20 09:05:43 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-20 09:05:43 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-20 09:05:43 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1115/160239 [00:00<00:14, 11135.81it/s]  2%|▏         | 2459/160239 [00:00<00:12, 12489.13it/s]  2%|▏         | 3837/160239 [00:00<00:11, 13070.57it/s]  3%|▎         | 5145/160239 [00:00<00:11, 13056.15it/s]  4%|▍         | 6451/160239 [00:00<00:11, 12840.93it/s]  5%|▍         | 7736/160239 [00:00<00:12, 12692.50it/s]  6%|▌         | 9006/160239 [00:00<00:12, 12560.57it/s]  6%|▋         | 10334/160239 [00:00<00:11, 12785.14it/s]  7%|▋         | 11614/160239 [00:00<00:11, 12785.56it/s]  8%|▊         | 12902/160239 [00:01<00:11, 12811.71it/s]  9%|▉         | 14184/160239 [00:01<00:11, 12744.95it/s] 10%|▉         | 15459/160239 [00:01<00:11, 12580.41it/s] 10%|█         | 16718/160239 [00:01<00:11, 12421.80it/s] 11%|█         | 17978/160239 [00:01<00:11, 12473.17it/s] 12%|█▏        | 19247/160239 [00:01<00:11, 12535.74it/s] 13%|█▎        | 20660/160239 [00:01<00:10, 13009.00it/s] 14%|█▎        | 21962/160239 [00:01<00:11, 12528.85it/s] 14%|█▍        | 23219/160239 [00:01<00:10, 12533.25it/s] 15%|█▌        | 24492/160239 [00:01<00:10, 12590.54it/s] 16%|█▌        | 25781/160239 [00:02<00:10, 12675.59it/s] 17%|█▋        | 27051/160239 [00:02<00:10, 12513.81it/s] 18%|█▊        | 28383/160239 [00:02<00:10, 12750.63it/s] 19%|█▊        | 29660/160239 [00:02<00:10, 12576.32it/s] 19%|█▉        | 30919/160239 [00:02<00:10, 12406.25it/s] 20%|██        | 32262/160239 [00:02<00:10, 12703.44it/s] 21%|██        | 33534/160239 [00:02<00:10, 12494.22it/s] 22%|██▏       | 34785/160239 [00:02<00:10, 12294.26it/s] 23%|██▎       | 36112/160239 [00:02<00:09, 12578.66it/s] 23%|██▎       | 37372/160239 [00:02<00:09, 12414.31it/s] 24%|██▍       | 38670/160239 [00:03<00:09, 12574.48it/s] 25%|██▍       | 39929/160239 [00:03<00:09, 12517.63it/s] 26%|██▌       | 41245/160239 [00:03<00:09, 12706.04it/s] 27%|██▋       | 42517/160239 [00:03<00:09, 12325.96it/s] 27%|██▋       | 43753/160239 [00:03<00:09, 12287.65it/s] 28%|██▊       | 44984/160239 [00:03<00:09, 12160.19it/s] 29%|██▉       | 46323/160239 [00:03<00:09, 12520.04it/s] 30%|██▉       | 47660/160239 [00:03<00:08, 12769.85it/s] 31%|███       | 48939/160239 [00:03<00:08, 12569.13it/s] 31%|███▏      | 50198/160239 [00:03<00:08, 12513.99it/s] 32%|███▏      | 51533/160239 [00:04<00:08, 12756.67it/s] 33%|███▎      | 52830/160239 [00:04<00:08, 12819.68it/s] 34%|███▍      | 54113/160239 [00:04<00:08, 12513.38it/s] 35%|███▍      | 55367/160239 [00:04<00:08, 12456.20it/s] 35%|███▌      | 56712/160239 [00:04<00:08, 12746.46it/s] 36%|███▌      | 58056/160239 [00:04<00:07, 12948.11it/s] 37%|███▋      | 59353/160239 [00:04<00:07, 12952.84it/s] 38%|███▊      | 60650/160239 [00:04<00:07, 12948.47it/s] 39%|███▊      | 61946/160239 [00:04<00:07, 12609.58it/s] 40%|███▉      | 63306/160239 [00:05<00:07, 12897.81it/s] 40%|████      | 64744/160239 [00:05<00:07, 13334.91it/s] 41%|████      | 66083/160239 [00:05<00:07, 13350.02it/s] 42%|████▏     | 67420/160239 [00:05<00:07, 12879.94it/s] 43%|████▎     | 68713/160239 [00:05<00:07, 12632.25it/s] 44%|████▎     | 70017/160239 [00:05<00:07, 12749.19it/s] 45%|████▍     | 71347/160239 [00:05<00:06, 12909.40it/s] 45%|████▌     | 72641/160239 [00:05<00:06, 12668.04it/s] 46%|████▌     | 73911/160239 [00:05<00:06, 12615.46it/s] 47%|████▋     | 75175/160239 [00:05<00:06, 12495.38it/s] 48%|████▊     | 76426/160239 [00:06<00:06, 12485.09it/s] 49%|████▊     | 77821/160239 [00:06<00:06, 12915.76it/s] 49%|████▉     | 79132/160239 [00:06<00:06, 12971.52it/s] 50%|█████     | 80487/160239 [00:06<00:06, 13143.40it/s] 51%|█████     | 81822/160239 [00:06<00:05, 13202.29it/s] 52%|█████▏    | 83145/160239 [00:06<00:05, 13208.49it/s] 53%|█████▎    | 84467/160239 [00:06<00:05, 13063.15it/s] 54%|█████▎    | 85854/160239 [00:06<00:05, 13300.06it/s] 54%|█████▍    | 87191/160239 [00:06<00:05, 13318.59it/s] 55%|█████▌    | 88524/160239 [00:06<00:05, 13119.71it/s] 56%|█████▌    | 89880/160239 [00:07<00:05, 13249.08it/s] 57%|█████▋    | 91206/160239 [00:07<00:05, 13063.35it/s] 58%|█████▊    | 92514/160239 [00:07<00:05, 13045.39it/s] 59%|█████▊    | 93820/160239 [00:07<00:05, 12585.44it/s] 59%|█████▉    | 95083/160239 [00:07<00:05, 12526.28it/s] 60%|██████    | 96394/160239 [00:07<00:05, 12695.92it/s] 61%|██████    | 97701/160239 [00:07<00:04, 12803.21it/s] 62%|██████▏   | 99026/160239 [00:07<00:04, 12932.43it/s] 63%|██████▎   | 100357/160239 [00:07<00:04, 13043.29it/s] 63%|██████▎   | 101663/160239 [00:07<00:04, 13033.40it/s] 64%|██████▍   | 102968/160239 [00:08<00:04, 12778.64it/s] 65%|██████▌   | 104307/160239 [00:08<00:04, 12956.50it/s] 66%|██████▌   | 105611/160239 [00:08<00:04, 12978.37it/s] 67%|██████▋   | 106910/160239 [00:08<00:04, 12917.75it/s] 68%|██████▊   | 108203/160239 [00:08<00:04, 12553.86it/s] 68%|██████▊   | 109461/160239 [00:08<00:04, 12450.88it/s] 69%|██████▉   | 110727/160239 [00:08<00:03, 12511.62it/s] 70%|██████▉   | 112076/160239 [00:08<00:03, 12797.52it/s] 71%|███████   | 113358/160239 [00:08<00:03, 12741.73it/s] 72%|███████▏  | 114657/160239 [00:08<00:03, 12813.15it/s] 72%|███████▏  | 115946/160239 [00:09<00:03, 12833.99it/s] 73%|███████▎  | 117230/160239 [00:09<00:03, 12692.76it/s] 74%|███████▍  | 118503/160239 [00:09<00:03, 12702.37it/s] 75%|███████▍  | 119896/160239 [00:09<00:03, 13063.35it/s] 76%|███████▌  | 121203/160239 [00:09<00:03, 12848.22it/s] 77%|███████▋  | 122608/160239 [00:09<00:02, 13200.32it/s] 77%|███████▋  | 123930/160239 [00:09<00:02, 13033.07it/s] 78%|███████▊  | 125235/160239 [00:09<00:02, 12644.10it/s] 79%|███████▉  | 126532/160239 [00:09<00:02, 12736.04it/s] 80%|███████▉  | 127858/160239 [00:10<00:02, 12886.15it/s] 81%|████████  | 129149/160239 [00:10<00:02, 12817.61it/s] 81%|████████▏ | 130433/160239 [00:10<00:02, 12463.87it/s] 82%|████████▏ | 131713/160239 [00:10<00:02, 12556.00it/s] 83%|████████▎ | 132971/160239 [00:10<00:02, 12492.07it/s] 84%|████████▍ | 134222/160239 [00:10<00:02, 12322.03it/s] 85%|████████▍ | 135526/160239 [00:10<00:01, 12529.26it/s] 85%|████████▌ | 136825/160239 [00:10<00:01, 12660.95it/s] 86%|████████▌ | 138133/160239 [00:10<00:01, 12783.55it/s] 87%|████████▋ | 139459/160239 [00:10<00:01, 12925.04it/s] 88%|████████▊ | 140840/160239 [00:11<00:01, 13185.39it/s] 89%|████████▊ | 142160/160239 [00:11<00:01, 12927.68it/s] 90%|████████▉ | 143455/160239 [00:11<00:01, 12852.12it/s] 90%|█████████ | 144742/160239 [00:11<00:01, 12776.07it/s] 91%|█████████ | 146021/160239 [00:11<00:01, 12554.04it/s] 92%|█████████▏| 147278/160239 [00:11<00:01, 12544.31it/s] 93%|█████████▎| 148534/160239 [00:11<00:00, 12306.87it/s] 93%|█████████▎| 149771/160239 [00:11<00:00, 12324.02it/s] 94%|█████████▍| 151044/160239 [00:11<00:00, 12442.65it/s] 95%|█████████▌| 152322/160239 [00:11<00:00, 12541.85it/s] 96%|█████████▌| 153594/160239 [00:12<00:00, 12590.90it/s] 97%|█████████▋| 154906/160239 [00:12<00:00, 12747.23it/s] 97%|█████████▋| 156196/160239 [00:12<00:00, 12792.06it/s] 98%|█████████▊| 157531/160239 [00:12<00:00, 12954.78it/s] 99%|█████████▉| 158827/160239 [00:12<00:00, 12487.08it/s]100%|█████████▉| 160213/160239 [00:12<00:00, 12883.17it/s]100%|██████████| 160239/160239 [00:12<00:00, 12737.42it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3852/160239 [00:00<00:04, 38509.66it/s]  5%|▍         | 7703/160239 [00:00<00:04, 38128.34it/s]  7%|▋         | 11562/160239 [00:00<00:03, 38335.10it/s] 10%|▉         | 15396/160239 [00:00<00:03, 38297.45it/s] 12%|█▏        | 19226/160239 [00:00<00:03, 37941.28it/s] 14%|█▍        | 23041/160239 [00:00<00:03, 38009.18it/s] 17%|█▋        | 26849/160239 [00:00<00:03, 38031.10it/s] 19%|█▉        | 30659/160239 [00:00<00:03, 38049.45it/s] 22%|██▏       | 34546/160239 [00:00<00:03, 38301.46it/s] 24%|██▍       | 38415/160239 [00:01<00:03, 38420.18it/s] 26%|██▋       | 42258/160239 [00:01<00:03, 38288.34it/s] 29%|██▉       | 46088/160239 [00:01<00:02, 38195.26it/s] 31%|███       | 49968/160239 [00:01<00:02, 38376.61it/s] 34%|███▎      | 53883/160239 [00:01<00:02, 38609.32it/s] 36%|███▌      | 57861/160239 [00:01<00:02, 38959.57it/s] 39%|███▊      | 61758/160239 [00:01<00:02, 38940.06it/s] 41%|████      | 65910/160239 [00:01<00:02, 39713.59it/s] 44%|████▎     | 69882/160239 [00:01<00:02, 39249.97it/s] 46%|████▌     | 73809/160239 [00:01<00:02, 39085.83it/s] 49%|████▊     | 77735/160239 [00:02<00:02, 39136.26it/s] 51%|█████     | 81783/160239 [00:02<00:01, 39532.98it/s] 54%|█████▎    | 85794/160239 [00:02<00:01, 39702.93it/s] 56%|█████▌    | 89824/160239 [00:02<00:01, 39876.97it/s] 59%|█████▊    | 93813/160239 [00:02<00:01, 39457.77it/s] 61%|██████    | 97761/160239 [00:02<00:01, 39383.27it/s] 64%|██████▎   | 101768/160239 [00:02<00:01, 39582.51it/s] 66%|██████▌   | 105727/160239 [00:02<00:01, 39508.62it/s] 68%|██████▊   | 109679/160239 [00:02<00:01, 38964.18it/s] 71%|███████   | 113650/160239 [00:02<00:01, 39182.98it/s] 73%|███████▎  | 117570/160239 [00:03<00:01, 39056.00it/s] 76%|███████▌  | 121552/160239 [00:03<00:00, 39282.62it/s] 78%|███████▊  | 125482/160239 [00:03<00:00, 39188.96it/s] 81%|████████  | 129450/160239 [00:03<00:00, 39332.86it/s] 83%|████████▎ | 133384/160239 [00:03<00:00, 38656.30it/s] 86%|████████▌ | 137317/160239 [00:03<00:00, 38853.16it/s] 88%|████████▊ | 141384/160239 [00:03<00:00, 39387.39it/s] 91%|█████████ | 145325/160239 [00:03<00:00, 39077.87it/s] 93%|█████████▎| 149235/160239 [00:03<00:00, 38397.76it/s] 96%|█████████▌| 153133/160239 [00:03<00:00, 38568.38it/s] 98%|█████████▊| 157146/160239 [00:04<00:00, 39027.77it/s]100%|██████████| 160239/160239 [00:04<00:00, 38905.21it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2039.04it/s]2022-03-20 09:06:02 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-20 09:06:02 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-20 09:06:02 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-20 09:06:02 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-20 09:06:02 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-20 09:06:02 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-20 09:06:02 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-20 09:06:02 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-20 09:06:02 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-20 09:06:02 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-20 09:06:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-20 09:06:02 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-20 09:06:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-20 09:06:02 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-20 09:06:02 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-20 09:06:02 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:06:02 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:06:02 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-20 09:06:02 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-20 09:06:02 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-20 09:06:02 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-20 09:06:03 | INFO | fairseq.trainer | begin training epoch 1
2022-03-20 09:06:03 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-20 09:06:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-20 09:06:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-20 09:06:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-20 09:06:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-20 09:06:48 | INFO | train_inner | epoch 001:    104 / 157 loss=12.845, ppl=7355.43, wps=66591.5, ups=2.63, wpb=25305.7, bsz=1024.9, num_updates=100, lr=1.25e-05, gnorm=2.943, loss_scale=8, train_wall=44, gb_free=12.2, wall=45
2022-03-20 09:07:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:07:10 | INFO | fairseq.tasks.translation | example hypothesis: ..
2022-03-20 09:07:10 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:07:13 | INFO | fairseq.tasks.translation | example hypothesis: ..
2022-03-20 09:07:13 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:07:15 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-20 09:07:15 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:07:18 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,
2022-03-20 09:07:18 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:07:21 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-20 09:07:21 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:07:24 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:07:24 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:07:29 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:07:29 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:07:34 | INFO | fairseq.tasks.translation | example hypothesis: the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:07:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:07:42 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:07:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:07:44 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:07:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:07:44 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.007 | ppl 4117.26 | bleu 0.01 | wps 4881.5 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-20 09:07:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-20 09:07:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:07:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:07:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.7048938707448542 seconds)
2022-03-20 09:07:46 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-20 09:07:46 | INFO | train | epoch 001 | loss 12.427 | ppl 5508.33 | wps 40183.1 | ups 1.59 | wpb 25225.5 | bsz 1001.6 | num_updates 153 | lr 1.9125e-05 | gnorm 2.342 | loss_scale 8 | train_wall 63 | gb_free 12.1 | wall 103
KL Stats: Epoch 1 Divergences: Uniform: 0.5592929161451852 Unigram: 1.465682550520744
2022-03-20 09:07:46 | INFO | fairseq.trainer | begin training epoch 2
2022-03-20 09:07:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:08:04 | INFO | train_inner | epoch 002:     47 / 157 loss=11.448, ppl=2794.71, wps=33088.2, ups=1.31, wpb=25181.6, bsz=982.6, num_updates=200, lr=2.5e-05, gnorm=1.037, loss_scale=8, train_wall=37, gb_free=11.9, wall=121
2022-03-20 09:08:41 | INFO | train_inner | epoch 002:    147 / 157 loss=10.767, ppl=1742.83, wps=67732.4, ups=2.7, wpb=25113.7, bsz=1018.9, num_updates=300, lr=3.75e-05, gnorm=1.113, loss_scale=8, train_wall=37, gb_free=12, wall=159
2022-03-20 09:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:08:48 | INFO | fairseq.tasks.translation | example hypothesis: .
2022-03-20 09:08:48 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:08:51 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and and and and and and and,,,,,,,,,.
2022-03-20 09:08:51 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:08:55 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and.
2022-03-20 09:08:55 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:08:59 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-20 09:08:59 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:09:04 | INFO | fairseq.tasks.translation | example hypothesis: and i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i.
2022-03-20 09:09:04 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:09:09 | INFO | fairseq.tasks.translation | example hypothesis: we we we we we we,,,,,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the.
2022-03-20 09:09:09 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:09:15 | INFO | fairseq.tasks.translation | example hypothesis: and we we we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:09:15 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:09:21 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and and and and and we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we
2022-03-20 09:09:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:09:29 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:09:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:09:31 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-20 09:09:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:09:31 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.279 | ppl 2485.02 | bleu 0.01 | wps 3782.9 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.01
2022-03-20 09:09:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-20 09:09:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:09:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:09:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.01) (writing took 1.954680002760142 seconds)
2022-03-20 09:09:33 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-20 09:09:33 | INFO | train | epoch 002 | loss 10.903 | ppl 1914.35 | wps 36732.2 | ups 1.46 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.025 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 211
KL Stats: Epoch 2 Divergences: Uniform: 0.7149124426300498 Unigram: 0.3845411498783771
2022-03-20 09:09:33 | INFO | fairseq.trainer | begin training epoch 3
2022-03-20 09:09:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:10:08 | INFO | train_inner | epoch 003:     90 / 157 loss=10.461, ppl=1409.1, wps=29161.2, ups=1.15, wpb=25301.4, bsz=1112.6, num_updates=400, lr=5e-05, gnorm=0.989, loss_scale=8, train_wall=37, gb_free=11.8, wall=245
2022-03-20 09:10:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:10:36 | INFO | fairseq.tasks.translation | example hypothesis: and it's.
2022-03-20 09:10:36 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:10:39 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and it it it it it it's's's, and and and it it it it.
2022-03-20 09:10:39 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:10:43 | INFO | fairseq.tasks.translation | example hypothesis: and and and and, and and and and and and and and and and and and and and and and and and and and and and and and and and, and and and and
2022-03-20 09:10:43 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:10:48 | INFO | fairseq.tasks.translation | example hypothesis: and and and the, and the the the, and and and and and the the the the the the the the the, and and and and and the the the the the the the.
2022-03-20 09:10:48 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:10:52 | INFO | fairseq.tasks.translation | example hypothesis: and i, i, i, i, i, i, i i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i
2022-03-20 09:10:52 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:10:58 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we, we, we, we, we, we, we, we, we, and we, we, we, we, we, we, we, we, we, we, and we, we, we, and we, we
2022-03-20 09:10:58 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:11:03 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, we, and we, we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and the, and we, and the the the the the the the the the the the the the
2022-03-20 09:11:03 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:11:09 | INFO | fairseq.tasks.translation | example hypothesis: and and and we we, and we we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we the the the the the, and and and we the the the the the, and and we
2022-03-20 09:11:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:11:17 | INFO | fairseq.tasks.translation | example hypothesis: and and "" "" "" "" "" "" "" "" "" "" "" "" "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-20 09:11:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:11:19 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, and we, we, and we, and we, and we, and the, and we, and we, and we, and we, and we, and we, and the, and we, and we, and we, and the, and we, and the, and the, and we, and we, and the, and we, and we, and we to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to,
2022-03-20 09:11:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:11:19 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.127 | ppl 2236.47 | bleu 0.19 | wps 3767 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.19
2022-03-20 09:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-20 09:11:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:11:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:11:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.19) (writing took 1.8161429851315916 seconds)
2022-03-20 09:11:21 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-20 09:11:21 | INFO | train | epoch 003 | loss 10.443 | ppl 1391.79 | wps 36654.7 | ups 1.46 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.999 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 318
KL Stats: Epoch 3 Divergences: Uniform: 0.9232495974238831 Unigram: 0.35753999184039864
2022-03-20 09:11:21 | INFO | fairseq.trainer | begin training epoch 4
2022-03-20 09:11:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:11:34 | INFO | train_inner | epoch 004:     33 / 157 loss=10.413, ppl=1363.5, wps=29223.6, ups=1.16, wpb=25178.3, bsz=910.4, num_updates=500, lr=6.25e-05, gnorm=1.156, loss_scale=8, train_wall=36, gb_free=12.5, wall=331
2022-03-20 09:12:11 | INFO | train_inner | epoch 004:    133 / 157 loss=10.262, ppl=1227.56, wps=66544.7, ups=2.68, wpb=24784.3, bsz=1026.2, num_updates=600, lr=7.5e-05, gnorm=1.229, loss_scale=8, train_wall=37, gb_free=12.2, wall=369
2022-03-20 09:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:12:24 | INFO | fairseq.tasks.translation | example hypothesis: so this is the.
2022-03-20 09:12:24 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:12:28 | INFO | fairseq.tasks.translation | example hypothesis: and it's that's the that's that's the that's the.
2022-03-20 09:12:28 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:12:33 | INFO | fairseq.tasks.translation | example hypothesis: and but it's a, but but but but but it's a, but it's a of the of the of the of the and it's a.
2022-03-20 09:12:33 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:12:38 | INFO | fairseq.tasks.translation | example hypothesis: and it's the, it's the, it's the world, it's the world of the world, and it's the world.
2022-03-20 09:12:38 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:12:44 | INFO | fairseq.tasks.translation | example hypothesis: so i'm to think it's that i think the that i've've've've've've've've've've've've've've've've've've've've've've've've to be to be to be to be to be to be
2022-03-20 09:12:44 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:12:50 | INFO | fairseq.tasks.translation | example hypothesis: it's a, we can can can can can can can can can can can can can can can can can can can can can can have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to be the
2022-03-20 09:12:50 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:12:56 | INFO | fairseq.tasks.translation | example hypothesis: it's that's that's that's the that's the, it's the that's the of the, it's that's that's that's that's that's the of the that's the that's that's the of the of the that's the of the that's the of the world, it's the that's the world, it's the
2022-03-20 09:12:56 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:13:02 | INFO | fairseq.tasks.translation | example hypothesis: and we're're the of the, and we've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've the the the the the the the the the the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the
2022-03-20 09:13:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:13:10 | INFO | fairseq.tasks.translation | example hypothesis: it's a "" "" "" "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-20 09:13:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:13:12 | INFO | fairseq.tasks.translation | example hypothesis: it's that's a, it's a, it's a, it's a that's a that's a that's a that's a that's a that's a that's a that's a that's a that's a that's a that's a that's a that's a that's that's a that's a that's a that's a that's a that it's a of the that's that's a that's a that's a that's a that's a that's a that's a that's a that's a that's a that's a that's a that's a that's a that's that's a that's a that's a that's a that's a that's a that's that's a that's a that's a that's a that's a that it's a that it's a a that's a that's a that's a that's a that's a that's a that's a that's a that's a that's a that's a that it's a that it's that's
2022-03-20 09:13:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:13:12 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.74 | ppl 1710.04 | bleu 0.56 | wps 3394.6 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.56
2022-03-20 09:13:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-20 09:13:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:13:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:13:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.56) (writing took 1.7548521948046982 seconds)
2022-03-20 09:13:14 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-20 09:13:14 | INFO | train | epoch 004 | loss 10.224 | ppl 1195.75 | wps 34953.9 | ups 1.39 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.272 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 431
KL Stats: Epoch 4 Divergences: Uniform: 0.9358497416628283 Unigram: 0.5295858991589242
2022-03-20 09:13:14 | INFO | fairseq.trainer | begin training epoch 5
2022-03-20 09:13:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:13:43 | INFO | train_inner | epoch 005:     76 / 157 loss=10.006, ppl=1028.18, wps=27426.9, ups=1.09, wpb=25085, bsz=977.3, num_updates=700, lr=8.75e-05, gnorm=1.204, loss_scale=8, train_wall=37, gb_free=12.2, wall=460
2022-03-20 09:13:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-20 09:13:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2022-03-20 09:14:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:14:17 | INFO | fairseq.tasks.translation | example hypothesis: but we can't't't't't't't't't't't't't't't't't't't't't have
2022-03-20 09:14:17 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:14:21 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world, and they're the world.
2022-03-20 09:14:21 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:14:25 | INFO | fairseq.tasks.translation | example hypothesis: and but it's a lot, but it's a lot, but it's a lot.
2022-03-20 09:14:25 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:14:30 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world, and it's the world, and it's the world.
2022-03-20 09:14:30 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:14:35 | INFO | fairseq.tasks.translation | example hypothesis: i'm going to see it, i think it's a lot, i'm going to do it, and i'm going to do it.
2022-03-20 09:14:35 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:14:40 | INFO | fairseq.tasks.translation | example hypothesis: so we can can can see it, we can can see it's a lot.
2022-03-20 09:14:40 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:14:46 | INFO | fairseq.tasks.translation | example hypothesis: and we can see the world, we can do it's the world, and we can do we can do it's going to do it's the world, and we're going to do it?
2022-03-20 09:14:46 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:14:51 | INFO | fairseq.tasks.translation | example hypothesis: and we can see the world, and we can do we can see the world, and we can see the world, and we can see we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world.
2022-03-20 09:14:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:14:58 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" "" "" we said, "" "" "" "" "" "" "" "" "we said,", "" we said, "we said," we said, "" "" we said, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "we said," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-20 09:14:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:15:00 | INFO | fairseq.tasks.translation | example hypothesis: and if we can see that we can see that we have to see the world, and you can see that we can see that we're going to see the world, and you can see the world, and you can see the world, and you can see that we can see the world, and you can see the world, and we can see the world, and you can see the world, and you can see that we can see the world, and we can see the world, and we can see it's the world, and we can see the world, and we can see the world, and we're going to see the world, and we can see that we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see that we're going to see the world, and we can see the world, and we're going to see the world, and we're going to see the world, and we can see that we can see that we can see the world
2022-03-20 09:15:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:15:00 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.468 | ppl 1416.53 | bleu 1.4 | wps 3760.3 | wpb 17862.2 | bsz 728.3 | num_updates 779 | best_bleu 1.4
2022-03-20 09:15:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 779 updates
2022-03-20 09:15:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:15:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:15:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 5 @ 779 updates, score 1.4) (writing took 1.7486006999388337 seconds)
2022-03-20 09:15:02 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-20 09:15:02 | INFO | train | epoch 005 | loss 9.906 | ppl 959.63 | wps 35950.8 | ups 1.43 | wpb 25123.7 | bsz 1019.1 | num_updates 779 | lr 9.7375e-05 | gnorm 1.275 | loss_scale 2 | train_wall 58 | gb_free 12.9 | wall 540
KL Stats: Epoch 5 Divergences: Uniform: 0.9893321239303942 Unigram: 0.7600534563453787
2022-03-20 09:15:02 | INFO | fairseq.trainer | begin training epoch 6
2022-03-20 09:15:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:15:11 | INFO | train_inner | epoch 006:     21 / 157 loss=9.816, ppl=901.62, wps=28587.5, ups=1.14, wpb=25141.2, bsz=1057.6, num_updates=800, lr=0.0001, gnorm=1.325, loss_scale=2, train_wall=38, gb_free=11.6, wall=548
2022-03-20 09:15:48 | INFO | train_inner | epoch 006:    121 / 157 loss=9.555, ppl=752.19, wps=68138.6, ups=2.68, wpb=25388.3, bsz=1073.4, num_updates=900, lr=0.0001125, gnorm=1.239, loss_scale=2, train_wall=37, gb_free=12.3, wall=585
2022-03-20 09:16:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:16:05 | INFO | fairseq.tasks.translation | example hypothesis: these can can can't can can can can can can can can can can can can can can can can can can can be
2022-03-20 09:16:05 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:16:10 | INFO | fairseq.tasks.translation | example hypothesis: and you can see the world, and you can see the world, and they can see the world, and they can see the world.
2022-03-20 09:16:10 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:16:16 | INFO | fairseq.tasks.translation | example hypothesis: and but it's a lot of a lot, but it's a lot of a lot, but it's a lot, but it's a lot, but it's a lot
2022-03-20 09:16:16 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:16:21 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it, and it's
2022-03-20 09:16:21 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:16:27 | INFO | fairseq.tasks.translation | example hypothesis: so i'm going to see it, and i'm going to be going to be going to see it, and i'm going to see it, and i'm going to be going to see it, and i'm going to see it.
2022-03-20 09:16:27 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:16:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see that we can see this is a lot of the world, we can can see that we can be a lot of the world.
2022-03-20 09:16:33 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:16:39 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to do it, and we're going to do we're going to do it, and we're going to do it, and we're going to do, and we're going to do it?
2022-03-20 09:16:39 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:16:45 | INFO | fairseq.tasks.translation | example hypothesis: and so we can see that we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, we can see the world
2022-03-20 09:16:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:16:53 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" "we said," "" we said, "" "" "" "we're going to say," we're going to say, "we're going to say," we're going to do the first, "we're going to say," "we're going to say," "we're going to say," "" "" "" "and we're going to be the first first," we're going to say, "we're going to say," we're going to say, "" "" we're going to say, "we're going to say," we're going to say, "" "" "we're going to say," "" "" "" "we're going to say," "we're going to say," we're going to say, "" "" ""
2022-03-20 09:16:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:16:55 | INFO | fairseq.tasks.translation | example hypothesis: and if if you're going to see that we're going to be a lot of this is that we're going to be a lot of the way, and you're going to be a lot of this is that we're going to be a lot of the way, and you're going to see that we're going to be a lot of the world, if you're going to be a lot of the way, and you're going to see that we're going to see the world, and you're going to be a lot of the world, if you're going to be a lot of this is that we're going to be a lot of the world, and you're going to be a lot of this is that we're going to see that we're going to see that we're going to see that we're going to see the way that we're going to see the way, and you're going to be a lot of the way, and you're going to see the world, and you're going to see it's going to see it's
2022-03-20 09:16:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:16:55 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.212 | ppl 1186.34 | bleu 1.18 | wps 3280.1 | wpb 17862.2 | bsz 728.3 | num_updates 936 | best_bleu 1.4
2022-03-20 09:16:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 936 updates
2022-03-20 09:16:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:16:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:16:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 6 @ 936 updates, score 1.18) (writing took 0.7550878450274467 seconds)
2022-03-20 09:16:56 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-20 09:16:56 | INFO | train | epoch 006 | loss 9.618 | ppl 785.91 | wps 34736.7 | ups 1.38 | wpb 25153.6 | bsz 1020.6 | num_updates 936 | lr 0.000117 | gnorm 1.23 | loss_scale 2 | train_wall 58 | gb_free 12.6 | wall 653
KL Stats: Epoch 6 Divergences: Uniform: 1.044600924206233 Unigram: 0.9200635992121007
2022-03-20 09:16:56 | INFO | fairseq.trainer | begin training epoch 7
2022-03-20 09:16:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:17:20 | INFO | train_inner | epoch 007:     64 / 157 loss=9.486, ppl=717.22, wps=27074, ups=1.08, wpb=24976.9, bsz=1033.6, num_updates=1000, lr=0.000125, gnorm=1.243, loss_scale=2, train_wall=36, gb_free=13, wall=678
2022-03-20 09:17:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:17:59 | INFO | fairseq.tasks.translation | example hypothesis: these can't can be these these these can can can can't can can can can be these these these.
2022-03-20 09:17:59 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:18:04 | INFO | fairseq.tasks.translation | example hypothesis: and they're going to see the world, and they can see the world.
2022-03-20 09:18:04 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:18:09 | INFO | fairseq.tasks.translation | example hypothesis: but it's a lot of the world, but but but it's a lot of the world, but it's a lot of the world and it's a lot of the world
2022-03-20 09:18:09 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:18:15 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's going to see the world.
2022-03-20 09:18:15 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:18:21 | INFO | fairseq.tasks.translation | example hypothesis: and i'm going to see that i'm going to see that i'm going to do it in the world, but i'm going to do that i'm going to do that i'm going to do that i'm going to do it's
2022-03-20 09:18:21 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:18:26 | INFO | fairseq.tasks.translation | example hypothesis: now, we can see that we can see that we can see that we can see that we can see that we can be able to be a lot of how we can see that we can see that we can be able to be able to do this.
2022-03-20 09:18:26 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:18:32 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to do that we're going to do it?
2022-03-20 09:18:32 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:18:39 | INFO | fairseq.tasks.translation | example hypothesis: and so we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see, and we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see
2022-03-20 09:18:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:18:46 | INFO | fairseq.tasks.translation | example hypothesis: and "we said," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" the first, "we said," we said, "we said," we said, "" "" we said, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-20 09:18:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:18:49 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to see that we're going to see that we're going to do that we're going to see that we're going to do that we're going to do that we're going to make the way that we're going to see that we're going to do that we're going to see the way that we're going to see the way that we're going to see the way that we're going to see the way that we're going to see the way that we're going to see the way that we're going to see the way that we're going to make the way that we're going to see the way that we're going to make the way that we're going to see the way that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to make the way that we're going to see that we're going to see that we're going to see the way that we're going to see that we're going to
2022-03-20 09:18:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:18:49 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.008 | ppl 1029.6 | bleu 1.35 | wps 3295.8 | wpb 17862.2 | bsz 728.3 | num_updates 1093 | best_bleu 1.4
2022-03-20 09:18:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1093 updates
2022-03-20 09:18:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:18:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:18:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 7 @ 1093 updates, score 1.35) (writing took 0.8204984292387962 seconds)
2022-03-20 09:18:50 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-20 09:18:50 | INFO | train | epoch 007 | loss 9.4 | ppl 675.58 | wps 34700.4 | ups 1.38 | wpb 25153.6 | bsz 1020.6 | num_updates 1093 | lr 0.000136625 | gnorm 1.094 | loss_scale 2 | train_wall 58 | gb_free 11.7 | wall 767
KL Stats: Epoch 7 Divergences: Uniform: 1.088118373685802 Unigram: 1.028003215892308
2022-03-20 09:18:50 | INFO | fairseq.trainer | begin training epoch 8
2022-03-20 09:18:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:18:53 | INFO | train_inner | epoch 008:      7 / 157 loss=9.385, ppl=668.77, wps=27178.9, ups=1.08, wpb=25226.8, bsz=996.1, num_updates=1100, lr=0.0001375, gnorm=1.004, loss_scale=2, train_wall=37, gb_free=12.9, wall=770
2022-03-20 09:19:31 | INFO | train_inner | epoch 008:    107 / 157 loss=9.303, ppl=631.8, wps=66922.4, ups=2.65, wpb=25234.7, bsz=981.5, num_updates=1200, lr=0.00015, gnorm=1.045, loss_scale=2, train_wall=37, gb_free=12.9, wall=808
2022-03-20 09:19:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:19:53 | INFO | fairseq.tasks.translation | example hypothesis: these can't have these these can't use this.
2022-03-20 09:19:53 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:19:57 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world that you can see the world.
2022-03-20 09:19:57 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:20:01 | INFO | fairseq.tasks.translation | example hypothesis: but there's a lot of the world, and it's a lot of the world.
2022-03-20 09:20:01 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:20:06 | INFO | fairseq.tasks.translation | example hypothesis: and it's a lot of the world, and it's the world.
2022-03-20 09:20:06 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:20:11 | INFO | fairseq.tasks.translation | example hypothesis: so i'm going to show you that i can see it in the world, and i can see it in the world.
2022-03-20 09:20:11 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:20:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see that we can see that we can be able to be able to be able to be able to be able to be able.
2022-03-20 09:20:16 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:20:21 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to do this, and we're going to do it, and we're going to do it, and we're going to do it?
2022-03-20 09:20:21 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:20:27 | INFO | fairseq.tasks.translation | example hypothesis: and so we can see that, and we can see that we can see the way, and then we can see that we can see that we can see the way, and then we can see that we can see that we can see the way, and then we can see that we can see the world.
2022-03-20 09:20:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:20:35 | INFO | fairseq.tasks.translation | example hypothesis: and when we said, "" i said, "" "" "" "" "" "" "" "" the first first time, "we've said," "" we said, "we've said," "" "" "" "" "" "the first first first first first is," "" the first first first first first time, "" "" "" "" we've said, "we've said," we've said, "we've said," "" "we've said," "" "" we've said, "we've said," "" "we've said," "" "" "" "" "" "the first," "" "" "we've said," "" "we've said," "" "" "" "" "" "" "" "
2022-03-20 09:20:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:20:37 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to be a lot of the way that we're going to be going to be able to be able to be able to be going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that we're going to be able to see that we're going to be able to be able to be able to see that we're going to see that we're going to be able to be able to see that we're going to be able to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that
2022-03-20 09:20:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:20:37 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.825 | ppl 907.01 | bleu 2.23 | wps 3692.4 | wpb 17862.2 | bsz 728.3 | num_updates 1250 | best_bleu 2.23
2022-03-20 09:20:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1250 updates
2022-03-20 09:20:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:20:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:20:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 8 @ 1250 updates, score 2.23) (writing took 1.7707830010913312 seconds)
2022-03-20 09:20:39 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-20 09:20:39 | INFO | train | epoch 008 | loss 9.244 | ppl 606.14 | wps 36126.1 | ups 1.44 | wpb 25153.6 | bsz 1020.6 | num_updates 1250 | lr 0.00015625 | gnorm 1.036 | loss_scale 2 | train_wall 58 | gb_free 12.9 | wall 877
KL Stats: Epoch 8 Divergences: Uniform: 1.1230049628212997 Unigram: 1.0927349748298076
2022-03-20 09:20:39 | INFO | fairseq.trainer | begin training epoch 9
2022-03-20 09:20:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:20:58 | INFO | train_inner | epoch 009:     50 / 157 loss=9.199, ppl=587.79, wps=28344.6, ups=1.14, wpb=24881.3, bsz=1011.8, num_updates=1300, lr=0.0001625, gnorm=0.959, loss_scale=2, train_wall=37, gb_free=12.1, wall=896
2022-03-20 09:21:36 | INFO | train_inner | epoch 009:    150 / 157 loss=8.964, ppl=499.53, wps=68768.5, ups=2.67, wpb=25757.6, bsz=1056.4, num_updates=1400, lr=0.000175, gnorm=0.984, loss_scale=2, train_wall=37, gb_free=12.1, wall=933
2022-03-20 09:21:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:21:42 | INFO | fairseq.tasks.translation | example hypothesis: these can't use this.
2022-03-20 09:21:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:21:46 | INFO | fairseq.tasks.translation | example hypothesis: and they're going to see the world, and they're going to see the world.
2022-03-20 09:21:46 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:21:50 | INFO | fairseq.tasks.translation | example hypothesis: but but there's a lot of the world, but there's a lot of the world, and there's a lot of the world.
2022-03-20 09:21:50 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:21:54 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's the world, because it's the world, and it's the world.
2022-03-20 09:21:54 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:21:59 | INFO | fairseq.tasks.translation | example hypothesis: so i can see it, but i can't be able to be able to do it.
2022-03-20 09:21:59 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:22:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to make this.
2022-03-20 09:22:03 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:22:09 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to talk about the world, and we're going to do it, and we're going to do it, and we're going to do it, and we're going to do it, and we're going to do it, and we're going to do it?
2022-03-20 09:22:09 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:22:15 | INFO | fairseq.tasks.translation | example hypothesis: and so if we can use the way that we can do that we can make the brain, and then we can make the brain, and then we can do it, and we can make the brain, and we can be able to do that we can be able to make the brain, and then we can be able to make the brain, and then we can do that we can be able to make the brain.
2022-03-20 09:22:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:22:22 | INFO | fairseq.tasks.translation | example hypothesis: and the first thing is, "" and we've got to say, "" "" "" and then we're going to say, "" "and the first first time," we're going to say, "" and the first time, "we're going to say," "and the first first first time," we're going to say, "" "and the first first first time," we're going to say, "we're going to say," "" and the first first first first first time, "we're going to say," and then we're going to say, "we're going to say," "" and the first first first first first first first first first, "" "" and the first, "you're going to say," we're going to say, "we're going to say," we're going to say
2022-03-20 09:22:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:22:24 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to take the way that we're going to get to get to be a little bit of the way that we're going to be able to be able to be able to make the way, and we're going to be able to get to be able to be able to be able to make the way that we're going to be able to get to be able to be able to be able to make the way that we're going to be able to be able to make the way that we're going to be able to be able to make the way that we're going to be able to make the way that we're going to be able to make the way that we're going to be able to be able to make the way that we're going to be able to be able to make the way that we're going to be able to make the way that we're going to get the way that we're going to make the way that we're going to make the way that we're going to be able to get to get to get the
2022-03-20 09:22:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:22:24 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.673 | ppl 816.33 | bleu 2.65 | wps 3864.6 | wpb 17862.2 | bsz 728.3 | num_updates 1407 | best_bleu 2.65
2022-03-20 09:22:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1407 updates
2022-03-20 09:22:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:22:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:22:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 9 @ 1407 updates, score 2.65) (writing took 1.8282986241392791 seconds)
2022-03-20 09:22:26 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-20 09:22:26 | INFO | train | epoch 009 | loss 9.076 | ppl 539.61 | wps 36789.7 | ups 1.46 | wpb 25153.6 | bsz 1020.6 | num_updates 1407 | lr 0.000175875 | gnorm 0.974 | loss_scale 2 | train_wall 58 | gb_free 12 | wall 984
KL Stats: Epoch 9 Divergences: Uniform: 1.1571559454703124 Unigram: 1.159635039784832
2022-03-20 09:22:27 | INFO | fairseq.trainer | begin training epoch 10
2022-03-20 09:22:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:23:02 | INFO | train_inner | epoch 010:     93 / 157 loss=8.965, ppl=499.56, wps=28936, ups=1.16, wpb=24883.8, bsz=1047.8, num_updates=1500, lr=0.0001875, gnorm=0.922, loss_scale=2, train_wall=37, gb_free=12, wall=1019
2022-03-20 09:23:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:23:29 | INFO | fairseq.tasks.translation | example hypothesis: these can't use these cells.
2022-03-20 09:23:29 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:23:34 | INFO | fairseq.tasks.translation | example hypothesis: and then, it turns out of the world, they see the world.
2022-03-20 09:23:34 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:23:38 | INFO | fairseq.tasks.translation | example hypothesis: but everybody's a lot of a lot of life.
2022-03-20 09:23:38 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:23:43 | INFO | fairseq.tasks.translation | example hypothesis: it's very very very very important, and in the united states, in the united states, the united states.
2022-03-20 09:23:43 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:23:47 | INFO | fairseq.tasks.translation | example hypothesis: it could be just just just just just like me, i can see that i can see it.
2022-03-20 09:23:47 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:23:52 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can be able to be able to be able to be able to be able to be able to be able to be able.
2022-03-20 09:23:52 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:23:56 | INFO | fairseq.tasks.translation | example hypothesis: it's the first thing that we're going to go from the world.
2022-03-20 09:23:56 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:24:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we look at the brain, we can see that we can use the brain, and we can see the brain that we can make a little bit of the brain.
2022-03-20 09:24:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:24:06 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the first time, "we said," you're going to say, "you know," you know, "you know," you're going to say, "you know," you're going to say, "you're going to say," you're going to say, "you know," you know, "you're going to say," you know, "you know," you know, "you're going to say," you're going to say, "you're going to say," you know, "you know," you know, "you know," you know, "you know," the first know, "you know," you know, "you're going to say," you know, "you know," you're going to say, "you're going to say," you're going to say,
2022-03-20 09:24:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:24:08 | INFO | fairseq.tasks.translation | example hypothesis: so, it's a very time that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to the
2022-03-20 09:24:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:24:08 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.472 | ppl 709.99 | bleu 4.01 | wps 4237.3 | wpb 17862.2 | bsz 728.3 | num_updates 1564 | best_bleu 4.01
2022-03-20 09:24:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1564 updates
2022-03-20 09:24:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:24:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:24:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 10 @ 1564 updates, score 4.01) (writing took 1.7650481630116701 seconds)
2022-03-20 09:24:10 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-20 09:24:10 | INFO | train | epoch 010 | loss 8.922 | ppl 485.09 | wps 38125.9 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 1564 | lr 0.0001955 | gnorm 0.974 | loss_scale 2 | train_wall 58 | gb_free 12.2 | wall 1087
KL Stats: Epoch 10 Divergences: Uniform: 1.1946278396084236 Unigram: 1.2180209084793416
2022-03-20 09:24:10 | INFO | fairseq.trainer | begin training epoch 11
2022-03-20 09:24:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:24:24 | INFO | train_inner | epoch 011:     36 / 157 loss=8.804, ppl=447.03, wps=30688.6, ups=1.22, wpb=25104.8, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=1.001, loss_scale=2, train_wall=36, gb_free=12.9, wall=1101
2022-03-20 09:25:01 | INFO | train_inner | epoch 011:    136 / 157 loss=8.788, ppl=442.07, wps=66246.7, ups=2.66, wpb=24875.8, bsz=1009.9, num_updates=1700, lr=0.0002125, gnorm=0.927, loss_scale=2, train_wall=37, gb_free=12.2, wall=1139
2022-03-20 09:25:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:25:13 | INFO | fairseq.tasks.translation | example hypothesis: these can't use.
2022-03-20 09:25:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:25:16 | INFO | fairseq.tasks.translation | example hypothesis: and then, there's no world, you can see the world, you see the world.
2022-03-20 09:25:16 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:25:21 | INFO | fairseq.tasks.translation | example hypothesis: but there's a sense between between between between between between between between between between between between between between between between between between between and.
2022-03-20 09:25:21 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:25:25 | INFO | fairseq.tasks.translation | example hypothesis: now, it's very important, in the united states, in the united states, and there are the united states, the united states, and the united states, and the united states are the united states.
2022-03-20 09:25:25 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:25:30 | INFO | fairseq.tasks.translation | example hypothesis: it also also also also also also, as i'm interested in the world, i'm going to look at the world, i'm going to look at the world.
2022-03-20 09:25:30 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:25:35 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can imagine how we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-20 09:25:35 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:25:40 | INFO | fairseq.tasks.translation | example hypothesis: it's going to talk about how we have to talk about the world, and what we're going to talk about the most of our kids who are going to come from our children, and our children who are going to help us from our children, and our own own own children, and our children.
2022-03-20 09:25:40 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:25:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we look at the information, we can do this information, and we can do the information of the information that we can do with the brain, and we can make the brain, and we can do this information, and we can make the brain of the brain, and we can make the brain, and we can do this kind of the brain, and we can make the brain, and we can do it.
2022-03-20 09:25:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:25:53 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons, there's a lot of course, and it's a lot of course, "i'm going to say," if you're going to say, "if you're going to say," you're going to say, "and you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," if you're going to tell you know, "you know," you know, "you're going to say," you know, "you know," you know, "you know," you're going to say, "you know," you know, "you're going to say," you know, "you know," you know, "you know," you know, "you're going to say," you know, "you know,
2022-03-20 09:25:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:25:55 | INFO | fairseq.tasks.translation | example hypothesis: well, it's still still still even even even even even even even even when we're going to have the same thing that we're going to do with the world, and if we're going to do that, if we're going to be able to make a little bit of the world, if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to create a little bit that we're going to be able to be able to be able to create a little bit that we're going to be able to be able to be able to be able to be able to
2022-03-20 09:25:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:25:55 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.249 | ppl 608.65 | bleu 4.85 | wps 3880.3 | wpb 17862.2 | bsz 728.3 | num_updates 1721 | best_bleu 4.85
2022-03-20 09:25:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1721 updates
2022-03-20 09:25:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:25:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:25:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 11 @ 1721 updates, score 4.85) (writing took 1.7697643148712814 seconds)
2022-03-20 09:25:57 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-20 09:25:57 | INFO | train | epoch 011 | loss 8.731 | ppl 424.84 | wps 36998.5 | ups 1.47 | wpb 25153.6 | bsz 1020.6 | num_updates 1721 | lr 0.000215125 | gnorm 0.913 | loss_scale 2 | train_wall 58 | gb_free 12.3 | wall 1194
KL Stats: Epoch 11 Divergences: Uniform: 1.2389485062404988 Unigram: 1.27702071156815
2022-03-20 09:25:57 | INFO | fairseq.trainer | begin training epoch 12
2022-03-20 09:25:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:26:27 | INFO | train_inner | epoch 012:     79 / 157 loss=8.511, ppl=364.83, wps=30014.5, ups=1.17, wpb=25693.2, bsz=1070.2, num_updates=1800, lr=0.000225, gnorm=0.996, loss_scale=2, train_wall=37, gb_free=11.5, wall=1224
2022-03-20 09:26:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:27:00 | INFO | fairseq.tasks.translation | example hypothesis: these can't use a cow.
2022-03-20 09:27:00 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:27:04 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, they didn't think it's the world.
2022-03-20 09:27:04 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:27:08 | INFO | fairseq.tasks.translation | example hypothesis: but everybody has a difference between a difference between between between between between between the difference and language.
2022-03-20 09:27:08 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:27:12 | INFO | fairseq.tasks.translation | example hypothesis: very important, and it has been working on the united states, and the united states are the united states.
2022-03-20 09:27:12 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:27:16 | INFO | fairseq.tasks.translation | example hypothesis: it could also also also me how i'm looking at the same time i can do on the other other side.
2022-03-20 09:27:16 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:27:20 | INFO | fairseq.tasks.translation | example hypothesis: so as we can imagine our brain, as we can use this new way, if it would be able to be able to be able to be able to be a new new way.
2022-03-20 09:27:20 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:27:24 | INFO | fairseq.tasks.translation | example hypothesis: and it's the question that we've got to talk about from the age of the age, and the most important person, and the most of our children, and the most of our children, and our children, the children, and they're talking about them.
2022-03-20 09:27:24 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:27:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information of information, we can do this kind of information, and we can do a kind of information, and we can make a kind of information that can make a kind of information, and the information.
2022-03-20 09:27:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:27:33 | INFO | fairseq.tasks.translation | example hypothesis: dh: one of the reasons, and it's really interesting for me, "and i'm going to say," "if we're going to say," "" if you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, ""
2022-03-20 09:27:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:27:35 | INFO | fairseq.tasks.translation | example hypothesis: well, in fact, the mother has been a way, and if we're going to do the way that we're going to be able to do a new way that we've been able to do it, and then we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do the same time.
2022-03-20 09:27:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:27:35 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.02 | ppl 519.07 | bleu 7.53 | wps 4613.6 | wpb 17862.2 | bsz 728.3 | num_updates 1878 | best_bleu 7.53
2022-03-20 09:27:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1878 updates
2022-03-20 09:27:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:27:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:27:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 12 @ 1878 updates, score 7.53) (writing took 1.782097693067044 seconds)
2022-03-20 09:27:37 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-20 09:27:37 | INFO | train | epoch 012 | loss 8.568 | ppl 379.41 | wps 39295.9 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 1878 | lr 0.00023475 | gnorm 0.995 | loss_scale 2 | train_wall 58 | gb_free 11.6 | wall 1295
KL Stats: Epoch 12 Divergences: Uniform: 1.2744422054087976 Unigram: 1.3267923446296856
2022-03-20 09:27:37 | INFO | fairseq.trainer | begin training epoch 13
2022-03-20 09:27:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:27:46 | INFO | train_inner | epoch 013:     22 / 157 loss=8.585, ppl=384.09, wps=31675.5, ups=1.26, wpb=25085.8, bsz=963.8, num_updates=1900, lr=0.0002375, gnorm=0.96, loss_scale=2, train_wall=37, gb_free=12, wall=1304
2022-03-20 09:28:23 | INFO | train_inner | epoch 013:    122 / 157 loss=8.326, ppl=320.82, wps=67346.2, ups=2.7, wpb=24959.9, bsz=1062.8, num_updates=2000, lr=0.00025, gnorm=0.98, loss_scale=2, train_wall=37, gb_free=11.9, wall=1341
2022-03-20 09:28:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:28:40 | INFO | fairseq.tasks.translation | example hypothesis: this can't be able to use these materials.
2022-03-20 09:28:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:28:44 | INFO | fairseq.tasks.translation | example hypothesis: and all of course, they don't see that they see the world.
2022-03-20 09:28:44 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:28:49 | INFO | fairseq.tasks.translation | example hypothesis: but everybody else else else else else between a difference between between the difference, and there's a difference.
2022-03-20 09:28:49 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:28:53 | INFO | fairseq.tasks.translation | example hypothesis: very interesting. it's happening on the united states, and it's happening in countries, and the united states, the united states, and the united states are the united states.
2022-03-20 09:28:53 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:28:58 | INFO | fairseq.tasks.translation | example hypothesis: it could also also be interested as well as well as i'm interested in my way, so i'm looking at the other side of the other side.
2022-03-20 09:28:58 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:29:03 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can imagine our computer computer, we can imagine how to use this new new new new brain, as a new new new new new new way, when it would be a new new way.
2022-03-20 09:29:03 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:29:07 | INFO | fairseq.tasks.translation | example hypothesis: it's the important thing we've heard from from from the university of the university, where we've got to talk from the university of the university, from the university of our students, and how many children are going to go to help our children.
2022-03-20 09:29:07 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:29:12 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information of information, the information that we can use with this kind of information, we can see with a kind of information, and we can see the information that we can do with the information, and then we can see the information, the information, the information that's going to make the information, and the information of the information that's going to make the information.
2022-03-20 09:29:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:29:18 | INFO | fairseq.tasks.translation | example hypothesis: rb: one of the reasons that it's interesting for me, and it's interesting for me, and it's interesting for me to tell me, "and i'm going to tell you," i'm going to tell you, "what's going to tell you," if we're going to say, "what's going to say," if we're going to say, "if we're going to say," what's going to say, "if we're going to say," the women's going to say, "what's going to say," what's going to say, "what's going to say," what's going to say, "what's going to tell you're going to say," what's going to say, "what's going to say," what's going to say, "what's going to tell you're going to say," and
2022-03-20 09:29:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:29:20 | INFO | fairseq.tasks.translation | example hypothesis: well, in fact, the mother's mother's mother's mother, and the mother's work of the work, and the work, and the work of the work, and we're going to see the way that we're going to see the way that we're going to see the internet, and we're going to look at a little bit of the world.
2022-03-20 09:29:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:29:20 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.898 | ppl 476.98 | bleu 8.07 | wps 4110.3 | wpb 17862.2 | bsz 728.3 | num_updates 2035 | best_bleu 8.07
2022-03-20 09:29:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2035 updates
2022-03-20 09:29:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:29:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:29:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 13 @ 2035 updates, score 8.07) (writing took 1.7596504199318588 seconds)
2022-03-20 09:29:22 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-20 09:29:22 | INFO | train | epoch 013 | loss 8.341 | ppl 324.2 | wps 37678.7 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 2035 | lr 0.000254375 | gnorm 0.935 | loss_scale 2 | train_wall 58 | gb_free 11.9 | wall 1399
KL Stats: Epoch 13 Divergences: Uniform: 1.319996048818382 Unigram: 1.3836918414711816
2022-03-20 09:29:22 | INFO | fairseq.trainer | begin training epoch 14
2022-03-20 09:29:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:29:47 | INFO | train_inner | epoch 014:     65 / 157 loss=8.092, ppl=272.88, wps=30647.9, ups=1.19, wpb=25826.2, bsz=1074.6, num_updates=2100, lr=0.0002625, gnorm=0.899, loss_scale=2, train_wall=37, gb_free=12.2, wall=1425
2022-03-20 09:30:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:30:25 | INFO | fairseq.tasks.translation | example hypothesis: this is no chemical use use.
2022-03-20 09:30:25 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:30:29 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, no, they see it, they see the world in the world.
2022-03-20 09:30:29 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:30:34 | INFO | fairseq.tasks.translation | example hypothesis: but every musician has a different relationship between between, between the power and intelligence, and intelligence.
2022-03-20 09:30:34 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:30:38 | INFO | fairseq.tasks.translation | example hypothesis: now, very important, it's going to go to china, and china, the united states, and the united states are the united states of united states.
2022-03-20 09:30:38 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:30:42 | INFO | fairseq.tasks.translation | example hypothesis: it could also also be interested as i'm going to do, so i'm so so so on my side side on the other side of the other side.
2022-03-20 09:30:42 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:30:47 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can imagine our computer computer, we can imagine the brain of this new new brain, if it would be a new way to be able to be a part of the brain.
2022-03-20 09:30:47 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:30:51 | INFO | fairseq.tasks.translation | example hypothesis: and it's the ability? we've got to talk from the university of jy, from the university of science, who are going to come from our children, and many children who come out of our children.
2022-03-20 09:30:51 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:30:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, we can use the information that we can start with a network, we can start able to start with a structure, and then we can use the structure of the structure, the structure of the structure of the structure, and the structure of the structure of information.
2022-03-20 09:30:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:31:00 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting and interesting for me, "i'm going to do this for me to say," well, "well," you know, "you know," you know, "you know," you know, "you know," well, "you know," you know, "hey," hey, "you know," hey, "you know," hey, "hey," hey, "you know," you know, "well," well, "well," you know, "you know," hey, "you know," hey, "hey," you know, "hey," you know, "hey," well, "you know," well, "hey," well, "well," you know, "hey," hey, "you know," well, "
2022-03-20 09:31:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:31:03 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, again, the mother's mother's mother, and we've been a great work on our work, and we're going to see that if we were able to see the surface of the surface, we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to create a problem.
2022-03-20 09:31:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:31:03 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.538 | ppl 371.7 | bleu 10.99 | wps 4368.5 | wpb 17862.2 | bsz 728.3 | num_updates 2192 | best_bleu 10.99
2022-03-20 09:31:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2192 updates
2022-03-20 09:31:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:31:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:31:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 14 @ 2192 updates, score 10.99) (writing took 1.7833073739893734 seconds)
2022-03-20 09:31:04 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-20 09:31:04 | INFO | train | epoch 014 | loss 8.127 | ppl 279.61 | wps 38534.3 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 2192 | lr 0.000274 | gnorm 0.942 | loss_scale 2 | train_wall 58 | gb_free 11.9 | wall 1502
KL Stats: Epoch 14 Divergences: Uniform: 1.3567785610120189 Unigram: 1.41677402720244
2022-03-20 09:31:05 | INFO | fairseq.trainer | begin training epoch 15
2022-03-20 09:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:31:08 | INFO | train_inner | epoch 015:      8 / 157 loss=8.236, ppl=301.52, wps=30225, ups=1.24, wpb=24314.6, bsz=903.3, num_updates=2200, lr=0.000275, gnorm=0.946, loss_scale=2, train_wall=36, gb_free=12, wall=1505
2022-03-20 09:31:45 | INFO | train_inner | epoch 015:    108 / 157 loss=7.949, ppl=247.1, wps=66726.1, ups=2.66, wpb=25063.9, bsz=1097.2, num_updates=2300, lr=0.0002875, gnorm=0.989, loss_scale=2, train_wall=37, gb_free=12.5, wall=1543
2022-03-20 09:32:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:32:07 | INFO | fairseq.tasks.translation | example hypothesis: these rocks can't use chemical chemical materials.
2022-03-20 09:32:07 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:32:11 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without course, they see that they see the world.
2022-03-20 09:32:11 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:32:15 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different difference between intelligence.
2022-03-20 09:32:15 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:32:18 | INFO | fairseq.tasks.translation | example hypothesis: especially especially in japan, there are japan, and the countries are the united states of the united states.
2022-03-20 09:32:18 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:32:22 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested as i'm going to make my attention on the other side.
2022-03-20 09:32:22 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:32:26 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can imagine our computer, we can create this new tool as a new tool.
2022-03-20 09:32:26 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:32:30 | INFO | fairseq.tasks.translation | example hypothesis: is it it? what do we come from from the university of university, and we come from the science of science, and many kids go to school.
2022-03-20 09:32:30 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:32:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, we can start able to start able to start with this kind of design, and we can start able to start able to create the shape of the structure of the structure of information.
2022-03-20 09:32:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:32:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting for me, and i'm going to be able to be here, "yes," yes, "yes," well, "well," well, "if we're going to tell you that the best time we're going to say," if you're going to say, "if you're going to say," well, "well," if you're going to say, "if you're going to say," well, "well," well, "well," if you're going to say, "if you're going to say," if you're looking at a long time, "hey," hey, "if you're looking at the best time," hey, "if you're looking at the best time," hey, "hey, the best time," what the best time we're going to do
2022-03-20 09:32:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:32:39 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still a great design, and we're going to see the design of our work that we had to see that if we had to solve the surface of the surface, if we had to make a huge model of the surface of the surface of the surface of a system that we had to be able to solve the surface of a huge system.
2022-03-20 09:32:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:32:39 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.504 | ppl 363.09 | bleu 10.06 | wps 5140 | wpb 17862.2 | bsz 728.3 | num_updates 2349 | best_bleu 10.99
2022-03-20 09:32:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2349 updates
2022-03-20 09:32:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:32:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:32:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 15 @ 2349 updates, score 10.06) (writing took 0.7719341521151364 seconds)
2022-03-20 09:32:40 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-20 09:32:40 | INFO | train | epoch 015 | loss 7.937 | ppl 245.08 | wps 41265.5 | ups 1.64 | wpb 25153.6 | bsz 1020.6 | num_updates 2349 | lr 0.000293625 | gnorm 0.943 | loss_scale 2 | train_wall 58 | gb_free 12.2 | wall 1598
KL Stats: Epoch 15 Divergences: Uniform: 1.3986489191782308 Unigram: 1.45231904812586
2022-03-20 09:32:40 | INFO | fairseq.trainer | begin training epoch 16
2022-03-20 09:32:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:33:00 | INFO | train_inner | epoch 016:     51 / 157 loss=7.734, ppl=212.93, wps=34818.3, ups=1.34, wpb=26004.8, bsz=1066.4, num_updates=2400, lr=0.0003, gnorm=0.89, loss_scale=2, train_wall=37, gb_free=11.8, wall=1618
2022-03-20 09:33:37 | INFO | train_inner | epoch 016:    151 / 157 loss=7.859, ppl=232.2, wps=66532.7, ups=2.71, wpb=24526.6, bsz=925.6, num_updates=2500, lr=0.0003125, gnorm=0.876, loss_scale=2, train_wall=37, gb_free=12.3, wall=1654
2022-03-20 09:33:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:33:43 | INFO | fairseq.tasks.translation | example hypothesis: these rocks can't use chemical chemical materials.
2022-03-20 09:33:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:33:48 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without course, you can see it without the world, you see the world.
2022-03-20 09:33:48 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:33:53 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different amount between the weight between the weight between intelligence and intelligence, and intelligence.
2022-03-20 09:33:53 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:33:58 | INFO | fairseq.tasks.translation | example hypothesis: especially, especially, it's very focus on japan, and in japan, in japan, the united states, and the united states, the united states are the united states.
2022-03-20 09:33:58 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:34:03 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me, so i'm so interested in my hand, so i can focus on the other side of the other side.
2022-03-20 09:34:03 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:34:07 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can imagine our computer computer, as we can imagine our brains, the new tools of the brain, when it would be a new form of the body.
2022-03-20 09:34:07 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:34:12 | INFO | fairseq.tasks.translation | example hypothesis: is it? we've got to have the impact of professor, from the university, from stanford, who are coming out of the scientific science, and many kids that are going to come from our research, and many of the scientific technologies that are going to get on on on.
2022-03-20 09:34:12 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:34:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information of information that we can start able to start with with a sense of traditional knowledge, and we can start able to start with it, and we can start able to start with it through the structure of the structure, and that's a different structure of information.
2022-03-20 09:34:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:34:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting to be interesting for me, "well," well, "well," that's the best thing we're going to say, "well," well, "well," well, "if you're going to say," if you're going to say, "well," well, "and if you're going to say," well, "well," well, "well," well, "well," well, "well," you're going to be the best for example, "and you're going to do it's the best for you're going to be the best for example," and you're going to do it's the best for example, "and you know," and you're going to do it's the best reasons, "and you're going to be the best for
2022-03-20 09:34:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:34:27 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still important, the mother, and the invention of the design of our work, and we have to be able to be able to be able to see that if we're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to solve with a problem with a big, and to be able to be able to solve the surface, and the surface of the surface of the surface of the surface of the surface, and we're still able to see that we're still able to see that we're still able to see that we're still able to see that we're still able to be able to see that we're still able to see that we're still able to see that we're still able to see that we're still able to see that we're still able to
2022-03-20 09:34:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:34:27 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.346 | ppl 325.46 | bleu 10.78 | wps 3782 | wpb 17862.2 | bsz 728.3 | num_updates 2506 | best_bleu 10.99
2022-03-20 09:34:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2506 updates
2022-03-20 09:34:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:34:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:34:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 16 @ 2506 updates, score 10.78) (writing took 0.7585478471592069 seconds)
2022-03-20 09:34:28 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-20 09:34:28 | INFO | train | epoch 016 | loss 7.763 | ppl 217.23 | wps 36754.8 | ups 1.46 | wpb 25153.6 | bsz 1020.6 | num_updates 2506 | lr 0.00031325 | gnorm 0.925 | loss_scale 2 | train_wall 58 | gb_free 11.8 | wall 1705
KL Stats: Epoch 16 Divergences: Uniform: 1.4432275459935155 Unigram: 1.4765410047357457
2022-03-20 09:34:28 | INFO | fairseq.trainer | begin training epoch 17
2022-03-20 09:34:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:35:04 | INFO | train_inner | epoch 017:     94 / 157 loss=7.631, ppl=198.29, wps=29004.4, ups=1.15, wpb=25144.7, bsz=1015.6, num_updates=2600, lr=0.000325, gnorm=0.876, loss_scale=2, train_wall=37, gb_free=11.9, wall=1741
2022-03-20 09:35:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:35:31 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use a chemical rape.
2022-03-20 09:35:31 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:35:35 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, you can see it without the world, you see the world.
2022-03-20 09:35:35 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:35:39 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different weight between the weight between the weight, and intelligence and intelligence and intelligence.
2022-03-20 09:35:39 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:35:44 | INFO | fairseq.tasks.translation | example hypothesis: especially, it's very focus on japan, and japan, australia, australia, australia, australia, and australia, the united states of the united states, which is the united states.
2022-03-20 09:35:44 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:35:48 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me, so i'm focused on my attention, so i can put my attention on the other side of the other side.
2022-03-20 09:35:48 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:35:52 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can imagine our computer, we can imagine the brain of the brain as a new tool of the brain, when it would be a part of the body.
2022-03-20 09:35:52 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:35:56 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we've got the impact of college, from berbery, at stanford university, and the scientific scientific scientific scientific scientific research, and many kids come to our experiments.
2022-03-20 09:35:56 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:36:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of this reflection, we can start able to start with a traditional face of the traditional face, and we can start able to start with the real face of the face of the physical structure, and there's a real shape of the physical structure.
2022-03-20 09:36:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:36:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to be here for tedson, "yeah, it's the best thing to be the best thing that someone's been working with you."
2022-03-20 09:36:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:36:07 | INFO | fairseq.tasks.translation | example hypothesis: so, unfortunately,, the mother is still the invention of the invention, and a huge part of the design that we had to solve on our aircraft, when we had to solve the ground, we had to solve the problem, if we had to solve the ground, it's a unique system, if you had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to solve the ground, if we had to be able to solve the ground, if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to solve the ground with the ground, if we had to see the ground, if we had to solve the ground, if we had to solve the ground, we had to be able to solve the ground, we had to solve the ground, if we had to solve the ground, if we had to solve the ground, if we had
2022-03-20 09:36:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:36:07 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.092 | ppl 272.92 | bleu 16.15 | wps 4454.1 | wpb 17862.2 | bsz 728.3 | num_updates 2663 | best_bleu 16.15
2022-03-20 09:36:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2663 updates
2022-03-20 09:36:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:36:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:36:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 17 @ 2663 updates, score 16.15) (writing took 1.7457340648397803 seconds)
2022-03-20 09:36:09 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-20 09:36:09 | INFO | train | epoch 017 | loss 7.568 | ppl 189.71 | wps 38819.7 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 2663 | lr 0.000332875 | gnorm 0.816 | loss_scale 2 | train_wall 58 | gb_free 11.8 | wall 1807
KL Stats: Epoch 17 Divergences: Uniform: 1.4871938532227937 Unigram: 1.5087568507733908
2022-03-20 09:36:10 | INFO | fairseq.trainer | begin training epoch 18
2022-03-20 09:36:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:36:24 | INFO | train_inner | epoch 018:     37 / 157 loss=7.514, ppl=182.73, wps=31319.3, ups=1.25, wpb=25102.2, bsz=1012.5, num_updates=2700, lr=0.0003375, gnorm=0.808, loss_scale=2, train_wall=37, gb_free=12, wall=1821
2022-03-20 09:37:01 | INFO | train_inner | epoch 018:    137 / 157 loss=7.377, ppl=166.27, wps=67441.3, ups=2.67, wpb=25254.6, bsz=1049.1, num_updates=2800, lr=0.00035, gnorm=0.82, loss_scale=2, train_wall=37, gb_free=11.8, wall=1859
2022-03-20 09:37:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:37:12 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rags.
2022-03-20 09:37:12 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:37:16 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without sure, you see, you see the world, the world is different.
2022-03-20 09:37:16 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:37:20 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between equality and uncertainty, intelligence and intelligence.
2022-03-20 09:37:20 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:37:24 | INFO | fairseq.tasks.translation | example hypothesis: very focus on japan, australia and australia, australia, australia, australia, australia, the united states of the united states.
2022-03-20 09:37:24 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:37:29 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused on my attention, so i'm my attention in the other side.
2022-03-20 09:37:29 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:37:32 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can imagine our computer, the brain, the brain of this new tool, when it was part of the body.
2022-03-20 09:37:32 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:37:37 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have students from berbery, from berbery, at stanford, from the indian institute, and many children come to our normal experiments, and many of our normal experiments.
2022-03-20 09:37:37 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:37:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection comes from a traditional face, we can start with a traditional face of the face of the face of the face, and there's all the information.
2022-03-20 09:37:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:37:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure, for me, for tedtedwomen, is that... "'"' "'"' "'"' "'"' "'"] "'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '
2022-03-20 09:37:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:37:48 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother of the invention, and a great part of design, we had to use on our airplane, and we had a unique level of the ground, and we had to see it, if we had to see it in the ground, it's a unique level of the ground.
2022-03-20 09:37:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:37:48 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 7.955 | ppl 248.08 | bleu 17.05 | wps 4619.9 | wpb 17862.2 | bsz 728.3 | num_updates 2820 | best_bleu 17.05
2022-03-20 09:37:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2820 updates
2022-03-20 09:37:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:37:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:37:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 18 @ 2820 updates, score 17.05) (writing took 1.7817243388853967 seconds)
2022-03-20 09:37:49 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-20 09:37:49 | INFO | train | epoch 018 | loss 7.404 | ppl 169.36 | wps 39442.4 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 2820 | lr 0.0003525 | gnorm 0.838 | loss_scale 2 | train_wall 58 | gb_free 12 | wall 1907
KL Stats: Epoch 18 Divergences: Uniform: 1.5237731449357297 Unigram: 1.5334843309501596
2022-03-20 09:37:50 | INFO | fairseq.trainer | begin training epoch 19
2022-03-20 09:37:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:38:20 | INFO | train_inner | epoch 019:     80 / 157 loss=7.222, ppl=149.32, wps=32286.3, ups=1.26, wpb=25549.3, bsz=990.1, num_updates=2900, lr=0.0003625, gnorm=0.761, loss_scale=2, train_wall=37, gb_free=11.9, wall=1938
2022-03-20 09:38:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:38:52 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rags.
2022-03-20 09:38:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:38:56 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you see it, you see the world.
2022-03-20 09:38:56 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:39:01 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different equation between the weight and uncertainty, and intelligence and intelligence and intelligence.
2022-03-20 09:39:01 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:39:05 | INFO | fairseq.tasks.translation | example hypothesis: very focus on japan, japan and australia, australia, australia, australia, australia, and australia, the united states, the united states of the united states are the united states.
2022-03-20 09:39:05 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:39:09 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me, as i'm focused, so i'm focused on my attention, so i can put my attention on the other side on the other side.
2022-03-20 09:39:09 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:39:14 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can imagine our computer, we can imagine our computers, the brain of this new tool to form this new tool as a primate of the body, if it would be part of the body.
2022-03-20 09:39:14 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:39:18 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact of influence? we have professor professor from berberbery, from berberberbery, at stanford university, from the scientific science institute, and many of our children who are going to go to the normal experiments.
2022-03-20 09:39:18 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:39:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the information of this reflection comes from this reflection, we can start with a traditional face of the face of the face of the face, and there's a real structure that gives all the information through the information.
2022-03-20 09:39:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:39:27 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons of the reasons that it's interesting, and measure it for me to be interesting to be here for tedwomen, is that it was the best thing that someone said, "someone who said," if you're working with you're working on the most important revolution, and then you're working with you're working with you're working on this revolution, "you're working on the most interesting women, and then you're working with you're working with you're working with the most interesting to help you know, and you know," the most interesting, and then you're working on the most interesting to help you're working with the most interesting, "the most interesting, and you're working on the most interesting," the most interesting, "you know, and you know, and then you know," you know, "the most interesting," the most interesting, "
2022-03-20 09:39:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:39:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother still needs the invention of the invention, and a great part of the design of design that we had to solve is a unique result that we had to solve the problems that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see everything in the ground with a different, or the ground with a mechanism the ground, and the ground with the ground with the ground, and the ground, if you're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-20 09:39:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:39:30 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.839 | ppl 228.96 | bleu 18.69 | wps 4389.6 | wpb 17862.2 | bsz 728.3 | num_updates 2977 | best_bleu 18.69
2022-03-20 09:39:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2977 updates
2022-03-20 09:39:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:39:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:39:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 19 @ 2977 updates, score 18.69) (writing took 1.7628963361494243 seconds)
2022-03-20 09:39:31 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-20 09:39:31 | INFO | train | epoch 019 | loss 7.195 | ppl 146.56 | wps 38732.1 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 2977 | lr 0.000372125 | gnorm 0.744 | loss_scale 2 | train_wall 58 | gb_free 12.3 | wall 2009
KL Stats: Epoch 19 Divergences: Uniform: 1.561802649804824 Unigram: 1.5701464057106902
2022-03-20 09:39:32 | INFO | fairseq.trainer | begin training epoch 20
2022-03-20 09:39:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:39:40 | INFO | train_inner | epoch 020:     23 / 157 loss=7.148, ppl=141.79, wps=30810.2, ups=1.25, wpb=24656.4, bsz=1036, num_updates=3000, lr=0.000375, gnorm=0.773, loss_scale=2, train_wall=36, gb_free=11.8, wall=2018
2022-03-20 09:40:18 | INFO | train_inner | epoch 020:    123 / 157 loss=7.045, ppl=132.03, wps=67820.7, ups=2.65, wpb=25584.9, bsz=1046.4, num_updates=3100, lr=0.0003875, gnorm=0.751, loss_scale=2, train_wall=37, gb_free=13.8, wall=2056
2022-03-20 09:40:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:40:34 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rays.
2022-03-20 09:40:34 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:40:38 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without sure you see it, you see the world's different.
2022-03-20 09:40:38 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:40:43 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different equation between believe, and uncertainty and intelligence.
2022-03-20 09:40:43 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:40:46 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly particularly focused on japan, korea, australia, australia, australia, australia, and australia, countries, who are connected to the united states.
2022-03-20 09:40:46 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:40:51 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me, as i'm focused on, so i'm able to focus my attention in the circuit.
2022-03-20 09:40:51 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:40:55 | INFO | fairseq.tasks.translation | example hypothesis: so, as fast as we can reform our computer, layers the brains to form this new tool as it would be part of the body.
2022-03-20 09:40:55 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:40:59 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from berberbery, stanford, from the indian science institute, stanford, stanford institute, stanford institute, from the indian science institute, and many kids who come to school.
2022-03-20 09:40:59 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:41:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that can reflect from this reflection, we can start with a traditional face, we can start able to start with a traditional face that can start with a traditional face, and there's the real shape of the right shape, and then there's a whole piece of information that is a whole structure, and that is a whole piece of information that's all the structure, and that is a structure.
2022-03-20 09:41:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:41:09 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons it's interesting and measure it, for me to be here in tedwomen, is that... yes, when it was the best thing that someone said, "if you say," if you're working on, you're working on a table, "and you're working on, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, and you know, you know, you know, and you know, you know, you know, you know, you know, you know, you know, you know, and you know, you know, and you know, you know, you know, you know, and you know,"
2022-03-20 09:41:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:41:11 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, luckily, the mother's mother's invention, and a big part of design work that we were on on the plane, which was a result that we had to solve, is that we had to solve the unique problems that were connected to the ground, and if you're able to see it.
2022-03-20 09:41:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:41:11 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.659 | ppl 202.15 | bleu 20.3 | wps 4393.3 | wpb 17862.2 | bsz 728.3 | num_updates 3134 | best_bleu 20.3
2022-03-20 09:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3134 updates
2022-03-20 09:41:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:41:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:41:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 20 @ 3134 updates, score 20.3) (writing took 1.74683492584154 seconds)
2022-03-20 09:41:13 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-20 09:41:13 | INFO | train | epoch 020 | loss 7.073 | ppl 134.6 | wps 38752.4 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 3134 | lr 0.00039175 | gnorm 0.765 | loss_scale 2 | train_wall 58 | gb_free 12.9 | wall 2111
KL Stats: Epoch 20 Divergences: Uniform: 1.5930049055982942 Unigram: 1.586955540051448
2022-03-20 09:41:14 | INFO | fairseq.trainer | begin training epoch 21
2022-03-20 09:41:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:41:39 | INFO | train_inner | epoch 021:     66 / 157 loss=7.067, ppl=134.04, wps=30571.9, ups=1.24, wpb=24648.1, bsz=972.6, num_updates=3200, lr=0.0004, gnorm=0.73, loss_scale=2, train_wall=37, gb_free=11.5, wall=2136
2022-03-20 09:42:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:42:17 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-20 09:42:17 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:42:21 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without seeing it, you see the world different.
2022-03-20 09:42:21 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:42:25 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between believe, and unconscious, instincts and intelligence.
2022-03-20 09:42:25 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:42:29 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries who are connected to united states.
2022-03-20 09:42:29 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:42:33 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me how i'm focused, so i can get my attention to the circulation on the other side.
2022-03-20 09:42:33 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:42:37 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can reform our computers, lasting the brains to form this new tool as it would be part of the prices.
2022-03-20 09:42:37 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:42:41 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from berberky, stanford, at stanford, and we have a lot of scientific experiments that are going to do.
2022-03-20 09:42:41 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:42:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big concrete of the face, and then there's all the information that gives you to the structure of this structure, and it's a structure that gives you a whole structure, and the whole structure, and the whole structure of the structure, and that's all of the structure.
2022-03-20 09:42:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:42:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it, "for me, we've been working on tedwomen."
2022-03-20 09:42:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:42:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design that we have to be able to solve in the plane was a result of the unique problems that we had to solve.
2022-03-20 09:42:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:42:52 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.544 | ppl 186.67 | bleu 20.68 | wps 4715.7 | wpb 17862.2 | bsz 728.3 | num_updates 3291 | best_bleu 20.68
2022-03-20 09:42:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3291 updates
2022-03-20 09:42:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:42:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:42:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 21 @ 3291 updates, score 20.68) (writing took 1.7817959571257234 seconds)
2022-03-20 09:42:53 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-20 09:42:53 | INFO | train | epoch 021 | loss 6.91 | ppl 120.22 | wps 39419.3 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 3291 | lr 0.000411375 | gnorm 0.693 | loss_scale 2 | train_wall 58 | gb_free 12.5 | wall 2211
KL Stats: Epoch 21 Divergences: Uniform: 1.624408684880948 Unigram: 1.610178072514634
2022-03-20 09:42:54 | INFO | fairseq.trainer | begin training epoch 22
2022-03-20 09:42:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:42:57 | INFO | train_inner | epoch 022:      9 / 157 loss=6.867, ppl=116.73, wps=32081.9, ups=1.27, wpb=25249.9, bsz=1008.1, num_updates=3300, lr=0.0004125, gnorm=0.676, loss_scale=2, train_wall=37, gb_free=11.9, wall=2215
2022-03-20 09:43:35 | INFO | train_inner | epoch 022:    109 / 157 loss=6.696, ppl=103.65, wps=68106.1, ups=2.64, wpb=25834.8, bsz=1029.1, num_updates=3400, lr=0.000425, gnorm=0.622, loss_scale=2, train_wall=38, gb_free=11.8, wall=2253
2022-03-20 09:43:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:43:56 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-20 09:43:56 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:44:01 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without seeing it, you see the world different.
2022-03-20 09:44:01 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:44:04 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between faith, instinct intelligence and intelligence.
2022-03-20 09:44:04 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:44:08 | INFO | fairseq.tasks.translation | example hypothesis: especially focused on japan, korea and australia, countries who are connected to the united states.
2022-03-20 09:44:08 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:44:12 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused my attention to the circuit on the other side.
2022-03-20 09:44:12 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:44:16 | INFO | fairseq.tasks.translation | example hypothesis: so fast as we can reconstruct our computer, the brain activity to form this new tool as it would be part of the primates.
2022-03-20 09:44:16 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:44:20 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, at stanford, and our kids who are trying to do a lot of scientific experiments that go to normal education. we've got on normal education.
2022-03-20 09:44:20 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:44:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start able to make a traditional facial of the face, and the real shape, and the shape of that information, and through it, and through that information that's what the whole portion of the structure that's going through, and all of these reflection, and all of these reflects and the structure, and all the structure.
2022-03-20 09:44:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:44:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measure me here for tedwomen is that... yeah, when somebody said, "well, when somebody said," well, "the best reasons that the men who said to you to you," and the men who are working on the table and say, "if we're working on a lot of interesting and said," when we're working on this revolution, "when we're working with you're working with you're working on the most interesting and the most interesting and the most interesting and the most interesting and the most interesting and the truth."
2022-03-20 09:44:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:44:32 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of invention, and a great part of the design that we've had to solve in our plane was a result that we had to solve unique problems that were connected to the unique problems that they had to solve it on the ground -- the ground -- the ground -- all the way to be connected to the ground -- and all the way to a refugegestile or a refrigerism, or a refrigeration of a refrigered by a refrigeration, or a refrigeration of a refrigeration, or a refufufugeous refrigerism, or a refriction, or a refrigerism, if you can see that we're going to see that we're able to see that we're able to see that we had to see that we had to see that we had to see that we had to see that we had to be able to see that we had to use it is that we had to see that we had to the
2022-03-20 09:44:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:44:32 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.542 | ppl 186.42 | bleu 21.62 | wps 4667.4 | wpb 17862.2 | bsz 728.3 | num_updates 3448 | best_bleu 21.62
2022-03-20 09:44:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3448 updates
2022-03-20 09:44:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:44:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:44:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 22 @ 3448 updates, score 21.62) (writing took 1.8659997768700123 seconds)
2022-03-20 09:44:34 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-20 09:44:34 | INFO | train | epoch 022 | loss 6.765 | ppl 108.76 | wps 39417.4 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 3448 | lr 0.000431 | gnorm 0.659 | loss_scale 2 | train_wall 58 | gb_free 12.8 | wall 2311
KL Stats: Epoch 22 Divergences: Uniform: 1.6395706575231352 Unigram: 1.6330470323355257
2022-03-20 09:44:34 | INFO | fairseq.trainer | begin training epoch 23
2022-03-20 09:44:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:44:54 | INFO | train_inner | epoch 023:     52 / 157 loss=6.81, ppl=112.18, wps=31127.1, ups=1.28, wpb=24410, bsz=1041.6, num_updates=3500, lr=0.0004375, gnorm=0.696, loss_scale=2, train_wall=36, gb_free=12, wall=2331
2022-03-20 09:45:31 | INFO | train_inner | epoch 023:    152 / 157 loss=6.611, ppl=97.76, wps=67916.1, ups=2.7, wpb=25161.4, bsz=1007.4, num_updates=3600, lr=0.00045, gnorm=0.606, loss_scale=2, train_wall=37, gb_free=11.8, wall=2368
2022-03-20 09:45:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:45:36 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-20 09:45:36 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:45:40 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-20 09:45:40 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:45:44 | INFO | fairseq.tasks.translation | example hypothesis: but everyone musicians find a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:45:44 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:45:48 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries, the united states.
2022-03-20 09:45:48 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:45:52 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how focused my attention in the circuits on the other side.
2022-03-20 09:45:52 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:45:56 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can reform our computers, layers the brain nactivity to form this new tool as if it was a body part of the primates.
2022-03-20 09:45:56 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:46:00 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, from the indian science institute, and our children contribute a lot of scientific experiments that go beyond normal education.
2022-03-20 09:46:00 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:46:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of the face and the basic shape, and through that information, which is all the portion of the structure, all the portion of it.
2022-03-20 09:46:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:46:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are very interesting and measuring it, and then we've been here in tedwomen, is that... yes, when someone said, "you know, men on a table table and say," when we're working on a revolution, "when we're working on the truth."
2022-03-20 09:46:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:46:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to the ground -- all of us.
2022-03-20 09:46:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:46:10 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.355 | ppl 163.73 | bleu 23.75 | wps 4954 | wpb 17862.2 | bsz 728.3 | num_updates 3605 | best_bleu 23.75
2022-03-20 09:46:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3605 updates
2022-03-20 09:46:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:46:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:46:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 23 @ 3605 updates, score 23.75) (writing took 1.780071625020355 seconds)
2022-03-20 09:46:11 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-20 09:46:11 | INFO | train | epoch 023 | loss 6.653 | ppl 100.67 | wps 40418.2 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 3605 | lr 0.000450625 | gnorm 0.619 | loss_scale 2 | train_wall 58 | gb_free 12.5 | wall 2409
KL Stats: Epoch 23 Divergences: Uniform: 1.6580746141700067 Unigram: 1.6506666963172079
2022-03-20 09:46:12 | INFO | fairseq.trainer | begin training epoch 24
2022-03-20 09:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:46:47 | INFO | train_inner | epoch 024:     95 / 157 loss=6.556, ppl=94.07, wps=32987.4, ups=1.3, wpb=25295.2, bsz=1053.9, num_updates=3700, lr=0.0004625, gnorm=0.635, loss_scale=2, train_wall=37, gb_free=12, wall=2445
2022-03-20 09:47:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:47:15 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-20 09:47:15 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:47:19 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you see the world differently.
2022-03-20 09:47:19 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:47:22 | INFO | fairseq.tasks.translation | example hypothesis: but everybody else's musicians find another balance between faith and reason, instinct intelligence.
2022-03-20 09:47:22 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:47:26 | INFO | fairseq.tasks.translation | example hypothesis: especially focused on japan, korea and australia.
2022-03-20 09:47:26 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:47:30 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how focused i'm focused on my attention degree in the circulation of the other side.
2022-03-20 09:47:30 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:47:34 | INFO | fairseq.tasks.translation | example hypothesis: so fast as we can restore our computers, we can reform the brain activity to form this new tool when it was a body part of the primates.
2022-03-20 09:47:34 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:47:38 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford of indian science institute that come and teach our children a lot of scientific sciences that go beyond normal education.
2022-03-20 09:47:38 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:47:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflective reflection.
2022-03-20 09:47:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:47:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me here in tedwomen is that... well, when i was given dinner, it was the best thing that someone said, "turn you to the men and say," if we're working on a table. "
2022-03-20 09:47:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:47:46 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we have to use at our airplane, was a result that we had to solve the unique problems that we had to solve it on the ground -- all of us.
2022-03-20 09:47:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:47:46 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.421 | ppl 171.41 | bleu 19.46 | wps 5328.7 | wpb 17862.2 | bsz 728.3 | num_updates 3762 | best_bleu 23.75
2022-03-20 09:47:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3762 updates
2022-03-20 09:47:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:47:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:47:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 24 @ 3762 updates, score 19.46) (writing took 0.770346388220787 seconds)
2022-03-20 09:47:46 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-20 09:47:46 | INFO | train | epoch 024 | loss 6.573 | ppl 95.18 | wps 41507.8 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 3762 | lr 0.00047025 | gnorm 0.635 | loss_scale 2 | train_wall 58 | gb_free 12.8 | wall 2504
KL Stats: Epoch 24 Divergences: Uniform: 1.6682493815653836 Unigram: 1.6635185469009501
2022-03-20 09:47:47 | INFO | fairseq.trainer | begin training epoch 25
2022-03-20 09:47:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:48:01 | INFO | train_inner | epoch 025:     38 / 157 loss=6.509, ppl=91.09, wps=34246.5, ups=1.35, wpb=25307.3, bsz=1030.8, num_updates=3800, lr=0.000475, gnorm=0.615, loss_scale=2, train_wall=37, gb_free=12.2, wall=2519
2022-03-20 09:48:39 | INFO | train_inner | epoch 025:    138 / 157 loss=6.478, ppl=89.16, wps=67258.6, ups=2.66, wpb=25314.8, bsz=1010.8, num_updates=3900, lr=0.0004875, gnorm=0.601, loss_scale=2, train_wall=37, gb_free=11.7, wall=2557
2022-03-20 09:48:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:48:49 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-20 09:48:49 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:48:54 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you notice it, you see the world differently.
2022-03-20 09:48:54 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:48:58 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between believe and sensitivity, instinct and intelligence.
2022-03-20 09:48:58 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:49:01 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are connected to the united states.
2022-03-20 09:49:01 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:49:05 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused on, so i can wear my attention degree in the circuit on the other side.
2022-03-20 09:49:05 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:49:09 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computer, our brains can reform the brain nactivity to form this new tool as it would be part of the primates.
2022-03-20 09:49:09 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:49:14 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formal experiments that go far beyond normal education.
2022-03-20 09:49:14 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:49:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of the face of the face and rereform the basic shape of the face and the basic shape of information that drives all the ports and fold all the structure.
2022-03-20 09:49:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:49:22 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measure it up to me here in tedwomen is that... tall, when someone said, "turn up to the best part of you," turn to the men on a table and say, "if the revolution begins to support them," if we're supporting the truth. "
2022-03-20 09:49:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:49:25 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we are at our plane, was a result that we had to solve the unique problems that were connected to the ground -- all of the continents of a variation and refrigeration system, and it allows us to use a mechanism to use it to use the vehicles to use an aircraft, or a mechanism, and it, and it allows us to see that if you to see that there's a mechanism, it's a mechanism, it's a mechanism, it's a mechanism, it's a mechanism, and it's a mechanism, and it's a mechanism, and it's a mechanism, it's a mechanism, and it's either if you can see that it allows us to use the most sophisticated mechanism to use it, it, it's a mechanism to see that you to use it, it, it, it's a mechanism, it
2022-03-20 09:49:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:49:25 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.148 | ppl 141.86 | bleu 26.87 | wps 4660.6 | wpb 17862.2 | bsz 728.3 | num_updates 3919 | best_bleu 26.87
2022-03-20 09:49:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3919 updates
2022-03-20 09:49:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:49:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:49:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 25 @ 3919 updates, score 26.87) (writing took 1.7959590633399785 seconds)
2022-03-20 09:49:26 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-20 09:49:26 | INFO | train | epoch 025 | loss 6.473 | ppl 88.85 | wps 39497.7 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 3919 | lr 0.000489875 | gnorm 0.589 | loss_scale 2 | train_wall 58 | gb_free 12.4 | wall 2604
KL Stats: Epoch 25 Divergences: Uniform: 1.679703172847488 Unigram: 1.6726853266920974
2022-03-20 09:49:27 | INFO | fairseq.trainer | begin training epoch 26
2022-03-20 09:49:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:49:58 | INFO | train_inner | epoch 026:     81 / 157 loss=6.422, ppl=85.72, wps=31246.4, ups=1.27, wpb=24563, bsz=1020.7, num_updates=4000, lr=0.0005, gnorm=0.585, loss_scale=2, train_wall=36, gb_free=11.8, wall=2635
2022-03-20 09:50:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:50:30 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-20 09:50:30 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:50:34 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world different.
2022-03-20 09:50:34 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:50:38 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:50:38 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:50:41 | INFO | fairseq.tasks.translation | example hypothesis: in particular, it focuses on japan, korea and australia, countries who are connected to the united states.
2022-03-20 09:50:41 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:50:46 | INFO | fairseq.tasks.translation | example hypothesis: it could be interested in how i'm focused on, so i can wear my attention degree in the circulation on the other side.
2022-03-20 09:50:46 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:50:50 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computer, the brain activity to form this new tool as if it was a body part of the primate.
2022-03-20 09:50:50 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:50:54 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers that go beyond normal education.
2022-03-20 09:50:54 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:50:58 | INFO | fairseq.tasks.translation | example hypothesis: so when we use information that comes from this reflection, we can start with a traditional face of the face of the face, and the basic shape of the face is restoring and restoring it through this information that folds all the ports and fold all of the structure.
2022-03-20 09:50:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:51:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measure it for me to be here at tedwomen is that... tyes, when somebody said, "well, it's the best thing that men said," stop you on your table and say, "when the revolution starts to support you," when we support you're working with your truth, "and then we've been working on this topic."
2022-03-20 09:51:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:51:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're at our plane at the most stest, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation and refrigeration system, and a refrigeration system that allows us to see when we're either going to use the vehicle, or if we're going to use it to use the car traffic, or if you're either.
2022-03-20 09:51:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:51:03 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.097 | ppl 136.92 | bleu 26.62 | wps 4972.8 | wpb 17862.2 | bsz 728.3 | num_updates 4076 | best_bleu 26.87
2022-03-20 09:51:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4076 updates
2022-03-20 09:51:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:51:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:51:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 26 @ 4076 updates, score 26.62) (writing took 0.7697855201549828 seconds)
2022-03-20 09:51:04 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-20 09:51:04 | INFO | train | epoch 026 | loss 6.38 | ppl 83.28 | wps 40530.4 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 4076 | lr 0.000495317 | gnorm 0.567 | loss_scale 2 | train_wall 58 | gb_free 12.1 | wall 2701
KL Stats: Epoch 26 Divergences: Uniform: 1.6853717737169698 Unigram: 1.6863760011624025
2022-03-20 09:51:04 | INFO | fairseq.trainer | begin training epoch 27
2022-03-20 09:51:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:51:13 | INFO | train_inner | epoch 027:     24 / 157 loss=6.393, ppl=84.06, wps=33149.5, ups=1.32, wpb=25103.7, bsz=1009.5, num_updates=4100, lr=0.000493865, gnorm=0.537, loss_scale=2, train_wall=37, gb_free=11.9, wall=2711
2022-03-20 09:51:51 | INFO | train_inner | epoch 027:    124 / 157 loss=6.368, ppl=82.58, wps=67020.6, ups=2.69, wpb=24950.8, bsz=981.7, num_updates=4200, lr=0.00048795, gnorm=0.615, loss_scale=2, train_wall=37, gb_free=11.8, wall=2748
2022-03-20 09:52:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:52:07 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 09:52:07 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:52:11 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without any time you notice it, you see the world different.
2022-03-20 09:52:11 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:52:15 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find another equilibrium between faith and reason, instinct and intelligence.
2022-03-20 09:52:15 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:52:19 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries, the encounter of the united states.
2022-03-20 09:52:19 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:52:23 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused on, so i can carry my attention in the circuit on the other side.
2022-03-20 09:52:23 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:52:27 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computer, we can restore the brain activity to form this new tool as if it was a body part of the primates.
2022-03-20 09:52:27 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:52:31 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers that go far beyond normal education.
2022-03-20 09:52:31 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:52:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can begin with a traditional face that gives the big concrete of the face and the basic shape of the face, and it restores all the ports and all a fold.
2022-03-20 09:52:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:52:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measure, for me here at tedwomen, is that... tall, when... tar, it was the best thing that somebody said, "stop the men on your table, and tell you, if the revolution starts to support you, we've already been working on the truth for you, we've already been working with you."
2022-03-20 09:52:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:52:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we are at our plane at the fastest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to see when we use the vehicle, or if you can see the wheel, it's a mechanism of a mechanism, or if you can see the wheel, it's in the ground, it's a mechanism, if you can use a mechanism, if you can use a mechanism, or if you can see the wheel, it's going to see the wheel, it's a mechanism, it's going to see the vehicle, it's a mechanism, or if you can use a mechanism.
2022-03-20 09:52:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:52:42 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.052 | ppl 132.7 | bleu 28.11 | wps 4688.3 | wpb 17862.2 | bsz 728.3 | num_updates 4233 | best_bleu 28.11
2022-03-20 09:52:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4233 updates
2022-03-20 09:52:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:52:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:52:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 27 @ 4233 updates, score 28.11) (writing took 1.8210158692672849 seconds)
2022-03-20 09:52:43 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-20 09:52:43 | INFO | train | epoch 027 | loss 6.321 | ppl 79.95 | wps 39647.6 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4233 | lr 0.000486044 | gnorm 0.574 | loss_scale 2 | train_wall 58 | gb_free 11.9 | wall 2801
KL Stats: Epoch 27 Divergences: Uniform: 1.6935831509671146 Unigram: 1.693488244512579
2022-03-20 09:52:44 | INFO | fairseq.trainer | begin training epoch 28
2022-03-20 09:52:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:53:09 | INFO | train_inner | epoch 028:     67 / 157 loss=6.189, ppl=72.95, wps=32402.6, ups=1.28, wpb=25362.8, bsz=1057.9, num_updates=4300, lr=0.000482243, gnorm=0.532, loss_scale=2, train_wall=37, gb_free=12, wall=2826
2022-03-20 09:53:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:53:47 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-20 09:53:47 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:53:51 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-20 09:53:51 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:53:55 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another equilibrium between faith and reason, instinct and intelligence.
2022-03-20 09:53:55 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:53:59 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia and australia, countries that are enconnected in the united states.
2022-03-20 09:53:59 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:54:03 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me how concentrating i'm so that i can wear my attention degree in the circuit on the other side.
2022-03-20 09:54:03 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:54:07 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computer, the brain activity to form this new tool as if it was a body part of primates.
2022-03-20 09:54:07 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:54:11 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our kids a lot of scientific formers, experiments that come far beyond normal education.
2022-03-20 09:54:11 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:54:16 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constructions of the face and the basic shape, and it refits all the ports and all a fold.
2022-03-20 09:54:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:54:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was highly interesting and measured to me here at tedwomen, is that... tyes, when it was best summarized when somebody said, "turn you to the men in your table and tell you," if the revolution starts to support you, "we love women, we've already started to support you for a long time."
2022-03-20 09:54:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:54:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we're at our plane at the most stest, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrigeration system that allows us to use a ridge, that allows us to use a truck machine, or if you can either see the propelled by a truck.
2022-03-20 09:54:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:54:20 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.061 | ppl 133.54 | bleu 27.76 | wps 4936.4 | wpb 17862.2 | bsz 728.3 | num_updates 4390 | best_bleu 28.11
2022-03-20 09:54:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4390 updates
2022-03-20 09:54:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:54:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:54:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 28 @ 4390 updates, score 27.76) (writing took 0.7632299070246518 seconds)
2022-03-20 09:54:21 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-20 09:54:21 | INFO | train | epoch 028 | loss 6.243 | ppl 75.76 | wps 40543.5 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 4390 | lr 0.000477274 | gnorm 0.537 | loss_scale 2 | train_wall 58 | gb_free 11.5 | wall 2898
KL Stats: Epoch 28 Divergences: Uniform: 1.695820024647844 Unigram: 1.7002065411687302
2022-03-20 09:54:21 | INFO | fairseq.trainer | begin training epoch 29
2022-03-20 09:54:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:54:25 | INFO | train_inner | epoch 029:     10 / 157 loss=6.24, ppl=75.59, wps=33239.6, ups=1.31, wpb=25347.9, bsz=984, num_updates=4400, lr=0.000476731, gnorm=0.54, loss_scale=2, train_wall=37, gb_free=11.7, wall=2903
2022-03-20 09:55:03 | INFO | train_inner | epoch 029:    110 / 157 loss=6.2, ppl=73.54, wps=66647.5, ups=2.67, wpb=24937.9, bsz=1035.8, num_updates=4500, lr=0.000471405, gnorm=0.478, loss_scale=2, train_wall=37, gb_free=12.4, wall=2940
2022-03-20 09:55:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:55:24 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 09:55:24 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:55:28 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly without you to notice it, you see the world different.
2022-03-20 09:55:28 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:55:32 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another equilibrium between faith and reason, instinct and intelligence.
2022-03-20 09:55:32 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:55:36 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are the united states.
2022-03-20 09:55:36 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:55:40 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in what i'm focused on, so i can carry my attention degree in the circuit on the other side.
2022-03-20 09:55:40 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:55:44 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computer, the brain activity to form this new tool as if it was a body part of the primates.
2022-03-20 09:55:44 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:55:48 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers, experiments that go far beyond normal education.
2022-03-20 09:55:48 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:55:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big configurations of the face and the basic shape, and through the major information that drives all the ports and all a fold.
2022-03-20 09:55:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:55:56 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measure for me to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to the men on your table and tell you," when the revolution starts to be here. "
2022-03-20 09:55:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:55:58 | INFO | fairseq.tasks.translation | example hypothesis: luckckily, the mother of invention, and a big part of the design work that we are at our plane at the most stest, was a result that we had to solve the unique problems that were connected to operate on the ground -- all from a continuous variation and refrigeration system that allows us to use the aircraft to either be able to use the ground, to see a trajectory.
2022-03-20 09:55:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:55:58 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 6.968 | ppl 125.21 | bleu 28.77 | wps 4854.3 | wpb 17862.2 | bsz 728.3 | num_updates 4547 | best_bleu 28.77
2022-03-20 09:55:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4547 updates
2022-03-20 09:55:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:55:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:55:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 29 @ 4547 updates, score 28.77) (writing took 1.781629275996238 seconds)
2022-03-20 09:55:59 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-20 09:55:59 | INFO | train | epoch 029 | loss 6.168 | ppl 71.92 | wps 40076.8 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4547 | lr 0.000468962 | gnorm 0.496 | loss_scale 2 | train_wall 58 | gb_free 11.6 | wall 2997
KL Stats: Epoch 29 Divergences: Uniform: 1.7017860043665187 Unigram: 1.7143119716091004
2022-03-20 09:56:00 | INFO | fairseq.trainer | begin training epoch 30
2022-03-20 09:56:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:56:20 | INFO | train_inner | epoch 030:     53 / 157 loss=6.1, ppl=68.58, wps=33095.5, ups=1.3, wpb=25543.1, bsz=1007.4, num_updates=4600, lr=0.000466252, gnorm=0.482, loss_scale=2, train_wall=37, gb_free=11.9, wall=3017
2022-03-20 09:56:57 | INFO | train_inner | epoch 030:    153 / 157 loss=6.121, ppl=69.6, wps=67539.9, ups=2.69, wpb=25108.1, bsz=1050.3, num_updates=4700, lr=0.000461266, gnorm=0.496, loss_scale=2, train_wall=37, gb_free=11.8, wall=3054
2022-03-20 09:56:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:57:02 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-20 09:57:02 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:57:06 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly without you to notice it, you see the world differently.
2022-03-20 09:57:06 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:57:10 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another equilibrium between faith and reason, instincts and intelligence.
2022-03-20 09:57:10 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:57:14 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries who are enabled in the united states.
2022-03-20 09:57:14 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:57:18 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused so that i can carry my attention level in the circuit on the other side.
2022-03-20 09:57:18 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:57:22 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computer, the brain activity invites to form this new tool as if it was a body part of the primates.
2022-03-20 09:57:22 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:57:26 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, from the indian science institute that come and teach our kids a lot of scientific forms, experiments that go far beyond normal education.
2022-03-20 09:57:26 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:57:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big concrete of the face and restore it through the basic shape of the face and the basic shape of that information that whole portion and all the folds.
2022-03-20 09:57:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:57:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and say, "if the revolution begins to be here at tedwomen," well, when... tyes, it was best summarized when someone said, "turn you to the men on your table and tell you," if the revolution begins to support you. "the truth is that we've already started to support you," we've already started to support you, "
2022-03-20 09:57:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:57:37 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're at our plane at the stest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft, or even if we're in the ground, or if you're going to see the most trajectory of a mechanism, or if you're going to use the propelled to use the vehicle, or if you're going to use the nightful, or if you can either, you're going to use the nightful, or if you're going to use the nightful, or if you're going to use the nightstand, you can either, or if you can either, you're going to use the nightstand.
2022-03-20 09:57:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:57:37 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 6.897 | ppl 119.18 | bleu 29.69 | wps 4743.7 | wpb 17862.2 | bsz 728.3 | num_updates 4704 | best_bleu 29.69
2022-03-20 09:57:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4704 updates
2022-03-20 09:57:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:57:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 09:57:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 30 @ 4704 updates, score 29.69) (writing took 1.728508250322193 seconds)
2022-03-20 09:57:39 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-20 09:57:39 | INFO | train | epoch 030 | loss 6.118 | ppl 69.43 | wps 39858.9 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4704 | lr 0.000461069 | gnorm 0.494 | loss_scale 2 | train_wall 58 | gb_free 11.5 | wall 3096
KL Stats: Epoch 30 Divergences: Uniform: 1.700445091815066 Unigram: 1.7178161418835538
2022-03-20 09:57:39 | INFO | fairseq.trainer | begin training epoch 31
2022-03-20 09:57:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:58:15 | INFO | train_inner | epoch 031:     96 / 157 loss=6.061, ppl=66.77, wps=32246.9, ups=1.28, wpb=25148.9, bsz=1020.9, num_updates=4800, lr=0.000456435, gnorm=0.491, loss_scale=2, train_wall=37, gb_free=12.9, wall=3132
2022-03-20 09:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:58:42 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 09:58:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 09:58:46 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without finding it, you see the world differently.
2022-03-20 09:58:46 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 09:58:49 | INFO | fairseq.tasks.translation | example hypothesis: but every musician is finding a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:58:49 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 09:58:53 | INFO | fairseq.tasks.translation | example hypothesis: especially, it focuses on japan, korea and australia, countries that are close to the united states.
2022-03-20 09:58:53 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 09:58:57 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how focused i am so that i can carry my attention degree in the circuit board on the other side.
2022-03-20 09:58:57 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 09:59:01 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computer, our brain activity to form this new tool as if it was a body part of the primates.
2022-03-20 09:59:01 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 09:59:06 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific shapes, experiments that go far beyond normal education.
2022-03-20 09:59:06 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 09:59:10 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that gives the big configurations of the face, and the basic shape, and the basic shape, and all of the information pulls the whole portion structure and all the folds.
2022-03-20 09:59:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:59:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and measured to me here at tedwomen is that... well, when dinner was best summarized when somebody said, "turn you to the men on your table, and tell you," when the revolution begins, we're supporting you. "the truth is that we've already started with you, you know, we've been working on this topic, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know
2022-03-20 09:59:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:59:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our plane at the stest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft, that allows us to use an aircraft, or you to use the vehicle, or you can see it, you can see, you can see, you can use it, or you can use it, you can see, you can see, you can use it, you can use it, you can see, you can use it, you know, or you can see, you can see, you can see, you can use it, you can see, you can see, you can see, you can see, you can see, you can see, you can see, you can see, you can see, you can see, you can see, you can see, you can use it in the
2022-03-20 09:59:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:59:17 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 6.862 | ppl 116.32 | bleu 29.67 | wps 4703.3 | wpb 17862.2 | bsz 728.3 | num_updates 4861 | best_bleu 29.69
2022-03-20 09:59:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4861 updates
2022-03-20 09:59:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:59:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 09:59:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 31 @ 4861 updates, score 29.67) (writing took 0.7612921828404069 seconds)
2022-03-20 09:59:17 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-20 09:59:17 | INFO | train | epoch 031 | loss 6.06 | ppl 66.7 | wps 39971.3 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4861 | lr 0.000453563 | gnorm 0.487 | loss_scale 2 | train_wall 58 | gb_free 12.6 | wall 3195
KL Stats: Epoch 31 Divergences: Uniform: 1.7016117354130933 Unigram: 1.7251627429586782
2022-03-20 09:59:18 | INFO | fairseq.trainer | begin training epoch 32
2022-03-20 09:59:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:59:33 | INFO | train_inner | epoch 032:     39 / 157 loss=6.054, ppl=66.45, wps=31956.5, ups=1.28, wpb=24950.3, bsz=1035.3, num_updates=4900, lr=0.000451754, gnorm=0.491, loss_scale=2, train_wall=37, gb_free=12, wall=3211
2022-03-20 10:00:11 | INFO | train_inner | epoch 032:    139 / 157 loss=6.008, ppl=64.34, wps=67386.1, ups=2.66, wpb=25321.2, bsz=1000.6, num_updates=5000, lr=0.000447214, gnorm=0.455, loss_scale=2, train_wall=37, gb_free=12.9, wall=3248
2022-03-20 10:00:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:00:21 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:00:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:00:25 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-20 10:00:25 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:00:29 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between belief and reason, instinct and intelligence.
2022-03-20 10:00:29 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:00:33 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries who are connected to the united states.
2022-03-20 10:00:33 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:00:37 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused on, so i can carry my attention degree in the circuit board on the other side.
2022-03-20 10:00:37 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:00:41 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computers, the brain activity to form this new tool as if it was a body part of the primate.
2022-03-20 10:00:41 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:00:46 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our kids a lot of scientific formers, experiments that go far beyond normal education.
2022-03-20 10:00:46 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:00:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that gives the big constructions of the face and the basic shape, and by the following information that drives all the portion and all the folds.
2022-03-20 10:00:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:00:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that... tyes, when dinner was best summarized when someone said, "turn you to the men on your table and tell you," if the revolution starts to support you. "'the truth is that we've already started to help you, we've been working on this topic for a long time."
2022-03-20 10:00:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:00:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're at our plane at the stest was a result that we had to solve the unique problems that were connected to operate it on the ground -- everything from a continuous variation and a refrigeration system that allows us to use a refrigeration machine to use, to either use the propelled, or if you look at the ground.
2022-03-20 10:00:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:00:55 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 6.823 | ppl 113.2 | bleu 30.72 | wps 4779.5 | wpb 17862.2 | bsz 728.3 | num_updates 5018 | best_bleu 30.72
2022-03-20 10:00:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5018 updates
2022-03-20 10:00:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:00:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:00:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 32 @ 5018 updates, score 30.72) (writing took 1.7873814338818192 seconds)
2022-03-20 10:00:57 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-20 10:00:57 | INFO | train | epoch 032 | loss 6.012 | ppl 64.53 | wps 39602.3 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5018 | lr 0.000446411 | gnorm 0.463 | loss_scale 2 | train_wall 58 | gb_free 12.1 | wall 3295
KL Stats: Epoch 32 Divergences: Uniform: 1.7048210655863751 Unigram: 1.7341697431594045
2022-03-20 10:00:57 | INFO | fairseq.trainer | begin training epoch 33
2022-03-20 10:00:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:01:28 | INFO | train_inner | epoch 033:     82 / 157 loss=5.991, ppl=63.59, wps=32106.5, ups=1.28, wpb=25016.7, bsz=1043, num_updates=5100, lr=0.000442807, gnorm=0.469, loss_scale=2, train_wall=37, gb_free=11.8, wall=3326
2022-03-20 10:01:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:02:00 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:02:00 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:02:04 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you realize it, you see the world differently.
2022-03-20 10:02:04 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:02:08 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:02:08 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:02:12 | INFO | fairseq.tasks.translation | example hypothesis: especially, it's focused on japan, korea and australia, countries that are enconnected to the united states.
2022-03-20 10:02:12 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:02:17 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i am, so i can put my attention degree in the circuit board on the other side.
2022-03-20 10:02:17 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:02:21 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can reinvent our computers, our brain activity invites to form this new tool as if it was a body part of the primate.
2022-03-20 10:02:21 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:02:25 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formula, experiments that go far beyond normal class.
2022-03-20 10:02:25 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:02:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that gives the big constructions of the face, and the basic shape of the face, and decreases it through the entire portion structure and all the folds.
2022-03-20 10:02:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:02:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's extremely interesting and appropriate for me to be here at tedwomen is that... well, when strictly dinner, it was best summarized when someone said, "turn you to the men at your table and tell you," if the revolution begins to be here, then we support you. "the truth is that we've already started to support you for you is that we've been supporting you, for you, you, you know, when you know, we're going to have a little bit of mine."
2022-03-20 10:02:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:02:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our plane at the stest was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and a cooling system that allows us to use a steady car car car car car car car car car to either be able to see if you can either be able to see the ground, if you can either be able to use the propelled by the ground, if you're going to be able to be able to operate it would be able to operate it, if you can see the ground, if you can see it would be connected to see it would be connected to operate it would be connected to the ground.
2022-03-20 10:02:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:02:36 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 6.816 | ppl 112.65 | bleu 30.95 | wps 4543.7 | wpb 17862.2 | bsz 728.3 | num_updates 5175 | best_bleu 30.95
2022-03-20 10:02:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5175 updates
2022-03-20 10:02:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:02:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:02:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 33 @ 5175 updates, score 30.95) (writing took 1.7751243286766112 seconds)
2022-03-20 10:02:38 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-20 10:02:38 | INFO | train | epoch 033 | loss 5.97 | ppl 62.67 | wps 39110.9 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 5175 | lr 0.000439587 | gnorm 0.478 | loss_scale 2 | train_wall 58 | gb_free 11.9 | wall 3396
KL Stats: Epoch 33 Divergences: Uniform: 1.7061391277941995 Unigram: 1.7360492116625554
2022-03-20 10:02:38 | INFO | fairseq.trainer | begin training epoch 34
2022-03-20 10:02:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:02:48 | INFO | train_inner | epoch 034:     25 / 157 loss=5.92, ppl=60.57, wps=32067.8, ups=1.26, wpb=25443.9, bsz=981.7, num_updates=5200, lr=0.000438529, gnorm=0.493, loss_scale=2, train_wall=37, gb_free=11.7, wall=3405
2022-03-20 10:03:25 | INFO | train_inner | epoch 034:    125 / 157 loss=5.939, ppl=61.34, wps=67154.7, ups=2.68, wpb=25048.9, bsz=1051.3, num_updates=5300, lr=0.000434372, gnorm=0.433, loss_scale=2, train_wall=37, gb_free=12, wall=3443
2022-03-20 10:03:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:03:41 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-20 10:03:41 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:03:45 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without finding it, you see the world differently.
2022-03-20 10:03:45 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:03:49 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between belief and reason, instincts and intelligence.
2022-03-20 10:03:49 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:03:53 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries who are close to the united states.
2022-03-20 10:03:53 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:03:57 | INFO | fairseq.tasks.translation | example hypothesis: i could also care about how concentrating i am so that i can carry my attention degree in the circuit on the other side.
2022-03-20 10:03:57 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:04:01 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity invites to form this new tool as if it was a body of primates.
2022-03-20 10:04:01 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:04:05 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific forms, experiments that go far beyond normal education.
2022-03-20 10:04:05 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:04:09 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that gives the big configurations of the face and the basic shape, and through that one of the things that the whole porter structure and all the folds a fold.
2022-03-20 10:04:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:04:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... tyes, when dinner was best summarized, when someone said, "turn to the men on your table and tell you," when the revolution starts to support you, we support you. "the truth is that we've already started to support you for a long time."
2022-03-20 10:04:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:04:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're at our plane at the stumest was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in the ground, to either use the vehicle, or if we were able to use the vehicle in the same direction of a mechanism, or if we were connected to operate it, to use it, to use it, to use it, to use it, or if we're either the vehicle vehicle vehicle, to use it.
2022-03-20 10:04:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:04:15 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 6.761 | ppl 108.48 | bleu 31.11 | wps 4827.1 | wpb 17862.2 | bsz 728.3 | num_updates 5332 | best_bleu 31.11
2022-03-20 10:04:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5332 updates
2022-03-20 10:04:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:04:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:04:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 34 @ 5332 updates, score 31.11) (writing took 1.7677304171957076 seconds)
2022-03-20 10:04:16 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-20 10:04:16 | INFO | train | epoch 034 | loss 5.928 | ppl 60.89 | wps 40129.9 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 5332 | lr 0.000433067 | gnorm 0.45 | loss_scale 2 | train_wall 58 | gb_free 11.5 | wall 3494
KL Stats: Epoch 34 Divergences: Uniform: 1.7075762771094918 Unigram: 1.7465101082206684
2022-03-20 10:04:17 | INFO | fairseq.trainer | begin training epoch 35
2022-03-20 10:04:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:04:43 | INFO | train_inner | epoch 035:     68 / 157 loss=5.989, ppl=63.53, wps=32067.2, ups=1.29, wpb=24833.2, bsz=935.6, num_updates=5400, lr=0.000430331, gnorm=0.467, loss_scale=2, train_wall=37, gb_free=11.8, wall=3520
2022-03-20 10:05:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:05:19 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:05:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:05:23 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without knowing it, you see the world differently.
2022-03-20 10:05:23 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:05:28 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:05:28 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:05:32 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are encountered by the united states.
2022-03-20 10:05:32 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:05:36 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how i'm focused, so i can carry my attention degree in the circuit board on the other side.
2022-03-20 10:05:36 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:05:40 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can reframe our computer, the brain activity to form this new tool as if it was a body of primate.
2022-03-20 10:05:40 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:05:44 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific forms, experiments that go far beyond normal education.
2022-03-20 10:05:44 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:05:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face can start with a traditional face that gives the big configurations of the face and the basic shape, and bring it through the entire portion structure and all the fits.
2022-03-20 10:05:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:05:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me to be here at tedwomen is that -- tyes, when they were best summarized, when someone said, "move to the men at your table and tell you, 'if the revolution starts to support you.' '' ''" the truth is that we've already started to support you for you for a long time, we've been supporting you about this, and then we've been working with you, you, you, you, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know,
2022-03-20 10:05:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:05:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a great part of the design work that we're on at our plane at the stest was a result that we had to solve the unique problems that were connected to operate on the ground -- all, from a continuous variation and refrigerator system, it allows us to use an aircraft that allows us to stop, or if you're going to go in the ground, or if you're going to go to the ground, you're either going to the road, if you're going to be able to be able to get rid of a car, you're going to see it, if you're going to drive it, or if you're going to run it, you're going to the ground, you're going to drive it, you're going to the road, you're going to the road, you're going to be able to get rid of you're going to run it, you're going to get it, you're going to be able to
2022-03-20 10:05:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:05:55 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 6.747 | ppl 107.41 | bleu 31.23 | wps 4566.5 | wpb 17862.2 | bsz 728.3 | num_updates 5489 | best_bleu 31.23
2022-03-20 10:05:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5489 updates
2022-03-20 10:05:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:05:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:05:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 35 @ 5489 updates, score 31.23) (writing took 1.8712080051191151 seconds)
2022-03-20 10:05:57 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-20 10:05:57 | INFO | train | epoch 035 | loss 5.899 | ppl 59.68 | wps 39212.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5489 | lr 0.000426828 | gnorm 0.46 | loss_scale 2 | train_wall 58 | gb_free 12 | wall 3595
KL Stats: Epoch 35 Divergences: Uniform: 1.7060432683595597 Unigram: 1.7436786459617386
2022-03-20 10:05:57 | INFO | fairseq.trainer | begin training epoch 36
2022-03-20 10:05:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:06:02 | INFO | train_inner | epoch 036:     11 / 157 loss=5.815, ppl=56.28, wps=32077.8, ups=1.26, wpb=25377.9, bsz=1087.8, num_updates=5500, lr=0.000426401, gnorm=0.443, loss_scale=2, train_wall=36, gb_free=12, wall=3599
2022-03-20 10:06:39 | INFO | train_inner | epoch 036:    111 / 157 loss=5.855, ppl=57.87, wps=67672.8, ups=2.68, wpb=25262.3, bsz=1050.5, num_updates=5600, lr=0.000422577, gnorm=0.468, loss_scale=2, train_wall=37, gb_free=12.5, wall=3637
2022-03-20 10:06:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:07:00 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:07:00 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:07:05 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without knowing it, you see the world differently.
2022-03-20 10:07:05 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:07:09 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:07:09 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:07:12 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-20 10:07:12 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:07:17 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i am, so i can put my attention degree in the circuit board on the other side.
2022-03-20 10:07:17 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:07:21 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to form this new tool as if it was a body of primates.
2022-03-20 10:07:21 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:07:25 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formulas, experiments that go far beyond normal education.
2022-03-20 10:07:25 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:07:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of mirror reflection, we can start with a traditional facial can that gives the big contextures of the face and restore the basic shape, and recommending it through the entire porting structure and all the fits.
2022-03-20 10:07:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:07:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measure it, for me, to be here at tedwomen, is that... tyes, at dinner, it was best summarized when someone said, "turn to the men on your table and say," if the revolution begins to support you. '' '' 'the truth, women, women, we already love is that we've already started to help you this topic for this issue for a long time. "
2022-03-20 10:07:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:07:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on at our plane at the stumest was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variable drives and a cooling system with refrigeration system that allows us to use an aircraft that allows us to use in the aircraft on the staircase, to use aircraft at the same time.
2022-03-20 10:07:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:07:36 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 6.729 | ppl 106.07 | bleu 31.86 | wps 4537 | wpb 17862.2 | bsz 728.3 | num_updates 5646 | best_bleu 31.86
2022-03-20 10:07:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5646 updates
2022-03-20 10:07:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:07:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:07:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 36 @ 5646 updates, score 31.86) (writing took 1.7740743369795382 seconds)
2022-03-20 10:07:38 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-20 10:07:38 | INFO | train | epoch 036 | loss 5.876 | ppl 58.74 | wps 39182.3 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5646 | lr 0.000420852 | gnorm 0.451 | loss_scale 2 | train_wall 58 | gb_free 12.3 | wall 3696
KL Stats: Epoch 36 Divergences: Uniform: 1.7074353352034248 Unigram: 1.7511228397088152
2022-03-20 10:07:38 | INFO | fairseq.trainer | begin training epoch 37
2022-03-20 10:07:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:07:59 | INFO | train_inner | epoch 037:     54 / 157 loss=5.952, ppl=61.9, wps=31136, ups=1.25, wpb=24847.4, bsz=1007, num_updates=5700, lr=0.000418854, gnorm=0.445, loss_scale=2, train_wall=37, gb_free=11.9, wall=3716
2022-03-20 10:08:36 | INFO | train_inner | epoch 037:    154 / 157 loss=5.776, ppl=54.79, wps=69079.2, ups=2.71, wpb=25530, bsz=1006.4, num_updates=5800, lr=0.000415227, gnorm=0.432, loss_scale=2, train_wall=37, gb_free=12.8, wall=3753
2022-03-20 10:08:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:08:41 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:08:41 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:08:45 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you notice it, you see the world differently.
2022-03-20 10:08:45 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:08:49 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another equilibrium between faith and reason, instincts and intelligence.
2022-03-20 10:08:49 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:08:53 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are closely connected to the united states.
2022-03-20 10:08:53 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:08:57 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrated i am, so i can put my attention degree in the circuit board on the other side.
2022-03-20 10:08:57 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:09:01 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computer, the brain activity invites to form this new tool as if it was a body part of the primate.
2022-03-20 10:09:01 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:09:05 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific forms, experiments that go far beyond normal education.
2022-03-20 10:09:05 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:09:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that restore the big contextures of the face and the basic shape, and deploy it through the whole portion structure and all the fits.
2022-03-20 10:09:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:09:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... tyes, when dinner was best summarized when someone said, "turn to the men on your table and tell you," when the revolution starts supporting you. '"the truth is that we've already started to support you with you for a long time, we've been supporting you,"
2022-03-20 10:09:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:09:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on at our airplane at the stumest was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft that allows us to stop and use the most specific traffic, to either use the propellant, to see that if you look at the most reliable, to use it's either if you look at the most reliable, to see the propelled, to see it allows us to use it's an aircraft that allows us to use it, to use it, to use it, to either, to see the most tragic of the most tragic of the most tragic, to the most tragic, to the most tragic, to see that allows us to see it's a vehicle that allows us to see it, to see it, to see it, to use it, to use
2022-03-20 10:09:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:09:16 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 6.714 | ppl 104.98 | bleu 31.3 | wps 4681.9 | wpb 17862.2 | bsz 728.3 | num_updates 5803 | best_bleu 31.86
2022-03-20 10:09:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5803 updates
2022-03-20 10:09:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:09:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:09:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 37 @ 5803 updates, score 31.3) (writing took 0.8064016927964985 seconds)
2022-03-20 10:09:16 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-20 10:09:16 | INFO | train | epoch 037 | loss 5.844 | ppl 57.42 | wps 40059.4 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5803 | lr 0.00041512 | gnorm 0.445 | loss_scale 2 | train_wall 58 | gb_free 13.1 | wall 3794
KL Stats: Epoch 37 Divergences: Uniform: 1.7104661600046374 Unigram: 1.757499548672748
2022-03-20 10:09:17 | INFO | fairseq.trainer | begin training epoch 38
2022-03-20 10:09:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:09:54 | INFO | train_inner | epoch 038:     97 / 157 loss=5.775, ppl=54.77, wps=32509, ups=1.28, wpb=25302.9, bsz=1067.5, num_updates=5900, lr=0.000411693, gnorm=0.435, loss_scale=2, train_wall=37, gb_free=12.5, wall=3831
2022-03-20 10:10:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:10:20 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:10:20 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:10:24 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you realize it, you see the world differently.
2022-03-20 10:10:24 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:10:28 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between belief and reason, instinct and intelligence.
2022-03-20 10:10:28 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:10:32 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-20 10:10:32 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:10:36 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrating i am, so i can put my attention degree in the circuit board on the other side.
2022-03-20 10:10:36 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:10:40 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computer, the brain activity is shifting to form this new tool as if it was a body of primate.
2022-03-20 10:10:40 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:10:44 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific forms, experiments that go far beyond normal education.
2022-03-20 10:10:44 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:10:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of mirror reflection, we can start with a traditional facial can that recommends the big contextures of the face and the basic shape, and decrease it through the most important information that pulls the entire portion structure and all the fits.
2022-03-20 10:10:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:10:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen, is that... tyes, when stripped dinner, it was best summarized when someone said, "turn to the men on your table and tell you," when the revolution begins, we support you. '"the truth is that we've already started to support you for a long time," and then we've been supporting you, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-20 10:10:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:10:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're on at our plane at the stumest was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable drive and a refrigeration system that allows us to use an aircraft in the ground, or if you can see one of the most trajectory vehicles in the ground, or if you can see one of one of the most trajectory vehicles that would see that would be used in the most specific things that would have to see in the same.
2022-03-20 10:10:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:10:55 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 6.676 | ppl 102.29 | bleu 32.21 | wps 4630.5 | wpb 17862.2 | bsz 728.3 | num_updates 5960 | best_bleu 32.21
2022-03-20 10:10:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5960 updates
2022-03-20 10:10:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:10:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:10:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 38 @ 5960 updates, score 32.21) (writing took 1.8378967442549765 seconds)
2022-03-20 10:10:57 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-20 10:10:57 | INFO | train | epoch 038 | loss 5.812 | ppl 56.19 | wps 39222.4 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5960 | lr 0.000409616 | gnorm 0.444 | loss_scale 2 | train_wall 58 | gb_free 12.9 | wall 3895
KL Stats: Epoch 38 Divergences: Uniform: 1.709474207832458 Unigram: 1.7587127402049278
2022-03-20 10:10:58 | INFO | fairseq.trainer | begin training epoch 39
2022-03-20 10:10:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:11:13 | INFO | train_inner | epoch 039:     40 / 157 loss=5.835, ppl=57.08, wps=31566.7, ups=1.26, wpb=25012, bsz=971.8, num_updates=6000, lr=0.000408248, gnorm=0.42, loss_scale=2, train_wall=37, gb_free=12.1, wall=3910
2022-03-20 10:11:50 | INFO | train_inner | epoch 039:    140 / 157 loss=5.796, ppl=55.55, wps=66534.8, ups=2.68, wpb=24852.3, bsz=1021.1, num_updates=6100, lr=0.000404888, gnorm=0.417, loss_scale=2, train_wall=37, gb_free=12.5, wall=3948
2022-03-20 10:11:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:12:01 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:12:01 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:12:05 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-20 10:12:05 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:12:09 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:12:09 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:12:12 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-20 10:12:12 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:12:16 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i am so that i can put my attention degree in the board on the other side.
2022-03-20 10:12:16 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:12:20 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity invites to form this new tool, as if it was a body of primates.
2022-03-20 10:12:20 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:12:24 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific shapes, experiments that go far beyond normal education.
2022-03-20 10:12:24 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:12:29 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restores the big contextures of the face and the basic shape, and deploy it through the entire information that pulls all the porn structure and all the fits.
2022-03-20 10:12:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:12:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when stripped dinner, it was best summarized when someone said, "turn to the men on your table and tell you," turn to the men at your table and tell you, "when the revolution begins to be here, then we support you. '" when the revolution, then we've already started to support you for a long time. "
2022-03-20 10:12:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:12:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a great part of the design work that we are on our airplane at the stumest was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation of design, and a refrigerator system that allows us to use an aircraft on the ground, to see in the ground, to the propellant, or if you're in the ground, to operate it's a mechanism, to operate on the ground, to operate it, to operate it, to operate it, to operate it, to operate it, to operate on the ground, to operate on the ground, to see it in a mechanism, to see it, to the ground -- everything, to the same time you can see it in a mechanism, to see it, to a mechanism -- everything, to a mechanism, to see it, to the same time you can see it in the ground -- everything, to the ground, to the
2022-03-20 10:12:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:12:36 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 6.693 | ppl 103.47 | bleu 31.99 | wps 4702.6 | wpb 17862.2 | bsz 728.3 | num_updates 6117 | best_bleu 32.21
2022-03-20 10:12:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6117 updates
2022-03-20 10:12:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:12:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 39 @ 6117 updates, score 31.99) (writing took 0.7491729222238064 seconds)
2022-03-20 10:12:36 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-20 10:12:36 | INFO | train | epoch 039 | loss 5.771 | ppl 54.6 | wps 39797.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 6117 | lr 0.000404325 | gnorm 0.403 | loss_scale 2 | train_wall 58 | gb_free 12.2 | wall 3994
KL Stats: Epoch 39 Divergences: Uniform: 1.7137607056648143 Unigram: 1.7678050599107296
2022-03-20 10:12:37 | INFO | fairseq.trainer | begin training epoch 40
2022-03-20 10:12:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:13:08 | INFO | train_inner | epoch 040:     83 / 157 loss=5.831, ppl=56.91, wps=32019.3, ups=1.29, wpb=24783.3, bsz=939.8, num_updates=6200, lr=0.00040161, gnorm=0.444, loss_scale=2, train_wall=36, gb_free=12.8, wall=4025
2022-03-20 10:13:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:13:39 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:13:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:13:44 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you realize it, you see the world differently.
2022-03-20 10:13:44 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:13:48 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:13:48 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:13:51 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-20 10:13:51 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:13:55 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how i'm focused so that i can put my attention degree in the board on the other side.
2022-03-20 10:13:55 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:13:59 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computers, the brain activity to form this new tool is like if it was a body part of the primate.
2022-03-20 10:13:59 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:14:03 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific forms, experiments that go far beyond normal education.
2022-03-20 10:14:03 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:14:08 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial sssssscan that restores the big contextures of the face and the basic shape, and decrease it through the whole portion structure and all the fits.
2022-03-20 10:14:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:14:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when stripped dinner, it was best summarized when someone said, "turn to the men on your table and tell you," when the revolution begins to support you. '' 'the truth is that women have already started you with silly carcolson's "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-20 10:14:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:14:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention is still the invention, and a big part of the design work that we were on our airplane was the result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigerator system that allows us to use an aircraft at the same time, to fit into a traffic station, or if you look at the propellant, or if you see the propelled, you can see it in the ground, or if you can see it in the same way that's a steady for the same way you can see a mechanism.
2022-03-20 10:14:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:14:15 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 6.635 | ppl 99.4 | bleu 32.53 | wps 4706.9 | wpb 17862.2 | bsz 728.3 | num_updates 6274 | best_bleu 32.53
2022-03-20 10:14:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6274 updates
2022-03-20 10:14:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:14:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:14:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 40 @ 6274 updates, score 32.53) (writing took 1.7845422169193625 seconds)
2022-03-20 10:14:16 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-20 10:14:16 | INFO | train | epoch 040 | loss 5.756 | ppl 54.06 | wps 39515.8 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6274 | lr 0.000399234 | gnorm 0.417 | loss_scale 2 | train_wall 58 | gb_free 11.8 | wall 4094
KL Stats: Epoch 40 Divergences: Uniform: 1.7104432049867442 Unigram: 1.767414407774151
2022-03-20 10:14:17 | INFO | fairseq.trainer | begin training epoch 41
2022-03-20 10:14:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:14:27 | INFO | train_inner | epoch 041:     26 / 157 loss=5.67, ppl=50.92, wps=32357, ups=1.27, wpb=25570.7, bsz=1083, num_updates=6300, lr=0.00039841, gnorm=0.386, loss_scale=2, train_wall=37, gb_free=11.9, wall=4104
2022-03-20 10:15:04 | INFO | train_inner | epoch 041:    126 / 157 loss=5.69, ppl=51.63, wps=68050.1, ups=2.66, wpb=25578.5, bsz=1003.1, num_updates=6400, lr=0.000395285, gnorm=0.416, loss_scale=2, train_wall=37, gb_free=11.9, wall=4142
2022-03-20 10:15:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:15:19 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:15:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:15:24 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you noticed it, you see the world differently.
2022-03-20 10:15:24 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:15:28 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between belief and reason, instinct and intelligence.
2022-03-20 10:15:28 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:15:31 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-20 10:15:31 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:15:35 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i am, so i can put my attention degree in the circuit board on the other side.
2022-03-20 10:15:35 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:15:39 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can reframe our computers, the brain activity invites to form this new tool as if it was part of the primate.
2022-03-20 10:15:39 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:15:43 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific shapes, experiments that go far beyond normal education.
2022-03-20 10:15:43 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:15:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that restores the big contextures of the face and the basic shape, and deploy it through the entire porn structure and all the fine folds.
2022-03-20 10:15:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:15:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... tyes, when stripped dinner, it was best summarized when someone said, "turn to the men on your table and tell you," when the revolution begins, we support you. '"the truth, women, we've already started you on this topic for a long time."
2022-03-20 10:15:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:15:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a great part of the design work that we're on at our airplane at the stumest was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable operating system and a cooling system that allows us to use an aircraft in the staircase, to the car traffic, to the most specific, if you look at the ground, or if you look at the wrong.
2022-03-20 10:15:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:15:53 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 6.656 | ppl 100.84 | bleu 32.1 | wps 4990.3 | wpb 17862.2 | bsz 728.3 | num_updates 6431 | best_bleu 32.53
2022-03-20 10:15:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6431 updates
2022-03-20 10:15:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:15:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:15:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 41 @ 6431 updates, score 32.1) (writing took 0.7923325579613447 seconds)
2022-03-20 10:15:54 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-20 10:15:54 | INFO | train | epoch 041 | loss 5.726 | ppl 52.92 | wps 40633.5 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 6431 | lr 0.000394331 | gnorm 0.405 | loss_scale 2 | train_wall 58 | gb_free 12.8 | wall 4191
KL Stats: Epoch 41 Divergences: Uniform: 1.7134941464919153 Unigram: 1.775667205093527
2022-03-20 10:15:54 | INFO | fairseq.trainer | begin training epoch 42
2022-03-20 10:15:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:16:20 | INFO | train_inner | epoch 042:     69 / 157 loss=5.705, ppl=52.15, wps=33344.9, ups=1.32, wpb=25345, bsz=1002.9, num_updates=6500, lr=0.000392232, gnorm=0.392, loss_scale=2, train_wall=37, gb_free=12.4, wall=4218
2022-03-20 10:16:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:16:56 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:16:56 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:17:01 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you realize it, you see the world different.
2022-03-20 10:17:01 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:17:05 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:17:05 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:17:09 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-20 10:17:09 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:17:13 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrated i am, so i can put my attention degree in the circuit board on the other side.
2022-03-20 10:17:13 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:17:17 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can reframe our computers, the brain productivity invites to form this new tool as if it was a body part of the primate.
2022-03-20 10:17:17 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:17:21 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific forms, experiments that go far beyond normal education.
2022-03-20 10:17:21 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:17:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that restores the big contextures of the face and the basic shape, and deploy it through the whole porn structure and all the fine fold.
2022-03-20 10:17:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:17:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when controversial dinner was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins to support you. '' 'women, we've already started to support you for a long time.
2022-03-20 10:17:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:17:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on on our airplane is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft at the top of go-traffic, to fit it in a particular way, to a propellant, to the ground, to see that either if you can see the propelled by a mechanism, or if you can see the mechanism in the ground in the same way we can see the same way that's mechanism, by a mechanism, if you can see it's in the same way we can see the same way that we can see the ground, by a continuously variable ways that we're going to the rains.
2022-03-20 10:17:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:17:32 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 6.627 | ppl 98.83 | bleu 32.67 | wps 4669 | wpb 17862.2 | bsz 728.3 | num_updates 6588 | best_bleu 32.67
2022-03-20 10:17:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6588 updates
2022-03-20 10:17:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:17:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:17:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 42 @ 6588 updates, score 32.67) (writing took 1.7289930740371346 seconds)
2022-03-20 10:17:33 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-20 10:17:33 | INFO | train | epoch 042 | loss 5.705 | ppl 52.17 | wps 39606.6 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6588 | lr 0.000389604 | gnorm 0.409 | loss_scale 2 | train_wall 58 | gb_free 12.5 | wall 4291
KL Stats: Epoch 42 Divergences: Uniform: 1.7143774882373364 Unigram: 1.7779234171317095
2022-03-20 10:17:34 | INFO | fairseq.trainer | begin training epoch 43
2022-03-20 10:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:17:38 | INFO | train_inner | epoch 043:     12 / 157 loss=5.778, ppl=54.87, wps=31137.1, ups=1.29, wpb=24219.5, bsz=1057, num_updates=6600, lr=0.000389249, gnorm=0.431, loss_scale=2, train_wall=36, gb_free=12.5, wall=4296
2022-03-20 10:18:16 | INFO | train_inner | epoch 043:    112 / 157 loss=5.656, ppl=50.42, wps=67671.6, ups=2.65, wpb=25509.4, bsz=1039, num_updates=6700, lr=0.000386334, gnorm=0.426, loss_scale=2, train_wall=37, gb_free=12.1, wall=4333
2022-03-20 10:18:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:18:36 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:18:36 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:18:41 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world differently.
2022-03-20 10:18:41 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:18:45 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instincts and intelligence.
2022-03-20 10:18:45 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:18:48 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-20 10:18:48 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:18:52 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrated i am, so i can put my attention degree in the circuit on the other side.
2022-03-20 10:18:52 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:18:56 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can reframe our computers, the brain activity invites to form this new tool as if it was a body part of the primate.
2022-03-20 10:18:56 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:19:00 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific shapes, experiments that go beyond normal education.
2022-03-20 10:19:00 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:19:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that gives the big configurations of the face and the basic shape, and add it through the whole information that refers the entire porn structure and all the fine folds.
2022-03-20 10:19:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:19:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when stripped dinner, it was best summarized when someone said, "turn to the men on your desk and tell you," when the revolution begins to support you. '"' the truth is that we've been supporting you for a long time."
2022-03-20 10:19:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:19:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're at at the stest of our plane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in stop and a special traffic system, to either see the propelled by the ground, if you see the mechanism, or if you can see the mechanism in the ground, you can see the same way.
2022-03-20 10:19:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:19:10 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 6.632 | ppl 99.18 | bleu 32.51 | wps 4844.6 | wpb 17862.2 | bsz 728.3 | num_updates 6745 | best_bleu 32.67
2022-03-20 10:19:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6745 updates
2022-03-20 10:19:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:19:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:19:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 43 @ 6745 updates, score 32.51) (writing took 0.844454362988472 seconds)
2022-03-20 10:19:11 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-20 10:19:11 | INFO | train | epoch 043 | loss 5.695 | ppl 51.8 | wps 40434.9 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 6745 | lr 0.000385043 | gnorm 0.426 | loss_scale 2 | train_wall 58 | gb_free 11.5 | wall 4389
KL Stats: Epoch 43 Divergences: Uniform: 1.7145543619616097 Unigram: 1.7792360758730519
2022-03-20 10:19:11 | INFO | fairseq.trainer | begin training epoch 44
2022-03-20 10:19:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:19:32 | INFO | train_inner | epoch 044:     55 / 157 loss=5.598, ppl=48.43, wps=33826.4, ups=1.31, wpb=25853, bsz=1091.9, num_updates=6800, lr=0.000383482, gnorm=0.388, loss_scale=2, train_wall=37, gb_free=12.6, wall=4410
2022-03-20 10:20:09 | INFO | train_inner | epoch 044:    155 / 157 loss=5.762, ppl=54.29, wps=66675.9, ups=2.71, wpb=24608.7, bsz=946.9, num_updates=6900, lr=0.000380693, gnorm=0.429, loss_scale=2, train_wall=37, gb_free=12.1, wall=4447
2022-03-20 10:20:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:20:14 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:20:14 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:20:18 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you noticed it, you see the world differently.
2022-03-20 10:20:18 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:20:22 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between belief and reason, instincts and intelligence.
2022-03-20 10:20:22 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:20:26 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-20 10:20:26 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:20:30 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrated i am, so that i can put my attention degree on the board on the other side.
2022-03-20 10:20:30 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:20:34 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computers, the brain activity shifts to form this new tool as if it was a body part of the primate.
2022-03-20 10:20:34 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:20:38 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific forms, experiments that go far beyond normal education.
2022-03-20 10:20:38 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:20:42 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial can that restores the big contextures of the face and the basic form, and add it through the information that refers all the porn structure and all the fones.
2022-03-20 10:20:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:20:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... tyes, when stripped dinner, it was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins to support you. '"the truth is that we've been supporting you in this topic for a long time."
2022-03-20 10:20:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:20:47 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on at our airplane is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variable drive and a refrigeration system that allows us to use an aircraft in stop-go-transportation, to fit the ground, to see, or if you're on the ground, from a mechanism.
2022-03-20 10:20:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:20:47 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 6.599 | ppl 96.92 | bleu 32.97 | wps 4868 | wpb 17862.2 | bsz 728.3 | num_updates 6902 | best_bleu 32.97
2022-03-20 10:20:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6902 updates
2022-03-20 10:20:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:20:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:20:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 44 @ 6902 updates, score 32.97) (writing took 1.823307830374688 seconds)
2022-03-20 10:20:49 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-20 10:20:49 | INFO | train | epoch 044 | loss 5.672 | ppl 50.97 | wps 40203 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6902 | lr 0.000380638 | gnorm 0.412 | loss_scale 2 | train_wall 58 | gb_free 13.2 | wall 4487
KL Stats: Epoch 44 Divergences: Uniform: 1.7130526676447995 Unigram: 1.7814788600470235
2022-03-20 10:20:49 | INFO | fairseq.trainer | begin training epoch 45
2022-03-20 10:20:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:21:26 | INFO | train_inner | epoch 045:     98 / 157 loss=5.685, ppl=51.45, wps=32052.6, ups=1.3, wpb=24657.3, bsz=974.7, num_updates=7000, lr=0.000377964, gnorm=0.395, loss_scale=2, train_wall=37, gb_free=12.2, wall=4524
2022-03-20 10:21:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:21:52 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:21:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:21:56 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden without you realizing it, you see the world differently.
2022-03-20 10:21:56 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:22:00 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different equilibrium between faith and reason, instinct and intelligence.
2022-03-20 10:22:00 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:22:04 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-20 10:22:04 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:22:08 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrated i am so that i can put my attention degree in the board on the other side.
2022-03-20 10:22:08 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:22:12 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to form this new tool as if it was a part of the primate.
2022-03-20 10:22:12 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:22:16 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific forms, experiments that go far beyond normal education.
2022-03-20 10:22:16 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:22:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that gives the big contextures of the face and the basic shape, and decrease it through the entire information that refers all the porn structure and all the fine folds.
2022-03-20 10:22:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:22:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when controversial dinner, it was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins to support you. '"the truth, women, we've been supporting you at this topic for a long time.
2022-03-20 10:22:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:22:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're at our plane at the stumes was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in stop and go-traffic, to fit it to one particular propeller, or if you look at the ground, the mechanism, or if you see the mechanism in the same time you're going to see the mechanism.
2022-03-20 10:22:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:22:26 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 6.599 | ppl 96.94 | bleu 32.63 | wps 4837.7 | wpb 17862.2 | bsz 728.3 | num_updates 7059 | best_bleu 32.97
2022-03-20 10:22:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7059 updates
2022-03-20 10:22:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:22:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:22:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 45 @ 7059 updates, score 32.63) (writing took 0.8258204655721784 seconds)
2022-03-20 10:22:27 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-20 10:22:27 | INFO | train | epoch 045 | loss 5.642 | ppl 49.94 | wps 40535.4 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 7059 | lr 0.000376382 | gnorm 0.39 | loss_scale 2 | train_wall 58 | gb_free 12.9 | wall 4584
KL Stats: Epoch 45 Divergences: Uniform: 1.7161133798146209 Unigram: 1.7882419526382984
2022-03-20 10:22:27 | INFO | fairseq.trainer | begin training epoch 46
2022-03-20 10:22:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:22:42 | INFO | train_inner | epoch 046:     41 / 157 loss=5.631, ppl=49.56, wps=32960.5, ups=1.31, wpb=25204.9, bsz=1068.6, num_updates=7100, lr=0.000375293, gnorm=0.395, loss_scale=2, train_wall=37, gb_free=11.8, wall=4600
2022-03-20 10:23:20 | INFO | train_inner | epoch 046:    141 / 157 loss=5.593, ppl=48.27, wps=68183.3, ups=2.67, wpb=25559.9, bsz=1018.2, num_updates=7200, lr=0.000372678, gnorm=0.385, loss_scale=2, train_wall=37, gb_free=11.8, wall=4638
2022-03-20 10:23:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:23:29 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:23:29 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:23:33 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world differently.
2022-03-20 10:23:33 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:23:37 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:23:37 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:23:41 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-20 10:23:41 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:23:46 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrated i am, so i can put my attention degree on the board on the other side.
2022-03-20 10:23:46 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:23:49 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computers, the brain activity shifts to form this new tool as if it was a body part of the primate.
2022-03-20 10:23:49 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:23:54 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formers, experiments that go far beyond normal education.
2022-03-20 10:23:54 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:23:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that comes from this mirror reflection, we can start with a traditional facial can that gives back the big contextures of the face and the basic shape, and add it through the information that refers all the porn structure and all the fine folds.
2022-03-20 10:23:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:24:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... tyes, when stripped dinner, it was best summarized when someone said, "turn to the men on your table and tell you, 'when the revolution begins to support you.' '' '' 'the truth, women, we've been supporting you at this topic for a long time.
2022-03-20 10:24:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:24:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of design, and a large part of the design work that we're on at our plane on the stest was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable basis and a refrigerator system that allows us to use an aircraft in stop and go-traffic, to fit it to a particular propeller, either if you were connected to the ground, or if you look at the mechanism, you're in the same time.
2022-03-20 10:24:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:24:03 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 6.6 | ppl 96.99 | bleu 33.16 | wps 4880.2 | wpb 17862.2 | bsz 728.3 | num_updates 7216 | best_bleu 33.16
2022-03-20 10:24:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7216 updates
2022-03-20 10:24:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:24:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:24:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 46 @ 7216 updates, score 33.16) (writing took 2.0397923002019525 seconds)
2022-03-20 10:24:05 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-20 10:24:05 | INFO | train | epoch 046 | loss 5.627 | ppl 49.41 | wps 40121.9 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 7216 | lr 0.000372265 | gnorm 0.393 | loss_scale 2 | train_wall 58 | gb_free 11.6 | wall 4683
KL Stats: Epoch 46 Divergences: Uniform: 1.7169361705251436 Unigram: 1.7931788743205141
2022-03-20 10:24:05 | INFO | fairseq.trainer | begin training epoch 47
2022-03-20 10:24:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:24:37 | INFO | train_inner | epoch 047:     84 / 157 loss=5.602, ppl=48.57, wps=32826.6, ups=1.3, wpb=25256.3, bsz=989.6, num_updates=7300, lr=0.000370117, gnorm=0.388, loss_scale=2, train_wall=37, gb_free=12.4, wall=4714
2022-03-20 10:25:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:25:08 | INFO | fairseq.tasks.translation | example hypothesis: this probe cannot use chemical rockets.
2022-03-20 10:25:08 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:25:12 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without realizing it, you see the world differently.
2022-03-20 10:25:12 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:25:16 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:25:16 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:25:19 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-20 10:25:19 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:25:23 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrated i am, so i can put my attention degree on the board on the other side.
2022-03-20 10:25:23 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:25:27 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can reframe our computers, brain activity shifts to form this new tool as if it was a body of primate.
2022-03-20 10:25:27 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:25:32 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our kids a lot of scientific formulas, experiments that go far beyond normal education.
2022-03-20 10:25:32 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:25:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can, which gives the big contextures of the face and the basic shape, and refers it through the information that refers all the porn structure and all the fones.
2022-03-20 10:25:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:25:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when stripped dinner, it was best summarized when someone said, "turn to the men on your desk and tell you," when the revolution begins to support you. '"the truth, women, that we've been supporting you at this topic for a long time." at chrael carrael's "
2022-03-20 10:25:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:25:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a cooling system with liquid that allows us to use an aircraft in the stop-go-transportation machine to a specially appropriate vehicle, to a propeller vehicle, or if you look at the ground, if you look at the wrong, if you look at the ground, if you put it's a mechanism on the ground, or if you look at the ground, if you put it's a mechanism on the ground, you see a mechanism on the ground, if you can see the mechanism in the same time you're in the ground, you're in the same time you can see a mechanism, if you put it's in the mechanical space, if you can see the ground, if you put it's in the mechanical space at the ground, you
2022-03-20 10:25:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:25:43 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 6.611 | ppl 97.74 | bleu 32.93 | wps 4651.7 | wpb 17862.2 | bsz 728.3 | num_updates 7373 | best_bleu 33.16
2022-03-20 10:25:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 7373 updates
2022-03-20 10:25:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:25:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:25:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 47 @ 7373 updates, score 32.93) (writing took 0.8077106047421694 seconds)
2022-03-20 10:25:44 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-20 10:25:44 | INFO | train | epoch 047 | loss 5.617 | ppl 49.06 | wps 39976.9 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 7373 | lr 0.00036828 | gnorm 0.418 | loss_scale 2 | train_wall 58 | gb_free 11.9 | wall 4781
KL Stats: Epoch 47 Divergences: Uniform: 1.7164664469840396 Unigram: 1.7934132054913023
2022-03-20 10:25:44 | INFO | fairseq.trainer | begin training epoch 48
2022-03-20 10:25:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:25:54 | INFO | train_inner | epoch 048:     27 / 157 loss=5.638, ppl=49.79, wps=32152.5, ups=1.29, wpb=24938.6, bsz=1093.3, num_updates=7400, lr=0.000367607, gnorm=0.429, loss_scale=2, train_wall=37, gb_free=11.8, wall=4792
2022-03-20 10:26:32 | INFO | train_inner | epoch 048:    127 / 157 loss=5.641, ppl=49.9, wps=66978.5, ups=2.67, wpb=25119.8, bsz=916, num_updates=7500, lr=0.000365148, gnorm=0.394, loss_scale=2, train_wall=37, gb_free=12, wall=4830
2022-03-20 10:26:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:26:47 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:26:47 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:26:50 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden without you realize it, you see the world different.
2022-03-20 10:26:50 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:26:54 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between belief and reason, instinct and intelligence.
2022-03-20 10:26:54 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:26:58 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-20 10:26:58 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:27:02 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrated i am so that i can put my attention degree in the board on the other side.
2022-03-20 10:27:02 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:27:06 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can reframe our computers, the brain activity shifts to form this new tool as if it was a body of primates.
2022-03-20 10:27:06 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:27:10 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific forms, experiments that go way beyond normal education.
2022-03-20 10:27:10 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:27:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can that will restore the big consculptures of the face and the basic shape of that information that will attract all the porn structure and all the folds.
2022-03-20 10:27:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:27:18 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when stripped dinner, it was best summarized when someone said, "turn to the men on your table and tell them, 'when the revolution begins to support you.' '' '' the truth, women, we've been supporting you at this topic for a long time.
2022-03-20 10:27:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:27:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're at our plane at the stest was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in stop-go-traffic, to a particular propelled propeller.
2022-03-20 10:27:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:27:20 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 6.598 | ppl 96.88 | bleu 32.58 | wps 4957.9 | wpb 17862.2 | bsz 728.3 | num_updates 7530 | best_bleu 33.16
2022-03-20 10:27:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 7530 updates
2022-03-20 10:27:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:27:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:27:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 48 @ 7530 updates, score 32.58) (writing took 0.7812917120754719 seconds)
2022-03-20 10:27:20 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-20 10:27:20 | INFO | train | epoch 048 | loss 5.595 | ppl 48.34 | wps 40862.2 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 7530 | lr 0.00036442 | gnorm 0.39 | loss_scale 2 | train_wall 58 | gb_free 12.1 | wall 4878
KL Stats: Epoch 48 Divergences: Uniform: 1.718805974948611 Unigram: 1.7985443264798637
2022-03-20 10:27:21 | INFO | fairseq.trainer | begin training epoch 49
2022-03-20 10:27:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:27:47 | INFO | train_inner | epoch 049:     70 / 157 loss=5.5, ppl=45.26, wps=33926.8, ups=1.33, wpb=25588.8, bsz=1137.5, num_updates=7600, lr=0.000362738, gnorm=0.377, loss_scale=2, train_wall=37, gb_free=12.5, wall=4905
2022-03-20 10:28:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:28:25 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:28:25 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:28:28 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world differently.
2022-03-20 10:28:28 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:28:32 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between belief and reason, instinct and intelligence.
2022-03-20 10:28:32 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:28:36 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-20 10:28:36 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:28:40 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrated i am so that i can put my attention degree in the board on the other side.
2022-03-20 10:28:40 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:28:44 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can reframe our computers, the brain activity invites to form this new tool as if it was part of the primate's body.
2022-03-20 10:28:44 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:28:48 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formulas, experiments that go far beyond normal education.
2022-03-20 10:28:48 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:28:53 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that gives the big contextures of the face and the basic shape, and deploy it through the information that refers all the pore-structure and all the fits.
2022-03-20 10:28:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:28:57 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, when i was striking dinner, it was best summarized when someone said, "turn to the men on your table and tell them," if the revolution begins to support you. 'the truth, women, women, we've been supporting you at this topic for a long time.
2022-03-20 10:28:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:28:59 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're on at our plane at the stumest was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft machine in stop-go-go-transportation, to a particular driver's transportation system, to a propeller, either to the propeller, to the propeller, to the propeller, to the ground, to the mechanism, to the mechanism, to the mechanism, to the mechanism, to the mechanism.
2022-03-20 10:28:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:28:59 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 6.565 | ppl 94.68 | bleu 33.59 | wps 4762 | wpb 17862.2 | bsz 728.3 | num_updates 7687 | best_bleu 33.59
2022-03-20 10:28:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 7687 updates
2022-03-20 10:28:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:29:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:29:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 49 @ 7687 updates, score 33.59) (writing took 1.8740540989674628 seconds)
2022-03-20 10:29:01 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-20 10:29:01 | INFO | train | epoch 049 | loss 5.577 | ppl 47.72 | wps 39330.3 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 7687 | lr 0.00036068 | gnorm 0.383 | loss_scale 2 | train_wall 58 | gb_free 11.8 | wall 4978
KL Stats: Epoch 49 Divergences: Uniform: 1.717251705628537 Unigram: 1.7988203769404885
2022-03-20 10:29:01 | INFO | fairseq.trainer | begin training epoch 50
2022-03-20 10:29:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:29:06 | INFO | train_inner | epoch 050:     13 / 157 loss=5.604, ppl=48.63, wps=31638.9, ups=1.27, wpb=24979.2, bsz=958.7, num_updates=7700, lr=0.000360375, gnorm=0.398, loss_scale=2, train_wall=36, gb_free=11.7, wall=4984
2022-03-20 10:29:44 | INFO | train_inner | epoch 050:    113 / 157 loss=5.601, ppl=48.55, wps=66696.9, ups=2.67, wpb=24958.7, bsz=1045, num_updates=7800, lr=0.000358057, gnorm=0.37, loss_scale=2, train_wall=37, gb_free=11.8, wall=5021
2022-03-20 10:30:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:30:04 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:30:04 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:30:08 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world differently.
2022-03-20 10:30:08 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:30:12 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between belief and reason, instinct and intelligence.
2022-03-20 10:30:12 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:30:16 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are tight allies in the united states.
2022-03-20 10:30:16 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:30:20 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i am, so i can put my attention degree in the board on the other side.
2022-03-20 10:30:20 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:30:24 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can reframe our computers, the brain activity shifts to form this new tool as if it was a body of primate.
2022-03-20 10:30:24 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:30:28 | INFO | fairseq.tasks.translation | example hypothesis: is it influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formulas, experiments that go way beyond normal education.
2022-03-20 10:30:28 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:30:32 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can, which gives the big configurations of the face and the basic shape, and add it through the information that refers the entire porn structure and all the fones.
2022-03-20 10:30:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:30:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when stripped dinner, it was best summarized when someone said, "turn to the men on your desk and tell them," when the revolution begins to support you. '"the truth, women, women, we've been supporting you at this topic for a long time. at chel carcinema,"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["]
2022-03-20 10:30:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:30:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we're at our airplane stumbling on was a result that we had to solve the unique problems associated with operating it on the ground -- everything from a continuous variation and a refrigerator system that allows us to use a stop-go-go-go-go-traffic aircraft aircraft aircraft, to a particular propeller, either if you drive the propeller, or if you look at the ground, the ground, you can see it's a mechanism, to see it in the same way.
2022-03-20 10:30:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:30:39 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 6.571 | ppl 95.1 | bleu 33.32 | wps 4664.8 | wpb 17862.2 | bsz 728.3 | num_updates 7844 | best_bleu 33.59
2022-03-20 10:30:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 7844 updates
2022-03-20 10:30:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:30:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:30:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 50 @ 7844 updates, score 33.32) (writing took 0.8074732962995768 seconds)
2022-03-20 10:30:39 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-20 10:30:39 | INFO | train | epoch 050 | loss 5.558 | ppl 47.12 | wps 40028.3 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 7844 | lr 0.000357052 | gnorm 0.385 | loss_scale 2 | train_wall 58 | gb_free 12.1 | wall 5077
KL Stats: Epoch 50 Divergences: Uniform: 1.7200826628519805 Unigram: 1.8039675850766788
2022-03-20 10:30:40 | INFO | fairseq.trainer | begin training epoch 51
2022-03-20 10:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:31:01 | INFO | train_inner | epoch 051:     56 / 157 loss=5.473, ppl=44.43, wps=33152.4, ups=1.29, wpb=25633.7, bsz=1022.2, num_updates=7900, lr=0.000355784, gnorm=0.381, loss_scale=2, train_wall=37, gb_free=12.6, wall=5099
2022-03-20 10:31:38 | INFO | train_inner | epoch 051:    156 / 157 loss=5.608, ppl=48.76, wps=66942.4, ups=2.71, wpb=24680.4, bsz=985.9, num_updates=8000, lr=0.000353553, gnorm=0.415, loss_scale=2, train_wall=36, gb_free=12.2, wall=5136
2022-03-20 10:31:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:31:42 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:31:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:31:46 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world differently.
2022-03-20 10:31:46 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:31:50 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:31:50 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:31:54 | INFO | fairseq.tasks.translation | example hypothesis: it's especially focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-20 10:31:54 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:31:59 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrated i am so that i can put my attention degree in the board on the other side.
2022-03-20 10:31:59 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:32:03 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can reframe our computers, the brain activity shifts to form this new tool as if it was a body of primate.
2022-03-20 10:32:03 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:32:07 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formulas, experiments that go far beyond normal education.
2022-03-20 10:32:07 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:32:11 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial can that gives back the big configurations of the face and the basic shape, and add it through the information that refers all the por-structure and all the fine folds.
2022-03-20 10:32:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:32:15 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... tyes, when strictly dinner, it was best summarized when someone said, "turn to the men at your table and tell them," when the revolution begins, we support you. '"the truth, women, that we've been supporting you at this topic for a long time. at chel cartheo,"
2022-03-20 10:32:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:32:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're at our plane on the stumest was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft in stop and traffic to fit in a particular propeller, or if you're at the ground, to see the propelled or if you're going to be in the ground, if you're going to be in a mechanism, if you're on the ground, you're going to see the ground, you're going to be in the same way you're going to see, if you're going to be in the ground, if you're going to see a mechanism, or if you're going to be in the ground, you're going to be in the same way you're going to see a mechanism.
2022-03-20 10:32:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:32:17 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 6.547 | ppl 93.48 | bleu 33.64 | wps 4719.7 | wpb 17862.2 | bsz 728.3 | num_updates 8001 | best_bleu 33.64
2022-03-20 10:32:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 8001 updates
2022-03-20 10:32:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:32:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:32:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 51 @ 8001 updates, score 33.64) (writing took 1.8743659099563956 seconds)
2022-03-20 10:32:19 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-20 10:32:19 | INFO | train | epoch 051 | loss 5.552 | ppl 46.92 | wps 39748.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 8001 | lr 0.000353531 | gnorm 0.394 | loss_scale 2 | train_wall 58 | gb_free 12.5 | wall 5176
KL Stats: Epoch 51 Divergences: Uniform: 1.7191626072585657 Unigram: 1.804380678482401
2022-03-20 10:32:19 | INFO | fairseq.trainer | begin training epoch 52
2022-03-20 10:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:32:56 | INFO | train_inner | epoch 052:     99 / 157 loss=5.547, ppl=46.77, wps=31735.7, ups=1.28, wpb=24811.1, bsz=1064.1, num_updates=8100, lr=0.000351364, gnorm=0.409, loss_scale=2, train_wall=37, gb_free=12, wall=5214
2022-03-20 10:33:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:33:22 | INFO | fairseq.tasks.translation | example hypothesis: this probe cannot use chemical rockets.
2022-03-20 10:33:22 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:33:26 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden without you notice it, you see the world differently.
2022-03-20 10:33:26 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:33:29 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:33:29 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:33:33 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-20 10:33:33 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:33:37 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i am so that i can put my attention degree in the circuit board on the other side.
2022-03-20 10:33:37 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:33:41 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to form this new tool as if it was part of the body of primates.
2022-03-20 10:33:41 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:33:46 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formulas, experiments that go far beyond normal education.
2022-03-20 10:33:46 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:33:50 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial can that gives back the big configurations of the face and the basic shape, and add it through the information that refers all the por-structure and all the fine folds.
2022-03-20 10:33:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:33:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when strictly dinner, it was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins to support you. '"the truth, women, is that we've been supporting you in this topic for a long time. in rael carson," with siltheo borra, "to the future down to sandstream."
2022-03-20 10:33:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:33:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention is still, and a large part of the design work that we're on at our airplane is the most stumbling, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and cooling system with liquid, that allows us to use an aircraft in stop and go-traffic, to a particular passage that either drives the propeller, or if you're on the ground, to be able to see the mechanism in the same way.
2022-03-20 10:33:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:33:56 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 6.544 | ppl 93.28 | bleu 33.88 | wps 4769.6 | wpb 17862.2 | bsz 728.3 | num_updates 8158 | best_bleu 33.88
2022-03-20 10:33:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 8158 updates
2022-03-20 10:33:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:33:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt
2022-03-20 10:33:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_best.pt (epoch 52 @ 8158 updates, score 33.88) (writing took 1.894736424088478 seconds)
2022-03-20 10:33:58 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-20 10:33:58 | INFO | train | epoch 052 | loss 5.542 | ppl 46.59 | wps 39824.2 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 8158 | lr 0.000350113 | gnorm 0.401 | loss_scale 2 | train_wall 58 | gb_free 12 | wall 5276
KL Stats: Epoch 52 Divergences: Uniform: 1.7215680094750156 Unigram: 1.8079858008580538
2022-03-20 10:33:58 | INFO | fairseq.trainer | begin training epoch 53
2022-03-20 10:33:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:34:14 | INFO | train_inner | epoch 053:     42 / 157 loss=5.509, ppl=45.54, wps=32510, ups=1.29, wpb=25247.7, bsz=1023.4, num_updates=8200, lr=0.000349215, gnorm=0.402, loss_scale=2, train_wall=37, gb_free=12.1, wall=5291
2022-03-20 10:34:52 | INFO | train_inner | epoch 053:    142 / 157 loss=5.546, ppl=46.71, wps=67425.2, ups=2.65, wpb=25466.9, bsz=943.4, num_updates=8300, lr=0.000347105, gnorm=0.39, loss_scale=2, train_wall=37, gb_free=12, wall=5329
2022-03-20 10:34:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:35:01 | INFO | fairseq.tasks.translation | example hypothesis: this probe cannot use chemical rockets.
2022-03-20 10:35:01 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:35:04 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-20 10:35:04 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:35:08 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instincts and intelligence.
2022-03-20 10:35:08 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:35:12 | INFO | fairseq.tasks.translation | example hypothesis: it's especially focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-20 10:35:12 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:35:16 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i am, so i can put my attention degree in the board on the other side.
2022-03-20 10:35:16 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:35:20 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to form this new tool as if it was a body of primate.
2022-03-20 10:35:20 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:35:24 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formulas, experiments that go far beyond normal education.
2022-03-20 10:35:24 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:35:28 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial can restore the big contextures of the face and the basic shape, and defend it through that information that refers all the pore-structure and all the fine folds.
2022-03-20 10:35:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:35:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, when controversial dinner, it was best summarized when someone said, "turn to the men at your table and tell them," 'when the revolution begins, then we support you.' "the truth, women, we've been supporting you at this topic for a long time. at racarel spring," our future down to sandra. "
2022-03-20 10:35:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:35:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're at our plane at the most stumbling was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable drive and a cooling system with liquid, that allows us to use a stop and go-go-traffic aircraft engine, until a particular propeller, or if you're on the ground, to see it in the same way.
2022-03-20 10:35:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:35:33 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 6.556 | ppl 94.07 | bleu 33.44 | wps 5038.3 | wpb 17862.2 | bsz 728.3 | num_updates 8315 | best_bleu 33.88
2022-03-20 10:35:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 8315 updates
2022-03-20 10:35:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:35:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:35:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 53 @ 8315 updates, score 33.44) (writing took 0.8533547567203641 seconds)
2022-03-20 10:35:34 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-20 10:35:34 | INFO | train | epoch 053 | loss 5.526 | ppl 46.09 | wps 41129.7 | ups 1.64 | wpb 25153.6 | bsz 1020.6 | num_updates 8315 | lr 0.000346792 | gnorm 0.395 | loss_scale 2 | train_wall 58 | gb_free 11.8 | wall 5372
KL Stats: Epoch 53 Divergences: Uniform: 1.720248233942621 Unigram: 1.8089968443776003
2022-03-20 10:35:34 | INFO | fairseq.trainer | begin training epoch 54
2022-03-20 10:35:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:36:07 | INFO | train_inner | epoch 054:     85 / 157 loss=5.452, ppl=43.77, wps=34243, ups=1.33, wpb=25727.3, bsz=1065.2, num_updates=8400, lr=0.000345033, gnorm=0.395, loss_scale=2, train_wall=37, gb_free=11.9, wall=5404
2022-03-20 10:36:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:36:38 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:36:38 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:36:41 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you noticing it, you see the world differently.
2022-03-20 10:36:41 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:36:45 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between belief and reason, instinct and intelligence.
2022-03-20 10:36:45 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:36:49 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-20 10:36:49 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:36:53 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i am so that i can put my attention degree in the board on the other side.
2022-03-20 10:36:53 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:36:57 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can reframe our computers, the brain activity shifts to form this new tool as if it was a body part of the primate.
2022-03-20 10:36:57 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:37:01 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formulas, experiments that go way beyond normal education.
2022-03-20 10:37:01 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:37:06 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial can that restore the big contextures of the face and the basic shape, and add it through that information that refers all the por-structure and all the fine folds.
2022-03-20 10:37:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:37:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when strictly dinner, it was best summarized when someone said, "turn to the men on your table and tell you," when the revolution starts to support you. '"the truth, women, we've been supporting you at this topic for a long time. in rachel cartheo," then, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["]
2022-03-20 10:37:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:37:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're on at our plane at the stumest was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigeration system that allows us to use a stop and go-go-traffic aircraft machine to a particular driver, either propeller, or if you had to solve the propeller on the ground, to see it in the ground, to the ground, to the mechanism, to the fall, to the mechanism of a mechanism, to the fall, to the fall in the fall in the ground, to the mechanism, to the fall, to the mechanism, to the freeze it will be able, to the freeze it will be able, to the ground, to the freeze it will allow us to see that it will be able, to see a mechanism, to see the ground, to the fall, to the
2022-03-20 10:37:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:37:12 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 6.53 | ppl 92.44 | bleu 33.63 | wps 4714.4 | wpb 17862.2 | bsz 728.3 | num_updates 8472 | best_bleu 33.88
2022-03-20 10:37:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 8472 updates
2022-03-20 10:37:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:37:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:37:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 54 @ 8472 updates, score 33.63) (writing took 0.8759785098955035 seconds)
2022-03-20 10:37:13 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-20 10:37:13 | INFO | train | epoch 054 | loss 5.516 | ppl 45.75 | wps 39807.9 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 8472 | lr 0.000343564 | gnorm 0.4 | loss_scale 2 | train_wall 58 | gb_free 12.5 | wall 5471
KL Stats: Epoch 54 Divergences: Uniform: 1.7214359289694456 Unigram: 1.8105280341388157
2022-03-20 10:37:14 | INFO | fairseq.trainer | begin training epoch 55
2022-03-20 10:37:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:37:24 | INFO | train_inner | epoch 055:     28 / 157 loss=5.561, ppl=47.2, wps=31653.7, ups=1.29, wpb=24525, bsz=1004.1, num_updates=8500, lr=0.000342997, gnorm=0.395, loss_scale=2, train_wall=36, gb_free=12.7, wall=5482
2022-03-20 10:38:01 | INFO | train_inner | epoch 055:    128 / 157 loss=5.575, ppl=47.68, wps=66056.1, ups=2.68, wpb=24642, bsz=1030.2, num_updates=8600, lr=0.000340997, gnorm=0.395, loss_scale=2, train_wall=37, gb_free=11.7, wall=5519
2022-03-20 10:38:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:38:16 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-20 10:38:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-20 10:38:20 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden without you notice it, you see the world differently.
2022-03-20 10:38:20 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-20 10:38:24 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between belief and reason, instinct and intelligence.
2022-03-20 10:38:24 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-20 10:38:28 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-20 10:38:28 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-20 10:38:32 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrated i am so that i can put my attention degree on the board on the other side.
2022-03-20 10:38:32 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-20 10:38:36 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can reframe our computers, the brain activity shifts to form this new tool as if it was a body part of the primates.
2022-03-20 10:38:36 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-20 10:38:40 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formulas, experiments that go far beyond normal education.
2022-03-20 10:38:40 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-20 10:38:44 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face that replaces the big contextures of the face and the basic shape, and add it through the information that refers all the por-structure and all the fine folds.
2022-03-20 10:38:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:38:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when controversial dinner, it was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins, we will support you. '"the truth, women, we've been supporting you at this topic for a long time. at racarson's"
2022-03-20 10:38:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:38:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on at our plane at the stest was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable gear and a refrigeration system that allows us to use a stop and go-transportation machine to a specially fit that either drives the propellers or when you run the ground, to the mechanism.
2022-03-20 10:38:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:38:49 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 6.548 | ppl 93.59 | bleu 33.59 | wps 4957.9 | wpb 17862.2 | bsz 728.3 | num_updates 8629 | best_bleu 33.88
2022-03-20 10:38:49 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-20 10:38:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 8629 updates
2022-03-20 10:38:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:38:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt
2022-03-20 10:38:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#2/checkpoint_last.pt (epoch 55 @ 8629 updates, score 33.59) (writing took 0.8394357012584805 seconds)
2022-03-20 10:38:50 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-20 10:38:50 | INFO | train | epoch 055 | loss 5.501 | ppl 45.27 | wps 40868.4 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 8629 | lr 0.000340424 | gnorm 0.391 | loss_scale 2 | train_wall 58 | gb_free 12.1 | wall 5567
2022-03-20 10:38:50 | INFO | fairseq_cli.train | done training in 5567.0 seconds
