Sender: LSF System <lsfadmin@eu-g3-060>
Subject: Job 210581753: <iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:25:58 2022
Job was executed on host(s) <eu-g3-060>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:26:23 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:26:23 2022
Terminated at Wed Mar 23 10:51:17 2022
Results reported at Wed Mar 23 10:51:17 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.35 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5087.52 sec.
    Max Memory :                                 5129 MB
    Average Memory :                             3893.49 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14871.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   5093 sec.
    Turnaround time :                            5119 sec.

The output (if any) follows:

2022-03-23 09:26:29 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.35, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.35, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:26:29 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:26:29 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:26:29 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:26:29 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:26:29 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:26:29 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:26:29 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:26:29 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:26:29 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:26:29 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:26:29 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:26:31 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:26:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:26:31 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:26:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:26:31 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:26:31 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:26:31 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 09:26:31 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 09:26:31 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:26:31 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:26:31 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:26:31 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:26:32 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:26:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:26:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:26:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:26:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:26:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:27:06 | INFO | train_inner | epoch 001:    104 / 157 loss=12.42, nll_loss=11.869, ppl=3741.46, wps=80039.3, ups=3.18, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=2.354, loss_scale=8, train_wall=33, gb_free=14, wall=35
2022-03-23 09:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:27:25 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 09:27:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:27:28 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:27:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:27:31 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,....
2022-03-23 09:27:31 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:27:34 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,
2022-03-23 09:27:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:27:38 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:38 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:27:43 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:27:48 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:27:54 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:28:01 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:28:03 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:28:03 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.226 | nll_loss 10.042 | ppl 1054.03 | bleu 0.01 | wps 4327.1 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:28:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:28:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:28:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:28:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.6238852249953197 seconds)
2022-03-23 09:28:05 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:28:05 | INFO | train | epoch 001 | loss 12.107 | nll_loss 11.393 | ppl 2688.49 | wps 42360.5 | ups 1.69 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 1.871 | loss_scale 8 | train_wall 49 | gb_free 22.4 | wall 93
2022-03-23 09:28:05 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:28:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:28:20 | INFO | train_inner | epoch 002:     47 / 157 loss=11.343, nll_loss=10.239, ppl=1208.8, wps=34163.1, ups=1.35, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=0.908, loss_scale=8, train_wall=30, gb_free=14.7, wall=109
2022-03-23 09:28:52 | INFO | train_inner | epoch 002:    147 / 157 loss=10.891, nll_loss=9.501, ppl=724.66, wps=80124.2, ups=3.18, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=0.983, loss_scale=8, train_wall=31, gb_free=14, wall=140
2022-03-23 09:28:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:28:58 | INFO | fairseq.tasks.translation | example hypothesis: we we we.
2022-03-23 09:28:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:29:01 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the.
2022-03-23 09:29:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:29:05 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the the the the.
2022-03-23 09:29:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:29:10 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:29:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:29:16 | INFO | fairseq.tasks.translation | example hypothesis: and and we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:29:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:29:21 | INFO | fairseq.tasks.translation | example hypothesis: and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:29:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:29:27 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:29:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:29:32 | INFO | fairseq.tasks.translation | example hypothesis: and and and we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:29:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:29:40 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:29:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:29:42 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:29:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:29:42 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 10.678 | nll_loss 9.049 | ppl 529.54 | bleu 0.01 | wps 3688 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.01
2022-03-23 09:29:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:29:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:29:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:29:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.01) (writing took 1.6727740559872473 seconds)
2022-03-23 09:29:44 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:29:44 | INFO | train | epoch 002 | loss 10.966 | nll_loss 9.63 | ppl 792.34 | wps 39977.2 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.935 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 192
2022-03-23 09:29:44 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:29:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:30:12 | INFO | train_inner | epoch 003:     90 / 157 loss=10.719, nll_loss=9.181, ppl=580.58, wps=30516, ups=1.24, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=0.939, loss_scale=8, train_wall=30, gb_free=13.7, wall=221
2022-03-23 09:30:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:30:36 | INFO | fairseq.tasks.translation | example hypothesis: we the the the.
2022-03-23 09:30:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:30:40 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the.
2022-03-23 09:30:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:30:44 | INFO | fairseq.tasks.translation | example hypothesis: and the the the of the of the the of the of the.
2022-03-23 09:30:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:30:49 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's, and it's, and it's's, and it's.
2022-03-23 09:30:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:30:54 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's's, it's's, it's's, it's's's, and it's's's's, and it's's's's, and it's's's's, and it's's's's.
2022-03-23 09:30:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:31:00 | INFO | fairseq.tasks.translation | example hypothesis: and and the the, and and the the the the the the the the the the the the the the the the the the the the the of the of the of the of the of the the the the the of the the the of the of the of the the the the the the the the
2022-03-23 09:31:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:31:06 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's, and it's's's, and it's, it's, and it's, and it's's's's's's, and the the the, and it's, and it's, and it's's's's, and the the the the the, and it's, and it's, and
2022-03-23 09:31:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:31:12 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, and we, and we, and we, and we, and we, and the the the the the, and the the the, and the the, and the the the, and we, and we, and we, and the the the the the the the, and the the the, and the the the the the the, and the the the the the the the the, and the the the the the the, and we
2022-03-23 09:31:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:31:19 | INFO | fairseq.tasks.translation | example hypothesis: and it's, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:31:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:31:22 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to,
2022-03-23 09:31:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:31:22 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.537 | nll_loss 8.76 | ppl 433.6 | bleu 0.17 | wps 3621.8 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.17
2022-03-23 09:31:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 09:31:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:31:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:31:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.17) (writing took 1.7011726240016287 seconds)
2022-03-23 09:31:23 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:31:23 | INFO | train | epoch 003 | loss 10.669 | nll_loss 9.096 | ppl 547.08 | wps 39621.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 1.001 | loss_scale 8 | train_wall 48 | gb_free 13.7 | wall 292
2022-03-23 09:31:24 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:31:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:31:34 | INFO | train_inner | epoch 004:     33 / 157 loss=10.577, nll_loss=8.94, ppl=491.03, wps=30938.4, ups=1.22, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=0.982, loss_scale=8, train_wall=31, gb_free=13.9, wall=303
2022-03-23 09:32:06 | INFO | train_inner | epoch 004:    133 / 157 loss=10.44, nll_loss=8.712, ppl=419.25, wps=79795.3, ups=3.16, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.06, loss_scale=8, train_wall=31, gb_free=12.6, wall=335
2022-03-23 09:32:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:32:17 | INFO | fairseq.tasks.translation | example hypothesis: we're the world.
2022-03-23 09:32:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:32:21 | INFO | fairseq.tasks.translation | example hypothesis: this is that's the world of the world of the world.
2022-03-23 09:32:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:32:26 | INFO | fairseq.tasks.translation | example hypothesis: now, we have to have to be the world of the world.
2022-03-23 09:32:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:32:31 | INFO | fairseq.tasks.translation | example hypothesis: and it's a of the world, and it's a world of the world.
2022-03-23 09:32:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:32:36 | INFO | fairseq.tasks.translation | example hypothesis: and it's a that we're're not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not that it.
2022-03-23 09:32:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:32:41 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world, and this is the world of the world of the world, and the world of the world of the world of the world.
2022-03-23 09:32:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:32:47 | INFO | fairseq.tasks.translation | example hypothesis: but it's the are are are the world, but you can can can can't't't know, but but they're are are are are are are are are are are the world, but but they're are are are are are are the world, but it's the world, but it's the world, but it's the world.
2022-03-23 09:32:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:32:53 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can can can can can can can can can can can can can can can can can can can can the the the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can be be be be be be be be be be be be be be be be be be be be be
2022-03-23 09:32:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:33:00 | INFO | fairseq.tasks.translation | example hypothesis: and "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:33:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:33:03 | INFO | fairseq.tasks.translation | example hypothesis: so, we have to have to have a a a to be a a a a to be a a a to be, and we have to be a to be a a a a a to be to be to be to be to be to be to be to be a a to be to be to be to be, and we have to be be to be to be to be a a a to be be be be be a a a a a to be to be to be to be, and it, and it, and we have to be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be to be to be to be to be, and it, and we have to be to be to be to be be be be be to be, and we have to be be to be be be be be be be be be be be to be be be be be be be be
2022-03-23 09:33:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:33:03 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.218 | nll_loss 8.201 | ppl 294.18 | bleu 0.81 | wps 3570.1 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.81
2022-03-23 09:33:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 09:33:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:33:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:33:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.81) (writing took 1.6821245239989366 seconds)
2022-03-23 09:33:04 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:33:04 | INFO | train | epoch 004 | loss 10.442 | nll_loss 8.716 | ppl 420.44 | wps 39048.2 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.004 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 393
2022-03-23 09:33:05 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:33:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:33:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:33:29 | INFO | train_inner | epoch 005:     77 / 157 loss=10.294, nll_loss=8.465, ppl=353.37, wps=29578.6, ups=1.21, wpb=24523.4, bsz=945.3, num_updates=700, lr=8.75e-05, gnorm=1.235, loss_scale=4, train_wall=31, gb_free=15.1, wall=418
2022-03-23 09:33:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:33:58 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the world in the world.
2022-03-23 09:33:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:34:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world of the world.
2022-03-23 09:34:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:34:07 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be to be a lot of the same of the world.
2022-03-23 09:34:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:34:12 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world, there's a lot of the world, and there's a lot of the world, and there's a lot of the world.
2022-03-23 09:34:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:34:17 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to do it's a lot of the world, and we're going to do it's going to be a lot of the world and we're going to do it's not not not not going to do it in the world
2022-03-23 09:34:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:34:23 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world of the world, and in the world in the world, and in the world, and the world in the world in the world, and the world in the world in the world, and in the world in the world in the world, and the world
2022-03-23 09:34:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:34:29 | INFO | fairseq.tasks.translation | example hypothesis: but if they're not to be to be a lot, but they're a lot of the world, but they're going to go to be a lot of the world, but they're to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be a lot
2022-03-23 09:34:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:34:35 | INFO | fairseq.tasks.translation | example hypothesis: and if we're a lot of the world, we have to be a lot of the world, and we can see the world, and we have to be a lot of the world, and we have to be a lot of the world, and we have to be a lot of the world, and we have to be the world to be the world to be the world, and we have to be a lot of the world, and we have to be the world
2022-03-23 09:34:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:34:43 | INFO | fairseq.tasks.translation | example hypothesis: so, "this is," it's a lot, "" it's a lot, "it's a lot," it's a lot, "it's a lot," it's a lot, "" "" it's a lot, "it's a lot," it's a lot, "" it's a lot, "it's a lot," "it's a lot," it's a lot, "it's a lot," "" "it's a lot," "" it's a lot, "" it's a lot, "" it's a lot, "" "" it's a lot, "" it's a lot, "it's a lot," "it's a lot," "it's a lot," "it's a lot," "it's a lot," "" "" ""
2022-03-23 09:34:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:34:45 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're a lot, we're going to be to be to be a lot of the world, and we have to be a lot, in the world, and we have to be a lot, in the world, and we have to be a lot, and we have to be a lot, in the world, in the world, we have to be a lot, in the world, in the world, in the world, and we have to be a lot, in the world, and we have to be a lot, in the world, in the world, and we have to be a lot of the world, we have to be a lot, in the world, in the world, we have to be to be to be a lot, in the world, and we have to be a lot of the world, we have to be a lot of the world, and we have to be to be a lot, in the world, in the world, in the world, we have to be to be a lot, in the world
2022-03-23 09:34:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:34:45 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.989 | nll_loss 7.832 | ppl 227.89 | bleu 1.18 | wps 3450.2 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.18
2022-03-23 09:34:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 09:34:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:34:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:34:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.18) (writing took 1.6870296169945505 seconds)
2022-03-23 09:34:47 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:34:47 | INFO | train | epoch 005 | loss 10.184 | nll_loss 8.277 | ppl 310.11 | wps 38349.2 | ups 1.52 | wpb 25182.3 | bsz 1008.1 | num_updates 780 | lr 9.75e-05 | gnorm 1.126 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 495
2022-03-23 09:34:47 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:34:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:34:54 | INFO | train_inner | epoch 006:     20 / 157 loss=10.113, nll_loss=8.156, ppl=285.31, wps=30076, ups=1.18, wpb=25435.1, bsz=1018.2, num_updates=800, lr=0.0001, gnorm=1.061, loss_scale=4, train_wall=31, gb_free=12.6, wall=502
2022-03-23 09:35:25 | INFO | train_inner | epoch 006:    120 / 157 loss=9.971, nll_loss=7.911, ppl=240.73, wps=80489.5, ups=3.18, wpb=25302.4, bsz=1024.5, num_updates=900, lr=0.0001125, gnorm=0.996, loss_scale=4, train_wall=31, gb_free=14.1, wall=534
2022-03-23 09:35:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:35:40 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 09:35:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:35:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the world.
2022-03-23 09:35:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:35:49 | INFO | fairseq.tasks.translation | example hypothesis: we're going to have to be a new lot of the world.
2022-03-23 09:35:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:35:53 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world, and there's a lot of the world.
2022-03-23 09:35:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:35:59 | INFO | fairseq.tasks.translation | example hypothesis: and it's not that we're going to do that we're going to do that we're going to do that we're going to do it's going to do it's going to do it's going to do it's going to do it
2022-03-23 09:35:59 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:36:04 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of people in the world, and in the world, and in the world, and in the world, and in the world, and in the world, in the world, and the world, in the world, and the world, and the world, and the world
2022-03-23 09:36:04 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:36:10 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to see, but they're going to be a lot of the world, but they're going to be a lot of the world, but they're going to be not not going to be a lot of the world, but they're going to be a lot of the world, but they're going to be a lot of the world
2022-03-23 09:36:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:36:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see that we're going to see that we can see the world, and then we can see the world, and then we can see that we can see the world, and then we can see the world, and then we can see the world, and then we can see the world, and then we can see that we can see that we can see the world, and then we can see that we can see that we can see the world,
2022-03-23 09:36:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:36:24 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "you know," you know, "you know," it's going to say, "it's going to say," it's going to say, "" you know, "you know," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "" "" "" "" "" "" "" "" "" "" and "" "" "" "" "" "" "and" "" "" "" and "" "" "" "" you know, "you know," you know, "it's going to say," you know, "it's going to say," it's going to say, "it's going to say," you know, "it's a"
2022-03-23 09:36:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:36:26 | INFO | fairseq.tasks.translation | example hypothesis: so, if you think that we're going to be a lot of a lot of the world that we're going to see that we're going to see that we're going to be a lot of a lot of a lot of a lot of the world, but we're going to do that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to be a lot of the world that we're going to see that we're going to be a lot of a lot of the world that we're going to do that we're going to see that we're going to see that we're going to see that we're going to see that we're going to be a lot of the world, and then that we're going to be a lot of the world, and then that we're going to do that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that
2022-03-23 09:36:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:36:26 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.787 | nll_loss 7.418 | ppl 170.98 | bleu 1.62 | wps 3540 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.62
2022-03-23 09:36:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 09:36:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:36:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:36:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.62) (writing took 1.68352406899794 seconds)
2022-03-23 09:36:28 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:36:28 | INFO | train | epoch 006 | loss 9.964 | nll_loss 7.9 | ppl 238.9 | wps 39035.7 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.049 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 597
2022-03-23 09:36:28 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:36:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:36:48 | INFO | train_inner | epoch 007:     63 / 157 loss=9.841, nll_loss=7.69, ppl=206.5, wps=30221.6, ups=1.2, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.012, loss_scale=4, train_wall=31, gb_free=14.9, wall=617
2022-03-23 09:37:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:37:21 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see this in the world.
2022-03-23 09:37:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:37:26 | INFO | fairseq.tasks.translation | example hypothesis: this is the first thing that the most of the most of the most of the most of the most of the most thing.
2022-03-23 09:37:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:37:31 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be able to be able to be able to be able to be able to be able to be new new new new new new new new new.
2022-03-23 09:37:31 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:37:36 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world, and there's a lot, and there's going to be, and there's going to be, and there's going to be going to be a lot.
2022-03-23 09:37:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:37:41 | INFO | fairseq.tasks.translation | example hypothesis: it's it's not to be a lot of the world, and it's going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do
2022-03-23 09:37:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:37:46 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in fact, in the world, in the world, in the world, in the world, in the world, in the world, and it's the world.
2022-03-23 09:37:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:37:51 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to see, you're going to see, but they're going to see, but they're going to be a lot of them, but they're going to be a lot of them, but they're going to be a lot of them, but they're going to be a lot of them.
2022-03-23 09:37:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:37:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take a lot of the world, and we can see that we can see that we can see that we can see, we're going to be a lot of the world.
2022-03-23 09:37:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:38:03 | INFO | fairseq.tasks.translation | example hypothesis: and then, "you know," we're going to say, "we're going to say," "you're going to say," you're going to say, "you're going to say," "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," "" "" "" you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you know," "you're going to say," you know, "you know," you're going to say, "you're going to say," you're going to say, "you're going to say," "
2022-03-23 09:38:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:38:06 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to get a lot of the world, we're going to get a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to be a lot of the world, and then we're going to be able to see that we're going to be able to be able to be able to see that we're going to see that we're going to be a lot of the world.
2022-03-23 09:38:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:38:06 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.633 | nll_loss 7.139 | ppl 140.96 | bleu 2 | wps 3681.8 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2
2022-03-23 09:38:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 09:38:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:38:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:38:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.0) (writing took 1.6865336689952528 seconds)
2022-03-23 09:38:07 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:38:07 | INFO | train | epoch 007 | loss 9.777 | nll_loss 7.581 | ppl 191.46 | wps 39718.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 0.963 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 696
2022-03-23 09:38:08 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:38:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:38:10 | INFO | train_inner | epoch 008:      6 / 157 loss=9.729, nll_loss=7.5, ppl=181.07, wps=30689, ups=1.23, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=0.92, loss_scale=4, train_wall=31, gb_free=14.4, wall=698
2022-03-23 09:38:41 | INFO | train_inner | epoch 008:    106 / 157 loss=9.595, nll_loss=7.273, ppl=154.64, wps=80626.4, ups=3.2, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=0.941, loss_scale=4, train_wall=31, gb_free=14.7, wall=730
2022-03-23 09:38:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:39:01 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the middle of the end.
2022-03-23 09:39:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:39:06 | INFO | fairseq.tasks.translation | example hypothesis: that's the most idea of the most idea of the most idea of the most idea of the most idea of the most thing.
2022-03-23 09:39:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:39:11 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 09:39:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:39:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's a lot of example, and there's a lot of life, and it's a lot of life, and it's going to be going to be going to be going
2022-03-23 09:39:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:39:22 | INFO | fairseq.tasks.translation | example hypothesis: it's not not that we're going to do that we're going to do it, and we're going to do it, and we're going to do it, and we're going to do that we're going to do it's not
2022-03-23 09:39:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:39:28 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the world, in the world, in the most people who are the most people in the people in the people, and the people in the most people who are the people in the most people in the most people in the people in the people, and the people in the
2022-03-23 09:39:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:39:33 | INFO | fairseq.tasks.translation | example hypothesis: some are some of some of some of these things, but they're going to get a lot, but but they're going to get a lot of course, but they're going to get the same time, but it, but but they're going to get the same time, but it, but they're going to be a lot of them, but it
2022-03-23 09:39:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:39:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the brain, we can see that we can see that we can see that we can see that we can see a lot of the world, and then we can see that we can see that we can see a lot of the brain, and then we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see a lot of all can see that
2022-03-23 09:39:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:39:47 | INFO | fairseq.tasks.translation | example hypothesis: one: one: it's one: "it's one of the first time," "it's a lot of the first time," you know, "you know," you know, "you know," it's a lot of the first time, "you know," it, "you know," you know, "it's going to say," you know, "it's a lot of you know," it's a lot of the first time, "it," it's a lot of the first time, "you know," you know, "it's a lot of the first first time," it's a lot of you know, "it's a lot of you know," you know, "you know," you know, "you know," it's a lot of the first time, "it's going to say," "
2022-03-23 09:39:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:39:50 | INFO | fairseq.tasks.translation | example hypothesis: now, if we're going to be a lot of the world, we're going to see that we're going to see that we're going to be a lot of the world, we're going to see that we're going to be a lot of the world, and then we're going to see that we're going to be a lot of the world that we're going to see that we're going to see that we're going to see that we're going to have to see that we're going to be a lot of the world, that we're going to be able to be a lot of the world that we're going to be a lot of the world that we're going to be a lot of the world, we're going to be a lot of the world, and then that we're going to have to be able to be able to be a lot of the world, that we're going to be able to see that we're going to have to be able to be able to be a lot of the world, and then have to be
2022-03-23 09:39:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:39:50 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.463 | nll_loss 6.828 | ppl 113.64 | bleu 2.63 | wps 3365.4 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 2.63
2022-03-23 09:39:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 09:39:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:39:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:39:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 2.63) (writing took 1.693506804003846 seconds)
2022-03-23 09:39:51 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:39:51 | INFO | train | epoch 008 | loss 9.62 | nll_loss 7.314 | ppl 159.11 | wps 38029.8 | ups 1.51 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 0.92 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 800
2022-03-23 09:39:52 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:39:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:40:07 | INFO | train_inner | epoch 009:     49 / 157 loss=9.566, nll_loss=7.223, ppl=149.4, wps=29739.3, ups=1.16, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=0.9, loss_scale=4, train_wall=31, gb_free=14.9, wall=816
2022-03-23 09:40:38 | INFO | train_inner | epoch 009:    149 / 157 loss=9.46, nll_loss=7.043, ppl=131.89, wps=79727.5, ups=3.21, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=0.852, loss_scale=4, train_wall=31, gb_free=14.3, wall=847
2022-03-23 09:40:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:40:45 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 09:40:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:40:49 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most most most most of the most most most most of the most most most most most of
2022-03-23 09:40:49 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:40:53 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new york are two two two of new york.
2022-03-23 09:40:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:40:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an example.
2022-03-23 09:40:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:41:01 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that we're going to see what we're going to do.
2022-03-23 09:41:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:41:06 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, how people like people in the people who are in the most people who are in the people, and the most people who are in the most people who are in the most people in the most people in the most people.
2022-03-23 09:41:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:41:11 | INFO | fairseq.tasks.translation | example hypothesis: first, are some of some of them, but if you can see, there are the same time, but if you can see, but if you can't see, but there are the right, if you can see, but if you can't see, but it's the same, but it's the same time.
2022-03-23 09:41:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:41:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see the brain that we can see that we can see, and then we can see that we can see that we can see the brain can see, and then we can see that we can see the brain can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to the
2022-03-23 09:41:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:41:24 | INFO | fairseq.tasks.translation | example hypothesis: yeah: there's a lot of people, "and if we said," well, "well," you know, "well," well, "you know," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," you know, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," you know, "well," well, "well," well, "well," well, "well," well, "you know," well, "well," well, "you know," well, "well," well, "well," well, "well,"
2022-03-23 09:41:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:41:26 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, there's a lot of course, and if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 09:41:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:41:26 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.265 | nll_loss 6.5 | ppl 90.49 | bleu 5 | wps 3969.2 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 5
2022-03-23 09:41:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 09:41:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:41:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:41:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 5.0) (writing took 1.7065909660013858 seconds)
2022-03-23 09:41:28 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:41:28 | INFO | train | epoch 009 | loss 9.463 | nll_loss 7.048 | ppl 132.36 | wps 40948.2 | ups 1.63 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 0.877 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 896
2022-03-23 09:41:28 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:41:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:41:57 | INFO | train_inner | epoch 010:     92 / 157 loss=9.341, nll_loss=6.842, ppl=114.7, wps=31793.7, ups=1.27, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=0.824, loss_scale=4, train_wall=31, gb_free=14.3, wall=926
2022-03-23 09:42:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:42:21 | INFO | fairseq.tasks.translation | example hypothesis: we did that in the pp of the way.
2022-03-23 09:42:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:42:25 | INFO | fairseq.tasks.translation | example hypothesis: and that's the right thing, most of most of most of most of most of the most most.
2022-03-23 09:42:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:42:29 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be going to be new york.
2022-03-23 09:42:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:42:33 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, where there are where you're going to go, where you're going to go.
2022-03-23 09:42:33 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:42:37 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're just just just just just a few few of his brain, and what's going to do.
2022-03-23 09:42:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:42:41 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, as the most people who are used for the people for the number of the people, and that's a lot of people are a lot of people.
2022-03-23 09:42:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:42:46 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of them are going to be able, but if you're not able to get the energy, but if you're not able to do it.
2022-03-23 09:42:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:42:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information, we can see that, we can get a lot of the brain, and then we can get a lot of the brain, and all of the brain, and all of the brain, and all of the brain, and all of the brain, and all of the brain, and all of the brain, and all of the brain, and all of the brain, and that is that is that is a kind of the
2022-03-23 09:42:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:42:57 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the first thing, and it's very interesting for me for me, for me, and then it's the first time for me that we're going to go to me, and then you know, for me, the first time.
2022-03-23 09:42:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:42:59 | INFO | fairseq.tasks.translation | example hypothesis: and then, it's still still still still a few years, and when we're going to get a lot of the world, when we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able,
2022-03-23 09:42:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:42:59 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.06 | nll_loss 6.16 | ppl 71.53 | bleu 6.97 | wps 4338.6 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 6.97
2022-03-23 09:42:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:42:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:43:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:43:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 6.97) (writing took 1.7059142790094484 seconds)
2022-03-23 09:43:01 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:43:01 | INFO | train | epoch 010 | loss 9.284 | nll_loss 6.747 | ppl 107.43 | wps 42478.8 | ups 1.69 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 0.847 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 989
2022-03-23 09:43:01 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:43:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:43:12 | INFO | train_inner | epoch 011:     35 / 157 loss=9.231, nll_loss=6.659, ppl=101.07, wps=33219.9, ups=1.34, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=0.886, loss_scale=4, train_wall=30, gb_free=13.4, wall=1001
2022-03-23 09:43:44 | INFO | train_inner | epoch 011:    135 / 157 loss=9.097, nll_loss=6.433, ppl=86.42, wps=81105.9, ups=3.17, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=0.857, loss_scale=4, train_wall=31, gb_free=13.3, wall=1032
2022-03-23 09:43:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:43:54 | INFO | fairseq.tasks.translation | example hypothesis: we had these ppppin the middle of the top.
2022-03-23 09:43:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:43:58 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the ha, most of most of most of the most most here here.
2022-03-23 09:43:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:44:03 | INFO | fairseq.tasks.translation | example hypothesis: they're going to get new new new new new new new new new cells that are going to be able.
2022-03-23 09:44:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:44:06 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a chinese food, where you're going to go with the ppppppppppppppple, and it's going to be going.
2022-03-23 09:44:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:44:11 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just just just a few of his head, and what's going on.
2022-03-23 09:44:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:44:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamase people like the number of the number of the number, and the number of the number of the number of the number.
2022-03-23 09:44:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:44:19 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you are some of the water, but you don't have the energy, but if you don't need the energy of the energy, you need the energy.
2022-03-23 09:44:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:44:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use this information from a structure, we can use the structure of the information, and all of the structure of the information.
2022-03-23 09:44:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:44:27 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons, and it's interesting to make me that i'm going to say, "you know," well, "you know," you know, "you know," you know, "you know," you know, "you know," well, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "well," you know, "you know," you know, "well," you know, "you know," you know, "you know," you know, "well," you know, "well," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "
2022-03-23 09:44:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:44:29 | INFO | fairseq.tasks.translation | example hypothesis: well, it's still still the mother, and the work of our work, if we had to be a global system that we had to be able to be able to be able to be able to be able to be able to the world.
2022-03-23 09:44:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:44:29 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.899 | nll_loss 5.839 | ppl 57.26 | bleu 9.4 | wps 4711.5 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 9.4
2022-03-23 09:44:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:44:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:44:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:44:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 9.4) (writing took 1.7110641019971808 seconds)
2022-03-23 09:44:31 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:44:31 | INFO | train | epoch 011 | loss 9.13 | nll_loss 6.489 | ppl 89.82 | wps 43804 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.848 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1079
2022-03-23 09:44:31 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:44:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:44:56 | INFO | train_inner | epoch 012:     78 / 157 loss=9.023, nll_loss=6.311, ppl=79.39, wps=34666.1, ups=1.39, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=0.805, loss_scale=4, train_wall=31, gb_free=14, wall=1104
2022-03-23 09:45:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:45:24 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppm in the middle.
2022-03-23 09:45:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:45:28 | INFO | fairseq.tasks.translation | example hypothesis: and that's the point of the ha, most of most of most of most of most of the most.
2022-03-23 09:45:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:45:32 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be able to be able to make two new ways that are going to be able to be able.
2022-03-23 09:45:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:45:36 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a chinese chinese chinese chinese chinese food, where they're going to get with it.
2022-03-23 09:45:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:45:41 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just just just a few of his head on his head, and what's going on.
2022-03-23 09:45:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:45:45 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamace of people like the most people, the number of the number of animals, and this is a number of animals in the most important way.
2022-03-23 09:45:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:45:49 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the rows in the brain, but it doesn't have to use the energy, if they don't need your energy, and if they need your energy, they need to need your energy, and they need to need the energy, and they need the energy.
2022-03-23 09:45:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:45:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we're going to use this structure, we can start with a kind of design that we can start with the kind of information, and that's all the structure of the structure of the structure, and all the structure of the structure of the structure, and all the information that's all the information that's all the information.
2022-03-23 09:45:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:45:59 | INFO | fairseq.tasks.translation | example hypothesis: again, one of the reasons that it's interesting, and it's interesting for me to be able to be able to be able to say that "well," well, "if we've got to say," well, "well," you know, "you know," well, "well," you know, "you're going to say," well, "well," you know, "you know," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," you know, "you know," we've got you're going to say, "well," well, "well," well, "well," well, "you know," well, "well," you know, "you've got
2022-03-23 09:45:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:46:01 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still still still the mother, and the big part of our work that we had to see that we had to be a lot of the world that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if
2022-03-23 09:46:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:46:01 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.706 | nll_loss 5.466 | ppl 44.21 | bleu 10.67 | wps 4446.4 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 10.67
2022-03-23 09:46:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:46:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:46:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:46:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 10.67) (writing took 1.8128962560003856 seconds)
2022-03-23 09:46:03 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:46:03 | INFO | train | epoch 012 | loss 8.941 | nll_loss 6.173 | ppl 72.18 | wps 42935.7 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.802 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1171
2022-03-23 09:46:03 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:46:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:46:10 | INFO | train_inner | epoch 013:     21 / 157 loss=8.86, nll_loss=6.039, ppl=65.77, wps=33948.9, ups=1.35, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=0.841, loss_scale=4, train_wall=30, gb_free=13.9, wall=1178
2022-03-23 09:46:41 | INFO | train_inner | epoch 013:    121 / 157 loss=8.789, nll_loss=5.915, ppl=60.36, wps=80323.8, ups=3.18, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=0.787, loss_scale=4, train_wall=31, gb_free=13.6, wall=1210
2022-03-23 09:46:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:46:56 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppon in the clinic.
2022-03-23 09:46:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:47:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of a doha, most of most of you know here.
2022-03-23 09:47:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:47:04 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be able to create new ways that are going to be going to be able to be able.
2022-03-23 09:47:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:47:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese food, where they're going to be able to be depat.
2022-03-23 09:47:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:47:12 | INFO | fairseq.tasks.translation | example hypothesis: it's pretty clear that we're not just just going to understand a few electrodes on his head, and what's going on on.
2022-03-23 09:47:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:47:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamase people like the responsibility for the number of animals, and this is a number of animals that has become a very important, and that has been done.
2022-03-23 09:47:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:47:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some file of the color, but it's not going to be able to go to the energy, if you need your energy, the energy and the energy.
2022-03-23 09:47:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:47:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information that we can start to be able to start with a new way that we can start with a big structure of the structure of the structure of the structure, and that's all the structure of the information.
2022-03-23 09:47:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:47:28 | INFO | fairseq.tasks.translation | example hypothesis: hth: one of the reasons that it's interesting for me, and i'm going to be able to be here, "yeah," well, "you know," you know, "the best time," if you're going to say, "well," you're going to say, "well," you're going to say, "you're going to say," well, "you know," you've got a long time to say, "well," well, "you're going to say," you're going to say, "well," you're going to say, "well," well, "well," well, "well," well, "well," you have a long time, "you're going to say," you have a long time, "you're going to say," you're going to be a long time
2022-03-23 09:47:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:47:30 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still the mother of the mother, and the big work of our work, we've had to see that we had to be a different system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:47:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:47:30 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.556 | nll_loss 5.174 | ppl 36.09 | bleu 12.78 | wps 4834.4 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 12.78
2022-03-23 09:47:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:47:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:47:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:47:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 12.78) (writing took 1.7824878040119074 seconds)
2022-03-23 09:47:32 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:47:32 | INFO | train | epoch 013 | loss 8.772 | nll_loss 5.89 | ppl 59.28 | wps 44274.6 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.795 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 1261
2022-03-23 09:47:33 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:47:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:47:53 | INFO | train_inner | epoch 014:     64 / 157 loss=8.677, nll_loss=5.73, ppl=53.09, wps=34868.3, ups=1.4, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=0.757, loss_scale=4, train_wall=31, gb_free=14, wall=1281
2022-03-23 09:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:48:26 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppills in the clinic.
2022-03-23 09:48:26 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:48:30 | INFO | fairseq.tasks.translation | example hypothesis: that's the line of the doha, which is the most most most of the most important thing here.
2022-03-23 09:48:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:48:34 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new features that are going to create two new ways.
2022-03-23 09:48:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:48:38 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese chinese food, where they're happy, and they're going to be able to be able.
2022-03-23 09:48:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:48:42 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just have a couple of electrodes on his head on his head, and all of his mind.
2022-03-23 09:48:42 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:48:46 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamaking people like the responsibility of the responsibility, for the number of animals, and the number of animals has become a group.
2022-03-23 09:48:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:48:50 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic of the lines in the lines, but in the field, if you don't have the energy, and the energy need to get your energy.
2022-03-23 09:48:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:48:53 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can actually start with a traditional view that are able to start with a huge structure of the information, and the whole structure of the information.
2022-03-23 09:48:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:48:57 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to do with tedtedtedwomen, "well, when we said," we've been talking to you're talking about the truth. "
2022-03-23 09:48:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:49:00 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need to be the mother's mother, and the big design part of the work that we had to see that we had to have to be able to solve the same system, and that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use a new system with a new system.
2022-03-23 09:49:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:49:00 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.47 | nll_loss 4.992 | ppl 31.83 | bleu 14.81 | wps 4825 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 14.81
2022-03-23 09:49:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:49:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:49:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:49:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 14.81) (writing took 1.8321404339949368 seconds)
2022-03-23 09:49:01 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:49:01 | INFO | train | epoch 014 | loss 8.589 | nll_loss 5.583 | ppl 47.93 | wps 44203.4 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.743 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1350
2022-03-23 09:49:02 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:49:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:49:04 | INFO | train_inner | epoch 015:      7 / 157 loss=8.522, nll_loss=5.471, ppl=44.35, wps=35787.8, ups=1.4, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=0.705, loss_scale=4, train_wall=31, gb_free=13.9, wall=1353
2022-03-23 09:49:36 | INFO | train_inner | epoch 015:    107 / 157 loss=8.443, nll_loss=5.338, ppl=40.45, wps=80376.8, ups=3.2, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=0.762, loss_scale=4, train_wall=31, gb_free=13.9, wall=1384
2022-03-23 09:49:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:49:55 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppills in the clinics.
2022-03-23 09:49:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:49:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the superline of doha, most of the most of you know here.
2022-03-23 09:49:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:50:03 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to create two new cooperation.
2022-03-23 09:50:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:50:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese chinese chinese food, where you're going to do with and pie.
2022-03-23 09:50:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:50:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a couple of electrodes on his head, and what all of his mind are on the mind.
2022-03-23 09:50:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:50:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamating people like the responsibility of the responsibility, which grew up the number of animals, and this is a number of the animals.
2022-03-23 09:50:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:50:20 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of these are some of the magic lines in the field, but it doesn't take it, but if you don't need your energy energy, you need your energy, you need your energy, and you need your energy.
2022-03-23 09:50:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:50:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that we can start able to start able to start with a traditional face of the shape of the shape, and the information is the whole structure of the structure of the structure.
2022-03-23 09:50:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:50:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me for tedtedwomen -- that's the best thing that you're going to say, "well, it's the best thing that you're going to say," the best revolution, "and then," if you're working with you've got a long time. "
2022-03-23 09:50:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:50:31 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the mother of the invention of the invention, and a part of the work that we've had to solve the airplane on our airplane, we had to solve a unique part of the problem, which is that if we had to solve it, it was a unique system, if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if you're able to use a unique system, if you're able to use the same, or a different, if you're going to use the power of a different system, if you're going to see that you're going to solve the power of a different, if you're going to solve the power of a different system, if you're going to solve the united states, if you're going to solve the united states, if you're going to solve the united states, if you're going to solve, you're going to be able to be able to be able to
2022-03-23 09:50:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:50:31 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.256 | nll_loss 4.638 | ppl 24.9 | bleu 16.13 | wps 4574.4 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 16.13
2022-03-23 09:50:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:50:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:50:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:50:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 16.13) (writing took 1.7260958830011077 seconds)
2022-03-23 09:50:33 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:50:33 | INFO | train | epoch 015 | loss 8.455 | nll_loss 5.356 | ppl 40.94 | wps 43318.3 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.735 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1441
2022-03-23 09:50:33 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:50:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:50:49 | INFO | train_inner | epoch 016:     50 / 157 loss=8.441, nll_loss=5.326, ppl=40.12, wps=34638.1, ups=1.36, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=0.694, loss_scale=4, train_wall=31, gb_free=14.3, wall=1458
2022-03-23 09:51:20 | INFO | train_inner | epoch 016:    150 / 157 loss=8.254, nll_loss=5.017, ppl=32.39, wps=79641.8, ups=3.23, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.659, loss_scale=4, train_wall=31, gb_free=14.5, wall=1488
2022-03-23 09:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:51:26 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 09:51:26 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:51:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know.
2022-03-23 09:51:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:51:33 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new logic.
2022-03-23 09:51:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:51:37 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french, where happy legs are going to be and salt.
2022-03-23 09:51:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:51:40 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand what all its thoughts are on the mind.
2022-03-23 09:51:40 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:51:44 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility of the life, and the number of animals has become a number of animals.
2022-03-23 09:51:44 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:51:48 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic lines are in the field, but it doesn't be able to move if you don't need it, and if you don't need your energy, it doesn't need your energy, and you need your energy.
2022-03-23 09:51:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:51:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection.
2022-03-23 09:51:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:51:56 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons, and it's interesting for me to be here at tedth, "well, it's the best time," well, "oh," well, "well, it was the best thing that somebody said," if we're going to be the best thing that we're going to be talking about, "and then we've been talking about," well, "well," well, "well," well, "well," well, "well," if we've been working with you know, "
2022-03-23 09:51:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:51:58 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention of the invention, and a big design that we have on our airplane was a little bit of the airplane that we had to solve was a unique result that we had to solve a unique result that we had to solve it.
2022-03-23 09:51:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:51:58 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.219 | nll_loss 4.593 | ppl 24.13 | bleu 13.44 | wps 5080.6 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 16.13
2022-03-23 09:51:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:51:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 09:51:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 09:51:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 13.44) (writing took 0.7555790559999878 seconds)
2022-03-23 09:51:59 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:51:59 | INFO | train | epoch 016 | loss 8.296 | nll_loss 5.088 | ppl 34.01 | wps 45654.5 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.689 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1528
2022-03-23 09:51:59 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:51:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:52:29 | INFO | train_inner | epoch 017:     93 / 157 loss=8.199, nll_loss=4.924, ppl=30.35, wps=36601, ups=1.45, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=0.686, loss_scale=4, train_wall=31, gb_free=14.9, wall=1558
2022-03-23 09:52:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:52:53 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppills in the clinic clinic clinic.
2022-03-23 09:52:53 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:52:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably the most of you know.
2022-03-23 09:52:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:53:01 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new lolocks that are going to be able to create two new locks.
2022-03-23 09:53:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:53:06 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food food, where happy legs are, and they're going to be defemining with pace.
2022-03-23 09:53:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:53:10 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just get a few electrodes on his head and understand what all his thoughts are on the top of your mind.
2022-03-23 09:53:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:53:14 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamaking like the responsibility for the life, the number of animals grew up, and this is a number of conservation for the world.
2022-03-23 09:53:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:53:18 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic magnetic lines, but the sulungs are not going to move, if you need to move your energy, and you need a couple of energy, and you need a few bloop of the power of magic.
2022-03-23 09:53:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:53:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of traditional face, and then we're going to start able to start with the whole shape of the face and the information that all the structure of the structure and the structure, and the structure of the structure, and the structure is going to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 09:53:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:53:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it for me to be at tedwomen, "well, in tedth, when someone said," you know, you know, you know, the best thing that we've been working on the table and you know, "you know," well, you know, you know, you know, you know, you know, you have a long time, you know, you've been working on this time, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you have a long time, you know, you know, you know, you know, you know, "
2022-03-23 09:53:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:53:32 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, the mother's mother still the invention of the invention, and a big part of the design that we have to solve is that we had to solve a unique result of these problems, or if we had to solve it in the ground, it's a unique system that we've got to be connected to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if you're able to see, and see, you're able to be able to see, you're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see, or a specific to see, or a special, and see that you're able to be able to be able to be able
2022-03-23 09:53:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:53:32 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.067 | nll_loss 4.334 | ppl 20.16 | bleu 16.91 | wps 4164.2 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 16.91
2022-03-23 09:53:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 09:53:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:53:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:53:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 16.91) (writing took 1.70970256900182 seconds)
2022-03-23 09:53:34 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:53:34 | INFO | train | epoch 017 | loss 8.193 | nll_loss 4.911 | ppl 30.09 | wps 41510.5 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.695 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1623
2022-03-23 09:53:35 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:53:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:53:46 | INFO | train_inner | epoch 018:     36 / 157 loss=8.146, nll_loss=4.831, ppl=28.46, wps=32665.2, ups=1.29, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.691, loss_scale=4, train_wall=30, gb_free=14.3, wall=1635
2022-03-23 09:54:18 | INFO | train_inner | epoch 018:    136 / 157 loss=8.024, nll_loss=4.634, ppl=24.83, wps=79170.4, ups=3.19, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.606, loss_scale=4, train_wall=31, gb_free=14.1, wall=1666
2022-03-23 09:54:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:54:28 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 09:54:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:54:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of them.
2022-03-23 09:54:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:54:36 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that will create the two new gesticks.
2022-03-23 09:54:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:54:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are being made with salz.
2022-03-23 09:54:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:54:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head, and understand exactly what all his thoughts are on the top.
2022-03-23 09:54:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:54:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammers like the people who grew up for the wild, and this is a number of animals. and this is a foundation of natural conservation.
2022-03-23 09:54:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:54:52 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bars of magnetic field, but the sucks in the interior lines, but the sucks doesn't move when they're moving, if they need their energy, they need their energy, and they need the energy.
2022-03-23 09:54:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:54:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face that can start with the great face of the face of the face, and the shape of the information, and the information that's a structure of the structure.
2022-03-23 09:54:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:55:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it very interesting, for me, "for example, in tedwomen, is that..."
2022-03-23 09:55:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:55:02 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother's invention of the invention, and a big part of the design of the design that we're in our plane, a result of it was a unique result that we had to solve the unique problems that we had to solve it in the ground -- it's all the way to be able to see that if you're able to use the power of a deployment, or to be able to use the power of a deployized, if you're able to use the power of a deployment in the power of a very specific, it in the air, it's actually use to be able to see that if you're able to use the air, it's a very specific, to use the power of a very specific, or an instructive, to be able to be able to see that if you're able to be able to be able to be able to be able to be able to be able to be able to be able to see that if you're able to use the power,
2022-03-23 09:55:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:55:02 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 7.866 | nll_loss 3.977 | ppl 15.75 | bleu 20.87 | wps 4734.8 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.87
2022-03-23 09:55:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 09:55:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:55:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:55:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.87) (writing took 1.7971498440019786 seconds)
2022-03-23 09:55:04 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:55:04 | INFO | train | epoch 018 | loss 8.029 | nll_loss 4.641 | ppl 24.95 | wps 43830.5 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.592 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 1713
2022-03-23 09:55:05 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:55:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:55:30 | INFO | train_inner | epoch 019:     79 / 157 loss=7.953, nll_loss=4.516, ppl=22.88, wps=35432.8, ups=1.38, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.57, loss_scale=4, train_wall=31, gb_free=14, wall=1739
2022-03-23 09:55:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:55:58 | INFO | fairseq.tasks.translation | example hypothesis: we made these wepure in the clinic.
2022-03-23 09:55:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:56:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:56:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:56:05 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks of the two new pigs.
2022-03-23 09:56:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:56:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where happy legs are going to be with salz and ppure.
2022-03-23 09:56:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:56:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand exactly what all his thoughts are on the ground.
2022-03-23 09:56:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:56:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people's responsibility for the wild, the number of the wild animals, and this is a foundation of natural conservation.
2022-03-23 09:56:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:56:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloods of magnetic lines, but the susulal alarm may not move when they need energy, and so the suick of the altitude of magnetic field.
2022-03-23 09:56:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:56:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of the face of the face, and that's the whole information of the information that we use all the information, the information of this reflection, and the information of this reflection, and we can start with a traditional reflection of this reflection, and we can start with a traditional face of this reflection.
2022-03-23 09:56:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:56:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons the high-interesting and measure for me to be here at tedtedwomen, is that...
2022-03-23 09:56:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:56:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of invention, and a big part of the design work that we have to see in our airplane is to solve the unique problems that we had to solve all the problems of the ground -- all the way that we had to be connected to a refugegeous, and to see that if we're going to be able to see the power of the power of the trajecctory of the power of the power of the power of the air, that we can be able to see in the air, or to see, or to see, it's a mechanism, it's a mechanism, or to see that it's a mechanical, or to see that if you can be a mechanical, it's a mechanical transfer to see that it's a mechanical, or to see that it's a mechanical transfer to see that it's all of the power of the air, to the air system that we have to see that we have to see, to be able to
2022-03-23 09:56:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:56:32 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.83 | nll_loss 3.909 | ppl 15.02 | bleu 21.18 | wps 4783.3 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.18
2022-03-23 09:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 09:56:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:56:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:56:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 21.18) (writing took 1.7077190230047563 seconds)
2022-03-23 09:56:34 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:56:34 | INFO | train | epoch 019 | loss 7.902 | nll_loss 4.433 | ppl 21.6 | wps 44155.8 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.585 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1802
2022-03-23 09:56:34 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:56:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:56:41 | INFO | train_inner | epoch 020:     22 / 157 loss=7.846, nll_loss=4.342, ppl=20.28, wps=34848, ups=1.41, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.569, loss_scale=4, train_wall=30, gb_free=14.7, wall=1810
2022-03-23 09:57:13 | INFO | train_inner | epoch 020:    122 / 157 loss=7.79, nll_loss=4.248, ppl=19.01, wps=81451.9, ups=3.15, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.517, loss_scale=4, train_wall=31, gb_free=13.6, wall=1841
2022-03-23 09:57:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:57:28 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:57:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:57:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:57:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:57:36 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that create the two new pigments that are going to be transmitted.
2022-03-23 09:57:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:57:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs with salz and salt bulled.
2022-03-23 09:57:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:57:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just making a couple of electroelectrodes on his head and understand exactly exactly what all its thoughts are on the way that we're in the way.
2022-03-23 09:57:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:57:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wild, the number of animals grew up again, and this is a foundation of natural protection in namibia.
2022-03-23 09:57:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:57:53 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloop of magnetic field in the inside the inner, but the susuicide may not be able to move when they need their energy, and so the suicide disorders.
2022-03-23 09:57:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:57:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face, which is the big constructions of the face and the basic shape of the face, and through that information, which is the whole structure of this reflection, which is the whole structure of the structure of this reflection.
2022-03-23 09:57:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:58:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measure it interesting, for me to be here at tedwomen, is that... "yeah, when someone was the best one said," as somebody said to you, "the men in a table, and if you're going to measure it interesting, and if you're going to measure the truth for you know, the truth is that we've already started to be here at the time,"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 09:58:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:58:05 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother's still the invention of invention, and a big part of design work that we're going to see in our airplane is a result of it that we had to solve the unique problems that were connected to the ground -- everything from a continent, and a big part of the current system that allows us to see that we're going to use to see in the same way, or to see that if you're going to see that it's a constraightforward to be a mechanism, or to see that it's a mechanism, it's a mechanism, it's a mechanism, that it's a mechanism, that it's the same result that we had to see that we had to see that we had to see that it's a mechanism in the same result that it has to be connected to be connected to be connected to be connected to the same output it's a mechanism, or to be connected to be connected to the same result that we had to the same result in the same way that it's
2022-03-23 09:58:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:58:05 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.756 | nll_loss 3.811 | ppl 14.04 | bleu 22.8 | wps 4417.7 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 22.8
2022-03-23 09:58:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 09:58:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:58:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 09:58:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 22.8) (writing took 1.8334881320042768 seconds)
2022-03-23 09:58:06 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:58:06 | INFO | train | epoch 020 | loss 7.785 | nll_loss 4.241 | ppl 18.91 | wps 42575.6 | ups 1.69 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.546 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1895
2022-03-23 09:58:07 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:58:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:58:27 | INFO | train_inner | epoch 021:     65 / 157 loss=7.707, nll_loss=4.115, ppl=17.33, wps=33398.5, ups=1.34, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.566, loss_scale=4, train_wall=30, gb_free=13.9, wall=1916
2022-03-23 09:58:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:59:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:59:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:59:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:59:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:59:08 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks.
2022-03-23 09:59:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:59:11 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs will be served with salz and pace.
2022-03-23 09:59:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:59:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all of his thoughts are on the way.
2022-03-23 09:59:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:59:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteria, people have grown responsibility for the wild animals, and this is a foundation for the natural protection in namibia.
2022-03-23 09:59:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:59:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloose of the magnetic field in the inside the inner, but the superconductor doesn't like that, if you move your energy, and you need the supermovements of the superconductor.
2022-03-23 09:59:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:59:26 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information, which is the whole structure, and we can start with a traditional facial face.
2022-03-23 09:59:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:59:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that you're going to be in a table, and if you're in this truth, "well, you know, you know, you know, you know," in the future, you know, you know, for a long time. "
2022-03-23 09:59:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:59:30 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, the unique problems that were connected to the ground, and a lot of the things that we're going to use in the car, or in the same way, if we're going to use it to be able to put it on the ground, by a variable system that allows us to use it in the aircraft.
2022-03-23 09:59:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:59:30 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.68 | nll_loss 3.71 | ppl 13.09 | bleu 21.5 | wps 5450.9 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 22.8
2022-03-23 09:59:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 09:59:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 09:59:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 09:59:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 21 @ 3292 updates, score 21.5) (writing took 0.771187716993154 seconds)
2022-03-23 09:59:31 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 09:59:31 | INFO | train | epoch 021 | loss 7.698 | nll_loss 4.1 | ppl 17.15 | wps 46795.1 | ups 1.86 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.547 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 1979
2022-03-23 09:59:31 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 09:59:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:59:34 | INFO | train_inner | epoch 022:      8 / 157 loss=7.713, nll_loss=4.124, ppl=17.43, wps=37254.8, ups=1.5, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.562, loss_scale=4, train_wall=31, gb_free=13.9, wall=1982
2022-03-23 10:00:05 | INFO | train_inner | epoch 022:    108 / 157 loss=7.662, nll_loss=4.042, ppl=16.47, wps=78961.7, ups=3.2, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.567, loss_scale=4, train_wall=31, gb_free=13.8, wall=2014
2022-03-23 10:00:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:00:24 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:00:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:00:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:00:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:00:32 | INFO | fairseq.tasks.translation | example hypothesis: stars are created new golden locks that are going to translate two new pigs.
2022-03-23 10:00:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:00:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food where happy legs are served with salz and puppets.
2022-03-23 10:00:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:00:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 10:00:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:00:43 | INFO | fairseq.tasks.translation | example hypothesis: and this is a foundation of conservation in namibia.
2022-03-23 10:00:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:00:47 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic field lines are starting inside the inner, but the susuperconductor doesn't like if they're moving, because their movements need energy.
2022-03-23 10:00:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:00:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which is the big constructions of the face and the basic shape of the face.
2022-03-23 10:00:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:00:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured for me here at tedwomen, is that... "well, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know."
2022-03-23 10:00:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:00:56 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we're going to see in our airplane, was a result of it.
2022-03-23 10:00:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:00:56 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.613 | nll_loss 3.547 | ppl 11.69 | bleu 23.25 | wps 5071.7 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 23.25
2022-03-23 10:00:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 10:00:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:00:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:00:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 22 @ 3449 updates, score 23.25) (writing took 1.8341168869956164 seconds)
2022-03-23 10:00:58 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 10:00:58 | INFO | train | epoch 022 | loss 7.639 | nll_loss 4.004 | ppl 16.05 | wps 45219.4 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.541 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 2067
2022-03-23 10:00:59 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 10:00:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:01:15 | INFO | train_inner | epoch 023:     51 / 157 loss=7.591, nll_loss=3.926, ppl=15.2, wps=36630.4, ups=1.44, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.455, loss_scale=4, train_wall=31, gb_free=13.8, wall=2083
2022-03-23 10:01:46 | INFO | train_inner | epoch 023:    151 / 157 loss=7.507, nll_loss=3.796, ppl=13.89, wps=81322.2, ups=3.2, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.5, loss_scale=4, train_wall=31, gb_free=13.8, wall=2115
2022-03-23 10:01:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:01:51 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheet in the clinic.
2022-03-23 10:01:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:01:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:01:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:01:59 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that create the two new pigs.
2022-03-23 10:01:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:02:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where happy legs are served with salz and psuitcase.
2022-03-23 10:02:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:02:07 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the line.
2022-03-23 10:02:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:02:11 | INFO | fairseq.tasks.translation | example hypothesis: and this is a basis of conservation in the wild, the number of wild animals grew again. and this is a foundation of natural protection in namibia.
2022-03-23 10:02:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:02:15 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field are starting in the inside, but the superconductor doesn't like the superconductor, if they're moving, because their movements need energy, and so the supermovements of magnetic field.
2022-03-23 10:02:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:02:20 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial can start with a traditional face that gives the big constraints of the face and the basic shape of the face, and through the basic information that gives the whole ports of this reflection, the entire portion of this reflection, the whole piece of reflection.
2022-03-23 10:02:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:25 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that... well,...
2022-03-23 10:02:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:02:27 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a great part of design work that we're on our plane at the stest, a result that we had to solve the unique problems that we had to solve the unique problems that were connected to the ground -- all the way it's connected to a continent -- and a big part of the design work that we're going to use in our aircraft, which we're going to use in our aircraft, to use in the refrigergergergering in the refrigeration of the refrightening in our aircraft, to use in the harm system that we're going to be able to be able to use in our aircraft, to use in the united states, to use in the united states, to use in the refrigergergergergergergerman, to use in the united states.
2022-03-23 10:02:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:02:27 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.573 | nll_loss 3.495 | ppl 11.27 | bleu 25.57 | wps 4598.3 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 25.57
2022-03-23 10:02:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 10:02:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:02:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:02:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 25.57) (writing took 1.8533835379930679 seconds)
2022-03-23 10:02:29 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 10:02:29 | INFO | train | epoch 023 | loss 7.536 | nll_loss 3.84 | ppl 14.32 | wps 43547.8 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.481 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2157
2022-03-23 10:02:29 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 10:02:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:02:59 | INFO | train_inner | epoch 024:     94 / 157 loss=7.489, nll_loss=3.765, ppl=13.6, wps=34187.2, ups=1.37, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.479, loss_scale=4, train_wall=31, gb_free=13.8, wall=2187
2022-03-23 10:03:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:23 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 10:03:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:03:26 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:03:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:03:30 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that create two new pigs.
2022-03-23 10:03:30 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:03:34 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are served with salz and psuitcase.
2022-03-23 10:03:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:03:38 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:03:38 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:03:42 | INFO | fairseq.tasks.translation | example hypothesis: and in the mapping of the people's responsibility for the wild, the number of wild animals grew again, and this is a foundation for conservation in namibia.
2022-03-23 10:03:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:03:46 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bars of magnetic field are caught in the inside, but the superconductor doesn't like it, if you move your energy, and so the superconducting disorders.
2022-03-23 10:03:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:03:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big configurations of the face and the basic shape, and through the one of the information that pulls all the portion structure and fold.
2022-03-23 10:03:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:03:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that... yeah, it was the best thing that someone said, "turn you into a table and tell you," if the revolution starts to support you. "
2022-03-23 10:03:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:03:56 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of the invention, and a big part of the design work that we're on our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuously variable system to a refrightening system that allows us to be refrightened to a promoting, or a promoting, to a promoting, to a promoting, to a promoting, to the air, to a promoting, or a promoting, to a promoting, to a promoting, to the air, to a promoting, to a promoting, to a promoting, to a promoting, to the air, to the air, to the air, to the same way to the air, to the air, to the air, to the air, to the same way that is either.
2022-03-23 10:03:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:03:56 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.458 | nll_loss 3.3 | ppl 9.85 | bleu 27.36 | wps 4883.2 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.36
2022-03-23 10:03:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:03:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:03:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:03:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 27.36) (writing took 1.7420030100038275 seconds)
2022-03-23 10:03:58 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:03:58 | INFO | train | epoch 024 | loss 7.466 | nll_loss 3.729 | ppl 13.26 | wps 44393.9 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.453 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2246
2022-03-23 10:03:58 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:03:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:04:10 | INFO | train_inner | epoch 025:     37 / 157 loss=7.404, nll_loss=3.631, ppl=12.39, wps=35879.3, ups=1.41, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.425, loss_scale=4, train_wall=31, gb_free=14, wall=2258
2022-03-23 10:04:41 | INFO | train_inner | epoch 025:    137 / 157 loss=7.453, nll_loss=3.711, ppl=13.09, wps=79754.3, ups=3.19, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.48, loss_scale=4, train_wall=31, gb_free=13.9, wall=2290
2022-03-23 10:04:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:04:51 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 10:04:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:04:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:04:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:04:59 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to be able to translate two new pigs.
2022-03-23 10:04:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:05:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where happy legs are served with salz and psuitcase.
2022-03-23 10:05:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:05:06 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:05:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:05:10 | INFO | fairseq.tasks.translation | example hypothesis: and in the mapping of people's responsibility for wildlife, the number of wild animals grew back, and this is a foundation for conservation in namibia.
2022-03-23 10:05:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:05:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines in the inside, but the supersuperconductor may not like moving, because your movements need energy, and so the superconducting disorders.
2022-03-23 10:05:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:05:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial face, which gives the great constructions of the face and the basic shape, and put it through the theft information that pulls the whole porch structure and a fold.
2022-03-23 10:05:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it high-interesting and measured for me here at tedwomen is that... tyes, it was the best embedded when someone said, "turn on the men on a table and tell you," if the revolution starts supporting you. "
2022-03-23 10:05:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:25 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're at our plane at the stest toe, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variable system and a refrigeration system with a fluid, and a fluid system that allows us to refrightening a fluid to the car car traffic, until you can see in the same way, until you're going to the car traffic, until you're going to be able to do, until you're going to do it's going to be able to do, until you're going to do, until you're going to be able to do that you're going to do it is to do it, to do it, to do it, to do it is to do anything else you're going to do it, to do it, all of a specific, to do it's going to be able to the same way, to do it, to do, to the
2022-03-23 10:05:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:25 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.449 | nll_loss 3.283 | ppl 9.73 | bleu 27.4 | wps 4767 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 27.4
2022-03-23 10:05:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:05:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:05:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:05:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 25 @ 3920 updates, score 27.4) (writing took 1.8857516649877653 seconds)
2022-03-23 10:05:27 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:05:27 | INFO | train | epoch 025 | loss 7.42 | nll_loss 3.657 | ppl 12.62 | wps 44142.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.459 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 2336
2022-03-23 10:05:28 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:05:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:05:53 | INFO | train_inner | epoch 026:     80 / 157 loss=7.35, nll_loss=3.546, ppl=11.68, wps=35451, ups=1.39, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.429, loss_scale=4, train_wall=31, gb_free=14, wall=2362
2022-03-23 10:06:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:21 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheets in the clinic.
2022-03-23 10:06:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:06:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:06:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:06:29 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that make two new pigs.
2022-03-23 10:06:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:06:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and psuitcase.
2022-03-23 10:06:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:06:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:06:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:06:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for the wild, the number of wildlife animals grew up again, and that's a foundation for conservation in namibia.
2022-03-23 10:06:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:06:45 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are caught in the inside, but the superconductor may not like it, if they're moving, because their movements use energy, and so the superconductor disorders.
2022-03-23 10:06:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:06:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can start the big configuration of the face and the basic form, and through the theft of information that contains the whole porn structure and all the fits.
2022-03-23 10:06:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:06:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting to be interesting and measure it, for me here at tedwomen, is that -- well, in the striking dinner, it's been put together the best than someone said, "turn you to the men on your table and tell you," 'if the revolution starts to support you. "'" the truth is that we've already started to support you've already started with you in this long time, we've already started with you've already been in the future, we've already started with you've already started with you've already been in the future, you've already started with the future, you know, you've already started to have women who have a rubellyourselves. "
2022-03-23 10:06:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:06:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our plane, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variable system and a refrigeration system that allows us to refrightening us that it allows us to use it to be in the aircraft, to be able to use the propelled traffic in a particular way that we're going to be able to see, if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the united states.
2022-03-23 10:06:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:06:56 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.342 | nll_loss 3.129 | ppl 8.75 | bleu 29.09 | wps 4738 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 29.09
2022-03-23 10:06:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:06:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:06:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:06:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 29.09) (writing took 1.7729808430012781 seconds)
2022-03-23 10:06:57 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:06:57 | INFO | train | epoch 026 | loss 7.341 | nll_loss 3.533 | ppl 11.57 | wps 43858.9 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.426 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 2426
2022-03-23 10:06:58 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:06:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:07:05 | INFO | train_inner | epoch 027:     23 / 157 loss=7.296, nll_loss=3.463, ppl=11.02, wps=34490.5, ups=1.38, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.405, loss_scale=4, train_wall=31, gb_free=14.8, wall=2434
2022-03-23 10:07:37 | INFO | train_inner | epoch 027:    123 / 157 loss=7.318, nll_loss=3.498, ppl=11.3, wps=80120.2, ups=3.2, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.433, loss_scale=4, train_wall=31, gb_free=13.6, wall=2465
2022-03-23 10:07:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:07:51 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:07:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:07:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:07:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:07:58 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to have two new pigs.
2022-03-23 10:07:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:08:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:08:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:08:06 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:08:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:08:10 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for the wildlife, the number grew up again, and that's a foundation for conservation in namibia.
2022-03-23 10:08:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:08:14 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are caught inside, but the superconductor doesn't like moving because their movements need energy, and so the superconductor.
2022-03-23 10:08:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:08:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can start with the big constraints of the face and the basic shape, and restoring it through the theft of the information that pulls the whole porn structure and all a fold.
2022-03-23 10:08:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:22 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and measured to me here at tedwomen, is that... well, in the striking dinner, it's best summarized when someone said, "turn to men on your table and tell you," if the revolution starts. "
2022-03-23 10:08:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:23 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large piece of design work that we're on our airplane at the stumber toes, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation and a refrigering system, and a refrigerator, that it allows us to stop aircraft, or if you're going to see the propelling space, or if you're going to be able to see the propelled.
2022-03-23 10:08:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:23 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.328 | nll_loss 3.094 | ppl 8.54 | bleu 29.12 | wps 5027.5 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.12
2022-03-23 10:08:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:08:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:08:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:08:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.12) (writing took 2.045112848994904 seconds)
2022-03-23 10:08:25 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:08:25 | INFO | train | epoch 027 | loss 7.288 | nll_loss 3.45 | ppl 10.93 | wps 44836.6 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.414 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2514
2022-03-23 10:08:26 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:08:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:08:47 | INFO | train_inner | epoch 028:     66 / 157 loss=7.246, nll_loss=3.384, ppl=10.44, wps=35590.6, ups=1.43, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.397, loss_scale=4, train_wall=31, gb_free=14.7, wall=2535
2022-03-23 10:09:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:19 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:09:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:09:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that i think most of you know here.
2022-03-23 10:09:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:09:27 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that make two new pigs overcome.
2022-03-23 10:09:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:09:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and psuitcase.
2022-03-23 10:09:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:09:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:09:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:09:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature of people's responsibility for the wild, the number of wild animals grew up again, and this is a foundation for conservation in namibia.
2022-03-23 10:09:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:09:42 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field lines are caught inside, but the superconductor doesn't like it when they move because their movements use energy, and so the superconducting disorders.
2022-03-23 10:09:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:09:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big constructions of the facial and the basic shape, and remove it through the theast information that refers the whole porter structure and all the fits.
2022-03-23 10:09:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:09:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and measured for me here at tedwomen is that -- well, in the strictly dinner, it's best summarized when someone said, "turn to men on your table and say," if the revolution begins, then we support you. "'"' "the truth is that we've already started with you, in the future, we've already been supporting you." & lt; em & gt; & gt;
2022-03-23 10:09:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:09:53 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a big part of the design work that we are at our plane at the stumber, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and a refrigeration system that allows us to use in the air, or if you see the propellism, or if you can't see the same, or if you can't see the same, or if you look at the same, or if you see the same as you can't see the propellyfish, or if you see the same, or if you see the same, or if you can actually, or if you can't see the same, or if you see the same, or if you see the same, or if you can actually, or if you see the same, or if you see the same, or if you can't see the same thing that you can't see the same thing that you see the
2022-03-23 10:09:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:09:53 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.288 | nll_loss 3.049 | ppl 8.28 | bleu 29.98 | wps 4767.3 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.98
2022-03-23 10:09:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:09:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:09:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:09:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 29.98) (writing took 2.110428055995726 seconds)
2022-03-23 10:09:55 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:09:55 | INFO | train | epoch 028 | loss 7.246 | nll_loss 3.384 | ppl 10.44 | wps 43963.4 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.419 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2604
2022-03-23 10:09:56 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:09:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:09:59 | INFO | train_inner | epoch 029:      9 / 157 loss=7.262, nll_loss=3.411, ppl=10.64, wps=34868.8, ups=1.38, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.444, loss_scale=4, train_wall=31, gb_free=13.6, wall=2607
2022-03-23 10:10:30 | INFO | train_inner | epoch 029:    109 / 157 loss=7.197, nll_loss=3.309, ppl=9.91, wps=80386, ups=3.2, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.399, loss_scale=4, train_wall=31, gb_free=13.6, wall=2639
2022-03-23 10:10:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:10:49 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:10:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:10:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 10:10:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:10:56 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create two new pigs.
2022-03-23 10:10:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:11:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salz and psuitcase.
2022-03-23 10:11:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:11:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:11:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:11:08 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for the wild, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:11:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:11:12 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like when they move, because their movements need energy, and so the superconductor disorder.
2022-03-23 10:11:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:11:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big configuration of the face and the basic shape, and reconstraints it through the theft information that draws all the ports structure and fold.
2022-03-23 10:11:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it was very interesting and measured to me here at tedwomen is that... tyes, when dinner was the best summarized when someone said, "turn to men on your table, and they say," if the revolution starts to support you. "
2022-03-23 10:11:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:23 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of design work that we're on our aircraft at the proud toes was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigerator system that allows us to use an aircraft in the air, or if you can use it, or if you can use it, or if you can use it, or if you can use it, or if you can use it, or if you can use it, it, you can use it, you can use it, you can use it, you can use it, you can use it, you can use it, you can use it, or if you can use it, you can use it, or if you can use it in a mechanism, or if you can use it, or if you can use it, or if you can use it, you can use it, or if you can use it
2022-03-23 10:11:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:23 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.266 | nll_loss 3.02 | ppl 8.11 | bleu 30.04 | wps 4792.4 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.04
2022-03-23 10:11:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:11:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:11:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:11:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.04) (writing took 1.8640239109954564 seconds)
2022-03-23 10:11:25 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:11:25 | INFO | train | epoch 029 | loss 7.195 | nll_loss 3.306 | ppl 9.89 | wps 44113.8 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.408 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2693
2022-03-23 10:11:25 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:11:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:11:42 | INFO | train_inner | epoch 030:     52 / 157 loss=7.18, nll_loss=3.282, ppl=9.72, wps=35089.4, ups=1.4, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.395, loss_scale=4, train_wall=31, gb_free=13.9, wall=2710
2022-03-23 10:12:13 | INFO | train_inner | epoch 030:    152 / 157 loss=7.135, nll_loss=3.214, ppl=9.28, wps=80971.5, ups=3.2, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.358, loss_scale=4, train_wall=31, gb_free=14.7, wall=2741
2022-03-23 10:12:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:12:18 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:12:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:12:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:12:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:12:26 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to be translate two new pigs.
2022-03-23 10:12:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:12:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are served with salt and pepper.
2022-03-23 10:12:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:12:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:12:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:12:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for the wild, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:12:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:12:42 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are caught inside, but the superconductor doesn't like it if they're moving, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:12:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:12:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which gives the big configuration of the face and repeat it through the fundamental information that pulls the whole portion structure and all the folds.
2022-03-23 10:12:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:12:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn to men on your table and tell you," if the revolution starts to support you. "
2022-03-23 10:12:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:12:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on on our plane was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft to a specific traffic, to a specific, to an aircraft, to an aircraft, to an aircraft, to an aircraft, to a specific, to an aircraft, to an aircraft, to an aircraft, to an aircraft, to an aircraft, to an awful result, to a result, to a specific, to a result, to a specific, to an awful result, to an awful result, to a result that we had to an awful result that we had to a unique problem that we had to a unique problems that we had to a unique problems that we had to a unique problems that's either when you.
2022-03-23 10:12:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:12:52 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.207 | nll_loss 2.955 | ppl 7.75 | bleu 30.75 | wps 4907.1 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.75
2022-03-23 10:12:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:12:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:12:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:12:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.75) (writing took 1.9264831570035312 seconds)
2022-03-23 10:12:54 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:12:54 | INFO | train | epoch 030 | loss 7.144 | nll_loss 3.227 | ppl 9.36 | wps 44505.2 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.366 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2782
2022-03-23 10:12:54 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:12:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:13:24 | INFO | train_inner | epoch 031:     95 / 157 loss=7.131, nll_loss=3.208, ppl=9.24, wps=35791.7, ups=1.4, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.39, loss_scale=4, train_wall=31, gb_free=13.6, wall=2813
2022-03-23 10:13:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:13:47 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:13:47 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:13:51 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:13:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:13:55 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create two new pigs.
2022-03-23 10:13:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:13:58 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and suitcase.
2022-03-23 10:13:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:14:02 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:14:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:14:06 | INFO | fairseq.tasks.translation | example hypothesis: and in the math of how people responsibility for wildlife, the number of wild animals grew up again, and that has become a basis for conservation in namibia.
2022-03-23 10:14:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:14:10 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and that's how the superconductor disorder disorder.
2022-03-23 10:14:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:14:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that gives the big configuration of the face and repeat it through the basic shape of the information that refers the whole porn structure and all the fits.
2022-03-23 10:14:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate to be here for me here at tedwomen is that -- well, when dinner was best summarized when someone said, "turn you to your men on your table and tell you," 'if the revolution begins to support you. "' the truth is that we've already been supporting you for this long time."
2022-03-23 10:14:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:21 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to it -- everything from a continuous variable, and a refrigeration system that allows us to stop an aircraft in gogos until some particular way, or if you can see the propelled, or if you can see the propelling space in the same way.
2022-03-23 10:14:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:21 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.19 | nll_loss 2.922 | ppl 7.58 | bleu 31.08 | wps 4801.7 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.08
2022-03-23 10:14:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:14:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:14:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:14:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.08) (writing took 1.88385013199877 seconds)
2022-03-23 10:14:23 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:14:23 | INFO | train | epoch 031 | loss 7.119 | nll_loss 3.189 | ppl 9.12 | wps 44236.5 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.381 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2871
2022-03-23 10:14:23 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:14:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:14:35 | INFO | train_inner | epoch 032:     38 / 157 loss=7.07, nll_loss=3.111, ppl=8.64, wps=34991.8, ups=1.4, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.352, loss_scale=4, train_wall=30, gb_free=14.3, wall=2884
2022-03-23 10:15:07 | INFO | train_inner | epoch 032:    138 / 157 loss=7.082, nll_loss=3.131, ppl=8.76, wps=80189.4, ups=3.17, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.378, loss_scale=4, train_wall=31, gb_free=14.4, wall=2916
2022-03-23 10:15:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:15:17 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:15:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:15:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 10:15:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will overwrite two new pigs.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:15:28 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salz and pepper.
2022-03-23 10:15:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:15:32 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:15:32 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:15:36 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people were taking responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:15:36 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:15:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and that's how the superconducting disorder is.
2022-03-23 10:15:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:15:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that refers the big constructions of the face and the basic shape, and then refers it through the one information that draws the whole porter structure and all the folds.
2022-03-23 10:15:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:15:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and measured to me here at tedwomen is that... well, when someone said, "turn you to your table and say," if the revolution begins, then we love women, we've been supporting you for this topic for a long time. "
2022-03-23 10:15:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:15:50 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on on our plane is a result that we had to solve the unique problems that were connected to it -- everything from a continuous variation and a system of refrigeration, that allows us to use an aircraft in the goodbble traffic, until a specialist, until one of the most promoting, or a state of a state of a state of a car that is either when you can see, or if you can see the prophearity, until you can see it's in a state of a state of a state of a security, until you can see it, or if you can see it's in the security, or if you can see it's either of a mechanism, until you can see it's a state of a state of a state of a state of a constant variable, or if you can see it's in the security, until you can see it's
2022-03-23 10:15:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:15:50 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.175 | nll_loss 2.897 | ppl 7.45 | bleu 31.06 | wps 4893.8 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.08
2022-03-23 10:15:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:15:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:15:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:15:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.06) (writing took 0.810939981995034 seconds)
2022-03-23 10:15:51 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:15:51 | INFO | train | epoch 032 | loss 7.072 | nll_loss 3.115 | ppl 8.66 | wps 44764.1 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.365 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 2960
2022-03-23 10:15:52 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:15:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:16:18 | INFO | train_inner | epoch 033:     81 / 157 loss=7.023, nll_loss=3.039, ppl=8.22, wps=35515.2, ups=1.42, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.369, loss_scale=4, train_wall=30, gb_free=14, wall=2986
2022-03-23 10:16:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:16:45 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic clinic.
2022-03-23 10:16:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:16:49 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 10:16:49 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:16:53 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of goldilocks that will create two new pigs.
2022-03-23 10:16:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:16:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pill suitcase.
2022-03-23 10:16:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:17:01 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:17:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:17:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people have taken responsibility for the wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:17:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:17:09 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field lines are captured inside, but the superconductor may not like the superconductor, because they use their movements, and so the superconducting disorders.
2022-03-23 10:17:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:17:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection from this reflection, we can start with a traditional facial can that refers the big constraints of the face and repeat it through the basic shape of this information that refers the whole porn structure and refers all the fers.
2022-03-23 10:17:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:17:18 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured, for me here at tedwomen, is that... well, when dinner was first summarized, when someone said, "turn you to the men on your table and tell you," if the revolution starts to support you, "the truth is that we already have supported you for this topic for a long time."
2022-03-23 10:17:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane at the stumble, was a result that we had to solve the unique problems that were connected to it on the ground -- everything from a continuous variables and a refrigerator system with liquid refrigeration, that allows us to use an aircraft in the world until you can see that's going to fly, or if you can see the propelled, or if you can see the ground, or if you can see the propelled, or if you can see it's all of a mechanism, that's all, or if you can see it, or if you can see it, or if you can see it's a steady, or the space that's going to make it, or if you can see that's a steady, or the space that's going to make it, that's possible.
2022-03-23 10:17:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:20 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.132 | nll_loss 2.866 | ppl 7.29 | bleu 32.23 | wps 4673.4 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.23
2022-03-23 10:17:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:17:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:17:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:17:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.23) (writing took 1.8208458729932318 seconds)
2022-03-23 10:17:22 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:17:22 | INFO | train | epoch 033 | loss 7.049 | nll_loss 3.08 | ppl 8.45 | wps 43445.8 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.373 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 3050
2022-03-23 10:17:22 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:17:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:17:30 | INFO | train_inner | epoch 034:     24 / 157 loss=7.068, nll_loss=3.108, ppl=8.62, wps=34595.4, ups=1.38, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.372, loss_scale=4, train_wall=31, gb_free=13.8, wall=3059
2022-03-23 10:18:02 | INFO | train_inner | epoch 034:    124 / 157 loss=6.997, nll_loss=2.998, ppl=7.99, wps=80176.3, ups=3.19, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.358, loss_scale=4, train_wall=31, gb_free=13.7, wall=3090
2022-03-23 10:18:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:18:15 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:18:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:18:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most of you here.
2022-03-23 10:18:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:18:23 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of goldilocks that will generate two new pigs.
2022-03-23 10:18:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:18:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are being served with salz and pepper.
2022-03-23 10:18:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:18:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:18:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:18:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for the wild, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:18:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:18:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field lines are captured inside, but the superconductor doesn't like it, if they're moving, because their movements are disrupting energy, and so the superconductor is disturbing.
2022-03-23 10:18:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:18:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big constraints of the face and the basic shape, and then defeat it through the one of the information that refers the entire porn structure and all the fits.
2022-03-23 10:18:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:18:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn you to the men on your table and tell you, 'if the revolution begins, then we support you, then we support you.' the truth, women, is that we've already been supporting you for a long time.
2022-03-23 10:18:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:18:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we are at our plane at the most proud toe, was a result that we had to solve the unique problems that were connected to it -- everything from a continuous variable and a cooling system with a refrigerator, that allows us to use an aircraft in the same way, until the sailing space, if you're either going to be able to do it, if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do it.
2022-03-23 10:18:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:18:51 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.141 | nll_loss 2.881 | ppl 7.37 | bleu 32.13 | wps 4637.4 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.23
2022-03-23 10:18:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 10:18:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:18:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:18:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 34 @ 5333 updates, score 32.13) (writing took 0.8003126950061414 seconds)
2022-03-23 10:18:52 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:18:52 | INFO | train | epoch 034 | loss 7.014 | nll_loss 3.024 | ppl 8.14 | wps 44059.4 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.368 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 3140
2022-03-23 10:18:52 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:18:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:19:13 | INFO | train_inner | epoch 035:     67 / 157 loss=7.022, nll_loss=3.036, ppl=8.2, wps=35198.4, ups=1.4, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.369, loss_scale=4, train_wall=30, gb_free=14.7, wall=3162
2022-03-23 10:19:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:19:45 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:19:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:19:49 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:19:49 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:19:52 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will be transferred to two new pigs.
2022-03-23 10:19:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:19:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salz and pepper.
2022-03-23 10:19:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:20:01 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:20:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:20:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:20:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:20:09 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:20:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:20:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constraints of the face and the basic shape, and then then then then remove it through the one information that refers all the porn structure and all of the folds.
2022-03-23 10:20:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:20:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that... well, when dinner was the best summarized when someone said, "turn you to your men on your table and tell you," when the revolution starts to support you. "'" the truth, women are already supporting you for a long time. "
2022-03-23 10:20:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:20:19 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variable and a cooling system with fluid that allows us to use an aircraft machine in the aircraft to either use the propellyfish traffic, or if you look at the ground, until you can see the security space, all the way -- all the way up to the way, to the way, to see it's a mechanism that we're going to see it's going to make it go, to the way that we're going to the security space that we're going to the same as you're going to be able to be able to see that we're going to the same as you're going to be able to be able to be able to see.
2022-03-23 10:20:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:20:19 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 7.107 | nll_loss 2.839 | ppl 7.16 | bleu 32.29 | wps 4796.4 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.29
2022-03-23 10:20:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 10:20:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:20:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:20:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 35 @ 5490 updates, score 32.29) (writing took 1.9699943760060705 seconds)
2022-03-23 10:20:21 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:20:21 | INFO | train | epoch 035 | loss 6.982 | nll_loss 2.975 | ppl 7.86 | wps 44169.3 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.344 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 3230
2022-03-23 10:20:21 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:20:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:20:25 | INFO | train_inner | epoch 036:     10 / 157 loss=6.969, nll_loss=2.956, ppl=7.76, wps=34764, ups=1.39, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.341, loss_scale=4, train_wall=31, gb_free=14.7, wall=3233
2022-03-23 10:20:56 | INFO | train_inner | epoch 036:    110 / 157 loss=6.951, nll_loss=2.925, ppl=7.6, wps=80179.4, ups=3.17, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.344, loss_scale=4, train_wall=31, gb_free=14.7, wall=3265
2022-03-23 10:21:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:21:14 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:21:14 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:21:18 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know.
2022-03-23 10:21:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:21:23 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks in the dinments that are going to overwrite two new pigs.
2022-03-23 10:21:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:21:26 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salt and pepper.
2022-03-23 10:21:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:21:30 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 10:21:30 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:21:34 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people revenued responsibility for wildlife, the number of wildanimals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:21:34 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:21:38 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field lines are captured inside, but the superconductor doesn't like, if they move, because their movements use energy, and so the superconducting iron disorder.
2022-03-23 10:21:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:21:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can of the face and the basic shape of the face, and then then deploy it through the one of the information that refers the entire porn structure, and all the floods refuse.
2022-03-23 10:21:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:21:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured it to me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to the men on your table and tell them," if the revolution begins, then we support you. "
2022-03-23 10:21:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:21:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a big part of the design work that we're on on our plane are the most stumbling toes, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variation and a refrigerator system with refrigerator that allows us to use the aircraft to stop, and to go to a specialize, which is either going to be acquire, and if you're going to move the unique problems that you're going to the earth, and if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do it, and if you're going to do it, and you're going to do it, and you're going to do it, and you're going to be able to be able to be able to be able to do it, and you're going to
2022-03-23 10:21:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:21:49 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 7.114 | nll_loss 2.813 | ppl 7.03 | bleu 32.84 | wps 4652 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.84
2022-03-23 10:21:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 10:21:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:21:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:21:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.84) (writing took 1.883148982989951 seconds)
2022-03-23 10:21:51 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:21:51 | INFO | train | epoch 036 | loss 6.96 | nll_loss 2.942 | ppl 7.68 | wps 43664.9 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.359 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 3320
2022-03-23 10:21:52 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:21:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:22:08 | INFO | train_inner | epoch 037:     53 / 157 loss=6.928, nll_loss=2.892, ppl=7.42, wps=35315.5, ups=1.38, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.362, loss_scale=4, train_wall=30, gb_free=14.7, wall=3337
2022-03-23 10:22:40 | INFO | train_inner | epoch 037:    153 / 157 loss=6.975, nll_loss=2.963, ppl=7.8, wps=79353.7, ups=3.2, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.346, loss_scale=4, train_wall=31, gb_free=13.5, wall=3368
2022-03-23 10:22:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:22:45 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:22:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:22:49 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:22:49 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:22:53 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will overwrite two new pigs.
2022-03-23 10:22:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:22:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pepper.
2022-03-23 10:22:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:23:01 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:23:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:23:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:23:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:23:09 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it if they move, because they use their movements to use energy, and that's how the superconductor disorders.
2022-03-23 10:23:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:23:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection from this reflection, we can start with a traditional facial can that restores the big constraints of the face and the basic shape, and then defeat it through the one of the information that refers all the porn structure and all the fits.
2022-03-23 10:23:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:23:18 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and measured to me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn you to the men on your table and tell you, 'if the revolution starts, we support you.' '" the truth, women is that we've already supported you at this topic for a long time, we've already been supported for a long time.
2022-03-23 10:23:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:23:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention is still the mother, and a big part of the design work that we're on on our plane is the most proud toes that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuously variable and a cooling system with refrigerator fluid, that it allows us to use an aircraft on the top of the aircraft traffic, to a specially appropriate passage to the ground, if you can see the propeller, or if you can see the space in a car storm, if you're going to the air, if you're going to the same thing that's going to the car stored, if you're going to the space, or if you're going to the car stored, if you're going to be seen that you're going to the air, if you're going to the ground, if you're going to the same.
2022-03-23 10:23:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:23:20 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 7.083 | nll_loss 2.768 | ppl 6.81 | bleu 33.08 | wps 4655.3 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 33.08
2022-03-23 10:23:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 10:23:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:23:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:23:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 33.08) (writing took 1.927487912995275 seconds)
2022-03-23 10:23:22 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:23:22 | INFO | train | epoch 037 | loss 6.938 | nll_loss 2.905 | ppl 7.49 | wps 43659.4 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.343 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 3410
2022-03-23 10:23:22 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:23:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:23:52 | INFO | train_inner | epoch 038:     96 / 157 loss=6.937, nll_loss=2.904, ppl=7.48, wps=33893.3, ups=1.38, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.372, loss_scale=4, train_wall=31, gb_free=14.3, wall=3441
2022-03-23 10:24:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:24:15 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:24:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:24:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 10:24:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:24:23 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:24:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:24:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salt and pepper.
2022-03-23 10:24:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:24:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:24:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:24:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for the wildlife, the number of wild animals grew back, and this has become a basis for conservation in namibia.
2022-03-23 10:24:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:24:39 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and the superconducting disorder.
2022-03-23 10:24:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:24:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restores the big constraints of the face and the basic shape, and then enable it through the information that refers the whole porn structure and all the fine folds.
2022-03-23 10:24:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:24:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn you to your men on your table and tell you," if the revolution begins, then we support you, "the truth, women are supporting you in this topic for a long time."
2022-03-23 10:24:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:24:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother, and a big part of the design work that we're the most stumbling on our airplane was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variation and a cooling system that allows us to use an aircraft on goand transportation to a very refrigeration, to an aircraft traffic, to a particular passage, to an aircraft, to an aircraft that's either when you see the ground, or when you can see the propelled by an aircraft where you can see the land in the security system that you can see the security system that you can see the security system that you can see some of an aircraft, or when you can see the land as well, if you can see the degrace of an aircraft, if you can see the degrading system that allows us to the decrease, if you can see the security system that you see
2022-03-23 10:24:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:24:49 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 7.076 | nll_loss 2.777 | ppl 6.85 | bleu 32.7 | wps 4767.1 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 33.08
2022-03-23 10:24:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 10:24:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:24:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:24:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 32.7) (writing took 0.8065616950043477 seconds)
2022-03-23 10:24:50 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:24:50 | INFO | train | epoch 038 | loss 6.928 | nll_loss 2.891 | ppl 7.42 | wps 44729.1 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.368 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 3499
2022-03-23 10:24:50 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:24:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:25:03 | INFO | train_inner | epoch 039:     39 / 157 loss=6.871, nll_loss=2.803, ppl=6.98, wps=36853.5, ups=1.41, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.335, loss_scale=4, train_wall=31, gb_free=13.6, wall=3512
2022-03-23 10:25:34 | INFO | train_inner | epoch 039:    139 / 157 loss=6.922, nll_loss=2.882, ppl=7.37, wps=79506.3, ups=3.2, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.371, loss_scale=4, train_wall=31, gb_free=14.7, wall=3543
2022-03-23 10:25:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:25:43 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:25:43 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:25:48 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:25:48 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:25:52 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will overwrite two new pigs.
2022-03-23 10:25:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:25:55 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:25:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:26:00 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:26:00 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:26:03 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for the wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:26:03 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:26:07 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:26:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:26:12 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constraints of the face and the basic shape, and then remove it through that information that refers all the porn structure and all the fine folds.
2022-03-23 10:26:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:26:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate, for me here at tedwomen, is that... well, in the strict dinner, it was best summarized when someone said, "turn you to the men on your table and tell you," when the revolution begins, we support you. "" the truth, women, we've already supported you in this topic for a long time. at raw spring, "
2022-03-23 10:26:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:26:18 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a lot of the design work that we're the most proud of on our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything, from a continuously variable and a refrigerator system with refrigeration that allows us to use an aircraft on the top of go-go-traffic, to a particular drive, or if you look at the ground, until you look at the same thing that's going on, until you see the fact that's going to see the air, or when you see the air that's going on, until you see the air, until you can see that's going on, until you can see that you see the air, or when you can see the crassink of a mechanism that's going to the crashes that you can see the ground, or when you see the air, until you can see the air, until you can see the fall that you see that you can see
2022-03-23 10:26:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:26:18 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 7.062 | nll_loss 2.753 | ppl 6.74 | bleu 33.35 | wps 4721.7 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.35
2022-03-23 10:26:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 10:26:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:26:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:26:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 33.35) (writing took 1.874374949009507 seconds)
2022-03-23 10:26:20 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:26:20 | INFO | train | epoch 039 | loss 6.896 | nll_loss 2.841 | ppl 7.17 | wps 43916 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.348 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3589
2022-03-23 10:26:20 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:26:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:26:46 | INFO | train_inner | epoch 040:     82 / 157 loss=6.88, nll_loss=2.815, ppl=7.04, wps=34436, ups=1.39, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.314, loss_scale=4, train_wall=31, gb_free=14.1, wall=3615
2022-03-23 10:27:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:27:13 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:27:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:27:18 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:27:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:27:22 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will overwrite two new pigs.
2022-03-23 10:27:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:27:26 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salt and pepper.
2022-03-23 10:27:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:27:29 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:27:29 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:27:33 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wild animals grew up again, and that's become a foundation for conservation in namibia.
2022-03-23 10:27:33 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:27:38 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like when they move, because their movements use energy, and the superconducting disorder.
2022-03-23 10:27:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:27:42 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection from this reflection, we can start with a traditional facial can that refers the big constraints of the face and restores the basic shape, and then deals it through the one of the information that refers the whole porn structure and all of the fine folds.
2022-03-23 10:27:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:27:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn to the men on your table and say," if the revolution starts, then we support you. 'the truth is that we've already been supporting you for a long time. at rachel with silspring, "
2022-03-23 10:27:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:27:48 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention, and a large part of the design work we're on on our aircraft is a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable operating and a refrigerator system that allows us to use an aircraft on the top of go-traffic to a special passage, or a passage that's either drifting the propeller, or if you look at the ground, or if you see the aircraft, or if you're in the ground, you're going to see the aircraft, it's going to be driving, or if you're going to the aircraft, or if you're in a car, it's in the ground, it's in the ground, it's in the air, you're in the same way, you're going to see it's going to see it's in a car, or if you're going to be driving, or if you're going to see the ground
2022-03-23 10:27:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:27:48 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 7.079 | nll_loss 2.769 | ppl 6.81 | bleu 33.16 | wps 4794.3 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.35
2022-03-23 10:27:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 10:27:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:27:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:27:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 33.16) (writing took 0.8473004789993865 seconds)
2022-03-23 10:27:49 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:27:49 | INFO | train | epoch 040 | loss 6.871 | nll_loss 2.801 | ppl 6.97 | wps 44625.2 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.325 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3677
2022-03-23 10:27:49 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:27:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:27:57 | INFO | train_inner | epoch 041:     25 / 157 loss=6.882, nll_loss=2.82, ppl=7.06, wps=36172.2, ups=1.42, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.342, loss_scale=4, train_wall=31, gb_free=14.4, wall=3685
2022-03-23 10:28:28 | INFO | train_inner | epoch 041:    125 / 157 loss=6.856, nll_loss=2.777, ppl=6.86, wps=79463, ups=3.19, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.343, loss_scale=4, train_wall=31, gb_free=13.8, wall=3717
2022-03-23 10:28:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:28:42 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep beep in the clinic.
2022-03-23 10:28:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:28:46 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most people know here.
2022-03-23 10:28:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:28:50 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of india that will transcend two new pigs.
2022-03-23 10:28:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:28:54 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:28:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:28:58 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:28:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:29:02 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:29:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:29:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements are using energy, and the superconducting disorder.
2022-03-23 10:29:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:29:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection from this reflection, we can start with a traditional facial can that gives the big constraints of the face, and restore the basic form, and then put it through the one of the information that refers the whole porn structure and all the wrinkles.
2022-03-23 10:29:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:29:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn you to your table and say," if the revolution begins, we support you. '"'" '"the truth, women are already supporting you for a long time." at rael spring, with silspring, "
2022-03-23 10:29:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:29:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention, and a big part of the design work that we're on our aircraft is a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuously varied and a cooling system of liquid that allows us to use an aircraft in the aircraft and go-traffic to a specially appropriate passage, or if you're going to fly, or if you look at the ground, you're going to see a car storm.
2022-03-23 10:29:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:29:16 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 7.025 | nll_loss 2.729 | ppl 6.63 | bleu 33.71 | wps 4835.9 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.71
2022-03-23 10:29:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 10:29:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:29:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:29:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 33.71) (writing took 1.8924318029894494 seconds)
2022-03-23 10:29:18 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:29:18 | INFO | train | epoch 041 | loss 6.86 | nll_loss 2.784 | ppl 6.89 | wps 44301.6 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.339 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 3766
2022-03-23 10:29:18 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 10:29:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:29:40 | INFO | train_inner | epoch 042:     68 / 157 loss=6.839, nll_loss=2.752, ppl=6.74, wps=35189.9, ups=1.4, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.336, loss_scale=4, train_wall=31, gb_free=22.4, wall=3788
2022-03-23 10:30:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:30:11 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep beep in the clinic.
2022-03-23 10:30:11 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:30:15 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:30:15 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:30:19 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks in india that will transcend two new pigs.
2022-03-23 10:30:19 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:30:23 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frogs are served with salt and pepper.
2022-03-23 10:30:23 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:30:27 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:30:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:30:31 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent that people took responsibility for wildlife, the number of wild animals grew up again, and this has become a foundation for conservation in namibia.
2022-03-23 10:30:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:30:35 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move because their movements are using their movements, and so the superconducting disorder.
2022-03-23 10:30:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:30:39 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constraints of the face and the basic shape, and then deploy it through the one of the information that refers the entire porn structure and all of the fin folds.
2022-03-23 10:30:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:30:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to the men on your table and tell you," when the revolution begins, we support you. '"'" the truth is that we've already supported you about this topic for a long time. at rael spring's "] ["] ["
2022-03-23 10:30:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:30:46 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention still is the mother, and a large part of the design work that we're on our airplane at the most stumbling toes was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously variable operating and a cooling system with fluid that allows us to use an aircraft machine on the top of the aircraft and go-traffic to a special passenger to either drive the propeller when you see, or if you see the fly in the ground, until you see a car storm.
2022-03-23 10:30:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:30:46 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 7.046 | nll_loss 2.745 | ppl 6.71 | bleu 33.26 | wps 4750.9 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.71
2022-03-23 10:30:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 10:30:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:30:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:30:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 42 @ 6589 updates, score 33.26) (writing took 0.8687974380009109 seconds)
2022-03-23 10:30:47 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 10:30:47 | INFO | train | epoch 042 | loss 6.835 | nll_loss 2.746 | ppl 6.71 | wps 44443.2 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.331 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 3855
2022-03-23 10:30:47 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 10:30:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:30:51 | INFO | train_inner | epoch 043:     11 / 157 loss=6.819, nll_loss=2.722, ppl=6.6, wps=35922.3, ups=1.41, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.315, loss_scale=4, train_wall=31, gb_free=13.9, wall=3859
2022-03-23 10:31:22 | INFO | train_inner | epoch 043:    111 / 157 loss=6.856, nll_loss=2.777, ppl=6.85, wps=79769.7, ups=3.2, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.361, loss_scale=4, train_wall=31, gb_free=13.8, wall=3890
2022-03-23 10:31:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:31:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:31:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:31:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most people know here.
2022-03-23 10:31:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:31:48 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of india that are going to create two new pigs.
2022-03-23 10:31:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:31:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pepper.
2022-03-23 10:31:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:31:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:31:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:32:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for the wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:32:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:32:04 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:32:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:32:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constraints of the face and restore the basic shape, and decrease it through the one of the information that refers the whole porn structure and all the wrinkles.
2022-03-23 10:32:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:32:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, in strict dinner, it was the best summarized when someone said, "turn you to the men on your table and tell them," when the revolution begins, we support you. '"' the truth, women, is that we've been supporting you with this topic for a long time. at rael spring's"
2022-03-23 10:32:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:32:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother, and a large part of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to doing it on the ground -- all, from a continuously variable drive and a cooling system with refrigeration that allows us to use an aircraft machine on the top of go-traffic to a special passenger that is either a propeller, or if you see the soil, until you see the degraded, or when you're going to be able to be able to operate on the ground, until we see the security system.
2022-03-23 10:32:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:32:14 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 7.02 | nll_loss 2.707 | ppl 6.53 | bleu 33.84 | wps 4766.3 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.84
2022-03-23 10:32:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 10:32:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:32:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:32:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 43 @ 6746 updates, score 33.84) (writing took 1.9336462470091647 seconds)
2022-03-23 10:32:16 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 10:32:16 | INFO | train | epoch 043 | loss 6.825 | nll_loss 2.73 | ppl 6.63 | wps 44096.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.342 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3945
2022-03-23 10:32:16 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 10:32:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:32:34 | INFO | train_inner | epoch 044:     54 / 157 loss=6.796, nll_loss=2.684, ppl=6.43, wps=34663.9, ups=1.39, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.34, loss_scale=4, train_wall=31, gb_free=14.2, wall=3962
2022-03-23 10:33:04 | INFO | train_inner | epoch 044:    154 / 157 loss=6.809, nll_loss=2.706, ppl=6.52, wps=82707.1, ups=3.24, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.33, loss_scale=4, train_wall=30, gb_free=13.8, wall=3993
2022-03-23 10:33:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:33:09 | INFO | fairseq.tasks.translation | example hypothesis: we put these betbleep up in the clinic.
2022-03-23 10:33:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:33:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:33:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:33:17 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of india that will transcend two new pigs.
2022-03-23 10:33:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:33:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salz and pepper.
2022-03-23 10:33:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:33:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:33:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:33:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the face of how people took responsibility for wildlife, the number of wildlife grew back. and this has become a foundation for conservation in namibia.
2022-03-23 10:33:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:33:33 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and the superconducting disorder.
2022-03-23 10:33:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:33:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constraints of the face and the basic form, and then then let it go through that information that refers the whole porn structure and all of the fine folds.
2022-03-23 10:33:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:33:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to the men on your table and tell you," when the revolution begins, we support you. "'" the truth, women is that we've been supporting you with this topic for a long time.
2022-03-23 10:33:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:33:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we're the most proud of on our plane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuously variable operating and a refrigerator system with fluid that allows us to use an aircraft in the stop and go-traffic to a special passage, either drill, or when you're driving the propeller, the ground, or when you can see it's connected to the ground, until you can see it's a mechanism.
2022-03-23 10:33:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:33:43 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 7.027 | nll_loss 2.705 | ppl 6.52 | bleu 33.59 | wps 4895.9 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.84
2022-03-23 10:33:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 10:33:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:33:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:33:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 44 @ 6903 updates, score 33.59) (writing took 0.8660648920049425 seconds)
2022-03-23 10:33:44 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 10:33:44 | INFO | train | epoch 044 | loss 6.809 | nll_loss 2.704 | ppl 6.52 | wps 45161.8 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.342 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 4032
2022-03-23 10:33:44 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 10:33:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:34:15 | INFO | train_inner | epoch 045:     97 / 157 loss=6.779, nll_loss=2.658, ppl=6.31, wps=36610.8, ups=1.43, wpb=25640.8, bsz=1040.4, num_updates=7000, lr=0.000377964, gnorm=0.332, loss_scale=4, train_wall=31, gb_free=14.6, wall=4063
2022-03-23 10:34:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:34:37 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:34:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:34:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 10:34:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:34:44 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of india that will transcend two new pigs.
2022-03-23 10:34:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:34:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:34:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:34:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all its thoughts are on the track.
2022-03-23 10:34:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:34:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:34:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:35:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements are using energy, and that's how the superconducting is disturbing.
2022-03-23 10:35:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:35:04 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constraints of the face and the basic shape, and then refuse it through the information that refers the whole porn structure and all the fin folds.
2022-03-23 10:35:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:35:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn to men on your table and tell them, 'when the revolution begins, we support you.'" the truth, women, we've been supporting you for a long time. "
2022-03-23 10:35:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:35:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention still is the mother of invention, and a large part of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuously variable drive and a refrigerator system with fluid that allows us to use an aircraft in the stop-go-traffic to a specific passenger, either run the propeller, or when you see the tragic of the ground, until you see the tragically drifted by a mechanism.
2022-03-23 10:35:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:35:11 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 7.011 | nll_loss 2.704 | ppl 6.52 | bleu 33.88 | wps 4801.5 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.88
2022-03-23 10:35:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 10:35:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:35:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:35:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 45 @ 7060 updates, score 33.88) (writing took 1.7640107670013094 seconds)
2022-03-23 10:35:12 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 10:35:12 | INFO | train | epoch 045 | loss 6.794 | nll_loss 2.683 | ppl 6.42 | wps 44408.1 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.344 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 4121
2022-03-23 10:35:13 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 10:35:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:35:25 | INFO | train_inner | epoch 046:     40 / 157 loss=6.808, nll_loss=2.703, ppl=6.51, wps=34335.3, ups=1.41, wpb=24304.7, bsz=957.9, num_updates=7100, lr=0.000375293, gnorm=0.351, loss_scale=4, train_wall=30, gb_free=14.3, wall=4134
2022-03-23 10:35:57 | INFO | train_inner | epoch 046:    140 / 157 loss=6.776, nll_loss=2.654, ppl=6.3, wps=81223, ups=3.19, wpb=25441.7, bsz=1021.5, num_updates=7200, lr=0.000372678, gnorm=0.331, loss_scale=4, train_wall=31, gb_free=13.6, wall=4165
2022-03-23 10:36:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:36:05 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:36:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:36:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i guess most of you know.
2022-03-23 10:36:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:36:13 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks beds that will transcend two new pigs.
2022-03-23 10:36:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:36:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pepper.
2022-03-23 10:36:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:36:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:36:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:36:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent of people taking responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:36:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:36:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move because their movements are using energy, and that's how the superconducting is disturbing.
2022-03-23 10:36:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:36:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constraints of the face and refers it through the basic information that refers all the porn structure and all the fine folds.
2022-03-23 10:36:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:36:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to men on your table and say to them," if the revolution begins, then we support you. "'" the truth, love women, we've been supporting you for a long time. at rachel carel spring, we've been best summarized at the future to download our sandstone works and say, "'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'"
2022-03-23 10:36:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:36:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the great part of the design work that we're at our plane is the result that we had to solve the unique problems that were connected to doing it on the ground -- all, from a continuous variables and refrigeration system with fluid, that it allows us to use an aircraft on the stop and go-traffic to a special passage, was either propeller, or when you look at the ground, or when you see the same as we're going to the security system.
2022-03-23 10:36:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:36:39 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 7.031 | nll_loss 2.694 | ppl 6.47 | bleu 33.53 | wps 4926 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 33.88
2022-03-23 10:36:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-23 10:36:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:36:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:36:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 46 @ 7217 updates, score 33.53) (writing took 0.8742090570012806 seconds)
2022-03-23 10:36:40 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 10:36:40 | INFO | train | epoch 046 | loss 6.78 | nll_loss 2.66 | ppl 6.32 | wps 45317.2 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.343 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 4208
2022-03-23 10:36:40 | INFO | fairseq.trainer | begin training epoch 47
2022-03-23 10:36:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:37:06 | INFO | train_inner | epoch 047:     83 / 157 loss=6.758, nll_loss=2.625, ppl=6.17, wps=36182.9, ups=1.44, wpb=25147.5, bsz=1057.7, num_updates=7300, lr=0.000370117, gnorm=0.341, loss_scale=4, train_wall=31, gb_free=13.8, wall=4235
2022-03-23 10:37:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:37:33 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep beep up in the clinic.
2022-03-23 10:37:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:37:36 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:37:36 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:37:40 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:37:40 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:37:44 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pepper.
2022-03-23 10:37:44 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:37:48 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:37:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:37:52 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent of people taking responsibility for wildlife, the number of wild animals grew back. and this has become a foundation for conservation in namibia.
2022-03-23 10:37:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:37:56 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like to move because their movements use energy to disrupt the superconductor.
2022-03-23 10:37:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:38:00 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constraints of the face, and then refuse it through that information that refers the whole porn structure and all the fine folds.
2022-03-23 10:38:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:38:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me here at tedwomen is that... well, in strict dinner, it was best summarized when someone said, "turn you to the men on your table and tell them, 'when the revolution begins, we support you.' '" the truth, women are already supporting you for a long time. "
2022-03-23 10:38:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:38:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our plane at the stumbling toes, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously variable, and a cooling system with liquid, that allows us to use an aircraft machine in the stop and go-traffic to a special passage, either when you see the propmatic space.
2022-03-23 10:38:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:38:05 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 7.012 | nll_loss 2.712 | ppl 6.55 | bleu 33.73 | wps 5102.3 | wpb 17862.2 | bsz 728.3 | num_updates 7374 | best_bleu 33.88
2022-03-23 10:38:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 7374 updates
2022-03-23 10:38:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:38:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:38:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 47 @ 7374 updates, score 33.73) (writing took 0.871312224000576 seconds)
2022-03-23 10:38:06 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-23 10:38:06 | INFO | train | epoch 047 | loss 6.762 | nll_loss 2.632 | ppl 6.2 | wps 45879.3 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 7374 | lr 0.000368255 | gnorm 0.327 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 4294
2022-03-23 10:38:06 | INFO | fairseq.trainer | begin training epoch 48
2022-03-23 10:38:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:38:14 | INFO | train_inner | epoch 048:     26 / 157 loss=6.758, nll_loss=2.626, ppl=6.17, wps=36720.7, ups=1.46, wpb=25089, bsz=1043, num_updates=7400, lr=0.000367607, gnorm=0.341, loss_scale=4, train_wall=30, gb_free=13.6, wall=4303
2022-03-23 10:38:46 | INFO | train_inner | epoch 048:    126 / 157 loss=6.761, nll_loss=2.629, ppl=6.18, wps=80804.1, ups=3.15, wpb=25678, bsz=966, num_updates=7500, lr=0.000365148, gnorm=0.303, loss_scale=4, train_wall=31, gb_free=14, wall=4335
2022-03-23 10:38:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:39:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-23 10:39:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:39:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:39:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:39:08 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks in india that will transcend two new pigs.
2022-03-23 10:39:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:39:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:39:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:39:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:39:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:39:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent of how people have taken responsibility for wildlife, the number of wildlife grew up again, and that has become a basis for conservation in namibia.
2022-03-23 10:39:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:39:24 | INFO | fairseq.tasks.translation | example hypothesis: first, a couple of strands of magnetic field are trapped inside, but the superconductor doesn't like it, if you move, because your movements use your energy, and so the superconductive.
2022-03-23 10:39:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:39:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constraints of the face and gives it back to the basic shape, and refuses it through the information that refers the entire porn structure and all the fine wrinkles.
2022-03-23 10:39:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:39:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate to be here at tedwomen is that... well, when dinner got the best summarized when someone said, "turn to the men on your table and tell them," if the revolution begins, then we support you. '"the truth, women, we've been supporting you for a long time."
2022-03-23 10:39:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:39:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention, and a large part of the design work that we're on our airplane the most proud of, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuously variable process and a refrigerator system with liquid that allows us to use an aircraft machine in the stop and go-traffic to a specially appropriate passage, that either drives the propeller, or when you see the proprophecy system that you can see that you can see on the ground, or when you can see that you can see the propheart-to-fly, or when you can see that's going to the ground, or when you can see that's going to fly, that's going to fly, that's going to the propropmatic space that you can see that you can see that you can see that you can see that's going to the ground, or when you can see that's going to fly that's the
2022-03-23 10:39:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:39:34 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 7.001 | nll_loss 2.696 | ppl 6.48 | bleu 34.04 | wps 4885.4 | wpb 17862.2 | bsz 728.3 | num_updates 7531 | best_bleu 34.04
2022-03-23 10:39:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 7531 updates
2022-03-23 10:39:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:39:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:39:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 48 @ 7531 updates, score 34.04) (writing took 1.8011906609899597 seconds)
2022-03-23 10:39:36 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-23 10:39:36 | INFO | train | epoch 048 | loss 6.75 | nll_loss 2.612 | ppl 6.11 | wps 43848.9 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 7531 | lr 0.000364396 | gnorm 0.333 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 4384
2022-03-23 10:39:36 | INFO | fairseq.trainer | begin training epoch 49
2022-03-23 10:39:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:39:58 | INFO | train_inner | epoch 049:     69 / 157 loss=6.74, nll_loss=2.596, ppl=6.05, wps=34065.8, ups=1.4, wpb=24399, bsz=1004.6, num_updates=7600, lr=0.000362738, gnorm=0.344, loss_scale=4, train_wall=30, gb_free=14.1, wall=4406
2022-03-23 10:40:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:40:29 | INFO | fairseq.tasks.translation | example hypothesis: we put those beep in the clinic.
2022-03-23 10:40:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:40:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:40:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:40:37 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks in india that will transcend two new pigs.
2022-03-23 10:40:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:40:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and pepper.
2022-03-23 10:40:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:40:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:40:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:40:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the face of how people took responsibility for wildlife, the number of wildlife grew again, and this has become a foundation for conservation in namibia.
2022-03-23 10:40:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:40:52 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move because their movements are using energy, and that's how the superconductive disorder is disturbing.
2022-03-23 10:40:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:40:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which refers the big constraints of the face and refers it through the information that refers the whole porn structure and all the wrinkles.
2022-03-23 10:40:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:41:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me here at tedwomen is that -- well, when dinner was best summarized, when someone said, "turn you to the men on your table and tell them," if the revolution begins, then we support you. "the truth, women are already supporting you for a long time.
2022-03-23 10:41:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:41:01 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we're on our airplane at the stumbling toes, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously variable drives and a cooling system with liquid, that it allows us to use an aircraft in stop and go-traffic to a special passage, which is either propelled, or when you see the propelled or when you see the tragic space.
2022-03-23 10:41:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:41:01 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 7.004 | nll_loss 2.709 | ppl 6.54 | bleu 33.86 | wps 5111.9 | wpb 17862.2 | bsz 728.3 | num_updates 7688 | best_bleu 34.04
2022-03-23 10:41:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 7688 updates
2022-03-23 10:41:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:41:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:41:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 49 @ 7688 updates, score 33.86) (writing took 0.8461826449929504 seconds)
2022-03-23 10:41:02 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-23 10:41:02 | INFO | train | epoch 049 | loss 6.734 | nll_loss 2.588 | ppl 6.01 | wps 45608 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 7688 | lr 0.000360656 | gnorm 0.318 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 4471
2022-03-23 10:41:03 | INFO | fairseq.trainer | begin training epoch 50
2022-03-23 10:41:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:41:07 | INFO | train_inner | epoch 050:     12 / 157 loss=6.73, nll_loss=2.584, ppl=6, wps=37176.8, ups=1.45, wpb=25586.8, bsz=1069, num_updates=7700, lr=0.000360375, gnorm=0.32, loss_scale=4, train_wall=30, gb_free=14.7, wall=4475
2022-03-23 10:41:38 | INFO | train_inner | epoch 050:    112 / 157 loss=6.719, nll_loss=2.563, ppl=5.91, wps=80968.8, ups=3.19, wpb=25420, bsz=1059.8, num_updates=7800, lr=0.000358057, gnorm=0.326, loss_scale=4, train_wall=31, gb_free=13.7, wall=4507
2022-03-23 10:41:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:41:55 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:41:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:41:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know.
2022-03-23 10:41:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:42:04 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 10:42:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:42:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pepper.
2022-03-23 10:42:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:42:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:42:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:42:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the face of how people took responsibility for wildlife, the number of wildlife grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:42:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:42:19 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements are using energy, and so the superconducting iron.
2022-03-23 10:42:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:42:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constraints of the face, and then refuses it through the information that's coming from the whole porn structure and all the fine folds.
2022-03-23 10:42:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:42:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, the best summarized when someone said, "turn you to the men on your table and say to them, 'if the revolution begins, we support you.'" 'the truth, women is that we've been supporting you in this topic for a long time.
2022-03-23 10:42:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:42:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, we still have the mother of invention, and a lot of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to doing it on the ground -- all, from a continuously variable operating and a refrigerator system with liquid liquid, that it allows us to use an aircraft in the stop and go-traffic to a particularly passing experience that either drives the propelled when you or when you fly the prophedrum or when you see in the ground, until you see in a car storage of a steady way that's going to the tragic system that's going to the car storm, until you see that's going to the ground, until you see that's a steady storm that's going to the wrong thing that's going to the car storage in the ground, until you see that's going to the bottom up until you see in the tragic gic gic gic gic case that's going to the ground
2022-03-23 10:42:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:42:30 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 6.99 | nll_loss 2.682 | ppl 6.42 | bleu 34.12 | wps 4769.9 | wpb 17862.2 | bsz 728.3 | num_updates 7845 | best_bleu 34.12
2022-03-23 10:42:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 7845 updates
2022-03-23 10:42:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:42:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:42:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 50 @ 7845 updates, score 34.12) (writing took 1.8053036740020616 seconds)
2022-03-23 10:42:32 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-23 10:42:32 | INFO | train | epoch 050 | loss 6.723 | nll_loss 2.57 | ppl 5.94 | wps 44232.4 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 7845 | lr 0.000357029 | gnorm 0.324 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 4560
2022-03-23 10:42:32 | INFO | fairseq.trainer | begin training epoch 51
2022-03-23 10:42:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:42:49 | INFO | train_inner | epoch 051:     55 / 157 loss=6.715, nll_loss=2.556, ppl=5.88, wps=34914.4, ups=1.4, wpb=24912.1, bsz=989.4, num_updates=7900, lr=0.000355784, gnorm=0.315, loss_scale=4, train_wall=30, gb_free=14.8, wall=4578
2022-03-23 10:43:20 | INFO | train_inner | epoch 051:    155 / 157 loss=6.713, nll_loss=2.555, ppl=5.88, wps=81457.5, ups=3.24, wpb=25169.7, bsz=1006.8, num_updates=8000, lr=0.000353553, gnorm=0.326, loss_scale=4, train_wall=31, gb_free=13.5, wall=4609
2022-03-23 10:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:43:25 | INFO | fairseq.tasks.translation | example hypothesis: we set up these betards in the clinic.
2022-03-23 10:43:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:43:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline by doha, probably most of you know here.
2022-03-23 10:43:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:43:32 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 10:43:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:43:36 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:43:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:43:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:43:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:43:44 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent of people taking responsibility for wildlife, the number of wildlife grew back. and this has become a basis for conservation in namibia.
2022-03-23 10:43:44 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:43:48 | INFO | fairseq.tasks.translation | example hypothesis: first, a couple of strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements are using energy, and so the superconducting system.
2022-03-23 10:43:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:43:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constraints of the face and reconcile it through the information that all the porn structure and all the fin folds.
2022-03-23 10:43:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:43:56 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me at tedwomen here is that... well, when dinner was best summarized, when someone said, "turn to men on your table and tell them," if the revolution begins, we support you. "'" the truth, women is that we've already been supporting you in this subject for a long time. rachel carson's spring, it was best summarized at the future, "well, we're going to go to grace our sand stream."
2022-03-23 10:43:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:43:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention, and a large part of the design work that we're the stumbling on our airplane was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuously variable operating and a cooling system with fluid, that it allows us to use an aircraft in the stop and go-traffic to a special passage, either propeller, or if you're flying, or if you're going to do the ground, or if you're going to do it, or if you're going to do it, or if you look at the tragic.
2022-03-23 10:43:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:43:58 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 7.004 | nll_loss 2.653 | ppl 6.29 | bleu 34.03 | wps 4926.8 | wpb 17862.2 | bsz 728.3 | num_updates 8002 | best_bleu 34.12
2022-03-23 10:43:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 8002 updates
2022-03-23 10:43:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:43:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:43:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 51 @ 8002 updates, score 34.03) (writing took 0.8708818540035281 seconds)
2022-03-23 10:43:59 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-23 10:43:59 | INFO | train | epoch 051 | loss 6.707 | nll_loss 2.545 | ppl 5.84 | wps 45230.4 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 8002 | lr 0.000353509 | gnorm 0.322 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 4648
2022-03-23 10:43:59 | INFO | fairseq.trainer | begin training epoch 52
2022-03-23 10:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:44:30 | INFO | train_inner | epoch 052:     98 / 157 loss=6.686, nll_loss=2.512, ppl=5.7, wps=36056.4, ups=1.44, wpb=25057.5, bsz=1065.7, num_updates=8100, lr=0.000351364, gnorm=0.341, loss_scale=4, train_wall=31, gb_free=13.6, wall=4678
2022-03-23 10:44:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:44:52 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:44:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:44:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you know here.
2022-03-23 10:44:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:45:00 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of india that will transcend two new pigs.
2022-03-23 10:45:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:45:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:45:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:45:07 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 10:45:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:45:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent of people's responsibility for wildlife revenues, the number of wildlife grew up again, and that has become a basis for conservation in namibia.
2022-03-23 10:45:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:45:15 | INFO | fairseq.tasks.translation | example hypothesis: first, a couple of strands of magnetic field are trapped inside, but the superconductor doesn't like the superconductor when they move, because their movements are harnessing energy, and so the superconductive.
2022-03-23 10:45:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:45:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constraints of the face and refers it through the information that all of the porn structure and all the fine wrinkles.
2022-03-23 10:45:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:45:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me here at tedwomen is that... well, in the strictly dinner, it's been the best summarized when someone said, "turn you to the men on your table and say," if the revolution begins, then we support you. '"'" the truth, love is that we've been supporting you with this topic for a long time. "
2022-03-23 10:45:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:45:25 | INFO | fairseq.tasks.translation | example hypothesis: luckily, still the mother of invention, and a big part of the design work that we were on on our plane at the stumbling toes was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuously variable, and a cooling system with liquid that allows us to use an aircraft machine in the stop-go-traffic to a special passenger either by the mechanism or if you look at the ground.
2022-03-23 10:45:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:45:25 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 6.974 | nll_loss 2.664 | ppl 6.34 | bleu 34.3 | wps 5036.2 | wpb 17862.2 | bsz 728.3 | num_updates 8159 | best_bleu 34.3
2022-03-23 10:45:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 8159 updates
2022-03-23 10:45:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:45:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:45:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 52 @ 8159 updates, score 34.3) (writing took 1.8485520929971244 seconds)
2022-03-23 10:45:26 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-23 10:45:26 | INFO | train | epoch 052 | loss 6.703 | nll_loss 2.538 | ppl 5.81 | wps 45134 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 8159 | lr 0.000350091 | gnorm 0.334 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 4735
2022-03-23 10:45:27 | INFO | fairseq.trainer | begin training epoch 53
2022-03-23 10:45:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:45:40 | INFO | train_inner | epoch 053:     41 / 157 loss=6.707, nll_loss=2.543, ppl=5.83, wps=35703.9, ups=1.42, wpb=25151.3, bsz=978.2, num_updates=8200, lr=0.000349215, gnorm=0.331, loss_scale=4, train_wall=31, gb_free=13.9, wall=4749
2022-03-23 10:46:11 | INFO | train_inner | epoch 053:    141 / 157 loss=6.703, nll_loss=2.539, ppl=5.81, wps=79803.8, ups=3.21, wpb=24894.4, bsz=1025.6, num_updates=8300, lr=0.000347105, gnorm=0.346, loss_scale=4, train_wall=31, gb_free=14.1, wall=4780
2022-03-23 10:46:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:46:20 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:46:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:46:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:46:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:46:28 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of india that will transcend two new pigs.
2022-03-23 10:46:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:46:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:46:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:46:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all your thoughts are on the track.
2022-03-23 10:46:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:46:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the face of how people took responsibility for wildlife, the number of wildlife grew back again, and that's become a basis for conservation in namibia.
2022-03-23 10:46:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:46:43 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductive.
2022-03-23 10:46:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:46:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constraints of the face and restore it through that information that refers the whole porn structure and all the fine wrinkles.
2022-03-23 10:46:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:46:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, at a strict dinner, it was best summarized when someone said, "turn you to men on your table and tell them," when the revolution begins, we support you. "'the truth, women are that we've been supporting you with this topic for a long time. at rael spring, with silent spring, borne's future to downharbor."
2022-03-23 10:46:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:46:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's need still to be the invention, and a lot of the design work that we're the most proud of on our airplane was a result that we had to solve the unique problems that were connected to doing it on the ground -- all, from a continuously variable drives and a cooling system of liquid that allows us to use an aircraft machine in the stop-go-traffic to a special passage that either drives the propeller or when you see the soil, to a mechanism, to the ground, to the deterioring the security system.
2022-03-23 10:46:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:46:52 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 6.973 | nll_loss 2.653 | ppl 6.29 | bleu 34.59 | wps 5060.5 | wpb 17862.2 | bsz 728.3 | num_updates 8316 | best_bleu 34.59
2022-03-23 10:46:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 8316 updates
2022-03-23 10:46:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:46:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt
2022-03-23 10:46:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_best.pt (epoch 53 @ 8316 updates, score 34.59) (writing took 1.894291948992759 seconds)
2022-03-23 10:46:54 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-23 10:46:54 | INFO | train | epoch 053 | loss 6.694 | nll_loss 2.525 | ppl 5.75 | wps 44918.7 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 8316 | lr 0.000346771 | gnorm 0.339 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 4823
2022-03-23 10:46:55 | INFO | fairseq.trainer | begin training epoch 54
2022-03-23 10:46:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:47:21 | INFO | train_inner | epoch 054:     84 / 157 loss=6.687, nll_loss=2.513, ppl=5.71, wps=36613.1, ups=1.44, wpb=25481.9, bsz=991, num_updates=8400, lr=0.000345033, gnorm=0.339, loss_scale=4, train_wall=31, gb_free=13.8, wall=4850
2022-03-23 10:47:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:47:47 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:47:47 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:47:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 10:47:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:47:55 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of india that will transcend two new pigs.
2022-03-23 10:47:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:47:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pepper.
2022-03-23 10:47:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:48:03 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:48:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:48:07 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent of people's responsibility for wildlife revenues, the number of wildlife regrew, and this has become a basis for conservation in namibia.
2022-03-23 10:48:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:48:11 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and that's how the superconducting disorder disturbs.
2022-03-23 10:48:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:48:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constraints of the face and gives it back through the information that comes from this mirror reflection, which refers the entire porn structure and all fine folds.
2022-03-23 10:48:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:48:18 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me here at tedwomen is that... well, when ratja was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins, we support you. '"the truth, women, is that we've been supporting you about this topic for a long time."
2022-03-23 10:48:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:48:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother still needs the invention, and a lot of the design work we're on on our plane is a result that we had to solve the unique problems that were connected to doing it on the ground -- all, from a continuously variable drive and refrigerator system with fluid that allows us to use an aircraft machine in stop and traffic, until a special passage that either drives the propeller or when you see on the ground.
2022-03-23 10:48:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:48:20 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 7 | nll_loss 2.678 | ppl 6.4 | bleu 34.15 | wps 5074.5 | wpb 17862.2 | bsz 728.3 | num_updates 8473 | best_bleu 34.59
2022-03-23 10:48:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 8473 updates
2022-03-23 10:48:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:48:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:48:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 54 @ 8473 updates, score 34.15) (writing took 0.8669700099999318 seconds)
2022-03-23 10:48:21 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-23 10:48:21 | INFO | train | epoch 054 | loss 6.682 | nll_loss 2.505 | ppl 5.68 | wps 45813.3 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 8473 | lr 0.000343543 | gnorm 0.342 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 4909
2022-03-23 10:48:21 | INFO | fairseq.trainer | begin training epoch 55
2022-03-23 10:48:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:48:30 | INFO | train_inner | epoch 055:     27 / 157 loss=6.671, nll_loss=2.489, ppl=5.61, wps=36854.1, ups=1.46, wpb=25284.2, bsz=1058, num_updates=8500, lr=0.000342997, gnorm=0.331, loss_scale=4, train_wall=31, gb_free=13.4, wall=4918
2022-03-23 10:49:01 | INFO | train_inner | epoch 055:    127 / 157 loss=6.683, nll_loss=2.507, ppl=5.68, wps=80749.1, ups=3.22, wpb=25067.6, bsz=963.8, num_updates=8600, lr=0.000340997, gnorm=0.338, loss_scale=4, train_wall=31, gb_free=14.7, wall=4949
2022-03-23 10:49:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:49:13 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleeds in the clinic.
2022-03-23 10:49:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:49:17 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which i think most people know here.
2022-03-23 10:49:17 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:49:21 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of india that will transcend two new pigs.
2022-03-23 10:49:21 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:49:25 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:49:25 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:49:29 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:49:29 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:49:33 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent that people have taken responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:49:33 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:49:37 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move because their movements use energy, and so the superconducting system.
2022-03-23 10:49:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:49:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constraints of the face and gives it back to the basic shape, and then add it into that information that refers all the porn structure and all the fine wrinkles.
2022-03-23 10:49:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:49:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, at the controversial dinner, it was best summarized when someone said, "turn you to the men on your table and tell you," if the revolution starts, we support you. "'the truth, women, is that we've been supporting you with this topic for a long time. at rachson carel spring," and then our future stumbled to grave sandstone plants. "
2022-03-23 10:49:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:49:47 | INFO | fairseq.tasks.translation | example hypothesis: luckily, still the mother of invention, and a large part of the design work that we're on on on our plane is a result that we had to solve the unique problems that were connected to doing it on the ground -- all, from a continuously variable drive and a cooling system to allow us to use an aircraft in stop-go-traffic, to a particular passage that either drives the propeller or when you see it on the ground, or when you see it's on a mechanism, to the ground, to the security system, to the security facility of a car storm, to which is to the decrease, until we see if you get rid of a mechanism, to the ground, until we get rid of a steady stored, to the ground, to the ground, to the decrease, to the decrease, to the decrease, until we're going to the decrease, until we're going to the decrease, to the security
2022-03-23 10:49:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:49:47 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 6.986 | nll_loss 2.644 | ppl 6.25 | bleu 34.13 | wps 4826.2 | wpb 17862.2 | bsz 728.3 | num_updates 8630 | best_bleu 34.59
2022-03-23 10:49:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 8630 updates
2022-03-23 10:49:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:49:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:49:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 55 @ 8630 updates, score 34.13) (writing took 0.8586948260053759 seconds)
2022-03-23 10:49:48 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-23 10:49:48 | INFO | train | epoch 055 | loss 6.67 | nll_loss 2.488 | ppl 5.61 | wps 44990.8 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 8630 | lr 0.000340404 | gnorm 0.332 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 4997
2022-03-23 10:49:49 | INFO | fairseq.trainer | begin training epoch 56
2022-03-23 10:49:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:50:11 | INFO | train_inner | epoch 056:     70 / 157 loss=6.667, nll_loss=2.481, ppl=5.58, wps=35076.6, ups=1.43, wpb=24477.2, bsz=993.4, num_updates=8700, lr=0.000339032, gnorm=0.342, loss_scale=4, train_wall=30, gb_free=13.7, wall=5019
2022-03-23 10:50:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:50:41 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:50:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:50:45 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most people here know.
2022-03-23 10:50:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:50:49 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 10:50:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:50:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pepper.
2022-03-23 10:50:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:50:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all your thoughts are on the track.
2022-03-23 10:50:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:51:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the face of people's responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:51:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:51:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and the superconducting disorder.
2022-03-23 10:51:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:51:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constraints of the face and gives it the basic shape, and adding it through the information that refers the whole porn structure and all of the wrinkles.
2022-03-23 10:51:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:51:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me here at tedwomen is that... well, at the strict dinner, it was best summarized when someone said, "turn to the men on your table and tell them," if the revolution begins, we support you. "the truth, women are supporting you for a long time.
2022-03-23 10:51:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:51:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still in the invention, and a large part of the design work that we're the most proud of in our airplane, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuously variable drives and a cooling system with liquid that allows us to use an aircraft machine in the stop and traffic to a special passage that either drives the propeller or when you're on the ground to see it.
2022-03-23 10:51:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:51:13 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 6.98 | nll_loss 2.662 | ppl 6.33 | bleu 34.29 | wps 5140.1 | wpb 17862.2 | bsz 728.3 | num_updates 8787 | best_bleu 34.59
2022-03-23 10:51:13 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:51:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 8787 updates
2022-03-23 10:51:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:51:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt
2022-03-23 10:51:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#1/checkpoint_last.pt (epoch 56 @ 8787 updates, score 34.29) (writing took 0.9654739539982984 seconds)
2022-03-23 10:51:14 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-23 10:51:14 | INFO | train | epoch 056 | loss 6.662 | nll_loss 2.473 | ppl 5.55 | wps 46095.3 | ups 1.83 | wpb 25153.6 | bsz 1020.6 | num_updates 8787 | lr 0.000337349 | gnorm 0.332 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 5083
2022-03-23 10:51:14 | INFO | fairseq_cli.train | done training in 5082.2 seconds
