Sender: LSF System <lsfadmin@eu-g3-060>
Subject: Job 210581519: <iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:25:06 2022
Job was executed on host(s) <eu-g3-060>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:25:23 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:25:23 2022
Terminated at Wed Mar 23 10:50:00 2022
Results reported at Wed Mar 23 10:50:00 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.3 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5068.33 sec.
    Max Memory :                                 5138 MB
    Average Memory :                             3889.51 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14862.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   5077 sec.
    Turnaround time :                            5094 sec.

The output (if any) follows:

2022-03-23 09:25:30 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.3, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.3, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:25:30 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:25:30 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:25:30 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:25:30 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:25:30 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:25:30 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:25:30 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:25:30 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:25:30 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:25:30 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:25:30 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:25:33 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:25:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:25:33 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:25:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:25:33 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:25:33 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:25:33 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 09:25:33 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 09:25:33 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:25:33 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:25:33 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:25:33 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:25:33 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:25:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:25:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:25:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:25:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:25:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:26:08 | INFO | train_inner | epoch 001:    104 / 157 loss=12.341, nll_loss=11.865, ppl=3729.2, wps=80432.3, ups=3.2, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=2.542, loss_scale=8, train_wall=35, gb_free=14, wall=36
2022-03-23 09:26:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:26:28 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 09:26:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:26:31 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:26:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:26:33 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,....
2022-03-23 09:26:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:26:36 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,
2022-03-23 09:26:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:26:40 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:40 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:26:45 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:26:51 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:26:56 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:27:03 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:27:06 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:27:06 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.062 | nll_loss 10.027 | ppl 1043.56 | bleu 0.01 | wps 4324.3 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:27:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:27:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:27:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:27:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.6009356580034364 seconds)
2022-03-23 09:27:07 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:27:07 | INFO | train | epoch 001 | loss 12.004 | nll_loss 11.384 | ppl 2673.33 | wps 42456.7 | ups 1.69 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 2.023 | loss_scale 8 | train_wall 50 | gb_free 22.4 | wall 94
2022-03-23 09:27:07 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:27:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:27:22 | INFO | train_inner | epoch 002:     47 / 157 loss=11.183, nll_loss=10.22, ppl=1192.38, wps=34231.9, ups=1.35, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=0.987, loss_scale=8, train_wall=30, gb_free=14.7, wall=110
2022-03-23 09:27:54 | INFO | train_inner | epoch 002:    147 / 157 loss=10.688, nll_loss=9.461, ppl=704.99, wps=80501.8, ups=3.2, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=1.069, loss_scale=8, train_wall=31, gb_free=14, wall=141
2022-03-23 09:27:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:28:00 | INFO | fairseq.tasks.translation | example hypothesis: we we we.
2022-03-23 09:28:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:28:03 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the.
2022-03-23 09:28:03 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:28:08 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the the the the.
2022-03-23 09:28:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:28:12 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:28:18 | INFO | fairseq.tasks.translation | example hypothesis: and and we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:28:23 | INFO | fairseq.tasks.translation | example hypothesis: and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:28:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:28:29 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:28:35 | INFO | fairseq.tasks.translation | example hypothesis: and and and we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:28:42 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:28:44 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:28:44 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 10.455 | nll_loss 9.009 | ppl 515.12 | bleu 0.01 | wps 3682.7 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.01
2022-03-23 09:28:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:28:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:28:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:28:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.01) (writing took 1.6603354120015865 seconds)
2022-03-23 09:28:46 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:28:46 | INFO | train | epoch 002 | loss 10.771 | nll_loss 9.594 | ppl 772.93 | wps 40058.6 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.017 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 193
2022-03-23 09:28:46 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:28:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:29:14 | INFO | train_inner | epoch 003:     90 / 157 loss=10.494, nll_loss=9.128, ppl=559.32, wps=30549.9, ups=1.24, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=1.014, loss_scale=8, train_wall=30, gb_free=13.7, wall=221
2022-03-23 09:29:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:29:38 | INFO | fairseq.tasks.translation | example hypothesis: we the the the.
2022-03-23 09:29:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:29:42 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the.
2022-03-23 09:29:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:29:46 | INFO | fairseq.tasks.translation | example hypothesis: and the the the of the of the the of the of the.
2022-03-23 09:29:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:29:50 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, and it's, and it's's, and it's's's.
2022-03-23 09:29:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:29:55 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, and it's's's, and it's's's, and it's's, and it's's, and it's's's's's's's's.
2022-03-23 09:29:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:30:00 | INFO | fairseq.tasks.translation | example hypothesis: and and and the the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:30:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:30:06 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, and it's, and it's, and it's, it's, and it's, and it's's's's's's's, it's, and it's, and it's, and it's, and it's's's's's's, and it's, and it's's's's's's
2022-03-23 09:30:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:30:12 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, and we, and we, and we, and we, and we, and the the the the, and the the the the the, and the the, and we, and we, and we, and we, and we, and the the the, and the the, and the the the, and the the the, and the the the the the the the the the the the, and the the the, and the the
2022-03-23 09:30:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:30:20 | INFO | fairseq.tasks.translation | example hypothesis: and it's, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:30:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:30:22 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, the the the the the the the, we, we, we, we, the the the the the the the a a a a a a a a a a a a a, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the, and the to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to,
2022-03-23 09:30:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:30:22 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.301 | nll_loss 8.724 | ppl 422.79 | bleu 0.18 | wps 3726.6 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.18
2022-03-23 09:30:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 09:30:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:30:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:30:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.18) (writing took 1.6738000730110798 seconds)
2022-03-23 09:30:24 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:30:24 | INFO | train | epoch 003 | loss 10.439 | nll_loss 9.04 | ppl 526.34 | wps 40304.8 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 1.081 | loss_scale 8 | train_wall 48 | gb_free 13.7 | wall 291
2022-03-23 09:30:24 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:30:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:30:35 | INFO | train_inner | epoch 004:     33 / 157 loss=10.338, nll_loss=8.882, ppl=471.71, wps=31549, ups=1.24, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.071, loss_scale=8, train_wall=31, gb_free=13.9, wall=302
2022-03-23 09:31:06 | INFO | train_inner | epoch 004:    133 / 157 loss=10.183, nll_loss=8.643, ppl=399.74, wps=80751.2, ups=3.2, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.143, loss_scale=8, train_wall=31, gb_free=12.6, wall=333
2022-03-23 09:31:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:31:17 | INFO | fairseq.tasks.translation | example hypothesis: we're the world in the world.
2022-03-23 09:31:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:31:21 | INFO | fairseq.tasks.translation | example hypothesis: this is that's the world of the world of the world.
2022-03-23 09:31:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:31:25 | INFO | fairseq.tasks.translation | example hypothesis: now, we're the world of the world.
2022-03-23 09:31:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:31:30 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, and it's a of the world.
2022-03-23 09:31:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:31:35 | INFO | fairseq.tasks.translation | example hypothesis: and it's a that we're not not not not not not not not not not that we're not not not not not not not not not not not not not not not not not not not not not not that we have.
2022-03-23 09:31:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:31:40 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world, and in the world of the world of the world, and the world of the world, and the world of the world, and the world, and the world of the world, and the world of the world.
2022-03-23 09:31:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:31:46 | INFO | fairseq.tasks.translation | example hypothesis: but they're are the world, but it's the world, but it's the world, but it's the world, but it's the world, but it's the world, but they are are are are are are are are are are are are are are are are the world.
2022-03-23 09:31:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:31:52 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can see the world, and we're the world, and we can can can can can can can can can can can can can can can can can can see the world of the world of the world of the world of the world of the world of the world, and the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see
2022-03-23 09:31:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:32:00 | INFO | fairseq.tasks.translation | example hypothesis: and "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:32:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:32:02 | INFO | fairseq.tasks.translation | example hypothesis: so, so, we have to have a a a a a a, and we have to be a to be a a a a a a a of the world, and we have to have to have to have to have to be, and we have to be to be a a a a a a a a a of the world, and we have to have to have to be to have to have to be be be be a a a a a a of the world, and we have, and we have to have to be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be to be be be be be be to be, which, which, which, and we've've've've've've've've've've've've've've've've've, which, and we have to be be be be be be be be be be be be be be be be be be be be be
2022-03-23 09:32:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:32:02 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 9.93 | nll_loss 8.141 | ppl 282.28 | bleu 0.94 | wps 3611.8 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.94
2022-03-23 09:32:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 09:32:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:32:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:32:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.94) (writing took 1.678804825001862 seconds)
2022-03-23 09:32:04 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:32:04 | INFO | train | epoch 004 | loss 10.185 | nll_loss 8.648 | ppl 401.14 | wps 39490.7 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.086 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 391
2022-03-23 09:32:04 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:32:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:32:28 | INFO | train_inner | epoch 005:     76 / 157 loss=10.015, nll_loss=8.383, ppl=333.91, wps=30038.5, ups=1.22, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.324, loss_scale=8, train_wall=30, gb_free=13.4, wall=415
2022-03-23 09:32:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:32:57 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 09:32:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:33:00 | INFO | fairseq.tasks.translation | example hypothesis: this is this is the world.
2022-03-23 09:33:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:33:04 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be to be a lot of the world.
2022-03-23 09:33:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:33:09 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot, there's a lot.
2022-03-23 09:33:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:33:14 | INFO | fairseq.tasks.translation | example hypothesis: and it's not not not that we're not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not that that we're going
2022-03-23 09:33:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:33:19 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of the world, and in the world, and in the world, and in the world in the world, and the world in the world, and the world in the world in the world, and the world in the world, and the world, and the world,
2022-03-23 09:33:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:33:25 | INFO | fairseq.tasks.translation | example hypothesis: but it's not not not not not not not not not a lot, but but they're not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not a lot, but but they're a lot, but they're a lot, but they're not not not not
2022-03-23 09:33:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:33:31 | INFO | fairseq.tasks.translation | example hypothesis: and if we're a lot of the world, we can see the world, and we're a lot of the world, and we're a lot of the world, and we're a lot of the world, and we can see the world, and we're a lot of the world, and we're the world, and we can see the world, and we're going to be a lot of the world, and we're going to see the world, and
2022-03-23 09:33:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:33:39 | INFO | fairseq.tasks.translation | example hypothesis: and this is that we're going to say, "it's a lot of the world," it's a lot of the world, "that we're going to say," that we're going to say, "" "that we're a lot of the world," it's a lot of the world, "it's a lot of the world," that we have to be a lot of the world, "that we're going to be the world," "" "" "" "" "" "it's a lot of the world," that we're going to say, "it's going to do it's a lot of the world," it's a lot of the world, "it's a lot of the world," that we're going to be a lot of the world, "it's a lot of the world," "" "" "
2022-03-23 09:33:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:33:41 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to be a lot of the world, and we're a lot of the world that we have to be a lot of the world that we're going to be a lot of the world that we have to be a lot of the world of the world, and the world that we're the world that we have to be a lot of the world that we have to be a lot of the world that we're going to be a lot of the world that we have to be a lot of the world that we're the world that we have to be a lot of the world that we're going to make the world that we have to do that we have to do that we have to be a lot of the world that we have to be a lot of the world, and the world that we have to be the world that we have to make the world that we have to make the world that we have to make the world that we have to make the world that we have to get the world that we have to make the world that we have
2022-03-23 09:33:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:33:41 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.66 | nll_loss 7.74 | ppl 213.76 | bleu 1.36 | wps 3651.9 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.36
2022-03-23 09:33:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 09:33:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:33:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:33:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.36) (writing took 1.6864033989986638 seconds)
2022-03-23 09:33:43 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:33:43 | INFO | train | epoch 005 | loss 9.893 | nll_loss 8.191 | ppl 292.21 | wps 39700.6 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.222 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 491
2022-03-23 09:33:44 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:33:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:33:49 | INFO | train_inner | epoch 006:     19 / 157 loss=9.812, nll_loss=8.065, ppl=267.76, wps=31092.5, ups=1.23, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=1.183, loss_scale=8, train_wall=30, gb_free=14.6, wall=497
2022-03-23 09:34:21 | INFO | train_inner | epoch 006:    119 / 157 loss=9.68, nll_loss=7.85, ppl=230.8, wps=81175.2, ups=3.21, wpb=25320.5, bsz=1021.9, num_updates=900, lr=0.0001125, gnorm=1.101, loss_scale=8, train_wall=31, gb_free=13.7, wall=528
2022-03-23 09:34:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:34:36 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 09:34:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:34:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the most thing that is that the most thing is that is that's here.
2022-03-23 09:34:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:34:45 | INFO | fairseq.tasks.translation | example hypothesis: we're going to have to be a lot of new new new lot of the world.
2022-03-23 09:34:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:34:49 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world, and there's a lot of the world.
2022-03-23 09:34:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:34:55 | INFO | fairseq.tasks.translation | example hypothesis: and it's not that we're going to do that we're going to do it's going to do that we're going to do that we're going to do it's going to do it's going to do it's going to do it
2022-03-23 09:34:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:35:00 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of people in the world, and in the world, and in the world, and people are in the world in the world, and in the world, and people are in the world in the world in the world in the world, and people in the world, and
2022-03-23 09:35:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:35:06 | INFO | fairseq.tasks.translation | example hypothesis: but they're going to see, but they're going to be a lot of the world, but they're not going to be a lot of the world, but they're going to be going to be not not going to be a lot of the world, but they're going to be a lot of that they're going to see that they're going to
2022-03-23 09:35:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:35:12 | INFO | fairseq.tasks.translation | example hypothesis: and if we can see that we're going to see that we're going to see that we're going to see that we're going to get a lot of the world, and then we're going to see that we're going to see that we're going to get a lot of the world, and then we're going to see that we're going to see that we're going to see that we're going to see that we're going to see the world,
2022-03-23 09:35:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:35:20 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" "" "" it's a lot of this is, "" "" it's going to say, "" "" "" it's going to say, "" "" "" "it's a lot of this is," it's going to say, "" "" "" "it's going to say," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "it's a" "" it's a first first first first first first first first first first first first first first first first first first first first first "
2022-03-23 09:35:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:35:22 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of fact that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to be a lot of the world, but it's going to do that we're going to do that we're going to do that we're going to do it's going to do that we're going to do that we're going to be a lot of this is a little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little bit of that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going
2022-03-23 09:35:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:35:22 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.464 | nll_loss 7.361 | ppl 164.34 | bleu 1.56 | wps 3536.2 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.56
2022-03-23 09:35:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 09:35:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:35:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:35:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 6 @ 938 updates, score 1.56) (writing took 1.7800566670048283 seconds)
2022-03-23 09:35:24 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:35:24 | INFO | train | epoch 006 | loss 9.665 | nll_loss 7.828 | ppl 227.16 | wps 39144.8 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 1.13 | loss_scale 8 | train_wall 48 | gb_free 14.7 | wall 591
2022-03-23 09:35:24 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:35:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:35:44 | INFO | train_inner | epoch 007:     62 / 157 loss=9.526, nll_loss=7.612, ppl=195.63, wps=30295, ups=1.2, wpb=25195.5, bsz=1022.5, num_updates=1000, lr=0.000125, gnorm=1.038, loss_scale=8, train_wall=30, gb_free=13.5, wall=611
2022-03-23 09:36:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:36:17 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see this.
2022-03-23 09:36:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:36:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the first thing that you're going to see the most most of the most of the most of the world.
2022-03-23 09:36:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:36:25 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to be going to be a new new new new new new new new new new new new new.
2022-03-23 09:36:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:36:30 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of course, and there's a lot, and there's going to be going to be going to be going to be a lot.
2022-03-23 09:36:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:36:35 | INFO | fairseq.tasks.translation | example hypothesis: it's it's not that we're not going to do that we're going to do that we're going to do that we're going to be going to do it's going to be going to be going to do and we're going to
2022-03-23 09:36:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:36:40 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in fact, in the people who is a lot of people, and people who is a lot of people in the world, and the world, and it's a lot of people who is a lot of people in the world.
2022-03-23 09:36:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:36:46 | INFO | fairseq.tasks.translation | example hypothesis: now, if you're going to get a lot of the same way, but they're not not going to be able to be a lot of the world, but they're going to be able to be able to be able to be able, but they're going to be able to be able to be able to be able to be able to be able to
2022-03-23 09:36:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:36:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take a lot of the world, and we're going to make a lot of the world, and we can see that we can see that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to make a lot of the world and then
2022-03-23 09:36:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:37:00 | INFO | fairseq.tasks.translation | example hypothesis: and then, if we said, "we said," you're going to say, "you know," you know, "you know," you're going to say, "we're going to say," we're going to say, "you're going to say," we're going to say, "we're going to say," we're going to say, "we're going to say," you're going to say, "and then we're going to say," and then we're going to say, "and then we're going to say," we're going to say, "we're going to say," we're going to say, "we're going to say," you're going to say, "you're going to say," you're going to say, "we're going to say," we're going to say, "
2022-03-23 09:37:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:37:02 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to be a lot of the world, we're going to be a lot of the world, and we're going to be able to see that we're going to make a lot of the world, and we're going to be able to be a lot of the world, and then we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to see that we're going to see that we're going to see that we're going to be a lot of the world, and we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to be a lot of the world, and we're going to see that we're going to see that we're going to be a lot of the world, and then we're going to see that we're going to have to be a lot of the world,
2022-03-23 09:37:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:37:02 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.271 | nll_loss 7.053 | ppl 132.77 | bleu 2.06 | wps 3597.5 | wpb 17862.2 | bsz 728.3 | num_updates 1095 | best_bleu 2.06
2022-03-23 09:37:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1095 updates
2022-03-23 09:37:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:37:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:37:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 7 @ 1095 updates, score 2.06) (writing took 1.6724121000006562 seconds)
2022-03-23 09:37:04 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:37:04 | INFO | train | epoch 007 | loss 9.449 | nll_loss 7.491 | ppl 179.93 | wps 39555 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 1095 | lr 0.000136875 | gnorm 1.063 | loss_scale 8 | train_wall 48 | gb_free 14.5 | wall 691
2022-03-23 09:37:04 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:37:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:37:06 | INFO | train_inner | epoch 008:      5 / 157 loss=9.394, nll_loss=7.406, ppl=169.6, wps=30448, ups=1.22, wpb=25002.6, bsz=1042.3, num_updates=1100, lr=0.0001375, gnorm=1.06, loss_scale=8, train_wall=30, gb_free=13.8, wall=693
2022-03-23 09:37:37 | INFO | train_inner | epoch 008:    105 / 157 loss=9.245, nll_loss=7.174, ppl=144.41, wps=81227.8, ups=3.23, wpb=25137.5, bsz=1075.3, num_updates=1200, lr=0.00015, gnorm=0.972, loss_scale=8, train_wall=30, gb_free=14.2, wall=724
2022-03-23 09:37:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:37:57 | INFO | fairseq.tasks.translation | example hypothesis: we did this, we've got in the middle of the world.
2022-03-23 09:37:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:38:03 | INFO | fairseq.tasks.translation | example hypothesis: this is the most idea of the most most most most most most most most of the most most most most most of the most most most most of the
2022-03-23 09:38:03 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:38:08 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be able to be new new new new new new york.
2022-03-23 09:38:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:38:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's a few example, and there's going to be going to be where you're going to see where where where are going to be in the country.
2022-03-23 09:38:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:38:19 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know, and we're going to do it, and we're going to do it, and we're going to do it, and we're going to do it, and we're not going to do it
2022-03-23 09:38:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:38:25 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in fact, in the most people who are in the people in the people in the people, for the most people who are in the people in the people for the people, for the people who are in the people in the people in the people in the people, for people
2022-03-23 09:38:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:38:30 | INFO | fairseq.tasks.translation | example hypothesis: some are some of some of some of these people, but it's a lot of their own own, but if you're going to go, but it, but it's not a lot of the same time, but it's not not a lot, but it, but it doesn't have a lot of the same time, but it's also also also
2022-03-23 09:38:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:38:36 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to take the world, we can see the brain, we can see that we can see the world, and then we can see that we can see the world, and then we can see that we can see the world, and then we can see the world, and make the brain, and then we can see that we can see the world.
2022-03-23 09:38:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:38:44 | INFO | fairseq.tasks.translation | example hypothesis: well, one of the first question, "it's a lot of example," and it's going to say, "" "and it's the first time," and it's the first thing, "and it's the first thing," and it's going to me, "and it's the first thing," and it's the first thing, "" "" "" "" "" "we have the first thing," we've got to say, "and it's the first thing," and it's the first thing, "it's the first thing," and then it's the first first first first first thing, "it's the first thing," it's the first thing, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know,
2022-03-23 09:38:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:38:46 | INFO | fairseq.tasks.translation | example hypothesis: now, in fact, if we're going to get a lot of the world, we're going to be a lot of the world, and we're going to be a lot of the world, and then we have to be a lot of the world, and then we've been able to be a lot of the world, and then we have to be able to be able to be a lot of the world.
2022-03-23 09:38:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:38:46 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.096 | nll_loss 6.774 | ppl 109.44 | bleu 2.71 | wps 3361.8 | wpb 17862.2 | bsz 728.3 | num_updates 1252 | best_bleu 2.71
2022-03-23 09:38:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1252 updates
2022-03-23 09:38:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:38:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:38:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 8 @ 1252 updates, score 2.71) (writing took 1.6901920459931716 seconds)
2022-03-23 09:38:48 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:38:48 | INFO | train | epoch 008 | loss 9.264 | nll_loss 7.202 | ppl 147.24 | wps 37999.4 | ups 1.51 | wpb 25153.6 | bsz 1020.6 | num_updates 1252 | lr 0.0001565 | gnorm 1.003 | loss_scale 8 | train_wall 48 | gb_free 13.6 | wall 795
2022-03-23 09:38:48 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:38:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:39:03 | INFO | train_inner | epoch 009:     48 / 157 loss=9.198, nll_loss=7.099, ppl=137.06, wps=29691.7, ups=1.16, wpb=25702.9, bsz=1011, num_updates=1300, lr=0.0001625, gnorm=1.021, loss_scale=8, train_wall=31, gb_free=14.5, wall=811
2022-03-23 09:39:34 | INFO | train_inner | epoch 009:    148 / 157 loss=9.112, nll_loss=6.963, ppl=124.76, wps=80326, ups=3.24, wpb=24780.2, bsz=958.6, num_updates=1400, lr=0.000175, gnorm=0.914, loss_scale=8, train_wall=30, gb_free=13.8, wall=842
2022-03-23 09:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:39:41 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in this room.
2022-03-23 09:39:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:39:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most, most of the most.
2022-03-23 09:39:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:39:49 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be going to be two two of the two two two.
2022-03-23 09:39:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:39:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there is there, where there's where are where are going to go with the water.
2022-03-23 09:39:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:39:58 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just just just just just just just a little bit of what's going on.
2022-03-23 09:39:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:40:02 | INFO | fairseq.tasks.translation | example hypothesis: and in the middle of people like people like the people for the people for the people, and it's a few people who's a lot of people in the people who's a lot of people.
2022-03-23 09:40:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:40:07 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are some of them, but if you're going to see it, but if you're going to see it, you don't see it, it's going to go on the right.
2022-03-23 09:40:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:40:12 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the way that we can see the world, we can see the brain, and we can see that we can see that we can see a lot of the brain, and then we can see it's a lot of the brain.
2022-03-23 09:40:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:40:18 | INFO | fairseq.tasks.translation | example hypothesis: well, one of the one of the idea, and it's going to say, "you know," you know, "well," well, "you know," well, "well," well, "well," well, "you know," well, "well," well, "well," well, "well," you know, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "you're going to say," you know, "well," well, "you know," well, "well," well, "well," well, "well," well,
2022-03-23 09:40:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:40:20 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's still still still a lot of course, and if we're going to do that we're going to get a lot of the same time, we're going to do that we're going to make a lot of the same time, we're going to do that we're going to do that we're going to do that we're going to make a lot of the world that we're going to do that we're going to do that we're going to do that we're going to make a lot of the same way to get a lot of the world that we're going to make a lot of the same time that we're going to do that we're going to do that we're going to do that we're going to make a lot of the same time that we're going to do that we're going to do that we're going to do that we're going to make a lot of the world that we're going to make a lot of the world that we're going to make a lot of the world that we're going
2022-03-23 09:40:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:40:20 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 8.841 | nll_loss 6.336 | ppl 80.8 | bleu 5.48 | wps 4151.7 | wpb 17862.2 | bsz 728.3 | num_updates 1409 | best_bleu 5.48
2022-03-23 09:40:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1409 updates
2022-03-23 09:40:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:40:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:40:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 9 @ 1409 updates, score 5.48) (writing took 1.7018562339944765 seconds)
2022-03-23 09:40:22 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:40:22 | INFO | train | epoch 009 | loss 9.093 | nll_loss 6.935 | ppl 122.33 | wps 41900.1 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 1409 | lr 0.000176125 | gnorm 0.942 | loss_scale 8 | train_wall 48 | gb_free 14.7 | wall 889
2022-03-23 09:40:22 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:40:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:40:51 | INFO | train_inner | epoch 010:     91 / 157 loss=8.919, nll_loss=6.666, ppl=101.56, wps=32755.2, ups=1.3, wpb=25166.5, bsz=1026, num_updates=1500, lr=0.0001875, gnorm=0.898, loss_scale=8, train_wall=31, gb_free=14.5, wall=918
2022-03-23 09:40:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:40:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2022-03-23 09:41:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:41:15 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the way.
2022-03-23 09:41:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:41:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of my talk, who are most of most of the most of the most.
2022-03-23 09:41:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:41:23 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new new new new new new new new york.
2022-03-23 09:41:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:41:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an example, where it's going to be going to be able, where it's going to be going to be able.
2022-03-23 09:41:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:41:31 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not going to do a few few years, and we're going to see what's going to do.
2022-03-23 09:41:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:41:36 | INFO | fairseq.tasks.translation | example hypothesis: and in the way, like people like people who have been working for people for a few people, and for a few years, and that's a group for a few years.
2022-03-23 09:41:36 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:41:42 | INFO | fairseq.tasks.translation | example hypothesis: first, some of some of you're going to go from the brain, but if it's not going to be able to be able to be able to be able to be able to be able to be able, but if they're going to be able to be able to be able to be able to be able to be able to be able to get the
2022-03-23 09:41:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:41:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information that we can be able to be able to take this.
2022-03-23 09:41:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:41:55 | INFO | fairseq.tasks.translation | example hypothesis: jo: one of the way, and it's going to be interesting for me, and i'm going to do it, and then it's going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to show you, and then you, and then you about this, and then you, and then you, and then you, and then you, and then you
2022-03-23 09:41:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:41:58 | INFO | fairseq.tasks.translation | example hypothesis: now, it's still still still at my mother, and the last year, and then we're going to get a new job, when we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a new job, when we're going to be a new project, when we're going to be a new job, when we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a
2022-03-23 09:41:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:41:58 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 8.683 | nll_loss 6.108 | ppl 69 | bleu 5.58 | wps 3844.5 | wpb 17862.2 | bsz 728.3 | num_updates 1564 | best_bleu 5.58
2022-03-23 09:41:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1564 updates
2022-03-23 09:41:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:41:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:41:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 10 @ 1564 updates, score 5.58) (writing took 1.7396539570036111 seconds)
2022-03-23 09:41:59 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:41:59 | INFO | train | epoch 010 | loss 8.921 | nll_loss 6.665 | ppl 101.47 | wps 39993.2 | ups 1.59 | wpb 25098.6 | bsz 1005.2 | num_updates 1564 | lr 0.0001955 | gnorm 0.991 | loss_scale 2 | train_wall 48 | gb_free 13.8 | wall 987
2022-03-23 09:42:00 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:42:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:42:11 | INFO | train_inner | epoch 011:     36 / 157 loss=8.918, nll_loss=6.658, ppl=100.95, wps=30957.2, ups=1.25, wpb=24731.9, bsz=973.7, num_updates=1600, lr=0.0002, gnorm=1.057, loss_scale=2, train_wall=31, gb_free=13.9, wall=998
2022-03-23 09:42:42 | INFO | train_inner | epoch 011:    136 / 157 loss=8.683, nll_loss=6.3, ppl=78.8, wps=82040.7, ups=3.21, wpb=25594.9, bsz=1070.4, num_updates=1700, lr=0.0002125, gnorm=0.886, loss_scale=2, train_wall=31, gb_free=13.6, wall=1030
2022-03-23 09:42:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:42:52 | INFO | fairseq.tasks.translation | example hypothesis: we had this pppon the way to go on.
2022-03-23 09:42:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:42:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the ha, most of most of most of most of the most.
2022-03-23 09:42:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:43:00 | INFO | fairseq.tasks.translation | example hypothesis: these are going to go from new new new new new new new new new york, which are going to be going to be able.
2022-03-23 09:43:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:43:05 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese, where they're going to be going to be going to be able to be able.
2022-03-23 09:43:05 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:43:09 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just a couple of your head, and what's going on.
2022-03-23 09:43:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:43:13 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamase people like the number of the number, and the number of the number of the number, and it's a lot for a few years.
2022-03-23 09:43:13 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:43:17 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are going to be able to be able to be able, but if you don't need to have the energy, it doesn't need to have the energy, and if you need to have the energy.
2022-03-23 09:43:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:43:21 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that we can use this structure, we can be able to create a structure of the structure, and that's all the structure of the structure, and all the structure.
2022-03-23 09:43:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:43:25 | INFO | fairseq.tasks.translation | example hypothesis: and one of the reasons, and it's interesting for me for me, "and then it's going to say," you know, "you know," you're going to say, "you know," you know, "you know," you know, "you know," you know, "you're going to say," you're going to say, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you're going to say," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you're going to say,"
2022-03-23 09:43:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:43:28 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still still still the mother, and we're going to be a lot of our work that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 09:43:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:43:28 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.48 | nll_loss 5.746 | ppl 53.66 | bleu 9.4 | wps 4658 | wpb 17862.2 | bsz 728.3 | num_updates 1721 | best_bleu 9.4
2022-03-23 09:43:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1721 updates
2022-03-23 09:43:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:43:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:43:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 11 @ 1721 updates, score 9.4) (writing took 1.6917112420051126 seconds)
2022-03-23 09:43:29 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:43:29 | INFO | train | epoch 011 | loss 8.737 | nll_loss 6.382 | ppl 83.4 | wps 43867 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 1721 | lr 0.000215125 | gnorm 0.898 | loss_scale 2 | train_wall 48 | gb_free 14.1 | wall 1077
2022-03-23 09:43:30 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:43:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:43:54 | INFO | train_inner | epoch 012:     79 / 157 loss=8.612, nll_loss=6.191, ppl=73.04, wps=34463.8, ups=1.39, wpb=24859.2, bsz=978.6, num_updates=1800, lr=0.000225, gnorm=0.864, loss_scale=2, train_wall=30, gb_free=14.8, wall=1102
2022-03-23 09:44:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:44:22 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppm in the middle of the center.
2022-03-23 09:44:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:44:26 | INFO | fairseq.tasks.translation | example hypothesis: and that's the right line of ha, most of most of most of most of most of most here.
2022-03-23 09:44:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:44:31 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to be able to make two kinds of conval new ways that are going to be able to be able to be able.
2022-03-23 09:44:31 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:44:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese chinese food, where you're going to get up with the ppie and then you're going to be able to get.
2022-03-23 09:44:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:44:40 | INFO | fairseq.tasks.translation | example hypothesis: and it's not that we're not just going to understand a few few few of his head on his head, and all of his head, all of the mind.
2022-03-23 09:44:40 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:44:44 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamace of people who took the experience for the number of animals, the number of animals, and the number of animals, and that has had been a lot for the authiiiiiiiiiiiiiiiiii
2022-03-23 09:44:44 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:44:49 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the map of the ddddddder, but if you don't want to use the water, but if you don't need your energy, you need to need the energy, you need to need the energy, and you need to need the energy.
2022-03-23 09:44:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:44:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this information, we can start to take a new piece of the web, we can start with a structure of the structure, and that's all the structure of the structure of the structure, and all the structure of the structure of the structure of the structure, and all the structure of the structure, and all the structure, and all the structure, and all the structure of the structure of the structure of the structure of the structure,
2022-03-23 09:44:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:44:59 | INFO | fairseq.tasks.translation | example hypothesis: and one of the reasons that it's interesting, and it's interesting for me to be able to be working for me, "oh," well, "you know," and then you know, "you know," you know, "you've got to say," well, "you know," you know, "you know," you're going to say, "you know," you're going to know, "you know," well, "you know," well, "well," you know, "you know," well, "you know," well, "well," you know, "you know," you're going to know, "you know," you're going to know, "you know," you're going to go to go to talk about that you're going to talk about that you're going to go to be a
2022-03-23 09:44:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:45:02 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, we still still still know the most of the mother, and a lot of work that we had to see our work on the world, and if we had to see that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we were able to be able to be able to see that if we were able to see that
2022-03-23 09:45:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:45:02 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.295 | nll_loss 5.462 | ppl 44.07 | bleu 9.69 | wps 4136 | wpb 17862.2 | bsz 728.3 | num_updates 1878 | best_bleu 9.69
2022-03-23 09:45:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1878 updates
2022-03-23 09:45:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:45:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:45:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 12 @ 1878 updates, score 9.69) (writing took 1.705990879010642 seconds)
2022-03-23 09:45:03 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:45:03 | INFO | train | epoch 012 | loss 8.529 | nll_loss 6.062 | ppl 66.8 | wps 42040.1 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 1878 | lr 0.00023475 | gnorm 0.866 | loss_scale 2 | train_wall 48 | gb_free 14.1 | wall 1171
2022-03-23 09:45:04 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:45:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:45:11 | INFO | train_inner | epoch 013:     22 / 157 loss=8.448, nll_loss=5.939, ppl=61.35, wps=33031.2, ups=1.31, wpb=25181.9, bsz=1051.8, num_updates=1900, lr=0.0002375, gnorm=0.927, loss_scale=2, train_wall=30, gb_free=13.8, wall=1178
2022-03-23 09:45:42 | INFO | train_inner | epoch 013:    122 / 157 loss=8.358, nll_loss=5.794, ppl=55.49, wps=81154.4, ups=3.2, wpb=25348.9, bsz=1035.8, num_updates=2000, lr=0.00025, gnorm=0.864, loss_scale=2, train_wall=31, gb_free=13.7, wall=1209
2022-03-23 09:45:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:45:56 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppin the clinic.
2022-03-23 09:45:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:46:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the car of ha, most of most of most of most.
2022-03-23 09:46:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:46:04 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be able to create new york.
2022-03-23 09:46:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:46:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese food, and they're going to be used with it.
2022-03-23 09:46:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:46:11 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just going to understand a few feet on his head, and what's going on on.
2022-03-23 09:46:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:46:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamace of people like the responsibility for the number of animals, and this is a number of animals that has become a number of animals.
2022-03-23 09:46:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:46:19 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magic of the lines in the lines, but if you don't need to do it, it doesn't need your energy, and if you need your energy.
2022-03-23 09:46:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:46:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information to use this information, we can start able to start with a huge form, and we can start able to start with the structure of the structure of the structure of the structure, and that's all the structure of the structure.
2022-03-23 09:46:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:46:27 | INFO | fairseq.tasks.translation | example hypothesis: th: the reasons it's interesting, and it's interesting for me to be here for me, "oh, you know," oh, "oh, you know, you know," the best time, "and then we've been working with you're going to say," and then you're going to say, "you know," you're going to say, "you're going to say," you're going to be a long time, "you know," you know, "the best time," you're working with you're working with you've been working with you've been working with you've been working with you've been working with you've been working with you've been working with you know, "and you know," the best time for a long time, "the best time," the best time, "the best time," the best time, "
2022-03-23 09:46:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:46:30 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of the mother, and a big design that we had to use our work on the ground, and that we had to use a lot of problems that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if
2022-03-23 09:46:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:46:30 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.117 | nll_loss 5.125 | ppl 34.9 | bleu 12.48 | wps 4867.5 | wpb 17862.2 | bsz 728.3 | num_updates 2035 | best_bleu 12.48
2022-03-23 09:46:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2035 updates
2022-03-23 09:46:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:46:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:46:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 13 @ 2035 updates, score 12.48) (writing took 1.6971067199920071 seconds)
2022-03-23 09:46:31 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:46:31 | INFO | train | epoch 013 | loss 8.349 | nll_loss 5.781 | ppl 54.99 | wps 44824.1 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 2035 | lr 0.000254375 | gnorm 0.883 | loss_scale 2 | train_wall 48 | gb_free 13.5 | wall 1259
2022-03-23 09:46:32 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:46:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:46:52 | INFO | train_inner | epoch 014:     65 / 157 loss=8.246, nll_loss=5.624, ppl=49.3, wps=35438.2, ups=1.42, wpb=24906.6, bsz=983.2, num_updates=2100, lr=0.0002625, gnorm=0.832, loss_scale=2, train_wall=30, gb_free=14.9, wall=1279
2022-03-23 09:47:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:47:24 | INFO | fairseq.tasks.translation | example hypothesis: we made these pppine in the clinic.
2022-03-23 09:47:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:47:28 | INFO | fairseq.tasks.translation | example hypothesis: that's the line of the doha, the most most of the most most of the most knows here.
2022-03-23 09:47:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:47:33 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new ores that are going to create two new ways.
2022-03-23 09:47:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:47:37 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese food, where they're going to eat with the legs, and they're going to be able.
2022-03-23 09:47:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:47:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a couple of electrodes on his head on his head and understand what all of his thoughts are on.
2022-03-23 09:47:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:47:45 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamace of how people came to the responsibility of responsibility, the number of animals, and the number of animals has had become become a historiiicide.
2022-03-23 09:47:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:47:49 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic of the lines in the lines, but in the lines, but if you don't need to move the energy, and you need the energy.
2022-03-23 09:47:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:47:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information that comes from this reflection, we can start with a traditional way that can start with a huge form of information, and the whole structure of the structure.
2022-03-23 09:47:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:47:57 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting to make me here for tedtedwomen, "well, and then we said," if we're going to tell you, "and then we're going to give you a second about this issue."
2022-03-23 09:47:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:47:59 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother's mother, and the invention of the world, and a big design that we've got to see that if we were able to use a lot of energy, and it was able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able.
2022-03-23 09:47:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:47:59 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 7.994 | nll_loss 4.89 | ppl 29.64 | bleu 14.97 | wps 4784 | wpb 17862.2 | bsz 728.3 | num_updates 2192 | best_bleu 14.97
2022-03-23 09:47:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2192 updates
2022-03-23 09:47:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:47:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:48:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 14 @ 2192 updates, score 14.97) (writing took 1.7698145479953382 seconds)
2022-03-23 09:48:00 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:48:00 | INFO | train | epoch 014 | loss 8.151 | nll_loss 5.476 | ppl 44.51 | wps 44339.9 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 2192 | lr 0.000274 | gnorm 0.811 | loss_scale 2 | train_wall 48 | gb_free 13.8 | wall 1348
2022-03-23 09:48:01 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:48:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:48:04 | INFO | train_inner | epoch 015:      8 / 157 loss=8.077, nll_loss=5.361, ppl=41.09, wps=35764.1, ups=1.4, wpb=25599, bsz=1067.5, num_updates=2200, lr=0.000275, gnorm=0.772, loss_scale=2, train_wall=30, gb_free=13.7, wall=1351
2022-03-23 09:48:35 | INFO | train_inner | epoch 015:    108 / 157 loss=7.995, nll_loss=5.233, ppl=37.6, wps=80551.1, ups=3.21, wpb=25086, bsz=1057.8, num_updates=2300, lr=0.0002875, gnorm=0.825, loss_scale=2, train_wall=31, gb_free=13.8, wall=1382
2022-03-23 09:48:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:48:54 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppills in the clinics.
2022-03-23 09:48:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:48:58 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of the most knows here.
2022-03-23 09:48:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:49:02 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to create two new ores.
2022-03-23 09:49:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:49:06 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food food, where they're going to do with pie, and they're going to be degrace.
2022-03-23 09:49:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:49:10 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a couple of electrodes on his head and understand what all of his thoughts are on the mind.
2022-03-23 09:49:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:49:14 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamab, people like the responsibility of the responsibility that grew up to the number of animals, and this is a number of priiiiibia.
2022-03-23 09:49:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:49:18 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of these are some of the magic lines in the lines, but it doesn't like it, if you don't need your energy, if you need your energy, and you need your energy.
2022-03-23 09:49:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:49:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information that comes from this reflection, we can start with a traditional light that can start able to start with a traditional form of the face of the structure, and there's all the information of the structure of the structure of the structure.
2022-03-23 09:49:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:49:27 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to be here for tedwomen -- that's the best time, "oh, it's the best thing we're going to say," well, "well, if we've been working with you've been working with a long time."
2022-03-23 09:49:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:49:30 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still the invention of the invention of the invention, and a large design that we had to use our airplane, that we had to solve a unique system, that if we had to use a unique system, it had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we were able to see that if we were able to use a unique, and see that if you were able to use the same, it's a unique, it's actually be able to be able to be able to be able to be able to be able to see that if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 09:49:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:49:30 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 7.776 | nll_loss 4.556 | ppl 23.53 | bleu 16.24 | wps 4522.8 | wpb 17862.2 | bsz 728.3 | num_updates 2349 | best_bleu 16.24
2022-03-23 09:49:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2349 updates
2022-03-23 09:49:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:49:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:49:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 15 @ 2349 updates, score 16.24) (writing took 1.7262546620040666 seconds)
2022-03-23 09:49:31 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:49:31 | INFO | train | epoch 015 | loss 8.002 | nll_loss 5.241 | ppl 37.83 | wps 43393.5 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 2349 | lr 0.000293625 | gnorm 0.796 | loss_scale 2 | train_wall 48 | gb_free 13.8 | wall 1439
2022-03-23 09:49:32 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:49:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:49:48 | INFO | train_inner | epoch 016:     51 / 157 loss=7.977, nll_loss=5.197, ppl=36.68, wps=34659.4, ups=1.36, wpb=25422.5, bsz=930.5, num_updates=2400, lr=0.0003, gnorm=0.743, loss_scale=2, train_wall=31, gb_free=14.3, wall=1456
2022-03-23 09:50:19 | INFO | train_inner | epoch 016:    151 / 157 loss=7.777, nll_loss=4.89, ppl=29.66, wps=80540.8, ups=3.27, wpb=24636.8, bsz=1031, num_updates=2500, lr=0.0003125, gnorm=0.72, loss_scale=2, train_wall=30, gb_free=14.1, wall=1486
2022-03-23 09:50:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:50:24 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 09:50:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:50:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know.
2022-03-23 09:50:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:50:32 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new logic.
2022-03-23 09:50:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:50:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs and salt.
2022-03-23 09:50:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:50:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head and understand what all its thoughts are.
2022-03-23 09:50:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:50:43 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility of responsibility, the number of animals grew up, and this is a challenge for the number.
2022-03-23 09:50:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:50:46 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic lines in the field, but the sucks doesn't move if you don't need your energy, and you need your energy.
2022-03-23 09:50:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:50:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start able to start able to start able to start with a traditional face of the face of the face, and that's the whole shape of the structure of the structure.
2022-03-23 09:50:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:50:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me to be here for tedwomen.
2022-03-23 09:50:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:50:57 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the invention of the invention of the invention, and one part of the design that we're in our airplane was a unique result that we had to be able to be able to see that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we're able to use a unique.
2022-03-23 09:50:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:50:57 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 7.663 | nll_loss 4.405 | ppl 21.19 | bleu 14.87 | wps 5098.3 | wpb 17862.2 | bsz 728.3 | num_updates 2506 | best_bleu 16.24
2022-03-23 09:50:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2506 updates
2022-03-23 09:50:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 09:50:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 09:50:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 16 @ 2506 updates, score 14.87) (writing took 0.7662287069979357 seconds)
2022-03-23 09:50:57 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:50:57 | INFO | train | epoch 016 | loss 7.819 | nll_loss 4.956 | ppl 31.05 | wps 46007.2 | ups 1.83 | wpb 25153.6 | bsz 1020.6 | num_updates 2506 | lr 0.00031325 | gnorm 0.74 | loss_scale 2 | train_wall 48 | gb_free 14 | wall 1525
2022-03-23 09:50:58 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:50:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:51:27 | INFO | train_inner | epoch 017:     94 / 157 loss=7.69, nll_loss=4.757, ppl=27.04, wps=37010.3, ups=1.46, wpb=25334.4, bsz=1053.2, num_updates=2600, lr=0.000325, gnorm=0.712, loss_scale=2, train_wall=31, gb_free=13.7, wall=1555
2022-03-23 09:51:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:51:51 | INFO | fairseq.tasks.translation | example hypothesis: we made these pace in the clinic clinic in the clinic clinic.
2022-03-23 09:51:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:51:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most of the most familiar here.
2022-03-23 09:51:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:51:59 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to create the two new swiss.
2022-03-23 09:51:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:52:04 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food food, where happy legs are going to be made with salt and pie.
2022-03-23 09:52:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:52:08 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just get a few electrodes on his head and understand what all its thoughts are on the way.
2022-03-23 09:52:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:52:12 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility of life, the number of animals, and this is a foundation of natural conservation in namibia.
2022-03-23 09:52:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:52:16 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic magnetic lines, but the susulle doesn't have your energy, and if you don't need your energy, and so that's what the energy is going on.
2022-03-23 09:52:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:52:21 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, we can start able to start the big face of the face and reform it through the whole shape of the structure, and the information, and the whole structure of the structure of the structure, which is the whole structure of the structure, which is the structure of this structure, the structure, the structure of the structure that we're going to be able to use
2022-03-23 09:52:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:52:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and you know, for me, "in tedwomen, is that when you've got the best one of them," and then we've been working on the best time, "and then we've been working with you."
2022-03-23 09:52:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:52:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of the design, and a big part of the design that we have to see is that we had to solve a unique result of it, so that we've got to solve the problems that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see, and see, and see it, and see it in a specific with a specific, and see that if we're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see,
2022-03-23 09:52:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:52:30 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 7.581 | nll_loss 4.22 | ppl 18.64 | bleu 16.75 | wps 4125.8 | wpb 17862.2 | bsz 728.3 | num_updates 2663 | best_bleu 16.75
2022-03-23 09:52:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2663 updates
2022-03-23 09:52:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:52:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:52:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 17 @ 2663 updates, score 16.75) (writing took 1.7311393929994665 seconds)
2022-03-23 09:52:32 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:52:32 | INFO | train | epoch 017 | loss 7.679 | nll_loss 4.739 | ppl 26.7 | wps 41642.5 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 2663 | lr 0.000332875 | gnorm 0.723 | loss_scale 2 | train_wall 48 | gb_free 13.7 | wall 1620
2022-03-23 09:52:33 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:52:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:52:44 | INFO | train_inner | epoch 018:     37 / 157 loss=7.629, nll_loss=4.659, ppl=25.27, wps=32758.3, ups=1.3, wpb=25284.4, bsz=1007, num_updates=2700, lr=0.0003375, gnorm=0.732, loss_scale=2, train_wall=30, gb_free=13.5, wall=1632
2022-03-23 09:53:15 | INFO | train_inner | epoch 018:    137 / 157 loss=7.531, nll_loss=4.512, ppl=22.81, wps=79745.9, ups=3.22, wpb=24760.8, bsz=1016.5, num_updates=2800, lr=0.00035, gnorm=0.691, loss_scale=2, train_wall=31, gb_free=13.8, wall=1663
2022-03-23 09:53:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:53:25 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 09:53:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:53:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of them.
2022-03-23 09:53:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:53:33 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks.
2022-03-23 09:53:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:53:37 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are made with salz and fat.
2022-03-23 09:53:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:53:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to get a few electrodes on his head, and understand exactly what all his thoughts are on the way.
2022-03-23 09:53:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:53:45 | INFO | fairseq.tasks.translation | example hypothesis: and in the maibia, people like the responsibility for the wild, grew up to the number of animals. and this is a foundation for natural conservation in namibia.
2022-03-23 09:53:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:53:49 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloods of magnetic fields in the inside the inside of the interior lines, but the susuicide may not move if they don't have energy, if they need their energy, they need energy, because they need energy, and so the sulength.
2022-03-23 09:53:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:53:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start with the big facial face of the face of the face, and the shape of the brain, and that's what the whole structure is.
2022-03-23 09:53:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:53:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons, and it's interesting, and you know, for me, it's a long time to be in tedwomen, which is that... "well, when you're going to be silent, you know, you know, you know, we've started to support it, and if you've got a silent, it's a lot of time to be silent, and then we've started to support, and then we've started to support it, and then we've started to be silent for example, and then we've started to be a lot of time to be silent."
2022-03-23 09:53:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:54:00 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and a big part of the design of the design work that we're in our airplane, was a result of it, we had to solve the unique problems that we had to solve is to solve the ground, and that it's all the way to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use, or to use the materials, and that if you're able to use the power of a specific, you're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:54:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:54:00 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 7.361 | nll_loss 3.893 | ppl 14.85 | bleu 20.85 | wps 4696.1 | wpb 17862.2 | bsz 728.3 | num_updates 2820 | best_bleu 20.85
2022-03-23 09:54:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2820 updates
2022-03-23 09:54:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:54:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:54:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 18 @ 2820 updates, score 20.85) (writing took 1.727846462992602 seconds)
2022-03-23 09:54:02 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:54:02 | INFO | train | epoch 018 | loss 7.535 | nll_loss 4.516 | ppl 22.88 | wps 43892.3 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 2820 | lr 0.0003525 | gnorm 0.673 | loss_scale 2 | train_wall 48 | gb_free 13.6 | wall 1709
2022-03-23 09:54:02 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:54:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:54:28 | INFO | train_inner | epoch 019:     80 / 157 loss=7.456, nll_loss=4.396, ppl=21.05, wps=35410.3, ups=1.38, wpb=25616.1, bsz=998.9, num_updates=2900, lr=0.0003625, gnorm=0.641, loss_scale=2, train_wall=31, gb_free=14.2, wall=1735
2022-03-23 09:54:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:54:55 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 09:54:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:54:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 09:54:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:55:03 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to create the two new pigs.
2022-03-23 09:55:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:55:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where frog legs and palt.
2022-03-23 09:55:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:55:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a few electrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 09:55:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:55:14 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for wild animals, the number of wild animals, and this is a foundation of natural conservation in namibia.
2022-03-23 09:55:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:55:18 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnet lines, but the susuck doesn't like if they need the energy and so forth.
2022-03-23 09:55:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:55:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face of the face and the shape of the information that's all the structure of this structure, the whole structure, and all the structure of this structure, and we can fold a structure.
2022-03-23 09:55:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:55:27 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it for me to be here at tedo, is that... yes, when someone said, "you know, when you're going to say, the men in your table, and then we've been talking to a table revolution, and then we've been saying that we've got a lot of anxo, and then we've been talking to you," oh, "well," well, "oh, we've got a lot of them, we've got a lot of them.
2022-03-23 09:55:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:55:29 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's mother's invention, and a great part of design work that we're going to be a result of it, that we had to solve the unique problems on the ground -- all the way we had to do it -- all of us -- and that it allows us to see that if we're going to be a gas system in the ground, or that we're going to be able to use the prophearity of a refrightening, or a refrightening, and that we're going to be able to see that we're going to be able to see that we're going to use the propellellent, or to be able to be able to be able to see that we're going to be able to be able to see that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:55:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:55:29 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.328 | nll_loss 3.808 | ppl 14 | bleu 21.46 | wps 4782.4 | wpb 17862.2 | bsz 728.3 | num_updates 2977 | best_bleu 21.46
2022-03-23 09:55:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2977 updates
2022-03-23 09:55:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:55:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:55:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 19 @ 2977 updates, score 21.46) (writing took 1.7187217639875598 seconds)
2022-03-23 09:55:31 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:55:31 | INFO | train | epoch 019 | loss 7.399 | nll_loss 4.311 | ppl 19.84 | wps 44419.1 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 2977 | lr 0.000372125 | gnorm 0.636 | loss_scale 2 | train_wall 48 | gb_free 13.8 | wall 1798
2022-03-23 09:55:31 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:55:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:55:39 | INFO | train_inner | epoch 020:     23 / 157 loss=7.334, nll_loss=4.211, ppl=18.52, wps=34955.8, ups=1.41, wpb=24810.7, bsz=1030.2, num_updates=3000, lr=0.000375, gnorm=0.61, loss_scale=2, train_wall=30, gb_free=13.9, wall=1806
2022-03-23 09:56:10 | INFO | train_inner | epoch 020:    123 / 157 loss=7.264, nll_loss=4.106, ppl=17.22, wps=81971.3, ups=3.17, wpb=25887.7, bsz=1015.4, num_updates=3100, lr=0.0003875, gnorm=0.551, loss_scale=2, train_wall=31, gb_free=14.5, wall=1838
2022-03-23 09:56:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:56:24 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:56:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:56:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most familiar here.
2022-03-23 09:56:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:56:32 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that will create the two new pigments.
2022-03-23 09:56:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:56:36 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs with salsalz and pills are served.
2022-03-23 09:56:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:56:40 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to just bring a few electroelectrodes on his head and understand exactly what all its thoughts are on the way.
2022-03-23 09:56:40 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:56:45 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, people like the responsibility for the wild, grew up the number of wild animals, and this is a foundation of natural protection in namibia.
2022-03-23 09:56:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:56:49 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bars of magnetic field, but the sulant lines in the inside the inside of the inside, not if they're moving, they need their energy movements, and so the superconducting.
2022-03-23 09:56:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:56:53 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, we can start with a traditional face, the big constructions of the face, and the basic shape of the face, and through that information that information, which makes the whole structure that all the structure of this structure and all the portion of these portion.
2022-03-23 09:56:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:56:59 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measure it interesting, for me to be here at tedwomen, is that... "yes, when someone was in the best," when someone said, "somebody who said to you," the men who said to a table and say, "when the revolution starts to be very interesting and measure it very interesting," when the revolution starts to be able to be able to be here in tedwomen, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 09:56:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:57:02 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we have in our plane, and we have to see a result of them that we had to solve the unique problems that were connected to the ground -- all of the way of the invention of the invention of the invention of the invention of a continent, and a big part of the big part of the design of the design of the design work of the design work of the design work that allows us to be able to use to be able to be able to be able to be able to be able to use is that we can be able to be able to be able to be able to use to see that if we're able to use in the propheartwork on the prophearable to use in our airaircraft, or a massive massive massive massive massive massive massive massive, or to use in the propheartwork that we can be able to be able to be able to be able to be able to be able to be able to be able to use
2022-03-23 09:57:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:57:02 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.211 | nll_loss 3.681 | ppl 12.83 | bleu 23.03 | wps 4366.9 | wpb 17862.2 | bsz 728.3 | num_updates 3134 | best_bleu 23.03
2022-03-23 09:57:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3134 updates
2022-03-23 09:57:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:57:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:57:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 20 @ 3134 updates, score 23.03) (writing took 1.7681860669981688 seconds)
2022-03-23 09:57:03 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:57:03 | INFO | train | epoch 020 | loss 7.262 | nll_loss 4.103 | ppl 17.18 | wps 42716.4 | ups 1.7 | wpb 25153.6 | bsz 1020.6 | num_updates 3134 | lr 0.00039175 | gnorm 0.589 | loss_scale 2 | train_wall 48 | gb_free 14.2 | wall 1891
2022-03-23 09:57:04 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:57:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:57:25 | INFO | train_inner | epoch 021:     66 / 157 loss=7.195, nll_loss=4.003, ppl=16.03, wps=33517.7, ups=1.34, wpb=24920.2, bsz=1098.6, num_updates=3200, lr=0.0004, gnorm=0.629, loss_scale=2, train_wall=30, gb_free=13.3, wall=1912
2022-03-23 09:57:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:57:57 | INFO | fairseq.tasks.translation | example hypothesis: we put this sheep in the clinic.
2022-03-23 09:57:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:58:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most familiar here.
2022-03-23 09:58:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:58:05 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will make the two new pigs.
2022-03-23 09:58:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:58:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there is french chinese food, where frog legs will be served with salz and pace.
2022-03-23 09:58:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:58:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a few electrodes on his head and understand exactly what all your thoughts are on the way.
2022-03-23 09:58:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:58:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the makea, people like the responsibility for the wild animals, grew up with the number of wild animals, and this is a foundation for the natural protection in namibia.
2022-03-23 09:58:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:58:21 | INFO | fairseq.tasks.translation | example hypothesis: first, some boul of the magnetic field, but the suck of the superconductor don't like it, if you move your energy, and so the superconductor.
2022-03-23 09:58:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:58:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial, which is the great constructions of the facial and the basic shape, and by the one of the information that makes all the pores and a structure.
2022-03-23 09:58:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:58:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that you do it up and you say, "we have a silent," you know, "for a long time," you know, you know, you know, "you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know,"
2022-03-23 09:58:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:58:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're in our plane, was a result that we had to be able to use the unique problems that were connected to the ground -- everything from a continuing to a continuous system, and that allows us to make a refrigergergering.
2022-03-23 09:58:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:58:32 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.152 | nll_loss 3.591 | ppl 12.05 | bleu 23.38 | wps 4658.9 | wpb 17862.2 | bsz 728.3 | num_updates 3291 | best_bleu 23.38
2022-03-23 09:58:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3291 updates
2022-03-23 09:58:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:58:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 09:58:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 21 @ 3291 updates, score 23.38) (writing took 1.7282319480000297 seconds)
2022-03-23 09:58:33 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 09:58:33 | INFO | train | epoch 021 | loss 7.189 | nll_loss 3.992 | ppl 15.92 | wps 43879.3 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 3291 | lr 0.000411375 | gnorm 0.611 | loss_scale 2 | train_wall 48 | gb_free 14.7 | wall 1981
2022-03-23 09:58:34 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 09:58:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:58:37 | INFO | train_inner | epoch 022:      9 / 157 loss=7.201, nll_loss=4.01, ppl=16.12, wps=34338.7, ups=1.39, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.618, loss_scale=2, train_wall=30, gb_free=13.3, wall=1984
2022-03-23 09:59:08 | INFO | train_inner | epoch 022:    109 / 157 loss=7.137, nll_loss=3.914, ppl=15.08, wps=79559.1, ups=3.24, wpb=24588.9, bsz=1001.6, num_updates=3400, lr=0.000425, gnorm=0.623, loss_scale=2, train_wall=31, gb_free=13.8, wall=2015
2022-03-23 09:59:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:59:26 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:59:26 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:59:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:59:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:59:34 | INFO | fairseq.tasks.translation | example hypothesis: stars become new golden locks.
2022-03-23 09:59:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:59:38 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are being served with salz and pills.
2022-03-23 09:59:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:59:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand what all of his thoughts are on the way.
2022-03-23 09:59:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:59:45 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for wild animals, the number of wild animals came back. and this is a foundation of conservation in namibia.
2022-03-23 09:59:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:59:49 | INFO | fairseq.tasks.translation | example hypothesis: first, some boul lines in the inner, but the superconductor don't like when they're moving, and so the suide disorder.
2022-03-23 09:59:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:59:53 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial that gives the big constructions of the face and the basic shape of the one.
2022-03-23 09:59:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:59:57 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are very interesting and measures for me at tedwomen, is that... "well, when somebody said," turn it together, "when somebody said," turn you to the men on your table and say, "and then we're working on a table," and then we've been working with silly. "
2022-03-23 09:59:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:59:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we're going to be able to see in our airplane.
2022-03-23 09:59:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:59:58 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.114 | nll_loss 3.516 | ppl 11.44 | bleu 23.03 | wps 5204.9 | wpb 17862.2 | bsz 728.3 | num_updates 3448 | best_bleu 23.38
2022-03-23 09:59:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3448 updates
2022-03-23 09:59:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 09:59:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 09:59:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 22 @ 3448 updates, score 23.03) (writing took 0.7644065609929385 seconds)
2022-03-23 09:59:59 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 09:59:59 | INFO | train | epoch 022 | loss 7.11 | nll_loss 3.873 | ppl 14.65 | wps 46390.7 | ups 1.84 | wpb 25153.6 | bsz 1020.6 | num_updates 3448 | lr 0.000431 | gnorm 0.585 | loss_scale 2 | train_wall 48 | gb_free 14.4 | wall 2066
2022-03-23 09:59:59 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 09:59:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:00:15 | INFO | train_inner | epoch 023:     52 / 157 loss=7.059, nll_loss=3.796, ppl=13.89, wps=37693.4, ups=1.48, wpb=25492.2, bsz=954.3, num_updates=3500, lr=0.0004375, gnorm=0.495, loss_scale=2, train_wall=31, gb_free=14, wall=2083
2022-03-23 10:00:46 | INFO | train_inner | epoch 023:    152 / 157 loss=6.963, nll_loss=3.66, ppl=12.64, wps=82224.9, ups=3.24, wpb=25381.3, bsz=1105.1, num_updates=3600, lr=0.00045, gnorm=0.53, loss_scale=2, train_wall=31, gb_free=14.3, wall=2114
2022-03-23 10:00:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:00:52 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:00:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:00:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:00:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:00:59 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks.
2022-03-23 10:00:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:01:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pitcase.
2022-03-23 10:01:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:01:07 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:01:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:01:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for wild animals, the number of wild animals grew back, and this is a basis of conservation in namibia.
2022-03-23 10:01:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:01:15 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic fields are caught in the inside, but the superconductor may not like the suicide, because their movements need their energy, and so the superconductor.
2022-03-23 10:01:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:01:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial, which is the big constructions of the face and the basic shape of the face and the basic shape of the real face and the basic shape of the fundamental information that's going to fold the whole portion of the whole portion of this reflection, which is the whole portion of the whole portion of this reflection.
2022-03-23 10:01:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:01:25 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's going to be high-interesting and measured for me here at tedwomen is that... tank, when someone said, "turn it up to the best than someone said," turn you to the men and tell you about a table interesting and say, "you know, if we're going to be here at tedwomen."
2022-03-23 10:01:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:01:27 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of design work that we're on our plane was a result that we had to solve the unique problems that were connected to surgical, so that we had to be connected to operations, so that there are all the mother of the mother of the invention, and a big part of a continent of the design work that allows us to do with a refrigeration of a refrightening system that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 10:01:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:01:27 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.033 | nll_loss 3.39 | ppl 10.48 | bleu 25.45 | wps 4637.3 | wpb 17862.2 | bsz 728.3 | num_updates 3605 | best_bleu 25.45
2022-03-23 10:01:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3605 updates
2022-03-23 10:01:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:01:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:01:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 23 @ 3605 updates, score 25.45) (writing took 1.7867705969983945 seconds)
2022-03-23 10:01:29 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 10:01:29 | INFO | train | epoch 023 | loss 6.999 | nll_loss 3.711 | ppl 13.1 | wps 43741.2 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 3605 | lr 0.000450625 | gnorm 0.518 | loss_scale 2 | train_wall 48 | gb_free 14.7 | wall 2156
2022-03-23 10:01:29 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 10:01:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:01:59 | INFO | train_inner | epoch 024:     95 / 157 loss=6.954, nll_loss=3.645, ppl=12.51, wps=34299.5, ups=1.37, wpb=24955.6, bsz=1033.7, num_updates=3700, lr=0.0004625, gnorm=0.512, loss_scale=2, train_wall=31, gb_free=13.8, wall=2186
2022-03-23 10:02:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:02:22 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 10:02:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:02:26 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most of you here.
2022-03-23 10:02:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:02:30 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that will create the two new pigs.
2022-03-23 10:02:30 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:02:34 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and ppepper.
2022-03-23 10:02:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:02:38 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:02:38 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:02:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild, grew up the number of wild animals, and that's a basis for conservation in namibia.
2022-03-23 10:02:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:02:45 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines in the inside, but the supersuperconductor doesn't like it, because their movements need energy, and so the superconductor.
2022-03-23 10:02:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:02:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial, which gives the big constructions of the face and the basic form, and restoring it through the one of the information that refold the whole portion and fold.
2022-03-23 10:02:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are very interesting and measured to me here at tedwomen, is that... tacky, it was the best thing when someone said, "turn you to a table and tell you, '' when the revolution starts to help you. '' '' '' '"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 10:02:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:02:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're at our airplane, was a result that we had to solve the unique problems that were connected to operations -- everything from a continuous amount of design and refrightening system that we're going to be able to see that we're going to be able to use in our aircraft.
2022-03-23 10:02:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:02:56 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 6.903 | nll_loss 3.214 | ppl 9.28 | bleu 27.63 | wps 4764.3 | wpb 17862.2 | bsz 728.3 | num_updates 3762 | best_bleu 27.63
2022-03-23 10:02:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3762 updates
2022-03-23 10:02:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:02:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 24 @ 3762 updates, score 27.63) (writing took 1.763628027998493 seconds)
2022-03-23 10:02:58 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:02:58 | INFO | train | epoch 024 | loss 6.928 | nll_loss 3.607 | ppl 12.18 | wps 44348.4 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 3762 | lr 0.00047025 | gnorm 0.487 | loss_scale 2 | train_wall 48 | gb_free 14.3 | wall 2245
2022-03-23 10:02:58 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:03:10 | INFO | train_inner | epoch 025:     38 / 157 loss=6.854, nll_loss=3.497, ppl=11.29, wps=35724.2, ups=1.4, wpb=25537.9, bsz=1059, num_updates=3800, lr=0.000475, gnorm=0.45, loss_scale=2, train_wall=30, gb_free=13.5, wall=2258
2022-03-23 10:03:42 | INFO | train_inner | epoch 025:    138 / 157 loss=6.909, nll_loss=3.582, ppl=11.97, wps=80162.9, ups=3.21, wpb=24941.2, bsz=984, num_updates=3900, lr=0.0004875, gnorm=0.53, loss_scale=2, train_wall=31, gb_free=13.8, wall=2289
2022-03-23 10:03:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:52 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 10:03:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:03:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:03:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:03:59 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to write two new pigments.
2022-03-23 10:03:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:04:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where happy legs are served with salz and psuitcase.
2022-03-23 10:04:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:04:07 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:04:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:04:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the case, people's responsibility for wild, the number of wild animals grew again, and this is a basis for conservation in namibia.
2022-03-23 10:04:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:04:15 | INFO | fairseq.tasks.translation | example hypothesis: first, some bands of magnetic field are caught inside, but the superconductor may not be able to move, because their movements need the superconductor, and so the superconductor disorder.
2022-03-23 10:04:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:04:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which gives the great constructions of the face and the basic form of information that refits the whole portion structure and a fold.
2022-03-23 10:04:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:04:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measured to me here at tedwomen is that... tyes, when someone said, "turn you to your own table and say," if the revolution begins to you in your table, "and then we support you."
2022-03-23 10:04:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:04:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're on our plane, was a result that we had to solve the unique problems that were connected to operations -- everything from a continuous variation and a large part of the refrigeration system and a large part of the refrigeration system, and with a refrigeration system, which is that we can use to be refrigered in the air, or if you can use a particular traffic in the ground, or if you can use it, or if you can use it, or if you can use it, or if you can use a particular traffic, or if you can use it, or if you can use it, or if you can use it, or the car car car, or if you can use it, or if you can use it to surgerators to the car car, or the most special traffic in the air, or the ground, you can't use it, it, it was either use it,
2022-03-23 10:04:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:04:26 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 6.932 | nll_loss 3.238 | ppl 9.43 | bleu 26.77 | wps 4835.6 | wpb 17862.2 | bsz 728.3 | num_updates 3919 | best_bleu 27.63
2022-03-23 10:04:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3919 updates
2022-03-23 10:04:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:04:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:04:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 25 @ 3919 updates, score 26.77) (writing took 0.8014665119990241 seconds)
2022-03-23 10:04:26 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:04:26 | INFO | train | epoch 025 | loss 6.872 | nll_loss 3.526 | ppl 11.52 | wps 44672.8 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 3919 | lr 0.000489875 | gnorm 0.501 | loss_scale 2 | train_wall 48 | gb_free 14.6 | wall 2334
2022-03-23 10:04:27 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:04:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:04:52 | INFO | train_inner | epoch 026:     81 / 157 loss=6.792, nll_loss=3.406, ppl=10.6, wps=36154.7, ups=1.42, wpb=25541.6, bsz=1024.2, num_updates=4000, lr=0.0005, gnorm=0.453, loss_scale=2, train_wall=30, gb_free=14.3, wall=2360
2022-03-23 10:05:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:05:19 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheets in the clinic.
2022-03-23 10:05:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:05:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here.
2022-03-23 10:05:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:05:28 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create two new pigs.
2022-03-23 10:05:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:05:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pitcase.
2022-03-23 10:05:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:05:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of your thoughts are on the track.
2022-03-23 10:05:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:05:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature like people's responsibility for the wild, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-23 10:05:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:05:44 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught in the inside, but the superconductor may not like you move, because your movements use energy, and so the superconducting disorders.
2022-03-23 10:05:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:05:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that gives the big constructions of the face and the basic shape, and refuse it all the ports of information and all the fits.
2022-03-23 10:05:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that... tyes, when dinner was the best summarized when someone said, "turn you to your table and say," 'if the revolution starts to support you.' "'"' "'"' "the truth is that we've already been supported for you for this long time, we've already been supported with a prior of silly cardial topic, then we've been supported by the future of our"] ["] [to be supported with cohereyourselves."
2022-03-23 10:05:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're at our aircraft, was a result that we had to solve the unique problems that were connected to surgery -- everything, from a continuous variation and a refrigering system that allows us to be able to use a fluid machine to be able to be used to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 10:05:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:55 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 6.806 | nll_loss 3.066 | ppl 8.37 | bleu 29.23 | wps 4649.3 | wpb 17862.2 | bsz 728.3 | num_updates 4076 | best_bleu 29.23
2022-03-23 10:05:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4076 updates
2022-03-23 10:05:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:05:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:05:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 26 @ 4076 updates, score 29.23) (writing took 1.7339286619971972 seconds)
2022-03-23 10:05:56 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:05:56 | INFO | train | epoch 026 | loss 6.793 | nll_loss 3.409 | ppl 10.62 | wps 43872.5 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4076 | lr 0.000495317 | gnorm 0.458 | loss_scale 2 | train_wall 48 | gb_free 14.2 | wall 2424
2022-03-23 10:05:57 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:05:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:06:05 | INFO | train_inner | epoch 027:     24 / 157 loss=6.758, nll_loss=3.359, ppl=10.26, wps=34312.1, ups=1.38, wpb=24889.4, bsz=1086.3, num_updates=4100, lr=0.000493865, gnorm=0.46, loss_scale=2, train_wall=30, gb_free=13.9, wall=2432
2022-03-23 10:06:36 | INFO | train_inner | epoch 027:    124 / 157 loss=6.765, nll_loss=3.369, ppl=10.33, wps=80560.3, ups=3.22, wpb=25054.5, bsz=944.5, num_updates=4200, lr=0.00048795, gnorm=0.464, loss_scale=2, train_wall=31, gb_free=14, wall=2463
2022-03-23 10:06:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:50 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:06:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:06:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:06:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:06:58 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are two new pigs.
2022-03-23 10:06:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:07:01 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:07:01 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:07:05 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:07:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:07:09 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for wildlife, the number of wild animals grew up, and this is a foundation for conservation in namibia.
2022-03-23 10:07:09 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:07:13 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines in the inside, but the superconductors don't like it if they move, their movements use energy, and so the superconductor disorder.
2022-03-23 10:07:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:07:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that repeats the big constructions of the face and the basic shape, and refits it through the theast of information that refits the whole porch structure and all the fits.
2022-03-23 10:07:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:07:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it high-interesting and measured for me here at tedwomen is that... tyes, when dinner was best summarized when someone said, "turn you to your men in your table and tell you," when the revolution starts. "
2022-03-23 10:07:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:07:22 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane at the stest, was a result that we had to solve the unique problems that were connected to operating the ground -- everything from a continuous variation and refrigering system, that allows us to use a refrigering machine, and if you can.
2022-03-23 10:07:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:07:22 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 6.767 | nll_loss 3.012 | ppl 8.07 | bleu 28.93 | wps 5186.8 | wpb 17862.2 | bsz 728.3 | num_updates 4233 | best_bleu 29.23
2022-03-23 10:07:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4233 updates
2022-03-23 10:07:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:07:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:07:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 27 @ 4233 updates, score 28.93) (writing took 0.7495910470024683 seconds)
2022-03-23 10:07:22 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:07:22 | INFO | train | epoch 027 | loss 6.738 | nll_loss 3.331 | ppl 10.06 | wps 45897.4 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 4233 | lr 0.000486044 | gnorm 0.453 | loss_scale 2 | train_wall 48 | gb_free 14 | wall 2510
2022-03-23 10:07:23 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:07:44 | INFO | train_inner | epoch 028:     67 / 157 loss=6.696, nll_loss=3.268, ppl=9.63, wps=36750.4, ups=1.48, wpb=24911.1, bsz=1019.6, num_updates=4300, lr=0.000482243, gnorm=0.437, loss_scale=2, train_wall=30, gb_free=14.6, wall=2531
2022-03-23 10:08:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:08:15 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:08:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:08:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:08:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:08:23 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to be exposed to two new pigs.
2022-03-23 10:08:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:08:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:08:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:08:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:08:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:08:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature like people's responsibility for wildlife, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-23 10:08:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:08:39 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught in the inside, but the superconductor doesn't like it if they're moving because their movements use energy, and so the superconducting disorder.
2022-03-23 10:08:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:08:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big configurations of the face and the basic form, and through the one of the information that refers the whole porch structure and all the fits.
2022-03-23 10:08:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured to me here at tedwomen is that -- well, when they were striking dinner, it was the best summarized when someone said, "turn you to the men on your table and say," if the revolution starts to support you. "the truth is that we've been supporting you for a long time."
2022-03-23 10:08:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation, and a system with a refrigeration that allows us to use a refrigeration, to a refrigering machine, to the aircraft, to a particular, to the aircraft, to either be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use, to use, to use, or to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 10:08:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:49 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 6.729 | nll_loss 2.943 | ppl 7.69 | bleu 30.35 | wps 4814.5 | wpb 17862.2 | bsz 728.3 | num_updates 4390 | best_bleu 30.35
2022-03-23 10:08:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4390 updates
2022-03-23 10:08:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:08:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:08:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 28 @ 4390 updates, score 30.35) (writing took 1.703068650997011 seconds)
2022-03-23 10:08:51 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:08:51 | INFO | train | epoch 028 | loss 6.695 | nll_loss 3.268 | ppl 9.63 | wps 44583.9 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 4390 | lr 0.000477274 | gnorm 0.455 | loss_scale 2 | train_wall 48 | gb_free 13.7 | wall 2598
2022-03-23 10:08:51 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:08:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:08:54 | INFO | train_inner | epoch 029:     10 / 157 loss=6.712, nll_loss=3.294, ppl=9.81, wps=35636.7, ups=1.41, wpb=25232.2, bsz=988.5, num_updates=4400, lr=0.000476731, gnorm=0.478, loss_scale=2, train_wall=30, gb_free=13.6, wall=2602
2022-03-23 10:09:26 | INFO | train_inner | epoch 029:    110 / 157 loss=6.637, nll_loss=3.184, ppl=9.09, wps=80484.8, ups=3.21, wpb=25083.8, bsz=1023.4, num_updates=4500, lr=0.000471405, gnorm=0.416, loss_scale=2, train_wall=31, gb_free=13.6, wall=2633
2022-03-23 10:09:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:44 | INFO | fairseq.tasks.translation | example hypothesis: we put these bars in the clinic.
2022-03-23 10:09:44 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:09:48 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:09:48 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:09:52 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-23 10:09:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:09:56 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 10:09:56 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:10:00 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:10:00 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:10:03 | INFO | fairseq.tasks.translation | example hypothesis: and in the maginet of how people were responsible for wildlife, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-23 10:10:03 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:10:07 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:10:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:10:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that refold the big constructions of the facial and the basic shape, and the information that refers the whole pora structure and all fold a fold.
2022-03-23 10:10:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:10:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was highly interesting and measured for me here at tedwomen is that... tja, when dinner was best summarized, when someone said, "turn you to the men on your table and tell them," if the revolution starts to support you. "
2022-03-23 10:10:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:10:18 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large piece of design work that we're on our aircraft, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation and a refrigerator system that allows us to use a machine in the air, or if you can see it in the air, or if you can see that it's a machine, it allows us to use it to use the air, or if you can use it, or if you can use the air, or if you can see the air, it's either, it's a mechanism, it's a mechanism, or if you can use it's a mechanism, or if you can see it's a mechanism, or if you can see it's a mechanism, or if you can use it's a mechanism, or if you can see the air, or if you can see the ground, or if you can see the air, or if you can see the air, the
2022-03-23 10:10:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:10:18 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 6.706 | nll_loss 2.929 | ppl 7.62 | bleu 30.21 | wps 4774.4 | wpb 17862.2 | bsz 728.3 | num_updates 4547 | best_bleu 30.35
2022-03-23 10:10:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4547 updates
2022-03-23 10:10:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:10:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:10:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 29 @ 4547 updates, score 30.21) (writing took 0.7853973480087006 seconds)
2022-03-23 10:10:19 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:10:19 | INFO | train | epoch 029 | loss 6.641 | nll_loss 3.19 | ppl 9.12 | wps 44914.2 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 4547 | lr 0.000468962 | gnorm 0.433 | loss_scale 2 | train_wall 48 | gb_free 13.3 | wall 2686
2022-03-23 10:10:19 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:10:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:10:36 | INFO | train_inner | epoch 030:     53 / 157 loss=6.629, nll_loss=3.172, ppl=9.01, wps=35694.2, ups=1.42, wpb=25115, bsz=976.6, num_updates=4600, lr=0.000466252, gnorm=0.436, loss_scale=2, train_wall=30, gb_free=13.8, wall=2703
2022-03-23 10:11:07 | INFO | train_inner | epoch 030:    153 / 157 loss=6.568, nll_loss=3.086, ppl=8.49, wps=81801.7, ups=3.23, wpb=25329, bsz=1070.9, num_updates=4700, lr=0.000461266, gnorm=0.378, loss_scale=2, train_wall=31, gb_free=13.7, wall=2734
2022-03-23 10:11:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:11:12 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep sheep in the clinic.
2022-03-23 10:11:12 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:11:16 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:11:16 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:11:20 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to transcend two new pigs.
2022-03-23 10:11:20 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:11:24 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper suitcase.
2022-03-23 10:11:24 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:11:28 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all his thoughts are on the track.
2022-03-23 10:11:28 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:11:32 | INFO | fairseq.tasks.translation | example hypothesis: and it's like people's responsibility for wildlife, the number of wild animals grew back again, and that's a basis for conservation in namibia.
2022-03-23 10:11:32 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:11:36 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught in the inside, but the superconductor doesn't like if you move, your movements use energy, and so the superconducting disorder.
2022-03-23 10:11:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:11:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big configurations of the facial and the basic shape, and by the one that refits the whole port structure and all the fits.
2022-03-23 10:11:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:44 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's highly interesting and measured to me here at tedwomen is that... well, when we were striking dinner, it was best summarized when someone said, "turn to men on your table and tell you," if the revolution starts to support you. "the truth is we've already been supporting you for a long time."
2022-03-23 10:11:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:46 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and a big part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuous variation and a refrigeration system that allows us to use an aircraft in a particular way, to be able to use the propellation, to be able to use the ground.
2022-03-23 10:11:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:46 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 6.657 | nll_loss 2.885 | ppl 7.39 | bleu 30.61 | wps 4930.4 | wpb 17862.2 | bsz 728.3 | num_updates 4704 | best_bleu 30.61
2022-03-23 10:11:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4704 updates
2022-03-23 10:11:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:11:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:11:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 30 @ 4704 updates, score 30.61) (writing took 1.8011623490019701 seconds)
2022-03-23 10:11:47 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:11:47 | INFO | train | epoch 030 | loss 6.581 | nll_loss 3.102 | ppl 8.59 | wps 44593.4 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 4704 | lr 0.000461069 | gnorm 0.394 | loss_scale 2 | train_wall 48 | gb_free 13.4 | wall 2775
2022-03-23 10:11:48 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:11:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:12:18 | INFO | train_inner | epoch 031:     96 / 157 loss=6.579, nll_loss=3.101, ppl=8.58, wps=35760.6, ups=1.4, wpb=25461, bsz=1003.8, num_updates=4800, lr=0.000456435, gnorm=0.444, loss_scale=2, train_wall=31, gb_free=14.1, wall=2806
2022-03-23 10:12:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:12:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:12:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:12:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:12:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:12:48 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create two new vibrations.
2022-03-23 10:12:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:12:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pfat suitcase.
2022-03-23 10:12:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:12:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:12:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:13:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the name of how people were responsible for wildlife, the number of wildlife animals grew up again, and this has become a foundation for conservation in namibia.
2022-03-23 10:13:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:13:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductors don't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:13:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:13:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restores the big configurations of the face and the basic shape, and refits it through the one of the one that refits the whole porter structure and all the fits a fold.
2022-03-23 10:13:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:13:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured to me here at tedwomen is that... well, when dinner was sucked up, it was the best summarized when someone said, "turn to the men on your table and tell them," if the revolution begins, we support you. "the truth is that we've been supporting you for a long time."
2022-03-23 10:13:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:13:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our aircraft, was a result that we had to solve the unique problems that were connected to surgery -- everything, from a continuous variation and a refrigeration system that allows us to use an aircraft in the aircraft, to be able to use in a very staggregation, or to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use an aircraft in the propelled by a special traffic in the ground, to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 10:13:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:13:15 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 6.635 | nll_loss 2.83 | ppl 7.11 | bleu 31.51 | wps 4752.8 | wpb 17862.2 | bsz 728.3 | num_updates 4861 | best_bleu 31.51
2022-03-23 10:13:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4861 updates
2022-03-23 10:13:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:13:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:13:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 31 @ 4861 updates, score 31.51) (writing took 1.7628852589987218 seconds)
2022-03-23 10:13:17 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:13:17 | INFO | train | epoch 031 | loss 6.562 | nll_loss 3.077 | ppl 8.44 | wps 44298.6 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4861 | lr 0.000453563 | gnorm 0.422 | loss_scale 2 | train_wall 48 | gb_free 13.3 | wall 2864
2022-03-23 10:13:17 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:13:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:13:29 | INFO | train_inner | epoch 032:     39 / 157 loss=6.503, nll_loss=2.99, ppl=7.95, wps=34974.2, ups=1.4, wpb=24902.2, bsz=1052.5, num_updates=4900, lr=0.000451754, gnorm=0.369, loss_scale=2, train_wall=30, gb_free=14.3, wall=2877
2022-03-23 10:14:01 | INFO | train_inner | epoch 032:    139 / 157 loss=6.519, nll_loss=3.015, ppl=8.09, wps=80827.4, ups=3.2, wpb=25232, bsz=1043, num_updates=5000, lr=0.000447214, gnorm=0.415, loss_scale=2, train_wall=31, gb_free=15.1, wall=2908
2022-03-23 10:14:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:14:10 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep beep in the clinic.
2022-03-23 10:14:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:14:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:14:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:14:18 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to transcend two new pigs.
2022-03-23 10:14:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:14:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pills.
2022-03-23 10:14:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:14:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:14:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:14:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wild animals grew back. and this has become a basis for conservation in namibia.
2022-03-23 10:14:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:14:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:14:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:14:37 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big contures of the face and the basic shape, and then refold it through the one information that pulls the whole por-structure and all fits.
2022-03-23 10:14:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate for me to be here at tedwomen is that... well, when you're striking dinner, it's best summarized when someone said, "turn to men in your table and tell them, 'when the revolution begins, we support you."' "'"
2022-03-23 10:14:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our plane, was a result that we had to solve the unique problems that were connected to doing it -- everything, from a continuous variation and a refrigeration system that allows us to use aircraft in the air, and to use an aircraft, and to a special traffic, or to be propelled, or if you look at the ground, all, and you can see it's all, and you can see it's all, all, and you can see it's all, and you can see, and you can see in the same way, and you can see, and you can see, and you can see, and you can see, and you can see, and you can see, and you can see, and you can see, in the same way, and you can see, and you can see, you can see, and you can see, you can see, and you can see, and you can
2022-03-23 10:14:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:44 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 6.618 | nll_loss 2.81 | ppl 7.01 | bleu 31.53 | wps 4778.4 | wpb 17862.2 | bsz 728.3 | num_updates 5018 | best_bleu 31.53
2022-03-23 10:14:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5018 updates
2022-03-23 10:14:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:14:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:14:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 32 @ 5018 updates, score 31.53) (writing took 1.8413113000133308 seconds)
2022-03-23 10:14:46 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:14:46 | INFO | train | epoch 032 | loss 6.509 | nll_loss 3 | ppl 8 | wps 44309.2 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 5018 | lr 0.000446411 | gnorm 0.395 | loss_scale 2 | train_wall 48 | gb_free 14.5 | wall 2953
2022-03-23 10:14:46 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:14:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:15:12 | INFO | train_inner | epoch 033:     82 / 157 loss=6.446, nll_loss=2.909, ppl=7.51, wps=35331.6, ups=1.4, wpb=25215.2, bsz=1107.8, num_updates=5100, lr=0.000442807, gnorm=0.377, loss_scale=2, train_wall=30, gb_free=13.5, wall=2979
2022-03-23 10:15:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:15:39 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep sheep sheep in the clinic.
2022-03-23 10:15:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:15:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:15:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:15:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of goldilocks that are going to transcend two new pigs.
2022-03-23 10:15:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:15:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pfat suitcase.
2022-03-23 10:15:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:15:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:15:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:15:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, like the people's responsibility for wildlife revenues, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:15:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:16:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:16:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:16:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that repeats the big configurations of the face and the basic form, and then refuse it through the one of the one information that refers the whole porch structure and all the fits.
2022-03-23 10:16:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:16:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was highly interesting and measured to me here at tedwomen is that... well, when congestion dinner, it was best summarized when someone said, "turn to the men on your table, and tell them," if the revolution starts to support you. "the truth is that we've already been supporting you for a long time with silly."
2022-03-23 10:16:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:16:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a refrigeration system that allows us to use an aircraft in the same way, or if you're going to fly the ground, to be able to operate it, to operate on the ground, to operate it, to operate it, to operate it, and to the safety space of a particular, to the ground, or to be able to be able to be done.
2022-03-23 10:16:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:16:13 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 6.572 | nll_loss 2.779 | ppl 6.87 | bleu 32.39 | wps 4845.2 | wpb 17862.2 | bsz 728.3 | num_updates 5175 | best_bleu 32.39
2022-03-23 10:16:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5175 updates
2022-03-23 10:16:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:16:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:16:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 33 @ 5175 updates, score 32.39) (writing took 1.8365745119954227 seconds)
2022-03-23 10:16:15 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:16:15 | INFO | train | epoch 033 | loss 6.471 | nll_loss 2.944 | ppl 7.69 | wps 44480.9 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5175 | lr 0.000439587 | gnorm 0.381 | loss_scale 2 | train_wall 48 | gb_free 14 | wall 3042
2022-03-23 10:16:15 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:16:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:16:23 | INFO | train_inner | epoch 034:     25 / 157 loss=6.498, nll_loss=2.983, ppl=7.91, wps=35229.3, ups=1.4, wpb=25083.3, bsz=912.9, num_updates=5200, lr=0.000438529, gnorm=0.393, loss_scale=2, train_wall=30, gb_free=13.8, wall=3051
2022-03-23 10:16:54 | INFO | train_inner | epoch 034:    125 / 157 loss=6.429, nll_loss=2.884, ppl=7.38, wps=80725.6, ups=3.21, wpb=25111.2, bsz=1056.8, num_updates=5300, lr=0.000434372, gnorm=0.391, loss_scale=2, train_wall=31, gb_free=14.3, wall=3082
2022-03-23 10:17:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:17:08 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:17:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:17:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:17:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:17:16 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to transcend two new pigs.
2022-03-23 10:17:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:17:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and peaks.
2022-03-23 10:17:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:17:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all of their thoughts are on the track.
2022-03-23 10:17:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:17:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people were responsible for wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:17:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:17:32 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like if they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:17:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:17:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection, which gives the big constraints of the face and restores the basic shape, and refuse it through the one who pulls the whole porch structure and all the fits the fine.
2022-03-23 10:17:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:17:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it high-interesting and appropriate for me here at tedwomen is that -- well, when dinner was best summarized when someone said, "turn to the men on your table and tell you, '" if the revolution begins, "then we support you." "the truth, we've been supporting you is that we've already been supporting you for a long time." "" ""
2022-03-23 10:17:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variable, and a cooling system with a refrigerator that allows us to use an aircraft in the aircraft, until go-to-gosh traffic, to a specially appropriate one, which is that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 10:17:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:43 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 6.587 | nll_loss 2.781 | ppl 6.87 | bleu 32.36 | wps 4667.7 | wpb 17862.2 | bsz 728.3 | num_updates 5332 | best_bleu 32.39
2022-03-23 10:17:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5332 updates
2022-03-23 10:17:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:17:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:17:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 34 @ 5332 updates, score 32.36) (writing took 0.8276892020076048 seconds)
2022-03-23 10:17:44 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:17:44 | INFO | train | epoch 034 | loss 6.442 | nll_loss 2.903 | ppl 7.48 | wps 44055.7 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5332 | lr 0.000433067 | gnorm 0.397 | loss_scale 2 | train_wall 48 | gb_free 13.7 | wall 3132
2022-03-23 10:17:45 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:17:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:18:06 | INFO | train_inner | epoch 035:     68 / 157 loss=6.444, nll_loss=2.905, ppl=7.49, wps=35009.7, ups=1.39, wpb=25183.3, bsz=969.6, num_updates=5400, lr=0.000430331, gnorm=0.409, loss_scale=2, train_wall=30, gb_free=13.7, wall=3154
2022-03-23 10:18:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:18:37 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep beep in the clinic.
2022-03-23 10:18:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:18:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:18:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:18:45 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that are going to overwrite two new pigs.
2022-03-23 10:18:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:18:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:18:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:18:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 10:18:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:18:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:18:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:19:01 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like when they move because their movements use energy, and so the superconducting disorder.
2022-03-23 10:19:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:19:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can of the face and the basic form, and restoring it through the one of the information that pulls the whole por-structure and all the fits.
2022-03-23 10:19:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:19:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that -- well, when dinner was best summarized when someone said, "turn to men on your table and tell them," when the revolution begins, we support you. '"the truth, women, we've already been supporting you for a long time."
2022-03-23 10:19:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:19:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuous variable operating and a cooling system with fluid that allows us to use a machine in the stop traffic to a specially appropriate car, or if you run the propelled for the ground, all the way that we can do it, all the way, all the way to operate in the way, all the way, if you can see the way that you can see the way that you can see the way that you can see the way that you can see that you can see that you can see that you can do it in a continuously variattribute of a continuously variable way that you can see that you can see that you can see it in a continuously variable variable variable way, you can see that you can see it
2022-03-23 10:19:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:19:12 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 6.545 | nll_loss 2.75 | ppl 6.73 | bleu 32.31 | wps 4768.9 | wpb 17862.2 | bsz 728.3 | num_updates 5489 | best_bleu 32.39
2022-03-23 10:19:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5489 updates
2022-03-23 10:19:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:19:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:19:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 35 @ 5489 updates, score 32.31) (writing took 1.5338850539992563 seconds)
2022-03-23 10:19:13 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:19:13 | INFO | train | epoch 035 | loss 6.409 | nll_loss 2.856 | ppl 7.24 | wps 44269.8 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 5489 | lr 0.000426828 | gnorm 0.38 | loss_scale 2 | train_wall 48 | gb_free 13.3 | wall 3221
2022-03-23 10:19:14 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:19:17 | INFO | train_inner | epoch 036:     11 / 157 loss=6.393, nll_loss=2.833, ppl=7.12, wps=35070.7, ups=1.41, wpb=24926.8, bsz=1040.6, num_updates=5500, lr=0.000426401, gnorm=0.356, loss_scale=2, train_wall=30, gb_free=13.5, wall=3225
2022-03-23 10:19:49 | INFO | train_inner | epoch 036:    111 / 157 loss=6.372, nll_loss=2.8, ppl=6.96, wps=80521.5, ups=3.19, wpb=25219.9, bsz=1035.4, num_updates=5600, lr=0.000422577, gnorm=0.359, loss_scale=2, train_wall=31, gb_free=13.1, wall=3256
2022-03-23 10:20:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:20:06 | INFO | fairseq.tasks.translation | example hypothesis: we set up these tweep sheep in the clinic.
2022-03-23 10:20:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:20:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:20:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:20:14 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of goldilocks that will be exposed to two new vibrations.
2022-03-23 10:20:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:20:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:20:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:20:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:20:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:20:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew back up again, and this has become a basis for conservation in namibia.
2022-03-23 10:20:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:20:31 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:20:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:20:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial bar that refuses the big configurations of the face and the basic shape, and then reconcipating it through the one of the information that refers the entire por-structure and all the fits the fits the fits the fits.
2022-03-23 10:20:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:20:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate, for me here at tedwomen, is that... well, in the strict dinner, it was the best summarized when someone said, "turn to the men on your table and tell them, 'if the revolution starts to support you.' '' '" the truth, we have the truth, women, we've already been supporting you for this topic for a long time. "
2022-03-23 10:20:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:20:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, there's still the mother of invention, and a big part of the design work that we're on on our plane at the most staggering, which was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variable operator and a refrigerator system with fluid that allows us to use an aircraft in the stop and to use of a conviction until either you're going to be able to be able to be able to be able to be able to be able to make a progressive or if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to operate on the rail or if you're going to be able to be able to be able to
2022-03-23 10:20:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:20:42 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 6.552 | nll_loss 2.739 | ppl 6.68 | bleu 32.56 | wps 4635.4 | wpb 17862.2 | bsz 728.3 | num_updates 5646 | best_bleu 32.56
2022-03-23 10:20:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5646 updates
2022-03-23 10:20:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:20:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:20:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 36 @ 5646 updates, score 32.56) (writing took 1.8362855190061964 seconds)
2022-03-23 10:20:44 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:20:44 | INFO | train | epoch 036 | loss 6.381 | nll_loss 2.815 | ppl 7.04 | wps 43777.1 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5646 | lr 0.000420852 | gnorm 0.381 | loss_scale 2 | train_wall 48 | gb_free 13.9 | wall 3311
2022-03-23 10:20:44 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:20:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:21:01 | INFO | train_inner | epoch 037:     54 / 157 loss=6.344, nll_loss=2.762, ppl=6.79, wps=35334.4, ups=1.39, wpb=25504.9, bsz=1104.3, num_updates=5700, lr=0.000418854, gnorm=0.385, loss_scale=2, train_wall=30, gb_free=14.4, wall=3328
2022-03-23 10:21:32 | INFO | train_inner | epoch 037:    154 / 157 loss=6.402, nll_loss=2.844, ppl=7.18, wps=80253, ups=3.23, wpb=24814.5, bsz=897.4, num_updates=5800, lr=0.000415227, gnorm=0.379, loss_scale=2, train_wall=31, gb_free=14.3, wall=3359
2022-03-23 10:21:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:21:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep beep in the clinic.
2022-03-23 10:21:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:21:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:21:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:21:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of mine that are going to transcend two new pigs.
2022-03-23 10:21:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:21:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:21:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:21:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 10:21:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:21:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people were taking responsibility for wildlife, the number of wildlife was growing up again, and that's become a basis for conservation in namibia.
2022-03-23 10:21:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:22:01 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it if they move, they use their movements of energy, and so the superconductor disorder.
2022-03-23 10:22:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:22:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that repeats the big contures of the face and restore the basic form of the face and fold it through the same information that refers the whole por-structure and all the fits.
2022-03-23 10:22:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:22:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that -- well, when constrict dinner, it was best summarized when someone said, "turn to the men on your table and tell them," if the revolution starts, we support you. '' '"" the truth, love, is that we've already supported you in this topic for a long time.
2022-03-23 10:22:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:22:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on on our aircraft at the stumble, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable drive and a cooling system with liquid refrigerators that allows us to use a machine in our aircraft in the aircraft on our plane to use of the road to a very stumpy traffic, to a specifile, or if we're going to be able to be able to be able to be able to be able to be able to run in the air.
2022-03-23 10:22:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:22:11 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 6.519 | nll_loss 2.685 | ppl 6.43 | bleu 32.77 | wps 4782.7 | wpb 17862.2 | bsz 728.3 | num_updates 5803 | best_bleu 32.77
2022-03-23 10:22:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5803 updates
2022-03-23 10:22:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:22:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:22:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 37 @ 5803 updates, score 32.77) (writing took 1.7799244430061663 seconds)
2022-03-23 10:22:13 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:22:13 | INFO | train | epoch 037 | loss 6.359 | nll_loss 2.782 | ppl 6.88 | wps 44403.3 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5803 | lr 0.00041512 | gnorm 0.366 | loss_scale 2 | train_wall 48 | gb_free 14.2 | wall 3400
2022-03-23 10:22:13 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:22:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:22:43 | INFO | train_inner | epoch 038:     97 / 157 loss=6.35, nll_loss=2.769, ppl=6.81, wps=34497.7, ups=1.4, wpb=24616.2, bsz=1005.4, num_updates=5900, lr=0.000411693, gnorm=0.379, loss_scale=2, train_wall=31, gb_free=14.3, wall=3430
2022-03-23 10:23:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:23:05 | INFO | fairseq.tasks.translation | example hypothesis: we put those beep beep in the clinic.
2022-03-23 10:23:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:23:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 10:23:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:23:13 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new gold locks that will transcend two new pigs.
2022-03-23 10:23:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:23:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:23:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:23:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 10:23:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:23:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew back again, and this has become a basis for conservation in namibia.
2022-03-23 10:23:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:23:29 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are captured inside, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconducting.
2022-03-23 10:23:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:23:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which repeats the big contures of the face and the basic form, and encode it through the one that refers the whole porch structure and all the fine.
2022-03-23 10:23:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:23:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when we were striking dinner, it was best summarized when someone said, "turn to the men on your table and tell you," the truth is that we've been supporting you. "
2022-03-23 10:23:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:23:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable operating and a refrigeration system that allows us to use an aircraft in the stop and to a special traffic to an aircraft in a propeller, to either drive, or a propeller, to either when you can see the aircraft in a mechanism, or an aircraft that, or an aircraft in the aircraft that, or an aircraft, or an aircraft that's going to a propeller, or a mechanism, or an aircraft that's going to an aircraft that, or an aircraft that's going to an aircraft that's going to an aircraft that's going to an aircraft that's going to an aircraft that's going to an aircraft that's going to a propeller, or a propeller,
2022-03-23 10:23:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:23:40 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 6.514 | nll_loss 2.688 | ppl 6.44 | bleu 32.56 | wps 4763.8 | wpb 17862.2 | bsz 728.3 | num_updates 5960 | best_bleu 32.77
2022-03-23 10:23:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5960 updates
2022-03-23 10:23:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:23:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:23:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 38 @ 5960 updates, score 32.56) (writing took 0.7872010639985092 seconds)
2022-03-23 10:23:41 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:23:41 | INFO | train | epoch 038 | loss 6.347 | nll_loss 2.766 | ppl 6.8 | wps 44878.2 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5960 | lr 0.000409616 | gnorm 0.389 | loss_scale 2 | train_wall 48 | gb_free 14.9 | wall 3488
2022-03-23 10:23:41 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:23:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:23:54 | INFO | train_inner | epoch 039:     40 / 157 loss=6.292, nll_loss=2.686, ppl=6.44, wps=37050.1, ups=1.42, wpb=26159.2, bsz=1155.7, num_updates=6000, lr=0.000408248, gnorm=0.364, loss_scale=2, train_wall=31, gb_free=13.3, wall=3501
2022-03-23 10:24:25 | INFO | train_inner | epoch 039:    140 / 157 loss=6.342, nll_loss=2.757, ppl=6.76, wps=80079, ups=3.23, wpb=24788.3, bsz=940.1, num_updates=6100, lr=0.000404888, gnorm=0.392, loss_scale=2, train_wall=31, gb_free=13.6, wall=3532
2022-03-23 10:24:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:24:33 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep beep in the clinic.
2022-03-23 10:24:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:24:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:24:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:24:41 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of goldilocks that will be exposed to two new vibrations.
2022-03-23 10:24:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:24:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:24:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:24:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:24:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:24:53 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:24:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:24:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines in the inside, but the superconductor doesn't like it if you move, your movements are using energy, and so the superconducting disorders.
2022-03-23 10:24:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:25:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that refers the big constraints of the face and refers the basic shape, and refers it through the same information that pulls the whole por-structure and all the fine folds.
2022-03-23 10:25:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:25:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it was very interesting and appropriate for me to be here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn to the men on your table and say," 'if the revolution begins, then we support you. "' the truth, women love you, is that we've already been supporting you for a long time. in fact, we've been supporting you with this topic of rachel spring," in the future of our prior spring spring spring, "to sandman, and then," down the future, "down to sandmarks of our prior before before before the future," sandra scholar ar, "sandra schededededules of our prior so forth, and our prior before the future, and our own,
2022-03-23 10:25:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:25:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane is the stumble, was a result that we had to solve the unique problems that were connected to it, all, from a continuously variable, and a cooling system of liquid, that allows us to use an aircraft in the stop and transportation to a specially appropriate drive, or either, or if you can see the propelled the soil of a mechanism, all the way around the ground of a mechanism, and a mechanism that's going to fly in the same way that we see the same way that's going to be connected to the air system that's going to the air system that's going to a mechanism.
2022-03-23 10:25:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:25:09 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 6.49 | nll_loss 2.663 | ppl 6.34 | bleu 33.25 | wps 4665 | wpb 17862.2 | bsz 728.3 | num_updates 6117 | best_bleu 33.25
2022-03-23 10:25:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6117 updates
2022-03-23 10:25:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:25:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:25:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 39 @ 6117 updates, score 33.25) (writing took 1.7511775660095736 seconds)
2022-03-23 10:25:10 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:25:10 | INFO | train | epoch 039 | loss 6.312 | nll_loss 2.715 | ppl 6.57 | wps 43964.7 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 6117 | lr 0.000404325 | gnorm 0.365 | loss_scale 2 | train_wall 48 | gb_free 14.8 | wall 3578
2022-03-23 10:25:11 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:25:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:25:37 | INFO | train_inner | epoch 040:     83 / 157 loss=6.293, nll_loss=2.686, ppl=6.44, wps=34441.5, ups=1.39, wpb=24847, bsz=995.6, num_updates=6200, lr=0.00040161, gnorm=0.338, loss_scale=2, train_wall=30, gb_free=13.8, wall=3604
2022-03-23 10:25:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:26:03 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters up in the clinic.
2022-03-23 10:26:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:26:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:26:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:26:11 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that create two new vibrations.
2022-03-23 10:26:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:26:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:26:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:26:19 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:26:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:26:23 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife grew back on, and that's become a foundation for conservation in namibia.
2022-03-23 10:26:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:26:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:26:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:26:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that repeats the big constructions of the face and the basic form, and then then restore it through the one of these information that refers all the por-structure and all the fine folds.
2022-03-23 10:26:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:26:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that... well, when constrict dinner was summarized it best, when somebody said, "turn you to the men on your table and tell you," turn to the men and tell you, "if the revolution begins, then we support you, then we support you. '" the truth, love is that we've already supported you for a long time. "at rachel spring's"
2022-03-23 10:26:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:26:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention, and a large part of the design work that we're on on our airplane at the stumber, was a result that we had to solve the unique problems that were connected to it, to operate on the ground -- everything, from a continuously variable drive and a cooling system of fluid, that allows us to use an aircraft in the stop and transportation to a special drive, which is either propelled to the ground, or if you see the ground in the same way that's going to a mechanism, or if you're going to the correct one, it's going to the ground, or if you're going to the aircraft, it's in a mechanism, or if you're going to the aircraft, or if you're going to the correct, it's going to the ground, it's going to the ground, or if you're going to the aircraft, it's going to the ground, it's going to the correct,
2022-03-23 10:26:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:26:38 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 6.502 | nll_loss 2.671 | ppl 6.37 | bleu 33.28 | wps 4751.4 | wpb 17862.2 | bsz 728.3 | num_updates 6274 | best_bleu 33.28
2022-03-23 10:26:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6274 updates
2022-03-23 10:26:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:26:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:26:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 40 @ 6274 updates, score 33.28) (writing took 1.87310639199859 seconds)
2022-03-23 10:26:40 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:26:40 | INFO | train | epoch 040 | loss 6.285 | nll_loss 2.676 | ppl 6.39 | wps 44171.1 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 6274 | lr 0.000399234 | gnorm 0.348 | loss_scale 2 | train_wall 48 | gb_free 14.1 | wall 3667
2022-03-23 10:26:40 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:26:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:26:48 | INFO | train_inner | epoch 041:     26 / 157 loss=6.298, nll_loss=2.695, ppl=6.48, wps=35581, ups=1.4, wpb=25414.2, bsz=998.1, num_updates=6300, lr=0.00039841, gnorm=0.365, loss_scale=2, train_wall=30, gb_free=14.9, wall=3676
2022-03-23 10:27:19 | INFO | train_inner | epoch 041:    126 / 157 loss=6.275, nll_loss=2.66, ppl=6.32, wps=80199.6, ups=3.22, wpb=24908.3, bsz=1021.4, num_updates=6400, lr=0.000395285, gnorm=0.382, loss_scale=2, train_wall=31, gb_free=14.2, wall=3707
2022-03-23 10:27:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:27:33 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep beep in the clinic.
2022-03-23 10:27:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:27:36 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:27:36 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:27:40 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to be exposed to two new vibrations.
2022-03-23 10:27:40 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:27:44 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:27:44 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:27:48 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on your head and understanding exactly what all of your thoughts are on the track.
2022-03-23 10:27:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:27:52 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife, the number of wildlife animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:27:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:27:56 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of the magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorders.
2022-03-23 10:27:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:28:01 | INFO | fairseq.tasks.translation | example hypothesis: so, when we use the information that comes from this reflection, we can start with a traditional facial can that repeats the big contures of the face and the basic form, and refers it through the one of the information that refers the whole por-structure and all the fits.
2022-03-23 10:28:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:28:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate for me to be here at tedwomen is that... well, when strictly dinner was summarized best, when someone said, "turn to the men at your table and tell them," if the revolution begins, we'll support you. "'the truth, women have already been supporting you for a long time. at rachel spring's future," and then we're going to download our silly spring, and then we're going to download the future. "
2022-03-23 10:28:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:28:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a big part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable, and a cooling system that allows us to use a aircraft in the stop and traffic to a specially appropriate vehicle, until either the propelled, or when we see the ground, all the way from a mechanism to the security system.
2022-03-23 10:28:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:28:07 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 6.448 | nll_loss 2.635 | ppl 6.21 | bleu 33.42 | wps 4779.2 | wpb 17862.2 | bsz 728.3 | num_updates 6431 | best_bleu 33.42
2022-03-23 10:28:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6431 updates
2022-03-23 10:28:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:28:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:28:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 41 @ 6431 updates, score 33.42) (writing took 1.6873855299927527 seconds)
2022-03-23 10:28:09 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:28:09 | INFO | train | epoch 041 | loss 6.277 | nll_loss 2.663 | ppl 6.34 | wps 44480.7 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6431 | lr 0.000394331 | gnorm 0.372 | loss_scale 2 | train_wall 48 | gb_free 13.6 | wall 3756
2022-03-23 10:28:09 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 10:28:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:28:30 | INFO | train_inner | epoch 042:     69 / 157 loss=6.25, nll_loss=2.625, ppl=6.17, wps=35473.4, ups=1.41, wpb=25194.2, bsz=1022.1, num_updates=6500, lr=0.000392232, gnorm=0.354, loss_scale=2, train_wall=30, gb_free=13.8, wall=3778
2022-03-23 10:28:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:29:02 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 10:29:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:29:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:29:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:29:09 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will create two new pigs.
2022-03-23 10:29:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:29:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:29:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:29:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:29:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:29:21 | INFO | fairseq.tasks.translation | example hypothesis: and as people took responsibility for wildlife, the number of wild animals grew back. and this has become a basis for conservation in namibia.
2022-03-23 10:29:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:29:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:29:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:29:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constraints of the face and the basic form, and defeat it through the one of the information that refers the whole por-structure and all the fine folds.
2022-03-23 10:29:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:29:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that -- well, when strictly dinner was best summarized when someone said, "turn to men on your table and tell them," when the revolution begins, we support you. "the truth is that we've already been supporting you for a long time. at rachel spring's"
2022-03-23 10:29:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:29:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane at the stumbling, was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variable operator and a cooling system with fluid that allows us to use an aircraft in the stop and transportation to a special drive, either when you see the propelled, or if you see the ground in the same way that you can see in the air, or if you can see the ground, you can see in the same way that you can see the ground, or if you can see it's a mechanism.
2022-03-23 10:29:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:29:36 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 6.478 | nll_loss 2.639 | ppl 6.23 | bleu 33.39 | wps 4771.3 | wpb 17862.2 | bsz 728.3 | num_updates 6588 | best_bleu 33.42
2022-03-23 10:29:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6588 updates
2022-03-23 10:29:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:29:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:29:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 42 @ 6588 updates, score 33.39) (writing took 0.8310545599961188 seconds)
2022-03-23 10:29:37 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 10:29:37 | INFO | train | epoch 042 | loss 6.249 | nll_loss 2.624 | ppl 6.17 | wps 44778.5 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 6588 | lr 0.000389604 | gnorm 0.351 | loss_scale 2 | train_wall 48 | gb_free 14.6 | wall 3844
2022-03-23 10:29:37 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 10:29:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:29:41 | INFO | train_inner | epoch 043:     12 / 157 loss=6.234, nll_loss=2.602, ppl=6.07, wps=36047.4, ups=1.41, wpb=25505, bsz=1088.5, num_updates=6600, lr=0.000389249, gnorm=0.337, loss_scale=2, train_wall=31, gb_free=13.6, wall=3848
2022-03-23 10:30:12 | INFO | train_inner | epoch 043:    112 / 157 loss=6.266, nll_loss=2.647, ppl=6.26, wps=80439.6, ups=3.24, wpb=24818.1, bsz=911.3, num_updates=6700, lr=0.000386334, gnorm=0.382, loss_scale=2, train_wall=31, gb_free=14.5, wall=3879
2022-03-23 10:30:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:30:30 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 10:30:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:30:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:30:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:30:37 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks events that create two new vibrations.
2022-03-23 10:30:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:30:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:30:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:30:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all your thoughts are on the track.
2022-03-23 10:30:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:30:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:30:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:30:54 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of the magnetic field lines in the inside are trapped, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:30:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:30:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that gives the big constructions of the face and the basic form, and then then then restore it through the information that refers the whole por-structure and all the fine wrinkles.
2022-03-23 10:30:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:31:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, dinner has been summarized best when someone said, "turn to the men on your table and tell them, 'if the revolution begins, then we support you.' the truth, women, we've been supporting you for a long time. at rachel carel's spring," and then our prior to the future of sand, and to downstream. "
2022-03-23 10:31:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:31:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our aircraft at the stumbling, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variable drive and a cooling system of fluid that allows us to use an aircraft in the stop and traffic to a specially appropriate vehicle that is either drifted up to the ground, or if you see the mechanism in the same way that it's going to a mechanism that's going to be able to be done in the same way that's going to be made by a mechanism, and to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the
2022-03-23 10:31:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:31:04 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 6.458 | nll_loss 2.617 | ppl 6.14 | bleu 33.62 | wps 4708.7 | wpb 17862.2 | bsz 728.3 | num_updates 6745 | best_bleu 33.62
2022-03-23 10:31:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6745 updates
2022-03-23 10:31:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:31:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:31:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 43 @ 6745 updates, score 33.62) (writing took 1.8992607700056396 seconds)
2022-03-23 10:31:06 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 10:31:06 | INFO | train | epoch 043 | loss 6.236 | nll_loss 2.604 | ppl 6.08 | wps 44090.8 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 6745 | lr 0.000385043 | gnorm 0.362 | loss_scale 2 | train_wall 48 | gb_free 14.3 | wall 3934
2022-03-23 10:31:07 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 10:31:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:31:24 | INFO | train_inner | epoch 044:     55 / 157 loss=6.21, nll_loss=2.566, ppl=5.92, wps=34622.6, ups=1.39, wpb=24892.1, bsz=1070.7, num_updates=6800, lr=0.000383482, gnorm=0.37, loss_scale=2, train_wall=30, gb_free=13.7, wall=3951
2022-03-23 10:31:55 | INFO | train_inner | epoch 044:    155 / 157 loss=6.216, nll_loss=2.576, ppl=5.96, wps=83378.6, ups=3.26, wpb=25576.4, bsz=1047.4, num_updates=6900, lr=0.000380693, gnorm=0.344, loss_scale=2, train_wall=30, gb_free=14, wall=3982
2022-03-23 10:31:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:31:59 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters in the clinic.
2022-03-23 10:31:59 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:32:03 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:32:03 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:32:07 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that are going to transcend two new pigs.
2022-03-23 10:32:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:32:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:32:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:32:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:32:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:32:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the stove of how people overtook responsibility for wildlife, the number of wildwildlife grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:32:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:32:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:32:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:32:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which regives the big contures of the face and the basic form, and reconcile it through that information that refers the whole por-structure and all the fine folds.
2022-03-23 10:32:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:32:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that... well, when strictly dinner, it was best summarized when someone said, "turn to the men on your table and tell you," if the revolution begins, then we support you. "the truth, women have already supported you for a long time.
2022-03-23 10:32:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:32:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work we're on on our aircraft was a result that we had to solve the unique problems that were connected to it, to operate on the ground -- everything, from a continuously variable drive and a refrigeration system that allows us to use an aircraft in the stop-go-to-traffic to a special drive, or a propeller, to the land that's going on, to be made up to the ground, all the same, to a mechanism, to the security system that we see in a storm that we can see, from an aircraft that's going to the security system that's going to the air conditioning space that's going to the same, to the air conditioning space that's going to the air, to the right, to the air conditioning space that's going to the ground.
2022-03-23 10:32:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:32:33 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 6.467 | nll_loss 2.623 | ppl 6.16 | bleu 33.49 | wps 4896.4 | wpb 17862.2 | bsz 728.3 | num_updates 6902 | best_bleu 33.62
2022-03-23 10:32:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6902 updates
2022-03-23 10:32:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:32:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:32:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 44 @ 6902 updates, score 33.49) (writing took 0.8825977069936926 seconds)
2022-03-23 10:32:33 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 10:32:33 | INFO | train | epoch 044 | loss 6.219 | nll_loss 2.579 | ppl 5.97 | wps 45333.3 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 6902 | lr 0.000380638 | gnorm 0.367 | loss_scale 2 | train_wall 48 | gb_free 13.3 | wall 4021
2022-03-23 10:32:34 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 10:32:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:33:05 | INFO | train_inner | epoch 045:     98 / 157 loss=6.192, nll_loss=2.539, ppl=5.81, wps=36370.9, ups=1.41, wpb=25712.3, bsz=1052.2, num_updates=7000, lr=0.000377964, gnorm=0.368, loss_scale=2, train_wall=31, gb_free=14.3, wall=4053
2022-03-23 10:33:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:33:27 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleeders up in the clinic.
2022-03-23 10:33:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:33:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:33:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:33:35 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new vibrations.
2022-03-23 10:33:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:33:38 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:33:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:33:42 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of your thoughts are on the track.
2022-03-23 10:33:42 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:33:46 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife grew back up, and this has become a basis for conservation in namibia.
2022-03-23 10:33:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:33:50 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines captured inside, but the superconductor doesn't like it when they move, because their movements consume energy, and so the superconducting disorder.
2022-03-23 10:33:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:33:54 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that gives the big constraints of the face, and restores the basic form, and refuse it through the one of the information that refers the whole por-structure and all the fine wrinkles.
2022-03-23 10:33:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:33:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it extremely interesting and appropriate for me here at tedwomen is that... well, when strictly dinner was summed up, it was the best summarized when someone said, "turn to men at your table and tell them, 'when the revolution begins, we support you.'" the truth, women have already been supporting you for a long time. rachel siltheaters, and then we started to download our prices. "
2022-03-23 10:33:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:34:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a large part of the design work that we're on our airplane at the stumbling, was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuously variable drive and a cooling system of fluid, that allows us to use an aircraft in the congestion and traffic to a special drive, either the prophecy, to the ground, to become a mechanism, to the safety space that's going to be made up to the air, to the table, to the table, to the table, to the table, to the table.
2022-03-23 10:34:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:34:00 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 6.449 | nll_loss 2.619 | ppl 6.14 | bleu 33.88 | wps 4952.2 | wpb 17862.2 | bsz 728.3 | num_updates 7059 | best_bleu 33.88
2022-03-23 10:34:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7059 updates
2022-03-23 10:34:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:34:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:34:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 45 @ 7059 updates, score 33.88) (writing took 1.8799806629976956 seconds)
2022-03-23 10:34:02 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 10:34:02 | INFO | train | epoch 045 | loss 6.21 | nll_loss 2.566 | ppl 5.92 | wps 44616.3 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 7059 | lr 0.000376382 | gnorm 0.378 | loss_scale 2 | train_wall 48 | gb_free 15.1 | wall 4109
2022-03-23 10:34:02 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 10:34:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:34:15 | INFO | train_inner | epoch 046:     41 / 157 loss=6.22, nll_loss=2.58, ppl=5.98, wps=34688.3, ups=1.43, wpb=24177.8, bsz=951, num_updates=7100, lr=0.000375293, gnorm=0.378, loss_scale=2, train_wall=30, gb_free=14.7, wall=4122
2022-03-23 10:34:46 | INFO | train_inner | epoch 046:    141 / 157 loss=6.188, nll_loss=2.534, ppl=5.79, wps=81744.9, ups=3.21, wpb=25501.3, bsz=1013, num_updates=7200, lr=0.000372678, gnorm=0.35, loss_scale=2, train_wall=31, gb_free=12.6, wall=4153
2022-03-23 10:34:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:34:55 | INFO | fairseq.tasks.translation | example hypothesis: we put up these beep beep in the clinic.
2022-03-23 10:34:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:34:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:34:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:35:03 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dines that will transcend two new pigs.
2022-03-23 10:35:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:35:06 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:35:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:35:10 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 10:35:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:35:14 | INFO | fairseq.tasks.translation | example hypothesis: and as people took responsibility for wildlife, the number of wildlife grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:35:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:35:18 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and they're disturbing the superconductor.
2022-03-23 10:35:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:35:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that regives the big constructures of the face and the basic form, and reconcile it from the information that refers the whole por-structure and all the fine folds.
2022-03-23 10:35:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:35:26 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when we tear dinner, it was best summarized when someone said, "turn to men at your table and tell them, 'if the revolution begins, then we support you.'" the truth, women have been supporting you for a long time. "
2022-03-23 10:35:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:35:27 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention, and a big part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable, and a cooling system of fluid that allows us to use an aircraft on the aircraft in stop and traffic to a special drive, either when you see the prophecy, or when you get to the ground.
2022-03-23 10:35:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:35:27 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 6.447 | nll_loss 2.611 | ppl 6.11 | bleu 33.6 | wps 5135 | wpb 17862.2 | bsz 728.3 | num_updates 7216 | best_bleu 33.88
2022-03-23 10:35:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7216 updates
2022-03-23 10:35:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:35:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:35:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 46 @ 7216 updates, score 33.6) (writing took 0.8099483309924835 seconds)
2022-03-23 10:35:28 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 10:35:28 | INFO | train | epoch 046 | loss 6.184 | nll_loss 2.529 | ppl 5.77 | wps 45954.9 | ups 1.83 | wpb 25153.6 | bsz 1020.6 | num_updates 7216 | lr 0.000372265 | gnorm 0.355 | loss_scale 2 | train_wall 48 | gb_free 14.8 | wall 4195
2022-03-23 10:35:28 | INFO | fairseq.trainer | begin training epoch 47
2022-03-23 10:35:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:35:55 | INFO | train_inner | epoch 047:     84 / 157 loss=6.158, nll_loss=2.489, ppl=5.62, wps=36824.1, ups=1.46, wpb=25212.8, bsz=1066.2, num_updates=7300, lr=0.000370117, gnorm=0.355, loss_scale=2, train_wall=30, gb_free=14, wall=4222
2022-03-23 10:36:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:36:20 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep petals in the clinic.
2022-03-23 10:36:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:36:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:36:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:36:29 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that will transcend two new pigs.
2022-03-23 10:36:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:36:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:36:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:36:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:36:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:36:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, like people overtook responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:36:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:36:44 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it if they move, because their movements use energy, and that's how the superconducting disorder is.
2022-03-23 10:36:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:36:48 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restores the big configurations of the face and the basic form, and then then redeploy it through the actual information that refers the whole por-structure and all the fine wrinkles.
2022-03-23 10:36:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:36:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when constrict dinner, it's been summed best when someone said, "turn to men at your table and tell them, 'if the revolution begins, then we support you.'" the truth, women have been supporting you for a long time.
2022-03-23 10:36:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:36:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane at the stumbling, was a result that we had to solve the unique problems that were connected to operate on the ground -- all, from a continuously variable drive and a cooling system of liquid, that allows us to use an aircraft in stop and traffic to a special drive, either if you see the folding, or if you're going to be able to be able to see the folded in a safe space.
2022-03-23 10:36:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:36:53 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 6.442 | nll_loss 2.616 | ppl 6.13 | bleu 33.99 | wps 4999 | wpb 17862.2 | bsz 728.3 | num_updates 7373 | best_bleu 33.99
2022-03-23 10:36:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 7373 updates
2022-03-23 10:36:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:36:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:36:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 47 @ 7373 updates, score 33.99) (writing took 1.8351190849934937 seconds)
2022-03-23 10:36:55 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-23 10:36:55 | INFO | train | epoch 047 | loss 6.169 | nll_loss 2.506 | ppl 5.68 | wps 45239.1 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 7373 | lr 0.00036828 | gnorm 0.348 | loss_scale 2 | train_wall 48 | gb_free 13.5 | wall 4282
2022-03-23 10:36:55 | INFO | fairseq.trainer | begin training epoch 48
2022-03-23 10:36:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:37:04 | INFO | train_inner | epoch 048:     27 / 157 loss=6.163, nll_loss=2.5, ppl=5.66, wps=36163.4, ups=1.44, wpb=25026.7, bsz=1041.3, num_updates=7400, lr=0.000367607, gnorm=0.361, loss_scale=2, train_wall=30, gb_free=14.5, wall=4291
2022-03-23 10:37:35 | INFO | train_inner | epoch 048:    127 / 157 loss=6.167, nll_loss=2.502, ppl=5.67, wps=81380.6, ups=3.18, wpb=25616.9, bsz=979.3, num_updates=7500, lr=0.000365148, gnorm=0.333, loss_scale=2, train_wall=31, gb_free=15.1, wall=4323
2022-03-23 10:37:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:37:48 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleeders up in the clinic.
2022-03-23 10:37:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:37:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:37:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:37:56 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks events that are going to transcend two new pigs.
2022-03-23 10:37:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:38:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:38:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:38:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:38:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:38:07 | INFO | fairseq.tasks.translation | example hypothesis: and in the corresponding responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:38:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:38:11 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductive disorder.
2022-03-23 10:38:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:38:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that gives the big constructions of the face and restores it through the original information that refers the whole porch structure and all the fine wrinkles.
2022-03-23 10:38:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:38:20 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, when constricted dinner, it was summed best when someone said, "turn to the men on your table and tell them, 'if the revolution begins, we'll support you.'" the truth, women is that we've been supporting you for a long time.
2022-03-23 10:38:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:38:22 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane at the stumble, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable engine and a refrigerator system of liquid that allows us to use an aircraft in the stop-and go-traffic to a specially appropriate to a passage, or a propeller, to be able to solve the ground, or if you can see the propeller, or if you can see it's going to be connected to the ground.
2022-03-23 10:38:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:38:22 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 6.442 | nll_loss 2.612 | ppl 6.11 | bleu 33.81 | wps 4840.6 | wpb 17862.2 | bsz 728.3 | num_updates 7530 | best_bleu 33.99
2022-03-23 10:38:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 7530 updates
2022-03-23 10:38:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:38:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:38:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 48 @ 7530 updates, score 33.81) (writing took 0.8316516899940325 seconds)
2022-03-23 10:38:22 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-23 10:38:22 | INFO | train | epoch 048 | loss 6.159 | nll_loss 2.492 | ppl 5.63 | wps 45228.8 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 7530 | lr 0.00036442 | gnorm 0.365 | loss_scale 2 | train_wall 48 | gb_free 13.7 | wall 4370
2022-03-23 10:38:23 | INFO | fairseq.trainer | begin training epoch 49
2022-03-23 10:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:38:45 | INFO | train_inner | epoch 049:     70 / 157 loss=6.153, nll_loss=2.482, ppl=5.59, wps=35309.6, ups=1.44, wpb=24459.1, bsz=988.7, num_updates=7600, lr=0.000362738, gnorm=0.376, loss_scale=2, train_wall=30, gb_free=14.3, wall=4392
2022-03-23 10:39:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:39:15 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleeders in the clinic.
2022-03-23 10:39:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:39:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that i think most people know here.
2022-03-23 10:39:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:39:22 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks events that will transcend two new pigs.
2022-03-23 10:39:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:39:26 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:39:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:39:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:39:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:39:34 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:39:34 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:39:38 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorders.
2022-03-23 10:39:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:39:42 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that regives the big constructions of the face and redeals it through the basic form of information that includes the entire porn structure and all the fine folds.
2022-03-23 10:39:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:39:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate to me here at tedwomen is that... well, when constrict dinner, it was best summarized when someone said, "turn to the men on your table and tell them, 'if the revolution begins, then we support you.' the truth is women have been supporting you with this topic for a long time. 'rachel carel's"' "siltheo '"' "] [" 'brick's "'" '"'" '"'" '"' brick '"' "'"' "'"' "'"' "'"' "'"' em & gt; '"'" '"'" '"' em & lt; / em & gt; / em & gt; / em & gt; / em & gt;
2022-03-23 10:39:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:39:48 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a big part of the design work that we're on our plane is on a trigger, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuously variable drive and a refrigeration system of liquid that allows us to use an aircraft in stop and traffic to a special driver, which is either drives the propelled by the ground if you're on a mechanism.
2022-03-23 10:39:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:39:48 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 6.428 | nll_loss 2.608 | ppl 6.1 | bleu 33.8 | wps 4882.8 | wpb 17862.2 | bsz 728.3 | num_updates 7687 | best_bleu 33.99
2022-03-23 10:39:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 7687 updates
2022-03-23 10:39:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:39:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:39:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 49 @ 7687 updates, score 33.8) (writing took 0.7959392110060435 seconds)
2022-03-23 10:39:49 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-23 10:39:49 | INFO | train | epoch 049 | loss 6.14 | nll_loss 2.464 | ppl 5.52 | wps 45506.9 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 7687 | lr 0.00036068 | gnorm 0.344 | loss_scale 2 | train_wall 47 | gb_free 14 | wall 4457
2022-03-23 10:39:50 | INFO | fairseq.trainer | begin training epoch 50
2022-03-23 10:39:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:39:54 | INFO | train_inner | epoch 050:     13 / 157 loss=6.135, nll_loss=2.459, ppl=5.5, wps=36887.9, ups=1.44, wpb=25570.4, bsz=1070.3, num_updates=7700, lr=0.000360375, gnorm=0.344, loss_scale=2, train_wall=30, gb_free=14.3, wall=4461
2022-03-23 10:40:25 | INFO | train_inner | epoch 050:    113 / 157 loss=6.119, nll_loss=2.435, ppl=5.41, wps=82161.7, ups=3.24, wpb=25382.8, bsz=1060.6, num_updates=7800, lr=0.000358057, gnorm=0.348, loss_scale=2, train_wall=31, gb_free=14.5, wall=4492
2022-03-23 10:40:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:40:42 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:40:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:40:46 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most people know here.
2022-03-23 10:40:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:40:49 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 10:40:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:40:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and peaks.
2022-03-23 10:40:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:40:57 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all your thoughts are on the track.
2022-03-23 10:40:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:41:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:41:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:41:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, their movements use energy, so the superconducting disorder.
2022-03-23 10:41:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:41:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big configurations of the face and then rearrange it through the form of that information that includes the whole porter structure and all the fine wrinkles.
2022-03-23 10:41:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:41:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, at striking dinner, it's been summarized best when someone said, "turn to men on your table and tell them," when the revolution begins, we'll support you. "the truth is, women have been supporting you for a long time. starting with rachel carchel spring's cake's cake's cake's cake's bribe down the future."
2022-03-23 10:41:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:41:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a big part of the design work that we're on on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable drive and a refrigeration system that allows us to use an aircraft in stop and transportation to a special driver, which is either drifting the propeller, or if you see the aircraft on the ground, you're going to be on the floor -- everything, you're going to the car storm, you're going to see the car storm, to be able to be able to be able to see that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the car deplowed.
2022-03-23 10:41:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:41:16 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 6.416 | nll_loss 2.589 | ppl 6.02 | bleu 34.15 | wps 4820.1 | wpb 17862.2 | bsz 728.3 | num_updates 7844 | best_bleu 34.15
2022-03-23 10:41:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 7844 updates
2022-03-23 10:41:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:41:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:41:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 50 @ 7844 updates, score 34.15) (writing took 1.8557047359936405 seconds)
2022-03-23 10:41:18 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-23 10:41:18 | INFO | train | epoch 050 | loss 6.126 | nll_loss 2.445 | ppl 5.44 | wps 44692.2 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 7844 | lr 0.000357052 | gnorm 0.346 | loss_scale 2 | train_wall 47 | gb_free 13.6 | wall 4545
2022-03-23 10:41:18 | INFO | fairseq.trainer | begin training epoch 51
2022-03-23 10:41:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:41:36 | INFO | train_inner | epoch 051:     56 / 157 loss=6.12, nll_loss=2.435, ppl=5.41, wps=35343.7, ups=1.41, wpb=25028.9, bsz=989, num_updates=7900, lr=0.000355784, gnorm=0.338, loss_scale=2, train_wall=30, gb_free=13.6, wall=4563
2022-03-23 10:42:06 | INFO | train_inner | epoch 051:    156 / 157 loss=6.113, nll_loss=2.425, ppl=5.37, wps=82367, ups=3.29, wpb=25046.4, bsz=1020.9, num_updates=8000, lr=0.000353553, gnorm=0.354, loss_scale=2, train_wall=30, gb_free=15.1, wall=4593
2022-03-23 10:42:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:42:10 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers up in the clinic.
2022-03-23 10:42:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:42:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most people here know.
2022-03-23 10:42:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:42:18 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks events that will transcend two new vibrations.
2022-03-23 10:42:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:42:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:42:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:42:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 10:42:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:42:29 | INFO | fairseq.tasks.translation | example hypothesis: and as people took responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:42:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:42:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like to move, because their movements use energy, and that's how the superconducting disorder.
2022-03-23 10:42:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:42:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big configurations of the face and reforms it, and reconcile it through the information that refers the whole por-structure and all the fine.
2022-03-23 10:42:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:42:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it was very interesting and appropriate for me to be here at tedwomen is that... well, in strictly dinner, it was summarized best when someone said, "turn to men on your table and tell them, 'when the revolution begins, then we support you.' the truth is that we have been supporting you about this topic for a long time. when rachel cares about it. 'when he said," when he said, "well," well, you know, let's go to the future of siltheo'am, and then we go down our prior to sandstone stream. "
2022-03-23 10:42:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:42:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a large part of the design work that we were on our airplane was the result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuously variable operating system and a refrigerating system of fluid that allows us to use an aircraft in stop and go-traffic to a special drive that is either when you fly to the ground or if you're in a mechanism.
2022-03-23 10:42:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:42:43 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 6.433 | nll_loss 2.576 | ppl 5.96 | bleu 34.05 | wps 5017.9 | wpb 17862.2 | bsz 728.3 | num_updates 8001 | best_bleu 34.15
2022-03-23 10:42:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 8001 updates
2022-03-23 10:42:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:42:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:42:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 51 @ 8001 updates, score 34.05) (writing took 0.8191763460054062 seconds)
2022-03-23 10:42:44 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-23 10:42:44 | INFO | train | epoch 051 | loss 6.11 | nll_loss 2.42 | ppl 5.35 | wps 45904.1 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 8001 | lr 0.000353531 | gnorm 0.347 | loss_scale 2 | train_wall 48 | gb_free 14 | wall 4631
2022-03-23 10:42:44 | INFO | fairseq.trainer | begin training epoch 52
2022-03-23 10:42:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:43:15 | INFO | train_inner | epoch 052:     99 / 157 loss=6.088, nll_loss=2.388, ppl=5.23, wps=36630.5, ups=1.45, wpb=25189, bsz=1055.9, num_updates=8100, lr=0.000351364, gnorm=0.36, loss_scale=2, train_wall=30, gb_free=13.9, wall=4662
2022-03-23 10:43:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:43:37 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 10:43:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:43:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you here know.
2022-03-23 10:43:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:43:45 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks's dinments that are going to overshoot two new pigs.
2022-03-23 10:43:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:43:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:43:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:43:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 10:43:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:43:56 | INFO | fairseq.tasks.translation | example hypothesis: and as people took responsibility for wildlife, the number of wildlife grew back in, and that's become a basis for conservation in namibia.
2022-03-23 10:43:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:44:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:44:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:44:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that repeats the big contures of the face and refers it through the form of the information that refers the whole por-structure and all the fine wrinkles.
2022-03-23 10:44:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:44:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's been summed up and measured to be here at tedwomen is that -- well, when he said, "turn to the men at your table and tell them, 'if the revolution begins, then we support you.'" the truth is that we've been supporting you for a long time at rachel with siltheo's spring, "to the future of sand."
2022-03-23 10:44:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:44:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and a big part of the design work that we were at our plane at the stumbling, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuously variable, and a cooling system of liquid that allows us to use an aircraft in the stop and go-traffic to a special driver, or if you're going to fly on the ground, or if you're on the floor, you're going to the mechanism.
2022-03-23 10:44:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:44:09 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 6.406 | nll_loss 2.578 | ppl 5.97 | bleu 34.35 | wps 5036.6 | wpb 17862.2 | bsz 728.3 | num_updates 8158 | best_bleu 34.35
2022-03-23 10:44:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 8158 updates
2022-03-23 10:44:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:44:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:44:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 52 @ 8158 updates, score 34.35) (writing took 1.8363864999992074 seconds)
2022-03-23 10:44:11 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-23 10:44:11 | INFO | train | epoch 052 | loss 6.106 | nll_loss 2.414 | ppl 5.33 | wps 45040.4 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 8158 | lr 0.000350113 | gnorm 0.361 | loss_scale 2 | train_wall 48 | gb_free 14.3 | wall 4719
2022-03-23 10:44:12 | INFO | fairseq.trainer | begin training epoch 53
2022-03-23 10:44:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:44:25 | INFO | train_inner | epoch 053:     42 / 157 loss=6.113, nll_loss=2.424, ppl=5.37, wps=35848.8, ups=1.43, wpb=25045.3, bsz=968.3, num_updates=8200, lr=0.000349215, gnorm=0.365, loss_scale=2, train_wall=30, gb_free=13.8, wall=4732
2022-03-23 10:44:56 | INFO | train_inner | epoch 053:    142 / 157 loss=6.098, nll_loss=2.404, ppl=5.29, wps=80598.1, ups=3.23, wpb=24991.5, bsz=1045.2, num_updates=8300, lr=0.000347105, gnorm=0.362, loss_scale=2, train_wall=31, gb_free=13.7, wall=4763
2022-03-23 10:45:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:45:04 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleeders in the clinic.
2022-03-23 10:45:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:45:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:45:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:45:12 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks's events that will transcend two new pigs.
2022-03-23 10:45:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:45:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:45:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:45:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of your thoughts are on the track.
2022-03-23 10:45:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:45:23 | INFO | fairseq.tasks.translation | example hypothesis: and as people took responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:45:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:45:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like them to move because their movements use their energy, and the superconductor disorder.
2022-03-23 10:45:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:45:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restores the big configurations of the face and the basic form and restore it through the one of the information that refers the whole porter structure and all the fine wrinkles.
2022-03-23 10:45:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:45:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when strictly dinner, it was summed best when someone said, "turn to men on your table and tell them, 'if the revolution begins, then we support you.' the truth is that we've been supporting you about this for a long time. when rachel carson's spring," from the future to the pride of sand. "
2022-03-23 10:45:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:45:37 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a big part of the design work we're on on on on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- all, from a continuously variable drive and a cooling system of fluid that allows us to use an aircraft in stop-go-traffic to a specially appropriate drive that drives either if you're on the ground, or if you're going to see the mechanism.
2022-03-23 10:45:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:45:37 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 6.402 | nll_loss 2.565 | ppl 5.92 | bleu 34.58 | wps 4973.4 | wpb 17862.2 | bsz 728.3 | num_updates 8315 | best_bleu 34.58
2022-03-23 10:45:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 8315 updates
2022-03-23 10:45:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:45:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt
2022-03-23 10:45:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_best.pt (epoch 53 @ 8315 updates, score 34.58) (writing took 1.8101020760077517 seconds)
2022-03-23 10:45:39 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-23 10:45:39 | INFO | train | epoch 053 | loss 6.094 | nll_loss 2.397 | ppl 5.27 | wps 45273 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 8315 | lr 0.000346792 | gnorm 0.359 | loss_scale 2 | train_wall 47 | gb_free 13.8 | wall 4806
2022-03-23 10:45:39 | INFO | fairseq.trainer | begin training epoch 54
2022-03-23 10:45:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:46:05 | INFO | train_inner | epoch 054:     85 / 157 loss=6.09, nll_loss=2.39, ppl=5.24, wps=36610.9, ups=1.44, wpb=25459.3, bsz=974.5, num_updates=8400, lr=0.000345033, gnorm=0.359, loss_scale=2, train_wall=30, gb_free=13.7, wall=4832
2022-03-23 10:46:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:46:31 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers up in the clinic.
2022-03-23 10:46:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:46:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most people here know.
2022-03-23 10:46:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:46:39 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks's events that will transcend two new vibrations.
2022-03-23 10:46:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:46:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:46:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:46:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all your thoughts are on the track.
2022-03-23 10:46:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:46:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the measure of how people took responsibility for wildlife, the number of wildlife grew back up, and that's become a basis for conservation in namibia.
2022-03-23 10:46:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:46:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, their movements use energy, and so the superconducting disorder.
2022-03-23 10:46:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:46:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that regives the big configurations of the face and the basic shape, and emitting it through the most of the information that refers all the porter structure and all the fine folds.
2022-03-23 10:46:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:47:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate for me to be here at tedwomen is that... well, when strictly dinner it was summed best when someone said, "turn to men on your table and tell them, 'if the revolution begins, then we support you.' the truth, women have supported you for a long time, starting with rachel carson spring theo's future, and our pride of sand."
2022-03-23 10:47:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:47:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work we're on on on on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- all, from a continuously variable drive and a cooling system that allows us to use an aircraft in stop-go-traffic to a specially appropriate vehicle, that drives either if you're on the ground or the mechanized.
2022-03-23 10:47:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:47:04 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 6.418 | nll_loss 2.583 | ppl 5.99 | bleu 33.99 | wps 5009.2 | wpb 17862.2 | bsz 728.3 | num_updates 8472 | best_bleu 34.58
2022-03-23 10:47:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 8472 updates
2022-03-23 10:47:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:47:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:47:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 54 @ 8472 updates, score 33.99) (writing took 0.8484898269962287 seconds)
2022-03-23 10:47:05 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-23 10:47:05 | INFO | train | epoch 054 | loss 6.08 | nll_loss 2.376 | ppl 5.19 | wps 45884.2 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 8472 | lr 0.000343564 | gnorm 0.357 | loss_scale 2 | train_wall 47 | gb_free 13.7 | wall 4892
2022-03-23 10:47:05 | INFO | fairseq.trainer | begin training epoch 55
2022-03-23 10:47:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:47:14 | INFO | train_inner | epoch 055:     28 / 157 loss=6.065, nll_loss=2.354, ppl=5.11, wps=36745, ups=1.45, wpb=25309, bsz=1068.2, num_updates=8500, lr=0.000342997, gnorm=0.348, loss_scale=2, train_wall=30, gb_free=14, wall=4901
2022-03-23 10:47:45 | INFO | train_inner | epoch 055:    128 / 157 loss=6.087, nll_loss=2.386, ppl=5.23, wps=81475.2, ups=3.27, wpb=24926.6, bsz=957, num_updates=8600, lr=0.000340997, gnorm=0.375, loss_scale=2, train_wall=30, gb_free=14.8, wall=4932
2022-03-23 10:47:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:47:57 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:47:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:48:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 10:48:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:48:05 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of india that will transcend two new pigs.
2022-03-23 10:48:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:48:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:48:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:48:12 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:48:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:48:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the measures of how people took responsibility for wildlife, the number of wildlife grew back in. and that's become a basis for conservation in namibia.
2022-03-23 10:48:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:48:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:48:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:48:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that regives the big configurations of the face and the basic shape, and then add it to that information that refers the whole por-structure and all the fine folds.
2022-03-23 10:48:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:48:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate for me to be here at tedwomen is that -- well, when you think about dinner, it's been summarized best when someone said, "turn to the men at your table and tell them, 'if the revolution starts, then we'll support you.' the truth, women, we've been supporting you for a long time with rachel carchel with sychel's spring, and then we started down the future of sandra beaches and the future," down our primorrors' brira route. "
2022-03-23 10:48:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:48:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable drive and a cooling system that allows us to use an aircraft in stop-go-traffic, to a specially appropriate vehicle that drives either when you fly to the ground, or when you're in a mechanism, to an automated, to an automation system that's going to an aircraft, to an aircraft, to an aircraft in the same way.
2022-03-23 10:48:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:48:30 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 6.401 | nll_loss 2.553 | ppl 5.87 | bleu 34.53 | wps 4941.2 | wpb 17862.2 | bsz 728.3 | num_updates 8629 | best_bleu 34.58
2022-03-23 10:48:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 8629 updates
2022-03-23 10:48:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:48:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:48:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 55 @ 8629 updates, score 34.53) (writing took 0.890440948001924 seconds)
2022-03-23 10:48:31 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-23 10:48:31 | INFO | train | epoch 055 | loss 6.071 | nll_loss 2.362 | ppl 5.14 | wps 45622.3 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 8629 | lr 0.000340424 | gnorm 0.361 | loss_scale 2 | train_wall 47 | gb_free 14.3 | wall 4979
2022-03-23 10:48:32 | INFO | fairseq.trainer | begin training epoch 56
2022-03-23 10:48:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:48:54 | INFO | train_inner | epoch 056:     71 / 157 loss=6.064, nll_loss=2.352, ppl=5.1, wps=35645.6, ups=1.45, wpb=24582.2, bsz=997.6, num_updates=8700, lr=0.000339032, gnorm=0.351, loss_scale=2, train_wall=30, gb_free=14.9, wall=5001
2022-03-23 10:49:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:49:24 | INFO | fairseq.tasks.translation | example hypothesis: we put those beep up in the clinic.
2022-03-23 10:49:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:49:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 10:49:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:49:32 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golf locks that will transcend two new pigs.
2022-03-23 10:49:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:49:36 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:49:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:49:40 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all your thoughts are on the track.
2022-03-23 10:49:40 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:49:43 | INFO | fairseq.tasks.translation | example hypothesis: and as people took responsibility for wildlife, the number of wildlife grew back. and that's become a basis for conservation in namibia.
2022-03-23 10:49:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:49:47 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:49:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:49:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that repeats the rough contures of the face and the basic form, and then add it through that information that whole porch structure and all the fine wrinkles.
2022-03-23 10:49:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:49:55 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate to me here at tedwomen is that... well, when we have been the best summarized at rachel spring, when someone said, "turn to men at your table and tell them, 'when the revolution begins, we support you.' the truth is that we've been supporting you for a long time. at rachel carent's" siltheo's future. "
2022-03-23 10:49:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:49:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're most stumbling on our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable drive and a cooling system of liquid, that allows us to use an aircraft in stop and traffic to a specially appropriate vehicle that drives either if you're flying, or if you're on the ground, or if you're on a mechanism, all the way down to a mechanism.
2022-03-23 10:49:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:49:56 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 6.418 | nll_loss 2.582 | ppl 5.99 | bleu 33.98 | wps 5135.2 | wpb 17862.2 | bsz 728.3 | num_updates 8786 | best_bleu 34.58
2022-03-23 10:49:56 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:49:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 8786 updates
2022-03-23 10:49:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:49:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt
2022-03-23 10:49:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#1/checkpoint_last.pt (epoch 56 @ 8786 updates, score 33.98) (writing took 0.8759823859872995 seconds)
2022-03-23 10:49:57 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-23 10:49:57 | INFO | train | epoch 056 | loss 6.059 | nll_loss 2.345 | ppl 5.08 | wps 45842.9 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 8786 | lr 0.000337368 | gnorm 0.353 | loss_scale 2 | train_wall 48 | gb_free 13.9 | wall 5065
2022-03-23 10:49:57 | INFO | fairseq_cli.train | done training in 5064.3 seconds
