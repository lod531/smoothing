Sender: LSF System <lsfadmin@eu-g3-036>
Subject: Job 207264028: <w103_size_0.03125_fp16_cross_entropy_#1> in cluster <euler> Exited

Job <w103_size_0.03125_fp16_cross_entropy_#1> was submitted from host <eu-login-33> by user <andriusb> in cluster <euler> at Sat Mar  5 14:20:45 2022
Job was executed on host(s) <eu-g3-036>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sat Mar  5 14:21:45 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar  5 14:21:45 2022
Terminated at Sun Mar  6 08:56:01 2022
Results reported at Sun Mar  6 08:56:01 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion cross_entropy --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   66800.20 sec.
    Max Memory :                                 6978 MB
    Average Memory :                             3899.53 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13022.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   66856 sec.
    Turnaround time :                            66916 sec.

The output (if any) follows:

2022-03-05 14:21:54 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575611, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-05 14:21:54 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-05 14:21:55 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-05 14:21:55 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-05 14:21:55 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-05 14:21:55 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2022-03-05 14:21:55 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-05 14:21:55 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-05 14:21:55 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-05 14:21:58 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-05 14:21:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:21:58 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-05 14:21:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:21:58 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-05 14:21:58 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-05 14:21:58 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 14:21:58 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 14:21:58 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-05 14:21:58 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-05 14:21:58 | INFO | fairseq.trainer | begin training epoch 1
2022-03-05 14:21:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:22:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-05 14:22:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:22:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:22:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 14:22:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-05 14:24:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:24:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.392 | ppl 42992.5 | wps 48413.6 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-05 14:24:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-05 14:24:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:24:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:24:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.392) (writing took 3.6351807452738285 seconds)
2022-03-05 14:24:10 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-05 14:24:10 | INFO | train | epoch 001 | loss 16.524 | ppl 94262.9 | wps 26638.2 | ups 0.41 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 5.085 | loss_scale 4 | train_wall 113 | gb_free 8.8 | wall 132
2022-03-05 14:24:10 | INFO | fairseq.trainer | begin training epoch 2
2022-03-05 14:24:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:26:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:26:05 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.878 | ppl 15056.4 | wps 48587.6 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 13.878
2022-03-05 14:26:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-05 14:26:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:26:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:26:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 2 @ 93 updates, score 13.878) (writing took 3.8359075551852584 seconds)
2022-03-05 14:26:09 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-05 14:26:09 | INFO | train | epoch 002 | loss 14.584 | ppl 24557.3 | wps 26806.7 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.311 | loss_scale 4 | train_wall 99 | gb_free 8.8 | wall 251
2022-03-05 14:26:09 | INFO | fairseq.trainer | begin training epoch 3
2022-03-05 14:26:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:26:25 | INFO | train_inner | epoch 003:      7 / 49 loss=15.389, ppl=42917.8, wps=26861.8, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.483, loss_scale=4, train_wall=227, gb_free=8.8, wall=267
2022-03-05 14:27:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:28:06 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.185 | ppl 9313.93 | wps 47606.2 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.185
2022-03-05 14:28:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-05 14:28:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:28:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:28:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.185) (writing took 3.5634425282478333 seconds)
2022-03-05 14:28:09 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-05 14:28:09 | INFO | train | epoch 003 | loss 13.61 | ppl 12505.1 | wps 26362 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.538 | loss_scale 8 | train_wall 99 | gb_free 8.8 | wall 371
2022-03-05 14:28:09 | INFO | fairseq.trainer | begin training epoch 4
2022-03-05 14:28:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:30:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:30:04 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.308 | ppl 5070.19 | wps 48471.9 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.308
2022-03-05 14:30:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-05 14:30:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:30:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:30:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.308) (writing took 4.259573839604855 seconds)
2022-03-05 14:30:08 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-05 14:30:08 | INFO | train | epoch 004 | loss 12.817 | ppl 7217.26 | wps 26703 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.323 | loss_scale 8 | train_wall 99 | gb_free 8.8 | wall 491
2022-03-05 14:30:08 | INFO | fairseq.trainer | begin training epoch 5
2022-03-05 14:30:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:30:29 | INFO | train_inner | epoch 005:      9 / 49 loss=13.078, ppl=8649.47, wps=26574.8, ups=0.41, wpb=64867.4, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.389, loss_scale=8, train_wall=203, gb_free=8.8, wall=511
2022-03-05 14:31:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:32:03 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.504 | ppl 2903.5 | wps 48595.8 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 11.504
2022-03-05 14:32:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-05 14:32:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:32:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:32:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 5 @ 240 updates, score 11.504) (writing took 3.7250184109434485 seconds)
2022-03-05 14:32:07 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-05 14:32:07 | INFO | train | epoch 005 | loss 11.926 | ppl 3890.9 | wps 26817.8 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 1.01 | loss_scale 8 | train_wall 99 | gb_free 8.8 | wall 609
2022-03-05 14:32:07 | INFO | fairseq.trainer | begin training epoch 6
2022-03-05 14:32:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:33:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:34:02 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.854 | ppl 1851.46 | wps 48219.1 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 10.854
2022-03-05 14:34:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-05 14:34:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:34:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:34:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 6 @ 289 updates, score 10.854) (writing took 3.9603233467787504 seconds)
2022-03-05 14:34:06 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-05 14:34:06 | INFO | train | epoch 006 | loss 11.166 | ppl 2297.79 | wps 26761 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.786 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 728
2022-03-05 14:34:06 | INFO | fairseq.trainer | begin training epoch 7
2022-03-05 14:34:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:34:31 | INFO | train_inner | epoch 007:     11 / 49 loss=11.392, ppl=2687.96, wps=26829.1, ups=0.41, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.855, loss_scale=16, train_wall=203, gb_free=8.8, wall=753
2022-03-05 14:35:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:36:01 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.432 | ppl 1381.28 | wps 48377.2 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 10.432
2022-03-05 14:36:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-05 14:36:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:36:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:36:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 7 @ 338 updates, score 10.432) (writing took 3.6202412648126483 seconds)
2022-03-05 14:36:04 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-05 14:36:04 | INFO | train | epoch 007 | loss 10.596 | ppl 1547.96 | wps 26841 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.642 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 846
2022-03-05 14:36:04 | INFO | fairseq.trainer | begin training epoch 8
2022-03-05 14:36:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:37:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:37:59 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.173 | ppl 1154.59 | wps 48710.5 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.173
2022-03-05 14:37:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-05 14:37:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:38:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:38:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.173) (writing took 3.8840938322246075 seconds)
2022-03-05 14:38:03 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-05 14:38:03 | INFO | train | epoch 008 | loss 10.239 | ppl 1208.11 | wps 26799.2 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.49 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 965
2022-03-05 14:38:03 | INFO | fairseq.trainer | begin training epoch 9
2022-03-05 14:38:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:38:32 | INFO | train_inner | epoch 009:     13 / 49 loss=10.333, ppl=1289.88, wps=26862.9, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.538, loss_scale=32, train_wall=203, gb_free=8.8, wall=994
2022-03-05 14:39:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:39:57 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.987 | ppl 1014.89 | wps 48640.9 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 9.987
2022-03-05 14:39:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-05 14:39:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:39:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:40:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 9 @ 436 updates, score 9.987) (writing took 4.602030614390969 seconds)
2022-03-05 14:40:02 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-05 14:40:02 | INFO | train | epoch 009 | loss 10.003 | ppl 1025.85 | wps 26636.6 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.518 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 1084
2022-03-05 14:40:02 | INFO | fairseq.trainer | begin training epoch 10
2022-03-05 14:40:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:41:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:41:57 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.82 | ppl 904.09 | wps 48420.7 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 9.82
2022-03-05 14:41:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-05 14:41:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:41:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:42:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 10 @ 485 updates, score 9.82) (writing took 4.137669716961682 seconds)
2022-03-05 14:42:01 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-05 14:42:01 | INFO | train | epoch 010 | loss 9.809 | ppl 897.27 | wps 26789.6 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.54 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 1203
2022-03-05 14:42:01 | INFO | fairseq.trainer | begin training epoch 11
2022-03-05 14:42:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:42:35 | INFO | train_inner | epoch 011:     15 / 49 loss=9.853, ppl=924.63, wps=26749.6, ups=0.41, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.548, loss_scale=32, train_wall=202, gb_free=8.8, wall=1237
2022-03-05 14:43:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:43:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:43:55 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.68 | ppl 820.37 | wps 48510.2 | wpb 510.9 | bsz 1 | num_updates 533 | best_loss 9.68
2022-03-05 14:43:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 533 updates
2022-03-05 14:43:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:43:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:43:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 11 @ 533 updates, score 9.68) (writing took 4.051198630593717 seconds)
2022-03-05 14:43:59 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-05 14:43:59 | INFO | train | epoch 011 | loss 9.633 | ppl 794.12 | wps 26207.3 | ups 0.4 | wpb 64844.1 | bsz 126.7 | num_updates 533 | lr 6.67117e-05 | gnorm 0.573 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 1321
2022-03-05 14:43:59 | INFO | fairseq.trainer | begin training epoch 12
2022-03-05 14:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:45:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:45:54 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.542 | ppl 745.37 | wps 48462.7 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 9.542
2022-03-05 14:45:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-05 14:45:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:45:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:45:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 12 @ 582 updates, score 9.542) (writing took 4.042869917117059 seconds)
2022-03-05 14:45:58 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-05 14:45:58 | INFO | train | epoch 012 | loss 9.467 | ppl 707.84 | wps 26744.2 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.65 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 1440
2022-03-05 14:45:58 | INFO | fairseq.trainer | begin training epoch 13
2022-03-05 14:45:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:46:39 | INFO | train_inner | epoch 013:     18 / 49 loss=9.491, ppl=719.65, wps=26545.3, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.626, loss_scale=32, train_wall=205, gb_free=8.8, wall=1481
2022-03-05 14:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:47:53 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.433 | ppl 691.03 | wps 48396.4 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 9.433
2022-03-05 14:47:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-05 14:47:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:47:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:47:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 13 @ 631 updates, score 9.433) (writing took 3.9513397943228483 seconds)
2022-03-05 14:47:57 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-05 14:47:57 | INFO | train | epoch 013 | loss 9.311 | ppl 635.07 | wps 26805.8 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.729 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 1559
2022-03-05 14:47:57 | INFO | fairseq.trainer | begin training epoch 14
2022-03-05 14:47:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:48:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:49:52 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.317 | ppl 637.6 | wps 48553.8 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 9.317
2022-03-05 14:49:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-05 14:49:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:49:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:49:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 14 @ 679 updates, score 9.317) (writing took 4.056932100094855 seconds)
2022-03-05 14:49:56 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-05 14:49:56 | INFO | train | epoch 014 | loss 9.165 | ppl 573.91 | wps 26203.7 | ups 0.4 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.757 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 1678
2022-03-05 14:49:56 | INFO | fairseq.trainer | begin training epoch 15
2022-03-05 14:49:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:50:43 | INFO | train_inner | epoch 015:     21 / 49 loss=9.178, ppl=579.33, wps=26576.4, ups=0.41, wpb=64876.2, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.753, loss_scale=32, train_wall=205, gb_free=8.8, wall=1725
2022-03-05 14:51:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:51:50 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.221 | ppl 596.63 | wps 48634.9 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.221
2022-03-05 14:51:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-05 14:51:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:51:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:51:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.221) (writing took 3.93649628944695 seconds)
2022-03-05 14:51:54 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-05 14:51:54 | INFO | train | epoch 015 | loss 9.02 | ppl 519.29 | wps 26793.7 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.759 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 1796
2022-03-05 14:51:54 | INFO | fairseq.trainer | begin training epoch 16
2022-03-05 14:51:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:52:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:53:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:53:49 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.142 | ppl 564.88 | wps 48542.5 | wpb 510.9 | bsz 1 | num_updates 776 | best_loss 9.142
2022-03-05 14:53:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 776 updates
2022-03-05 14:53:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:53:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:53:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 16 @ 776 updates, score 9.142) (writing took 3.9351952727884054 seconds)
2022-03-05 14:53:53 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-05 14:53:53 | INFO | train | epoch 016 | loss 8.882 | ppl 471.94 | wps 26245.2 | ups 0.4 | wpb 64844.1 | bsz 126.7 | num_updates 776 | lr 9.70806e-05 | gnorm 0.913 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 1915
2022-03-05 14:53:53 | INFO | fairseq.trainer | begin training epoch 17
2022-03-05 14:53:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:54:47 | INFO | train_inner | epoch 017:     24 / 49 loss=8.889, ppl=474, wps=26566.4, ups=0.41, wpb=64867.4, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.862, loss_scale=16, train_wall=205, gb_free=8.8, wall=1969
2022-03-05 14:55:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:55:48 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.043 | ppl 527.32 | wps 48457.3 | wpb 510.9 | bsz 1 | num_updates 825 | best_loss 9.043
2022-03-05 14:55:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 825 updates
2022-03-05 14:55:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:55:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:55:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 17 @ 825 updates, score 9.043) (writing took 4.019480883143842 seconds)
2022-03-05 14:55:52 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-05 14:55:52 | INFO | train | epoch 017 | loss 8.747 | ppl 429.7 | wps 26748.8 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 825 | lr 0.000103204 | gnorm 0.867 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 2034
2022-03-05 14:55:52 | INFO | fairseq.trainer | begin training epoch 18
2022-03-05 14:55:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:57:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:57:46 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.955 | ppl 496.27 | wps 48618.1 | wpb 510.9 | bsz 1 | num_updates 874 | best_loss 8.955
2022-03-05 14:57:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 874 updates
2022-03-05 14:57:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:57:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 18 @ 874 updates, score 8.955) (writing took 3.996163746342063 seconds)
2022-03-05 14:57:50 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-05 14:57:50 | INFO | train | epoch 018 | loss 8.613 | ppl 391.56 | wps 26766.6 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 874 | lr 0.000109328 | gnorm 0.967 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 2152
2022-03-05 14:57:50 | INFO | fairseq.trainer | begin training epoch 19
2022-03-05 14:57:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:58:49 | INFO | train_inner | epoch 019:     26 / 49 loss=8.61, ppl=390.86, wps=26820.5, ups=0.41, wpb=64876.2, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.934, loss_scale=32, train_wall=203, gb_free=8.8, wall=2211
2022-03-05 14:59:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:59:45 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.884 | ppl 472.54 | wps 48622.4 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 8.884
2022-03-05 14:59:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-05 14:59:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:59:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 14:59:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 19 @ 923 updates, score 8.884) (writing took 6.208682789467275 seconds)
2022-03-05 14:59:51 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-05 14:59:51 | INFO | train | epoch 019 | loss 8.484 | ppl 358.07 | wps 26313.7 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.941 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 2273
2022-03-05 14:59:51 | INFO | fairseq.trainer | begin training epoch 20
2022-03-05 14:59:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:01:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:01:46 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.806 | ppl 447.61 | wps 48133.3 | wpb 510.9 | bsz 1 | num_updates 972 | best_loss 8.806
2022-03-05 15:01:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 972 updates
2022-03-05 15:01:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:01:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:01:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 20 @ 972 updates, score 8.806) (writing took 4.0022429609671235 seconds)
2022-03-05 15:01:50 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-05 15:01:50 | INFO | train | epoch 020 | loss 8.357 | ppl 327.81 | wps 26779.3 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 972 | lr 0.000121576 | gnorm 0.883 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 2392
2022-03-05 15:01:50 | INFO | fairseq.trainer | begin training epoch 21
2022-03-05 15:01:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:02:53 | INFO | train_inner | epoch 021:     28 / 49 loss=8.353, ppl=326.92, wps=26588.3, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.931, loss_scale=64, train_wall=203, gb_free=8.8, wall=2455
2022-03-05 15:02:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:03:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:03:44 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.732 | ppl 425.09 | wps 48571.6 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 8.732
2022-03-05 15:03:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-05 15:03:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:03:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 21 @ 1020 updates, score 8.732) (writing took 4.01858220435679 seconds)
2022-03-05 15:03:48 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-05 15:03:48 | INFO | train | epoch 021 | loss 8.24 | ppl 302.25 | wps 26261.2 | ups 0.4 | wpb 64844.1 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.971 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 2510
2022-03-05 15:03:48 | INFO | fairseq.trainer | begin training epoch 22
2022-03-05 15:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:05:43 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.685 | ppl 411.58 | wps 48478.4 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 8.685
2022-03-05 15:05:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-05 15:05:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:05:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:05:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 22 @ 1069 updates, score 8.685) (writing took 4.416597398929298 seconds)
2022-03-05 15:05:47 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-05 15:05:47 | INFO | train | epoch 022 | loss 8.124 | ppl 278.89 | wps 26673.4 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.946 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 2630
2022-03-05 15:05:47 | INFO | fairseq.trainer | begin training epoch 23
2022-03-05 15:05:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:06:58 | INFO | train_inner | epoch 023:     31 / 49 loss=8.112, ppl=276.57, wps=26518, ups=0.41, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.977, loss_scale=32, train_wall=205, gb_free=8.8, wall=2700
2022-03-05 15:07:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:07:42 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.638 | ppl 398.5 | wps 48698 | wpb 510.9 | bsz 1 | num_updates 1118 | best_loss 8.638
2022-03-05 15:07:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1118 updates
2022-03-05 15:07:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:07:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:07:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 23 @ 1118 updates, score 8.638) (writing took 3.980081019923091 seconds)
2022-03-05 15:07:46 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-05 15:07:46 | INFO | train | epoch 023 | loss 8.015 | ppl 258.68 | wps 26777.3 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 1118 | lr 0.000139822 | gnorm 1.049 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 2748
2022-03-05 15:07:46 | INFO | fairseq.trainer | begin training epoch 24
2022-03-05 15:07:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:08:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:09:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:09:41 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.62 | ppl 393.36 | wps 48478.5 | wpb 510.9 | bsz 1 | num_updates 1166 | best_loss 8.62
2022-03-05 15:09:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1166 updates
2022-03-05 15:09:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:09:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:09:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 24 @ 1166 updates, score 8.62) (writing took 3.987944939173758 seconds)
2022-03-05 15:09:45 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-05 15:09:45 | INFO | train | epoch 024 | loss 7.903 | ppl 239.41 | wps 26217 | ups 0.4 | wpb 64844.1 | bsz 126.7 | num_updates 1166 | lr 0.000145821 | gnorm 0.96 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 2867
2022-03-05 15:09:45 | INFO | fairseq.trainer | begin training epoch 25
2022-03-05 15:09:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:11:02 | INFO | train_inner | epoch 025:     34 / 49 loss=7.885, ppl=236.45, wps=26575.6, ups=0.41, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.99, loss_scale=32, train_wall=205, gb_free=8.8, wall=2944
2022-03-05 15:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:11:40 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.551 | ppl 375.01 | wps 48520.9 | wpb 510.9 | bsz 1 | num_updates 1215 | best_loss 8.551
2022-03-05 15:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1215 updates
2022-03-05 15:11:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:11:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:11:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 25 @ 1215 updates, score 8.551) (writing took 3.9949764916673303 seconds)
2022-03-05 15:11:44 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-05 15:11:44 | INFO | train | epoch 025 | loss 7.8 | ppl 222.83 | wps 26780.8 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 1215 | lr 0.000151945 | gnorm 0.978 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 2986
2022-03-05 15:11:44 | INFO | fairseq.trainer | begin training epoch 26
2022-03-05 15:11:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:13:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:13:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:13:38 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.55 | ppl 374.79 | wps 48836.8 | wpb 510.9 | bsz 1 | num_updates 1263 | best_loss 8.55
2022-03-05 15:13:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1263 updates
2022-03-05 15:13:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:13:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:13:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 26 @ 1263 updates, score 8.55) (writing took 3.8967507909983397 seconds)
2022-03-05 15:13:42 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-05 15:13:42 | INFO | train | epoch 026 | loss 7.696 | ppl 207.34 | wps 26284.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1263 | lr 0.000157943 | gnorm 1.052 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 3104
2022-03-05 15:13:42 | INFO | fairseq.trainer | begin training epoch 27
2022-03-05 15:13:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:15:06 | INFO | train_inner | epoch 027:     37 / 49 loss=7.674, ppl=204.25, wps=26596, ups=0.41, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=1.026, loss_scale=16, train_wall=205, gb_free=8.8, wall=3188
2022-03-05 15:15:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:15:37 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.5 | ppl 362.13 | wps 48566.1 | wpb 510.9 | bsz 1 | num_updates 1312 | best_loss 8.5
2022-03-05 15:15:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1312 updates
2022-03-05 15:15:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:15:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:15:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 27 @ 1312 updates, score 8.5) (writing took 3.9165238486602902 seconds)
2022-03-05 15:15:40 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-05 15:15:40 | INFO | train | epoch 027 | loss 7.592 | ppl 192.93 | wps 26812.6 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 1312 | lr 0.000164067 | gnorm 1.002 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 3223
2022-03-05 15:15:41 | INFO | fairseq.trainer | begin training epoch 28
2022-03-05 15:15:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:17:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:17:35 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.496 | ppl 361.08 | wps 48410.8 | wpb 510.9 | bsz 1 | num_updates 1361 | best_loss 8.496
2022-03-05 15:17:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1361 updates
2022-03-05 15:17:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:17:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:17:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 28 @ 1361 updates, score 8.496) (writing took 3.9449456743896008 seconds)
2022-03-05 15:17:39 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-05 15:17:39 | INFO | train | epoch 028 | loss 7.488 | ppl 179.5 | wps 26772.6 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 1361 | lr 0.000170191 | gnorm 1.015 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 3341
2022-03-05 15:17:39 | INFO | fairseq.trainer | begin training epoch 29
2022-03-05 15:17:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:19:08 | INFO | train_inner | epoch 029:     39 / 49 loss=7.456, ppl=175.53, wps=26817.9, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=1.025, loss_scale=32, train_wall=203, gb_free=8.8, wall=3430
2022-03-05 15:19:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:19:34 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.475 | ppl 355.85 | wps 48540 | wpb 510.9 | bsz 1 | num_updates 1410 | best_loss 8.475
2022-03-05 15:19:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1410 updates
2022-03-05 15:19:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:19:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:19:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 29 @ 1410 updates, score 8.475) (writing took 4.008084425702691 seconds)
2022-03-05 15:19:38 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-05 15:19:38 | INFO | train | epoch 029 | loss 7.382 | ppl 166.86 | wps 26752.5 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 1410 | lr 0.000176315 | gnorm 1.062 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 3460
2022-03-05 15:19:38 | INFO | fairseq.trainer | begin training epoch 30
2022-03-05 15:19:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:21:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:21:33 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.474 | ppl 355.62 | wps 48517.5 | wpb 510.9 | bsz 1 | num_updates 1459 | best_loss 8.474
2022-03-05 15:21:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1459 updates
2022-03-05 15:21:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:21:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:21:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 30 @ 1459 updates, score 8.474) (writing took 4.063838887959719 seconds)
2022-03-05 15:21:37 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-05 15:21:37 | INFO | train | epoch 030 | loss 7.276 | ppl 155.03 | wps 26733.9 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 1459 | lr 0.000182439 | gnorm 1.067 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 3579
2022-03-05 15:21:37 | INFO | fairseq.trainer | begin training epoch 31
2022-03-05 15:21:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:23:10 | INFO | train_inner | epoch 031:     41 / 49 loss=7.243, ppl=151.52, wps=26798.4, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=1.07, loss_scale=32, train_wall=203, gb_free=8.8, wall=3672
2022-03-05 15:23:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:23:31 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.449 | ppl 349.52 | wps 48672.9 | wpb 510.9 | bsz 1 | num_updates 1508 | best_loss 8.449
2022-03-05 15:23:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1508 updates
2022-03-05 15:23:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:23:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt
2022-03-05 15:23:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_best.pt (epoch 31 @ 1508 updates, score 8.449) (writing took 4.076406253501773 seconds)
2022-03-05 15:23:36 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-05 15:23:36 | INFO | train | epoch 031 | loss 7.172 | ppl 144.21 | wps 26778.7 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 1508 | lr 0.000188562 | gnorm 1.072 | loss_scale 64 | train_wall 99 | gb_free 8.8 | wall 3698
2022-03-05 15:23:36 | INFO | fairseq.trainer | begin training epoch 32
2022-03-05 15:23:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:23:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:25:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:25:30 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.476 | ppl 355.96 | wps 48608.1 | wpb 510.9 | bsz 1 | num_updates 1556 | best_loss 8.449
2022-03-05 15:25:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1556 updates
2022-03-05 15:25:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:25:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:25:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 32 @ 1556 updates, score 8.476) (writing took 1.5623236084356904 seconds)
2022-03-05 15:25:32 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-05 15:25:32 | INFO | train | epoch 032 | loss 7.064 | ppl 133.83 | wps 26796.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1556 | lr 0.000194561 | gnorm 1.041 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 3814
2022-03-05 15:25:32 | INFO | fairseq.trainer | begin training epoch 33
2022-03-05 15:25:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:27:12 | INFO | train_inner | epoch 033:     44 / 49 loss=7.027, ppl=130.41, wps=26848.2, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=1.064, loss_scale=32, train_wall=205, gb_free=8.8, wall=3914
2022-03-05 15:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:27:26 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.453 | ppl 350.45 | wps 48747.7 | wpb 510.9 | bsz 1 | num_updates 1605 | best_loss 8.449
2022-03-05 15:27:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1605 updates
2022-03-05 15:27:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:27:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:27:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 33 @ 1605 updates, score 8.453) (writing took 1.7953483052551746 seconds)
2022-03-05 15:27:28 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-05 15:27:28 | INFO | train | epoch 033 | loss 6.964 | ppl 124.88 | wps 27308.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1605 | lr 0.000200685 | gnorm 1.087 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 3930
2022-03-05 15:27:28 | INFO | fairseq.trainer | begin training epoch 34
2022-03-05 15:27:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:28:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:29:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:29:23 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.463 | ppl 352.95 | wps 48316.5 | wpb 510.9 | bsz 1 | num_updates 1653 | best_loss 8.449
2022-03-05 15:29:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1653 updates
2022-03-05 15:29:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:29:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:29:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 34 @ 1653 updates, score 8.463) (writing took 1.8550247736275196 seconds)
2022-03-05 15:29:24 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-05 15:29:24 | INFO | train | epoch 034 | loss 6.862 | ppl 116.32 | wps 26742.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1653 | lr 0.000206684 | gnorm 1.097 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 4047
2022-03-05 15:29:24 | INFO | fairseq.trainer | begin training epoch 35
2022-03-05 15:29:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:31:11 | INFO | train_inner | epoch 035:     47 / 49 loss=6.819, ppl=112.89, wps=27080.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=1.092, loss_scale=32, train_wall=204, gb_free=8.8, wall=4153
2022-03-05 15:31:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:31:19 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.453 | ppl 350.4 | wps 48788.7 | wpb 510.9 | bsz 1 | num_updates 1702 | best_loss 8.449
2022-03-05 15:31:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1702 updates
2022-03-05 15:31:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:31:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:31:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 35 @ 1702 updates, score 8.453) (writing took 1.7219434343278408 seconds)
2022-03-05 15:31:21 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-05 15:31:21 | INFO | train | epoch 035 | loss 6.761 | ppl 108.43 | wps 27327.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1702 | lr 0.000212807 | gnorm 1.101 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 4163
2022-03-05 15:31:21 | INFO | fairseq.trainer | begin training epoch 36
2022-03-05 15:31:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:33:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:33:15 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.493 | ppl 360.35 | wps 48842.9 | wpb 510.9 | bsz 1 | num_updates 1751 | best_loss 8.449
2022-03-05 15:33:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1751 updates
2022-03-05 15:33:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:33:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:33:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 36 @ 1751 updates, score 8.493) (writing took 1.7458919705823064 seconds)
2022-03-05 15:33:17 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-05 15:33:17 | INFO | train | epoch 036 | loss 6.658 | ppl 100.97 | wps 27341.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1751 | lr 0.000218931 | gnorm 1.087 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 4279
2022-03-05 15:33:17 | INFO | fairseq.trainer | begin training epoch 37
2022-03-05 15:33:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:34:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:35:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:35:11 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.491 | ppl 359.91 | wps 48789 | wpb 510.9 | bsz 1 | num_updates 1799 | best_loss 8.449
2022-03-05 15:35:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1799 updates
2022-03-05 15:35:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:35:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:35:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 37 @ 1799 updates, score 8.491) (writing took 1.5520853446796536 seconds)
2022-03-05 15:35:13 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-05 15:35:13 | INFO | train | epoch 037 | loss 6.558 | ppl 94.24 | wps 26820.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1799 | lr 0.00022493 | gnorm 1.134 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 4395
2022-03-05 15:35:13 | INFO | fairseq.trainer | begin training epoch 38
2022-03-05 15:35:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:35:15 | INFO | train_inner | epoch 038:      1 / 49 loss=6.608, ppl=97.54, wps=26418.3, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=1.113, loss_scale=32, train_wall=204, gb_free=8.8, wall=4397
2022-03-05 15:37:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:37:08 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.497 | ppl 361.38 | wps 48667.4 | wpb 510.9 | bsz 1 | num_updates 1848 | best_loss 8.449
2022-03-05 15:37:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1848 updates
2022-03-05 15:37:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:37:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:37:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 38 @ 1848 updates, score 8.497) (writing took 1.6874479986727238 seconds)
2022-03-05 15:37:09 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-05 15:37:09 | INFO | train | epoch 038 | loss 6.458 | ppl 87.91 | wps 27339.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1848 | lr 0.000231054 | gnorm 1.121 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 4511
2022-03-05 15:37:09 | INFO | fairseq.trainer | begin training epoch 39
2022-03-05 15:37:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:38:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:39:04 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.603 | ppl 388.76 | wps 48645.5 | wpb 510.9 | bsz 1 | num_updates 1897 | best_loss 8.449
2022-03-05 15:39:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1897 updates
2022-03-05 15:39:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:39:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:39:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 39 @ 1897 updates, score 8.603) (writing took 1.5998656200245023 seconds)
2022-03-05 15:39:05 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-05 15:39:05 | INFO | train | epoch 039 | loss 6.357 | ppl 81.99 | wps 27368.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1897 | lr 0.000237178 | gnorm 1.138 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 4627
2022-03-05 15:39:05 | INFO | fairseq.trainer | begin training epoch 40
2022-03-05 15:39:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:39:12 | INFO | train_inner | epoch 040:      3 / 49 loss=6.403, ppl=84.65, wps=27384.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=1.132, loss_scale=32, train_wall=202, gb_free=8.8, wall=4634
2022-03-05 15:39:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:40:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:41:00 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.62 | ppl 393.52 | wps 48657.2 | wpb 510.9 | bsz 1 | num_updates 1945 | best_loss 8.449
2022-03-05 15:41:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1945 updates
2022-03-05 15:41:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:41:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:41:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 40 @ 1945 updates, score 8.62) (writing took 1.568731970153749 seconds)
2022-03-05 15:41:01 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-05 15:41:01 | INFO | train | epoch 040 | loss 6.257 | ppl 76.47 | wps 26823.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1945 | lr 0.000243176 | gnorm 1.141 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 4743
2022-03-05 15:41:01 | INFO | fairseq.trainer | begin training epoch 41
2022-03-05 15:41:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:42:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:42:56 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.651 | ppl 401.87 | wps 48747.1 | wpb 510.9 | bsz 1 | num_updates 1994 | best_loss 8.449
2022-03-05 15:42:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1994 updates
2022-03-05 15:42:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:42:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:42:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 41 @ 1994 updates, score 8.651) (writing took 1.5471900282427669 seconds)
2022-03-05 15:42:58 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-05 15:42:58 | INFO | train | epoch 041 | loss 6.164 | ppl 71.68 | wps 27378.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1994 | lr 0.0002493 | gnorm 1.179 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 4860
2022-03-05 15:42:58 | INFO | fairseq.trainer | begin training epoch 42
2022-03-05 15:42:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:43:11 | INFO | train_inner | epoch 042:      6 / 49 loss=6.198, ppl=73.41, wps=27152.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=1.157, loss_scale=32, train_wall=204, gb_free=8.8, wall=4873
2022-03-05 15:43:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:44:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:44:52 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.737 | ppl 426.67 | wps 48813.1 | wpb 510.9 | bsz 1 | num_updates 2042 | best_loss 8.449
2022-03-05 15:44:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2042 updates
2022-03-05 15:44:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:44:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:44:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 42 @ 2042 updates, score 8.737) (writing took 1.5668046418577433 seconds)
2022-03-05 15:44:54 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-05 15:44:54 | INFO | train | epoch 042 | loss 6.065 | ppl 66.93 | wps 26826.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 2042 | lr 0.000255299 | gnorm 1.197 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 4976
2022-03-05 15:44:54 | INFO | fairseq.trainer | begin training epoch 43
2022-03-05 15:44:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:46:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:46:48 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.706 | ppl 417.75 | wps 48750.7 | wpb 510.9 | bsz 1 | num_updates 2091 | best_loss 8.449
2022-03-05 15:46:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2091 updates
2022-03-05 15:46:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:46:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:46:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 43 @ 2091 updates, score 8.706) (writing took 1.9077911172062159 seconds)
2022-03-05 15:46:50 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-05 15:46:50 | INFO | train | epoch 043 | loss 5.971 | ppl 62.75 | wps 27293.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2091 | lr 0.000261423 | gnorm 1.193 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 5092
2022-03-05 15:46:50 | INFO | fairseq.trainer | begin training epoch 44
2022-03-05 15:46:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:47:10 | INFO | train_inner | epoch 044:      9 / 49 loss=6, ppl=64.02, wps=27116.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.202, loss_scale=16, train_wall=204, gb_free=8.8, wall=5112
2022-03-05 15:48:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:48:45 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.819 | ppl 451.76 | wps 48636.1 | wpb 510.9 | bsz 1 | num_updates 2140 | best_loss 8.449
2022-03-05 15:48:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2140 updates
2022-03-05 15:48:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:48:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:48:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 44 @ 2140 updates, score 8.819) (writing took 1.6408453322947025 seconds)
2022-03-05 15:48:46 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-05 15:48:46 | INFO | train | epoch 044 | loss 5.872 | ppl 58.55 | wps 27360.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2140 | lr 0.000267547 | gnorm 1.19 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 5208
2022-03-05 15:48:46 | INFO | fairseq.trainer | begin training epoch 45
2022-03-05 15:48:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:50:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:50:41 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.962 | ppl 498.54 | wps 48602.5 | wpb 510.9 | bsz 1 | num_updates 2189 | best_loss 8.449
2022-03-05 15:50:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2189 updates
2022-03-05 15:50:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:50:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:50:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 45 @ 2189 updates, score 8.962) (writing took 1.590878926217556 seconds)
2022-03-05 15:50:42 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-05 15:50:42 | INFO | train | epoch 045 | loss 5.776 | ppl 54.78 | wps 27364.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2189 | lr 0.00027367 | gnorm 1.21 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 5324
2022-03-05 15:50:42 | INFO | fairseq.trainer | begin training epoch 46
2022-03-05 15:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:51:07 | INFO | train_inner | epoch 046:     11 / 49 loss=5.805, ppl=55.9, wps=27391.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.209, loss_scale=32, train_wall=202, gb_free=8.8, wall=5349
2022-03-05 15:52:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:52:37 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.993 | ppl 509.42 | wps 48534 | wpb 510.9 | bsz 1 | num_updates 2238 | best_loss 8.449
2022-03-05 15:52:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2238 updates
2022-03-05 15:52:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:52:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:52:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 46 @ 2238 updates, score 8.993) (writing took 1.5996692394837737 seconds)
2022-03-05 15:52:38 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-05 15:52:38 | INFO | train | epoch 046 | loss 5.681 | ppl 51.32 | wps 27349.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2238 | lr 0.000279794 | gnorm 1.264 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 5441
2022-03-05 15:52:38 | INFO | fairseq.trainer | begin training epoch 47
2022-03-05 15:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:54:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:54:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:54:33 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.976 | ppl 503.66 | wps 48791.1 | wpb 510.9 | bsz 1 | num_updates 2286 | best_loss 8.449
2022-03-05 15:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2286 updates
2022-03-05 15:54:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 47 @ 2286 updates, score 8.976) (writing took 1.642701718956232 seconds)
2022-03-05 15:54:35 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-05 15:54:35 | INFO | train | epoch 047 | loss 5.583 | ppl 47.93 | wps 26798.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 2286 | lr 0.000285793 | gnorm 1.243 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 5557
2022-03-05 15:54:35 | INFO | fairseq.trainer | begin training epoch 48
2022-03-05 15:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:55:06 | INFO | train_inner | epoch 048:     14 / 49 loss=5.608, ppl=48.77, wps=27125.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.245, loss_scale=32, train_wall=205, gb_free=8.8, wall=5588
2022-03-05 15:56:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:56:29 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.072 | ppl 538.12 | wps 48663.2 | wpb 510.9 | bsz 1 | num_updates 2335 | best_loss 8.449
2022-03-05 15:56:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2335 updates
2022-03-05 15:56:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:56:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:56:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 48 @ 2335 updates, score 9.072) (writing took 1.6112000159919262 seconds)
2022-03-05 15:56:31 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-05 15:56:31 | INFO | train | epoch 048 | loss 5.492 | ppl 45.02 | wps 27345.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2335 | lr 0.000291917 | gnorm 1.246 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 5673
2022-03-05 15:56:31 | INFO | fairseq.trainer | begin training epoch 49
2022-03-05 15:56:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:58:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:58:25 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.145 | ppl 566.18 | wps 48684.4 | wpb 510.9 | bsz 1 | num_updates 2384 | best_loss 8.449
2022-03-05 15:58:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2384 updates
2022-03-05 15:58:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:58:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 15:58:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 49 @ 2384 updates, score 9.145) (writing took 1.5927744349464774 seconds)
2022-03-05 15:58:27 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-05 15:58:27 | INFO | train | epoch 049 | loss 5.398 | ppl 42.16 | wps 27366.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2384 | lr 0.00029804 | gnorm 1.307 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 5789
2022-03-05 15:58:27 | INFO | fairseq.trainer | begin training epoch 50
2022-03-05 15:58:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:59:03 | INFO | train_inner | epoch 050:     16 / 49 loss=5.415, ppl=42.66, wps=27388.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.261, loss_scale=32, train_wall=203, gb_free=8.8, wall=5825
2022-03-05 15:59:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 16:00:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:00:21 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.286 | ppl 624.24 | wps 48601.4 | wpb 510.9 | bsz 1 | num_updates 2432 | best_loss 8.449
2022-03-05 16:00:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2432 updates
2022-03-05 16:00:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:00:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:00:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 50 @ 2432 updates, score 9.286) (writing took 1.6502683842554688 seconds)
2022-03-05 16:00:23 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-05 16:00:23 | INFO | train | epoch 050 | loss 5.298 | ppl 39.33 | wps 26798 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 2432 | lr 0.000304039 | gnorm 1.266 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 5905
2022-03-05 16:00:23 | INFO | fairseq.trainer | begin training epoch 51
2022-03-05 16:00:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:02:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:02:18 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.319 | ppl 638.74 | wps 48181.8 | wpb 510.9 | bsz 1 | num_updates 2481 | best_loss 8.449
2022-03-05 16:02:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2481 updates
2022-03-05 16:02:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:02:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:02:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 51 @ 2481 updates, score 9.319) (writing took 1.6614660266786814 seconds)
2022-03-05 16:02:19 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-05 16:02:19 | INFO | train | epoch 051 | loss 5.208 | ppl 36.97 | wps 27367.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2481 | lr 0.000310163 | gnorm 1.287 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 6021
2022-03-05 16:02:19 | INFO | fairseq.trainer | begin training epoch 52
2022-03-05 16:02:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:03:02 | INFO | train_inner | epoch 052:     19 / 49 loss=5.212, ppl=37.08, wps=27129.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.306, loss_scale=32, train_wall=204, gb_free=8.8, wall=6064
2022-03-05 16:04:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:04:14 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.434 | ppl 691.84 | wps 48500.1 | wpb 510.9 | bsz 1 | num_updates 2530 | best_loss 8.449
2022-03-05 16:04:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2530 updates
2022-03-05 16:04:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:04:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:04:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 52 @ 2530 updates, score 9.434) (writing took 1.6345995729789138 seconds)
2022-03-05 16:04:16 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-05 16:04:16 | INFO | train | epoch 052 | loss 5.115 | ppl 34.66 | wps 27333.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2530 | lr 0.000316287 | gnorm 1.312 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 6138
2022-03-05 16:04:16 | INFO | fairseq.trainer | begin training epoch 53
2022-03-05 16:04:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:04:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 16:04:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:06:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:06:10 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.492 | ppl 720.28 | wps 48970.3 | wpb 510.9 | bsz 1 | num_updates 2577 | best_loss 8.449
2022-03-05 16:06:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2577 updates
2022-03-05 16:06:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:06:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:06:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 53 @ 2577 updates, score 9.492) (writing took 1.6313095213845372 seconds)
2022-03-05 16:06:12 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-05 16:06:12 | INFO | train | epoch 053 | loss 5.021 | ppl 32.46 | wps 26234.5 | ups 0.4 | wpb 64829.4 | bsz 126.6 | num_updates 2577 | lr 0.000322161 | gnorm 1.352 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 6254
2022-03-05 16:06:12 | INFO | fairseq.trainer | begin training epoch 54
2022-03-05 16:06:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:07:04 | INFO | train_inner | epoch 054:     23 / 49 loss=5.033, ppl=32.74, wps=26868.6, ups=0.41, wpb=64867.4, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.352, loss_scale=16, train_wall=207, gb_free=8.8, wall=6306
2022-03-05 16:08:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:08:06 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.665 | ppl 811.82 | wps 48514.7 | wpb 510.9 | bsz 1 | num_updates 2626 | best_loss 8.449
2022-03-05 16:08:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2626 updates
2022-03-05 16:08:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:08:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:08:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 54 @ 2626 updates, score 9.665) (writing took 1.6507952939718962 seconds)
2022-03-05 16:08:08 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-05 16:08:08 | INFO | train | epoch 054 | loss 4.935 | ppl 30.59 | wps 27352.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2626 | lr 0.000328284 | gnorm 1.376 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 6370
2022-03-05 16:08:08 | INFO | fairseq.trainer | begin training epoch 55
2022-03-05 16:08:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:09:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:10:02 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.658 | ppl 807.78 | wps 48646.6 | wpb 510.9 | bsz 1 | num_updates 2675 | best_loss 8.449
2022-03-05 16:10:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2675 updates
2022-03-05 16:10:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:10:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:10:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 55 @ 2675 updates, score 9.658) (writing took 1.5760237695649266 seconds)
2022-03-05 16:10:04 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-05 16:10:04 | INFO | train | epoch 055 | loss 4.841 | ppl 28.65 | wps 27379.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2675 | lr 0.000334408 | gnorm 1.385 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 6486
2022-03-05 16:10:04 | INFO | fairseq.trainer | begin training epoch 56
2022-03-05 16:10:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:11:01 | INFO | train_inner | epoch 056:     25 / 49 loss=4.84, ppl=28.65, wps=27394.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.376, loss_scale=32, train_wall=202, gb_free=8.8, wall=6543
2022-03-05 16:11:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:11:59 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.778 | ppl 878.17 | wps 48011.9 | wpb 510.9 | bsz 1 | num_updates 2724 | best_loss 8.449
2022-03-05 16:11:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2724 updates
2022-03-05 16:11:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:12:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:12:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 56 @ 2724 updates, score 9.778) (writing took 1.6619885237887502 seconds)
2022-03-05 16:12:00 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-05 16:12:00 | INFO | train | epoch 056 | loss 4.749 | ppl 26.88 | wps 27338.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2724 | lr 0.000340532 | gnorm 1.394 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 6602
2022-03-05 16:12:00 | INFO | fairseq.trainer | begin training epoch 57
2022-03-05 16:12:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:12:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:13:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:13:55 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.851 | ppl 923.46 | wps 48623.7 | wpb 510.9 | bsz 1 | num_updates 2772 | best_loss 8.449
2022-03-05 16:13:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2772 updates
2022-03-05 16:13:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:13:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:13:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 57 @ 2772 updates, score 9.851) (writing took 1.5716934073716402 seconds)
2022-03-05 16:13:56 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-05 16:13:56 | INFO | train | epoch 057 | loss 4.659 | ppl 25.27 | wps 26828.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 2772 | lr 0.000346531 | gnorm 1.448 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 6718
2022-03-05 16:13:56 | INFO | fairseq.trainer | begin training epoch 58
2022-03-05 16:13:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:15:00 | INFO | train_inner | epoch 058:     28 / 49 loss=4.654, ppl=25.18, wps=27130.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.424, loss_scale=16, train_wall=204, gb_free=8.8, wall=6782
2022-03-05 16:15:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:15:51 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.958 | ppl 994.47 | wps 48668.3 | wpb 510.9 | bsz 1 | num_updates 2821 | best_loss 8.449
2022-03-05 16:15:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2821 updates
2022-03-05 16:15:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:15:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:15:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 58 @ 2821 updates, score 9.958) (writing took 1.631956035271287 seconds)
2022-03-05 16:15:52 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-05 16:15:52 | INFO | train | epoch 058 | loss 4.567 | ppl 23.7 | wps 27353 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2821 | lr 0.000352654 | gnorm 1.422 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 6834
2022-03-05 16:15:52 | INFO | fairseq.trainer | begin training epoch 59
2022-03-05 16:15:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:17:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:17:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:17:47 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.954 | ppl 991.61 | wps 48731.2 | wpb 510.9 | bsz 1 | num_updates 2869 | best_loss 8.449
2022-03-05 16:17:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2869 updates
2022-03-05 16:17:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:17:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:17:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 59 @ 2869 updates, score 9.954) (writing took 1.600220551714301 seconds)
2022-03-05 16:17:49 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-05 16:17:49 | INFO | train | epoch 059 | loss 4.476 | ppl 22.25 | wps 26799.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 2869 | lr 0.000358653 | gnorm 1.44 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 6951
2022-03-05 16:17:49 | INFO | fairseq.trainer | begin training epoch 60
2022-03-05 16:17:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:18:59 | INFO | train_inner | epoch 060:     31 / 49 loss=4.471, ppl=22.17, wps=27136.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.466, loss_scale=16, train_wall=204, gb_free=8.8, wall=7021
2022-03-05 16:19:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:19:43 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.983 | ppl 1011.8 | wps 48478.3 | wpb 510.9 | bsz 1 | num_updates 2918 | best_loss 8.449
2022-03-05 16:19:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2918 updates
2022-03-05 16:19:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:19:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:19:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 60 @ 2918 updates, score 9.983) (writing took 1.6517401514574885 seconds)
2022-03-05 16:19:45 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-05 16:19:45 | INFO | train | epoch 060 | loss 4.391 | ppl 20.98 | wps 27352.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2918 | lr 0.000364777 | gnorm 1.476 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 7067
2022-03-05 16:19:45 | INFO | fairseq.trainer | begin training epoch 61
2022-03-05 16:19:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:21:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:21:39 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 10.113 | ppl 1107.34 | wps 48609.5 | wpb 510.9 | bsz 1 | num_updates 2967 | best_loss 8.449
2022-03-05 16:21:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2967 updates
2022-03-05 16:21:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:21:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:21:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 61 @ 2967 updates, score 10.113) (writing took 1.642493317835033 seconds)
2022-03-05 16:21:41 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-05 16:21:41 | INFO | train | epoch 061 | loss 4.305 | ppl 19.77 | wps 27335.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2967 | lr 0.000370901 | gnorm 1.549 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 7183
2022-03-05 16:21:41 | INFO | fairseq.trainer | begin training epoch 62
2022-03-05 16:21:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:22:56 | INFO | train_inner | epoch 062:     33 / 49 loss=4.281, ppl=19.44, wps=27376.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.437, loss_scale=32, train_wall=203, gb_free=8.8, wall=7258
2022-03-05 16:23:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:23:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:23:35 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 10.23 | ppl 1201.02 | wps 48612.2 | wpb 510.9 | bsz 1 | num_updates 3015 | best_loss 8.449
2022-03-05 16:23:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3015 updates
2022-03-05 16:23:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:23:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:23:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 62 @ 3015 updates, score 10.23) (writing took 1.6161624090746045 seconds)
2022-03-05 16:23:37 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-05 16:23:37 | INFO | train | epoch 062 | loss 4.208 | ppl 18.49 | wps 26804.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 3015 | lr 0.0003769 | gnorm 1.467 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 7299
2022-03-05 16:23:37 | INFO | fairseq.trainer | begin training epoch 63
2022-03-05 16:23:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:25:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:25:32 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 10.373 | ppl 1326.41 | wps 48689.2 | wpb 510.9 | bsz 1 | num_updates 3064 | best_loss 8.449
2022-03-05 16:25:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3064 updates
2022-03-05 16:25:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:25:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:25:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 63 @ 3064 updates, score 10.373) (writing took 1.5952113149687648 seconds)
2022-03-05 16:25:33 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-05 16:25:33 | INFO | train | epoch 063 | loss 4.125 | ppl 17.45 | wps 27377.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3064 | lr 0.000383023 | gnorm 1.479 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 7415
2022-03-05 16:25:33 | INFO | fairseq.trainer | begin training epoch 64
2022-03-05 16:25:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:26:55 | INFO | train_inner | epoch 064:     36 / 49 loss=4.107, ppl=17.23, wps=27136.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.494, loss_scale=16, train_wall=205, gb_free=8.8, wall=7497
2022-03-05 16:27:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:27:28 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 10.382 | ppl 1334.83 | wps 48546.6 | wpb 510.9 | bsz 1 | num_updates 3113 | best_loss 8.449
2022-03-05 16:27:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3113 updates
2022-03-05 16:27:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:27:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:27:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 64 @ 3113 updates, score 10.382) (writing took 1.668280865997076 seconds)
2022-03-05 16:27:29 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-05 16:27:29 | INFO | train | epoch 064 | loss 4.04 | ppl 16.45 | wps 27325.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3113 | lr 0.000389147 | gnorm 1.559 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 7532
2022-03-05 16:27:29 | INFO | fairseq.trainer | begin training epoch 65
2022-03-05 16:27:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:29:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:29:24 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 10.649 | ppl 1605.33 | wps 48557.6 | wpb 510.9 | bsz 1 | num_updates 3162 | best_loss 8.449
2022-03-05 16:29:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3162 updates
2022-03-05 16:29:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:29:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:29:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 65 @ 3162 updates, score 10.649) (writing took 1.6480389265343547 seconds)
2022-03-05 16:29:26 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-05 16:29:26 | INFO | train | epoch 065 | loss 3.949 | ppl 15.45 | wps 27347.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3162 | lr 0.000395271 | gnorm 1.453 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 7648
2022-03-05 16:29:26 | INFO | fairseq.trainer | begin training epoch 66
2022-03-05 16:29:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:30:52 | INFO | train_inner | epoch 066:     38 / 49 loss=3.933, ppl=15.28, wps=27363.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.555, loss_scale=32, train_wall=203, gb_free=8.8, wall=7734
2022-03-05 16:30:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:31:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:31:20 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 10.458 | ppl 1406.46 | wps 48576.4 | wpb 510.9 | bsz 1 | num_updates 3210 | best_loss 8.449
2022-03-05 16:31:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3210 updates
2022-03-05 16:31:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:31:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:31:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 66 @ 3210 updates, score 10.458) (writing took 1.5939807584509254 seconds)
2022-03-05 16:31:22 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-05 16:31:22 | INFO | train | epoch 066 | loss 3.865 | ppl 14.57 | wps 26789.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 3210 | lr 0.00040127 | gnorm 1.566 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 7764
2022-03-05 16:31:22 | INFO | fairseq.trainer | begin training epoch 67
2022-03-05 16:31:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:33:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:33:16 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 10.627 | ppl 1581.47 | wps 48641.7 | wpb 510.9 | bsz 1 | num_updates 3259 | best_loss 8.449
2022-03-05 16:33:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3259 updates
2022-03-05 16:33:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:33:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:33:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 67 @ 3259 updates, score 10.627) (writing took 1.6979424599558115 seconds)
2022-03-05 16:33:18 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-05 16:33:18 | INFO | train | epoch 067 | loss 3.779 | ppl 13.73 | wps 27338.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3259 | lr 0.000407394 | gnorm 1.51 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 7880
2022-03-05 16:33:18 | INFO | fairseq.trainer | begin training epoch 68
2022-03-05 16:33:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:34:51 | INFO | train_inner | epoch 068:     41 / 49 loss=3.752, ppl=13.47, wps=27112.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.542, loss_scale=16, train_wall=205, gb_free=8.8, wall=7973
2022-03-05 16:35:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:35:13 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 10.817 | ppl 1804.54 | wps 48592.5 | wpb 510.9 | bsz 1 | num_updates 3308 | best_loss 8.449
2022-03-05 16:35:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3308 updates
2022-03-05 16:35:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:35:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:35:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 68 @ 3308 updates, score 10.817) (writing took 1.6843857811763883 seconds)
2022-03-05 16:35:14 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-05 16:35:14 | INFO | train | epoch 068 | loss 3.695 | ppl 12.95 | wps 27326.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3308 | lr 0.000413517 | gnorm 1.559 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 7996
2022-03-05 16:35:14 | INFO | fairseq.trainer | begin training epoch 69
2022-03-05 16:35:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:37:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:37:09 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 10.774 | ppl 1751.02 | wps 48584.5 | wpb 510.9 | bsz 1 | num_updates 3357 | best_loss 8.449
2022-03-05 16:37:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3357 updates
2022-03-05 16:37:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:37:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:37:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 69 @ 3357 updates, score 10.774) (writing took 1.633656551130116 seconds)
2022-03-05 16:37:11 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-05 16:37:11 | INFO | train | epoch 069 | loss 3.609 | ppl 12.21 | wps 27356.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3357 | lr 0.000419641 | gnorm 1.534 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 8113
2022-03-05 16:37:11 | INFO | fairseq.trainer | begin training epoch 70
2022-03-05 16:37:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:37:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:38:50 | INFO | train_inner | epoch 070:     44 / 49 loss=3.581, ppl=11.97, wps=27132.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.566, loss_scale=16, train_wall=204, gb_free=8.8, wall=8212
2022-03-05 16:39:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:39:05 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 10.924 | ppl 1942.56 | wps 48691.1 | wpb 510.9 | bsz 1 | num_updates 3405 | best_loss 8.449
2022-03-05 16:39:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3405 updates
2022-03-05 16:39:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:39:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:39:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 70 @ 3405 updates, score 10.924) (writing took 1.6710621314123273 seconds)
2022-03-05 16:39:07 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-05 16:39:07 | INFO | train | epoch 070 | loss 3.525 | ppl 11.51 | wps 26808.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 3405 | lr 0.00042564 | gnorm 1.603 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 8229
2022-03-05 16:39:07 | INFO | fairseq.trainer | begin training epoch 71
2022-03-05 16:39:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:40:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:41:01 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 11.037 | ppl 2100.85 | wps 48691.6 | wpb 510.9 | bsz 1 | num_updates 3454 | best_loss 8.449
2022-03-05 16:41:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3454 updates
2022-03-05 16:41:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:41:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:41:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 71 @ 3454 updates, score 11.037) (writing took 1.71960321161896 seconds)
2022-03-05 16:41:03 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-05 16:41:03 | INFO | train | epoch 071 | loss 3.453 | ppl 10.95 | wps 27335.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3454 | lr 0.000431764 | gnorm 1.598 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 8345
2022-03-05 16:41:03 | INFO | fairseq.trainer | begin training epoch 72
2022-03-05 16:41:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:42:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:42:49 | INFO | train_inner | epoch 072:     47 / 49 loss=3.418, ppl=10.69, wps=27125.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.608, loss_scale=16, train_wall=204, gb_free=8.8, wall=8451
2022-03-05 16:42:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:42:57 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 11.089 | ppl 2178.2 | wps 48586.2 | wpb 510.9 | bsz 1 | num_updates 3502 | best_loss 8.449
2022-03-05 16:42:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3502 updates
2022-03-05 16:42:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:42:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:42:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 72 @ 3502 updates, score 11.089) (writing took 1.6860121078789234 seconds)
2022-03-05 16:42:59 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-05 16:42:59 | INFO | train | epoch 072 | loss 3.366 | ppl 10.31 | wps 26800.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 3502 | lr 0.000437762 | gnorm 1.579 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 8461
2022-03-05 16:42:59 | INFO | fairseq.trainer | begin training epoch 73
2022-03-05 16:42:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:44:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:44:54 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 11.294 | ppl 2511.66 | wps 48438.2 | wpb 510.9 | bsz 1 | num_updates 3551 | best_loss 8.449
2022-03-05 16:44:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3551 updates
2022-03-05 16:44:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:44:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:44:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 73 @ 3551 updates, score 11.294) (writing took 1.627702104859054 seconds)
2022-03-05 16:44:55 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-05 16:44:55 | INFO | train | epoch 073 | loss 3.293 | ppl 9.8 | wps 27314.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3551 | lr 0.000443886 | gnorm 1.621 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 8577
2022-03-05 16:44:55 | INFO | fairseq.trainer | begin training epoch 74
2022-03-05 16:44:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:46:46 | INFO | train_inner | epoch 074:     49 / 49 loss=3.255, ppl=9.55, wps=27325, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=3600, lr=0.00045001, gnorm=1.6, loss_scale=16, train_wall=202, gb_free=8.8, wall=8688
2022-03-05 16:46:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:46:50 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 11.263 | ppl 2458.18 | wps 48598.1 | wpb 510.9 | bsz 1 | num_updates 3600 | best_loss 8.449
2022-03-05 16:46:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3600 updates
2022-03-05 16:46:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:46:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:46:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 74 @ 3600 updates, score 11.263) (writing took 1.612400938756764 seconds)
2022-03-05 16:46:52 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-05 16:46:52 | INFO | train | epoch 074 | loss 3.213 | ppl 9.27 | wps 27314.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3600 | lr 0.00045001 | gnorm 1.586 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 8694
2022-03-05 16:46:52 | INFO | fairseq.trainer | begin training epoch 75
2022-03-05 16:46:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:48:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:48:46 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 11.462 | ppl 2821.99 | wps 48444.4 | wpb 510.9 | bsz 1 | num_updates 3649 | best_loss 8.449
2022-03-05 16:48:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3649 updates
2022-03-05 16:48:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:48:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:48:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 75 @ 3649 updates, score 11.462) (writing took 2.0669418685138226 seconds)
2022-03-05 16:48:49 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-05 16:48:49 | INFO | train | epoch 075 | loss 3.134 | ppl 8.78 | wps 27225 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3649 | lr 0.000456134 | gnorm 1.6 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 8811
2022-03-05 16:48:49 | INFO | fairseq.trainer | begin training epoch 76
2022-03-05 16:48:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:48:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:50:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:50:43 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 11.424 | ppl 2748.3 | wps 48446.7 | wpb 510.9 | bsz 1 | num_updates 3697 | best_loss 8.449
2022-03-05 16:50:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3697 updates
2022-03-05 16:50:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:50:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:50:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 76 @ 3697 updates, score 11.424) (writing took 1.6681786412373185 seconds)
2022-03-05 16:50:45 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-05 16:50:45 | INFO | train | epoch 076 | loss 3.063 | ppl 8.35 | wps 26742 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 3697 | lr 0.000462133 | gnorm 1.664 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 8927
2022-03-05 16:50:45 | INFO | fairseq.trainer | begin training epoch 77
2022-03-05 16:50:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:50:52 | INFO | train_inner | epoch 077:      3 / 49 loss=3.094, ppl=8.54, wps=26351.9, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.629, loss_scale=16, train_wall=205, gb_free=8.8, wall=8934
2022-03-05 16:52:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:52:40 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 11.702 | ppl 3331.42 | wps 48452.6 | wpb 510.9 | bsz 1 | num_updates 3746 | best_loss 8.449
2022-03-05 16:52:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3746 updates
2022-03-05 16:52:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:52:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:52:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 77 @ 3746 updates, score 11.702) (writing took 1.5843393672257662 seconds)
2022-03-05 16:52:41 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-05 16:52:41 | INFO | train | epoch 077 | loss 2.994 | ppl 7.97 | wps 27339.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3746 | lr 0.000468256 | gnorm 1.645 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 9043
2022-03-05 16:52:41 | INFO | fairseq.trainer | begin training epoch 78
2022-03-05 16:52:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:53:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:54:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:54:36 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 11.818 | ppl 3610.97 | wps 48513.7 | wpb 510.9 | bsz 1 | num_updates 3794 | best_loss 8.449
2022-03-05 16:54:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3794 updates
2022-03-05 16:54:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:54:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:54:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 78 @ 3794 updates, score 11.818) (writing took 1.6697310181334615 seconds)
2022-03-05 16:54:38 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-05 16:54:38 | INFO | train | epoch 078 | loss 2.91 | ppl 7.52 | wps 26705.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 3794 | lr 0.000474255 | gnorm 1.599 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 9160
2022-03-05 16:54:38 | INFO | fairseq.trainer | begin training epoch 79
2022-03-05 16:54:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:54:51 | INFO | train_inner | epoch 079:      6 / 49 loss=2.942, ppl=7.69, wps=27079.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.616, loss_scale=16, train_wall=205, gb_free=8.8, wall=9173
2022-03-05 16:56:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:56:32 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 11.732 | ppl 3402.01 | wps 48505.3 | wpb 510.9 | bsz 1 | num_updates 3843 | best_loss 8.449
2022-03-05 16:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3843 updates
2022-03-05 16:56:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:56:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:56:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 79 @ 3843 updates, score 11.732) (writing took 1.6964633436873555 seconds)
2022-03-05 16:56:34 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-05 16:56:34 | INFO | train | epoch 079 | loss 2.835 | ppl 7.13 | wps 27307.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3843 | lr 0.000480379 | gnorm 1.605 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 9276
2022-03-05 16:56:34 | INFO | fairseq.trainer | begin training epoch 80
2022-03-05 16:56:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:58:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:58:29 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 11.954 | ppl 3966.35 | wps 48522.4 | wpb 510.9 | bsz 1 | num_updates 3892 | best_loss 8.449
2022-03-05 16:58:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3892 updates
2022-03-05 16:58:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:58:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 16:58:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 80 @ 3892 updates, score 11.954) (writing took 1.6006798911839724 seconds)
2022-03-05 16:58:30 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-05 16:58:30 | INFO | train | epoch 080 | loss 2.764 | ppl 6.79 | wps 27352.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3892 | lr 0.000486503 | gnorm 1.556 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 9392
2022-03-05 16:58:30 | INFO | fairseq.trainer | begin training epoch 81
2022-03-05 16:58:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:58:48 | INFO | train_inner | epoch 081:      8 / 49 loss=2.786, ppl=6.9, wps=27359.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.595, loss_scale=16, train_wall=203, gb_free=8.8, wall=9411
2022-03-05 16:59:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:00:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:00:25 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 11.818 | ppl 3610.66 | wps 48604.3 | wpb 510.9 | bsz 1 | num_updates 3940 | best_loss 8.449
2022-03-05 17:00:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3940 updates
2022-03-05 17:00:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:00:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:00:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 81 @ 3940 updates, score 11.818) (writing took 1.606059175916016 seconds)
2022-03-05 17:00:26 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-05 17:00:26 | INFO | train | epoch 081 | loss 2.701 | ppl 6.5 | wps 26784.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 3940 | lr 0.000492502 | gnorm 1.657 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 9509
2022-03-05 17:00:26 | INFO | fairseq.trainer | begin training epoch 82
2022-03-05 17:00:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:02:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:02:21 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 12.198 | ppl 4698.67 | wps 48483.9 | wpb 510.9 | bsz 1 | num_updates 3989 | best_loss 8.449
2022-03-05 17:02:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3989 updates
2022-03-05 17:02:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:02:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:02:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 82 @ 3989 updates, score 12.198) (writing took 1.8266063593328 seconds)
2022-03-05 17:02:23 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-05 17:02:23 | INFO | train | epoch 082 | loss 2.632 | ppl 6.2 | wps 27285.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3989 | lr 0.000498625 | gnorm 1.616 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 9625
2022-03-05 17:02:23 | INFO | fairseq.trainer | begin training epoch 83
2022-03-05 17:02:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:02:48 | INFO | train_inner | epoch 083:     11 / 49 loss=2.65, ppl=6.28, wps=27088.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.624, loss_scale=16, train_wall=205, gb_free=8.8, wall=9650
2022-03-05 17:04:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:04:18 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 12.043 | ppl 4220.02 | wps 48670.4 | wpb 510.9 | bsz 1 | num_updates 4038 | best_loss 8.449
2022-03-05 17:04:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4038 updates
2022-03-05 17:04:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:04:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:04:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 83 @ 4038 updates, score 12.043) (writing took 1.7303575268015265 seconds)
2022-03-05 17:04:19 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-05 17:04:19 | INFO | train | epoch 083 | loss 2.559 | ppl 5.89 | wps 27312.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4038 | lr 0.000497642 | gnorm 1.629 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 9741
2022-03-05 17:04:19 | INFO | fairseq.trainer | begin training epoch 84
2022-03-05 17:04:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:06:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:06:14 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 12.16 | ppl 4577.67 | wps 48661.5 | wpb 510.9 | bsz 1 | num_updates 4087 | best_loss 8.449
2022-03-05 17:06:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4087 updates
2022-03-05 17:06:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:06:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:06:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 84 @ 4087 updates, score 12.16) (writing took 1.710019776597619 seconds)
2022-03-05 17:06:16 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-05 17:06:16 | INFO | train | epoch 084 | loss 2.482 | ppl 5.58 | wps 27335.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4087 | lr 0.00049465 | gnorm 1.538 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 9858
2022-03-05 17:06:16 | INFO | fairseq.trainer | begin training epoch 85
2022-03-05 17:06:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:06:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:06:47 | INFO | train_inner | epoch 085:     14 / 49 loss=2.506, ppl=5.68, wps=27095.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.595, loss_scale=16, train_wall=205, gb_free=8.8, wall=9889
2022-03-05 17:08:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:08:10 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 12.237 | ppl 4828.59 | wps 48551.7 | wpb 510.9 | bsz 1 | num_updates 4135 | best_loss 8.449
2022-03-05 17:08:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4135 updates
2022-03-05 17:08:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:08:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:08:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 85 @ 4135 updates, score 12.237) (writing took 1.6386543409898877 seconds)
2022-03-05 17:08:12 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-05 17:08:12 | INFO | train | epoch 085 | loss 2.414 | ppl 5.33 | wps 26786.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 4135 | lr 0.00049177 | gnorm 1.564 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 9974
2022-03-05 17:08:12 | INFO | fairseq.trainer | begin training epoch 86
2022-03-05 17:08:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:10:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:10:06 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 12.532 | ppl 5924.26 | wps 48781.8 | wpb 510.9 | bsz 1 | num_updates 4184 | best_loss 8.449
2022-03-05 17:10:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4184 updates
2022-03-05 17:10:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:10:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:10:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 86 @ 4184 updates, score 12.532) (writing took 1.7565622990950942 seconds)
2022-03-05 17:10:08 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-05 17:10:08 | INFO | train | epoch 086 | loss 2.349 | ppl 5.09 | wps 27302.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4184 | lr 0.000488882 | gnorm 1.537 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 10090
2022-03-05 17:10:08 | INFO | fairseq.trainer | begin training epoch 87
2022-03-05 17:10:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:10:44 | INFO | train_inner | epoch 087:     16 / 49 loss=2.355, ppl=5.12, wps=27359.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.521, loss_scale=16, train_wall=203, gb_free=8.8, wall=10127
2022-03-05 17:11:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:12:03 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 12.426 | ppl 5502.16 | wps 48735.1 | wpb 510.9 | bsz 1 | num_updates 4233 | best_loss 8.449
2022-03-05 17:12:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4233 updates
2022-03-05 17:12:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:12:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:12:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 87 @ 4233 updates, score 12.426) (writing took 1.7598171466961503 seconds)
2022-03-05 17:12:04 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-05 17:12:04 | INFO | train | epoch 087 | loss 2.286 | ppl 4.88 | wps 27327.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4233 | lr 0.000486044 | gnorm 1.551 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 10207
2022-03-05 17:12:04 | INFO | fairseq.trainer | begin training epoch 88
2022-03-05 17:12:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:13:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:13:59 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 12.602 | ppl 6218.83 | wps 48512 | wpb 510.9 | bsz 1 | num_updates 4282 | best_loss 8.449
2022-03-05 17:13:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4282 updates
2022-03-05 17:13:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:14:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:14:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 88 @ 4282 updates, score 12.602) (writing took 1.6130575006827712 seconds)
2022-03-05 17:14:01 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-05 17:14:01 | INFO | train | epoch 088 | loss 2.211 | ppl 4.63 | wps 27360.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4282 | lr 0.000483255 | gnorm 1.464 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 10323
2022-03-05 17:14:01 | INFO | fairseq.trainer | begin training epoch 89
2022-03-05 17:14:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:14:42 | INFO | train_inner | epoch 089:     18 / 49 loss=2.226, ppl=4.68, wps=27368.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.513, loss_scale=32, train_wall=203, gb_free=8.8, wall=10364
2022-03-05 17:15:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:15:55 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 12.888 | ppl 7581.51 | wps 48618.5 | wpb 510.9 | bsz 1 | num_updates 4331 | best_loss 8.449
2022-03-05 17:15:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4331 updates
2022-03-05 17:15:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:15:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:15:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 89 @ 4331 updates, score 12.888) (writing took 1.6211736602708697 seconds)
2022-03-05 17:15:57 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-05 17:15:57 | INFO | train | epoch 089 | loss 2.152 | ppl 4.45 | wps 27342.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4331 | lr 0.000480514 | gnorm 1.502 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 10439
2022-03-05 17:15:57 | INFO | fairseq.trainer | begin training epoch 90
2022-03-05 17:15:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:16:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 17:17:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:17:51 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 12.769 | ppl 6980.8 | wps 48598 | wpb 510.9 | bsz 1 | num_updates 4379 | best_loss 8.449
2022-03-05 17:17:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4379 updates
2022-03-05 17:17:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:17:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 90 @ 4379 updates, score 12.769) (writing took 1.7232331316918135 seconds)
2022-03-05 17:17:53 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-05 17:17:53 | INFO | train | epoch 090 | loss 2.088 | ppl 4.25 | wps 26776.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 4379 | lr 0.000477873 | gnorm 1.448 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 10555
2022-03-05 17:17:53 | INFO | fairseq.trainer | begin training epoch 91
2022-03-05 17:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:18:41 | INFO | train_inner | epoch 091:     21 / 49 loss=2.098, ppl=4.28, wps=27115.2, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.478, loss_scale=32, train_wall=204, gb_free=8.8, wall=10603
2022-03-05 17:19:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:19:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:19:48 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 12.659 | ppl 6469.49 | wps 48521 | wpb 510.9 | bsz 1 | num_updates 4427 | best_loss 8.449
2022-03-05 17:19:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4427 updates
2022-03-05 17:19:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:19:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:19:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 91 @ 4427 updates, score 12.659) (writing took 1.7207176489755511 seconds)
2022-03-05 17:19:49 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-05 17:19:49 | INFO | train | epoch 091 | loss 2.04 | ppl 4.11 | wps 26772.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 4427 | lr 0.000475275 | gnorm 1.51 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 10671
2022-03-05 17:19:49 | INFO | fairseq.trainer | begin training epoch 92
2022-03-05 17:19:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:21:44 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 12.858 | ppl 7423.06 | wps 48501.5 | wpb 510.9 | bsz 1 | num_updates 4476 | best_loss 8.449
2022-03-05 17:21:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4476 updates
2022-03-05 17:21:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:21:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:21:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 92 @ 4476 updates, score 12.858) (writing took 1.8191088223829865 seconds)
2022-03-05 17:21:46 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-05 17:21:46 | INFO | train | epoch 092 | loss 1.982 | ppl 3.95 | wps 27284.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4476 | lr 0.000472667 | gnorm 1.468 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 10788
2022-03-05 17:21:46 | INFO | fairseq.trainer | begin training epoch 93
2022-03-05 17:21:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:22:40 | INFO | train_inner | epoch 093:     24 / 49 loss=1.982, ppl=3.95, wps=27078.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.464, loss_scale=16, train_wall=205, gb_free=8.8, wall=10842
2022-03-05 17:23:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:23:40 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 13.085 | ppl 8688.83 | wps 48494.6 | wpb 510.9 | bsz 1 | num_updates 4525 | best_loss 8.449
2022-03-05 17:23:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4525 updates
2022-03-05 17:23:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:23:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:23:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 93 @ 4525 updates, score 13.085) (writing took 1.8369872234761715 seconds)
2022-03-05 17:23:42 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-05 17:23:42 | INFO | train | epoch 093 | loss 1.922 | ppl 3.79 | wps 27282.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4525 | lr 0.0004701 | gnorm 1.435 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 10904
2022-03-05 17:23:42 | INFO | fairseq.trainer | begin training epoch 94
2022-03-05 17:23:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:25:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:25:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:25:37 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 13.157 | ppl 9135.54 | wps 48657 | wpb 510.9 | bsz 1 | num_updates 4573 | best_loss 8.449
2022-03-05 17:25:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4573 updates
2022-03-05 17:25:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:25:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:25:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 94 @ 4573 updates, score 13.157) (writing took 1.8945787101984024 seconds)
2022-03-05 17:25:39 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-05 17:25:39 | INFO | train | epoch 094 | loss 1.869 | ppl 3.65 | wps 26716.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 4573 | lr 0.000467627 | gnorm 1.416 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 11021
2022-03-05 17:25:39 | INFO | fairseq.trainer | begin training epoch 95
2022-03-05 17:25:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:26:40 | INFO | train_inner | epoch 095:     27 / 49 loss=1.871, ppl=3.66, wps=27053.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.442, loss_scale=16, train_wall=205, gb_free=8.8, wall=11082
2022-03-05 17:27:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:27:34 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 13.276 | ppl 9916.26 | wps 48349.1 | wpb 510.9 | bsz 1 | num_updates 4622 | best_loss 8.449
2022-03-05 17:27:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4622 updates
2022-03-05 17:27:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:27:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:27:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 95 @ 4622 updates, score 13.276) (writing took 1.8971614576876163 seconds)
2022-03-05 17:27:35 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-05 17:27:35 | INFO | train | epoch 095 | loss 1.821 | ppl 3.53 | wps 27254.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4622 | lr 0.000465141 | gnorm 1.43 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 11137
2022-03-05 17:27:35 | INFO | fairseq.trainer | begin training epoch 96
2022-03-05 17:27:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:29:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:29:30 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 13.281 | ppl 9954.94 | wps 48372.6 | wpb 510.9 | bsz 1 | num_updates 4671 | best_loss 8.449
2022-03-05 17:29:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4671 updates
2022-03-05 17:29:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:29:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:29:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 96 @ 4671 updates, score 13.281) (writing took 1.9386482443660498 seconds)
2022-03-05 17:29:32 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-05 17:29:32 | INFO | train | epoch 096 | loss 1.772 | ppl 3.42 | wps 27246.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4671 | lr 0.000462695 | gnorm 1.426 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 11254
2022-03-05 17:29:32 | INFO | fairseq.trainer | begin training epoch 97
2022-03-05 17:29:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:30:38 | INFO | train_inner | epoch 097:     29 / 49 loss=1.766, ppl=3.4, wps=27275.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.405, loss_scale=32, train_wall=203, gb_free=8.8, wall=11320
2022-03-05 17:31:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:31:27 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 13.477 | ppl 11398.9 | wps 48591.6 | wpb 510.9 | bsz 1 | num_updates 4720 | best_loss 8.449
2022-03-05 17:31:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4720 updates
2022-03-05 17:31:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:31:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:31:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 97 @ 4720 updates, score 13.477) (writing took 1.8953069346025586 seconds)
2022-03-05 17:31:29 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-05 17:31:29 | INFO | train | epoch 097 | loss 1.72 | ppl 3.3 | wps 27263 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4720 | lr 0.000460287 | gnorm 1.377 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 11371
2022-03-05 17:31:29 | INFO | fairseq.trainer | begin training epoch 98
2022-03-05 17:31:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:31:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:33:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:33:23 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 13.695 | ppl 13259 | wps 48125.4 | wpb 510.9 | bsz 1 | num_updates 4768 | best_loss 8.449
2022-03-05 17:33:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4768 updates
2022-03-05 17:33:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:33:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:33:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 98 @ 4768 updates, score 13.695) (writing took 1.8365178741514683 seconds)
2022-03-05 17:33:25 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-05 17:33:25 | INFO | train | epoch 098 | loss 1.677 | ppl 3.2 | wps 26690.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 4768 | lr 0.000457965 | gnorm 1.395 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 11487
2022-03-05 17:33:25 | INFO | fairseq.trainer | begin training epoch 99
2022-03-05 17:33:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:34:38 | INFO | train_inner | epoch 099:     32 / 49 loss=1.676, ppl=3.2, wps=27038, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.384, loss_scale=16, train_wall=205, gb_free=8.8, wall=11560
2022-03-05 17:35:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:35:20 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 13.697 | ppl 13277.8 | wps 48470.4 | wpb 510.9 | bsz 1 | num_updates 4817 | best_loss 8.449
2022-03-05 17:35:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4817 updates
2022-03-05 17:35:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:35:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:35:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 99 @ 4817 updates, score 13.697) (writing took 1.8788362564519048 seconds)
2022-03-05 17:35:22 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-05 17:35:22 | INFO | train | epoch 099 | loss 1.633 | ppl 3.1 | wps 27279.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4817 | lr 0.000455629 | gnorm 1.374 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 11604
2022-03-05 17:35:22 | INFO | fairseq.trainer | begin training epoch 100
2022-03-05 17:35:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:37:16 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 13.707 | ppl 13371.3 | wps 48410.6 | wpb 510.9 | bsz 1 | num_updates 4866 | best_loss 8.449
2022-03-05 17:37:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4866 updates
2022-03-05 17:37:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:37:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:37:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 100 @ 4866 updates, score 13.707) (writing took 1.888940030708909 seconds)
2022-03-05 17:37:18 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-05 17:37:18 | INFO | train | epoch 100 | loss 1.594 | ppl 3.02 | wps 27261.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4866 | lr 0.000453329 | gnorm 1.387 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 11720
2022-03-05 17:37:18 | INFO | fairseq.trainer | begin training epoch 101
2022-03-05 17:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:38:35 | INFO | train_inner | epoch 101:     34 / 49 loss=1.582, ppl=2.99, wps=27306.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.366, loss_scale=32, train_wall=203, gb_free=8.8, wall=11797
2022-03-05 17:39:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:39:13 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 13.794 | ppl 14200.3 | wps 48485.5 | wpb 510.9 | bsz 1 | num_updates 4915 | best_loss 8.449
2022-03-05 17:39:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4915 updates
2022-03-05 17:39:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:39:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:39:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 101 @ 4915 updates, score 13.794) (writing took 1.8843244696035981 seconds)
2022-03-05 17:39:15 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-05 17:39:15 | INFO | train | epoch 101 | loss 1.548 | ppl 2.92 | wps 27289.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4915 | lr 0.000451064 | gnorm 1.352 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 11837
2022-03-05 17:39:15 | INFO | fairseq.trainer | begin training epoch 102
2022-03-05 17:39:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:41:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:41:09 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 13.929 | ppl 15595.3 | wps 48617.8 | wpb 510.9 | bsz 1 | num_updates 4964 | best_loss 8.449
2022-03-05 17:41:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4964 updates
2022-03-05 17:41:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:41:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:41:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 102 @ 4964 updates, score 13.929) (writing took 1.9342172527685761 seconds)
2022-03-05 17:41:11 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-05 17:41:11 | INFO | train | epoch 102 | loss 1.509 | ppl 2.85 | wps 27248.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4964 | lr 0.000448832 | gnorm 1.337 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 11953
2022-03-05 17:41:11 | INFO | fairseq.trainer | begin training epoch 103
2022-03-05 17:41:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:42:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 17:42:35 | INFO | train_inner | epoch 103:     37 / 49 loss=1.498, ppl=2.82, wps=27042.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.327, loss_scale=32, train_wall=205, gb_free=8.8, wall=12037
2022-03-05 17:43:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:43:06 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 14.019 | ppl 16597.6 | wps 48072.7 | wpb 510.9 | bsz 1 | num_updates 5012 | best_loss 8.449
2022-03-05 17:43:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5012 updates
2022-03-05 17:43:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:43:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:43:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 103 @ 5012 updates, score 14.019) (writing took 1.9217133559286594 seconds)
2022-03-05 17:43:08 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-05 17:43:08 | INFO | train | epoch 103 | loss 1.466 | ppl 2.76 | wps 26700.4 | ups 0.41 | wpb 64853.3 | bsz 126.7 | num_updates 5012 | lr 0.000446678 | gnorm 1.31 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 12070
2022-03-05 17:43:08 | INFO | fairseq.trainer | begin training epoch 104
2022-03-05 17:43:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:44:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:45:03 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 13.957 | ppl 15902.6 | wps 48467.3 | wpb 510.9 | bsz 1 | num_updates 5061 | best_loss 8.449
2022-03-05 17:45:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5061 updates
2022-03-05 17:45:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:45:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:45:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 104 @ 5061 updates, score 13.957) (writing took 1.9184619784355164 seconds)
2022-03-05 17:45:05 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-05 17:45:05 | INFO | train | epoch 104 | loss 1.437 | ppl 2.71 | wps 27282.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5061 | lr 0.00044451 | gnorm 1.325 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 12187
2022-03-05 17:45:05 | INFO | fairseq.trainer | begin training epoch 105
2022-03-05 17:45:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:46:33 | INFO | train_inner | epoch 105:     39 / 49 loss=1.429, ppl=2.69, wps=27294.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.336, loss_scale=32, train_wall=203, gb_free=8.8, wall=12275
2022-03-05 17:46:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:47:00 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 14.193 | ppl 18728.8 | wps 46460.8 | wpb 510.9 | bsz 1 | num_updates 5110 | best_loss 8.449
2022-03-05 17:47:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5110 updates
2022-03-05 17:47:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:47:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:47:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 105 @ 5110 updates, score 14.193) (writing took 1.7817917242646217 seconds)
2022-03-05 17:47:01 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-05 17:47:01 | INFO | train | epoch 105 | loss 1.4 | ppl 2.64 | wps 27208.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5110 | lr 0.000442374 | gnorm 1.314 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 12303
2022-03-05 17:47:01 | INFO | fairseq.trainer | begin training epoch 106
2022-03-05 17:47:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:47:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 17:48:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:48:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:48:56 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 14.227 | ppl 19182 | wps 48643.3 | wpb 510.9 | bsz 1 | num_updates 5157 | best_loss 8.449
2022-03-05 17:48:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5157 updates
2022-03-05 17:48:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:48:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:48:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 106 @ 5157 updates, score 14.227) (writing took 1.680563921108842 seconds)
2022-03-05 17:48:57 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-05 17:48:57 | INFO | train | epoch 106 | loss 1.359 | ppl 2.56 | wps 26231.8 | ups 0.4 | wpb 64829.4 | bsz 126.6 | num_updates 5157 | lr 0.000440353 | gnorm 1.282 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 12420
2022-03-05 17:48:57 | INFO | fairseq.trainer | begin training epoch 107
2022-03-05 17:48:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:50:35 | INFO | train_inner | epoch 107:     43 / 49 loss=1.354, ppl=2.56, wps=26814.5, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.289, loss_scale=16, train_wall=207, gb_free=8.8, wall=12517
2022-03-05 17:50:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:50:52 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 14.29 | ppl 20026.6 | wps 48622.1 | wpb 510.9 | bsz 1 | num_updates 5206 | best_loss 8.449
2022-03-05 17:50:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5206 updates
2022-03-05 17:50:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:50:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:50:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 107 @ 5206 updates, score 14.29) (writing took 1.7431221436709166 seconds)
2022-03-05 17:50:54 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-05 17:50:54 | INFO | train | epoch 107 | loss 1.334 | ppl 2.52 | wps 27330.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5206 | lr 0.000438276 | gnorm 1.303 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 12536
2022-03-05 17:50:54 | INFO | fairseq.trainer | begin training epoch 108
2022-03-05 17:50:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:52:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:52:48 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 14.394 | ppl 21529.6 | wps 48730.3 | wpb 510.9 | bsz 1 | num_updates 5255 | best_loss 8.449
2022-03-05 17:52:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5255 updates
2022-03-05 17:52:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:52:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:52:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 108 @ 5255 updates, score 14.394) (writing took 1.7284597987309098 seconds)
2022-03-05 17:52:50 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-05 17:52:50 | INFO | train | epoch 108 | loss 1.297 | ppl 2.46 | wps 27331.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5255 | lr 0.000436228 | gnorm 1.266 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 12652
2022-03-05 17:52:50 | INFO | fairseq.trainer | begin training epoch 109
2022-03-05 17:52:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:54:32 | INFO | train_inner | epoch 109:     45 / 49 loss=1.287, ppl=2.44, wps=27359.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.281, loss_scale=32, train_wall=202, gb_free=8.8, wall=12754
2022-03-05 17:54:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:54:45 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 14.307 | ppl 20272.3 | wps 48594.8 | wpb 510.9 | bsz 1 | num_updates 5304 | best_loss 8.449
2022-03-05 17:54:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5304 updates
2022-03-05 17:54:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:54:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:54:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 109 @ 5304 updates, score 14.307) (writing took 1.7318277703598142 seconds)
2022-03-05 17:54:46 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-05 17:54:46 | INFO | train | epoch 109 | loss 1.27 | ppl 2.41 | wps 27330.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5304 | lr 0.000434208 | gnorm 1.315 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 12768
2022-03-05 17:54:46 | INFO | fairseq.trainer | begin training epoch 110
2022-03-05 17:54:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:56:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:56:41 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 14.52 | ppl 23496.7 | wps 48635 | wpb 510.9 | bsz 1 | num_updates 5353 | best_loss 8.449
2022-03-05 17:56:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5353 updates
2022-03-05 17:56:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:56:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:56:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 110 @ 5353 updates, score 14.52) (writing took 1.6458128597587347 seconds)
2022-03-05 17:56:42 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-05 17:56:42 | INFO | train | epoch 110 | loss 1.239 | ppl 2.36 | wps 27360.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5353 | lr 0.000432217 | gnorm 1.266 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 12884
2022-03-05 17:56:42 | INFO | fairseq.trainer | begin training epoch 111
2022-03-05 17:56:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:58:29 | INFO | train_inner | epoch 111:     47 / 49 loss=1.227, ppl=2.34, wps=27373.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5400, lr=0.000430331, gnorm=1.273, loss_scale=32, train_wall=202, gb_free=8.8, wall=12991
2022-03-05 17:58:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:58:37 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 14.681 | ppl 26265.4 | wps 48606.5 | wpb 510.9 | bsz 1 | num_updates 5402 | best_loss 8.449
2022-03-05 17:58:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5402 updates
2022-03-05 17:58:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:58:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 17:58:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 111 @ 5402 updates, score 14.681) (writing took 1.7171552730724216 seconds)
2022-03-05 17:58:39 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-05 17:58:39 | INFO | train | epoch 111 | loss 1.209 | ppl 2.31 | wps 27327.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5402 | lr 0.000430252 | gnorm 1.264 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 13001
2022-03-05 17:58:39 | INFO | fairseq.trainer | begin training epoch 112
2022-03-05 17:58:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:59:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:00:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:00:33 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 14.827 | ppl 29055.5 | wps 48649.9 | wpb 510.9 | bsz 1 | num_updates 5450 | best_loss 8.449
2022-03-05 18:00:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5450 updates
2022-03-05 18:00:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:00:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:00:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 112 @ 5450 updates, score 14.827) (writing took 1.7244875002652407 seconds)
2022-03-05 18:00:35 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-05 18:00:35 | INFO | train | epoch 112 | loss 1.176 | ppl 2.26 | wps 26786 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 5450 | lr 0.000428353 | gnorm 1.214 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 13117
2022-03-05 18:00:35 | INFO | fairseq.trainer | begin training epoch 113
2022-03-05 18:00:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:02:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:02:30 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 14.614 | ppl 25077.3 | wps 48685.3 | wpb 510.9 | bsz 1 | num_updates 5499 | best_loss 8.449
2022-03-05 18:02:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5499 updates
2022-03-05 18:02:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:02:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:02:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 113 @ 5499 updates, score 14.614) (writing took 1.6981572676450014 seconds)
2022-03-05 18:02:31 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-05 18:02:31 | INFO | train | epoch 113 | loss 1.158 | ppl 2.23 | wps 27330 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5499 | lr 0.00042644 | gnorm 1.236 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 13233
2022-03-05 18:02:31 | INFO | fairseq.trainer | begin training epoch 114
2022-03-05 18:02:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:02:34 | INFO | train_inner | epoch 114:      1 / 49 loss=1.167, ppl=2.25, wps=26394.1, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=5500, lr=0.000426401, gnorm=1.228, loss_scale=32, train_wall=204, gb_free=8.8, wall=13236
2022-03-05 18:04:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:04:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:04:26 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 14.804 | ppl 28600.8 | wps 48632.8 | wpb 510.9 | bsz 1 | num_updates 5547 | best_loss 8.449
2022-03-05 18:04:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5547 updates
2022-03-05 18:04:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:04:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:04:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 114 @ 5547 updates, score 14.804) (writing took 1.9243090972304344 seconds)
2022-03-05 18:04:28 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-05 18:04:28 | INFO | train | epoch 114 | loss 1.13 | ppl 2.19 | wps 26717.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 5547 | lr 0.000424591 | gnorm 1.217 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 13350
2022-03-05 18:04:28 | INFO | fairseq.trainer | begin training epoch 115
2022-03-05 18:04:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:06:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:06:22 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 14.85 | ppl 29523.6 | wps 48617.4 | wpb 510.9 | bsz 1 | num_updates 5596 | best_loss 8.449
2022-03-05 18:06:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5596 updates
2022-03-05 18:06:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:06:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:06:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 115 @ 5596 updates, score 14.85) (writing took 1.8430351493880153 seconds)
2022-03-05 18:06:24 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-05 18:06:24 | INFO | train | epoch 115 | loss 1.108 | ppl 2.15 | wps 27321.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5596 | lr 0.000422728 | gnorm 1.214 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 13466
2022-03-05 18:06:24 | INFO | fairseq.trainer | begin training epoch 116
2022-03-05 18:06:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:06:33 | INFO | train_inner | epoch 116:      4 / 49 loss=1.116, ppl=2.17, wps=27074.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=1.214, loss_scale=32, train_wall=204, gb_free=8.8, wall=13475
2022-03-05 18:08:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:08:19 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 15.057 | ppl 34083.5 | wps 48696.5 | wpb 510.9 | bsz 1 | num_updates 5645 | best_loss 8.449
2022-03-05 18:08:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5645 updates
2022-03-05 18:08:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:08:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:08:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 116 @ 5645 updates, score 15.057) (writing took 1.77771261241287 seconds)
2022-03-05 18:08:20 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-05 18:08:20 | INFO | train | epoch 116 | loss 1.08 | ppl 2.11 | wps 27323.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5645 | lr 0.000420889 | gnorm 1.193 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 13582
2022-03-05 18:08:20 | INFO | fairseq.trainer | begin training epoch 117
2022-03-05 18:08:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:09:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:10:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:10:15 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 15.033 | ppl 33519.8 | wps 48514.9 | wpb 510.9 | bsz 1 | num_updates 5693 | best_loss 8.449
2022-03-05 18:10:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5693 updates
2022-03-05 18:10:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:10:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:10:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 117 @ 5693 updates, score 15.033) (writing took 1.8450451586395502 seconds)
2022-03-05 18:10:17 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-05 18:10:17 | INFO | train | epoch 117 | loss 1.059 | ppl 2.08 | wps 26751.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 5693 | lr 0.000419111 | gnorm 1.19 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 13699
2022-03-05 18:10:17 | INFO | fairseq.trainer | begin training epoch 118
2022-03-05 18:10:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:10:33 | INFO | train_inner | epoch 118:      7 / 49 loss=1.067, ppl=2.1, wps=27090.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=1.192, loss_scale=32, train_wall=204, gb_free=8.8, wall=13715
2022-03-05 18:12:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:12:11 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 15.049 | ppl 33889.2 | wps 48753.5 | wpb 510.9 | bsz 1 | num_updates 5742 | best_loss 8.449
2022-03-05 18:12:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5742 updates
2022-03-05 18:12:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:12:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:12:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 118 @ 5742 updates, score 15.049) (writing took 1.8700671819970012 seconds)
2022-03-05 18:12:13 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-05 18:12:13 | INFO | train | epoch 118 | loss 1.039 | ppl 2.06 | wps 27292.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5742 | lr 0.000417319 | gnorm 1.195 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 13815
2022-03-05 18:12:13 | INFO | fairseq.trainer | begin training epoch 119
2022-03-05 18:12:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:14:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:14:08 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 15.132 | ppl 35914.6 | wps 48665.1 | wpb 510.9 | bsz 1 | num_updates 5791 | best_loss 8.449
2022-03-05 18:14:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5791 updates
2022-03-05 18:14:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:14:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:14:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 119 @ 5791 updates, score 15.132) (writing took 1.8375700041651726 seconds)
2022-03-05 18:14:10 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-05 18:14:10 | INFO | train | epoch 119 | loss 1.013 | ppl 2.02 | wps 27290 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5791 | lr 0.00041555 | gnorm 1.164 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 13932
2022-03-05 18:14:10 | INFO | fairseq.trainer | begin training epoch 120
2022-03-05 18:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:14:30 | INFO | train_inner | epoch 120:      9 / 49 loss=1.021, ppl=2.03, wps=27319.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=1.175, loss_scale=32, train_wall=203, gb_free=8.8, wall=13952
2022-03-05 18:15:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:16:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:16:04 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 15.249 | ppl 38949.2 | wps 48675.6 | wpb 510.9 | bsz 1 | num_updates 5839 | best_loss 8.449
2022-03-05 18:16:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5839 updates
2022-03-05 18:16:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:16:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:16:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 120 @ 5839 updates, score 15.249) (writing took 1.8821714809164405 seconds)
2022-03-05 18:16:06 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-05 18:16:06 | INFO | train | epoch 120 | loss 0.991 | ppl 1.99 | wps 26736.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 5839 | lr 0.000413838 | gnorm 1.169 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 14048
2022-03-05 18:16:06 | INFO | fairseq.trainer | begin training epoch 121
2022-03-05 18:16:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:17:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:18:01 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 15.388 | ppl 42879.7 | wps 48583.6 | wpb 510.9 | bsz 1 | num_updates 5888 | best_loss 8.449
2022-03-05 18:18:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5888 updates
2022-03-05 18:18:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:18:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:18:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 121 @ 5888 updates, score 15.388) (writing took 1.839587333612144 seconds)
2022-03-05 18:18:02 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-05 18:18:02 | INFO | train | epoch 121 | loss 0.972 | ppl 1.96 | wps 27294.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5888 | lr 0.000412113 | gnorm 1.141 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 14165
2022-03-05 18:18:02 | INFO | fairseq.trainer | begin training epoch 122
2022-03-05 18:18:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:18:30 | INFO | train_inner | epoch 122:     12 / 49 loss=0.976, ppl=1.97, wps=27071.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=1.156, loss_scale=32, train_wall=204, gb_free=8.8, wall=14192
2022-03-05 18:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:19:57 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 15.339 | ppl 41444 | wps 48446.3 | wpb 510.9 | bsz 1 | num_updates 5937 | best_loss 8.449
2022-03-05 18:19:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5937 updates
2022-03-05 18:19:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:19:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:19:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 122 @ 5937 updates, score 15.339) (writing took 1.871478951536119 seconds)
2022-03-05 18:19:59 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-05 18:19:59 | INFO | train | epoch 122 | loss 0.954 | ppl 1.94 | wps 27291.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5937 | lr 0.000410409 | gnorm 1.129 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 14281
2022-03-05 18:19:59 | INFO | fairseq.trainer | begin training epoch 123
2022-03-05 18:19:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:20:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:21:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:21:53 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 15.311 | ppl 40658.4 | wps 48590.5 | wpb 510.9 | bsz 1 | num_updates 5985 | best_loss 8.449
2022-03-05 18:21:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5985 updates
2022-03-05 18:21:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:21:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:21:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 123 @ 5985 updates, score 15.311) (writing took 2.6923577254638076 seconds)
2022-03-05 18:21:56 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-05 18:21:56 | INFO | train | epoch 123 | loss 0.933 | ppl 1.91 | wps 26547.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 5985 | lr 0.00040876 | gnorm 1.121 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 14398
2022-03-05 18:21:56 | INFO | fairseq.trainer | begin training epoch 124
2022-03-05 18:21:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:22:30 | INFO | train_inner | epoch 124:     15 / 49 loss=0.939, ppl=1.92, wps=26977.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=1.133, loss_scale=32, train_wall=204, gb_free=8.8, wall=14432
2022-03-05 18:23:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:23:51 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 15.542 | ppl 47697.1 | wps 48561.5 | wpb 510.9 | bsz 1 | num_updates 6034 | best_loss 8.449
2022-03-05 18:23:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6034 updates
2022-03-05 18:23:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:23:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:23:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 124 @ 6034 updates, score 15.542) (writing took 1.8257289994508028 seconds)
2022-03-05 18:23:53 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-05 18:23:53 | INFO | train | epoch 124 | loss 0.919 | ppl 1.89 | wps 27303.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 6034 | lr 0.000407096 | gnorm 1.153 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 14515
2022-03-05 18:23:53 | INFO | fairseq.trainer | begin training epoch 125
2022-03-05 18:23:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:25:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:25:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:25:47 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 15.636 | ppl 50929.3 | wps 48621.5 | wpb 510.9 | bsz 1 | num_updates 6082 | best_loss 8.449
2022-03-05 18:25:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6082 updates
2022-03-05 18:25:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:25:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:25:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 125 @ 6082 updates, score 15.636) (writing took 1.8549891095608473 seconds)
2022-03-05 18:25:49 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-05 18:25:49 | INFO | train | epoch 125 | loss 0.897 | ppl 1.86 | wps 26743.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 6082 | lr 0.000405487 | gnorm 1.112 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 14631
2022-03-05 18:25:49 | INFO | fairseq.trainer | begin training epoch 126
2022-03-05 18:25:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:26:30 | INFO | train_inner | epoch 126:     18 / 49 loss=0.9, ppl=1.87, wps=27071.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=1.113, loss_scale=32, train_wall=205, gb_free=8.8, wall=14672
2022-03-05 18:27:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:27:44 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 15.799 | ppl 57011.5 | wps 48696.6 | wpb 510.9 | bsz 1 | num_updates 6131 | best_loss 8.449
2022-03-05 18:27:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6131 updates
2022-03-05 18:27:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:27:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:27:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 126 @ 6131 updates, score 15.799) (writing took 1.823935809545219 seconds)
2022-03-05 18:27:45 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-05 18:27:45 | INFO | train | epoch 126 | loss 0.883 | ppl 1.84 | wps 27298.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 6131 | lr 0.000403863 | gnorm 1.111 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 14747
2022-03-05 18:27:45 | INFO | fairseq.trainer | begin training epoch 127
2022-03-05 18:27:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:27:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:29:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:29:40 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 15.761 | ppl 55527.8 | wps 48757.5 | wpb 510.9 | bsz 1 | num_updates 6179 | best_loss 8.449
2022-03-05 18:29:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6179 updates
2022-03-05 18:29:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:29:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:29:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 127 @ 6179 updates, score 15.761) (writing took 1.874938365072012 seconds)
2022-03-05 18:29:42 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-05 18:29:42 | INFO | train | epoch 127 | loss 0.867 | ppl 1.82 | wps 26731.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 6179 | lr 0.000402292 | gnorm 1.101 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 14864
2022-03-05 18:29:42 | INFO | fairseq.trainer | begin training epoch 128
2022-03-05 18:29:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:30:29 | INFO | train_inner | epoch 128:     21 / 49 loss=0.869, ppl=1.83, wps=27074, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=1.113, loss_scale=16, train_wall=204, gb_free=8.8, wall=14912
2022-03-05 18:31:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:31:36 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 15.725 | ppl 54178.7 | wps 48589.7 | wpb 510.9 | bsz 1 | num_updates 6228 | best_loss 8.449
2022-03-05 18:31:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6228 updates
2022-03-05 18:31:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:31:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:31:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 128 @ 6228 updates, score 15.725) (writing took 1.8677158439531922 seconds)
2022-03-05 18:31:38 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-05 18:31:38 | INFO | train | epoch 128 | loss 0.853 | ppl 1.81 | wps 27301.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 6228 | lr 0.000400706 | gnorm 1.111 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 14980
2022-03-05 18:31:38 | INFO | fairseq.trainer | begin training epoch 129
2022-03-05 18:31:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:33:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:33:33 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 15.815 | ppl 57657.4 | wps 48639.5 | wpb 510.9 | bsz 1 | num_updates 6277 | best_loss 8.449
2022-03-05 18:33:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6277 updates
2022-03-05 18:33:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:33:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:33:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 129 @ 6277 updates, score 15.815) (writing took 1.8727924162521958 seconds)
2022-03-05 18:33:35 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-05 18:33:35 | INFO | train | epoch 129 | loss 0.838 | ppl 1.79 | wps 27301.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 6277 | lr 0.000399139 | gnorm 1.111 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 15097
2022-03-05 18:33:35 | INFO | fairseq.trainer | begin training epoch 130
2022-03-05 18:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:34:27 | INFO | train_inner | epoch 130:     23 / 49 loss=0.838, ppl=1.79, wps=27331, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=1.1, loss_scale=32, train_wall=202, gb_free=8.8, wall=15149
2022-03-05 18:35:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:35:29 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 15.896 | ppl 60994.8 | wps 48581.4 | wpb 510.9 | bsz 1 | num_updates 6326 | best_loss 8.449
2022-03-05 18:35:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6326 updates
2022-03-05 18:35:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:35:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:35:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 130 @ 6326 updates, score 15.896) (writing took 1.8088636165484786 seconds)
2022-03-05 18:35:31 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-05 18:35:31 | INFO | train | epoch 130 | loss 0.821 | ppl 1.77 | wps 27318.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 6326 | lr 0.00039759 | gnorm 1.083 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 15213
2022-03-05 18:35:31 | INFO | fairseq.trainer | begin training epoch 131
2022-03-05 18:35:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:37:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:37:26 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 15.944 | ppl 63056 | wps 48679.3 | wpb 510.9 | bsz 1 | num_updates 6375 | best_loss 8.449
2022-03-05 18:37:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6375 updates
2022-03-05 18:37:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:37:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:37:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 131 @ 6375 updates, score 15.944) (writing took 1.8434554431587458 seconds)
2022-03-05 18:37:27 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-05 18:37:27 | INFO | train | epoch 131 | loss 0.806 | ppl 1.75 | wps 27304 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 6375 | lr 0.000396059 | gnorm 1.073 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 15329
2022-03-05 18:37:27 | INFO | fairseq.trainer | begin training epoch 132
2022-03-05 18:37:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:38:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:38:26 | INFO | train_inner | epoch 132:     26 / 49 loss=0.806, ppl=1.75, wps=27086.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=1.075, loss_scale=32, train_wall=204, gb_free=8.8, wall=15388
2022-03-05 18:39:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:39:22 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 16.051 | ppl 67892.1 | wps 48575.6 | wpb 510.9 | bsz 1 | num_updates 6423 | best_loss 8.449
2022-03-05 18:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6423 updates
2022-03-05 18:39:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:39:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:39:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 132 @ 6423 updates, score 16.051) (writing took 1.8287690542638302 seconds)
2022-03-05 18:39:24 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-05 18:39:24 | INFO | train | epoch 132 | loss 0.793 | ppl 1.73 | wps 26745.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 6423 | lr 0.000394576 | gnorm 1.078 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 15446
2022-03-05 18:39:24 | INFO | fairseq.trainer | begin training epoch 133
2022-03-05 18:39:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:41:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:41:18 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 16.207 | ppl 75663.3 | wps 48704.2 | wpb 510.9 | bsz 1 | num_updates 6472 | best_loss 8.449
2022-03-05 18:41:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6472 updates
2022-03-05 18:41:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:41:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:41:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 133 @ 6472 updates, score 16.207) (writing took 1.8459498258307576 seconds)
2022-03-05 18:41:20 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-05 18:41:20 | INFO | train | epoch 133 | loss 0.78 | ppl 1.72 | wps 27311.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 6472 | lr 0.00039308 | gnorm 1.068 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 15562
2022-03-05 18:41:20 | INFO | fairseq.trainer | begin training epoch 134
2022-03-05 18:41:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:42:24 | INFO | train_inner | epoch 134:     28 / 49 loss=0.778, ppl=1.72, wps=27334.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=1.054, loss_scale=32, train_wall=203, gb_free=8.8, wall=15626
2022-03-05 18:43:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:43:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:43:15 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 16.202 | ppl 75361.4 | wps 48688.7 | wpb 510.9 | bsz 1 | num_updates 6520 | best_loss 8.449
2022-03-05 18:43:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6520 updates
2022-03-05 18:43:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:43:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:43:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 134 @ 6520 updates, score 16.202) (writing took 1.8515188293531537 seconds)
2022-03-05 18:43:17 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-05 18:43:17 | INFO | train | epoch 134 | loss 0.762 | ppl 1.7 | wps 26733 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 6520 | lr 0.00039163 | gnorm 1.012 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 15679
2022-03-05 18:43:17 | INFO | fairseq.trainer | begin training epoch 135
2022-03-05 18:43:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:45:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:45:11 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 16.283 | ppl 79744 | wps 48456 | wpb 510.9 | bsz 1 | num_updates 6569 | best_loss 8.449
2022-03-05 18:45:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6569 updates
2022-03-05 18:45:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:45:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:45:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 135 @ 6569 updates, score 16.283) (writing took 1.8618401642888784 seconds)
2022-03-05 18:45:13 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-05 18:45:13 | INFO | train | epoch 135 | loss 0.756 | ppl 1.69 | wps 27295.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 6569 | lr 0.000390167 | gnorm 1.051 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 15795
2022-03-05 18:45:13 | INFO | fairseq.trainer | begin training epoch 136
2022-03-05 18:45:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:46:23 | INFO | train_inner | epoch 136:     31 / 49 loss=0.755, ppl=1.69, wps=27070.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=1.042, loss_scale=32, train_wall=205, gb_free=8.8, wall=15865
2022-03-05 18:47:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:47:07 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 16.335 | ppl 82676.6 | wps 48577.7 | wpb 510.9 | bsz 1 | num_updates 6618 | best_loss 8.449
2022-03-05 18:47:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6618 updates
2022-03-05 18:47:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:47:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:47:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 136 @ 6618 updates, score 16.335) (writing took 1.8161834366619587 seconds)
2022-03-05 18:47:09 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-05 18:47:09 | INFO | train | epoch 136 | loss 0.746 | ppl 1.68 | wps 27319.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 6618 | lr 0.00038872 | gnorm 1.051 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 15911
2022-03-05 18:47:09 | INFO | fairseq.trainer | begin training epoch 137
2022-03-05 18:47:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:48:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:48:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:49:04 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 16.3 | ppl 80682.1 | wps 48676.3 | wpb 510.9 | bsz 1 | num_updates 6666 | best_loss 8.449
2022-03-05 18:49:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6666 updates
2022-03-05 18:49:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:49:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:49:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 137 @ 6666 updates, score 16.3) (writing took 1.857583099976182 seconds)
2022-03-05 18:49:06 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-05 18:49:06 | INFO | train | epoch 137 | loss 0.733 | ppl 1.66 | wps 26748.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 6666 | lr 0.000387318 | gnorm 1.069 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 16028
2022-03-05 18:49:06 | INFO | fairseq.trainer | begin training epoch 138
2022-03-05 18:49:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:50:23 | INFO | train_inner | epoch 138:     34 / 49 loss=0.729, ppl=1.66, wps=27090.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=1.045, loss_scale=32, train_wall=204, gb_free=8.8, wall=16105
2022-03-05 18:50:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:51:00 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 16.519 | ppl 93892.8 | wps 48599.1 | wpb 510.9 | bsz 1 | num_updates 6715 | best_loss 8.449
2022-03-05 18:51:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6715 updates
2022-03-05 18:51:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:51:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:51:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 138 @ 6715 updates, score 16.519) (writing took 1.9067153530195355 seconds)
2022-03-05 18:51:02 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-05 18:51:02 | INFO | train | epoch 138 | loss 0.715 | ppl 1.64 | wps 27293.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 6715 | lr 0.000385902 | gnorm 1.006 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 16144
2022-03-05 18:51:02 | INFO | fairseq.trainer | begin training epoch 139
2022-03-05 18:51:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:52:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:52:57 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 16.672 | ppl 104407 | wps 48559.3 | wpb 510.9 | bsz 1 | num_updates 6764 | best_loss 8.449
2022-03-05 18:52:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6764 updates
2022-03-05 18:52:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:52:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:52:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 139 @ 6764 updates, score 16.672) (writing took 1.8656087210401893 seconds)
2022-03-05 18:52:59 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-05 18:52:59 | INFO | train | epoch 139 | loss 0.709 | ppl 1.63 | wps 27286.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 6764 | lr 0.000384502 | gnorm 1.017 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 16261
2022-03-05 18:52:59 | INFO | fairseq.trainer | begin training epoch 140
2022-03-05 18:52:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:53:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:54:22 | INFO | train_inner | epoch 140:     37 / 49 loss=0.706, ppl=1.63, wps=27064.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=1.018, loss_scale=32, train_wall=204, gb_free=8.8, wall=16344
2022-03-05 18:54:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:54:53 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 16.551 | ppl 95992.6 | wps 48053.1 | wpb 510.9 | bsz 1 | num_updates 6812 | best_loss 8.449
2022-03-05 18:54:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6812 updates
2022-03-05 18:54:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:54:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:54:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 140 @ 6812 updates, score 16.551) (writing took 1.917535831220448 seconds)
2022-03-05 18:54:55 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-05 18:54:55 | INFO | train | epoch 140 | loss 0.697 | ppl 1.62 | wps 26718.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 6812 | lr 0.000383145 | gnorm 1.017 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 16377
2022-03-05 18:54:55 | INFO | fairseq.trainer | begin training epoch 141
2022-03-05 18:54:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:56:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:56:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:56:50 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 16.523 | ppl 94197.1 | wps 48270.4 | wpb 510.9 | bsz 1 | num_updates 6860 | best_loss 8.449
2022-03-05 18:56:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6860 updates
2022-03-05 18:56:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:56:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:56:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 141 @ 6860 updates, score 16.523) (writing took 1.898736129514873 seconds)
2022-03-05 18:56:51 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-05 18:56:51 | INFO | train | epoch 141 | loss 0.685 | ppl 1.61 | wps 26737.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 6860 | lr 0.000381802 | gnorm 1 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 16493
2022-03-05 18:56:51 | INFO | fairseq.trainer | begin training epoch 142
2022-03-05 18:56:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:58:22 | INFO | train_inner | epoch 142:     40 / 49 loss=0.683, ppl=1.61, wps=27059.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=1.005, loss_scale=16, train_wall=204, gb_free=8.8, wall=16584
2022-03-05 18:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:58:46 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 16.504 | ppl 92960.5 | wps 48695.5 | wpb 510.9 | bsz 1 | num_updates 6909 | best_loss 8.449
2022-03-05 18:58:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6909 updates
2022-03-05 18:58:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 18:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 142 @ 6909 updates, score 16.504) (writing took 1.825031602755189 seconds)
2022-03-05 18:58:48 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-05 18:58:48 | INFO | train | epoch 142 | loss 0.678 | ppl 1.6 | wps 27309.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 6909 | lr 0.000380445 | gnorm 1.007 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 16610
2022-03-05 18:58:48 | INFO | fairseq.trainer | begin training epoch 143
2022-03-05 18:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:00:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:00:42 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 16.639 | ppl 102081 | wps 48629.5 | wpb 510.9 | bsz 1 | num_updates 6958 | best_loss 8.449
2022-03-05 19:00:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6958 updates
2022-03-05 19:00:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:00:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:00:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 143 @ 6958 updates, score 16.639) (writing took 1.8761991197243333 seconds)
2022-03-05 19:00:44 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-05 19:00:44 | INFO | train | epoch 143 | loss 0.667 | ppl 1.59 | wps 27307.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 6958 | lr 0.000379103 | gnorm 0.987 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 16726
2022-03-05 19:00:44 | INFO | fairseq.trainer | begin training epoch 144
2022-03-05 19:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:02:20 | INFO | train_inner | epoch 144:     42 / 49 loss=0.666, ppl=1.59, wps=27331.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=1.002, loss_scale=32, train_wall=202, gb_free=8.8, wall=16822
2022-03-05 19:02:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:02:39 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 16.63 | ppl 101425 | wps 48577.7 | wpb 510.9 | bsz 1 | num_updates 7007 | best_loss 8.449
2022-03-05 19:02:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7007 updates
2022-03-05 19:02:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:02:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:02:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 144 @ 7007 updates, score 16.63) (writing took 1.8626006934791803 seconds)
2022-03-05 19:02:41 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-05 19:02:41 | INFO | train | epoch 144 | loss 0.66 | ppl 1.58 | wps 27282.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 7007 | lr 0.000377776 | gnorm 1.009 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 16843
2022-03-05 19:02:41 | INFO | fairseq.trainer | begin training epoch 145
2022-03-05 19:02:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:04:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:04:35 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 16.767 | ppl 111545 | wps 48711.9 | wpb 510.9 | bsz 1 | num_updates 7056 | best_loss 8.449
2022-03-05 19:04:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7056 updates
2022-03-05 19:04:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:04:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:04:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 145 @ 7056 updates, score 16.767) (writing took 1.84430680423975 seconds)
2022-03-05 19:04:37 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-05 19:04:37 | INFO | train | epoch 145 | loss 0.646 | ppl 1.57 | wps 27317.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 7056 | lr 0.000376462 | gnorm 0.979 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 16959
2022-03-05 19:04:37 | INFO | fairseq.trainer | begin training epoch 146
2022-03-05 19:04:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:06:17 | INFO | train_inner | epoch 146:     44 / 49 loss=0.643, ppl=1.56, wps=27338.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.981, loss_scale=32, train_wall=202, gb_free=8.8, wall=17059
2022-03-05 19:06:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:06:32 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 16.769 | ppl 111710 | wps 48563.8 | wpb 510.9 | bsz 1 | num_updates 7105 | best_loss 8.449
2022-03-05 19:06:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7105 updates
2022-03-05 19:06:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:06:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:06:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 146 @ 7105 updates, score 16.769) (writing took 1.9035259382799268 seconds)
2022-03-05 19:06:34 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-05 19:06:34 | INFO | train | epoch 146 | loss 0.638 | ppl 1.56 | wps 27288 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 7105 | lr 0.000375161 | gnorm 0.99 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 17076
2022-03-05 19:06:34 | INFO | fairseq.trainer | begin training epoch 147
2022-03-05 19:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:06:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:08:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:08:28 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 16.893 | ppl 121741 | wps 48587.5 | wpb 510.9 | bsz 1 | num_updates 7153 | best_loss 8.449
2022-03-05 19:08:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7153 updates
2022-03-05 19:08:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:08:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:08:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 147 @ 7153 updates, score 16.893) (writing took 1.9235347090288997 seconds)
2022-03-05 19:08:30 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-05 19:08:30 | INFO | train | epoch 147 | loss 0.629 | ppl 1.55 | wps 26719 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 7153 | lr 0.0003739 | gnorm 0.963 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 17192
2022-03-05 19:08:30 | INFO | fairseq.trainer | begin training epoch 148
2022-03-05 19:08:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:10:17 | INFO | train_inner | epoch 148:     47 / 49 loss=0.627, ppl=1.54, wps=27060.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7200, lr=0.000372678, gnorm=0.974, loss_scale=32, train_wall=204, gb_free=8.8, wall=17299
2022-03-05 19:10:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:10:25 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 16.802 | ppl 114279 | wps 48721.3 | wpb 510.9 | bsz 1 | num_updates 7202 | best_loss 8.449
2022-03-05 19:10:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7202 updates
2022-03-05 19:10:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:10:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:10:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 148 @ 7202 updates, score 16.802) (writing took 1.9333248101174831 seconds)
2022-03-05 19:10:26 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-05 19:10:26 | INFO | train | epoch 148 | loss 0.622 | ppl 1.54 | wps 27291.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 7202 | lr 0.000372626 | gnorm 0.98 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 17308
2022-03-05 19:10:26 | INFO | fairseq.trainer | begin training epoch 149
2022-03-05 19:10:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:11:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:12:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:12:21 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 16.965 | ppl 127892 | wps 48574.7 | wpb 510.9 | bsz 1 | num_updates 7250 | best_loss 8.449
2022-03-05 19:12:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7250 updates
2022-03-05 19:12:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:12:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:12:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 149 @ 7250 updates, score 16.965) (writing took 1.8582275761291385 seconds)
2022-03-05 19:12:23 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-05 19:12:23 | INFO | train | epoch 149 | loss 0.612 | ppl 1.53 | wps 26744.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 7250 | lr 0.000371391 | gnorm 0.953 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 17425
2022-03-05 19:12:23 | INFO | fairseq.trainer | begin training epoch 150
2022-03-05 19:12:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:14:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:14:17 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 16.907 | ppl 122926 | wps 48644.2 | wpb 510.9 | bsz 1 | num_updates 7299 | best_loss 8.449
2022-03-05 19:14:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7299 updates
2022-03-05 19:14:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:14:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:14:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 150 @ 7299 updates, score 16.907) (writing took 1.9107033908367157 seconds)
2022-03-05 19:14:19 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-05 19:14:19 | INFO | train | epoch 150 | loss 0.606 | ppl 1.52 | wps 27291.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 7299 | lr 0.000370142 | gnorm 0.968 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 17541
2022-03-05 19:14:19 | INFO | fairseq.trainer | begin training epoch 151
2022-03-05 19:14:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:14:22 | INFO | train_inner | epoch 151:      1 / 49 loss=0.61, ppl=1.53, wps=26336.4, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=7300, lr=0.000370117, gnorm=0.965, loss_scale=32, train_wall=204, gb_free=8.8, wall=17544
2022-03-05 19:16:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:16:14 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 17.1 | ppl 140465 | wps 48624 | wpb 510.9 | bsz 1 | num_updates 7348 | best_loss 8.449
2022-03-05 19:16:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7348 updates
2022-03-05 19:16:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:16:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:16:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 151 @ 7348 updates, score 17.1) (writing took 1.8680328540503979 seconds)
2022-03-05 19:16:16 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-05 19:16:16 | INFO | train | epoch 151 | loss 0.596 | ppl 1.51 | wps 27293.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 7348 | lr 0.000368906 | gnorm 0.949 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 17658
2022-03-05 19:16:16 | INFO | fairseq.trainer | begin training epoch 152
2022-03-05 19:16:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:17:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:18:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:18:10 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 17.025 | ppl 133390 | wps 48480.8 | wpb 510.9 | bsz 1 | num_updates 7396 | best_loss 8.449
2022-03-05 19:18:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7396 updates
2022-03-05 19:18:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:18:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:18:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 152 @ 7396 updates, score 17.025) (writing took 1.8459652438759804 seconds)
2022-03-05 19:18:12 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-05 19:18:12 | INFO | train | epoch 152 | loss 0.588 | ppl 1.5 | wps 26733.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 7396 | lr 0.000367707 | gnorm 0.947 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 17774
2022-03-05 19:18:12 | INFO | fairseq.trainer | begin training epoch 153
2022-03-05 19:18:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:18:21 | INFO | train_inner | epoch 153:      4 / 49 loss=0.591, ppl=1.51, wps=27067.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7400, lr=0.000367607, gnorm=0.944, loss_scale=32, train_wall=205, gb_free=8.8, wall=17783
2022-03-05 19:20:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:20:07 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 17.256 | ppl 156494 | wps 48592.5 | wpb 510.9 | bsz 1 | num_updates 7445 | best_loss 8.449
2022-03-05 19:20:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7445 updates
2022-03-05 19:20:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:20:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:20:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 153 @ 7445 updates, score 17.256) (writing took 1.8699346454814076 seconds)
2022-03-05 19:20:09 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-05 19:20:09 | INFO | train | epoch 153 | loss 0.581 | ppl 1.5 | wps 27306.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 7445 | lr 0.000366495 | gnorm 0.93 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 17891
2022-03-05 19:20:09 | INFO | fairseq.trainer | begin training epoch 154
2022-03-05 19:20:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:21:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:22:03 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 17.286 | ppl 159835 | wps 48618.4 | wpb 510.9 | bsz 1 | num_updates 7494 | best_loss 8.449
2022-03-05 19:22:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7494 updates
2022-03-05 19:22:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:22:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:22:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 154 @ 7494 updates, score 17.286) (writing took 1.8667950769886374 seconds)
2022-03-05 19:22:05 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-05 19:22:05 | INFO | train | epoch 154 | loss 0.577 | ppl 1.49 | wps 27279.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 7494 | lr 0.000365295 | gnorm 0.95 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 18007
2022-03-05 19:22:05 | INFO | fairseq.trainer | begin training epoch 155
2022-03-05 19:22:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:22:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:22:21 | INFO | train_inner | epoch 155:      7 / 49 loss=0.578, ppl=1.49, wps=27067.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.943, loss_scale=32, train_wall=205, gb_free=8.8, wall=18023
2022-03-05 19:23:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:24:00 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 17.327 | ppl 164401 | wps 48645 | wpb 510.9 | bsz 1 | num_updates 7542 | best_loss 8.449
2022-03-05 19:24:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7542 updates
2022-03-05 19:24:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:24:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:24:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 155 @ 7542 updates, score 17.327) (writing took 1.8918641479685903 seconds)
2022-03-05 19:24:01 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-05 19:24:01 | INFO | train | epoch 155 | loss 0.568 | ppl 1.48 | wps 26742.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 7542 | lr 0.00036413 | gnorm 0.942 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 18123
2022-03-05 19:24:01 | INFO | fairseq.trainer | begin training epoch 156
2022-03-05 19:24:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:25:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:25:56 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 17.311 | ppl 162605 | wps 48793.6 | wpb 510.9 | bsz 1 | num_updates 7591 | best_loss 8.449
2022-03-05 19:25:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7591 updates
2022-03-05 19:25:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:25:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:25:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 156 @ 7591 updates, score 17.311) (writing took 1.8146900413557887 seconds)
2022-03-05 19:25:58 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-05 19:25:58 | INFO | train | epoch 156 | loss 0.56 | ppl 1.47 | wps 27309.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 7591 | lr 0.000362953 | gnorm 0.93 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 18240
2022-03-05 19:25:58 | INFO | fairseq.trainer | begin training epoch 157
2022-03-05 19:25:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:26:18 | INFO | train_inner | epoch 157:      9 / 49 loss=0.562, ppl=1.48, wps=27338.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.933, loss_scale=32, train_wall=202, gb_free=8.8, wall=18260
2022-03-05 19:27:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:27:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:27:52 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 17.302 | ppl 161590 | wps 48596 | wpb 510.9 | bsz 1 | num_updates 7639 | best_loss 8.449
2022-03-05 19:27:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7639 updates
2022-03-05 19:27:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:27:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:27:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 157 @ 7639 updates, score 17.302) (writing took 1.8809251012280583 seconds)
2022-03-05 19:27:54 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-05 19:27:54 | INFO | train | epoch 157 | loss 0.553 | ppl 1.47 | wps 26730 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 7639 | lr 0.000361811 | gnorm 0.925 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 18356
2022-03-05 19:27:54 | INFO | fairseq.trainer | begin training epoch 158
2022-03-05 19:27:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:29:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:29:49 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 17.469 | ppl 181462 | wps 48691.3 | wpb 510.9 | bsz 1 | num_updates 7688 | best_loss 8.449
2022-03-05 19:29:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7688 updates
2022-03-05 19:29:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:29:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:29:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 158 @ 7688 updates, score 17.469) (writing took 1.8699977342039347 seconds)
2022-03-05 19:29:51 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-05 19:29:51 | INFO | train | epoch 158 | loss 0.546 | ppl 1.46 | wps 27288.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 7688 | lr 0.000360656 | gnorm 0.909 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 18473
2022-03-05 19:29:51 | INFO | fairseq.trainer | begin training epoch 159
2022-03-05 19:29:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:30:18 | INFO | train_inner | epoch 159:     12 / 49 loss=0.548, ppl=1.46, wps=27060.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.916, loss_scale=32, train_wall=205, gb_free=8.8, wall=18500
2022-03-05 19:31:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:31:45 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 17.382 | ppl 170779 | wps 48639.2 | wpb 510.9 | bsz 1 | num_updates 7737 | best_loss 8.449
2022-03-05 19:31:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7737 updates
2022-03-05 19:31:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:31:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:31:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 159 @ 7737 updates, score 17.382) (writing took 1.8610994778573513 seconds)
2022-03-05 19:31:47 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-05 19:31:47 | INFO | train | epoch 159 | loss 0.542 | ppl 1.46 | wps 27302.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 7737 | lr 0.000359512 | gnorm 0.929 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 18589
2022-03-05 19:31:47 | INFO | fairseq.trainer | begin training epoch 160
2022-03-05 19:31:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:32:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:33:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:33:42 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 17.338 | ppl 165636 | wps 48585.4 | wpb 510.9 | bsz 1 | num_updates 7785 | best_loss 8.449
2022-03-05 19:33:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7785 updates
2022-03-05 19:33:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:33:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:33:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 160 @ 7785 updates, score 17.338) (writing took 1.8593101492151618 seconds)
2022-03-05 19:33:43 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-05 19:33:43 | INFO | train | epoch 160 | loss 0.532 | ppl 1.45 | wps 26737.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 7785 | lr 0.000358402 | gnorm 0.897 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 18706
2022-03-05 19:33:44 | INFO | fairseq.trainer | begin training epoch 161
2022-03-05 19:33:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:34:18 | INFO | train_inner | epoch 161:     15 / 49 loss=0.535, ppl=1.45, wps=27076.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.907, loss_scale=32, train_wall=204, gb_free=8.8, wall=18740
2022-03-05 19:35:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:35:38 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 17.442 | ppl 178009 | wps 48623.5 | wpb 510.9 | bsz 1 | num_updates 7834 | best_loss 8.449
2022-03-05 19:35:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7834 updates
2022-03-05 19:35:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:35:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:35:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 161 @ 7834 updates, score 17.442) (writing took 1.860548666678369 seconds)
2022-03-05 19:35:40 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-05 19:35:40 | INFO | train | epoch 161 | loss 0.527 | ppl 1.44 | wps 27300.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 7834 | lr 0.00035728 | gnorm 0.892 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 18822
2022-03-05 19:35:40 | INFO | fairseq.trainer | begin training epoch 162
2022-03-05 19:35:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:37:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:37:34 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 17.37 | ppl 169444 | wps 48685.2 | wpb 510.9 | bsz 1 | num_updates 7883 | best_loss 8.449
2022-03-05 19:37:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7883 updates
2022-03-05 19:37:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:37:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:37:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 162 @ 7883 updates, score 17.37) (writing took 1.8434211388230324 seconds)
2022-03-05 19:37:36 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-05 19:37:36 | INFO | train | epoch 162 | loss 0.523 | ppl 1.44 | wps 27315.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 7883 | lr 0.000356167 | gnorm 0.903 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 18938
2022-03-05 19:37:36 | INFO | fairseq.trainer | begin training epoch 163
2022-03-05 19:37:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:37:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:38:17 | INFO | train_inner | epoch 163:     18 / 49 loss=0.524, ppl=1.44, wps=27081.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.904, loss_scale=32, train_wall=204, gb_free=8.8, wall=18979
2022-03-05 19:39:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:39:31 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 17.565 | ppl 193925 | wps 48090 | wpb 510.9 | bsz 1 | num_updates 7931 | best_loss 8.449
2022-03-05 19:39:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7931 updates
2022-03-05 19:39:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:39:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:39:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 163 @ 7931 updates, score 17.565) (writing took 1.8669793829321861 seconds)
2022-03-05 19:39:33 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-05 19:39:33 | INFO | train | epoch 163 | loss 0.516 | ppl 1.43 | wps 26722.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 7931 | lr 0.000355088 | gnorm 0.897 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 19055
2022-03-05 19:39:33 | INFO | fairseq.trainer | begin training epoch 164
2022-03-05 19:39:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:41:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:41:27 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 17.561 | ppl 193308 | wps 48584.7 | wpb 510.9 | bsz 1 | num_updates 7980 | best_loss 8.449
2022-03-05 19:41:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7980 updates
2022-03-05 19:41:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:41:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:41:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 164 @ 7980 updates, score 17.561) (writing took 1.8627389539033175 seconds)
2022-03-05 19:41:29 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-05 19:41:29 | INFO | train | epoch 164 | loss 0.509 | ppl 1.42 | wps 27306.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 7980 | lr 0.000353996 | gnorm 0.875 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 19171
2022-03-05 19:41:29 | INFO | fairseq.trainer | begin training epoch 165
2022-03-05 19:41:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:42:15 | INFO | train_inner | epoch 165:     20 / 49 loss=0.509, ppl=1.42, wps=27326.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.881, loss_scale=32, train_wall=202, gb_free=8.8, wall=19217
2022-03-05 19:42:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:43:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:43:24 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 17.612 | ppl 200347 | wps 48712.6 | wpb 510.9 | bsz 1 | num_updates 8028 | best_loss 8.449
2022-03-05 19:43:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8028 updates
2022-03-05 19:43:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:43:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:43:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 165 @ 8028 updates, score 17.612) (writing took 1.8893245737999678 seconds)
2022-03-05 19:43:26 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-05 19:43:26 | INFO | train | epoch 165 | loss 0.506 | ppl 1.42 | wps 26735.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 8028 | lr 0.000352936 | gnorm 0.891 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 19288
2022-03-05 19:43:26 | INFO | fairseq.trainer | begin training epoch 166
2022-03-05 19:43:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:45:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:45:20 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 17.651 | ppl 205826 | wps 48767.5 | wpb 510.9 | bsz 1 | num_updates 8077 | best_loss 8.449
2022-03-05 19:45:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8077 updates
2022-03-05 19:45:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:45:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:45:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 166 @ 8077 updates, score 17.651) (writing took 1.8610171843320131 seconds)
2022-03-05 19:45:22 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-05 19:45:22 | INFO | train | epoch 166 | loss 0.5 | ppl 1.41 | wps 27311.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8077 | lr 0.000351864 | gnorm 0.887 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 19404
2022-03-05 19:45:22 | INFO | fairseq.trainer | begin training epoch 167
2022-03-05 19:45:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:46:14 | INFO | train_inner | epoch 167:     23 / 49 loss=0.5, ppl=1.41, wps=27068.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.881, loss_scale=32, train_wall=204, gb_free=8.8, wall=19456
2022-03-05 19:47:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:47:17 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 17.826 | ppl 232303 | wps 48641.4 | wpb 510.9 | bsz 1 | num_updates 8126 | best_loss 8.449
2022-03-05 19:47:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8126 updates
2022-03-05 19:47:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:47:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:47:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 167 @ 8126 updates, score 17.826) (writing took 1.9262994611635804 seconds)
2022-03-05 19:47:18 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-05 19:47:18 | INFO | train | epoch 167 | loss 0.494 | ppl 1.41 | wps 27269.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8126 | lr 0.000350802 | gnorm 0.869 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 19520
2022-03-05 19:47:18 | INFO | fairseq.trainer | begin training epoch 168
2022-03-05 19:47:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:47:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:49:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:49:13 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 17.774 | ppl 224157 | wps 48115.8 | wpb 510.9 | bsz 1 | num_updates 8174 | best_loss 8.449
2022-03-05 19:49:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8174 updates
2022-03-05 19:49:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:49:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:49:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 168 @ 8174 updates, score 17.774) (writing took 1.8485984653234482 seconds)
2022-03-05 19:49:15 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-05 19:49:15 | INFO | train | epoch 168 | loss 0.491 | ppl 1.41 | wps 26738.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 8174 | lr 0.00034977 | gnorm 0.892 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 19637
2022-03-05 19:49:15 | INFO | fairseq.trainer | begin training epoch 169
2022-03-05 19:49:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:50:14 | INFO | train_inner | epoch 169:     26 / 49 loss=0.491, ppl=1.4, wps=27065.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.883, loss_scale=32, train_wall=204, gb_free=8.8, wall=19696
2022-03-05 19:51:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:51:09 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 17.738 | ppl 218540 | wps 48498.2 | wpb 510.9 | bsz 1 | num_updates 8223 | best_loss 8.449
2022-03-05 19:51:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8223 updates
2022-03-05 19:51:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:51:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:51:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 169 @ 8223 updates, score 17.738) (writing took 1.8968851454555988 seconds)
2022-03-05 19:51:11 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-05 19:51:11 | INFO | train | epoch 169 | loss 0.484 | ppl 1.4 | wps 27290.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8223 | lr 0.000348726 | gnorm 0.871 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 19753
2022-03-05 19:51:11 | INFO | fairseq.trainer | begin training epoch 170
2022-03-05 19:51:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:52:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:53:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:53:06 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 17.92 | ppl 248004 | wps 48656.2 | wpb 510.9 | bsz 1 | num_updates 8271 | best_loss 8.449
2022-03-05 19:53:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8271 updates
2022-03-05 19:53:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:53:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:53:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 170 @ 8271 updates, score 17.92) (writing took 1.8679484920576215 seconds)
2022-03-05 19:53:08 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-05 19:53:08 | INFO | train | epoch 170 | loss 0.479 | ppl 1.39 | wps 26723.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 8271 | lr 0.000347713 | gnorm 0.874 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 19870
2022-03-05 19:53:08 | INFO | fairseq.trainer | begin training epoch 171
2022-03-05 19:53:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:54:14 | INFO | train_inner | epoch 171:     29 / 49 loss=0.478, ppl=1.39, wps=27055.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.864, loss_scale=32, train_wall=205, gb_free=8.8, wall=19936
2022-03-05 19:54:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:55:02 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 17.858 | ppl 237511 | wps 48744.6 | wpb 510.9 | bsz 1 | num_updates 8320 | best_loss 8.449
2022-03-05 19:55:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8320 updates
2022-03-05 19:55:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:55:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:55:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 171 @ 8320 updates, score 17.858) (writing took 1.8480277555063367 seconds)
2022-03-05 19:55:04 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-05 19:55:04 | INFO | train | epoch 171 | loss 0.472 | ppl 1.39 | wps 27294.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8320 | lr 0.000346688 | gnorm 0.85 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 19986
2022-03-05 19:55:04 | INFO | fairseq.trainer | begin training epoch 172
2022-03-05 19:55:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:56:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:56:59 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 17.89 | ppl 242880 | wps 48669.3 | wpb 510.9 | bsz 1 | num_updates 8369 | best_loss 8.449
2022-03-05 19:56:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8369 updates
2022-03-05 19:56:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:57:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:57:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 172 @ 8369 updates, score 17.89) (writing took 1.8319342890754342 seconds)
2022-03-05 19:57:01 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-05 19:57:01 | INFO | train | epoch 172 | loss 0.469 | ppl 1.38 | wps 27302.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8369 | lr 0.000345671 | gnorm 0.873 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 20103
2022-03-05 19:57:01 | INFO | fairseq.trainer | begin training epoch 173
2022-03-05 19:57:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:58:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:58:13 | INFO | train_inner | epoch 173:     32 / 49 loss=0.468, ppl=1.38, wps=27076.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.862, loss_scale=32, train_wall=205, gb_free=8.8, wall=20175
2022-03-05 19:58:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:58:55 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 17.872 | ppl 239953 | wps 48767.2 | wpb 510.9 | bsz 1 | num_updates 8417 | best_loss 8.449
2022-03-05 19:58:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8417 updates
2022-03-05 19:58:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:58:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 19:58:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 173 @ 8417 updates, score 17.872) (writing took 1.866057600826025 seconds)
2022-03-05 19:58:57 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-05 19:58:57 | INFO | train | epoch 173 | loss 0.464 | ppl 1.38 | wps 26733.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 8417 | lr 0.000344684 | gnorm 0.857 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 20219
2022-03-05 19:58:57 | INFO | fairseq.trainer | begin training epoch 174
2022-03-05 19:58:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:00:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:00:52 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 17.896 | ppl 243986 | wps 48629.4 | wpb 510.9 | bsz 1 | num_updates 8466 | best_loss 8.449
2022-03-05 20:00:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8466 updates
2022-03-05 20:00:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:00:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:00:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 174 @ 8466 updates, score 17.896) (writing took 1.8366978587582707 seconds)
2022-03-05 20:00:53 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-05 20:00:53 | INFO | train | epoch 174 | loss 0.459 | ppl 1.37 | wps 27314.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8466 | lr 0.000343685 | gnorm 0.848 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 20335
2022-03-05 20:00:53 | INFO | fairseq.trainer | begin training epoch 175
2022-03-05 20:00:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:02:11 | INFO | train_inner | epoch 175:     34 / 49 loss=0.458, ppl=1.37, wps=27328, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.845, loss_scale=32, train_wall=202, gb_free=8.8, wall=20413
2022-03-05 20:02:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:02:48 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 18.024 | ppl 266608 | wps 48616.5 | wpb 510.9 | bsz 1 | num_updates 8515 | best_loss 8.449
2022-03-05 20:02:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8515 updates
2022-03-05 20:02:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:02:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:02:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 175 @ 8515 updates, score 18.024) (writing took 1.8915351191535592 seconds)
2022-03-05 20:02:50 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-05 20:02:50 | INFO | train | epoch 175 | loss 0.453 | ppl 1.37 | wps 27283.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8515 | lr 0.000342695 | gnorm 0.831 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 20452
2022-03-05 20:02:50 | INFO | fairseq.trainer | begin training epoch 176
2022-03-05 20:02:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:03:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:04:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:04:44 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 17.906 | ppl 245585 | wps 48498.9 | wpb 510.9 | bsz 1 | num_updates 8563 | best_loss 8.449
2022-03-05 20:04:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8563 updates
2022-03-05 20:04:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:04:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:04:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 176 @ 8563 updates, score 17.906) (writing took 1.8858979120850563 seconds)
2022-03-05 20:04:46 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-05 20:04:46 | INFO | train | epoch 176 | loss 0.452 | ppl 1.37 | wps 26734.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 8563 | lr 0.000341733 | gnorm 0.858 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 20568
2022-03-05 20:04:46 | INFO | fairseq.trainer | begin training epoch 177
2022-03-05 20:04:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:06:10 | INFO | train_inner | epoch 177:     37 / 49 loss=0.451, ppl=1.37, wps=27058.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.849, loss_scale=32, train_wall=205, gb_free=8.8, wall=20652
2022-03-05 20:06:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:06:41 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 18.124 | ppl 285660 | wps 48644.5 | wpb 510.9 | bsz 1 | num_updates 8612 | best_loss 8.449
2022-03-05 20:06:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8612 updates
2022-03-05 20:06:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:06:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:06:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 177 @ 8612 updates, score 18.124) (writing took 1.8583342004567385 seconds)
2022-03-05 20:06:43 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-05 20:06:43 | INFO | train | epoch 177 | loss 0.446 | ppl 1.36 | wps 27272.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8612 | lr 0.00034076 | gnorm 0.835 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 20685
2022-03-05 20:06:43 | INFO | fairseq.trainer | begin training epoch 178
2022-03-05 20:06:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:08:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:08:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:08:37 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 18.129 | ppl 286691 | wps 48727.2 | wpb 510.9 | bsz 1 | num_updates 8660 | best_loss 8.449
2022-03-05 20:08:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8660 updates
2022-03-05 20:08:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:08:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:08:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 178 @ 8660 updates, score 18.129) (writing took 1.8808847330510616 seconds)
2022-03-05 20:08:39 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-05 20:08:39 | INFO | train | epoch 178 | loss 0.44 | ppl 1.36 | wps 26724.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 8660 | lr 0.000339814 | gnorm 0.829 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 20801
2022-03-05 20:08:39 | INFO | fairseq.trainer | begin training epoch 179
2022-03-05 20:08:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:10:10 | INFO | train_inner | epoch 179:     40 / 49 loss=0.439, ppl=1.36, wps=27060.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.827, loss_scale=32, train_wall=205, gb_free=8.8, wall=20892
2022-03-05 20:10:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:10:34 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 18.144 | ppl 289659 | wps 48476 | wpb 510.9 | bsz 1 | num_updates 8709 | best_loss 8.449
2022-03-05 20:10:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8709 updates
2022-03-05 20:10:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:10:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:10:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 179 @ 8709 updates, score 18.144) (writing took 2.3278411366045475 seconds)
2022-03-05 20:10:36 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-05 20:10:36 | INFO | train | epoch 179 | loss 0.437 | ppl 1.35 | wps 27178.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8709 | lr 0.000338857 | gnorm 0.829 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 20918
2022-03-05 20:10:36 | INFO | fairseq.trainer | begin training epoch 180
2022-03-05 20:10:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:12:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:12:31 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 18.261 | ppl 314045 | wps 48600.4 | wpb 510.9 | bsz 1 | num_updates 8758 | best_loss 8.449
2022-03-05 20:12:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8758 updates
2022-03-05 20:12:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:12:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:12:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 180 @ 8758 updates, score 18.261) (writing took 1.8053486170247197 seconds)
2022-03-05 20:12:33 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-05 20:12:33 | INFO | train | epoch 180 | loss 0.434 | ppl 1.35 | wps 27301.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8758 | lr 0.000337907 | gnorm 0.826 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 21035
2022-03-05 20:12:33 | INFO | fairseq.trainer | begin training epoch 181
2022-03-05 20:12:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:13:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:14:10 | INFO | train_inner | epoch 181:     43 / 49 loss=0.433, ppl=1.35, wps=27022.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.829, loss_scale=32, train_wall=204, gb_free=8.8, wall=21132
2022-03-05 20:14:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:14:27 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 18.28 | ppl 318220 | wps 48548.8 | wpb 510.9 | bsz 1 | num_updates 8806 | best_loss 8.449
2022-03-05 20:14:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8806 updates
2022-03-05 20:14:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:14:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:14:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 181 @ 8806 updates, score 18.28) (writing took 1.8518761424347758 seconds)
2022-03-05 20:14:29 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-05 20:14:29 | INFO | train | epoch 181 | loss 0.43 | ppl 1.35 | wps 26748.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 8806 | lr 0.000336985 | gnorm 0.83 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 21151
2022-03-05 20:14:29 | INFO | fairseq.trainer | begin training epoch 182
2022-03-05 20:14:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:16:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:16:24 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 18.322 | ppl 327639 | wps 48661.5 | wpb 510.9 | bsz 1 | num_updates 8855 | best_loss 8.449
2022-03-05 20:16:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8855 updates
2022-03-05 20:16:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:16:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:16:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 182 @ 8855 updates, score 18.322) (writing took 1.8328209100291133 seconds)
2022-03-05 20:16:25 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-05 20:16:25 | INFO | train | epoch 182 | loss 0.426 | ppl 1.34 | wps 27308.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8855 | lr 0.000336051 | gnorm 0.824 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 21267
2022-03-05 20:16:25 | INFO | fairseq.trainer | begin training epoch 183
2022-03-05 20:16:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:18:08 | INFO | train_inner | epoch 183:     45 / 49 loss=0.424, ppl=1.34, wps=27328.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.811, loss_scale=32, train_wall=203, gb_free=8.8, wall=21370
2022-03-05 20:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:18:20 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 18.211 | ppl 303337 | wps 48505.9 | wpb 510.9 | bsz 1 | num_updates 8904 | best_loss 8.449
2022-03-05 20:18:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8904 updates
2022-03-05 20:18:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:18:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:18:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 183 @ 8904 updates, score 18.211) (writing took 1.85272928327322 seconds)
2022-03-05 20:18:22 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-05 20:18:22 | INFO | train | epoch 183 | loss 0.42 | ppl 1.34 | wps 27282.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8904 | lr 0.000335125 | gnorm 0.798 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 21384
2022-03-05 20:18:22 | INFO | fairseq.trainer | begin training epoch 184
2022-03-05 20:18:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:18:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:20:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:20:16 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 18.27 | ppl 316127 | wps 48580.8 | wpb 510.9 | bsz 1 | num_updates 8952 | best_loss 8.449
2022-03-05 20:20:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8952 updates
2022-03-05 20:20:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:20:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:20:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 184 @ 8952 updates, score 18.27) (writing took 1.8838954763486981 seconds)
2022-03-05 20:20:18 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-05 20:20:18 | INFO | train | epoch 184 | loss 0.418 | ppl 1.34 | wps 26731.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 8952 | lr 0.000334226 | gnorm 0.803 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 21500
2022-03-05 20:20:18 | INFO | fairseq.trainer | begin training epoch 185
2022-03-05 20:20:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:22:07 | INFO | train_inner | epoch 185:     48 / 49 loss=0.418, ppl=1.34, wps=27056.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.807, loss_scale=32, train_wall=205, gb_free=8.8, wall=21609
2022-03-05 20:22:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:22:13 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 18.268 | ppl 315586 | wps 48623.5 | wpb 510.9 | bsz 1 | num_updates 9001 | best_loss 8.449
2022-03-05 20:22:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9001 updates
2022-03-05 20:22:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:22:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:22:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 185 @ 9001 updates, score 18.268) (writing took 1.8401828361675143 seconds)
2022-03-05 20:22:15 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-05 20:22:15 | INFO | train | epoch 185 | loss 0.417 | ppl 1.34 | wps 27276.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9001 | lr 0.000333315 | gnorm 0.81 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 21617
2022-03-05 20:22:15 | INFO | fairseq.trainer | begin training epoch 186
2022-03-05 20:22:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:23:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:24:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:24:09 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 18.436 | ppl 354533 | wps 48593.5 | wpb 510.9 | bsz 1 | num_updates 9049 | best_loss 8.449
2022-03-05 20:24:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9049 updates
2022-03-05 20:24:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:24:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:24:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 186 @ 9049 updates, score 18.436) (writing took 1.8229224923998117 seconds)
2022-03-05 20:24:11 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-05 20:24:11 | INFO | train | epoch 186 | loss 0.411 | ppl 1.33 | wps 26744 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 9049 | lr 0.00033243 | gnorm 0.808 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 21733
2022-03-05 20:24:11 | INFO | fairseq.trainer | begin training epoch 187
2022-03-05 20:24:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:26:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:26:06 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 18.45 | ppl 358192 | wps 48522 | wpb 510.9 | bsz 1 | num_updates 9098 | best_loss 8.449
2022-03-05 20:26:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9098 updates
2022-03-05 20:26:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:26:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:26:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 187 @ 9098 updates, score 18.45) (writing took 1.8432068526744843 seconds)
2022-03-05 20:26:08 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-05 20:26:08 | INFO | train | epoch 187 | loss 0.408 | ppl 1.33 | wps 27296.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9098 | lr 0.000331533 | gnorm 0.807 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 21850
2022-03-05 20:26:08 | INFO | fairseq.trainer | begin training epoch 188
2022-03-05 20:26:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:26:12 | INFO | train_inner | epoch 188:      2 / 49 loss=0.409, ppl=1.33, wps=26344.8, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=9100, lr=0.000331497, gnorm=0.809, loss_scale=32, train_wall=204, gb_free=8.8, wall=21854
2022-03-05 20:27:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:28:02 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 18.454 | ppl 359000 | wps 48680.5 | wpb 510.9 | bsz 1 | num_updates 9147 | best_loss 8.449
2022-03-05 20:28:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9147 updates
2022-03-05 20:28:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:28:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:28:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 188 @ 9147 updates, score 18.454) (writing took 1.83473352342844 seconds)
2022-03-05 20:28:04 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-05 20:28:04 | INFO | train | epoch 188 | loss 0.404 | ppl 1.32 | wps 27303.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9147 | lr 0.000330644 | gnorm 0.801 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 21966
2022-03-05 20:28:04 | INFO | fairseq.trainer | begin training epoch 189
2022-03-05 20:28:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:28:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:29:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:29:59 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 18.424 | ppl 351707 | wps 48582.2 | wpb 510.9 | bsz 1 | num_updates 9195 | best_loss 8.449
2022-03-05 20:29:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9195 updates
2022-03-05 20:29:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:30:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:30:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 189 @ 9195 updates, score 18.424) (writing took 1.8324192501604557 seconds)
2022-03-05 20:30:00 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-05 20:30:00 | INFO | train | epoch 189 | loss 0.4 | ppl 1.32 | wps 26744.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 9195 | lr 0.00032978 | gnorm 0.793 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 22082
2022-03-05 20:30:00 | INFO | fairseq.trainer | begin training epoch 190
2022-03-05 20:30:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:30:12 | INFO | train_inner | epoch 190:      5 / 49 loss=0.401, ppl=1.32, wps=27079.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9200, lr=0.00032969, gnorm=0.797, loss_scale=32, train_wall=204, gb_free=8.8, wall=22094
2022-03-05 20:31:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:31:55 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 18.538 | ppl 380655 | wps 48559.7 | wpb 510.9 | bsz 1 | num_updates 9244 | best_loss 8.449
2022-03-05 20:31:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9244 updates
2022-03-05 20:31:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:31:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:31:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 190 @ 9244 updates, score 18.538) (writing took 1.8712609950453043 seconds)
2022-03-05 20:31:57 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-05 20:31:57 | INFO | train | epoch 190 | loss 0.399 | ppl 1.32 | wps 27275.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9244 | lr 0.000328905 | gnorm 0.801 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 22199
2022-03-05 20:31:57 | INFO | fairseq.trainer | begin training epoch 191
2022-03-05 20:31:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:33:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:33:52 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 18.524 | ppl 377007 | wps 48595.3 | wpb 510.9 | bsz 1 | num_updates 9293 | best_loss 8.449
2022-03-05 20:33:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9293 updates
2022-03-05 20:33:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:33:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:33:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 191 @ 9293 updates, score 18.524) (writing took 1.8471868196502328 seconds)
2022-03-05 20:33:53 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-05 20:33:53 | INFO | train | epoch 191 | loss 0.393 | ppl 1.31 | wps 27283.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9293 | lr 0.000328036 | gnorm 0.786 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 22315
2022-03-05 20:33:53 | INFO | fairseq.trainer | begin training epoch 192
2022-03-05 20:33:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:34:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:34:12 | INFO | train_inner | epoch 192:      8 / 49 loss=0.395, ppl=1.32, wps=27054.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.793, loss_scale=32, train_wall=205, gb_free=8.8, wall=22334
2022-03-05 20:35:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:35:48 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 18.672 | ppl 417617 | wps 48527.3 | wpb 510.9 | bsz 1 | num_updates 9341 | best_loss 8.449
2022-03-05 20:35:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9341 updates
2022-03-05 20:35:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:35:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:35:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 192 @ 9341 updates, score 18.672) (writing took 1.876149912364781 seconds)
2022-03-05 20:35:50 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-05 20:35:50 | INFO | train | epoch 192 | loss 0.392 | ppl 1.31 | wps 26726.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 9341 | lr 0.000327192 | gnorm 0.792 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 22432
2022-03-05 20:35:50 | INFO | fairseq.trainer | begin training epoch 193
2022-03-05 20:35:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:37:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:37:44 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 18.512 | ppl 373815 | wps 48537.1 | wpb 510.9 | bsz 1 | num_updates 9390 | best_loss 8.449
2022-03-05 20:37:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9390 updates
2022-03-05 20:37:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:37:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:37:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 193 @ 9390 updates, score 18.512) (writing took 1.8337973579764366 seconds)
2022-03-05 20:37:46 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-05 20:37:46 | INFO | train | epoch 193 | loss 0.387 | ppl 1.31 | wps 27296.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9390 | lr 0.000326338 | gnorm 0.785 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 22548
2022-03-05 20:37:46 | INFO | fairseq.trainer | begin training epoch 194
2022-03-05 20:37:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:38:09 | INFO | train_inner | epoch 194:     10 / 49 loss=0.389, ppl=1.31, wps=27323.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.784, loss_scale=32, train_wall=203, gb_free=8.8, wall=22571
2022-03-05 20:39:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:39:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:39:41 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 18.669 | ppl 416749 | wps 48656.7 | wpb 510.9 | bsz 1 | num_updates 9438 | best_loss 8.449
2022-03-05 20:39:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9438 updates
2022-03-05 20:39:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:39:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:39:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 194 @ 9438 updates, score 18.669) (writing took 1.8805654821917415 seconds)
2022-03-05 20:39:43 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-05 20:39:43 | INFO | train | epoch 194 | loss 0.384 | ppl 1.31 | wps 26749.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 9438 | lr 0.000325507 | gnorm 0.787 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 22665
2022-03-05 20:39:43 | INFO | fairseq.trainer | begin training epoch 195
2022-03-05 20:39:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:41:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:41:37 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 18.64 | ppl 408558 | wps 48599.6 | wpb 510.9 | bsz 1 | num_updates 9487 | best_loss 8.449
2022-03-05 20:41:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9487 updates
2022-03-05 20:41:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:41:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:41:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 195 @ 9487 updates, score 18.64) (writing took 1.8629596987739205 seconds)
2022-03-05 20:41:39 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-05 20:41:39 | INFO | train | epoch 195 | loss 0.379 | ppl 1.3 | wps 27291.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9487 | lr 0.000324665 | gnorm 0.765 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 22781
2022-03-05 20:41:39 | INFO | fairseq.trainer | begin training epoch 196
2022-03-05 20:41:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:42:09 | INFO | train_inner | epoch 196:     13 / 49 loss=0.381, ppl=1.3, wps=27074.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.778, loss_scale=32, train_wall=204, gb_free=8.8, wall=22811
2022-03-05 20:43:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:43:34 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 18.777 | ppl 449242 | wps 48663.4 | wpb 510.9 | bsz 1 | num_updates 9536 | best_loss 8.449
2022-03-05 20:43:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9536 updates
2022-03-05 20:43:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:43:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:43:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 196 @ 9536 updates, score 18.777) (writing took 1.883810332044959 seconds)
2022-03-05 20:43:35 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-05 20:43:35 | INFO | train | epoch 196 | loss 0.379 | ppl 1.3 | wps 27309.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9536 | lr 0.00032383 | gnorm 0.775 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 22898
2022-03-05 20:43:35 | INFO | fairseq.trainer | begin training epoch 197
2022-03-05 20:43:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:44:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:45:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:45:30 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 18.709 | ppl 428652 | wps 48584.2 | wpb 510.9 | bsz 1 | num_updates 9584 | best_loss 8.449
2022-03-05 20:45:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9584 updates
2022-03-05 20:45:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:45:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:45:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 197 @ 9584 updates, score 18.709) (writing took 1.878870232962072 seconds)
2022-03-05 20:45:32 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-05 20:45:32 | INFO | train | epoch 197 | loss 0.376 | ppl 1.3 | wps 26730.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 9584 | lr 0.000323018 | gnorm 0.785 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 23014
2022-03-05 20:45:32 | INFO | fairseq.trainer | begin training epoch 198
2022-03-05 20:45:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:46:08 | INFO | train_inner | epoch 198:     16 / 49 loss=0.376, ppl=1.3, wps=27075.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.776, loss_scale=32, train_wall=204, gb_free=8.8, wall=23050
2022-03-05 20:47:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:47:26 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 18.811 | ppl 459961 | wps 48438.8 | wpb 510.9 | bsz 1 | num_updates 9633 | best_loss 8.449
2022-03-05 20:47:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9633 updates
2022-03-05 20:47:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:47:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:47:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 198 @ 9633 updates, score 18.811) (writing took 1.893919182009995 seconds)
2022-03-05 20:47:28 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-05 20:47:28 | INFO | train | epoch 198 | loss 0.37 | ppl 1.29 | wps 27287.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9633 | lr 0.000322195 | gnorm 0.754 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 23130
2022-03-05 20:47:28 | INFO | fairseq.trainer | begin training epoch 199
2022-03-05 20:47:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:49:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:49:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:49:23 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 18.785 | ppl 451774 | wps 48582.4 | wpb 510.9 | bsz 1 | num_updates 9681 | best_loss 8.449
2022-03-05 20:49:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9681 updates
2022-03-05 20:49:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:49:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:49:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 199 @ 9681 updates, score 18.785) (writing took 1.8668521950021386 seconds)
2022-03-05 20:49:25 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-05 20:49:25 | INFO | train | epoch 199 | loss 0.369 | ppl 1.29 | wps 26740.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 9681 | lr 0.000321396 | gnorm 0.773 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 23247
2022-03-05 20:49:25 | INFO | fairseq.trainer | begin training epoch 200
2022-03-05 20:49:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:50:08 | INFO | train_inner | epoch 200:     19 / 49 loss=0.368, ppl=1.29, wps=27067.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.766, loss_scale=32, train_wall=204, gb_free=8.8, wall=23290
2022-03-05 20:51:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:51:19 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 18.881 | ppl 482793 | wps 48475.7 | wpb 510.9 | bsz 1 | num_updates 9730 | best_loss 8.449
2022-03-05 20:51:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9730 updates
2022-03-05 20:51:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:51:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:51:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 200 @ 9730 updates, score 18.881) (writing took 1.8910742113366723 seconds)
2022-03-05 20:51:21 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-05 20:51:21 | INFO | train | epoch 200 | loss 0.367 | ppl 1.29 | wps 27282.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9730 | lr 0.000320585 | gnorm 0.778 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 23363
2022-03-05 20:51:21 | INFO | fairseq.trainer | begin training epoch 201
2022-03-05 20:51:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:53:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:53:16 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 18.843 | ppl 470169 | wps 48576.2 | wpb 510.9 | bsz 1 | num_updates 9779 | best_loss 8.449
2022-03-05 20:53:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9779 updates
2022-03-05 20:53:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:53:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:53:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 201 @ 9779 updates, score 18.843) (writing took 1.880149339325726 seconds)
2022-03-05 20:53:18 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-05 20:53:18 | INFO | train | epoch 201 | loss 0.363 | ppl 1.29 | wps 27304.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9779 | lr 0.000319781 | gnorm 0.761 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 23480
2022-03-05 20:53:18 | INFO | fairseq.trainer | begin training epoch 202
2022-03-05 20:53:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:54:05 | INFO | train_inner | epoch 202:     21 / 49 loss=0.363, ppl=1.29, wps=27319.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.765, loss_scale=32, train_wall=202, gb_free=8.8, wall=23527
2022-03-05 20:54:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:55:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:55:12 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 18.892 | ppl 486604 | wps 48558.6 | wpb 510.9 | bsz 1 | num_updates 9827 | best_loss 8.449
2022-03-05 20:55:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9827 updates
2022-03-05 20:55:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:55:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:55:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 202 @ 9827 updates, score 18.892) (writing took 1.8630271079018712 seconds)
2022-03-05 20:55:14 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-05 20:55:14 | INFO | train | epoch 202 | loss 0.36 | ppl 1.28 | wps 26731.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 9827 | lr 0.000318999 | gnorm 0.762 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 23596
2022-03-05 20:55:14 | INFO | fairseq.trainer | begin training epoch 203
2022-03-05 20:55:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:57:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:57:09 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 18.779 | ppl 449920 | wps 48621.4 | wpb 510.9 | bsz 1 | num_updates 9876 | best_loss 8.449
2022-03-05 20:57:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9876 updates
2022-03-05 20:57:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:57:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:57:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 203 @ 9876 updates, score 18.779) (writing took 1.8610952273011208 seconds)
2022-03-05 20:57:11 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-05 20:57:11 | INFO | train | epoch 203 | loss 0.358 | ppl 1.28 | wps 27292.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9876 | lr 0.000318207 | gnorm 0.751 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 23713
2022-03-05 20:57:11 | INFO | fairseq.trainer | begin training epoch 204
2022-03-05 20:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:58:05 | INFO | train_inner | epoch 204:     24 / 49 loss=0.358, ppl=1.28, wps=27070.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.756, loss_scale=16, train_wall=205, gb_free=8.8, wall=23767
2022-03-05 20:59:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:59:05 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 18.895 | ppl 487608 | wps 48506.2 | wpb 510.9 | bsz 1 | num_updates 9925 | best_loss 8.449
2022-03-05 20:59:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9925 updates
2022-03-05 20:59:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:59:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 20:59:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 204 @ 9925 updates, score 18.895) (writing took 1.8652547299861908 seconds)
2022-03-05 20:59:07 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-05 20:59:07 | INFO | train | epoch 204 | loss 0.355 | ppl 1.28 | wps 27287.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9925 | lr 0.00031742 | gnorm 0.756 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 23829
2022-03-05 20:59:07 | INFO | fairseq.trainer | begin training epoch 205
2022-03-05 20:59:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:00:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:01:02 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 19.064 | ppl 548250 | wps 48428.7 | wpb 510.9 | bsz 1 | num_updates 9974 | best_loss 8.449
2022-03-05 21:01:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9974 updates
2022-03-05 21:01:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:01:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:01:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 205 @ 9974 updates, score 19.064) (writing took 1.8780669355764985 seconds)
2022-03-05 21:01:03 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-05 21:01:03 | INFO | train | epoch 205 | loss 0.353 | ppl 1.28 | wps 27296.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9974 | lr 0.00031664 | gnorm 0.747 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 23945
2022-03-05 21:01:03 | INFO | fairseq.trainer | begin training epoch 206
2022-03-05 21:01:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:02:02 | INFO | train_inner | epoch 206:     26 / 49 loss=0.354, ppl=1.28, wps=27319.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.751, loss_scale=32, train_wall=203, gb_free=8.8, wall=24004
2022-03-05 21:02:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:02:58 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 18.911 | ppl 493047 | wps 48538 | wpb 510.9 | bsz 1 | num_updates 10023 | best_loss 8.449
2022-03-05 21:02:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10023 updates
2022-03-05 21:02:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:03:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:03:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 206 @ 10023 updates, score 18.911) (writing took 1.8816304244101048 seconds)
2022-03-05 21:03:00 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-05 21:03:00 | INFO | train | epoch 206 | loss 0.351 | ppl 1.28 | wps 27295.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 10023 | lr 0.000315865 | gnorm 0.757 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 24062
2022-03-05 21:03:00 | INFO | fairseq.trainer | begin training epoch 207
2022-03-05 21:03:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:04:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:04:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:04:54 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 19.068 | ppl 549630 | wps 48433.3 | wpb 510.9 | bsz 1 | num_updates 10071 | best_loss 8.449
2022-03-05 21:04:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10071 updates
2022-03-05 21:04:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:04:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:04:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 207 @ 10071 updates, score 19.068) (writing took 1.8630312327295542 seconds)
2022-03-05 21:04:56 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-05 21:04:56 | INFO | train | epoch 207 | loss 0.346 | ppl 1.27 | wps 26740.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 10071 | lr 0.000315111 | gnorm 0.737 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 24178
2022-03-05 21:04:56 | INFO | fairseq.trainer | begin training epoch 208
2022-03-05 21:04:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:06:02 | INFO | train_inner | epoch 208:     29 / 49 loss=0.347, ppl=1.27, wps=27066.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.742, loss_scale=32, train_wall=205, gb_free=8.8, wall=24244
2022-03-05 21:06:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:06:51 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 19.006 | ppl 526553 | wps 48639.9 | wpb 510.9 | bsz 1 | num_updates 10120 | best_loss 8.449
2022-03-05 21:06:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10120 updates
2022-03-05 21:06:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:06:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:06:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 208 @ 10120 updates, score 19.006) (writing took 1.8781542014330626 seconds)
2022-03-05 21:06:53 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-05 21:06:53 | INFO | train | epoch 208 | loss 0.344 | ppl 1.27 | wps 27282.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 10120 | lr 0.000314347 | gnorm 0.74 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 24295
2022-03-05 21:06:53 | INFO | fairseq.trainer | begin training epoch 209
2022-03-05 21:06:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:08:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:08:47 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 19.007 | ppl 526749 | wps 47921.6 | wpb 510.9 | bsz 1 | num_updates 10169 | best_loss 8.449
2022-03-05 21:08:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10169 updates
2022-03-05 21:08:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:08:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:08:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 209 @ 10169 updates, score 19.007) (writing took 1.8699901718646288 seconds)
2022-03-05 21:08:49 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-05 21:08:49 | INFO | train | epoch 209 | loss 0.342 | ppl 1.27 | wps 27283.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 10169 | lr 0.000313589 | gnorm 0.733 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 24411
2022-03-05 21:08:49 | INFO | fairseq.trainer | begin training epoch 210
2022-03-05 21:08:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:09:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:10:02 | INFO | train_inner | epoch 210:     32 / 49 loss=0.342, ppl=1.27, wps=27067.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.738, loss_scale=32, train_wall=204, gb_free=8.8, wall=24484
2022-03-05 21:10:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:10:44 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 18.999 | ppl 523922 | wps 48524 | wpb 510.9 | bsz 1 | num_updates 10217 | best_loss 8.449
2022-03-05 21:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10217 updates
2022-03-05 21:10:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:10:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:10:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 210 @ 10217 updates, score 18.999) (writing took 1.859439067542553 seconds)
2022-03-05 21:10:46 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-05 21:10:46 | INFO | train | epoch 210 | loss 0.339 | ppl 1.26 | wps 26742.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 10217 | lr 0.000312852 | gnorm 0.742 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 24528
2022-03-05 21:10:46 | INFO | fairseq.trainer | begin training epoch 211
2022-03-05 21:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:11:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:12:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:12:40 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 19.103 | ppl 563022 | wps 48499.4 | wpb 510.9 | bsz 1 | num_updates 10265 | best_loss 8.449
2022-03-05 21:12:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10265 updates
2022-03-05 21:12:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:12:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:12:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 211 @ 10265 updates, score 19.103) (writing took 1.8804063713178039 seconds)
2022-03-05 21:12:42 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-05 21:12:42 | INFO | train | epoch 211 | loss 0.337 | ppl 1.26 | wps 26737.8 | ups 0.41 | wpb 64853.3 | bsz 126.7 | num_updates 10265 | lr 0.000312119 | gnorm 0.737 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 24644
2022-03-05 21:12:42 | INFO | fairseq.trainer | begin training epoch 212
2022-03-05 21:12:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:14:01 | INFO | train_inner | epoch 212:     35 / 49 loss=0.337, ppl=1.26, wps=27067.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.735, loss_scale=16, train_wall=205, gb_free=8.8, wall=24724
2022-03-05 21:14:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:14:37 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 19.202 | ppl 603068 | wps 48479.7 | wpb 510.9 | bsz 1 | num_updates 10314 | best_loss 8.449
2022-03-05 21:14:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10314 updates
2022-03-05 21:14:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:14:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:14:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 212 @ 10314 updates, score 19.202) (writing took 1.8782138135284185 seconds)
2022-03-05 21:14:39 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-05 21:14:39 | INFO | train | epoch 212 | loss 0.335 | ppl 1.26 | wps 27274.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 10314 | lr 0.000311377 | gnorm 0.73 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 24761
2022-03-05 21:14:39 | INFO | fairseq.trainer | begin training epoch 213
2022-03-05 21:14:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:16:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:16:33 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 19.285 | ppl 638967 | wps 48611.4 | wpb 510.9 | bsz 1 | num_updates 10363 | best_loss 8.449
2022-03-05 21:16:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10363 updates
2022-03-05 21:16:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:16:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:16:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 213 @ 10363 updates, score 19.285) (writing took 1.893324313685298 seconds)
2022-03-05 21:16:35 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-05 21:16:35 | INFO | train | epoch 213 | loss 0.332 | ppl 1.26 | wps 27293.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 10363 | lr 0.00031064 | gnorm 0.728 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 24877
2022-03-05 21:16:35 | INFO | fairseq.trainer | begin training epoch 214
2022-03-05 21:16:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:17:59 | INFO | train_inner | epoch 214:     37 / 49 loss=0.333, ppl=1.26, wps=27320.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.735, loss_scale=32, train_wall=202, gb_free=8.8, wall=24961
2022-03-05 21:18:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:18:30 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 19.174 | ppl 591542 | wps 48605.8 | wpb 510.9 | bsz 1 | num_updates 10412 | best_loss 8.449
2022-03-05 21:18:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10412 updates
2022-03-05 21:18:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:18:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:18:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 214 @ 10412 updates, score 19.174) (writing took 1.874256107956171 seconds)
2022-03-05 21:18:31 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-05 21:18:31 | INFO | train | epoch 214 | loss 0.331 | ppl 1.26 | wps 27285.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 10412 | lr 0.000309908 | gnorm 0.737 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 24994
2022-03-05 21:18:31 | INFO | fairseq.trainer | begin training epoch 215
2022-03-05 21:18:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:20:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:20:26 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 19.177 | ppl 592772 | wps 48470.3 | wpb 510.9 | bsz 1 | num_updates 10461 | best_loss 8.449
2022-03-05 21:20:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10461 updates
2022-03-05 21:20:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:20:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:20:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 215 @ 10461 updates, score 19.177) (writing took 1.883739941753447 seconds)
2022-03-05 21:20:28 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-05 21:20:28 | INFO | train | epoch 215 | loss 0.328 | ppl 1.25 | wps 27307 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 10461 | lr 0.000309181 | gnorm 0.722 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 25110
2022-03-05 21:20:28 | INFO | fairseq.trainer | begin training epoch 216
2022-03-05 21:20:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:21:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:21:59 | INFO | train_inner | epoch 216:     40 / 49 loss=0.327, ppl=1.25, wps=27066, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.72, loss_scale=32, train_wall=205, gb_free=8.8, wall=25201
2022-03-05 21:22:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:22:22 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 19.254 | ppl 625218 | wps 48518.4 | wpb 510.9 | bsz 1 | num_updates 10509 | best_loss 8.449
2022-03-05 21:22:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10509 updates
2022-03-05 21:22:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:22:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:22:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 216 @ 10509 updates, score 19.254) (writing took 1.8805689625442028 seconds)
2022-03-05 21:22:24 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-05 21:22:24 | INFO | train | epoch 216 | loss 0.326 | ppl 1.25 | wps 26722.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 10509 | lr 0.000308475 | gnorm 0.717 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 25226
2022-03-05 21:22:24 | INFO | fairseq.trainer | begin training epoch 217
2022-03-05 21:22:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:24:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:24:19 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 19.238 | ppl 618266 | wps 48711.9 | wpb 510.9 | bsz 1 | num_updates 10558 | best_loss 8.449
2022-03-05 21:24:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10558 updates
2022-03-05 21:24:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:24:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:24:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 217 @ 10558 updates, score 19.238) (writing took 1.859434594400227 seconds)
2022-03-05 21:24:21 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-05 21:24:21 | INFO | train | epoch 217 | loss 0.322 | ppl 1.25 | wps 27305.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 10558 | lr 0.000307758 | gnorm 0.717 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 25343
2022-03-05 21:24:21 | INFO | fairseq.trainer | begin training epoch 218
2022-03-05 21:24:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:25:56 | INFO | train_inner | epoch 218:     42 / 49 loss=0.323, ppl=1.25, wps=27329.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.723, loss_scale=32, train_wall=202, gb_free=8.8, wall=25438
2022-03-05 21:26:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:26:15 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 19.399 | ppl 691498 | wps 48657.5 | wpb 510.9 | bsz 1 | num_updates 10607 | best_loss 8.449
2022-03-05 21:26:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10607 updates
2022-03-05 21:26:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:26:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:26:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 218 @ 10607 updates, score 19.399) (writing took 1.8944502398371696 seconds)
2022-03-05 21:26:17 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-05 21:26:17 | INFO | train | epoch 218 | loss 0.323 | ppl 1.25 | wps 27296 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 10607 | lr 0.000307046 | gnorm 0.734 | loss_scale 64 | train_wall 99 | gb_free 8.8 | wall 25459
2022-03-05 21:26:17 | INFO | fairseq.trainer | begin training epoch 219
2022-03-05 21:26:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:26:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:28:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:28:12 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 19.232 | ppl 615665 | wps 48576.9 | wpb 510.9 | bsz 1 | num_updates 10655 | best_loss 8.449
2022-03-05 21:28:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10655 updates
2022-03-05 21:28:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:28:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:28:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 219 @ 10655 updates, score 19.232) (writing took 1.8610441852360964 seconds)
2022-03-05 21:28:14 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-05 21:28:14 | INFO | train | epoch 219 | loss 0.317 | ppl 1.25 | wps 26744.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 10655 | lr 0.000306354 | gnorm 0.708 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 25576
2022-03-05 21:28:14 | INFO | fairseq.trainer | begin training epoch 220
2022-03-05 21:28:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:29:56 | INFO | train_inner | epoch 220:     45 / 49 loss=0.318, ppl=1.25, wps=27076.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.715, loss_scale=32, train_wall=204, gb_free=8.8, wall=25678
2022-03-05 21:30:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:30:08 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 19.213 | ppl 607535 | wps 48585.5 | wpb 510.9 | bsz 1 | num_updates 10704 | best_loss 8.449
2022-03-05 21:30:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10704 updates
2022-03-05 21:30:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:30:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:30:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 220 @ 10704 updates, score 19.213) (writing took 1.8746441174298525 seconds)
2022-03-05 21:30:10 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-05 21:30:10 | INFO | train | epoch 220 | loss 0.317 | ppl 1.25 | wps 27302.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 10704 | lr 0.000305652 | gnorm 0.72 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 25692
2022-03-05 21:30:10 | INFO | fairseq.trainer | begin training epoch 221
2022-03-05 21:30:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:31:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:32:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:32:05 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 19.271 | ppl 632502 | wps 48636.1 | wpb 510.9 | bsz 1 | num_updates 10752 | best_loss 8.449
2022-03-05 21:32:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10752 updates
2022-03-05 21:32:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:32:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:32:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 221 @ 10752 updates, score 19.271) (writing took 1.8749239929020405 seconds)
2022-03-05 21:32:06 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-05 21:32:06 | INFO | train | epoch 221 | loss 0.315 | ppl 1.24 | wps 26727.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 10752 | lr 0.000304969 | gnorm 0.717 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 25808
2022-03-05 21:32:06 | INFO | fairseq.trainer | begin training epoch 222
2022-03-05 21:32:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:33:55 | INFO | train_inner | epoch 222:     48 / 49 loss=0.315, ppl=1.24, wps=27074.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.715, loss_scale=32, train_wall=204, gb_free=8.8, wall=25917
2022-03-05 21:33:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:34:01 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 19.406 | ppl 694452 | wps 48618.9 | wpb 510.9 | bsz 1 | num_updates 10801 | best_loss 8.449
2022-03-05 21:34:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10801 updates
2022-03-05 21:34:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:34:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:34:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 222 @ 10801 updates, score 19.406) (writing took 1.873979584313929 seconds)
2022-03-05 21:34:03 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-05 21:34:03 | INFO | train | epoch 222 | loss 0.314 | ppl 1.24 | wps 27314.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 10801 | lr 0.000304276 | gnorm 0.713 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 25925
2022-03-05 21:34:03 | INFO | fairseq.trainer | begin training epoch 223
2022-03-05 21:34:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:35:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:35:57 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 19.413 | ppl 698021 | wps 48360.3 | wpb 510.9 | bsz 1 | num_updates 10850 | best_loss 8.449
2022-03-05 21:35:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10850 updates
2022-03-05 21:35:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:35:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:35:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 223 @ 10850 updates, score 19.413) (writing took 1.8755539758130908 seconds)
2022-03-05 21:35:59 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-05 21:35:59 | INFO | train | epoch 223 | loss 0.31 | ppl 1.24 | wps 27291.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 10850 | lr 0.000303588 | gnorm 0.7 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 26041
2022-03-05 21:35:59 | INFO | fairseq.trainer | begin training epoch 224
2022-03-05 21:35:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:36:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:37:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:37:54 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 19.388 | ppl 686064 | wps 48617.8 | wpb 510.9 | bsz 1 | num_updates 10898 | best_loss 8.449
2022-03-05 21:37:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10898 updates
2022-03-05 21:37:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:37:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:37:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 224 @ 10898 updates, score 19.388) (writing took 1.956297335214913 seconds)
2022-03-05 21:37:56 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-05 21:37:56 | INFO | train | epoch 224 | loss 0.31 | ppl 1.24 | wps 26705.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 10898 | lr 0.000302919 | gnorm 0.706 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 26158
2022-03-05 21:37:56 | INFO | fairseq.trainer | begin training epoch 225
2022-03-05 21:37:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:38:00 | INFO | train_inner | epoch 225:      2 / 49 loss=0.31, ppl=1.24, wps=26322.4, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=10900, lr=0.000302891, gnorm=0.705, loss_scale=32, train_wall=204, gb_free=8.8, wall=26162
2022-03-05 21:39:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:39:50 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 19.398 | ppl 690665 | wps 48518.2 | wpb 510.9 | bsz 1 | num_updates 10947 | best_loss 8.449
2022-03-05 21:39:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10947 updates
2022-03-05 21:39:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:39:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:39:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 225 @ 10947 updates, score 19.398) (writing took 1.9088306808844209 seconds)
2022-03-05 21:39:52 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-05 21:39:52 | INFO | train | epoch 225 | loss 0.308 | ppl 1.24 | wps 27278.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 10947 | lr 0.00030224 | gnorm 0.698 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 26274
2022-03-05 21:39:52 | INFO | fairseq.trainer | begin training epoch 226
2022-03-05 21:39:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:41:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:41:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:41:47 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 19.389 | ppl 686696 | wps 48630.4 | wpb 510.9 | bsz 1 | num_updates 10995 | best_loss 8.449
2022-03-05 21:41:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 10995 updates
2022-03-05 21:41:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:41:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:41:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 226 @ 10995 updates, score 19.389) (writing took 1.9290521144866943 seconds)
2022-03-05 21:41:49 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-05 21:41:49 | INFO | train | epoch 226 | loss 0.304 | ppl 1.23 | wps 26717.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 10995 | lr 0.00030158 | gnorm 0.696 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 26391
2022-03-05 21:41:49 | INFO | fairseq.trainer | begin training epoch 227
2022-03-05 21:41:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:42:00 | INFO | train_inner | epoch 227:      5 / 49 loss=0.306, ppl=1.24, wps=27052.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=11000, lr=0.000301511, gnorm=0.697, loss_scale=32, train_wall=205, gb_free=8.8, wall=26402
2022-03-05 21:43:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:43:43 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 19.437 | ppl 709873 | wps 48577.8 | wpb 510.9 | bsz 1 | num_updates 11044 | best_loss 8.449
2022-03-05 21:43:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11044 updates
2022-03-05 21:43:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:43:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:43:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 227 @ 11044 updates, score 19.437) (writing took 1.8993245009332895 seconds)
2022-03-05 21:43:45 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-05 21:43:45 | INFO | train | epoch 227 | loss 0.305 | ppl 1.24 | wps 27287.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11044 | lr 0.00030091 | gnorm 0.709 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 26507
2022-03-05 21:43:45 | INFO | fairseq.trainer | begin training epoch 228
2022-03-05 21:43:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:45:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:45:40 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 19.375 | ppl 680141 | wps 48547.8 | wpb 510.9 | bsz 1 | num_updates 11093 | best_loss 8.449
2022-03-05 21:45:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11093 updates
2022-03-05 21:45:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:45:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:45:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 228 @ 11093 updates, score 19.375) (writing took 1.918345695361495 seconds)
2022-03-05 21:45:42 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-05 21:45:42 | INFO | train | epoch 228 | loss 0.301 | ppl 1.23 | wps 27263.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11093 | lr 0.000300245 | gnorm 0.691 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 26624
2022-03-05 21:45:42 | INFO | fairseq.trainer | begin training epoch 229
2022-03-05 21:45:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:45:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:46:00 | INFO | train_inner | epoch 229:      8 / 49 loss=0.303, ppl=1.23, wps=27052.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=11100, lr=0.00030015, gnorm=0.699, loss_scale=16, train_wall=205, gb_free=8.8, wall=26642
2022-03-05 21:47:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:47:36 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 19.42 | ppl 701384 | wps 48535.7 | wpb 510.9 | bsz 1 | num_updates 11141 | best_loss 8.449
2022-03-05 21:47:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11141 updates
2022-03-05 21:47:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:47:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:47:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 229 @ 11141 updates, score 19.42) (writing took 1.8779932335019112 seconds)
2022-03-05 21:47:38 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-05 21:47:38 | INFO | train | epoch 229 | loss 0.3 | ppl 1.23 | wps 26731.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 11141 | lr 0.000299597 | gnorm 0.699 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 26740
2022-03-05 21:47:38 | INFO | fairseq.trainer | begin training epoch 230
2022-03-05 21:47:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:49:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:49:33 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 19.574 | ppl 780382 | wps 48539.3 | wpb 510.9 | bsz 1 | num_updates 11190 | best_loss 8.449
2022-03-05 21:49:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11190 updates
2022-03-05 21:49:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:49:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:49:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 230 @ 11190 updates, score 19.574) (writing took 1.9503782084211707 seconds)
2022-03-05 21:49:35 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-05 21:49:35 | INFO | train | epoch 230 | loss 0.299 | ppl 1.23 | wps 27279.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11190 | lr 0.000298941 | gnorm 0.699 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 26857
2022-03-05 21:49:35 | INFO | fairseq.trainer | begin training epoch 231
2022-03-05 21:49:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:49:58 | INFO | train_inner | epoch 231:     10 / 49 loss=0.299, ppl=1.23, wps=27309.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.7, loss_scale=16, train_wall=203, gb_free=8.8, wall=26880
2022-03-05 21:51:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:51:29 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 19.485 | ppl 733684 | wps 48618.9 | wpb 510.9 | bsz 1 | num_updates 11239 | best_loss 8.449
2022-03-05 21:51:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11239 updates
2022-03-05 21:51:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:51:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:51:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 231 @ 11239 updates, score 19.485) (writing took 1.9023540280759335 seconds)
2022-03-05 21:51:31 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-05 21:51:31 | INFO | train | epoch 231 | loss 0.297 | ppl 1.23 | wps 27274.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11239 | lr 0.000298288 | gnorm 0.697 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 26973
2022-03-05 21:51:31 | INFO | fairseq.trainer | begin training epoch 232
2022-03-05 21:51:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:53:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:53:26 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 19.432 | ppl 707188 | wps 48475.6 | wpb 510.9 | bsz 1 | num_updates 11288 | best_loss 8.449
2022-03-05 21:53:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11288 updates
2022-03-05 21:53:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:53:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:53:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 232 @ 11288 updates, score 19.432) (writing took 1.9166654767468572 seconds)
2022-03-05 21:53:28 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-05 21:53:28 | INFO | train | epoch 232 | loss 0.293 | ppl 1.23 | wps 27281.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11288 | lr 0.00029764 | gnorm 0.691 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 27090
2022-03-05 21:53:28 | INFO | fairseq.trainer | begin training epoch 233
2022-03-05 21:53:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:53:55 | INFO | train_inner | epoch 233:     12 / 49 loss=0.294, ppl=1.23, wps=27313.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.692, loss_scale=32, train_wall=202, gb_free=8.8, wall=27117
2022-03-05 21:55:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:55:22 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 19.586 | ppl 786832 | wps 48464.2 | wpb 510.9 | bsz 1 | num_updates 11337 | best_loss 8.449
2022-03-05 21:55:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11337 updates
2022-03-05 21:55:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:55:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:55:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 233 @ 11337 updates, score 19.586) (writing took 1.9217451820150018 seconds)
2022-03-05 21:55:24 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-05 21:55:24 | INFO | train | epoch 233 | loss 0.291 | ppl 1.22 | wps 27280.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11337 | lr 0.000296996 | gnorm 0.69 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 27206
2022-03-05 21:55:24 | INFO | fairseq.trainer | begin training epoch 234
2022-03-05 21:55:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:56:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:57:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:57:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:57:19 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 19.492 | ppl 737313 | wps 48586.4 | wpb 510.9 | bsz 1 | num_updates 11384 | best_loss 8.449
2022-03-05 21:57:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11384 updates
2022-03-05 21:57:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:57:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:57:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 234 @ 11384 updates, score 19.492) (writing took 1.9105205349624157 seconds)
2022-03-05 21:57:21 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-05 21:57:21 | INFO | train | epoch 234 | loss 0.289 | ppl 1.22 | wps 26166.4 | ups 0.4 | wpb 64829.4 | bsz 126.6 | num_updates 11384 | lr 0.000296382 | gnorm 0.681 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 27323
2022-03-05 21:57:21 | INFO | fairseq.trainer | begin training epoch 235
2022-03-05 21:57:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:57:57 | INFO | train_inner | epoch 235:     16 / 49 loss=0.289, ppl=1.22, wps=26809.2, ups=0.41, wpb=64876.2, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.685, loss_scale=16, train_wall=207, gb_free=8.8, wall=27359
2022-03-05 21:59:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:59:15 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 19.639 | ppl 816569 | wps 48491.2 | wpb 510.9 | bsz 1 | num_updates 11433 | best_loss 8.449
2022-03-05 21:59:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11433 updates
2022-03-05 21:59:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:59:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 21:59:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 235 @ 11433 updates, score 19.639) (writing took 1.9724139627069235 seconds)
2022-03-05 21:59:17 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-05 21:59:17 | INFO | train | epoch 235 | loss 0.288 | ppl 1.22 | wps 27255.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11433 | lr 0.000295747 | gnorm 0.676 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 27439
2022-03-05 21:59:17 | INFO | fairseq.trainer | begin training epoch 236
2022-03-05 21:59:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:01:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:01:12 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 19.606 | ppl 797727 | wps 48448.1 | wpb 510.9 | bsz 1 | num_updates 11482 | best_loss 8.449
2022-03-05 22:01:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11482 updates
2022-03-05 22:01:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:01:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:01:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 236 @ 11482 updates, score 19.606) (writing took 1.9369749752804637 seconds)
2022-03-05 22:01:14 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-05 22:01:14 | INFO | train | epoch 236 | loss 0.287 | ppl 1.22 | wps 27284.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11482 | lr 0.000295115 | gnorm 0.677 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 27556
2022-03-05 22:01:14 | INFO | fairseq.trainer | begin training epoch 237
2022-03-05 22:01:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:01:55 | INFO | train_inner | epoch 237:     18 / 49 loss=0.287, ppl=1.22, wps=27298.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.678, loss_scale=16, train_wall=202, gb_free=8.8, wall=27597
2022-03-05 22:03:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:03:09 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 19.695 | ppl 849021 | wps 48727 | wpb 510.9 | bsz 1 | num_updates 11531 | best_loss 8.449
2022-03-05 22:03:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11531 updates
2022-03-05 22:03:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:03:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:03:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 237 @ 11531 updates, score 19.695) (writing took 1.9063698714599013 seconds)
2022-03-05 22:03:10 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-05 22:03:10 | INFO | train | epoch 237 | loss 0.286 | ppl 1.22 | wps 27223.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11531 | lr 0.000294487 | gnorm 0.682 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 27673
2022-03-05 22:03:11 | INFO | fairseq.trainer | begin training epoch 238
2022-03-05 22:03:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:05:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:05:05 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 19.679 | ppl 839514 | wps 48490.9 | wpb 510.9 | bsz 1 | num_updates 11580 | best_loss 8.449
2022-03-05 22:05:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11580 updates
2022-03-05 22:05:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:05:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:05:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 238 @ 11580 updates, score 19.679) (writing took 1.8476541405543685 seconds)
2022-03-05 22:05:07 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-05 22:05:07 | INFO | train | epoch 238 | loss 0.283 | ppl 1.22 | wps 27304.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11580 | lr 0.000293864 | gnorm 0.672 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 27789
2022-03-05 22:05:07 | INFO | fairseq.trainer | begin training epoch 239
2022-03-05 22:05:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:05:52 | INFO | train_inner | epoch 239:     20 / 49 loss=0.283, ppl=1.22, wps=27293.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.673, loss_scale=32, train_wall=203, gb_free=8.8, wall=27834
2022-03-05 22:06:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:07:01 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 19.802 | ppl 914048 | wps 48676.4 | wpb 510.9 | bsz 1 | num_updates 11629 | best_loss 8.449
2022-03-05 22:07:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11629 updates
2022-03-05 22:07:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:07:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:07:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 239 @ 11629 updates, score 19.802) (writing took 1.8883663732558489 seconds)
2022-03-05 22:07:03 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-05 22:07:03 | INFO | train | epoch 239 | loss 0.282 | ppl 1.22 | wps 27290.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11629 | lr 0.000293244 | gnorm 0.676 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 27905
2022-03-05 22:07:03 | INFO | fairseq.trainer | begin training epoch 240
2022-03-05 22:07:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:07:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:08:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:08:58 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 19.735 | ppl 872630 | wps 47914.6 | wpb 510.9 | bsz 1 | num_updates 11677 | best_loss 8.449
2022-03-05 22:08:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11677 updates
2022-03-05 22:08:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:09:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:09:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 240 @ 11677 updates, score 19.735) (writing took 1.9177188957110047 seconds)
2022-03-05 22:09:00 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-05 22:09:00 | INFO | train | epoch 240 | loss 0.281 | ppl 1.21 | wps 26714.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 11677 | lr 0.00029264 | gnorm 0.678 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 28022
2022-03-05 22:09:00 | INFO | fairseq.trainer | begin training epoch 241
2022-03-05 22:09:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:09:52 | INFO | train_inner | epoch 241:     23 / 49 loss=0.28, ppl=1.21, wps=27059.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.678, loss_scale=32, train_wall=204, gb_free=8.8, wall=28074
2022-03-05 22:10:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:10:54 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 19.741 | ppl 876286 | wps 48526.6 | wpb 510.9 | bsz 1 | num_updates 11726 | best_loss 8.449
2022-03-05 22:10:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11726 updates
2022-03-05 22:10:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:10:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:10:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 241 @ 11726 updates, score 19.741) (writing took 1.8426573909819126 seconds)
2022-03-05 22:10:56 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-05 22:10:56 | INFO | train | epoch 241 | loss 0.279 | ppl 1.21 | wps 27302.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11726 | lr 0.000292028 | gnorm 0.681 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 28138
2022-03-05 22:10:56 | INFO | fairseq.trainer | begin training epoch 242
2022-03-05 22:10:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:12:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:12:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:12:51 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 19.661 | ppl 828831 | wps 48557.3 | wpb 510.9 | bsz 1 | num_updates 11774 | best_loss 8.449
2022-03-05 22:12:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11774 updates
2022-03-05 22:12:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:12:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:12:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 242 @ 11774 updates, score 19.661) (writing took 1.8897672640159726 seconds)
2022-03-05 22:12:53 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-05 22:12:53 | INFO | train | epoch 242 | loss 0.277 | ppl 1.21 | wps 26727.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 11774 | lr 0.000291433 | gnorm 0.674 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 28255
2022-03-05 22:12:53 | INFO | fairseq.trainer | begin training epoch 243
2022-03-05 22:12:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:13:52 | INFO | train_inner | epoch 243:     26 / 49 loss=0.278, ppl=1.21, wps=27071.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.676, loss_scale=32, train_wall=205, gb_free=8.8, wall=28314
2022-03-05 22:14:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:14:47 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 19.859 | ppl 951111 | wps 48617.7 | wpb 510.9 | bsz 1 | num_updates 11823 | best_loss 8.449
2022-03-05 22:14:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11823 updates
2022-03-05 22:14:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:14:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:14:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 243 @ 11823 updates, score 19.859) (writing took 1.8766068313270807 seconds)
2022-03-05 22:14:49 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-05 22:14:49 | INFO | train | epoch 243 | loss 0.276 | ppl 1.21 | wps 27293.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11823 | lr 0.000290828 | gnorm 0.67 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 28371
2022-03-05 22:14:49 | INFO | fairseq.trainer | begin training epoch 244
2022-03-05 22:14:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:16:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:16:44 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 19.926 | ppl 996310 | wps 48595.7 | wpb 510.9 | bsz 1 | num_updates 11872 | best_loss 8.449
2022-03-05 22:16:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11872 updates
2022-03-05 22:16:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:16:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:16:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 244 @ 11872 updates, score 19.926) (writing took 1.9301094049587846 seconds)
2022-03-05 22:16:46 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-05 22:16:46 | INFO | train | epoch 244 | loss 0.276 | ppl 1.21 | wps 27271.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11872 | lr 0.000290227 | gnorm 0.677 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 28488
2022-03-05 22:16:46 | INFO | fairseq.trainer | begin training epoch 245
2022-03-05 22:16:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:17:49 | INFO | train_inner | epoch 245:     28 / 49 loss=0.275, ppl=1.21, wps=27313.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.669, loss_scale=64, train_wall=202, gb_free=8.8, wall=28551
2022-03-05 22:17:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:18:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:18:40 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 19.844 | ppl 941167 | wps 48388.8 | wpb 510.9 | bsz 1 | num_updates 11920 | best_loss 8.449
2022-03-05 22:18:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11920 updates
2022-03-05 22:18:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:18:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:18:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 245 @ 11920 updates, score 19.844) (writing took 1.8526403168216348 seconds)
2022-03-05 22:18:42 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-05 22:18:42 | INFO | train | epoch 245 | loss 0.272 | ppl 1.21 | wps 26731.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 11920 | lr 0.000289642 | gnorm 0.662 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 28604
2022-03-05 22:18:42 | INFO | fairseq.trainer | begin training epoch 246
2022-03-05 22:18:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:20:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:20:37 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 19.85 | ppl 944734 | wps 48633.9 | wpb 510.9 | bsz 1 | num_updates 11969 | best_loss 8.449
2022-03-05 22:20:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11969 updates
2022-03-05 22:20:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:20:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:20:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 246 @ 11969 updates, score 19.85) (writing took 1.8958458304405212 seconds)
2022-03-05 22:20:39 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-05 22:20:39 | INFO | train | epoch 246 | loss 0.271 | ppl 1.21 | wps 27282 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11969 | lr 0.000289049 | gnorm 0.667 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 28721
2022-03-05 22:20:39 | INFO | fairseq.trainer | begin training epoch 247
2022-03-05 22:20:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:21:49 | INFO | train_inner | epoch 247:     31 / 49 loss=0.271, ppl=1.21, wps=27055.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.663, loss_scale=32, train_wall=205, gb_free=8.8, wall=28791
2022-03-05 22:22:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:22:33 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 19.813 | ppl 921102 | wps 48467.2 | wpb 510.9 | bsz 1 | num_updates 12018 | best_loss 8.449
2022-03-05 22:22:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12018 updates
2022-03-05 22:22:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:22:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:22:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 247 @ 12018 updates, score 19.813) (writing took 1.8432442182675004 seconds)
2022-03-05 22:22:35 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-05 22:22:35 | INFO | train | epoch 247 | loss 0.269 | ppl 1.2 | wps 27283 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12018 | lr 0.000288459 | gnorm 0.656 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 28837
2022-03-05 22:22:35 | INFO | fairseq.trainer | begin training epoch 248
2022-03-05 22:22:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:23:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:24:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:24:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:24:30 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 19.618 | ppl 804393 | wps 48598.6 | wpb 510.9 | bsz 1 | num_updates 12065 | best_loss 8.449
2022-03-05 22:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12065 updates
2022-03-05 22:24:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:24:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:24:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 248 @ 12065 updates, score 19.618) (writing took 1.866364219225943 seconds)
2022-03-05 22:24:32 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-05 22:24:32 | INFO | train | epoch 248 | loss 0.267 | ppl 1.2 | wps 26168.2 | ups 0.4 | wpb 64829.4 | bsz 126.6 | num_updates 12065 | lr 0.000287896 | gnorm 0.657 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 28954
2022-03-05 22:24:32 | INFO | fairseq.trainer | begin training epoch 249
2022-03-05 22:24:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:25:51 | INFO | train_inner | epoch 249:     35 / 49 loss=0.268, ppl=1.2, wps=26817.9, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.659, loss_scale=16, train_wall=207, gb_free=8.8, wall=29033
2022-03-05 22:26:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:26:26 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 19.765 | ppl 890660 | wps 48674 | wpb 510.9 | bsz 1 | num_updates 12114 | best_loss 8.449
2022-03-05 22:26:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12114 updates
2022-03-05 22:26:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:26:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:26:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 249 @ 12114 updates, score 19.765) (writing took 1.8741792812943459 seconds)
2022-03-05 22:26:28 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-05 22:26:28 | INFO | train | epoch 249 | loss 0.268 | ppl 1.2 | wps 27314.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12114 | lr 0.000287314 | gnorm 0.661 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 29070
2022-03-05 22:26:28 | INFO | fairseq.trainer | begin training epoch 250
2022-03-05 22:26:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:28:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:28:22 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 19.851 | ppl 945772 | wps 48463.6 | wpb 510.9 | bsz 1 | num_updates 12163 | best_loss 8.449
2022-03-05 22:28:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12163 updates
2022-03-05 22:28:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:28:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:28:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 250 @ 12163 updates, score 19.851) (writing took 1.8846929483115673 seconds)
2022-03-05 22:28:24 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-05 22:28:24 | INFO | train | epoch 250 | loss 0.265 | ppl 1.2 | wps 27282.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12163 | lr 0.000286734 | gnorm 0.656 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 29186
2022-03-05 22:28:24 | INFO | fairseq.trainer | begin training epoch 251
2022-03-05 22:28:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:29:48 | INFO | train_inner | epoch 251:     37 / 49 loss=0.265, ppl=1.2, wps=27326.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.658, loss_scale=32, train_wall=202, gb_free=8.8, wall=29270
2022-03-05 22:30:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:30:19 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 19.911 | ppl 986000 | wps 47969.8 | wpb 510.9 | bsz 1 | num_updates 12212 | best_loss 8.449
2022-03-05 22:30:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12212 updates
2022-03-05 22:30:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:30:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:30:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 251 @ 12212 updates, score 19.911) (writing took 1.9539230717346072 seconds)
2022-03-05 22:30:21 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-05 22:30:21 | INFO | train | epoch 251 | loss 0.263 | ppl 1.2 | wps 27261.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12212 | lr 0.000286158 | gnorm 0.655 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 29303
2022-03-05 22:30:21 | INFO | fairseq.trainer | begin training epoch 252
2022-03-05 22:30:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:32:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:32:16 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 20.041 | ppl 1.07892e+06 | wps 48445.3 | wpb 510.9 | bsz 1 | num_updates 12261 | best_loss 8.449
2022-03-05 22:32:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12261 updates
2022-03-05 22:32:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:32:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:32:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 252 @ 12261 updates, score 20.041) (writing took 1.9278284255415201 seconds)
2022-03-05 22:32:17 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-05 22:32:17 | INFO | train | epoch 252 | loss 0.261 | ppl 1.2 | wps 27271.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12261 | lr 0.000285586 | gnorm 0.654 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 29420
2022-03-05 22:32:17 | INFO | fairseq.trainer | begin training epoch 253
2022-03-05 22:32:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:33:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:33:48 | INFO | train_inner | epoch 253:     40 / 49 loss=0.262, ppl=1.2, wps=27032.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.655, loss_scale=16, train_wall=205, gb_free=8.8, wall=29510
2022-03-05 22:34:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:34:12 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 19.919 | ppl 991485 | wps 48554.2 | wpb 510.9 | bsz 1 | num_updates 12309 | best_loss 8.449
2022-03-05 22:34:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12309 updates
2022-03-05 22:34:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:34:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:34:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 253 @ 12309 updates, score 19.919) (writing took 1.8731405483558774 seconds)
2022-03-05 22:34:14 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-05 22:34:14 | INFO | train | epoch 253 | loss 0.261 | ppl 1.2 | wps 26717.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 12309 | lr 0.000285029 | gnorm 0.66 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 29536
2022-03-05 22:34:14 | INFO | fairseq.trainer | begin training epoch 254
2022-03-05 22:34:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:36:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:36:09 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 19.959 | ppl 1.01931e+06 | wps 48545.4 | wpb 510.9 | bsz 1 | num_updates 12358 | best_loss 8.449
2022-03-05 22:36:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12358 updates
2022-03-05 22:36:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:36:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:36:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 254 @ 12358 updates, score 19.959) (writing took 1.9071298642084002 seconds)
2022-03-05 22:36:10 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-05 22:36:10 | INFO | train | epoch 254 | loss 0.259 | ppl 1.2 | wps 27286.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12358 | lr 0.000284463 | gnorm 0.65 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 29652
2022-03-05 22:36:10 | INFO | fairseq.trainer | begin training epoch 255
2022-03-05 22:36:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:37:46 | INFO | train_inner | epoch 255:     42 / 49 loss=0.259, ppl=1.2, wps=27315.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.649, loss_scale=16, train_wall=202, gb_free=8.8, wall=29748
2022-03-05 22:38:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:38:05 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 19.824 | ppl 928398 | wps 48525.1 | wpb 510.9 | bsz 1 | num_updates 12407 | best_loss 8.449
2022-03-05 22:38:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12407 updates
2022-03-05 22:38:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:38:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:38:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 255 @ 12407 updates, score 19.824) (writing took 1.8791843326762319 seconds)
2022-03-05 22:38:07 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-05 22:38:07 | INFO | train | epoch 255 | loss 0.258 | ppl 1.2 | wps 27279.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12407 | lr 0.000283901 | gnorm 0.646 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 29769
2022-03-05 22:38:07 | INFO | fairseq.trainer | begin training epoch 256
2022-03-05 22:38:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:39:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:40:02 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 19.941 | ppl 1.00661e+06 | wps 48614.1 | wpb 510.9 | bsz 1 | num_updates 12456 | best_loss 8.449
2022-03-05 22:40:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12456 updates
2022-03-05 22:40:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:40:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:40:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 256 @ 12456 updates, score 19.941) (writing took 1.8858876153826714 seconds)
2022-03-05 22:40:03 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-05 22:40:03 | INFO | train | epoch 256 | loss 0.257 | ppl 1.19 | wps 27282.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12456 | lr 0.000283342 | gnorm 0.64 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 29885
2022-03-05 22:40:03 | INFO | fairseq.trainer | begin training epoch 257
2022-03-05 22:40:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:41:43 | INFO | train_inner | epoch 257:     44 / 49 loss=0.256, ppl=1.19, wps=27327.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.641, loss_scale=32, train_wall=202, gb_free=8.8, wall=29985
2022-03-05 22:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:41:58 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 19.982 | ppl 1.03533e+06 | wps 48579.2 | wpb 510.9 | bsz 1 | num_updates 12505 | best_loss 8.449
2022-03-05 22:41:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12505 updates
2022-03-05 22:41:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:42:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:42:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 257 @ 12505 updates, score 19.982) (writing took 1.9301528176292777 seconds)
2022-03-05 22:42:00 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-05 22:42:00 | INFO | train | epoch 257 | loss 0.255 | ppl 1.19 | wps 27299.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12505 | lr 0.000282786 | gnorm 0.641 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 30002
2022-03-05 22:42:00 | INFO | fairseq.trainer | begin training epoch 258
2022-03-05 22:42:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:43:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:43:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:43:54 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 20.015 | ppl 1.05984e+06 | wps 48456.4 | wpb 510.9 | bsz 1 | num_updates 12553 | best_loss 8.449
2022-03-05 22:43:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12553 updates
2022-03-05 22:43:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:43:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:43:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 258 @ 12553 updates, score 20.015) (writing took 1.8348856419324875 seconds)
2022-03-05 22:43:56 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-05 22:43:56 | INFO | train | epoch 258 | loss 0.254 | ppl 1.19 | wps 26747.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 12553 | lr 0.000282245 | gnorm 0.649 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 30118
2022-03-05 22:43:56 | INFO | fairseq.trainer | begin training epoch 259
2022-03-05 22:43:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:45:43 | INFO | train_inner | epoch 259:     47 / 49 loss=0.254, ppl=1.19, wps=27065.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.645, loss_scale=32, train_wall=205, gb_free=8.8, wall=30225
2022-03-05 22:45:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:45:51 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 20.098 | ppl 1.12252e+06 | wps 48544.3 | wpb 510.9 | bsz 1 | num_updates 12602 | best_loss 8.449
2022-03-05 22:45:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12602 updates
2022-03-05 22:45:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:45:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:45:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 259 @ 12602 updates, score 20.098) (writing took 1.8990148417651653 seconds)
2022-03-05 22:45:53 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-05 22:45:53 | INFO | train | epoch 259 | loss 0.253 | ppl 1.19 | wps 27284.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12602 | lr 0.000281696 | gnorm 0.64 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 30235
2022-03-05 22:45:53 | INFO | fairseq.trainer | begin training epoch 260
2022-03-05 22:45:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:47:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:47:47 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 20.173 | ppl 1.18222e+06 | wps 48649.7 | wpb 510.9 | bsz 1 | num_updates 12651 | best_loss 8.449
2022-03-05 22:47:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12651 updates
2022-03-05 22:47:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:47:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:47:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 260 @ 12651 updates, score 20.173) (writing took 1.853454913944006 seconds)
2022-03-05 22:47:49 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-05 22:47:49 | INFO | train | epoch 260 | loss 0.253 | ppl 1.19 | wps 27287.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12651 | lr 0.00028115 | gnorm 0.646 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 30351
2022-03-05 22:47:49 | INFO | fairseq.trainer | begin training epoch 261
2022-03-05 22:47:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:48:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:49:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:49:44 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 19.994 | ppl 1.04398e+06 | wps 48700 | wpb 510.9 | bsz 1 | num_updates 12699 | best_loss 8.449
2022-03-05 22:49:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12699 updates
2022-03-05 22:49:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:49:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:49:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 261 @ 12699 updates, score 19.994) (writing took 1.924475665204227 seconds)
2022-03-05 22:49:46 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-05 22:49:46 | INFO | train | epoch 261 | loss 0.251 | ppl 1.19 | wps 26709.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 12699 | lr 0.000280618 | gnorm 0.637 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 30468
2022-03-05 22:49:46 | INFO | fairseq.trainer | begin training epoch 262
2022-03-05 22:49:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:49:48 | INFO | train_inner | epoch 262:      1 / 49 loss=0.252, ppl=1.19, wps=26318.7, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=12700, lr=0.000280607, gnorm=0.643, loss_scale=32, train_wall=204, gb_free=8.8, wall=30470
2022-03-05 22:51:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:51:40 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 20.048 | ppl 1.08424e+06 | wps 48661 | wpb 510.9 | bsz 1 | num_updates 12748 | best_loss 8.449
2022-03-05 22:51:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12748 updates
2022-03-05 22:51:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:51:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:51:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 262 @ 12748 updates, score 20.048) (writing took 1.8160833735018969 seconds)
2022-03-05 22:51:42 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-05 22:51:42 | INFO | train | epoch 262 | loss 0.249 | ppl 1.19 | wps 27311.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12748 | lr 0.000280078 | gnorm 0.65 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 30584
2022-03-05 22:51:42 | INFO | fairseq.trainer | begin training epoch 263
2022-03-05 22:51:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:53:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:53:37 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 19.994 | ppl 1.04422e+06 | wps 48546.9 | wpb 510.9 | bsz 1 | num_updates 12797 | best_loss 8.449
2022-03-05 22:53:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12797 updates
2022-03-05 22:53:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:53:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:53:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 263 @ 12797 updates, score 19.994) (writing took 1.8900774605572224 seconds)
2022-03-05 22:53:39 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-05 22:53:39 | INFO | train | epoch 263 | loss 0.247 | ppl 1.19 | wps 27277.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12797 | lr 0.000279541 | gnorm 0.633 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 30701
2022-03-05 22:53:39 | INFO | fairseq.trainer | begin training epoch 264
2022-03-05 22:53:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:53:45 | INFO | train_inner | epoch 264:      3 / 49 loss=0.248, ppl=1.19, wps=27326.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12800, lr=0.000279508, gnorm=0.641, loss_scale=32, train_wall=203, gb_free=8.8, wall=30707
2022-03-05 22:53:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:54:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:55:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:55:33 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 20.116 | ppl 1.13618e+06 | wps 48558.9 | wpb 510.9 | bsz 1 | num_updates 12844 | best_loss 8.449
2022-03-05 22:55:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12844 updates
2022-03-05 22:55:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:55:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:55:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 264 @ 12844 updates, score 20.116) (writing took 1.8701881989836693 seconds)
2022-03-05 22:55:35 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-05 22:55:35 | INFO | train | epoch 264 | loss 0.246 | ppl 1.19 | wps 26179.4 | ups 0.4 | wpb 64829.4 | bsz 126.6 | num_updates 12844 | lr 0.000279029 | gnorm 0.649 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 30817
2022-03-05 22:55:35 | INFO | fairseq.trainer | begin training epoch 265
2022-03-05 22:55:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:57:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:57:30 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 19.941 | ppl 1.00686e+06 | wps 48784.3 | wpb 510.9 | bsz 1 | num_updates 12893 | best_loss 8.449
2022-03-05 22:57:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12893 updates
2022-03-05 22:57:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:57:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:57:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 265 @ 12893 updates, score 19.941) (writing took 1.8694579973816872 seconds)
2022-03-05 22:57:31 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-05 22:57:31 | INFO | train | epoch 265 | loss 0.245 | ppl 1.18 | wps 27289.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12893 | lr 0.000278499 | gnorm 0.63 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 30933
2022-03-05 22:57:31 | INFO | fairseq.trainer | begin training epoch 266
2022-03-05 22:57:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:57:47 | INFO | train_inner | epoch 266:      7 / 49 loss=0.245, ppl=1.19, wps=26817.4, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=12900, lr=0.000278423, gnorm=0.64, loss_scale=16, train_wall=207, gb_free=8.8, wall=30949
2022-03-05 22:59:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:59:26 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 20.072 | ppl 1.10219e+06 | wps 48531.3 | wpb 510.9 | bsz 1 | num_updates 12942 | best_loss 8.449
2022-03-05 22:59:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12942 updates
2022-03-05 22:59:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:59:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 22:59:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 266 @ 12942 updates, score 20.072) (writing took 1.9049364291131496 seconds)
2022-03-05 22:59:28 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-05 22:59:28 | INFO | train | epoch 266 | loss 0.243 | ppl 1.18 | wps 27277.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12942 | lr 0.000277971 | gnorm 0.631 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 31050
2022-03-05 22:59:28 | INFO | fairseq.trainer | begin training epoch 267
2022-03-05 22:59:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:01:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:01:22 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 20.215 | ppl 1.21706e+06 | wps 48686.1 | wpb 510.9 | bsz 1 | num_updates 12991 | best_loss 8.449
2022-03-05 23:01:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12991 updates
2022-03-05 23:01:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:01:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:01:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 267 @ 12991 updates, score 20.215) (writing took 1.8826771955937147 seconds)
2022-03-05 23:01:24 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-05 23:01:24 | INFO | train | epoch 267 | loss 0.244 | ppl 1.18 | wps 27291.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12991 | lr 0.000277446 | gnorm 0.637 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 31166
2022-03-05 23:01:24 | INFO | fairseq.trainer | begin training epoch 268
2022-03-05 23:01:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:01:45 | INFO | train_inner | epoch 268:      9 / 49 loss=0.243, ppl=1.18, wps=27312.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=13000, lr=0.00027735, gnorm=0.633, loss_scale=32, train_wall=203, gb_free=8.8, wall=31187
2022-03-05 23:03:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:03:19 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 20.239 | ppl 1.23748e+06 | wps 48553.8 | wpb 510.9 | bsz 1 | num_updates 13040 | best_loss 8.449
2022-03-05 23:03:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13040 updates
2022-03-05 23:03:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:03:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:03:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 268 @ 13040 updates, score 20.239) (writing took 1.9348215078935027 seconds)
2022-03-05 23:03:21 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-05 23:03:21 | INFO | train | epoch 268 | loss 0.243 | ppl 1.18 | wps 27285.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13040 | lr 0.000276924 | gnorm 0.636 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 31283
2022-03-05 23:03:21 | INFO | fairseq.trainer | begin training epoch 269
2022-03-05 23:03:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:04:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:05:15 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 20.293 | ppl 1.28457e+06 | wps 48664.8 | wpb 510.9 | bsz 1 | num_updates 13088 | best_loss 8.449
2022-03-05 23:05:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13088 updates
2022-03-05 23:05:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:05:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:05:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 269 @ 13088 updates, score 20.293) (writing took 1.8216776717454195 seconds)
2022-03-05 23:05:17 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-05 23:05:17 | INFO | train | epoch 269 | loss 0.24 | ppl 1.18 | wps 26740.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 13088 | lr 0.000276416 | gnorm 0.628 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 31399
2022-03-05 23:05:17 | INFO | fairseq.trainer | begin training epoch 270
2022-03-05 23:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:05:44 | INFO | train_inner | epoch 270:     12 / 49 loss=0.241, ppl=1.18, wps=27071.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.631, loss_scale=32, train_wall=205, gb_free=8.8, wall=31427
2022-03-05 23:07:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:07:12 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 20.117 | ppl 1.13747e+06 | wps 48742.2 | wpb 510.9 | bsz 1 | num_updates 13137 | best_loss 8.449
2022-03-05 23:07:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13137 updates
2022-03-05 23:07:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:07:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:07:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 270 @ 13137 updates, score 20.117) (writing took 1.876610640436411 seconds)
2022-03-05 23:07:14 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-05 23:07:14 | INFO | train | epoch 270 | loss 0.238 | ppl 1.18 | wps 27314.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13137 | lr 0.0002759 | gnorm 0.631 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 31516
2022-03-05 23:07:14 | INFO | fairseq.trainer | begin training epoch 271
2022-03-05 23:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:09:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:09:08 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 20.195 | ppl 1.20044e+06 | wps 48591.6 | wpb 510.9 | bsz 1 | num_updates 13186 | best_loss 8.449
2022-03-05 23:09:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13186 updates
2022-03-05 23:09:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:09:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:09:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 271 @ 13186 updates, score 20.195) (writing took 1.9317342061549425 seconds)
2022-03-05 23:09:10 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-05 23:09:10 | INFO | train | epoch 271 | loss 0.238 | ppl 1.18 | wps 27267.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13186 | lr 0.000275387 | gnorm 0.639 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 31632
2022-03-05 23:09:10 | INFO | fairseq.trainer | begin training epoch 272
2022-03-05 23:09:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:09:42 | INFO | train_inner | epoch 272:     14 / 49 loss=0.238, ppl=1.18, wps=27320, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.633, loss_scale=32, train_wall=202, gb_free=8.8, wall=31664
2022-03-05 23:09:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:11:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:11:05 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 20.314 | ppl 1.30324e+06 | wps 48637.6 | wpb 510.9 | bsz 1 | num_updates 13234 | best_loss 8.449
2022-03-05 23:11:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13234 updates
2022-03-05 23:11:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:11:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:11:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 272 @ 13234 updates, score 20.314) (writing took 1.8343902947381139 seconds)
2022-03-05 23:11:07 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-05 23:11:07 | INFO | train | epoch 272 | loss 0.236 | ppl 1.18 | wps 26734.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 13234 | lr 0.000274887 | gnorm 0.619 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 31749
2022-03-05 23:11:07 | INFO | fairseq.trainer | begin training epoch 273
2022-03-05 23:11:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:12:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:13:01 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 20.395 | ppl 1.37884e+06 | wps 48612.7 | wpb 510.9 | bsz 1 | num_updates 13283 | best_loss 8.449
2022-03-05 23:13:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13283 updates
2022-03-05 23:13:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:13:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:13:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 273 @ 13283 updates, score 20.395) (writing took 1.8870262429118156 seconds)
2022-03-05 23:13:03 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-05 23:13:03 | INFO | train | epoch 273 | loss 0.237 | ppl 1.18 | wps 27293.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13283 | lr 0.00027438 | gnorm 0.624 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 31865
2022-03-05 23:13:03 | INFO | fairseq.trainer | begin training epoch 274
2022-03-05 23:13:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:13:42 | INFO | train_inner | epoch 274:     17 / 49 loss=0.236, ppl=1.18, wps=27068, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.624, loss_scale=32, train_wall=205, gb_free=8.8, wall=31904
2022-03-05 23:14:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:14:58 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 20.355 | ppl 1.34156e+06 | wps 48642 | wpb 510.9 | bsz 1 | num_updates 13332 | best_loss 8.449
2022-03-05 23:14:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13332 updates
2022-03-05 23:14:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:14:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:14:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 274 @ 13332 updates, score 20.355) (writing took 1.8512636851519346 seconds)
2022-03-05 23:14:59 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-05 23:14:59 | INFO | train | epoch 274 | loss 0.234 | ppl 1.18 | wps 27289.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13332 | lr 0.000273875 | gnorm 0.624 | loss_scale 64 | train_wall 99 | gb_free 8.8 | wall 31981
2022-03-05 23:14:59 | INFO | fairseq.trainer | begin training epoch 275
2022-03-05 23:14:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:15:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:16:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:16:54 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 20.34 | ppl 1.32685e+06 | wps 48602.7 | wpb 510.9 | bsz 1 | num_updates 13380 | best_loss 8.449
2022-03-05 23:16:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13380 updates
2022-03-05 23:16:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:16:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:16:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 275 @ 13380 updates, score 20.34) (writing took 1.8601807663217187 seconds)
2022-03-05 23:16:56 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-05 23:16:56 | INFO | train | epoch 275 | loss 0.233 | ppl 1.18 | wps 26750 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 13380 | lr 0.000273383 | gnorm 0.616 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 32098
2022-03-05 23:16:56 | INFO | fairseq.trainer | begin training epoch 276
2022-03-05 23:16:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:17:41 | INFO | train_inner | epoch 276:     20 / 49 loss=0.233, ppl=1.18, wps=27074.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.617, loss_scale=32, train_wall=204, gb_free=8.8, wall=32143
2022-03-05 23:18:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:18:50 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 20.483 | ppl 1.46591e+06 | wps 48543.6 | wpb 510.9 | bsz 1 | num_updates 13429 | best_loss 8.449
2022-03-05 23:18:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13429 updates
2022-03-05 23:18:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:18:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:18:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 276 @ 13429 updates, score 20.483) (writing took 1.8470063814893365 seconds)
2022-03-05 23:18:52 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-05 23:18:52 | INFO | train | epoch 276 | loss 0.233 | ppl 1.17 | wps 27293.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13429 | lr 0.000272884 | gnorm 0.621 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 32214
2022-03-05 23:18:52 | INFO | fairseq.trainer | begin training epoch 277
2022-03-05 23:18:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:20:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:20:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:20:47 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 20.344 | ppl 1.33109e+06 | wps 48544.2 | wpb 510.9 | bsz 1 | num_updates 13477 | best_loss 8.449
2022-03-05 23:20:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13477 updates
2022-03-05 23:20:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:20:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:20:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 277 @ 13477 updates, score 20.344) (writing took 1.902403885498643 seconds)
2022-03-05 23:20:49 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-05 23:20:49 | INFO | train | epoch 277 | loss 0.232 | ppl 1.17 | wps 26722.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 13477 | lr 0.000272398 | gnorm 0.622 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 32331
2022-03-05 23:20:49 | INFO | fairseq.trainer | begin training epoch 278
2022-03-05 23:20:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:21:41 | INFO | train_inner | epoch 278:     23 / 49 loss=0.231, ppl=1.17, wps=27058.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.621, loss_scale=32, train_wall=205, gb_free=8.8, wall=32383
2022-03-05 23:22:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:22:43 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 20.507 | ppl 1.48976e+06 | wps 48765.1 | wpb 510.9 | bsz 1 | num_updates 13526 | best_loss 8.449
2022-03-05 23:22:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13526 updates
2022-03-05 23:22:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:22:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:22:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 278 @ 13526 updates, score 20.507) (writing took 1.820282363332808 seconds)
2022-03-05 23:22:45 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-05 23:22:45 | INFO | train | epoch 278 | loss 0.23 | ppl 1.17 | wps 27313.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13526 | lr 0.000271904 | gnorm 0.612 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 32447
2022-03-05 23:22:45 | INFO | fairseq.trainer | begin training epoch 279
2022-03-05 23:22:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:24:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:24:40 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 20.328 | ppl 1.3159e+06 | wps 48612 | wpb 510.9 | bsz 1 | num_updates 13575 | best_loss 8.449
2022-03-05 23:24:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13575 updates
2022-03-05 23:24:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:24:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:24:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 279 @ 13575 updates, score 20.328) (writing took 1.9579203492030501 seconds)
2022-03-05 23:24:42 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-05 23:24:42 | INFO | train | epoch 279 | loss 0.23 | ppl 1.17 | wps 27269.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13575 | lr 0.000271413 | gnorm 0.617 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 32564
2022-03-05 23:24:42 | INFO | fairseq.trainer | begin training epoch 280
2022-03-05 23:24:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:25:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:25:41 | INFO | train_inner | epoch 280:     26 / 49 loss=0.23, ppl=1.17, wps=27070, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.615, loss_scale=32, train_wall=204, gb_free=8.8, wall=32623
2022-03-05 23:26:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:26:36 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 20.326 | ppl 1.31465e+06 | wps 48537.2 | wpb 510.9 | bsz 1 | num_updates 13623 | best_loss 8.449
2022-03-05 23:26:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13623 updates
2022-03-05 23:26:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:26:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:26:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 280 @ 13623 updates, score 20.326) (writing took 1.8384532937780023 seconds)
2022-03-05 23:26:38 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-05 23:26:38 | INFO | train | epoch 280 | loss 0.227 | ppl 1.17 | wps 26752.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 13623 | lr 0.000270934 | gnorm 0.617 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 32680
2022-03-05 23:26:38 | INFO | fairseq.trainer | begin training epoch 281
2022-03-05 23:26:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:28:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:28:33 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 20.429 | ppl 1.41208e+06 | wps 48730 | wpb 510.9 | bsz 1 | num_updates 13672 | best_loss 8.449
2022-03-05 23:28:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13672 updates
2022-03-05 23:28:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:28:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:28:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 281 @ 13672 updates, score 20.429) (writing took 1.8794799102470279 seconds)
2022-03-05 23:28:34 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-05 23:28:34 | INFO | train | epoch 281 | loss 0.225 | ppl 1.17 | wps 27300.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13672 | lr 0.000270448 | gnorm 0.606 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 32796
2022-03-05 23:28:34 | INFO | fairseq.trainer | begin training epoch 282
2022-03-05 23:28:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:29:38 | INFO | train_inner | epoch 282:     28 / 49 loss=0.226, ppl=1.17, wps=27335.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.609, loss_scale=32, train_wall=202, gb_free=8.8, wall=32860
2022-03-05 23:30:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:30:29 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 20.364 | ppl 1.34978e+06 | wps 48526.7 | wpb 510.9 | bsz 1 | num_updates 13721 | best_loss 8.449
2022-03-05 23:30:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13721 updates
2022-03-05 23:30:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:30:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:30:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 282 @ 13721 updates, score 20.364) (writing took 1.8705652821809053 seconds)
2022-03-05 23:30:31 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-05 23:30:31 | INFO | train | epoch 282 | loss 0.226 | ppl 1.17 | wps 27293.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13721 | lr 0.000269965 | gnorm 0.609 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 32913
2022-03-05 23:30:31 | INFO | fairseq.trainer | begin training epoch 283
2022-03-05 23:30:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:30:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:32:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:32:25 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 20.368 | ppl 1.353e+06 | wps 48520.2 | wpb 510.9 | bsz 1 | num_updates 13769 | best_loss 8.449
2022-03-05 23:32:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13769 updates
2022-03-05 23:32:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:32:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:32:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 283 @ 13769 updates, score 20.368) (writing took 1.8829288557171822 seconds)
2022-03-05 23:32:27 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-05 23:32:27 | INFO | train | epoch 283 | loss 0.225 | ppl 1.17 | wps 26729.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 13769 | lr 0.000269494 | gnorm 0.607 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 33029
2022-03-05 23:32:27 | INFO | fairseq.trainer | begin training epoch 284
2022-03-05 23:32:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:33:38 | INFO | train_inner | epoch 284:     31 / 49 loss=0.225, ppl=1.17, wps=27065.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.606, loss_scale=32, train_wall=205, gb_free=8.8, wall=33100
2022-03-05 23:33:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 23:34:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:34:22 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 20.28 | ppl 1.27319e+06 | wps 48617.1 | wpb 510.9 | bsz 1 | num_updates 13817 | best_loss 8.449
2022-03-05 23:34:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13817 updates
2022-03-05 23:34:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:34:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:34:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 284 @ 13817 updates, score 20.28) (writing took 1.8355978596955538 seconds)
2022-03-05 23:34:24 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-05 23:34:24 | INFO | train | epoch 284 | loss 0.223 | ppl 1.17 | wps 26743.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 13817 | lr 0.000269025 | gnorm 0.605 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 33146
2022-03-05 23:34:24 | INFO | fairseq.trainer | begin training epoch 285
2022-03-05 23:34:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:36:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:36:18 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 20.368 | ppl 1.35285e+06 | wps 48575.9 | wpb 510.9 | bsz 1 | num_updates 13866 | best_loss 8.449
2022-03-05 23:36:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13866 updates
2022-03-05 23:36:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:36:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:36:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 285 @ 13866 updates, score 20.368) (writing took 1.9327147053554654 seconds)
2022-03-05 23:36:20 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-05 23:36:20 | INFO | train | epoch 285 | loss 0.223 | ppl 1.17 | wps 27270.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13866 | lr 0.00026855 | gnorm 0.603 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 33262
2022-03-05 23:36:20 | INFO | fairseq.trainer | begin training epoch 286
2022-03-05 23:36:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:37:37 | INFO | train_inner | epoch 286:     34 / 49 loss=0.222, ppl=1.17, wps=27057.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.602, loss_scale=16, train_wall=205, gb_free=8.8, wall=33339
2022-03-05 23:38:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:38:15 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 20.362 | ppl 1.34732e+06 | wps 48456.8 | wpb 510.9 | bsz 1 | num_updates 13915 | best_loss 8.449
2022-03-05 23:38:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13915 updates
2022-03-05 23:38:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:38:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:38:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 286 @ 13915 updates, score 20.362) (writing took 1.9167412221431732 seconds)
2022-03-05 23:38:17 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-05 23:38:17 | INFO | train | epoch 286 | loss 0.221 | ppl 1.17 | wps 27274.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13915 | lr 0.000268076 | gnorm 0.599 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 33379
2022-03-05 23:38:17 | INFO | fairseq.trainer | begin training epoch 287
2022-03-05 23:38:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:40:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:40:11 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 20.43 | ppl 1.41312e+06 | wps 48780.1 | wpb 510.9 | bsz 1 | num_updates 13964 | best_loss 8.449
2022-03-05 23:40:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13964 updates
2022-03-05 23:40:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:40:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:40:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 287 @ 13964 updates, score 20.43) (writing took 1.8141891034319997 seconds)
2022-03-05 23:40:13 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-05 23:40:13 | INFO | train | epoch 287 | loss 0.222 | ppl 1.17 | wps 27308.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13964 | lr 0.000267606 | gnorm 0.607 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 33495
2022-03-05 23:40:13 | INFO | fairseq.trainer | begin training epoch 288
2022-03-05 23:40:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:41:35 | INFO | train_inner | epoch 288:     36 / 49 loss=0.221, ppl=1.17, wps=27330.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.601, loss_scale=32, train_wall=202, gb_free=8.8, wall=33577
2022-03-05 23:42:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:42:08 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 20.413 | ppl 1.39567e+06 | wps 48575.4 | wpb 510.9 | bsz 1 | num_updates 14013 | best_loss 8.449
2022-03-05 23:42:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14013 updates
2022-03-05 23:42:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:42:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:42:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 288 @ 14013 updates, score 20.413) (writing took 1.9013515766710043 seconds)
2022-03-05 23:42:10 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-05 23:42:10 | INFO | train | epoch 288 | loss 0.22 | ppl 1.16 | wps 27297.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14013 | lr 0.000267137 | gnorm 0.596 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 33612
2022-03-05 23:42:10 | INFO | fairseq.trainer | begin training epoch 289
2022-03-05 23:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:44:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:44:04 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 20.404 | ppl 1.38758e+06 | wps 48526.5 | wpb 510.9 | bsz 1 | num_updates 14062 | best_loss 8.449
2022-03-05 23:44:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14062 updates
2022-03-05 23:44:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:44:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:44:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 289 @ 14062 updates, score 20.404) (writing took 1.8166593750938773 seconds)
2022-03-05 23:44:06 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-05 23:44:06 | INFO | train | epoch 289 | loss 0.22 | ppl 1.17 | wps 27286.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14062 | lr 0.000266671 | gnorm 0.609 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 33728
2022-03-05 23:44:06 | INFO | fairseq.trainer | begin training epoch 290
2022-03-05 23:44:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:44:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:45:34 | INFO | train_inner | epoch 290:     39 / 49 loss=0.22, ppl=1.16, wps=27059.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.603, loss_scale=32, train_wall=205, gb_free=8.8, wall=33816
2022-03-05 23:45:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:46:01 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 20.464 | ppl 1.44663e+06 | wps 48619.9 | wpb 510.9 | bsz 1 | num_updates 14110 | best_loss 8.449
2022-03-05 23:46:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14110 updates
2022-03-05 23:46:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:46:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:46:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 290 @ 14110 updates, score 20.464) (writing took 1.892269209958613 seconds)
2022-03-05 23:46:02 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-05 23:46:02 | INFO | train | epoch 290 | loss 0.218 | ppl 1.16 | wps 26723.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 14110 | lr 0.000266217 | gnorm 0.591 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 33844
2022-03-05 23:46:02 | INFO | fairseq.trainer | begin training epoch 291
2022-03-05 23:46:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:47:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:47:57 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 20.329 | ppl 1.3176e+06 | wps 48637.5 | wpb 510.9 | bsz 1 | num_updates 14159 | best_loss 8.449
2022-03-05 23:47:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14159 updates
2022-03-05 23:47:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:47:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:47:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 291 @ 14159 updates, score 20.329) (writing took 1.8531419271603227 seconds)
2022-03-05 23:47:59 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-05 23:47:59 | INFO | train | epoch 291 | loss 0.217 | ppl 1.16 | wps 27312.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14159 | lr 0.000265756 | gnorm 0.595 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 33961
2022-03-05 23:47:59 | INFO | fairseq.trainer | begin training epoch 292
2022-03-05 23:47:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:49:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 23:49:34 | INFO | train_inner | epoch 292:     42 / 49 loss=0.216, ppl=1.16, wps=27085.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.596, loss_scale=16, train_wall=204, gb_free=8.8, wall=34056
2022-03-05 23:49:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:49:53 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 20.476 | ppl 1.45879e+06 | wps 48503 | wpb 510.9 | bsz 1 | num_updates 14207 | best_loss 8.449
2022-03-05 23:49:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14207 updates
2022-03-05 23:49:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:49:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:49:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 292 @ 14207 updates, score 20.476) (writing took 1.891585505567491 seconds)
2022-03-05 23:49:55 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-05 23:49:55 | INFO | train | epoch 292 | loss 0.216 | ppl 1.16 | wps 26737.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 14207 | lr 0.000265307 | gnorm 0.603 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 34077
2022-03-05 23:49:55 | INFO | fairseq.trainer | begin training epoch 293
2022-03-05 23:49:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:51:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:51:50 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 20.405 | ppl 1.38801e+06 | wps 48577.5 | wpb 510.9 | bsz 1 | num_updates 14256 | best_loss 8.449
2022-03-05 23:51:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14256 updates
2022-03-05 23:51:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:51:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:51:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 293 @ 14256 updates, score 20.405) (writing took 1.8279053084552288 seconds)
2022-03-05 23:51:52 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-05 23:51:52 | INFO | train | epoch 293 | loss 0.216 | ppl 1.16 | wps 27318.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14256 | lr 0.000264851 | gnorm 0.594 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 34194
2022-03-05 23:51:52 | INFO | fairseq.trainer | begin training epoch 294
2022-03-05 23:51:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:53:31 | INFO | train_inner | epoch 294:     44 / 49 loss=0.215, ppl=1.16, wps=27320.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.594, loss_scale=16, train_wall=203, gb_free=8.8, wall=34293
2022-03-05 23:53:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:53:46 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 20.513 | ppl 1.49618e+06 | wps 48560.4 | wpb 510.9 | bsz 1 | num_updates 14305 | best_loss 8.449
2022-03-05 23:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14305 updates
2022-03-05 23:53:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:53:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 294 @ 14305 updates, score 20.513) (writing took 1.8813570076599717 seconds)
2022-03-05 23:53:48 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-05 23:53:48 | INFO | train | epoch 294 | loss 0.214 | ppl 1.16 | wps 27277.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14305 | lr 0.000264397 | gnorm 0.592 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 34310
2022-03-05 23:53:48 | INFO | fairseq.trainer | begin training epoch 295
2022-03-05 23:53:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:55:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:55:43 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 20.539 | ppl 1.52313e+06 | wps 48810 | wpb 510.9 | bsz 1 | num_updates 14354 | best_loss 8.449
2022-03-05 23:55:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14354 updates
2022-03-05 23:55:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:55:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:55:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 295 @ 14354 updates, score 20.539) (writing took 1.8562103062868118 seconds)
2022-03-05 23:55:44 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-05 23:55:44 | INFO | train | epoch 295 | loss 0.213 | ppl 1.16 | wps 27295.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14354 | lr 0.000263945 | gnorm 0.588 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 34427
2022-03-05 23:55:45 | INFO | fairseq.trainer | begin training epoch 296
2022-03-05 23:55:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:56:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 23:57:31 | INFO | train_inner | epoch 296:     47 / 49 loss=0.214, ppl=1.16, wps=27072, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.595, loss_scale=16, train_wall=205, gb_free=8.8, wall=34533
2022-03-05 23:57:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:57:39 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 20.515 | ppl 1.49839e+06 | wps 48522.8 | wpb 510.9 | bsz 1 | num_updates 14402 | best_loss 8.449
2022-03-05 23:57:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14402 updates
2022-03-05 23:57:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:57:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:57:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 296 @ 14402 updates, score 20.515) (writing took 1.9622181998565793 seconds)
2022-03-05 23:57:41 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-05 23:57:41 | INFO | train | epoch 296 | loss 0.214 | ppl 1.16 | wps 26717.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 14402 | lr 0.000263505 | gnorm 0.602 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 34543
2022-03-05 23:57:41 | INFO | fairseq.trainer | begin training epoch 297
2022-03-05 23:57:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:59:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:59:36 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 20.547 | ppl 1.53178e+06 | wps 48517.6 | wpb 510.9 | bsz 1 | num_updates 14451 | best_loss 8.449
2022-03-05 23:59:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14451 updates
2022-03-05 23:59:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:59:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-05 23:59:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 297 @ 14451 updates, score 20.547) (writing took 1.924806329421699 seconds)
2022-03-05 23:59:38 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-05 23:59:38 | INFO | train | epoch 297 | loss 0.212 | ppl 1.16 | wps 27276 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14451 | lr 0.000263058 | gnorm 0.598 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 34660
2022-03-05 23:59:38 | INFO | fairseq.trainer | begin training epoch 298
2022-03-05 23:59:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:01:28 | INFO | train_inner | epoch 298:     49 / 49 loss=0.211, ppl=1.16, wps=27295.9, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=14500, lr=0.000262613, gnorm=0.593, loss_scale=16, train_wall=202, gb_free=8.8, wall=34770
2022-03-06 00:01:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:01:32 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 20.57 | ppl 1.55615e+06 | wps 48217.5 | wpb 510.9 | bsz 1 | num_updates 14500 | best_loss 8.449
2022-03-06 00:01:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14500 updates
2022-03-06 00:01:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:01:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:01:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 298 @ 14500 updates, score 20.57) (writing took 1.820302663370967 seconds)
2022-03-06 00:01:34 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-06 00:01:34 | INFO | train | epoch 298 | loss 0.21 | ppl 1.16 | wps 27304.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14500 | lr 0.000262613 | gnorm 0.584 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 34776
2022-03-06 00:01:34 | INFO | fairseq.trainer | begin training epoch 299
2022-03-06 00:01:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:03:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:03:28 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 20.55 | ppl 1.53506e+06 | wps 48624.2 | wpb 510.9 | bsz 1 | num_updates 14549 | best_loss 8.449
2022-03-06 00:03:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14549 updates
2022-03-06 00:03:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:03:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:03:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 299 @ 14549 updates, score 20.55) (writing took 1.8666500383988023 seconds)
2022-03-06 00:03:30 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-06 00:03:30 | INFO | train | epoch 299 | loss 0.211 | ppl 1.16 | wps 27309 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14549 | lr 0.00026217 | gnorm 0.596 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 34892
2022-03-06 00:03:30 | INFO | fairseq.trainer | begin training epoch 300
2022-03-06 00:03:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:05:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:05:25 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 20.675 | ppl 1.67403e+06 | wps 48536.6 | wpb 510.9 | bsz 1 | num_updates 14598 | best_loss 8.449
2022-03-06 00:05:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14598 updates
2022-03-06 00:05:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:05:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:05:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 300 @ 14598 updates, score 20.675) (writing took 1.846993369050324 seconds)
2022-03-06 00:05:27 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-06 00:05:27 | INFO | train | epoch 300 | loss 0.209 | ppl 1.16 | wps 27301.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14598 | lr 0.00026173 | gnorm 0.585 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 35009
2022-03-06 00:05:27 | INFO | fairseq.trainer | begin training epoch 301
2022-03-06 00:05:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:05:31 | INFO | train_inner | epoch 301:      2 / 49 loss=0.21, ppl=1.16, wps=26607.2, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=14600, lr=0.000261712, gnorm=0.59, loss_scale=32, train_wall=202, gb_free=8.8, wall=35013
2022-03-06 00:06:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:07:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:07:21 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 20.718 | ppl 1.72479e+06 | wps 48617.8 | wpb 510.9 | bsz 1 | num_updates 14646 | best_loss 8.449
2022-03-06 00:07:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14646 updates
2022-03-06 00:07:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:07:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:07:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 301 @ 14646 updates, score 20.718) (writing took 1.8864952083677053 seconds)
2022-03-06 00:07:23 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-06 00:07:23 | INFO | train | epoch 301 | loss 0.208 | ppl 1.16 | wps 26730.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 14646 | lr 0.000261301 | gnorm 0.587 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 35125
2022-03-06 00:07:23 | INFO | fairseq.trainer | begin training epoch 302
2022-03-06 00:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:07:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 00:09:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:09:18 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 20.778 | ppl 1.7978e+06 | wps 48562.9 | wpb 510.9 | bsz 1 | num_updates 14694 | best_loss 8.449
2022-03-06 00:09:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14694 updates
2022-03-06 00:09:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:09:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:09:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 302 @ 14694 updates, score 20.778) (writing took 1.8356495751067996 seconds)
2022-03-06 00:09:20 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-06 00:09:20 | INFO | train | epoch 302 | loss 0.208 | ppl 1.15 | wps 26738 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 14694 | lr 0.000260874 | gnorm 0.592 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 35242
2022-03-06 00:09:20 | INFO | fairseq.trainer | begin training epoch 303
2022-03-06 00:09:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:09:33 | INFO | train_inner | epoch 303:      6 / 49 loss=0.208, ppl=1.15, wps=26816.9, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=14700, lr=0.00026082, gnorm=0.59, loss_scale=16, train_wall=207, gb_free=8.8, wall=35255
2022-03-06 00:11:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:11:14 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 20.731 | ppl 1.74017e+06 | wps 48503.8 | wpb 510.9 | bsz 1 | num_updates 14743 | best_loss 8.449
2022-03-06 00:11:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14743 updates
2022-03-06 00:11:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:11:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:11:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 303 @ 14743 updates, score 20.731) (writing took 1.9084714315831661 seconds)
2022-03-06 00:11:16 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-06 00:11:16 | INFO | train | epoch 303 | loss 0.208 | ppl 1.15 | wps 27274.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14743 | lr 0.00026044 | gnorm 0.593 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 35358
2022-03-06 00:11:16 | INFO | fairseq.trainer | begin training epoch 304
2022-03-06 00:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:13:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:13:11 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 20.736 | ppl 1.74661e+06 | wps 48623.6 | wpb 510.9 | bsz 1 | num_updates 14792 | best_loss 8.449
2022-03-06 00:13:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14792 updates
2022-03-06 00:13:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:13:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:13:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 304 @ 14792 updates, score 20.736) (writing took 1.80927998945117 seconds)
2022-03-06 00:13:12 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-06 00:13:12 | INFO | train | epoch 304 | loss 0.205 | ppl 1.15 | wps 27309.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14792 | lr 0.000260008 | gnorm 0.579 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 35474
2022-03-06 00:13:12 | INFO | fairseq.trainer | begin training epoch 305
2022-03-06 00:13:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:13:31 | INFO | train_inner | epoch 305:      8 / 49 loss=0.206, ppl=1.15, wps=27322.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.584, loss_scale=32, train_wall=202, gb_free=8.8, wall=35493
2022-03-06 00:15:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:15:07 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 20.673 | ppl 1.67189e+06 | wps 48558.7 | wpb 510.9 | bsz 1 | num_updates 14841 | best_loss 8.449
2022-03-06 00:15:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14841 updates
2022-03-06 00:15:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:15:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:15:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 305 @ 14841 updates, score 20.673) (writing took 1.8679434778168797 seconds)
2022-03-06 00:15:09 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-06 00:15:09 | INFO | train | epoch 305 | loss 0.205 | ppl 1.15 | wps 27293 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14841 | lr 0.000259578 | gnorm 0.581 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 35591
2022-03-06 00:15:09 | INFO | fairseq.trainer | begin training epoch 306
2022-03-06 00:15:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:16:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:17:03 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 20.674 | ppl 1.67357e+06 | wps 48571.6 | wpb 510.9 | bsz 1 | num_updates 14890 | best_loss 8.449
2022-03-06 00:17:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14890 updates
2022-03-06 00:17:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:17:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:17:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 306 @ 14890 updates, score 20.674) (writing took 1.8390760198235512 seconds)
2022-03-06 00:17:05 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-06 00:17:05 | INFO | train | epoch 306 | loss 0.205 | ppl 1.15 | wps 27310.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14890 | lr 0.000259151 | gnorm 0.583 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 35707
2022-03-06 00:17:05 | INFO | fairseq.trainer | begin training epoch 307
2022-03-06 00:17:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:17:28 | INFO | train_inner | epoch 307:     10 / 49 loss=0.205, ppl=1.15, wps=27326.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.582, loss_scale=32, train_wall=202, gb_free=8.8, wall=35730
2022-03-06 00:17:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:18:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:19:00 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 20.65 | ppl 1.64523e+06 | wps 48538.9 | wpb 510.9 | bsz 1 | num_updates 14938 | best_loss 8.449
2022-03-06 00:19:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14938 updates
2022-03-06 00:19:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:19:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:19:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 307 @ 14938 updates, score 20.65) (writing took 1.8845613226294518 seconds)
2022-03-06 00:19:02 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-06 00:19:02 | INFO | train | epoch 307 | loss 0.202 | ppl 1.15 | wps 26730.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 14938 | lr 0.000258734 | gnorm 0.572 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 35824
2022-03-06 00:19:02 | INFO | fairseq.trainer | begin training epoch 308
2022-03-06 00:19:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:20:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:20:56 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 20.825 | ppl 1.85815e+06 | wps 48745 | wpb 510.9 | bsz 1 | num_updates 14987 | best_loss 8.449
2022-03-06 00:20:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14987 updates
2022-03-06 00:20:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:20:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:20:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 308 @ 14987 updates, score 20.825) (writing took 1.8254740238189697 seconds)
2022-03-06 00:20:58 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-06 00:20:58 | INFO | train | epoch 308 | loss 0.202 | ppl 1.15 | wps 27317.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 14987 | lr 0.000258311 | gnorm 0.58 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 35940
2022-03-06 00:20:58 | INFO | fairseq.trainer | begin training epoch 309
2022-03-06 00:20:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:21:28 | INFO | train_inner | epoch 309:     13 / 49 loss=0.202, ppl=1.15, wps=27078.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.575, loss_scale=32, train_wall=205, gb_free=8.8, wall=35970
2022-03-06 00:22:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:22:53 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 20.782 | ppl 1.80257e+06 | wps 48673.4 | wpb 510.9 | bsz 1 | num_updates 15036 | best_loss 8.449
2022-03-06 00:22:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15036 updates
2022-03-06 00:22:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:22:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:22:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 309 @ 15036 updates, score 20.782) (writing took 1.9204729935154319 seconds)
2022-03-06 00:22:54 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-06 00:22:54 | INFO | train | epoch 309 | loss 0.201 | ppl 1.15 | wps 27287 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15036 | lr 0.00025789 | gnorm 0.572 | loss_scale 64 | train_wall 99 | gb_free 8.8 | wall 36057
2022-03-06 00:22:54 | INFO | fairseq.trainer | begin training epoch 310
2022-03-06 00:22:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:22:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:24:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:24:49 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 20.763 | ppl 1.77939e+06 | wps 48646.1 | wpb 510.9 | bsz 1 | num_updates 15084 | best_loss 8.449
2022-03-06 00:24:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15084 updates
2022-03-06 00:24:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:24:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:24:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 310 @ 15084 updates, score 20.763) (writing took 1.8951961658895016 seconds)
2022-03-06 00:24:51 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-06 00:24:51 | INFO | train | epoch 310 | loss 0.2 | ppl 1.15 | wps 26726.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 15084 | lr 0.000257479 | gnorm 0.574 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 36173
2022-03-06 00:24:51 | INFO | fairseq.trainer | begin training epoch 311
2022-03-06 00:24:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:25:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 00:25:30 | INFO | train_inner | epoch 311:     17 / 49 loss=0.2, ppl=1.15, wps=26818, ups=0.41, wpb=64876.2, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.575, loss_scale=16, train_wall=206, gb_free=8.8, wall=36212
2022-03-06 00:26:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:26:45 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 20.624 | ppl 1.61612e+06 | wps 48644.8 | wpb 510.9 | bsz 1 | num_updates 15132 | best_loss 8.449
2022-03-06 00:26:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15132 updates
2022-03-06 00:26:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:26:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:26:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 311 @ 15132 updates, score 20.624) (writing took 1.8739691879600286 seconds)
2022-03-06 00:26:47 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-06 00:26:47 | INFO | train | epoch 311 | loss 0.201 | ppl 1.15 | wps 26747.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 15132 | lr 0.00025707 | gnorm 0.586 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 36289
2022-03-06 00:26:47 | INFO | fairseq.trainer | begin training epoch 312
2022-03-06 00:26:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:28:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:28:42 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 20.761 | ppl 1.77743e+06 | wps 48586.8 | wpb 510.9 | bsz 1 | num_updates 15181 | best_loss 8.449
2022-03-06 00:28:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15181 updates
2022-03-06 00:28:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:28:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:28:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 312 @ 15181 updates, score 20.761) (writing took 1.8206428634002805 seconds)
2022-03-06 00:28:44 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-06 00:28:44 | INFO | train | epoch 312 | loss 0.199 | ppl 1.15 | wps 27297.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15181 | lr 0.000256655 | gnorm 0.57 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 36406
2022-03-06 00:28:44 | INFO | fairseq.trainer | begin training epoch 313
2022-03-06 00:28:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:29:27 | INFO | train_inner | epoch 313:     19 / 49 loss=0.199, ppl=1.15, wps=27327.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.575, loss_scale=16, train_wall=202, gb_free=8.8, wall=36449
2022-03-06 00:30:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:30:38 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 20.813 | ppl 1.84165e+06 | wps 48917.5 | wpb 510.9 | bsz 1 | num_updates 15230 | best_loss 8.449
2022-03-06 00:30:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15230 updates
2022-03-06 00:30:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:30:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:30:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 313 @ 15230 updates, score 20.813) (writing took 1.8960665483027697 seconds)
2022-03-06 00:30:40 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-06 00:30:40 | INFO | train | epoch 313 | loss 0.198 | ppl 1.15 | wps 27294.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15230 | lr 0.000256242 | gnorm 0.568 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 36522
2022-03-06 00:30:40 | INFO | fairseq.trainer | begin training epoch 314
2022-03-06 00:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:32:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:32:35 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 20.69 | ppl 1.69196e+06 | wps 48714.1 | wpb 510.9 | bsz 1 | num_updates 15279 | best_loss 8.449
2022-03-06 00:32:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15279 updates
2022-03-06 00:32:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:32:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:32:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 314 @ 15279 updates, score 20.69) (writing took 1.8333692224696279 seconds)
2022-03-06 00:32:37 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-06 00:32:37 | INFO | train | epoch 314 | loss 0.198 | ppl 1.15 | wps 27300.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15279 | lr 0.000255831 | gnorm 0.567 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 36639
2022-03-06 00:32:37 | INFO | fairseq.trainer | begin training epoch 315
2022-03-06 00:32:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:33:24 | INFO | train_inner | epoch 315:     21 / 49 loss=0.198, ppl=1.15, wps=27331.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.567, loss_scale=32, train_wall=202, gb_free=8.8, wall=36686
2022-03-06 00:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:34:31 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 20.717 | ppl 1.7236e+06 | wps 48695.9 | wpb 510.9 | bsz 1 | num_updates 15328 | best_loss 8.449
2022-03-06 00:34:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15328 updates
2022-03-06 00:34:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:34:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:34:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 315 @ 15328 updates, score 20.717) (writing took 1.8679401585832238 seconds)
2022-03-06 00:34:33 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-06 00:34:33 | INFO | train | epoch 315 | loss 0.197 | ppl 1.15 | wps 27294.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15328 | lr 0.000255421 | gnorm 0.573 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 36755
2022-03-06 00:34:33 | INFO | fairseq.trainer | begin training epoch 316
2022-03-06 00:34:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:35:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:36:28 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 20.753 | ppl 1.76683e+06 | wps 48644.2 | wpb 510.9 | bsz 1 | num_updates 15376 | best_loss 8.449
2022-03-06 00:36:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15376 updates
2022-03-06 00:36:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:36:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:36:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 316 @ 15376 updates, score 20.753) (writing took 1.8689915938302875 seconds)
2022-03-06 00:36:29 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-06 00:36:29 | INFO | train | epoch 316 | loss 0.197 | ppl 1.15 | wps 26728 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 15376 | lr 0.000255022 | gnorm 0.579 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 36872
2022-03-06 00:36:29 | INFO | fairseq.trainer | begin training epoch 317
2022-03-06 00:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:37:24 | INFO | train_inner | epoch 317:     24 / 49 loss=0.197, ppl=1.15, wps=27065.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.576, loss_scale=32, train_wall=205, gb_free=8.8, wall=36926
2022-03-06 00:38:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:38:24 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 20.819 | ppl 1.84949e+06 | wps 48526.8 | wpb 510.9 | bsz 1 | num_updates 15425 | best_loss 8.449
2022-03-06 00:38:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15425 updates
2022-03-06 00:38:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:38:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:38:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 317 @ 15425 updates, score 20.819) (writing took 1.8894248446449637 seconds)
2022-03-06 00:38:26 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-06 00:38:26 | INFO | train | epoch 317 | loss 0.196 | ppl 1.15 | wps 27295.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15425 | lr 0.000254617 | gnorm 0.569 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 36988
2022-03-06 00:38:26 | INFO | fairseq.trainer | begin training epoch 318
2022-03-06 00:38:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:40:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:40:20 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 20.716 | ppl 1.72207e+06 | wps 48611.5 | wpb 510.9 | bsz 1 | num_updates 15474 | best_loss 8.449
2022-03-06 00:40:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15474 updates
2022-03-06 00:40:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:40:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:40:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 318 @ 15474 updates, score 20.716) (writing took 1.8767608478665352 seconds)
2022-03-06 00:40:22 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-06 00:40:22 | INFO | train | epoch 318 | loss 0.194 | ppl 1.14 | wps 27295.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15474 | lr 0.000254214 | gnorm 0.567 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 37104
2022-03-06 00:40:22 | INFO | fairseq.trainer | begin training epoch 319
2022-03-06 00:40:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:40:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:41:24 | INFO | train_inner | epoch 319:     27 / 49 loss=0.194, ppl=1.14, wps=27069.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.566, loss_scale=32, train_wall=204, gb_free=8.8, wall=37166
2022-03-06 00:42:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:42:17 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 20.811 | ppl 1.83937e+06 | wps 48576.3 | wpb 510.9 | bsz 1 | num_updates 15522 | best_loss 8.449
2022-03-06 00:42:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15522 updates
2022-03-06 00:42:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:42:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:42:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 319 @ 15522 updates, score 20.811) (writing took 1.81496721226722 seconds)
2022-03-06 00:42:19 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-06 00:42:19 | INFO | train | epoch 319 | loss 0.193 | ppl 1.14 | wps 26760.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 15522 | lr 0.00025382 | gnorm 0.567 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 37221
2022-03-06 00:42:19 | INFO | fairseq.trainer | begin training epoch 320
2022-03-06 00:42:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:44:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:44:13 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 20.897 | ppl 1.95281e+06 | wps 48558.2 | wpb 510.9 | bsz 1 | num_updates 15571 | best_loss 8.449
2022-03-06 00:44:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15571 updates
2022-03-06 00:44:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:44:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:44:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 320 @ 15571 updates, score 20.897) (writing took 1.8642229242250323 seconds)
2022-03-06 00:44:15 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-06 00:44:15 | INFO | train | epoch 320 | loss 0.194 | ppl 1.14 | wps 27285.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15571 | lr 0.000253421 | gnorm 0.568 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 37337
2022-03-06 00:44:15 | INFO | fairseq.trainer | begin training epoch 321
2022-03-06 00:44:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:45:21 | INFO | train_inner | epoch 321:     29 / 49 loss=0.193, ppl=1.14, wps=27337.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.566, loss_scale=32, train_wall=202, gb_free=8.8, wall=37403
2022-03-06 00:45:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:46:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:46:10 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 20.95 | ppl 2.02598e+06 | wps 48513.1 | wpb 510.9 | bsz 1 | num_updates 15619 | best_loss 8.449
2022-03-06 00:46:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15619 updates
2022-03-06 00:46:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:46:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:46:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 321 @ 15619 updates, score 20.95) (writing took 1.831848324276507 seconds)
2022-03-06 00:46:11 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-06 00:46:11 | INFO | train | epoch 321 | loss 0.193 | ppl 1.14 | wps 26763.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 15619 | lr 0.000253031 | gnorm 0.566 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 37453
2022-03-06 00:46:11 | INFO | fairseq.trainer | begin training epoch 322
2022-03-06 00:46:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:48:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:48:06 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 20.925 | ppl 1.99127e+06 | wps 48698.2 | wpb 510.9 | bsz 1 | num_updates 15668 | best_loss 8.449
2022-03-06 00:48:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15668 updates
2022-03-06 00:48:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:48:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:48:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 322 @ 15668 updates, score 20.925) (writing took 1.895777557976544 seconds)
2022-03-06 00:48:08 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-06 00:48:08 | INFO | train | epoch 322 | loss 0.193 | ppl 1.14 | wps 27285.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15668 | lr 0.000252635 | gnorm 0.565 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 37570
2022-03-06 00:48:08 | INFO | fairseq.trainer | begin training epoch 323
2022-03-06 00:48:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:49:20 | INFO | train_inner | epoch 323:     32 / 49 loss=0.193, ppl=1.14, wps=27072.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.565, loss_scale=32, train_wall=205, gb_free=8.8, wall=37643
2022-03-06 00:49:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:50:02 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 20.862 | ppl 1.90537e+06 | wps 48762.8 | wpb 510.9 | bsz 1 | num_updates 15717 | best_loss 8.449
2022-03-06 00:50:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15717 updates
2022-03-06 00:50:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:50:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:50:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 323 @ 15717 updates, score 20.862) (writing took 1.8378129107877612 seconds)
2022-03-06 00:50:04 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-06 00:50:04 | INFO | train | epoch 323 | loss 0.191 | ppl 1.14 | wps 27311.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15717 | lr 0.000252241 | gnorm 0.558 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 37686
2022-03-06 00:50:04 | INFO | fairseq.trainer | begin training epoch 324
2022-03-06 00:50:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:51:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:51:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:51:59 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 20.978 | ppl 2.06607e+06 | wps 48521.1 | wpb 510.9 | bsz 1 | num_updates 15765 | best_loss 8.449
2022-03-06 00:51:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15765 updates
2022-03-06 00:51:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:52:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:52:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 324 @ 15765 updates, score 20.978) (writing took 1.9321659235283732 seconds)
2022-03-06 00:52:01 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-06 00:52:01 | INFO | train | epoch 324 | loss 0.19 | ppl 1.14 | wps 26705.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 15765 | lr 0.000251856 | gnorm 0.553 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 37803
2022-03-06 00:52:01 | INFO | fairseq.trainer | begin training epoch 325
2022-03-06 00:52:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:53:20 | INFO | train_inner | epoch 325:     35 / 49 loss=0.19, ppl=1.14, wps=27065.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.556, loss_scale=32, train_wall=205, gb_free=8.8, wall=37882
2022-03-06 00:53:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:53:55 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 21.042 | ppl 2.15951e+06 | wps 48393.8 | wpb 510.9 | bsz 1 | num_updates 15814 | best_loss 8.449
2022-03-06 00:53:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15814 updates
2022-03-06 00:53:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:53:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:53:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 325 @ 15814 updates, score 21.042) (writing took 1.928895921446383 seconds)
2022-03-06 00:53:57 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-06 00:53:57 | INFO | train | epoch 325 | loss 0.191 | ppl 1.14 | wps 27275 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15814 | lr 0.000251466 | gnorm 0.561 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 37919
2022-03-06 00:53:57 | INFO | fairseq.trainer | begin training epoch 326
2022-03-06 00:53:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:55:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:55:52 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 21.016 | ppl 2.12045e+06 | wps 48682.3 | wpb 510.9 | bsz 1 | num_updates 15863 | best_loss 8.449
2022-03-06 00:55:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15863 updates
2022-03-06 00:55:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:55:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:55:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 326 @ 15863 updates, score 21.016) (writing took 1.862335354089737 seconds)
2022-03-06 00:55:54 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-06 00:55:54 | INFO | train | epoch 326 | loss 0.189 | ppl 1.14 | wps 27301.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15863 | lr 0.000251077 | gnorm 0.557 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 38036
2022-03-06 00:55:54 | INFO | fairseq.trainer | begin training epoch 327
2022-03-06 00:55:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:56:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:57:20 | INFO | train_inner | epoch 327:     38 / 49 loss=0.189, ppl=1.14, wps=27054.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.558, loss_scale=32, train_wall=205, gb_free=8.8, wall=38122
2022-03-06 00:57:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:57:48 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 20.959 | ppl 2.03835e+06 | wps 48745.2 | wpb 510.9 | bsz 1 | num_updates 15911 | best_loss 8.449
2022-03-06 00:57:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15911 updates
2022-03-06 00:57:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:57:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 327 @ 15911 updates, score 20.959) (writing took 1.9069553017616272 seconds)
2022-03-06 00:57:50 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-06 00:57:50 | INFO | train | epoch 327 | loss 0.188 | ppl 1.14 | wps 26723.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 15911 | lr 0.000250698 | gnorm 0.556 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 38152
2022-03-06 00:57:50 | INFO | fairseq.trainer | begin training epoch 328
2022-03-06 00:57:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:59:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:59:45 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 20.908 | ppl 1.96769e+06 | wps 48056.5 | wpb 510.9 | bsz 1 | num_updates 15960 | best_loss 8.449
2022-03-06 00:59:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15960 updates
2022-03-06 00:59:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:59:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 00:59:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 328 @ 15960 updates, score 20.908) (writing took 1.9010926904156804 seconds)
2022-03-06 00:59:47 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-06 00:59:47 | INFO | train | epoch 328 | loss 0.189 | ppl 1.14 | wps 27274.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15960 | lr 0.000250313 | gnorm 0.561 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 38269
2022-03-06 00:59:47 | INFO | fairseq.trainer | begin training epoch 329
2022-03-06 00:59:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:59:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 01:01:20 | INFO | train_inner | epoch 329:     41 / 49 loss=0.188, ppl=1.14, wps=27066.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.557, loss_scale=16, train_wall=204, gb_free=8.8, wall=38362
2022-03-06 01:01:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:01:41 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 21.007 | ppl 2.108e+06 | wps 48744.1 | wpb 510.9 | bsz 1 | num_updates 16008 | best_loss 8.449
2022-03-06 01:01:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16008 updates
2022-03-06 01:01:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:01:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:01:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 329 @ 16008 updates, score 21.007) (writing took 1.855808841995895 seconds)
2022-03-06 01:01:43 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-06 01:01:43 | INFO | train | epoch 329 | loss 0.186 | ppl 1.14 | wps 26760.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 16008 | lr 0.000249938 | gnorm 0.553 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 38385
2022-03-06 01:01:43 | INFO | fairseq.trainer | begin training epoch 330
2022-03-06 01:01:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:03:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:03:38 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 21.001 | ppl 2.09804e+06 | wps 48501 | wpb 510.9 | bsz 1 | num_updates 16057 | best_loss 8.449
2022-03-06 01:03:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16057 updates
2022-03-06 01:03:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:03:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:03:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 330 @ 16057 updates, score 21.001) (writing took 1.9903209758922458 seconds)
2022-03-06 01:03:40 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-06 01:03:40 | INFO | train | epoch 330 | loss 0.187 | ppl 1.14 | wps 27262 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16057 | lr 0.000249556 | gnorm 0.556 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 38502
2022-03-06 01:03:40 | INFO | fairseq.trainer | begin training epoch 331
2022-03-06 01:03:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:05:17 | INFO | train_inner | epoch 331:     43 / 49 loss=0.186, ppl=1.14, wps=27310.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.558, loss_scale=32, train_wall=203, gb_free=8.8, wall=38599
2022-03-06 01:05:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:05:34 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 21.08 | ppl 2.21654e+06 | wps 48540.6 | wpb 510.9 | bsz 1 | num_updates 16106 | best_loss 8.449
2022-03-06 01:05:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16106 updates
2022-03-06 01:05:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:05:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:05:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 331 @ 16106 updates, score 21.08) (writing took 2.00658774189651 seconds)
2022-03-06 01:05:36 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-06 01:05:36 | INFO | train | epoch 331 | loss 0.186 | ppl 1.14 | wps 27248.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16106 | lr 0.000249176 | gnorm 0.561 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 38618
2022-03-06 01:05:36 | INFO | fairseq.trainer | begin training epoch 332
2022-03-06 01:05:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:07:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:07:31 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 21.09 | ppl 2.23231e+06 | wps 48679.2 | wpb 510.9 | bsz 1 | num_updates 16155 | best_loss 8.449
2022-03-06 01:07:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16155 updates
2022-03-06 01:07:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:07:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:07:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 332 @ 16155 updates, score 21.09) (writing took 1.8985693026334047 seconds)
2022-03-06 01:07:33 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-06 01:07:33 | INFO | train | epoch 332 | loss 0.185 | ppl 1.14 | wps 27301.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16155 | lr 0.000248798 | gnorm 0.559 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 38735
2022-03-06 01:07:33 | INFO | fairseq.trainer | begin training epoch 333
2022-03-06 01:07:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:09:15 | INFO | train_inner | epoch 333:     45 / 49 loss=0.185, ppl=1.14, wps=27313.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.556, loss_scale=32, train_wall=202, gb_free=8.8, wall=38837
2022-03-06 01:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:09:27 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 21.122 | ppl 2.28158e+06 | wps 48722.3 | wpb 510.9 | bsz 1 | num_updates 16204 | best_loss 8.449
2022-03-06 01:09:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16204 updates
2022-03-06 01:09:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:09:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:09:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 333 @ 16204 updates, score 21.122) (writing took 1.947257717140019 seconds)
2022-03-06 01:09:29 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-06 01:09:29 | INFO | train | epoch 333 | loss 0.184 | ppl 1.14 | wps 27286.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16204 | lr 0.000248421 | gnorm 0.55 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 38851
2022-03-06 01:09:29 | INFO | fairseq.trainer | begin training epoch 334
2022-03-06 01:09:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:10:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:11:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:11:24 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 21.037 | ppl 2.15097e+06 | wps 48418.7 | wpb 510.9 | bsz 1 | num_updates 16252 | best_loss 8.449
2022-03-06 01:11:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16252 updates
2022-03-06 01:11:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:11:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:11:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 334 @ 16252 updates, score 21.037) (writing took 1.9480831120163202 seconds)
2022-03-06 01:11:26 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-06 01:11:26 | INFO | train | epoch 334 | loss 0.183 | ppl 1.13 | wps 26726.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 16252 | lr 0.000248054 | gnorm 0.551 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 38968
2022-03-06 01:11:26 | INFO | fairseq.trainer | begin training epoch 335
2022-03-06 01:11:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:13:14 | INFO | train_inner | epoch 335:     48 / 49 loss=0.183, ppl=1.14, wps=27060.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.551, loss_scale=32, train_wall=204, gb_free=8.8, wall=39076
2022-03-06 01:13:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:13:20 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 21.056 | ppl 2.17952e+06 | wps 48622.3 | wpb 510.9 | bsz 1 | num_updates 16301 | best_loss 8.449
2022-03-06 01:13:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16301 updates
2022-03-06 01:13:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:13:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:13:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 335 @ 16301 updates, score 21.056) (writing took 1.8759749084711075 seconds)
2022-03-06 01:13:22 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-06 01:13:22 | INFO | train | epoch 335 | loss 0.183 | ppl 1.14 | wps 27299.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16301 | lr 0.000247681 | gnorm 0.552 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 39084
2022-03-06 01:13:22 | INFO | fairseq.trainer | begin training epoch 336
2022-03-06 01:13:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:15:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:15:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:15:16 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 21.054 | ppl 2.17771e+06 | wps 48546.7 | wpb 510.9 | bsz 1 | num_updates 16349 | best_loss 8.449
2022-03-06 01:15:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16349 updates
2022-03-06 01:15:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:15:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:15:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 336 @ 16349 updates, score 21.054) (writing took 1.94011749047786 seconds)
2022-03-06 01:15:18 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-06 01:15:18 | INFO | train | epoch 336 | loss 0.182 | ppl 1.13 | wps 26731.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 16349 | lr 0.000247317 | gnorm 0.552 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 39200
2022-03-06 01:15:18 | INFO | fairseq.trainer | begin training epoch 337
2022-03-06 01:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:17:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:17:13 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 21.064 | ppl 2.19244e+06 | wps 48684.7 | wpb 510.9 | bsz 1 | num_updates 16398 | best_loss 8.449
2022-03-06 01:17:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16398 updates
2022-03-06 01:17:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:17:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:17:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 337 @ 16398 updates, score 21.064) (writing took 1.8664518371224403 seconds)
2022-03-06 01:17:15 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-06 01:17:15 | INFO | train | epoch 337 | loss 0.182 | ppl 1.13 | wps 27324 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16398 | lr 0.000246947 | gnorm 0.55 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 39317
2022-03-06 01:17:15 | INFO | fairseq.trainer | begin training epoch 338
2022-03-06 01:17:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:17:19 | INFO | train_inner | epoch 338:      2 / 49 loss=0.182, ppl=1.13, wps=26347.8, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=16400, lr=0.000246932, gnorm=0.553, loss_scale=32, train_wall=203, gb_free=8.8, wall=39321
2022-03-06 01:19:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:19:09 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 21.102 | ppl 2.2504e+06 | wps 48572.3 | wpb 510.9 | bsz 1 | num_updates 16447 | best_loss 8.449
2022-03-06 01:19:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16447 updates
2022-03-06 01:19:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:19:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:19:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 338 @ 16447 updates, score 21.102) (writing took 1.9821336278691888 seconds)
2022-03-06 01:19:11 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-06 01:19:11 | INFO | train | epoch 338 | loss 0.182 | ppl 1.13 | wps 27267.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16447 | lr 0.000246579 | gnorm 0.556 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 39433
2022-03-06 01:19:11 | INFO | fairseq.trainer | begin training epoch 339
2022-03-06 01:19:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:20:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:20:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 01:21:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:21:06 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 21.164 | ppl 2.34943e+06 | wps 48674.4 | wpb 510.9 | bsz 1 | num_updates 16494 | best_loss 8.449
2022-03-06 01:21:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16494 updates
2022-03-06 01:21:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:21:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:21:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 339 @ 16494 updates, score 21.164) (writing took 1.9777703052386642 seconds)
2022-03-06 01:21:08 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-06 01:21:08 | INFO | train | epoch 339 | loss 0.18 | ppl 1.13 | wps 26159 | ups 0.4 | wpb 64829.4 | bsz 126.6 | num_updates 16494 | lr 0.000246228 | gnorm 0.551 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 39550
2022-03-06 01:21:08 | INFO | fairseq.trainer | begin training epoch 340
2022-03-06 01:21:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:21:21 | INFO | train_inner | epoch 340:      6 / 49 loss=0.181, ppl=1.13, wps=26796.7, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=16500, lr=0.000246183, gnorm=0.554, loss_scale=16, train_wall=206, gb_free=8.8, wall=39563
2022-03-06 01:22:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:23:02 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 21.14 | ppl 2.31148e+06 | wps 48629.6 | wpb 510.9 | bsz 1 | num_updates 16543 | best_loss 8.449
2022-03-06 01:23:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16543 updates
2022-03-06 01:23:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:23:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:23:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 340 @ 16543 updates, score 21.14) (writing took 1.9291499322280288 seconds)
2022-03-06 01:23:04 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-06 01:23:04 | INFO | train | epoch 340 | loss 0.18 | ppl 1.13 | wps 27270.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16543 | lr 0.000245863 | gnorm 0.55 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 39666
2022-03-06 01:23:04 | INFO | fairseq.trainer | begin training epoch 341
2022-03-06 01:23:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:24:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:24:59 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 21.184 | ppl 2.38165e+06 | wps 48778.9 | wpb 510.9 | bsz 1 | num_updates 16592 | best_loss 8.449
2022-03-06 01:24:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16592 updates
2022-03-06 01:24:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:25:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:25:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 341 @ 16592 updates, score 21.184) (writing took 1.9772242419421673 seconds)
2022-03-06 01:25:01 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-06 01:25:01 | INFO | train | epoch 341 | loss 0.179 | ppl 1.13 | wps 27273.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16592 | lr 0.0002455 | gnorm 0.544 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 39783
2022-03-06 01:25:01 | INFO | fairseq.trainer | begin training epoch 342
2022-03-06 01:25:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:25:19 | INFO | train_inner | epoch 342:      8 / 49 loss=0.179, ppl=1.13, wps=27299.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16600, lr=0.00024544, gnorm=0.546, loss_scale=16, train_wall=203, gb_free=8.8, wall=39801
2022-03-06 01:26:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:26:55 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 21.164 | ppl 2.34941e+06 | wps 48545.5 | wpb 510.9 | bsz 1 | num_updates 16641 | best_loss 8.449
2022-03-06 01:26:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16641 updates
2022-03-06 01:26:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:26:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:26:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 342 @ 16641 updates, score 21.164) (writing took 1.9115686258301139 seconds)
2022-03-06 01:26:57 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-06 01:26:57 | INFO | train | epoch 342 | loss 0.178 | ppl 1.13 | wps 27284.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16641 | lr 0.000245138 | gnorm 0.546 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 39899
2022-03-06 01:26:57 | INFO | fairseq.trainer | begin training epoch 343
2022-03-06 01:26:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:28:52 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 21.334 | ppl 2.64297e+06 | wps 48685.1 | wpb 510.9 | bsz 1 | num_updates 16690 | best_loss 8.449
2022-03-06 01:28:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16690 updates
2022-03-06 01:28:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:28:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:28:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 343 @ 16690 updates, score 21.334) (writing took 1.9214670583605766 seconds)
2022-03-06 01:28:54 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-06 01:28:54 | INFO | train | epoch 343 | loss 0.179 | ppl 1.13 | wps 27288.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16690 | lr 0.000244778 | gnorm 0.55 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 40016
2022-03-06 01:28:54 | INFO | fairseq.trainer | begin training epoch 344
2022-03-06 01:28:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:29:17 | INFO | train_inner | epoch 344:     10 / 49 loss=0.179, ppl=1.13, wps=27320.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.547, loss_scale=32, train_wall=202, gb_free=8.8, wall=40039
2022-03-06 01:30:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:30:48 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 21.192 | ppl 2.39525e+06 | wps 48657.8 | wpb 510.9 | bsz 1 | num_updates 16739 | best_loss 8.449
2022-03-06 01:30:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16739 updates
2022-03-06 01:30:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:30:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:30:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 344 @ 16739 updates, score 21.192) (writing took 1.916378860361874 seconds)
2022-03-06 01:30:50 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-06 01:30:50 | INFO | train | epoch 344 | loss 0.177 | ppl 1.13 | wps 27310.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16739 | lr 0.000244419 | gnorm 0.544 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 40132
2022-03-06 01:30:50 | INFO | fairseq.trainer | begin training epoch 345
2022-03-06 01:30:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:31:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:32:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:32:45 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 21.166 | ppl 2.35362e+06 | wps 48539.6 | wpb 510.9 | bsz 1 | num_updates 16787 | best_loss 8.449
2022-03-06 01:32:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16787 updates
2022-03-06 01:32:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:32:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:32:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 345 @ 16787 updates, score 21.166) (writing took 1.919261378236115 seconds)
2022-03-06 01:32:47 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-06 01:32:47 | INFO | train | epoch 345 | loss 0.177 | ppl 1.13 | wps 26716.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 16787 | lr 0.000244069 | gnorm 0.54 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 40249
2022-03-06 01:32:47 | INFO | fairseq.trainer | begin training epoch 346
2022-03-06 01:32:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:33:16 | INFO | train_inner | epoch 346:     13 / 49 loss=0.177, ppl=1.13, wps=27071.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.544, loss_scale=32, train_wall=204, gb_free=8.8, wall=40278
2022-03-06 01:34:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:34:41 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 21.197 | ppl 2.40346e+06 | wps 48583.8 | wpb 510.9 | bsz 1 | num_updates 16836 | best_loss 8.449
2022-03-06 01:34:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16836 updates
2022-03-06 01:34:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:34:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:34:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 346 @ 16836 updates, score 21.197) (writing took 1.9741090442985296 seconds)
2022-03-06 01:34:43 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-06 01:34:43 | INFO | train | epoch 346 | loss 0.177 | ppl 1.13 | wps 27295.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16836 | lr 0.000243714 | gnorm 0.549 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 40365
2022-03-06 01:34:43 | INFO | fairseq.trainer | begin training epoch 347
2022-03-06 01:34:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:36:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:36:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:36:38 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 21.281 | ppl 2.54752e+06 | wps 48549.5 | wpb 510.9 | bsz 1 | num_updates 16884 | best_loss 8.449
2022-03-06 01:36:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16884 updates
2022-03-06 01:36:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:36:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:36:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 347 @ 16884 updates, score 21.281) (writing took 1.9219290995970368 seconds)
2022-03-06 01:36:40 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-06 01:36:40 | INFO | train | epoch 347 | loss 0.175 | ppl 1.13 | wps 26712.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 16884 | lr 0.000243367 | gnorm 0.533 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 40482
2022-03-06 01:36:40 | INFO | fairseq.trainer | begin training epoch 348
2022-03-06 01:36:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:37:16 | INFO | train_inner | epoch 348:     16 / 49 loss=0.175, ppl=1.13, wps=27057, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.538, loss_scale=32, train_wall=204, gb_free=8.8, wall=40518
2022-03-06 01:38:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:38:34 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 21.186 | ppl 2.38651e+06 | wps 48684.9 | wpb 510.9 | bsz 1 | num_updates 16933 | best_loss 8.449
2022-03-06 01:38:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16933 updates
2022-03-06 01:38:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:38:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 348 @ 16933 updates, score 21.186) (writing took 1.8760509053245187 seconds)
2022-03-06 01:38:36 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-06 01:38:36 | INFO | train | epoch 348 | loss 0.174 | ppl 1.13 | wps 27294.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16933 | lr 0.000243015 | gnorm 0.532 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 40598
2022-03-06 01:38:36 | INFO | fairseq.trainer | begin training epoch 349
2022-03-06 01:38:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:40:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:40:31 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 21.213 | ppl 2.4309e+06 | wps 48550.8 | wpb 510.9 | bsz 1 | num_updates 16982 | best_loss 8.449
2022-03-06 01:40:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16982 updates
2022-03-06 01:40:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:40:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:40:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 349 @ 16982 updates, score 21.213) (writing took 1.978505091741681 seconds)
2022-03-06 01:40:33 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-06 01:40:33 | INFO | train | epoch 349 | loss 0.175 | ppl 1.13 | wps 27279.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16982 | lr 0.000242664 | gnorm 0.548 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 40715
2022-03-06 01:40:33 | INFO | fairseq.trainer | begin training epoch 350
2022-03-06 01:40:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:41:13 | INFO | train_inner | epoch 350:     18 / 49 loss=0.175, ppl=1.13, wps=27313.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.541, loss_scale=32, train_wall=202, gb_free=8.8, wall=40755
2022-03-06 01:41:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:42:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:42:27 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 21.166 | ppl 2.35239e+06 | wps 48363.5 | wpb 510.9 | bsz 1 | num_updates 17030 | best_loss 8.449
2022-03-06 01:42:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17030 updates
2022-03-06 01:42:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:42:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:42:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 350 @ 17030 updates, score 21.166) (writing took 1.85401058383286 seconds)
2022-03-06 01:42:29 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-06 01:42:29 | INFO | train | epoch 350 | loss 0.174 | ppl 1.13 | wps 26738.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 17030 | lr 0.000242322 | gnorm 0.535 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 40831
2022-03-06 01:42:29 | INFO | fairseq.trainer | begin training epoch 351
2022-03-06 01:42:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:44:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:44:23 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 21.312 | ppl 2.60302e+06 | wps 48648.7 | wpb 510.9 | bsz 1 | num_updates 17079 | best_loss 8.449
2022-03-06 01:44:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17079 updates
2022-03-06 01:44:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:44:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:44:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 351 @ 17079 updates, score 21.312) (writing took 1.9860776644200087 seconds)
2022-03-06 01:44:25 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-06 01:44:25 | INFO | train | epoch 351 | loss 0.172 | ppl 1.13 | wps 27268.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17079 | lr 0.000241974 | gnorm 0.533 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 40948
2022-03-06 01:44:25 | INFO | fairseq.trainer | begin training epoch 352
2022-03-06 01:44:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:44:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 01:45:15 | INFO | train_inner | epoch 352:     22 / 49 loss=0.173, ppl=1.13, wps=26813.4, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.533, loss_scale=16, train_wall=206, gb_free=8.8, wall=40997
2022-03-06 01:46:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:46:20 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 21.291 | ppl 2.56558e+06 | wps 48596.3 | wpb 510.9 | bsz 1 | num_updates 17127 | best_loss 8.449
2022-03-06 01:46:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17127 updates
2022-03-06 01:46:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:46:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:46:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 352 @ 17127 updates, score 21.291) (writing took 1.972885730676353 seconds)
2022-03-06 01:46:22 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-06 01:46:22 | INFO | train | epoch 352 | loss 0.172 | ppl 1.13 | wps 26727.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 17127 | lr 0.000241635 | gnorm 0.537 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 41064
2022-03-06 01:46:22 | INFO | fairseq.trainer | begin training epoch 353
2022-03-06 01:46:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:48:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:48:16 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 21.243 | ppl 2.48198e+06 | wps 48655.4 | wpb 510.9 | bsz 1 | num_updates 17176 | best_loss 8.449
2022-03-06 01:48:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17176 updates
2022-03-06 01:48:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:48:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:48:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 353 @ 17176 updates, score 21.243) (writing took 1.8881007572636008 seconds)
2022-03-06 01:48:18 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-06 01:48:18 | INFO | train | epoch 353 | loss 0.172 | ppl 1.13 | wps 27296.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17176 | lr 0.00024129 | gnorm 0.542 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 41180
2022-03-06 01:48:18 | INFO | fairseq.trainer | begin training epoch 354
2022-03-06 01:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:49:13 | INFO | train_inner | epoch 354:     24 / 49 loss=0.172, ppl=1.13, wps=27320.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.539, loss_scale=16, train_wall=202, gb_free=8.8, wall=41235
2022-03-06 01:50:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:50:13 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 21.19 | ppl 2.39311e+06 | wps 48043.7 | wpb 510.9 | bsz 1 | num_updates 17225 | best_loss 8.449
2022-03-06 01:50:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17225 updates
2022-03-06 01:50:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:50:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:50:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 354 @ 17225 updates, score 21.19) (writing took 2.0138091575354338 seconds)
2022-03-06 01:50:15 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-06 01:50:15 | INFO | train | epoch 354 | loss 0.171 | ppl 1.13 | wps 27265 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17225 | lr 0.000240946 | gnorm 0.533 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 41297
2022-03-06 01:50:15 | INFO | fairseq.trainer | begin training epoch 355
2022-03-06 01:50:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:52:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:52:09 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 21.229 | ppl 2.45808e+06 | wps 48443.1 | wpb 510.9 | bsz 1 | num_updates 17274 | best_loss 8.449
2022-03-06 01:52:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17274 updates
2022-03-06 01:52:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:52:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:52:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 355 @ 17274 updates, score 21.229) (writing took 1.9497314002364874 seconds)
2022-03-06 01:52:11 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-06 01:52:11 | INFO | train | epoch 355 | loss 0.171 | ppl 1.13 | wps 27276.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17274 | lr 0.000240604 | gnorm 0.537 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 41413
2022-03-06 01:52:11 | INFO | fairseq.trainer | begin training epoch 356
2022-03-06 01:52:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:53:10 | INFO | train_inner | epoch 356:     26 / 49 loss=0.171, ppl=1.13, wps=27306.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.534, loss_scale=32, train_wall=202, gb_free=8.8, wall=41472
2022-03-06 01:54:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:54:06 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 21.221 | ppl 2.44493e+06 | wps 48648.8 | wpb 510.9 | bsz 1 | num_updates 17323 | best_loss 8.449
2022-03-06 01:54:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17323 updates
2022-03-06 01:54:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:54:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:54:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 356 @ 17323 updates, score 21.221) (writing took 1.8998654382303357 seconds)
2022-03-06 01:54:08 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-06 01:54:08 | INFO | train | epoch 356 | loss 0.17 | ppl 1.13 | wps 27304.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17323 | lr 0.000240264 | gnorm 0.53 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 41530
2022-03-06 01:54:08 | INFO | fairseq.trainer | begin training epoch 357
2022-03-06 01:54:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:54:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:55:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:56:02 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 21.326 | ppl 2.62855e+06 | wps 48582.7 | wpb 510.9 | bsz 1 | num_updates 17371 | best_loss 8.449
2022-03-06 01:56:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17371 updates
2022-03-06 01:56:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:56:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:56:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 357 @ 17371 updates, score 21.326) (writing took 1.9156073136255145 seconds)
2022-03-06 01:56:04 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-06 01:56:04 | INFO | train | epoch 357 | loss 0.17 | ppl 1.12 | wps 26741.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 17371 | lr 0.000239932 | gnorm 0.534 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 41646
2022-03-06 01:56:04 | INFO | fairseq.trainer | begin training epoch 358
2022-03-06 01:56:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:57:10 | INFO | train_inner | epoch 358:     29 / 49 loss=0.17, ppl=1.13, wps=27070.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.532, loss_scale=32, train_wall=204, gb_free=8.8, wall=41712
2022-03-06 01:57:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:57:59 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 21.213 | ppl 2.43071e+06 | wps 48720.3 | wpb 510.9 | bsz 1 | num_updates 17420 | best_loss 8.449
2022-03-06 01:57:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17420 updates
2022-03-06 01:57:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:58:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:58:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 358 @ 17420 updates, score 21.213) (writing took 2.012268035672605 seconds)
2022-03-06 01:58:01 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-06 01:58:01 | INFO | train | epoch 358 | loss 0.17 | ppl 1.13 | wps 27268.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17420 | lr 0.000239594 | gnorm 0.531 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 41763
2022-03-06 01:58:01 | INFO | fairseq.trainer | begin training epoch 359
2022-03-06 01:58:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:59:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 01:59:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:59:55 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 21.386 | ppl 2.74008e+06 | wps 48544.2 | wpb 510.9 | bsz 1 | num_updates 17468 | best_loss 8.449
2022-03-06 01:59:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17468 updates
2022-03-06 01:59:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:59:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 01:59:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 359 @ 17468 updates, score 21.386) (writing took 1.8706579422578216 seconds)
2022-03-06 01:59:57 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-06 01:59:57 | INFO | train | epoch 359 | loss 0.168 | ppl 1.12 | wps 26748.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 17468 | lr 0.000239265 | gnorm 0.534 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 41879
2022-03-06 01:59:57 | INFO | fairseq.trainer | begin training epoch 360
2022-03-06 01:59:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:01:10 | INFO | train_inner | epoch 360:     32 / 49 loss=0.169, ppl=1.12, wps=27072.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.531, loss_scale=16, train_wall=204, gb_free=8.8, wall=41952
2022-03-06 02:01:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:01:52 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 21.229 | ppl 2.45805e+06 | wps 48668.2 | wpb 510.9 | bsz 1 | num_updates 17517 | best_loss 8.449
2022-03-06 02:01:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17517 updates
2022-03-06 02:01:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:01:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:01:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 360 @ 17517 updates, score 21.229) (writing took 1.896156320348382 seconds)
2022-03-06 02:01:53 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-06 02:01:53 | INFO | train | epoch 360 | loss 0.168 | ppl 1.12 | wps 27324.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17517 | lr 0.00023893 | gnorm 0.53 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 41995
2022-03-06 02:01:53 | INFO | fairseq.trainer | begin training epoch 361
2022-03-06 02:01:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:03:48 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 21.353 | ppl 2.67911e+06 | wps 48633.4 | wpb 510.9 | bsz 1 | num_updates 17566 | best_loss 8.449
2022-03-06 02:03:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17566 updates
2022-03-06 02:03:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:03:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:03:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 361 @ 17566 updates, score 21.353) (writing took 1.9236320434138179 seconds)
2022-03-06 02:03:50 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-06 02:03:50 | INFO | train | epoch 361 | loss 0.168 | ppl 1.12 | wps 27289.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17566 | lr 0.000238596 | gnorm 0.531 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 42112
2022-03-06 02:03:50 | INFO | fairseq.trainer | begin training epoch 362
2022-03-06 02:03:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:05:07 | INFO | train_inner | epoch 362:     34 / 49 loss=0.167, ppl=1.12, wps=27336.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.53, loss_scale=32, train_wall=202, gb_free=8.8, wall=42189
2022-03-06 02:05:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:05:44 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 21.389 | ppl 2.74636e+06 | wps 48502 | wpb 510.9 | bsz 1 | num_updates 17615 | best_loss 8.449
2022-03-06 02:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17615 updates
2022-03-06 02:05:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:05:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:05:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 362 @ 17615 updates, score 21.389) (writing took 1.8195208385586739 seconds)
2022-03-06 02:05:46 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-06 02:05:46 | INFO | train | epoch 362 | loss 0.167 | ppl 1.12 | wps 27332.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17615 | lr 0.000238264 | gnorm 0.528 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 42228
2022-03-06 02:05:46 | INFO | fairseq.trainer | begin training epoch 363
2022-03-06 02:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:07:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:07:41 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 21.376 | ppl 2.72163e+06 | wps 48757.9 | wpb 510.9 | bsz 1 | num_updates 17664 | best_loss 8.449
2022-03-06 02:07:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17664 updates
2022-03-06 02:07:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:07:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:07:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 363 @ 17664 updates, score 21.376) (writing took 1.8964954651892185 seconds)
2022-03-06 02:07:42 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-06 02:07:42 | INFO | train | epoch 363 | loss 0.166 | ppl 1.12 | wps 27320.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17664 | lr 0.000237933 | gnorm 0.524 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 42345
2022-03-06 02:07:43 | INFO | fairseq.trainer | begin training epoch 364
2022-03-06 02:07:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:09:04 | INFO | train_inner | epoch 364:     36 / 49 loss=0.167, ppl=1.12, wps=27358, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.526, loss_scale=32, train_wall=202, gb_free=8.8, wall=42426
2022-03-06 02:09:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:09:37 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 21.396 | ppl 2.75972e+06 | wps 48503.4 | wpb 510.9 | bsz 1 | num_updates 17713 | best_loss 8.449
2022-03-06 02:09:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17713 updates
2022-03-06 02:09:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:09:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:09:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 364 @ 17713 updates, score 21.396) (writing took 1.8122842097654939 seconds)
2022-03-06 02:09:39 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-06 02:09:39 | INFO | train | epoch 364 | loss 0.167 | ppl 1.12 | wps 27320.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17713 | lr 0.000237604 | gnorm 0.527 | loss_scale 64 | train_wall 99 | gb_free 8.8 | wall 42461
2022-03-06 02:09:39 | INFO | fairseq.trainer | begin training epoch 365
2022-03-06 02:09:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:09:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:11:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:11:33 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 21.394 | ppl 2.75543e+06 | wps 48663.5 | wpb 510.9 | bsz 1 | num_updates 17761 | best_loss 8.449
2022-03-06 02:11:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17761 updates
2022-03-06 02:11:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:11:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:11:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 365 @ 17761 updates, score 21.394) (writing took 1.890923634171486 seconds)
2022-03-06 02:11:35 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-06 02:11:35 | INFO | train | epoch 365 | loss 0.166 | ppl 1.12 | wps 26761.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 17761 | lr 0.000237283 | gnorm 0.53 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 42577
2022-03-06 02:11:35 | INFO | fairseq.trainer | begin training epoch 366
2022-03-06 02:11:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:13:04 | INFO | train_inner | epoch 366:     39 / 49 loss=0.165, ppl=1.12, wps=27093.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.525, loss_scale=32, train_wall=204, gb_free=8.8, wall=42666
2022-03-06 02:13:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:13:30 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 21.393 | ppl 2.75317e+06 | wps 48575.2 | wpb 510.9 | bsz 1 | num_updates 17810 | best_loss 8.449
2022-03-06 02:13:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17810 updates
2022-03-06 02:13:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:13:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:13:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 366 @ 17810 updates, score 21.393) (writing took 1.8386921528726816 seconds)
2022-03-06 02:13:31 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-06 02:13:31 | INFO | train | epoch 366 | loss 0.164 | ppl 1.12 | wps 27326.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17810 | lr 0.000236956 | gnorm 0.522 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 42693
2022-03-06 02:13:31 | INFO | fairseq.trainer | begin training epoch 367
2022-03-06 02:13:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:14:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:15:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:15:26 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 21.43 | ppl 2.82505e+06 | wps 48670.8 | wpb 510.9 | bsz 1 | num_updates 17858 | best_loss 8.449
2022-03-06 02:15:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17858 updates
2022-03-06 02:15:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:15:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:15:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 367 @ 17858 updates, score 21.43) (writing took 1.8985169073566794 seconds)
2022-03-06 02:15:28 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-06 02:15:28 | INFO | train | epoch 367 | loss 0.165 | ppl 1.12 | wps 26761.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 17858 | lr 0.000236638 | gnorm 0.527 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 42810
2022-03-06 02:15:28 | INFO | fairseq.trainer | begin training epoch 368
2022-03-06 02:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:17:03 | INFO | train_inner | epoch 368:     42 / 49 loss=0.164, ppl=1.12, wps=27087.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.524, loss_scale=32, train_wall=204, gb_free=8.8, wall=42905
2022-03-06 02:17:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:17:22 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 21.343 | ppl 2.66033e+06 | wps 48690.7 | wpb 510.9 | bsz 1 | num_updates 17907 | best_loss 8.449
2022-03-06 02:17:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17907 updates
2022-03-06 02:17:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:17:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:17:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 368 @ 17907 updates, score 21.343) (writing took 1.856583789922297 seconds)
2022-03-06 02:17:24 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-06 02:17:24 | INFO | train | epoch 368 | loss 0.163 | ppl 1.12 | wps 27298.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17907 | lr 0.000236314 | gnorm 0.522 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 42926
2022-03-06 02:17:24 | INFO | fairseq.trainer | begin training epoch 369
2022-03-06 02:17:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:19:19 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 21.428 | ppl 2.82235e+06 | wps 48418.9 | wpb 510.9 | bsz 1 | num_updates 17956 | best_loss 8.449
2022-03-06 02:19:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17956 updates
2022-03-06 02:19:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:19:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:19:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 369 @ 17956 updates, score 21.428) (writing took 1.879232034087181 seconds)
2022-03-06 02:19:21 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-06 02:19:21 | INFO | train | epoch 369 | loss 0.164 | ppl 1.12 | wps 27306.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17956 | lr 0.000235991 | gnorm 0.53 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 43043
2022-03-06 02:19:21 | INFO | fairseq.trainer | begin training epoch 370
2022-03-06 02:19:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:20:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:21:03 | INFO | train_inner | epoch 370:     45 / 49 loss=0.164, ppl=1.12, wps=27084.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.531, loss_scale=32, train_wall=204, gb_free=8.8, wall=43145
2022-03-06 02:21:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:21:15 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 21.487 | ppl 2.93872e+06 | wps 48477.3 | wpb 510.9 | bsz 1 | num_updates 18004 | best_loss 8.449
2022-03-06 02:21:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18004 updates
2022-03-06 02:21:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:21:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:21:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 370 @ 18004 updates, score 21.487) (writing took 1.8337149126455188 seconds)
2022-03-06 02:21:17 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-06 02:21:17 | INFO | train | epoch 370 | loss 0.164 | ppl 1.12 | wps 26753.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18004 | lr 0.000235676 | gnorm 0.532 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 43159
2022-03-06 02:21:17 | INFO | fairseq.trainer | begin training epoch 371
2022-03-06 02:21:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:23:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:23:11 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 21.471 | ppl 2.90639e+06 | wps 48681.6 | wpb 510.9 | bsz 1 | num_updates 18053 | best_loss 8.449
2022-03-06 02:23:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18053 updates
2022-03-06 02:23:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:23:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:23:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 371 @ 18053 updates, score 21.471) (writing took 1.8936130655929446 seconds)
2022-03-06 02:23:13 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-06 02:23:13 | INFO | train | epoch 371 | loss 0.162 | ppl 1.12 | wps 27306 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18053 | lr 0.000235356 | gnorm 0.518 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 43275
2022-03-06 02:23:13 | INFO | fairseq.trainer | begin training epoch 372
2022-03-06 02:23:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:25:00 | INFO | train_inner | epoch 372:     47 / 49 loss=0.162, ppl=1.12, wps=27343, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.518, loss_scale=32, train_wall=202, gb_free=8.8, wall=43382
2022-03-06 02:25:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:25:08 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 21.412 | ppl 2.79099e+06 | wps 48791.3 | wpb 510.9 | bsz 1 | num_updates 18102 | best_loss 8.449
2022-03-06 02:25:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18102 updates
2022-03-06 02:25:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:25:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:25:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 372 @ 18102 updates, score 21.412) (writing took 1.8252577474340796 seconds)
2022-03-06 02:25:10 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-06 02:25:10 | INFO | train | epoch 372 | loss 0.162 | ppl 1.12 | wps 27327.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18102 | lr 0.000235037 | gnorm 0.518 | loss_scale 64 | train_wall 99 | gb_free 8.8 | wall 43392
2022-03-06 02:25:10 | INFO | fairseq.trainer | begin training epoch 373
2022-03-06 02:25:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:25:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:27:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:27:04 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 21.47 | ppl 2.90549e+06 | wps 48714.2 | wpb 510.9 | bsz 1 | num_updates 18150 | best_loss 8.449
2022-03-06 02:27:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18150 updates
2022-03-06 02:27:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:27:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:27:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 373 @ 18150 updates, score 21.47) (writing took 1.874981952831149 seconds)
2022-03-06 02:27:06 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-06 02:27:06 | INFO | train | epoch 373 | loss 0.161 | ppl 1.12 | wps 26751.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18150 | lr 0.000234726 | gnorm 0.518 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 43508
2022-03-06 02:27:06 | INFO | fairseq.trainer | begin training epoch 374
2022-03-06 02:27:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:28:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:29:00 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 21.592 | ppl 3.16096e+06 | wps 48606 | wpb 510.9 | bsz 1 | num_updates 18199 | best_loss 8.449
2022-03-06 02:29:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18199 updates
2022-03-06 02:29:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:29:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:29:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 374 @ 18199 updates, score 21.592) (writing took 1.8165350249037147 seconds)
2022-03-06 02:29:02 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-06 02:29:02 | INFO | train | epoch 374 | loss 0.16 | ppl 1.12 | wps 27323.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18199 | lr 0.00023441 | gnorm 0.518 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 43624
2022-03-06 02:29:02 | INFO | fairseq.trainer | begin training epoch 375
2022-03-06 02:29:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:29:05 | INFO | train_inner | epoch 375:      1 / 49 loss=0.161, ppl=1.12, wps=26365.7, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=18200, lr=0.000234404, gnorm=0.52, loss_scale=32, train_wall=203, gb_free=8.8, wall=43627
2022-03-06 02:30:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:30:57 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 21.462 | ppl 2.88922e+06 | wps 48844 | wpb 510.9 | bsz 1 | num_updates 18247 | best_loss 8.449
2022-03-06 02:30:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18247 updates
2022-03-06 02:30:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:30:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:30:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 375 @ 18247 updates, score 21.462) (writing took 1.8986758412793279 seconds)
2022-03-06 02:30:59 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-06 02:30:59 | INFO | train | epoch 375 | loss 0.16 | ppl 1.12 | wps 26764.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18247 | lr 0.000234102 | gnorm 0.514 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 43741
2022-03-06 02:30:59 | INFO | fairseq.trainer | begin training epoch 376
2022-03-06 02:30:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:32:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:32:53 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 21.439 | ppl 2.84399e+06 | wps 48541.5 | wpb 510.9 | bsz 1 | num_updates 18296 | best_loss 8.449
2022-03-06 02:32:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18296 updates
2022-03-06 02:32:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:32:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:32:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 376 @ 18296 updates, score 21.439) (writing took 1.8350576143711805 seconds)
2022-03-06 02:32:55 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-06 02:32:55 | INFO | train | epoch 376 | loss 0.16 | ppl 1.12 | wps 27320 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18296 | lr 0.000233788 | gnorm 0.518 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 43857
2022-03-06 02:32:55 | INFO | fairseq.trainer | begin training epoch 377
2022-03-06 02:32:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:33:04 | INFO | train_inner | epoch 377:      4 / 49 loss=0.16, ppl=1.12, wps=27097.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18300, lr=0.000233762, gnorm=0.516, loss_scale=32, train_wall=204, gb_free=8.8, wall=43866
2022-03-06 02:34:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:34:49 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 21.528 | ppl 3.02476e+06 | wps 48746.2 | wpb 510.9 | bsz 1 | num_updates 18345 | best_loss 8.449
2022-03-06 02:34:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18345 updates
2022-03-06 02:34:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:34:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:34:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 377 @ 18345 updates, score 21.528) (writing took 1.8955240724608302 seconds)
2022-03-06 02:34:51 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-06 02:34:51 | INFO | train | epoch 377 | loss 0.16 | ppl 1.12 | wps 27322 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18345 | lr 0.000233475 | gnorm 0.514 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 43973
2022-03-06 02:34:51 | INFO | fairseq.trainer | begin training epoch 378
2022-03-06 02:34:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:35:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:36:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:36:46 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 21.457 | ppl 2.87944e+06 | wps 48440.5 | wpb 510.9 | bsz 1 | num_updates 18393 | best_loss 8.449
2022-03-06 02:36:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18393 updates
2022-03-06 02:36:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:36:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:36:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 378 @ 18393 updates, score 21.457) (writing took 1.8315289486199617 seconds)
2022-03-06 02:36:48 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-06 02:36:48 | INFO | train | epoch 378 | loss 0.16 | ppl 1.12 | wps 26752.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18393 | lr 0.000233171 | gnorm 0.519 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 44090
2022-03-06 02:36:48 | INFO | fairseq.trainer | begin training epoch 379
2022-03-06 02:36:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:37:03 | INFO | train_inner | epoch 379:      7 / 49 loss=0.159, ppl=1.12, wps=27089.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18400, lr=0.000233126, gnorm=0.515, loss_scale=32, train_wall=204, gb_free=8.8, wall=44106
2022-03-06 02:38:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:38:42 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 21.553 | ppl 3.07576e+06 | wps 48639.1 | wpb 510.9 | bsz 1 | num_updates 18442 | best_loss 8.449
2022-03-06 02:38:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18442 updates
2022-03-06 02:38:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:38:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:38:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 379 @ 18442 updates, score 21.553) (writing took 1.9114165930077434 seconds)
2022-03-06 02:38:44 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-06 02:38:44 | INFO | train | epoch 379 | loss 0.158 | ppl 1.12 | wps 27287.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18442 | lr 0.000232861 | gnorm 0.511 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 44206
2022-03-06 02:38:44 | INFO | fairseq.trainer | begin training epoch 380
2022-03-06 02:38:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:40:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:40:38 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 21.578 | ppl 3.13159e+06 | wps 48704.9 | wpb 510.9 | bsz 1 | num_updates 18491 | best_loss 8.449
2022-03-06 02:40:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18491 updates
2022-03-06 02:40:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:40:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:40:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 380 @ 18491 updates, score 21.578) (writing took 1.8613853845745325 seconds)
2022-03-06 02:40:40 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-06 02:40:40 | INFO | train | epoch 380 | loss 0.158 | ppl 1.12 | wps 27323.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18491 | lr 0.000232552 | gnorm 0.515 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 44322
2022-03-06 02:40:40 | INFO | fairseq.trainer | begin training epoch 381
2022-03-06 02:40:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:40:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:41:03 | INFO | train_inner | epoch 381:     10 / 49 loss=0.158, ppl=1.12, wps=27080.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.514, loss_scale=32, train_wall=204, gb_free=8.8, wall=44345
2022-03-06 02:42:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:42:35 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 21.583 | ppl 3.14133e+06 | wps 48533.5 | wpb 510.9 | bsz 1 | num_updates 18539 | best_loss 8.449
2022-03-06 02:42:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18539 updates
2022-03-06 02:42:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:42:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:42:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 381 @ 18539 updates, score 21.583) (writing took 1.8986353911459446 seconds)
2022-03-06 02:42:37 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-06 02:42:37 | INFO | train | epoch 381 | loss 0.158 | ppl 1.12 | wps 26735.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18539 | lr 0.000232251 | gnorm 0.516 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 44439
2022-03-06 02:42:37 | INFO | fairseq.trainer | begin training epoch 382
2022-03-06 02:42:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:44:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:44:31 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 21.454 | ppl 2.87317e+06 | wps 48610.8 | wpb 510.9 | bsz 1 | num_updates 18588 | best_loss 8.449
2022-03-06 02:44:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18588 updates
2022-03-06 02:44:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:44:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:44:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 382 @ 18588 updates, score 21.454) (writing took 1.8548210933804512 seconds)
2022-03-06 02:44:33 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-06 02:44:33 | INFO | train | epoch 382 | loss 0.157 | ppl 1.12 | wps 27294.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18588 | lr 0.000231944 | gnorm 0.517 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 44555
2022-03-06 02:44:33 | INFO | fairseq.trainer | begin training epoch 383
2022-03-06 02:44:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:45:00 | INFO | train_inner | epoch 383:     12 / 49 loss=0.157, ppl=1.12, wps=27328.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.515, loss_scale=32, train_wall=202, gb_free=8.8, wall=44582
2022-03-06 02:45:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:46:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:46:28 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 21.396 | ppl 2.75982e+06 | wps 48511.1 | wpb 510.9 | bsz 1 | num_updates 18636 | best_loss 8.449
2022-03-06 02:46:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18636 updates
2022-03-06 02:46:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:46:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:46:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 383 @ 18636 updates, score 21.396) (writing took 1.9092179918661714 seconds)
2022-03-06 02:46:29 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-06 02:46:29 | INFO | train | epoch 383 | loss 0.157 | ppl 1.11 | wps 26757 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18636 | lr 0.000231645 | gnorm 0.514 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 44672
2022-03-06 02:46:29 | INFO | fairseq.trainer | begin training epoch 384
2022-03-06 02:46:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:48:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:48:24 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 21.489 | ppl 2.94383e+06 | wps 48735.5 | wpb 510.9 | bsz 1 | num_updates 18685 | best_loss 8.449
2022-03-06 02:48:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18685 updates
2022-03-06 02:48:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:48:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:48:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 384 @ 18685 updates, score 21.489) (writing took 1.8743395125493407 seconds)
2022-03-06 02:48:26 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-06 02:48:26 | INFO | train | epoch 384 | loss 0.155 | ppl 1.11 | wps 27296.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18685 | lr 0.000231341 | gnorm 0.509 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 44788
2022-03-06 02:48:26 | INFO | fairseq.trainer | begin training epoch 385
2022-03-06 02:48:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:49:00 | INFO | train_inner | epoch 385:     15 / 49 loss=0.156, ppl=1.11, wps=27079.9, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.513, loss_scale=32, train_wall=204, gb_free=8.8, wall=44822
2022-03-06 02:50:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:50:20 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 21.452 | ppl 2.86848e+06 | wps 48564.8 | wpb 510.9 | bsz 1 | num_updates 18734 | best_loss 8.449
2022-03-06 02:50:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18734 updates
2022-03-06 02:50:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:50:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:50:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 385 @ 18734 updates, score 21.452) (writing took 1.8931408859789371 seconds)
2022-03-06 02:50:22 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-06 02:50:22 | INFO | train | epoch 385 | loss 0.156 | ppl 1.11 | wps 27303.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18734 | lr 0.000231039 | gnorm 0.513 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 44904
2022-03-06 02:50:22 | INFO | fairseq.trainer | begin training epoch 386
2022-03-06 02:50:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:51:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:52:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:52:17 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 21.488 | ppl 2.94112e+06 | wps 48642.9 | wpb 510.9 | bsz 1 | num_updates 18782 | best_loss 8.449
2022-03-06 02:52:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18782 updates
2022-03-06 02:52:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:52:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:52:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 386 @ 18782 updates, score 21.488) (writing took 1.8526314683258533 seconds)
2022-03-06 02:52:19 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-06 02:52:19 | INFO | train | epoch 386 | loss 0.155 | ppl 1.11 | wps 26756.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18782 | lr 0.000230743 | gnorm 0.509 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 45021
2022-03-06 02:52:19 | INFO | fairseq.trainer | begin training epoch 387
2022-03-06 02:52:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:52:59 | INFO | train_inner | epoch 387:     18 / 49 loss=0.155, ppl=1.11, wps=27085.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.508, loss_scale=32, train_wall=204, gb_free=8.8, wall=45061
2022-03-06 02:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:54:13 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 21.568 | ppl 3.10885e+06 | wps 48686 | wpb 510.9 | bsz 1 | num_updates 18831 | best_loss 8.449
2022-03-06 02:54:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18831 updates
2022-03-06 02:54:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:54:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:54:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 387 @ 18831 updates, score 21.568) (writing took 1.9037710670381784 seconds)
2022-03-06 02:54:15 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-06 02:54:15 | INFO | train | epoch 387 | loss 0.155 | ppl 1.11 | wps 27305.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18831 | lr 0.000230443 | gnorm 0.507 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 45137
2022-03-06 02:54:15 | INFO | fairseq.trainer | begin training epoch 388
2022-03-06 02:54:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:56:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:56:09 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 21.396 | ppl 2.76017e+06 | wps 48707.5 | wpb 510.9 | bsz 1 | num_updates 18880 | best_loss 8.449
2022-03-06 02:56:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18880 updates
2022-03-06 02:56:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:56:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:56:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 388 @ 18880 updates, score 21.396) (writing took 1.8601907696574926 seconds)
2022-03-06 02:56:11 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-06 02:56:11 | INFO | train | epoch 388 | loss 0.155 | ppl 1.11 | wps 27318.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18880 | lr 0.000230144 | gnorm 0.512 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 45253
2022-03-06 02:56:11 | INFO | fairseq.trainer | begin training epoch 389
2022-03-06 02:56:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:56:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:56:59 | INFO | train_inner | epoch 389:     21 / 49 loss=0.155, ppl=1.11, wps=27083.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.511, loss_scale=32, train_wall=204, gb_free=8.8, wall=45301
2022-03-06 02:58:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:58:06 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 21.488 | ppl 2.94214e+06 | wps 48457.7 | wpb 510.9 | bsz 1 | num_updates 18928 | best_loss 8.449
2022-03-06 02:58:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18928 updates
2022-03-06 02:58:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:58:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 02:58:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 389 @ 18928 updates, score 21.488) (writing took 1.8936990927904844 seconds)
2022-03-06 02:58:08 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-06 02:58:08 | INFO | train | epoch 389 | loss 0.154 | ppl 1.11 | wps 26735 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18928 | lr 0.000229852 | gnorm 0.509 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 45370
2022-03-06 02:58:08 | INFO | fairseq.trainer | begin training epoch 390
2022-03-06 02:58:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:59:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:00:02 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 21.428 | ppl 2.82105e+06 | wps 48574.4 | wpb 510.9 | bsz 1 | num_updates 18977 | best_loss 8.449
2022-03-06 03:00:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18977 updates
2022-03-06 03:00:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:00:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:00:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 390 @ 18977 updates, score 21.428) (writing took 1.8465605732053518 seconds)
2022-03-06 03:00:04 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-06 03:00:04 | INFO | train | epoch 390 | loss 0.154 | ppl 1.11 | wps 27313.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18977 | lr 0.000229555 | gnorm 0.512 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 45486
2022-03-06 03:00:04 | INFO | fairseq.trainer | begin training epoch 391
2022-03-06 03:00:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:00:56 | INFO | train_inner | epoch 391:     23 / 49 loss=0.154, ppl=1.11, wps=27334.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.509, loss_scale=32, train_wall=202, gb_free=8.8, wall=45538
2022-03-06 03:01:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:01:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:01:59 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 21.539 | ppl 3.04772e+06 | wps 48549 | wpb 510.9 | bsz 1 | num_updates 19025 | best_loss 8.449
2022-03-06 03:01:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19025 updates
2022-03-06 03:01:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:02:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:02:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 391 @ 19025 updates, score 21.539) (writing took 1.9040532391518354 seconds)
2022-03-06 03:02:00 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-06 03:02:00 | INFO | train | epoch 391 | loss 0.153 | ppl 1.11 | wps 26755.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19025 | lr 0.000229265 | gnorm 0.507 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 45602
2022-03-06 03:02:00 | INFO | fairseq.trainer | begin training epoch 392
2022-03-06 03:02:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:03:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:03:55 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 21.579 | ppl 3.13351e+06 | wps 48136.2 | wpb 510.9 | bsz 1 | num_updates 19074 | best_loss 8.449
2022-03-06 03:03:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19074 updates
2022-03-06 03:03:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:03:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:03:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 392 @ 19074 updates, score 21.579) (writing took 1.8307849429547787 seconds)
2022-03-06 03:03:57 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-06 03:03:57 | INFO | train | epoch 392 | loss 0.152 | ppl 1.11 | wps 27312.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19074 | lr 0.00022897 | gnorm 0.499 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 45719
2022-03-06 03:03:57 | INFO | fairseq.trainer | begin training epoch 393
2022-03-06 03:03:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:04:56 | INFO | train_inner | epoch 393:     26 / 49 loss=0.152, ppl=1.11, wps=27090.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.5, loss_scale=32, train_wall=204, gb_free=8.8, wall=45778
2022-03-06 03:05:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:05:51 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 21.524 | ppl 3.01548e+06 | wps 48681 | wpb 510.9 | bsz 1 | num_updates 19123 | best_loss 8.449
2022-03-06 03:05:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19123 updates
2022-03-06 03:05:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:05:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:05:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 393 @ 19123 updates, score 21.524) (writing took 1.9087673500180244 seconds)
2022-03-06 03:05:53 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-06 03:05:53 | INFO | train | epoch 393 | loss 0.152 | ppl 1.11 | wps 27309.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19123 | lr 0.000228677 | gnorm 0.5 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 45835
2022-03-06 03:05:53 | INFO | fairseq.trainer | begin training epoch 394
2022-03-06 03:05:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:06:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:07:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:07:48 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 21.624 | ppl 3.23094e+06 | wps 48737.2 | wpb 510.9 | bsz 1 | num_updates 19171 | best_loss 8.449
2022-03-06 03:07:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19171 updates
2022-03-06 03:07:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:07:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:07:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 394 @ 19171 updates, score 21.624) (writing took 1.8419741103425622 seconds)
2022-03-06 03:07:49 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-06 03:07:49 | INFO | train | epoch 394 | loss 0.152 | ppl 1.11 | wps 26764.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19171 | lr 0.00022839 | gnorm 0.501 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 45952
2022-03-06 03:07:49 | INFO | fairseq.trainer | begin training epoch 395
2022-03-06 03:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:08:55 | INFO | train_inner | epoch 395:     29 / 49 loss=0.152, ppl=1.11, wps=27088.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.502, loss_scale=32, train_wall=204, gb_free=8.8, wall=46017
2022-03-06 03:09:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:09:44 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 21.555 | ppl 3.08033e+06 | wps 48683.7 | wpb 510.9 | bsz 1 | num_updates 19220 | best_loss 8.449
2022-03-06 03:09:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19220 updates
2022-03-06 03:09:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:09:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:09:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 395 @ 19220 updates, score 21.555) (writing took 1.9137206375598907 seconds)
2022-03-06 03:09:46 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-06 03:09:46 | INFO | train | epoch 395 | loss 0.152 | ppl 1.11 | wps 27304.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19220 | lr 0.000228099 | gnorm 0.502 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 46068
2022-03-06 03:09:46 | INFO | fairseq.trainer | begin training epoch 396
2022-03-06 03:09:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:11:40 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 21.651 | ppl 3.29339e+06 | wps 48772.3 | wpb 510.9 | bsz 1 | num_updates 19269 | best_loss 8.449
2022-03-06 03:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19269 updates
2022-03-06 03:11:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:11:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:11:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 396 @ 19269 updates, score 21.651) (writing took 1.8533680038526654 seconds)
2022-03-06 03:11:42 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-06 03:11:42 | INFO | train | epoch 396 | loss 0.151 | ppl 1.11 | wps 27324.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19269 | lr 0.000227809 | gnorm 0.502 | loss_scale 64 | train_wall 99 | gb_free 8.8 | wall 46184
2022-03-06 03:11:42 | INFO | fairseq.trainer | begin training epoch 397
2022-03-06 03:11:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:11:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:12:55 | INFO | train_inner | epoch 397:     32 / 49 loss=0.151, ppl=1.11, wps=27095.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.502, loss_scale=32, train_wall=204, gb_free=8.8, wall=46257
2022-03-06 03:13:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:13:37 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 21.684 | ppl 3.36978e+06 | wps 48595.2 | wpb 510.9 | bsz 1 | num_updates 19317 | best_loss 8.449
2022-03-06 03:13:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19317 updates
2022-03-06 03:13:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:13:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:13:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 397 @ 19317 updates, score 21.684) (writing took 1.9151397552341223 seconds)
2022-03-06 03:13:39 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-06 03:13:39 | INFO | train | epoch 397 | loss 0.15 | ppl 1.11 | wps 26745.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19317 | lr 0.000227526 | gnorm 0.499 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 46301
2022-03-06 03:13:39 | INFO | fairseq.trainer | begin training epoch 398
2022-03-06 03:13:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:15:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:15:33 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 21.651 | ppl 3.29396e+06 | wps 48548.2 | wpb 510.9 | bsz 1 | num_updates 19366 | best_loss 8.449
2022-03-06 03:15:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19366 updates
2022-03-06 03:15:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:15:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:15:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 398 @ 19366 updates, score 21.651) (writing took 1.8392519373446703 seconds)
2022-03-06 03:15:35 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-06 03:15:35 | INFO | train | epoch 398 | loss 0.151 | ppl 1.11 | wps 27315.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19366 | lr 0.000227238 | gnorm 0.503 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 46417
2022-03-06 03:15:35 | INFO | fairseq.trainer | begin training epoch 399
2022-03-06 03:15:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:16:52 | INFO | train_inner | epoch 399:     34 / 49 loss=0.15, ppl=1.11, wps=27330.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.501, loss_scale=64, train_wall=202, gb_free=8.8, wall=46494
2022-03-06 03:17:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:17:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:17:29 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 21.56 | ppl 3.09111e+06 | wps 48642.5 | wpb 510.9 | bsz 1 | num_updates 19414 | best_loss 8.449
2022-03-06 03:17:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19414 updates
2022-03-06 03:17:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:17:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:17:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 399 @ 19414 updates, score 21.56) (writing took 1.922960358671844 seconds)
2022-03-06 03:17:31 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-06 03:17:31 | INFO | train | epoch 399 | loss 0.15 | ppl 1.11 | wps 26731 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19414 | lr 0.000226956 | gnorm 0.501 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 46533
2022-03-06 03:17:31 | INFO | fairseq.trainer | begin training epoch 400
2022-03-06 03:17:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:19:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:19:26 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 21.656 | ppl 3.30467e+06 | wps 48541.5 | wpb 510.9 | bsz 1 | num_updates 19463 | best_loss 8.449
2022-03-06 03:19:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19463 updates
2022-03-06 03:19:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:19:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:19:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 400 @ 19463 updates, score 21.656) (writing took 1.8512296648696065 seconds)
2022-03-06 03:19:28 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-06 03:19:28 | INFO | train | epoch 400 | loss 0.149 | ppl 1.11 | wps 27314.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19463 | lr 0.000226671 | gnorm 0.501 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 46650
2022-03-06 03:19:28 | INFO | fairseq.trainer | begin training epoch 401
2022-03-06 03:19:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:20:52 | INFO | train_inner | epoch 401:     37 / 49 loss=0.149, ppl=1.11, wps=27081.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.5, loss_scale=32, train_wall=204, gb_free=8.8, wall=46734
2022-03-06 03:21:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:21:22 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 21.694 | ppl 3.39296e+06 | wps 48665.4 | wpb 510.9 | bsz 1 | num_updates 19512 | best_loss 8.449
2022-03-06 03:21:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19512 updates
2022-03-06 03:21:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:21:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:21:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 401 @ 19512 updates, score 21.694) (writing took 1.9017146993428469 seconds)
2022-03-06 03:21:24 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-06 03:21:24 | INFO | train | epoch 401 | loss 0.148 | ppl 1.11 | wps 27303.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19512 | lr 0.000226386 | gnorm 0.5 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 46766
2022-03-06 03:21:24 | INFO | fairseq.trainer | begin training epoch 402
2022-03-06 03:21:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:22:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:23:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:23:19 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 21.709 | ppl 3.42729e+06 | wps 48528.7 | wpb 510.9 | bsz 1 | num_updates 19560 | best_loss 8.449
2022-03-06 03:23:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19560 updates
2022-03-06 03:23:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:23:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:23:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 402 @ 19560 updates, score 21.709) (writing took 1.8639355162158608 seconds)
2022-03-06 03:23:20 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-06 03:23:20 | INFO | train | epoch 402 | loss 0.148 | ppl 1.11 | wps 26749.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19560 | lr 0.000226108 | gnorm 0.496 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 46882
2022-03-06 03:23:20 | INFO | fairseq.trainer | begin training epoch 403
2022-03-06 03:23:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:24:51 | INFO | train_inner | epoch 403:     40 / 49 loss=0.149, ppl=1.11, wps=27081.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.5, loss_scale=32, train_wall=204, gb_free=8.8, wall=46973
2022-03-06 03:25:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:25:15 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 21.742 | ppl 3.50737e+06 | wps 48679 | wpb 510.9 | bsz 1 | num_updates 19609 | best_loss 8.449
2022-03-06 03:25:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19609 updates
2022-03-06 03:25:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:25:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:25:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 403 @ 19609 updates, score 21.742) (writing took 1.8954407554119825 seconds)
2022-03-06 03:25:17 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-06 03:25:17 | INFO | train | epoch 403 | loss 0.148 | ppl 1.11 | wps 27306.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19609 | lr 0.000225825 | gnorm 0.504 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 46999
2022-03-06 03:25:17 | INFO | fairseq.trainer | begin training epoch 404
2022-03-06 03:25:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:27:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:27:11 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 21.825 | ppl 3.71468e+06 | wps 48694.3 | wpb 510.9 | bsz 1 | num_updates 19658 | best_loss 8.449
2022-03-06 03:27:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19658 updates
2022-03-06 03:27:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:27:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:27:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 404 @ 19658 updates, score 21.825) (writing took 1.8957189219072461 seconds)
2022-03-06 03:27:13 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-06 03:27:13 | INFO | train | epoch 404 | loss 0.147 | ppl 1.11 | wps 27298.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19658 | lr 0.000225544 | gnorm 0.495 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 47115
2022-03-06 03:27:13 | INFO | fairseq.trainer | begin training epoch 405
2022-03-06 03:27:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:27:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:28:51 | INFO | train_inner | epoch 405:     43 / 49 loss=0.147, ppl=1.11, wps=27080.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.498, loss_scale=32, train_wall=204, gb_free=8.8, wall=47213
2022-03-06 03:29:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:29:08 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 21.869 | ppl 3.83062e+06 | wps 48582.3 | wpb 510.9 | bsz 1 | num_updates 19706 | best_loss 8.449
2022-03-06 03:29:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19706 updates
2022-03-06 03:29:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:29:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:29:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 405 @ 19706 updates, score 21.869) (writing took 1.9174512214958668 seconds)
2022-03-06 03:29:10 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-06 03:29:10 | INFO | train | epoch 405 | loss 0.147 | ppl 1.11 | wps 26750.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19706 | lr 0.000225269 | gnorm 0.497 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 47232
2022-03-06 03:29:10 | INFO | fairseq.trainer | begin training epoch 406
2022-03-06 03:29:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:31:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:31:04 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 21.835 | ppl 3.74115e+06 | wps 48482.4 | wpb 510.9 | bsz 1 | num_updates 19755 | best_loss 8.449
2022-03-06 03:31:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19755 updates
2022-03-06 03:31:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:31:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:31:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 406 @ 19755 updates, score 21.835) (writing took 1.857185018248856 seconds)
2022-03-06 03:31:06 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-06 03:31:06 | INFO | train | epoch 406 | loss 0.147 | ppl 1.11 | wps 27307.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19755 | lr 0.000224989 | gnorm 0.5 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 47348
2022-03-06 03:31:06 | INFO | fairseq.trainer | begin training epoch 407
2022-03-06 03:31:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:32:48 | INFO | train_inner | epoch 407:     45 / 49 loss=0.147, ppl=1.11, wps=27327.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.497, loss_scale=64, train_wall=202, gb_free=8.8, wall=47450
2022-03-06 03:32:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:32:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:33:01 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 21.716 | ppl 3.44479e+06 | wps 48386.5 | wpb 510.9 | bsz 1 | num_updates 19803 | best_loss 8.449
2022-03-06 03:33:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19803 updates
2022-03-06 03:33:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:33:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:33:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 407 @ 19803 updates, score 21.716) (writing took 1.91549720056355 seconds)
2022-03-06 03:33:02 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-06 03:33:02 | INFO | train | epoch 407 | loss 0.146 | ppl 1.11 | wps 26720.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19803 | lr 0.000224716 | gnorm 0.496 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 47465
2022-03-06 03:33:02 | INFO | fairseq.trainer | begin training epoch 408
2022-03-06 03:33:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:34:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:34:57 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 21.845 | ppl 3.76718e+06 | wps 48617.2 | wpb 510.9 | bsz 1 | num_updates 19852 | best_loss 8.449
2022-03-06 03:34:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19852 updates
2022-03-06 03:34:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:34:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:34:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 408 @ 19852 updates, score 21.845) (writing took 1.9111940283328295 seconds)
2022-03-06 03:34:59 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-06 03:34:59 | INFO | train | epoch 408 | loss 0.146 | ppl 1.11 | wps 27311.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19852 | lr 0.000224439 | gnorm 0.496 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 47581
2022-03-06 03:34:59 | INFO | fairseq.trainer | begin training epoch 409
2022-03-06 03:34:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:36:48 | INFO | train_inner | epoch 409:     48 / 49 loss=0.146, ppl=1.11, wps=27078.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.496, loss_scale=32, train_wall=204, gb_free=8.8, wall=47690
2022-03-06 03:36:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:36:53 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 21.745 | ppl 3.51424e+06 | wps 48588.2 | wpb 510.9 | bsz 1 | num_updates 19901 | best_loss 8.449
2022-03-06 03:36:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19901 updates
2022-03-06 03:36:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:36:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:36:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 409 @ 19901 updates, score 21.745) (writing took 1.9293986661359668 seconds)
2022-03-06 03:36:55 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-06 03:36:55 | INFO | train | epoch 409 | loss 0.145 | ppl 1.11 | wps 27296.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19901 | lr 0.000224162 | gnorm 0.496 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 47697
2022-03-06 03:36:55 | INFO | fairseq.trainer | begin training epoch 410
2022-03-06 03:36:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:38:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:38:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:38:50 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 21.724 | ppl 3.46493e+06 | wps 48585.7 | wpb 510.9 | bsz 1 | num_updates 19949 | best_loss 8.449
2022-03-06 03:38:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19949 updates
2022-03-06 03:38:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:38:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:38:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 410 @ 19949 updates, score 21.724) (writing took 1.9016320677474141 seconds)
2022-03-06 03:38:52 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-06 03:38:52 | INFO | train | epoch 410 | loss 0.145 | ppl 1.11 | wps 26762.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19949 | lr 0.000223892 | gnorm 0.497 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 47814
2022-03-06 03:38:52 | INFO | fairseq.trainer | begin training epoch 411
2022-03-06 03:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:40:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:40:46 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 21.628 | ppl 3.24144e+06 | wps 48561.8 | wpb 510.9 | bsz 1 | num_updates 19998 | best_loss 8.449
2022-03-06 03:40:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 19998 updates
2022-03-06 03:40:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:40:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:40:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 411 @ 19998 updates, score 21.628) (writing took 1.9573526233434677 seconds)
2022-03-06 03:40:48 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-06 03:40:48 | INFO | train | epoch 411 | loss 0.145 | ppl 1.11 | wps 27271.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19998 | lr 0.000223618 | gnorm 0.496 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 47930
2022-03-06 03:40:48 | INFO | fairseq.trainer | begin training epoch 412
2022-03-06 03:40:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:40:53 | INFO | train_inner | epoch 412:      2 / 49 loss=0.145, ppl=1.11, wps=26334.3, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=20000, lr=0.000223607, gnorm=0.498, loss_scale=32, train_wall=203, gb_free=8.8, wall=47935
2022-03-06 03:42:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:42:43 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 21.779 | ppl 3.59956e+06 | wps 48634.7 | wpb 510.9 | bsz 1 | num_updates 20047 | best_loss 8.449
2022-03-06 03:42:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20047 updates
2022-03-06 03:42:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:42:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:42:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 412 @ 20047 updates, score 21.779) (writing took 1.8954596100375056 seconds)
2022-03-06 03:42:44 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-06 03:42:44 | INFO | train | epoch 412 | loss 0.144 | ppl 1.11 | wps 27304.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20047 | lr 0.000223345 | gnorm 0.495 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 48047
2022-03-06 03:42:45 | INFO | fairseq.trainer | begin training epoch 413
2022-03-06 03:42:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:43:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:44:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:44:39 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 21.739 | ppl 3.50045e+06 | wps 48536.5 | wpb 510.9 | bsz 1 | num_updates 20095 | best_loss 8.449
2022-03-06 03:44:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20095 updates
2022-03-06 03:44:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:44:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:44:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 413 @ 20095 updates, score 21.739) (writing took 1.9512526635080576 seconds)
2022-03-06 03:44:41 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-06 03:44:41 | INFO | train | epoch 413 | loss 0.144 | ppl 1.11 | wps 26722.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 20095 | lr 0.000223078 | gnorm 0.5 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 48163
2022-03-06 03:44:41 | INFO | fairseq.trainer | begin training epoch 414
2022-03-06 03:44:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:44:52 | INFO | train_inner | epoch 414:      5 / 49 loss=0.144, ppl=1.11, wps=27066.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20100, lr=0.00022305, gnorm=0.497, loss_scale=32, train_wall=204, gb_free=8.8, wall=48174
2022-03-06 03:46:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:46:35 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 21.796 | ppl 3.64094e+06 | wps 48438.7 | wpb 510.9 | bsz 1 | num_updates 20144 | best_loss 8.449
2022-03-06 03:46:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20144 updates
2022-03-06 03:46:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:46:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:46:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 414 @ 20144 updates, score 21.796) (writing took 1.9306644946336746 seconds)
2022-03-06 03:46:37 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-06 03:46:37 | INFO | train | epoch 414 | loss 0.144 | ppl 1.1 | wps 27293.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20144 | lr 0.000222806 | gnorm 0.499 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 48279
2022-03-06 03:46:37 | INFO | fairseq.trainer | begin training epoch 415
2022-03-06 03:46:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:48:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:48:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:48:32 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 21.816 | ppl 3.69149e+06 | wps 48453.2 | wpb 510.9 | bsz 1 | num_updates 20192 | best_loss 8.449
2022-03-06 03:48:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20192 updates
2022-03-06 03:48:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:48:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:48:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 415 @ 20192 updates, score 21.816) (writing took 2.000799129717052 seconds)
2022-03-06 03:48:34 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-06 03:48:34 | INFO | train | epoch 415 | loss 0.144 | ppl 1.1 | wps 26694.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 20192 | lr 0.000222541 | gnorm 0.491 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 48396
2022-03-06 03:48:34 | INFO | fairseq.trainer | begin training epoch 416
2022-03-06 03:48:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:48:52 | INFO | train_inner | epoch 416:      8 / 49 loss=0.143, ppl=1.1, wps=27049.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.494, loss_scale=32, train_wall=204, gb_free=8.8, wall=48414
2022-03-06 03:50:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:50:29 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 21.794 | ppl 3.63677e+06 | wps 48433.7 | wpb 510.9 | bsz 1 | num_updates 20241 | best_loss 8.449
2022-03-06 03:50:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20241 updates
2022-03-06 03:50:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:50:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:50:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 416 @ 20241 updates, score 21.794) (writing took 1.9366028234362602 seconds)
2022-03-06 03:50:31 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-06 03:50:31 | INFO | train | epoch 416 | loss 0.142 | ppl 1.1 | wps 27276.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20241 | lr 0.000222272 | gnorm 0.491 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 48513
2022-03-06 03:50:31 | INFO | fairseq.trainer | begin training epoch 417
2022-03-06 03:50:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:52:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:52:25 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 21.947 | ppl 4.04436e+06 | wps 48529.8 | wpb 510.9 | bsz 1 | num_updates 20290 | best_loss 8.449
2022-03-06 03:52:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20290 updates
2022-03-06 03:52:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:52:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:52:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 417 @ 20290 updates, score 21.947) (writing took 1.9749496821314096 seconds)
2022-03-06 03:52:27 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-06 03:52:27 | INFO | train | epoch 417 | loss 0.143 | ppl 1.1 | wps 27273.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20290 | lr 0.000222003 | gnorm 0.489 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 48629
2022-03-06 03:52:27 | INFO | fairseq.trainer | begin training epoch 418
2022-03-06 03:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:52:50 | INFO | train_inner | epoch 418:     10 / 49 loss=0.143, ppl=1.1, wps=27307.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.49, loss_scale=32, train_wall=202, gb_free=8.8, wall=48652
2022-03-06 03:53:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:54:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:54:22 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 21.87 | ppl 3.83292e+06 | wps 48030.8 | wpb 510.9 | bsz 1 | num_updates 20338 | best_loss 8.449
2022-03-06 03:54:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20338 updates
2022-03-06 03:54:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:54:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:54:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 418 @ 20338 updates, score 21.87) (writing took 1.9503908855840564 seconds)
2022-03-06 03:54:24 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-06 03:54:24 | INFO | train | epoch 418 | loss 0.142 | ppl 1.1 | wps 26713.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 20338 | lr 0.000221741 | gnorm 0.494 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 48746
2022-03-06 03:54:24 | INFO | fairseq.trainer | begin training epoch 419
2022-03-06 03:54:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:56:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:56:18 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 21.943 | ppl 4.03098e+06 | wps 48706.2 | wpb 510.9 | bsz 1 | num_updates 20387 | best_loss 8.449
2022-03-06 03:56:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20387 updates
2022-03-06 03:56:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:56:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:56:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 419 @ 20387 updates, score 21.943) (writing took 1.9991159290075302 seconds)
2022-03-06 03:56:20 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-06 03:56:20 | INFO | train | epoch 419 | loss 0.142 | ppl 1.1 | wps 27292.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20387 | lr 0.000221474 | gnorm 0.488 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 48862
2022-03-06 03:56:20 | INFO | fairseq.trainer | begin training epoch 420
2022-03-06 03:56:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:56:50 | INFO | train_inner | epoch 420:     13 / 49 loss=0.142, ppl=1.1, wps=27058.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.491, loss_scale=32, train_wall=204, gb_free=8.8, wall=48892
2022-03-06 03:58:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:58:15 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 21.99 | ppl 4.16554e+06 | wps 48534.4 | wpb 510.9 | bsz 1 | num_updates 20436 | best_loss 8.449
2022-03-06 03:58:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20436 updates
2022-03-06 03:58:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:58:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 03:58:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 420 @ 20436 updates, score 21.99) (writing took 1.9482366694137454 seconds)
2022-03-06 03:58:17 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-06 03:58:17 | INFO | train | epoch 420 | loss 0.142 | ppl 1.1 | wps 27273.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20436 | lr 0.000221209 | gnorm 0.496 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 48979
2022-03-06 03:58:17 | INFO | fairseq.trainer | begin training epoch 421
2022-03-06 03:58:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:58:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:00:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:00:11 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 21.774 | ppl 3.58548e+06 | wps 48510.1 | wpb 510.9 | bsz 1 | num_updates 20484 | best_loss 8.449
2022-03-06 04:00:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20484 updates
2022-03-06 04:00:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:00:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:00:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 421 @ 20484 updates, score 21.774) (writing took 2.011521072126925 seconds)
2022-03-06 04:00:13 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-06 04:00:13 | INFO | train | epoch 421 | loss 0.141 | ppl 1.1 | wps 26733.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 20484 | lr 0.000220949 | gnorm 0.485 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 49095
2022-03-06 04:00:13 | INFO | fairseq.trainer | begin training epoch 422
2022-03-06 04:00:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:00:49 | INFO | train_inner | epoch 422:     16 / 49 loss=0.141, ppl=1.1, wps=27060.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.488, loss_scale=32, train_wall=204, gb_free=8.8, wall=49131
2022-03-06 04:02:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:02:07 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 21.895 | ppl 3.89933e+06 | wps 48481.4 | wpb 510.9 | bsz 1 | num_updates 20533 | best_loss 8.449
2022-03-06 04:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20533 updates
2022-03-06 04:02:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:02:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:02:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 422 @ 20533 updates, score 21.895) (writing took 1.9335605576634407 seconds)
2022-03-06 04:02:09 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-06 04:02:09 | INFO | train | epoch 422 | loss 0.141 | ppl 1.1 | wps 27287.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20533 | lr 0.000220685 | gnorm 0.485 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 49211
2022-03-06 04:02:09 | INFO | fairseq.trainer | begin training epoch 423
2022-03-06 04:02:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:03:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:03:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:04:04 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 21.899 | ppl 3.91046e+06 | wps 48677.8 | wpb 510.9 | bsz 1 | num_updates 20581 | best_loss 8.449
2022-03-06 04:04:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20581 updates
2022-03-06 04:04:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:04:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:04:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 423 @ 20581 updates, score 21.899) (writing took 1.9961026972159743 seconds)
2022-03-06 04:04:06 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-06 04:04:06 | INFO | train | epoch 423 | loss 0.14 | ppl 1.1 | wps 26734.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 20581 | lr 0.000220428 | gnorm 0.486 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 49328
2022-03-06 04:04:06 | INFO | fairseq.trainer | begin training epoch 424
2022-03-06 04:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:04:49 | INFO | train_inner | epoch 424:     19 / 49 loss=0.14, ppl=1.1, wps=27058.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.486, loss_scale=32, train_wall=204, gb_free=8.8, wall=49371
2022-03-06 04:05:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:06:00 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 21.81 | ppl 3.67661e+06 | wps 48610 | wpb 510.9 | bsz 1 | num_updates 20630 | best_loss 8.449
2022-03-06 04:06:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20630 updates
2022-03-06 04:06:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:06:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:06:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 424 @ 20630 updates, score 21.81) (writing took 1.9175849510356784 seconds)
2022-03-06 04:06:02 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-06 04:06:02 | INFO | train | epoch 424 | loss 0.14 | ppl 1.1 | wps 27295.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20630 | lr 0.000220166 | gnorm 0.488 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 49444
2022-03-06 04:06:02 | INFO | fairseq.trainer | begin training epoch 425
2022-03-06 04:06:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:07:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:07:57 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 21.895 | ppl 3.90076e+06 | wps 48560.2 | wpb 510.9 | bsz 1 | num_updates 20679 | best_loss 8.449
2022-03-06 04:07:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20679 updates
2022-03-06 04:07:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:07:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:07:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 425 @ 20679 updates, score 21.895) (writing took 2.0271020028740168 seconds)
2022-03-06 04:07:59 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-06 04:07:59 | INFO | train | epoch 425 | loss 0.14 | ppl 1.1 | wps 27245.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20679 | lr 0.000219905 | gnorm 0.488 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 49561
2022-03-06 04:07:59 | INFO | fairseq.trainer | begin training epoch 426
2022-03-06 04:07:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:08:47 | INFO | train_inner | epoch 426:     21 / 49 loss=0.14, ppl=1.1, wps=27308.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.487, loss_scale=32, train_wall=202, gb_free=8.8, wall=49609
2022-03-06 04:08:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:09:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:09:53 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 21.862 | ppl 3.81089e+06 | wps 48292.9 | wpb 510.9 | bsz 1 | num_updates 20727 | best_loss 8.449
2022-03-06 04:09:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20727 updates
2022-03-06 04:09:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:09:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:09:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 426 @ 20727 updates, score 21.862) (writing took 1.9480217415839434 seconds)
2022-03-06 04:09:55 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-06 04:09:55 | INFO | train | epoch 426 | loss 0.14 | ppl 1.1 | wps 26725.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 20727 | lr 0.00021965 | gnorm 0.487 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 49677
2022-03-06 04:09:55 | INFO | fairseq.trainer | begin training epoch 427
2022-03-06 04:09:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:11:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:11:50 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 21.886 | ppl 3.87536e+06 | wps 48395.9 | wpb 510.9 | bsz 1 | num_updates 20776 | best_loss 8.449
2022-03-06 04:11:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20776 updates
2022-03-06 04:11:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:11:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:11:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 427 @ 20776 updates, score 21.886) (writing took 1.98349389154464 seconds)
2022-03-06 04:11:52 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-06 04:11:52 | INFO | train | epoch 427 | loss 0.139 | ppl 1.1 | wps 27284.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20776 | lr 0.000219391 | gnorm 0.481 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 49794
2022-03-06 04:11:52 | INFO | fairseq.trainer | begin training epoch 428
2022-03-06 04:11:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:12:46 | INFO | train_inner | epoch 428:     24 / 49 loss=0.139, ppl=1.1, wps=27060, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.482, loss_scale=32, train_wall=204, gb_free=8.8, wall=49848
2022-03-06 04:13:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:13:46 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 21.875 | ppl 3.84492e+06 | wps 48490.7 | wpb 510.9 | bsz 1 | num_updates 20825 | best_loss 8.449
2022-03-06 04:13:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20825 updates
2022-03-06 04:13:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:13:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:13:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 428 @ 20825 updates, score 21.875) (writing took 1.9352953396737576 seconds)
2022-03-06 04:13:48 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-06 04:13:48 | INFO | train | epoch 428 | loss 0.138 | ppl 1.1 | wps 27296.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20825 | lr 0.000219133 | gnorm 0.483 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 49910
2022-03-06 04:13:48 | INFO | fairseq.trainer | begin training epoch 429
2022-03-06 04:13:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:14:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:15:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:15:43 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 21.844 | ppl 3.76523e+06 | wps 48630.5 | wpb 510.9 | bsz 1 | num_updates 20873 | best_loss 8.449
2022-03-06 04:15:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20873 updates
2022-03-06 04:15:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:15:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:15:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 429 @ 20873 updates, score 21.844) (writing took 1.9613445680588484 seconds)
2022-03-06 04:15:45 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-06 04:15:45 | INFO | train | epoch 429 | loss 0.139 | ppl 1.1 | wps 26718 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 20873 | lr 0.000218881 | gnorm 0.489 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 50027
2022-03-06 04:15:45 | INFO | fairseq.trainer | begin training epoch 430
2022-03-06 04:15:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:16:46 | INFO | train_inner | epoch 430:     27 / 49 loss=0.138, ppl=1.1, wps=27065.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.486, loss_scale=32, train_wall=204, gb_free=8.8, wall=50088
2022-03-06 04:17:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:17:39 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 21.815 | ppl 3.69003e+06 | wps 48500 | wpb 510.9 | bsz 1 | num_updates 20922 | best_loss 8.449
2022-03-06 04:17:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20922 updates
2022-03-06 04:17:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:17:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:17:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 430 @ 20922 updates, score 21.815) (writing took 1.973343314602971 seconds)
2022-03-06 04:17:41 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-06 04:17:41 | INFO | train | epoch 430 | loss 0.138 | ppl 1.1 | wps 27283.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20922 | lr 0.000218624 | gnorm 0.48 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 50143
2022-03-06 04:17:41 | INFO | fairseq.trainer | begin training epoch 431
2022-03-06 04:17:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:19:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:19:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:19:36 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 21.932 | ppl 4.00024e+06 | wps 48570.8 | wpb 510.9 | bsz 1 | num_updates 20970 | best_loss 8.449
2022-03-06 04:19:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20970 updates
2022-03-06 04:19:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:19:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:19:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 431 @ 20970 updates, score 21.932) (writing took 2.0052792746573687 seconds)
2022-03-06 04:19:38 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-06 04:19:38 | INFO | train | epoch 431 | loss 0.137 | ppl 1.1 | wps 26714.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 20970 | lr 0.000218374 | gnorm 0.482 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 50260
2022-03-06 04:19:38 | INFO | fairseq.trainer | begin training epoch 432
2022-03-06 04:19:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:20:46 | INFO | train_inner | epoch 432:     30 / 49 loss=0.137, ppl=1.1, wps=27047.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.479, loss_scale=32, train_wall=204, gb_free=8.8, wall=50328
2022-03-06 04:21:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:21:32 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 21.905 | ppl 3.92628e+06 | wps 48574.4 | wpb 510.9 | bsz 1 | num_updates 21019 | best_loss 8.449
2022-03-06 04:21:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21019 updates
2022-03-06 04:21:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:21:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:21:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 432 @ 21019 updates, score 21.905) (writing took 1.9371422370895743 seconds)
2022-03-06 04:21:34 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-06 04:21:34 | INFO | train | epoch 432 | loss 0.137 | ppl 1.1 | wps 27295.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21019 | lr 0.000218119 | gnorm 0.477 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 50376
2022-03-06 04:21:34 | INFO | fairseq.trainer | begin training epoch 433
2022-03-06 04:21:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:23:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:23:29 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 22.008 | ppl 4.21769e+06 | wps 48585.5 | wpb 510.9 | bsz 1 | num_updates 21068 | best_loss 8.449
2022-03-06 04:23:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21068 updates
2022-03-06 04:23:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:23:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:23:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 433 @ 21068 updates, score 22.008) (writing took 2.0210072845220566 seconds)
2022-03-06 04:23:31 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-06 04:23:31 | INFO | train | epoch 433 | loss 0.137 | ppl 1.1 | wps 27281.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21068 | lr 0.000217865 | gnorm 0.477 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 50493
2022-03-06 04:23:31 | INFO | fairseq.trainer | begin training epoch 434
2022-03-06 04:23:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:24:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:24:45 | INFO | train_inner | epoch 434:     33 / 49 loss=0.137, ppl=1.1, wps=27075, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.48, loss_scale=32, train_wall=204, gb_free=8.8, wall=50567
2022-03-06 04:25:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:25:25 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 21.89 | ppl 3.8857e+06 | wps 48462.2 | wpb 510.9 | bsz 1 | num_updates 21116 | best_loss 8.449
2022-03-06 04:25:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21116 updates
2022-03-06 04:25:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:25:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:25:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 434 @ 21116 updates, score 21.89) (writing took 1.9266886366531253 seconds)
2022-03-06 04:25:27 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-06 04:25:27 | INFO | train | epoch 434 | loss 0.137 | ppl 1.1 | wps 26751.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 21116 | lr 0.000217618 | gnorm 0.487 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 50609
2022-03-06 04:25:27 | INFO | fairseq.trainer | begin training epoch 435
2022-03-06 04:25:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:27:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:27:22 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 21.992 | ppl 4.17217e+06 | wps 48534.1 | wpb 510.9 | bsz 1 | num_updates 21165 | best_loss 8.449
2022-03-06 04:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21165 updates
2022-03-06 04:27:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:27:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:27:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 435 @ 21165 updates, score 21.992) (writing took 1.998822970315814 seconds)
2022-03-06 04:27:24 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-06 04:27:24 | INFO | train | epoch 435 | loss 0.137 | ppl 1.1 | wps 27284 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21165 | lr 0.000217366 | gnorm 0.484 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 50726
2022-03-06 04:27:24 | INFO | fairseq.trainer | begin training epoch 436
2022-03-06 04:27:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:28:43 | INFO | train_inner | epoch 436:     35 / 49 loss=0.137, ppl=1.1, wps=27325.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.486, loss_scale=32, train_wall=202, gb_free=8.8, wall=50805
2022-03-06 04:29:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:29:18 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 22.031 | ppl 4.28585e+06 | wps 48568.9 | wpb 510.9 | bsz 1 | num_updates 21214 | best_loss 8.449
2022-03-06 04:29:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21214 updates
2022-03-06 04:29:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:29:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:29:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 436 @ 21214 updates, score 22.031) (writing took 1.9464326119050384 seconds)
2022-03-06 04:29:20 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-06 04:29:20 | INFO | train | epoch 436 | loss 0.137 | ppl 1.1 | wps 27307.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21214 | lr 0.000217114 | gnorm 0.487 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 50842
2022-03-06 04:29:20 | INFO | fairseq.trainer | begin training epoch 437
2022-03-06 04:29:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:29:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:31:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:31:14 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 21.971 | ppl 4.11156e+06 | wps 48721 | wpb 510.9 | bsz 1 | num_updates 21262 | best_loss 8.449
2022-03-06 04:31:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21262 updates
2022-03-06 04:31:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:31:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:31:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 437 @ 21262 updates, score 21.971) (writing took 1.9701978974044323 seconds)
2022-03-06 04:31:16 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-06 04:31:16 | INFO | train | epoch 437 | loss 0.135 | ppl 1.1 | wps 26725.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 21262 | lr 0.000216869 | gnorm 0.48 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 50958
2022-03-06 04:31:16 | INFO | fairseq.trainer | begin training epoch 438
2022-03-06 04:31:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:32:42 | INFO | train_inner | epoch 438:     38 / 49 loss=0.136, ppl=1.1, wps=27070.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.48, loss_scale=32, train_wall=204, gb_free=8.8, wall=51044
2022-03-06 04:33:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:33:11 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 21.986 | ppl 4.15446e+06 | wps 48463.8 | wpb 510.9 | bsz 1 | num_updates 21311 | best_loss 8.449
2022-03-06 04:33:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21311 updates
2022-03-06 04:33:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:33:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:33:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 438 @ 21311 updates, score 21.986) (writing took 1.9649490164592862 seconds)
2022-03-06 04:33:13 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-06 04:33:13 | INFO | train | epoch 438 | loss 0.135 | ppl 1.1 | wps 27287.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21311 | lr 0.00021662 | gnorm 0.479 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 51075
2022-03-06 04:33:13 | INFO | fairseq.trainer | begin training epoch 439
2022-03-06 04:33:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:33:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 04:35:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:35:07 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 21.928 | ppl 3.99008e+06 | wps 48691.9 | wpb 510.9 | bsz 1 | num_updates 21359 | best_loss 8.449
2022-03-06 04:35:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21359 updates
2022-03-06 04:35:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:35:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:35:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 439 @ 21359 updates, score 21.928) (writing took 1.9764501741155982 seconds)
2022-03-06 04:35:09 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-06 04:35:09 | INFO | train | epoch 439 | loss 0.134 | ppl 1.1 | wps 26732.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 21359 | lr 0.000216376 | gnorm 0.475 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 51191
2022-03-06 04:35:09 | INFO | fairseq.trainer | begin training epoch 440
2022-03-06 04:35:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:36:42 | INFO | train_inner | epoch 440:     41 / 49 loss=0.134, ppl=1.1, wps=27053.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.476, loss_scale=16, train_wall=204, gb_free=8.8, wall=51284
2022-03-06 04:36:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:37:04 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 21.901 | ppl 3.91667e+06 | wps 48555.6 | wpb 510.9 | bsz 1 | num_updates 21408 | best_loss 8.449
2022-03-06 04:37:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21408 updates
2022-03-06 04:37:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:37:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:37:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 440 @ 21408 updates, score 21.901) (writing took 1.9660887457430363 seconds)
2022-03-06 04:37:06 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-06 04:37:06 | INFO | train | epoch 440 | loss 0.135 | ppl 1.1 | wps 27275.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21408 | lr 0.000216128 | gnorm 0.476 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 51308
2022-03-06 04:37:06 | INFO | fairseq.trainer | begin training epoch 441
2022-03-06 04:37:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:38:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:39:00 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 21.971 | ppl 4.11002e+06 | wps 48540.8 | wpb 510.9 | bsz 1 | num_updates 21457 | best_loss 8.449
2022-03-06 04:39:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21457 updates
2022-03-06 04:39:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:39:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:39:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 441 @ 21457 updates, score 21.971) (writing took 2.007553699426353 seconds)
2022-03-06 04:39:02 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-06 04:39:02 | INFO | train | epoch 441 | loss 0.134 | ppl 1.1 | wps 27271.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21457 | lr 0.000215882 | gnorm 0.475 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 51424
2022-03-06 04:39:02 | INFO | fairseq.trainer | begin training epoch 442
2022-03-06 04:39:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:40:40 | INFO | train_inner | epoch 442:     43 / 49 loss=0.134, ppl=1.1, wps=27303.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.473, loss_scale=32, train_wall=202, gb_free=8.8, wall=51522
2022-03-06 04:40:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:40:57 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 22.054 | ppl 4.35381e+06 | wps 48498.7 | wpb 510.9 | bsz 1 | num_updates 21506 | best_loss 8.449
2022-03-06 04:40:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21506 updates
2022-03-06 04:40:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:40:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:40:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 442 @ 21506 updates, score 22.054) (writing took 1.9575002351775765 seconds)
2022-03-06 04:40:59 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-06 04:40:59 | INFO | train | epoch 442 | loss 0.134 | ppl 1.1 | wps 27274.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21506 | lr 0.000215635 | gnorm 0.472 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 51541
2022-03-06 04:40:59 | INFO | fairseq.trainer | begin training epoch 443
2022-03-06 04:40:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:42:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:42:53 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 22.099 | ppl 4.49113e+06 | wps 48558.6 | wpb 510.9 | bsz 1 | num_updates 21555 | best_loss 8.449
2022-03-06 04:42:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21555 updates
2022-03-06 04:42:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:42:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:42:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 443 @ 21555 updates, score 22.099) (writing took 1.984567672945559 seconds)
2022-03-06 04:42:55 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-06 04:42:55 | INFO | train | epoch 443 | loss 0.134 | ppl 1.1 | wps 27282.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21555 | lr 0.00021539 | gnorm 0.474 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 51657
2022-03-06 04:42:55 | INFO | fairseq.trainer | begin training epoch 444
2022-03-06 04:42:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:43:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:44:40 | INFO | train_inner | epoch 444:     46 / 49 loss=0.133, ppl=1.1, wps=27058.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.472, loss_scale=32, train_wall=204, gb_free=8.8, wall=51762
2022-03-06 04:44:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:44:50 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 21.949 | ppl 4.0483e+06 | wps 48579.5 | wpb 510.9 | bsz 1 | num_updates 21603 | best_loss 8.449
2022-03-06 04:44:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21603 updates
2022-03-06 04:44:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:44:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:44:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 444 @ 21603 updates, score 21.949) (writing took 1.954476404003799 seconds)
2022-03-06 04:44:52 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-06 04:44:52 | INFO | train | epoch 444 | loss 0.133 | ppl 1.1 | wps 26722.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 21603 | lr 0.000215151 | gnorm 0.47 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 51774
2022-03-06 04:44:52 | INFO | fairseq.trainer | begin training epoch 445
2022-03-06 04:44:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:46:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:46:46 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 22.008 | ppl 4.2163e+06 | wps 48483.9 | wpb 510.9 | bsz 1 | num_updates 21652 | best_loss 8.449
2022-03-06 04:46:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21652 updates
2022-03-06 04:46:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:46:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:46:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 445 @ 21652 updates, score 22.008) (writing took 2.0020261304453015 seconds)
2022-03-06 04:46:48 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-06 04:46:48 | INFO | train | epoch 445 | loss 0.133 | ppl 1.1 | wps 27253.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21652 | lr 0.000214907 | gnorm 0.468 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 51890
2022-03-06 04:46:48 | INFO | fairseq.trainer | begin training epoch 446
2022-03-06 04:46:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:48:37 | INFO | train_inner | epoch 446:     48 / 49 loss=0.133, ppl=1.1, wps=27291.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.471, loss_scale=32, train_wall=202, gb_free=8.8, wall=51999
2022-03-06 04:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:48:43 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 22.043 | ppl 4.32210e+06 | wps 48559.2 | wpb 510.9 | bsz 1 | num_updates 21701 | best_loss 8.449
2022-03-06 04:48:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21701 updates
2022-03-06 04:48:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:48:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:48:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 446 @ 21701 updates, score 22.043) (writing took 1.9847972448915243 seconds)
2022-03-06 04:48:45 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-06 04:48:45 | INFO | train | epoch 446 | loss 0.133 | ppl 1.1 | wps 27258.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21701 | lr 0.000214664 | gnorm 0.474 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 52007
2022-03-06 04:48:45 | INFO | fairseq.trainer | begin training epoch 447
2022-03-06 04:48:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:48:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:50:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:50:40 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 22.087 | ppl 4.45447e+06 | wps 48458.3 | wpb 510.9 | bsz 1 | num_updates 21749 | best_loss 8.449
2022-03-06 04:50:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21749 updates
2022-03-06 04:50:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:50:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:50:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 447 @ 21749 updates, score 22.087) (writing took 1.9854437494650483 seconds)
2022-03-06 04:50:41 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-06 04:50:41 | INFO | train | epoch 447 | loss 0.132 | ppl 1.1 | wps 26720.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 21749 | lr 0.000214427 | gnorm 0.474 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 52124
2022-03-06 04:50:42 | INFO | fairseq.trainer | begin training epoch 448
2022-03-06 04:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:52:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:52:36 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 22.102 | ppl 4.50194e+06 | wps 48537.2 | wpb 510.9 | bsz 1 | num_updates 21798 | best_loss 8.449
2022-03-06 04:52:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21798 updates
2022-03-06 04:52:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:52:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:52:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 448 @ 21798 updates, score 22.102) (writing took 1.9967513978481293 seconds)
2022-03-06 04:52:38 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-06 04:52:38 | INFO | train | epoch 448 | loss 0.132 | ppl 1.1 | wps 27254.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21798 | lr 0.000214186 | gnorm 0.469 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 52240
2022-03-06 04:52:38 | INFO | fairseq.trainer | begin training epoch 449
2022-03-06 04:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:52:43 | INFO | train_inner | epoch 449:      2 / 49 loss=0.132, ppl=1.1, wps=26296.8, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=21800, lr=0.000214176, gnorm=0.473, loss_scale=32, train_wall=203, gb_free=8.8, wall=52245
2022-03-06 04:53:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:54:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:54:33 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 22.095 | ppl 4.4784e+06 | wps 47916.2 | wpb 510.9 | bsz 1 | num_updates 21846 | best_loss 8.449
2022-03-06 04:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21846 updates
2022-03-06 04:54:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 449 @ 21846 updates, score 22.095) (writing took 1.9969033179804683 seconds)
2022-03-06 04:54:35 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-06 04:54:35 | INFO | train | epoch 449 | loss 0.131 | ppl 1.1 | wps 26709.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 21846 | lr 0.000213951 | gnorm 0.471 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 52357
2022-03-06 04:54:35 | INFO | fairseq.trainer | begin training epoch 450
2022-03-06 04:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:56:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:56:29 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 21.977 | ppl 4.12736e+06 | wps 48373.4 | wpb 510.9 | bsz 1 | num_updates 21895 | best_loss 8.449
2022-03-06 04:56:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21895 updates
2022-03-06 04:56:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:56:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:56:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 450 @ 21895 updates, score 21.977) (writing took 1.969664167612791 seconds)
2022-03-06 04:56:31 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-06 04:56:31 | INFO | train | epoch 450 | loss 0.131 | ppl 1.09 | wps 27288.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21895 | lr 0.000213711 | gnorm 0.465 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 52473
2022-03-06 04:56:31 | INFO | fairseq.trainer | begin training epoch 451
2022-03-06 04:56:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:56:43 | INFO | train_inner | epoch 451:      5 / 49 loss=0.131, ppl=1.1, wps=27054.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21900, lr=0.000213687, gnorm=0.468, loss_scale=32, train_wall=204, gb_free=8.8, wall=52485
2022-03-06 04:58:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:58:26 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 22 | ppl 4.19352e+06 | wps 48446.8 | wpb 510.9 | bsz 1 | num_updates 21944 | best_loss 8.449
2022-03-06 04:58:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21944 updates
2022-03-06 04:58:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:58:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 04:58:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 451 @ 21944 updates, score 22.0) (writing took 1.9891578508540988 seconds)
2022-03-06 04:58:28 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-06 04:58:28 | INFO | train | epoch 451 | loss 0.131 | ppl 1.1 | wps 27268.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21944 | lr 0.000213473 | gnorm 0.473 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 52590
2022-03-06 04:58:28 | INFO | fairseq.trainer | begin training epoch 452
2022-03-06 04:58:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:59:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:00:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:00:22 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 22.232 | ppl 4.92589e+06 | wps 48382.1 | wpb 510.9 | bsz 1 | num_updates 21992 | best_loss 8.449
2022-03-06 05:00:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 21992 updates
2022-03-06 05:00:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:00:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:00:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 452 @ 21992 updates, score 22.232) (writing took 1.9831651905551553 seconds)
2022-03-06 05:00:24 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-06 05:00:24 | INFO | train | epoch 452 | loss 0.13 | ppl 1.09 | wps 26715.2 | ups 0.41 | wpb 64853.3 | bsz 126.7 | num_updates 21992 | lr 0.000213239 | gnorm 0.469 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 52706
2022-03-06 05:00:24 | INFO | fairseq.trainer | begin training epoch 453
2022-03-06 05:00:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:00:42 | INFO | train_inner | epoch 453:      8 / 49 loss=0.131, ppl=1.09, wps=27047.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.471, loss_scale=32, train_wall=204, gb_free=8.8, wall=52724
2022-03-06 05:02:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:02:19 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 22.053 | ppl 4.34983e+06 | wps 48613.4 | wpb 510.9 | bsz 1 | num_updates 22041 | best_loss 8.449
2022-03-06 05:02:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22041 updates
2022-03-06 05:02:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:02:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:02:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 453 @ 22041 updates, score 22.053) (writing took 2.0115319434553385 seconds)
2022-03-06 05:02:21 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-06 05:02:21 | INFO | train | epoch 453 | loss 0.13 | ppl 1.09 | wps 27261.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 22041 | lr 0.000213002 | gnorm 0.467 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 52823
2022-03-06 05:02:21 | INFO | fairseq.trainer | begin training epoch 454
2022-03-06 05:02:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:04:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:04:15 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 22.099 | ppl 4.49104e+06 | wps 48486.5 | wpb 510.9 | bsz 1 | num_updates 22090 | best_loss 8.449
2022-03-06 05:04:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22090 updates
2022-03-06 05:04:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:04:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:04:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 454 @ 22090 updates, score 22.099) (writing took 1.9745481442660093 seconds)
2022-03-06 05:04:17 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-06 05:04:17 | INFO | train | epoch 454 | loss 0.13 | ppl 1.09 | wps 27289.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 22090 | lr 0.000212766 | gnorm 0.467 | loss_scale 64 | train_wall 99 | gb_free 8.8 | wall 52939
2022-03-06 05:04:17 | INFO | fairseq.trainer | begin training epoch 455
2022-03-06 05:04:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:04:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:04:42 | INFO | train_inner | epoch 455:     11 / 49 loss=0.13, ppl=1.09, wps=27052.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.467, loss_scale=32, train_wall=204, gb_free=8.8, wall=52964
2022-03-06 05:06:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:06:12 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 22.103 | ppl 4.50504e+06 | wps 48567.5 | wpb 510.9 | bsz 1 | num_updates 22138 | best_loss 8.449
2022-03-06 05:06:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22138 updates
2022-03-06 05:06:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:06:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:06:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 455 @ 22138 updates, score 22.103) (writing took 2.004569032229483 seconds)
2022-03-06 05:06:14 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-06 05:06:14 | INFO | train | epoch 455 | loss 0.13 | ppl 1.09 | wps 26708.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 22138 | lr 0.000212535 | gnorm 0.472 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 53056
2022-03-06 05:06:14 | INFO | fairseq.trainer | begin training epoch 456
2022-03-06 05:06:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:08:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:08:08 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 22.252 | ppl 4.99457e+06 | wps 48416.4 | wpb 510.9 | bsz 1 | num_updates 22187 | best_loss 8.449
2022-03-06 05:08:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22187 updates
2022-03-06 05:08:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:08:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:08:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 456 @ 22187 updates, score 22.252) (writing took 1.9960656045004725 seconds)
2022-03-06 05:08:10 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-06 05:08:10 | INFO | train | epoch 456 | loss 0.13 | ppl 1.09 | wps 27260.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 22187 | lr 0.0002123 | gnorm 0.471 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 53172
2022-03-06 05:08:10 | INFO | fairseq.trainer | begin training epoch 457
2022-03-06 05:08:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:08:40 | INFO | train_inner | epoch 457:     13 / 49 loss=0.13, ppl=1.09, wps=27292.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.47, loss_scale=32, train_wall=202, gb_free=8.8, wall=53202
2022-03-06 05:09:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:10:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:10:05 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 22.199 | ppl 4.81315e+06 | wps 48591.9 | wpb 510.9 | bsz 1 | num_updates 22235 | best_loss 8.449
2022-03-06 05:10:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22235 updates
2022-03-06 05:10:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:10:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:10:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 457 @ 22235 updates, score 22.199) (writing took 2.0227100495249033 seconds)
2022-03-06 05:10:07 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-06 05:10:07 | INFO | train | epoch 457 | loss 0.129 | ppl 1.09 | wps 26707.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 22235 | lr 0.000212071 | gnorm 0.465 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 53289
2022-03-06 05:10:07 | INFO | fairseq.trainer | begin training epoch 458
2022-03-06 05:10:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:11:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:12:01 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 22.119 | ppl 4.55573e+06 | wps 48581.2 | wpb 510.9 | bsz 1 | num_updates 22284 | best_loss 8.449
2022-03-06 05:12:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22284 updates
2022-03-06 05:12:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:12:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:12:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 458 @ 22284 updates, score 22.119) (writing took 1.9582132073119283 seconds)
2022-03-06 05:12:03 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-06 05:12:03 | INFO | train | epoch 458 | loss 0.129 | ppl 1.09 | wps 27277.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 22284 | lr 0.000211838 | gnorm 0.467 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 53405
2022-03-06 05:12:03 | INFO | fairseq.trainer | begin training epoch 459
2022-03-06 05:12:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:12:40 | INFO | train_inner | epoch 459:     16 / 49 loss=0.128, ppl=1.09, wps=27050.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=22300, lr=0.000211762, gnorm=0.465, loss_scale=32, train_wall=204, gb_free=8.8, wall=53442
2022-03-06 05:13:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:13:58 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 22.083 | ppl 4.44281e+06 | wps 48424.1 | wpb 510.9 | bsz 1 | num_updates 22333 | best_loss 8.449
2022-03-06 05:13:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22333 updates
2022-03-06 05:13:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:14:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:14:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 459 @ 22333 updates, score 22.083) (writing took 2.0284360870718956 seconds)
2022-03-06 05:14:00 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-06 05:14:00 | INFO | train | epoch 459 | loss 0.128 | ppl 1.09 | wps 27261.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 22333 | lr 0.000211605 | gnorm 0.462 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 53522
2022-03-06 05:14:00 | INFO | fairseq.trainer | begin training epoch 460
2022-03-06 05:14:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:14:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:15:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:15:54 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 22.026 | ppl 4.26917e+06 | wps 48675.5 | wpb 510.9 | bsz 1 | num_updates 22381 | best_loss 8.449
2022-03-06 05:15:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22381 updates
2022-03-06 05:15:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:15:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:15:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 460 @ 22381 updates, score 22.026) (writing took 2.0124349845573306 seconds)
2022-03-06 05:15:56 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-06 05:15:56 | INFO | train | epoch 460 | loss 0.128 | ppl 1.09 | wps 26726.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 22381 | lr 0.000211378 | gnorm 0.466 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 53638
2022-03-06 05:15:56 | INFO | fairseq.trainer | begin training epoch 461
2022-03-06 05:15:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:16:40 | INFO | train_inner | epoch 461:     19 / 49 loss=0.128, ppl=1.09, wps=27043.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.465, loss_scale=32, train_wall=204, gb_free=8.8, wall=53682
2022-03-06 05:17:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:17:51 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 22.148 | ppl 4.64792e+06 | wps 48546.2 | wpb 510.9 | bsz 1 | num_updates 22430 | best_loss 8.449
2022-03-06 05:17:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22430 updates
2022-03-06 05:17:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:17:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 461 @ 22430 updates, score 22.148) (writing took 2.036709346808493 seconds)
2022-03-06 05:17:53 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-06 05:17:53 | INFO | train | epoch 461 | loss 0.128 | ppl 1.09 | wps 27256.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 22430 | lr 0.000211147 | gnorm 0.464 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 53755
2022-03-06 05:17:53 | INFO | fairseq.trainer | begin training epoch 462
2022-03-06 05:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:19:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:19:48 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 22.037 | ppl 4.30328e+06 | wps 48587.9 | wpb 510.9 | bsz 1 | num_updates 22479 | best_loss 8.449
2022-03-06 05:19:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22479 updates
2022-03-06 05:19:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:19:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:19:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 462 @ 22479 updates, score 22.037) (writing took 1.9762681424617767 seconds)
2022-03-06 05:19:50 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-06 05:19:50 | INFO | train | epoch 462 | loss 0.128 | ppl 1.09 | wps 27268.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 22479 | lr 0.000210917 | gnorm 0.464 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 53872
2022-03-06 05:19:50 | INFO | fairseq.trainer | begin training epoch 463
2022-03-06 05:19:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:20:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:20:39 | INFO | train_inner | epoch 463:     22 / 49 loss=0.128, ppl=1.09, wps=27040.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.464, loss_scale=32, train_wall=204, gb_free=8.8, wall=53921
2022-03-06 05:21:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:21:44 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 22.088 | ppl 4.45916e+06 | wps 48635.4 | wpb 510.9 | bsz 1 | num_updates 22527 | best_loss 8.449
2022-03-06 05:21:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22527 updates
2022-03-06 05:21:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:21:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:21:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 463 @ 22527 updates, score 22.088) (writing took 2.012663188390434 seconds)
2022-03-06 05:21:46 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-06 05:21:46 | INFO | train | epoch 463 | loss 0.127 | ppl 1.09 | wps 26707.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 22527 | lr 0.000210692 | gnorm 0.465 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 53988
2022-03-06 05:21:46 | INFO | fairseq.trainer | begin training epoch 464
2022-03-06 05:21:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:23:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:23:41 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 22.117 | ppl 4.5479e+06 | wps 48440.9 | wpb 510.9 | bsz 1 | num_updates 22576 | best_loss 8.449
2022-03-06 05:23:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22576 updates
2022-03-06 05:23:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:23:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:23:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 464 @ 22576 updates, score 22.117) (writing took 1.974295706488192 seconds)
2022-03-06 05:23:43 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-06 05:23:43 | INFO | train | epoch 464 | loss 0.127 | ppl 1.09 | wps 27273.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 22576 | lr 0.000210463 | gnorm 0.469 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 54105
2022-03-06 05:23:43 | INFO | fairseq.trainer | begin training epoch 465
2022-03-06 05:23:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:24:37 | INFO | train_inner | epoch 465:     24 / 49 loss=0.127, ppl=1.09, wps=27306.2, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.467, loss_scale=32, train_wall=202, gb_free=8.8, wall=54159
2022-03-06 05:25:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:25:37 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 22.06 | ppl 4.37252e+06 | wps 48446.2 | wpb 510.9 | bsz 1 | num_updates 22625 | best_loss 8.449
2022-03-06 05:25:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22625 updates
2022-03-06 05:25:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:25:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:25:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 465 @ 22625 updates, score 22.06) (writing took 2.030192614533007 seconds)
2022-03-06 05:25:39 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-06 05:25:39 | INFO | train | epoch 465 | loss 0.127 | ppl 1.09 | wps 27257.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 22625 | lr 0.000210235 | gnorm 0.464 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 54221
2022-03-06 05:25:39 | INFO | fairseq.trainer | begin training epoch 466
2022-03-06 05:25:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:25:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:27:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:27:34 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 22.185 | ppl 4.76877e+06 | wps 48427.2 | wpb 510.9 | bsz 1 | num_updates 22673 | best_loss 8.449
2022-03-06 05:27:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22673 updates
2022-03-06 05:27:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:27:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:27:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 466 @ 22673 updates, score 22.185) (writing took 2.002694606781006 seconds)
2022-03-06 05:27:36 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-06 05:27:36 | INFO | train | epoch 466 | loss 0.127 | ppl 1.09 | wps 26708.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 22673 | lr 0.000210013 | gnorm 0.467 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 54338
2022-03-06 05:27:36 | INFO | fairseq.trainer | begin training epoch 467
2022-03-06 05:27:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:28:37 | INFO | train_inner | epoch 467:     27 / 49 loss=0.127, ppl=1.09, wps=27033.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.463, loss_scale=32, train_wall=205, gb_free=8.8, wall=54399
2022-03-06 05:29:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:29:30 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 22.251 | ppl 4.99179e+06 | wps 48650.2 | wpb 510.9 | bsz 1 | num_updates 22722 | best_loss 8.449
2022-03-06 05:29:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22722 updates
2022-03-06 05:29:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:29:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:29:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 467 @ 22722 updates, score 22.251) (writing took 2.013539679348469 seconds)
2022-03-06 05:29:32 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-06 05:29:32 | INFO | train | epoch 467 | loss 0.126 | ppl 1.09 | wps 27248.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 22722 | lr 0.000209786 | gnorm 0.458 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 54454
2022-03-06 05:29:32 | INFO | fairseq.trainer | begin training epoch 468
2022-03-06 05:29:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:31:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:31:27 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 22.127 | ppl 4.57956e+06 | wps 48470.3 | wpb 510.9 | bsz 1 | num_updates 22771 | best_loss 8.449
2022-03-06 05:31:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22771 updates
2022-03-06 05:31:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:31:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:31:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 468 @ 22771 updates, score 22.127) (writing took 1.9882177049294114 seconds)
2022-03-06 05:31:29 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-06 05:31:29 | INFO | train | epoch 468 | loss 0.125 | ppl 1.09 | wps 27285.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 22771 | lr 0.00020956 | gnorm 0.457 | loss_scale 64 | train_wall 99 | gb_free 8.8 | wall 54571
2022-03-06 05:31:29 | INFO | fairseq.trainer | begin training epoch 469
2022-03-06 05:31:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:31:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:32:37 | INFO | train_inner | epoch 469:     30 / 49 loss=0.125, ppl=1.09, wps=27039.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.457, loss_scale=32, train_wall=204, gb_free=8.8, wall=54639
2022-03-06 05:33:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:33:23 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 22.108 | ppl 4.52095e+06 | wps 48468.4 | wpb 510.9 | bsz 1 | num_updates 22819 | best_loss 8.449
2022-03-06 05:33:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22819 updates
2022-03-06 05:33:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:33:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:33:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 469 @ 22819 updates, score 22.108) (writing took 2.0139935379847884 seconds)
2022-03-06 05:33:25 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-06 05:33:25 | INFO | train | epoch 469 | loss 0.125 | ppl 1.09 | wps 26701.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 22819 | lr 0.00020934 | gnorm 0.457 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 54687
2022-03-06 05:33:25 | INFO | fairseq.trainer | begin training epoch 470
2022-03-06 05:33:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:35:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:35:20 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 22.207 | ppl 4.84269e+06 | wps 48475.3 | wpb 510.9 | bsz 1 | num_updates 22868 | best_loss 8.449
2022-03-06 05:35:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22868 updates
2022-03-06 05:35:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:35:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:35:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 470 @ 22868 updates, score 22.207) (writing took 1.9819590980187058 seconds)
2022-03-06 05:35:22 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-06 05:35:22 | INFO | train | epoch 470 | loss 0.126 | ppl 1.09 | wps 27283.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 22868 | lr 0.000209115 | gnorm 0.463 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 54804
2022-03-06 05:35:22 | INFO | fairseq.trainer | begin training epoch 471
2022-03-06 05:35:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:36:34 | INFO | train_inner | epoch 471:     32 / 49 loss=0.126, ppl=1.09, wps=27308.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.46, loss_scale=64, train_wall=202, gb_free=8.8, wall=54877
2022-03-06 05:36:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:37:16 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 22.059 | ppl 4.37043e+06 | wps 48583.6 | wpb 510.9 | bsz 1 | num_updates 22916 | best_loss 8.449
2022-03-06 05:37:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22916 updates
2022-03-06 05:37:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:37:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:37:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 471 @ 22916 updates, score 22.059) (writing took 1.9997976152226329 seconds)
2022-03-06 05:37:18 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-06 05:37:18 | INFO | train | epoch 471 | loss 0.125 | ppl 1.09 | wps 26712.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 22916 | lr 0.000208896 | gnorm 0.458 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 54920
2022-03-06 05:37:18 | INFO | fairseq.trainer | begin training epoch 472
2022-03-06 05:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:39:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:39:13 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 22.109 | ppl 4.52417e+06 | wps 48345.1 | wpb 510.9 | bsz 1 | num_updates 22965 | best_loss 8.449
2022-03-06 05:39:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22965 updates
2022-03-06 05:39:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:39:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:39:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 472 @ 22965 updates, score 22.109) (writing took 1.9925140962004662 seconds)
2022-03-06 05:39:15 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-06 05:39:15 | INFO | train | epoch 472 | loss 0.126 | ppl 1.09 | wps 27267.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 22965 | lr 0.000208673 | gnorm 0.464 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 55037
2022-03-06 05:39:15 | INFO | fairseq.trainer | begin training epoch 473
2022-03-06 05:39:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:40:34 | INFO | train_inner | epoch 473:     35 / 49 loss=0.125, ppl=1.09, wps=27042.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.463, loss_scale=32, train_wall=204, gb_free=8.8, wall=55116
2022-03-06 05:41:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:41:10 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 22.262 | ppl 5.02832e+06 | wps 48396.6 | wpb 510.9 | bsz 1 | num_updates 23014 | best_loss 8.449
2022-03-06 05:41:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23014 updates
2022-03-06 05:41:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:41:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:41:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 473 @ 23014 updates, score 22.262) (writing took 1.9953216351568699 seconds)
2022-03-06 05:41:12 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-06 05:41:12 | INFO | train | epoch 473 | loss 0.125 | ppl 1.09 | wps 27255.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23014 | lr 0.000208451 | gnorm 0.459 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 55154
2022-03-06 05:41:12 | INFO | fairseq.trainer | begin training epoch 474
2022-03-06 05:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:41:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:43:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:43:06 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 22.282 | ppl 5.09871e+06 | wps 48499.4 | wpb 510.9 | bsz 1 | num_updates 23062 | best_loss 8.449
2022-03-06 05:43:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23062 updates
2022-03-06 05:43:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:43:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:43:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 474 @ 23062 updates, score 22.282) (writing took 1.9797264728695154 seconds)
2022-03-06 05:43:08 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-06 05:43:08 | INFO | train | epoch 474 | loss 0.125 | ppl 1.09 | wps 26704 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 23062 | lr 0.000208234 | gnorm 0.457 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 55270
2022-03-06 05:43:08 | INFO | fairseq.trainer | begin training epoch 475
2022-03-06 05:43:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:44:34 | INFO | train_inner | epoch 475:     38 / 49 loss=0.125, ppl=1.09, wps=27042.2, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.457, loss_scale=32, train_wall=204, gb_free=8.8, wall=55356
2022-03-06 05:44:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:45:03 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 22.201 | ppl 4.81968e+06 | wps 48493.8 | wpb 510.9 | bsz 1 | num_updates 23111 | best_loss 8.449
2022-03-06 05:45:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23111 updates
2022-03-06 05:45:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:45:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:45:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 475 @ 23111 updates, score 22.201) (writing took 2.032013221643865 seconds)
2022-03-06 05:45:05 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-06 05:45:05 | INFO | train | epoch 475 | loss 0.124 | ppl 1.09 | wps 27268 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23111 | lr 0.000208013 | gnorm 0.459 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 55387
2022-03-06 05:45:05 | INFO | fairseq.trainer | begin training epoch 476
2022-03-06 05:45:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:46:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:46:59 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 22.208 | ppl 4.84470e+06 | wps 48607.9 | wpb 510.9 | bsz 1 | num_updates 23160 | best_loss 8.449
2022-03-06 05:46:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23160 updates
2022-03-06 05:46:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:47:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:47:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 476 @ 23160 updates, score 22.208) (writing took 2.0248933220282197 seconds)
2022-03-06 05:47:01 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-06 05:47:01 | INFO | train | epoch 476 | loss 0.124 | ppl 1.09 | wps 27266 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23160 | lr 0.000207793 | gnorm 0.458 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 55503
2022-03-06 05:47:01 | INFO | fairseq.trainer | begin training epoch 477
2022-03-06 05:47:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:47:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:48:34 | INFO | train_inner | epoch 477:     41 / 49 loss=0.124, ppl=1.09, wps=27035.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.458, loss_scale=32, train_wall=204, gb_free=8.8, wall=55596
2022-03-06 05:48:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:48:56 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 22.222 | ppl 4.89281e+06 | wps 48245.3 | wpb 510.9 | bsz 1 | num_updates 23208 | best_loss 8.449
2022-03-06 05:48:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23208 updates
2022-03-06 05:48:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:48:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:48:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 477 @ 23208 updates, score 22.222) (writing took 1.984156402759254 seconds)
2022-03-06 05:48:58 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-06 05:48:58 | INFO | train | epoch 477 | loss 0.124 | ppl 1.09 | wps 26705.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 23208 | lr 0.000207578 | gnorm 0.457 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 55620
2022-03-06 05:48:58 | INFO | fairseq.trainer | begin training epoch 478
2022-03-06 05:48:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:50:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:50:52 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 22.207 | ppl 4.83978e+06 | wps 48532.5 | wpb 510.9 | bsz 1 | num_updates 23257 | best_loss 8.449
2022-03-06 05:50:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23257 updates
2022-03-06 05:50:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:50:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:50:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 478 @ 23257 updates, score 22.207) (writing took 1.9823078820481896 seconds)
2022-03-06 05:50:54 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-06 05:50:54 | INFO | train | epoch 478 | loss 0.123 | ppl 1.09 | wps 27270.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23257 | lr 0.000207359 | gnorm 0.457 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 55736
2022-03-06 05:50:54 | INFO | fairseq.trainer | begin training epoch 479
2022-03-06 05:50:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:52:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:52:34 | INFO | train_inner | epoch 479:     44 / 49 loss=0.123, ppl=1.09, wps=27052.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.456, loss_scale=32, train_wall=204, gb_free=8.8, wall=55836
2022-03-06 05:52:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:52:49 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 22.218 | ppl 4.87876e+06 | wps 48453.5 | wpb 510.9 | bsz 1 | num_updates 23305 | best_loss 8.449
2022-03-06 05:52:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23305 updates
2022-03-06 05:52:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:52:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:52:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 479 @ 23305 updates, score 22.218) (writing took 1.9635569360107183 seconds)
2022-03-06 05:52:51 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-06 05:52:51 | INFO | train | epoch 479 | loss 0.123 | ppl 1.09 | wps 26728.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 23305 | lr 0.000207145 | gnorm 0.454 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 55853
2022-03-06 05:52:51 | INFO | fairseq.trainer | begin training epoch 480
2022-03-06 05:52:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:54:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 05:54:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:54:45 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 22.267 | ppl 5.04548e+06 | wps 48510.8 | wpb 510.9 | bsz 1 | num_updates 23353 | best_loss 8.449
2022-03-06 05:54:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23353 updates
2022-03-06 05:54:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:54:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:54:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 480 @ 23353 updates, score 22.267) (writing took 1.9831902477890253 seconds)
2022-03-06 05:54:47 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-06 05:54:47 | INFO | train | epoch 480 | loss 0.122 | ppl 1.09 | wps 26694.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 23353 | lr 0.000206932 | gnorm 0.455 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 55969
2022-03-06 05:54:47 | INFO | fairseq.trainer | begin training epoch 481
2022-03-06 05:54:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:56:34 | INFO | train_inner | epoch 481:     47 / 49 loss=0.122, ppl=1.09, wps=27046.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.453, loss_scale=16, train_wall=204, gb_free=8.8, wall=56076
2022-03-06 05:56:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:56:42 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 22.225 | ppl 4.9009e+06 | wps 48324.3 | wpb 510.9 | bsz 1 | num_updates 23402 | best_loss 8.449
2022-03-06 05:56:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23402 updates
2022-03-06 05:56:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:56:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:56:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 481 @ 23402 updates, score 22.225) (writing took 1.980990699492395 seconds)
2022-03-06 05:56:44 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-06 05:56:44 | INFO | train | epoch 481 | loss 0.122 | ppl 1.09 | wps 27282.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23402 | lr 0.000206716 | gnorm 0.451 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 56086
2022-03-06 05:56:44 | INFO | fairseq.trainer | begin training epoch 482
2022-03-06 05:56:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:58:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:58:38 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 22.177 | ppl 4.74161e+06 | wps 48507.3 | wpb 510.9 | bsz 1 | num_updates 23451 | best_loss 8.449
2022-03-06 05:58:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23451 updates
2022-03-06 05:58:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:58:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 05:58:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 482 @ 23451 updates, score 22.177) (writing took 1.9885267987847328 seconds)
2022-03-06 05:58:40 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-06 05:58:40 | INFO | train | epoch 482 | loss 0.122 | ppl 1.09 | wps 27266.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23451 | lr 0.0002065 | gnorm 0.455 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 56202
2022-03-06 05:58:40 | INFO | fairseq.trainer | begin training epoch 483
2022-03-06 05:58:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:00:30 | INFO | train_inner | epoch 483:     49 / 49 loss=0.123, ppl=1.09, wps=27284.8, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=23500, lr=0.000206284, gnorm=0.457, loss_scale=32, train_wall=201, gb_free=8.8, wall=56312
2022-03-06 06:00:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:00:35 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 22.314 | ppl 5.21397e+06 | wps 48357 | wpb 510.9 | bsz 1 | num_updates 23500 | best_loss 8.449
2022-03-06 06:00:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23500 updates
2022-03-06 06:00:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:00:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:00:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 483 @ 23500 updates, score 22.314) (writing took 1.9624237911775708 seconds)
2022-03-06 06:00:37 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-06 06:00:37 | INFO | train | epoch 483 | loss 0.123 | ppl 1.09 | wps 27269.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23500 | lr 0.000206284 | gnorm 0.456 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 56319
2022-03-06 06:00:37 | INFO | fairseq.trainer | begin training epoch 484
2022-03-06 06:00:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:02:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:02:32 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 22.316 | ppl 5.22134e+06 | wps 48503.6 | wpb 510.9 | bsz 1 | num_updates 23549 | best_loss 8.449
2022-03-06 06:02:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23549 updates
2022-03-06 06:02:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:02:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:02:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 484 @ 23549 updates, score 22.316) (writing took 1.9799320315942168 seconds)
2022-03-06 06:02:34 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-06 06:02:34 | INFO | train | epoch 484 | loss 0.122 | ppl 1.09 | wps 27257.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23549 | lr 0.00020607 | gnorm 0.453 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 56436
2022-03-06 06:02:34 | INFO | fairseq.trainer | begin training epoch 485
2022-03-06 06:02:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:04:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:04:28 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 22.269 | ppl 5.05273e+06 | wps 48496.1 | wpb 510.9 | bsz 1 | num_updates 23598 | best_loss 8.449
2022-03-06 06:04:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23598 updates
2022-03-06 06:04:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:04:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:04:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 485 @ 23598 updates, score 22.269) (writing took 2.0120752854272723 seconds)
2022-03-06 06:04:30 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-06 06:04:30 | INFO | train | epoch 485 | loss 0.122 | ppl 1.09 | wps 27260.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23598 | lr 0.000205855 | gnorm 0.456 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 56552
2022-03-06 06:04:30 | INFO | fairseq.trainer | begin training epoch 486
2022-03-06 06:04:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:04:35 | INFO | train_inner | epoch 486:      2 / 49 loss=0.122, ppl=1.09, wps=26548.8, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=23600, lr=0.000205847, gnorm=0.455, loss_scale=32, train_wall=202, gb_free=8.8, wall=56557
2022-03-06 06:04:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:06:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:06:25 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 22.36 | ppl 5.38449e+06 | wps 48514 | wpb 510.9 | bsz 1 | num_updates 23646 | best_loss 8.449
2022-03-06 06:06:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23646 updates
2022-03-06 06:06:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:06:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:06:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 486 @ 23646 updates, score 22.36) (writing took 2.004397758282721 seconds)
2022-03-06 06:06:27 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-06 06:06:27 | INFO | train | epoch 486 | loss 0.121 | ppl 1.09 | wps 26715.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 23646 | lr 0.000205646 | gnorm 0.455 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 56669
2022-03-06 06:06:27 | INFO | fairseq.trainer | begin training epoch 487
2022-03-06 06:06:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:08:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:08:21 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 22.414 | ppl 5.5881e+06 | wps 49264.5 | wpb 510.9 | bsz 1 | num_updates 23695 | best_loss 8.449
2022-03-06 06:08:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23695 updates
2022-03-06 06:08:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:08:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:08:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 487 @ 23695 updates, score 22.414) (writing took 2.0345874782651663 seconds)
2022-03-06 06:08:23 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-06 06:08:23 | INFO | train | epoch 487 | loss 0.122 | ppl 1.09 | wps 27273.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23695 | lr 0.000205434 | gnorm 0.458 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 56785
2022-03-06 06:08:23 | INFO | fairseq.trainer | begin training epoch 488
2022-03-06 06:08:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:08:35 | INFO | train_inner | epoch 488:      5 / 49 loss=0.121, ppl=1.09, wps=27049.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=23700, lr=0.000205412, gnorm=0.457, loss_scale=32, train_wall=204, gb_free=8.8, wall=56797
2022-03-06 06:10:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:10:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:10:18 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 22.351 | ppl 5.34998e+06 | wps 48351.7 | wpb 510.9 | bsz 1 | num_updates 23743 | best_loss 8.449
2022-03-06 06:10:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23743 updates
2022-03-06 06:10:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:10:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:10:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 488 @ 23743 updates, score 22.351) (writing took 1.9740954795852304 seconds)
2022-03-06 06:10:20 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-06 06:10:20 | INFO | train | epoch 488 | loss 0.12 | ppl 1.09 | wps 26711.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 23743 | lr 0.000205226 | gnorm 0.452 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 56902
2022-03-06 06:10:20 | INFO | fairseq.trainer | begin training epoch 489
2022-03-06 06:10:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:12:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:12:14 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 22.407 | ppl 5.56048e+06 | wps 48478 | wpb 510.9 | bsz 1 | num_updates 23792 | best_loss 8.449
2022-03-06 06:12:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23792 updates
2022-03-06 06:12:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:12:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:12:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 489 @ 23792 updates, score 22.407) (writing took 2.0056837275624275 seconds)
2022-03-06 06:12:16 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-06 06:12:16 | INFO | train | epoch 489 | loss 0.12 | ppl 1.09 | wps 27258.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23792 | lr 0.000205014 | gnorm 0.452 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 57018
2022-03-06 06:12:16 | INFO | fairseq.trainer | begin training epoch 490
2022-03-06 06:12:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:12:34 | INFO | train_inner | epoch 490:      8 / 49 loss=0.12, ppl=1.09, wps=27043.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.451, loss_scale=32, train_wall=204, gb_free=8.8, wall=57037
2022-03-06 06:14:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:14:11 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 22.27 | ppl 5.05636e+06 | wps 48329.4 | wpb 510.9 | bsz 1 | num_updates 23841 | best_loss 8.449
2022-03-06 06:14:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23841 updates
2022-03-06 06:14:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:14:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:14:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 490 @ 23841 updates, score 22.27) (writing took 1.998597119934857 seconds)
2022-03-06 06:14:13 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-06 06:14:13 | INFO | train | epoch 490 | loss 0.12 | ppl 1.09 | wps 27272.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23841 | lr 0.000204804 | gnorm 0.45 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 57135
2022-03-06 06:14:13 | INFO | fairseq.trainer | begin training epoch 491
2022-03-06 06:14:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:15:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:16:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:16:07 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 22.409 | ppl 5.56998e+06 | wps 48442.8 | wpb 510.9 | bsz 1 | num_updates 23889 | best_loss 8.449
2022-03-06 06:16:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23889 updates
2022-03-06 06:16:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:16:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:16:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 491 @ 23889 updates, score 22.409) (writing took 1.979838814586401 seconds)
2022-03-06 06:16:09 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-06 06:16:09 | INFO | train | epoch 491 | loss 0.119 | ppl 1.09 | wps 26725.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 23889 | lr 0.000204598 | gnorm 0.449 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 57251
2022-03-06 06:16:09 | INFO | fairseq.trainer | begin training epoch 492
2022-03-06 06:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:16:34 | INFO | train_inner | epoch 492:     11 / 49 loss=0.12, ppl=1.09, wps=27047.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.449, loss_scale=32, train_wall=204, gb_free=8.8, wall=57276
2022-03-06 06:17:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:18:04 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 22.27 | ppl 5.05762e+06 | wps 48621.6 | wpb 510.9 | bsz 1 | num_updates 23938 | best_loss 8.449
2022-03-06 06:18:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23938 updates
2022-03-06 06:18:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:18:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:18:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 492 @ 23938 updates, score 22.27) (writing took 1.9596372721716762 seconds)
2022-03-06 06:18:06 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-06 06:18:06 | INFO | train | epoch 492 | loss 0.119 | ppl 1.09 | wps 27283.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23938 | lr 0.000204388 | gnorm 0.449 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 57368
2022-03-06 06:18:06 | INFO | fairseq.trainer | begin training epoch 493
2022-03-06 06:18:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:20:00 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 22.242 | ppl 4.9589e+06 | wps 48569.7 | wpb 510.9 | bsz 1 | num_updates 23987 | best_loss 8.449
2022-03-06 06:20:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 23987 updates
2022-03-06 06:20:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:20:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:20:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 493 @ 23987 updates, score 22.242) (writing took 1.9984306637197733 seconds)
2022-03-06 06:20:02 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-06 06:20:02 | INFO | train | epoch 493 | loss 0.118 | ppl 1.09 | wps 27260.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23987 | lr 0.000204179 | gnorm 0.448 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 57484
2022-03-06 06:20:02 | INFO | fairseq.trainer | begin training epoch 494
2022-03-06 06:20:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:20:32 | INFO | train_inner | epoch 494:     13 / 49 loss=0.119, ppl=1.09, wps=27308.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.448, loss_scale=64, train_wall=202, gb_free=8.8, wall=57514
2022-03-06 06:20:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:21:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:21:57 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 22.369 | ppl 5.41812e+06 | wps 48630.3 | wpb 510.9 | bsz 1 | num_updates 24035 | best_loss 8.449
2022-03-06 06:21:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24035 updates
2022-03-06 06:21:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:21:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:21:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 494 @ 24035 updates, score 22.369) (writing took 1.9483264293521643 seconds)
2022-03-06 06:21:59 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-06 06:21:59 | INFO | train | epoch 494 | loss 0.119 | ppl 1.09 | wps 26734 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 24035 | lr 0.000203975 | gnorm 0.448 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 57601
2022-03-06 06:21:59 | INFO | fairseq.trainer | begin training epoch 495
2022-03-06 06:21:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:23:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:23:53 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 22.271 | ppl 5.06225e+06 | wps 48662.1 | wpb 510.9 | bsz 1 | num_updates 24084 | best_loss 8.449
2022-03-06 06:23:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24084 updates
2022-03-06 06:23:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:23:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:23:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 495 @ 24084 updates, score 22.271) (writing took 1.998407262377441 seconds)
2022-03-06 06:23:55 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-06 06:23:55 | INFO | train | epoch 495 | loss 0.118 | ppl 1.09 | wps 27255 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24084 | lr 0.000203768 | gnorm 0.447 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 57717
2022-03-06 06:23:55 | INFO | fairseq.trainer | begin training epoch 496
2022-03-06 06:23:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:24:32 | INFO | train_inner | epoch 496:     16 / 49 loss=0.119, ppl=1.09, wps=27048.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24100, lr=0.0002037, gnorm=0.448, loss_scale=32, train_wall=204, gb_free=8.8, wall=57754
2022-03-06 06:25:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:25:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:25:50 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 22.34 | ppl 5.30994e+06 | wps 48433.3 | wpb 510.9 | bsz 1 | num_updates 24132 | best_loss 8.449
2022-03-06 06:25:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24132 updates
2022-03-06 06:25:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:25:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:25:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 496 @ 24132 updates, score 22.34) (writing took 1.9607201591134071 seconds)
2022-03-06 06:25:52 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-06 06:25:52 | INFO | train | epoch 496 | loss 0.12 | ppl 1.09 | wps 26702.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 24132 | lr 0.000203565 | gnorm 0.452 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 57834
2022-03-06 06:25:52 | INFO | fairseq.trainer | begin training epoch 497
2022-03-06 06:25:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:27:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:27:46 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 22.253 | ppl 4.99842e+06 | wps 48444.5 | wpb 510.9 | bsz 1 | num_updates 24181 | best_loss 8.449
2022-03-06 06:27:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24181 updates
2022-03-06 06:27:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:27:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:27:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 497 @ 24181 updates, score 22.253) (writing took 1.977700972929597 seconds)
2022-03-06 06:27:48 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-06 06:27:48 | INFO | train | epoch 497 | loss 0.118 | ppl 1.09 | wps 27272.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24181 | lr 0.000203359 | gnorm 0.447 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 57950
2022-03-06 06:27:48 | INFO | fairseq.trainer | begin training epoch 498
2022-03-06 06:27:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:28:32 | INFO | train_inner | epoch 498:     19 / 49 loss=0.119, ppl=1.09, wps=27040.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.449, loss_scale=32, train_wall=204, gb_free=8.8, wall=57994
2022-03-06 06:29:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:29:43 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 22.342 | ppl 5.31541e+06 | wps 48511.4 | wpb 510.9 | bsz 1 | num_updates 24230 | best_loss 8.449
2022-03-06 06:29:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24230 updates
2022-03-06 06:29:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:29:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:29:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 498 @ 24230 updates, score 22.342) (writing took 1.951796448789537 seconds)
2022-03-06 06:29:45 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-06 06:29:45 | INFO | train | epoch 498 | loss 0.118 | ppl 1.09 | wps 27278.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24230 | lr 0.000203153 | gnorm 0.447 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 58067
2022-03-06 06:29:45 | INFO | fairseq.trainer | begin training epoch 499
2022-03-06 06:29:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:30:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:31:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:31:39 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 22.302 | ppl 5.17155e+06 | wps 48636.5 | wpb 510.9 | bsz 1 | num_updates 24278 | best_loss 8.449
2022-03-06 06:31:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24278 updates
2022-03-06 06:31:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:31:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:31:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 499 @ 24278 updates, score 22.302) (writing took 1.9896428184583783 seconds)
2022-03-06 06:31:41 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-06 06:31:41 | INFO | train | epoch 499 | loss 0.118 | ppl 1.08 | wps 26722.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 24278 | lr 0.000202952 | gnorm 0.449 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 58183
2022-03-06 06:31:41 | INFO | fairseq.trainer | begin training epoch 500
2022-03-06 06:31:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:32:31 | INFO | train_inner | epoch 500:     22 / 49 loss=0.118, ppl=1.08, wps=27051.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.447, loss_scale=32, train_wall=204, gb_free=8.8, wall=58233
2022-03-06 06:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:33:36 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 22.438 | ppl 5.68395e+06 | wps 48580.9 | wpb 510.9 | bsz 1 | num_updates 24327 | best_loss 8.449
2022-03-06 06:33:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24327 updates
2022-03-06 06:33:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:33:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:33:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 500 @ 24327 updates, score 22.438) (writing took 1.9866579230874777 seconds)
2022-03-06 06:33:38 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-06 06:33:38 | INFO | train | epoch 500 | loss 0.117 | ppl 1.08 | wps 27269.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24327 | lr 0.000202748 | gnorm 0.448 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 58300
2022-03-06 06:33:38 | INFO | fairseq.trainer | begin training epoch 501
2022-03-06 06:33:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:35:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:35:33 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 22.39 | ppl 5.49619e+06 | wps 48561.4 | wpb 510.9 | bsz 1 | num_updates 24376 | best_loss 8.449
2022-03-06 06:35:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24376 updates
2022-03-06 06:35:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:35:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:35:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 501 @ 24376 updates, score 22.39) (writing took 2.001621293835342 seconds)
2022-03-06 06:35:35 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-06 06:35:35 | INFO | train | epoch 501 | loss 0.117 | ppl 1.08 | wps 27273.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24376 | lr 0.000202544 | gnorm 0.442 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 58417
2022-03-06 06:35:35 | INFO | fairseq.trainer | begin training epoch 502
2022-03-06 06:35:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:36:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:36:31 | INFO | train_inner | epoch 502:     25 / 49 loss=0.117, ppl=1.08, wps=27054.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.446, loss_scale=32, train_wall=204, gb_free=8.8, wall=58473
2022-03-06 06:37:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:37:29 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 22.442 | ppl 5.698e+06 | wps 48549.9 | wpb 510.9 | bsz 1 | num_updates 24424 | best_loss 8.449
2022-03-06 06:37:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24424 updates
2022-03-06 06:37:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:37:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:37:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 502 @ 24424 updates, score 22.442) (writing took 1.9900465570390224 seconds)
2022-03-06 06:37:31 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-06 06:37:31 | INFO | train | epoch 502 | loss 0.117 | ppl 1.08 | wps 26724.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 24424 | lr 0.000202345 | gnorm 0.445 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 58533
2022-03-06 06:37:31 | INFO | fairseq.trainer | begin training epoch 503
2022-03-06 06:37:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:39:26 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 22.421 | ppl 5.61628e+06 | wps 48547.5 | wpb 510.9 | bsz 1 | num_updates 24473 | best_loss 8.449
2022-03-06 06:39:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24473 updates
2022-03-06 06:39:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:39:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:39:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 503 @ 24473 updates, score 22.421) (writing took 2.000087708234787 seconds)
2022-03-06 06:39:28 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-06 06:39:28 | INFO | train | epoch 503 | loss 0.117 | ppl 1.08 | wps 27266.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24473 | lr 0.000202142 | gnorm 0.446 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 58650
2022-03-06 06:39:28 | INFO | fairseq.trainer | begin training epoch 504
2022-03-06 06:39:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:40:29 | INFO | train_inner | epoch 504:     27 / 49 loss=0.117, ppl=1.08, wps=27301.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.444, loss_scale=32, train_wall=202, gb_free=8.8, wall=58711
2022-03-06 06:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:41:22 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 22.339 | ppl 5.30532e+06 | wps 48544.5 | wpb 510.9 | bsz 1 | num_updates 24522 | best_loss 8.449
2022-03-06 06:41:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24522 updates
2022-03-06 06:41:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:41:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:41:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 504 @ 24522 updates, score 22.339) (writing took 2.022472961805761 seconds)
2022-03-06 06:41:24 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-06 06:41:24 | INFO | train | epoch 504 | loss 0.116 | ppl 1.08 | wps 27246.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24522 | lr 0.00020194 | gnorm 0.446 | loss_scale 64 | train_wall 99 | gb_free 8.8 | wall 58766
2022-03-06 06:41:24 | INFO | fairseq.trainer | begin training epoch 505
2022-03-06 06:41:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:41:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:43:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:43:19 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 22.414 | ppl 5.58753e+06 | wps 48363 | wpb 510.9 | bsz 1 | num_updates 24570 | best_loss 8.449
2022-03-06 06:43:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24570 updates
2022-03-06 06:43:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:43:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:43:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 505 @ 24570 updates, score 22.414) (writing took 2.0310636553913355 seconds)
2022-03-06 06:43:21 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-06 06:43:21 | INFO | train | epoch 505 | loss 0.116 | ppl 1.08 | wps 26700.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 24570 | lr 0.000201743 | gnorm 0.446 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 58883
2022-03-06 06:43:21 | INFO | fairseq.trainer | begin training epoch 506
2022-03-06 06:43:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:44:29 | INFO | train_inner | epoch 506:     30 / 49 loss=0.116, ppl=1.08, wps=27027.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.446, loss_scale=32, train_wall=205, gb_free=8.8, wall=58951
2022-03-06 06:45:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:45:15 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 22.415 | ppl 5.59241e+06 | wps 48629.4 | wpb 510.9 | bsz 1 | num_updates 24619 | best_loss 8.449
2022-03-06 06:45:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24619 updates
2022-03-06 06:45:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:45:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:45:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 506 @ 24619 updates, score 22.415) (writing took 2.0064101591706276 seconds)
2022-03-06 06:45:17 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-06 06:45:17 | INFO | train | epoch 506 | loss 0.116 | ppl 1.08 | wps 27261.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24619 | lr 0.000201542 | gnorm 0.445 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 58999
2022-03-06 06:45:17 | INFO | fairseq.trainer | begin training epoch 507
2022-03-06 06:45:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:46:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:47:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:47:12 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 22.373 | ppl 5.43197e+06 | wps 48006.7 | wpb 510.9 | bsz 1 | num_updates 24667 | best_loss 8.449
2022-03-06 06:47:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24667 updates
2022-03-06 06:47:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:47:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:47:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 507 @ 24667 updates, score 22.373) (writing took 1.9832307631149888 seconds)
2022-03-06 06:47:14 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-06 06:47:14 | INFO | train | epoch 507 | loss 0.116 | ppl 1.08 | wps 26705.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 24667 | lr 0.000201345 | gnorm 0.442 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 59116
2022-03-06 06:47:14 | INFO | fairseq.trainer | begin training epoch 508
2022-03-06 06:47:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:48:29 | INFO | train_inner | epoch 508:     33 / 49 loss=0.116, ppl=1.08, wps=27044.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.443, loss_scale=32, train_wall=204, gb_free=8.8, wall=59191
2022-03-06 06:49:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:49:08 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 22.433 | ppl 5.66388e+06 | wps 48438.9 | wpb 510.9 | bsz 1 | num_updates 24716 | best_loss 8.449
2022-03-06 06:49:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24716 updates
2022-03-06 06:49:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:49:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:49:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 508 @ 24716 updates, score 22.433) (writing took 2.0049990816041827 seconds)
2022-03-06 06:49:10 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-06 06:49:10 | INFO | train | epoch 508 | loss 0.115 | ppl 1.08 | wps 27265 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24716 | lr 0.000201146 | gnorm 0.441 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 59232
2022-03-06 06:49:10 | INFO | fairseq.trainer | begin training epoch 509
2022-03-06 06:49:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:51:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:51:05 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 22.514 | ppl 5.99065e+06 | wps 48676.3 | wpb 510.9 | bsz 1 | num_updates 24765 | best_loss 8.449
2022-03-06 06:51:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24765 updates
2022-03-06 06:51:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:51:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:51:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 509 @ 24765 updates, score 22.514) (writing took 1.9832908250391483 seconds)
2022-03-06 06:51:07 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-06 06:51:07 | INFO | train | epoch 509 | loss 0.115 | ppl 1.08 | wps 27277.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24765 | lr 0.000200947 | gnorm 0.442 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 59349
2022-03-06 06:51:07 | INFO | fairseq.trainer | begin training epoch 510
2022-03-06 06:51:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:52:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:52:29 | INFO | train_inner | epoch 510:     36 / 49 loss=0.116, ppl=1.08, wps=27047.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.442, loss_scale=32, train_wall=204, gb_free=8.8, wall=59431
2022-03-06 06:52:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:53:01 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 22.481 | ppl 5.85536e+06 | wps 48672.9 | wpb 510.9 | bsz 1 | num_updates 24813 | best_loss 8.449
2022-03-06 06:53:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24813 updates
2022-03-06 06:53:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:53:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:53:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 510 @ 24813 updates, score 22.481) (writing took 1.9756391113623977 seconds)
2022-03-06 06:53:03 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-06 06:53:03 | INFO | train | epoch 510 | loss 0.115 | ppl 1.08 | wps 26731.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 24813 | lr 0.000200752 | gnorm 0.442 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 59465
2022-03-06 06:53:03 | INFO | fairseq.trainer | begin training epoch 511
2022-03-06 06:53:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:54:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:54:58 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 22.53 | ppl 6.05465e+06 | wps 48636.4 | wpb 510.9 | bsz 1 | num_updates 24862 | best_loss 8.449
2022-03-06 06:54:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24862 updates
2022-03-06 06:54:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:55:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:55:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 511 @ 24862 updates, score 22.53) (writing took 2.0193023597821593 seconds)
2022-03-06 06:55:00 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-06 06:55:00 | INFO | train | epoch 511 | loss 0.115 | ppl 1.08 | wps 27257.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24862 | lr 0.000200554 | gnorm 0.441 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 59582
2022-03-06 06:55:00 | INFO | fairseq.trainer | begin training epoch 512
2022-03-06 06:55:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:56:26 | INFO | train_inner | epoch 512:     38 / 49 loss=0.115, ppl=1.08, wps=27311.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.44, loss_scale=32, train_wall=202, gb_free=8.8, wall=59668
2022-03-06 06:56:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:56:54 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 22.457 | ppl 5.75627e+06 | wps 48472 | wpb 510.9 | bsz 1 | num_updates 24911 | best_loss 8.449
2022-03-06 06:56:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24911 updates
2022-03-06 06:56:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:56:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:56:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 512 @ 24911 updates, score 22.457) (writing took 1.989968415349722 seconds)
2022-03-06 06:56:56 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-06 06:56:56 | INFO | train | epoch 512 | loss 0.114 | ppl 1.08 | wps 27281.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24911 | lr 0.000200357 | gnorm 0.439 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 59699
2022-03-06 06:56:56 | INFO | fairseq.trainer | begin training epoch 513
2022-03-06 06:56:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:57:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:58:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:58:51 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 22.455 | ppl 5.75029e+06 | wps 48392.4 | wpb 510.9 | bsz 1 | num_updates 24959 | best_loss 8.449
2022-03-06 06:58:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24959 updates
2022-03-06 06:58:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:58:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 06:58:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 513 @ 24959 updates, score 22.455) (writing took 2.0062670055776834 seconds)
2022-03-06 06:58:53 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-06 06:58:53 | INFO | train | epoch 513 | loss 0.114 | ppl 1.08 | wps 26716.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 24959 | lr 0.000200164 | gnorm 0.44 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 59815
2022-03-06 06:58:53 | INFO | fairseq.trainer | begin training epoch 514
2022-03-06 06:58:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:00:26 | INFO | train_inner | epoch 514:     41 / 49 loss=0.114, ppl=1.08, wps=27039.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.437, loss_scale=32, train_wall=204, gb_free=8.8, wall=59908
2022-03-06 07:00:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:00:48 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 22.436 | ppl 5.67295e+06 | wps 48562 | wpb 510.9 | bsz 1 | num_updates 25008 | best_loss 8.449
2022-03-06 07:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25008 updates
2022-03-06 07:00:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:00:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 514 @ 25008 updates, score 22.436) (writing took 2.033319501206279 seconds)
2022-03-06 07:00:50 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-06 07:00:50 | INFO | train | epoch 514 | loss 0.114 | ppl 1.08 | wps 27249.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25008 | lr 0.000199968 | gnorm 0.437 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 59932
2022-03-06 07:00:50 | INFO | fairseq.trainer | begin training epoch 515
2022-03-06 07:00:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:02:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:02:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:02:44 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 22.46 | ppl 5.76856e+06 | wps 48571.9 | wpb 510.9 | bsz 1 | num_updates 25056 | best_loss 8.449
2022-03-06 07:02:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25056 updates
2022-03-06 07:02:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:02:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:02:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 515 @ 25056 updates, score 22.46) (writing took 2.017575306817889 seconds)
2022-03-06 07:02:46 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-06 07:02:46 | INFO | train | epoch 515 | loss 0.114 | ppl 1.08 | wps 26724.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 25056 | lr 0.000199776 | gnorm 0.437 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 60048
2022-03-06 07:02:46 | INFO | fairseq.trainer | begin training epoch 516
2022-03-06 07:02:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:04:26 | INFO | train_inner | epoch 516:     44 / 49 loss=0.114, ppl=1.08, wps=27045.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.437, loss_scale=32, train_wall=204, gb_free=8.8, wall=60148
2022-03-06 07:04:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:04:41 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 22.436 | ppl 5.6761e+06 | wps 48445.4 | wpb 510.9 | bsz 1 | num_updates 25105 | best_loss 8.449
2022-03-06 07:04:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25105 updates
2022-03-06 07:04:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:04:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:04:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 516 @ 25105 updates, score 22.436) (writing took 2.0462582409381866 seconds)
2022-03-06 07:04:43 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-06 07:04:43 | INFO | train | epoch 516 | loss 0.114 | ppl 1.08 | wps 27244.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25105 | lr 0.000199581 | gnorm 0.437 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 60165
2022-03-06 07:04:43 | INFO | fairseq.trainer | begin training epoch 517
2022-03-06 07:04:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:06:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:06:37 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 22.557 | ppl 6.17103e+06 | wps 48537.1 | wpb 510.9 | bsz 1 | num_updates 25154 | best_loss 8.449
2022-03-06 07:06:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25154 updates
2022-03-06 07:06:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:06:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:06:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 517 @ 25154 updates, score 22.557) (writing took 2.0099256159737706 seconds)
2022-03-06 07:06:39 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-06 07:06:39 | INFO | train | epoch 517 | loss 0.114 | ppl 1.08 | wps 27264.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25154 | lr 0.000199387 | gnorm 0.435 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 60281
2022-03-06 07:06:39 | INFO | fairseq.trainer | begin training epoch 518
2022-03-06 07:06:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:07:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:08:26 | INFO | train_inner | epoch 518:     47 / 49 loss=0.114, ppl=1.08, wps=27031.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.438, loss_scale=32, train_wall=204, gb_free=8.8, wall=60388
2022-03-06 07:08:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:08:34 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 22.557 | ppl 6.16881e+06 | wps 48486.6 | wpb 510.9 | bsz 1 | num_updates 25202 | best_loss 8.449
2022-03-06 07:08:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25202 updates
2022-03-06 07:08:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:08:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:08:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 518 @ 25202 updates, score 22.557) (writing took 1.9908229587599635 seconds)
2022-03-06 07:08:36 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-06 07:08:36 | INFO | train | epoch 518 | loss 0.113 | ppl 1.08 | wps 26707 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 25202 | lr 0.000199197 | gnorm 0.442 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 60398
2022-03-06 07:08:36 | INFO | fairseq.trainer | begin training epoch 519
2022-03-06 07:08:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:10:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:10:30 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 22.512 | ppl 5.9803e+06 | wps 48453.9 | wpb 510.9 | bsz 1 | num_updates 25251 | best_loss 8.449
2022-03-06 07:10:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25251 updates
2022-03-06 07:10:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:10:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:10:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 519 @ 25251 updates, score 22.512) (writing took 2.026703517884016 seconds)
2022-03-06 07:10:32 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-06 07:10:32 | INFO | train | epoch 519 | loss 0.114 | ppl 1.08 | wps 27257.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25251 | lr 0.000199003 | gnorm 0.439 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 60514
2022-03-06 07:10:32 | INFO | fairseq.trainer | begin training epoch 520
2022-03-06 07:10:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:12:22 | INFO | train_inner | epoch 520:     49 / 49 loss=0.113, ppl=1.08, wps=27286.7, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=25300, lr=0.000198811, gnorm=0.439, loss_scale=32, train_wall=201, gb_free=8.8, wall=60624
2022-03-06 07:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:12:27 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 22.543 | ppl 6.10941e+06 | wps 48426 | wpb 510.9 | bsz 1 | num_updates 25300 | best_loss 8.449
2022-03-06 07:12:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25300 updates
2022-03-06 07:12:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:12:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:12:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 520 @ 25300 updates, score 22.543) (writing took 2.006444301456213 seconds)
2022-03-06 07:12:29 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-06 07:12:29 | INFO | train | epoch 520 | loss 0.112 | ppl 1.08 | wps 27272.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25300 | lr 0.000198811 | gnorm 0.436 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 60631
2022-03-06 07:12:29 | INFO | fairseq.trainer | begin training epoch 521
2022-03-06 07:12:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:13:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:14:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:14:24 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 22.513 | ppl 5.98642e+06 | wps 48358.3 | wpb 510.9 | bsz 1 | num_updates 25348 | best_loss 8.449
2022-03-06 07:14:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25348 updates
2022-03-06 07:14:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:14:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:14:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 521 @ 25348 updates, score 22.513) (writing took 1.994896157644689 seconds)
2022-03-06 07:14:26 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-06 07:14:26 | INFO | train | epoch 521 | loss 0.113 | ppl 1.08 | wps 26700.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 25348 | lr 0.000198622 | gnorm 0.439 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 60748
2022-03-06 07:14:26 | INFO | fairseq.trainer | begin training epoch 522
2022-03-06 07:14:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:16:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:16:20 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 22.697 | ppl 6.79962e+06 | wps 48648.4 | wpb 510.9 | bsz 1 | num_updates 25397 | best_loss 8.449
2022-03-06 07:16:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25397 updates
2022-03-06 07:16:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:16:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:16:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 522 @ 25397 updates, score 22.697) (writing took 1.966674773953855 seconds)
2022-03-06 07:16:22 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-06 07:16:22 | INFO | train | epoch 522 | loss 0.113 | ppl 1.08 | wps 27280.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25397 | lr 0.000198431 | gnorm 0.439 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 60864
2022-03-06 07:16:22 | INFO | fairseq.trainer | begin training epoch 523
2022-03-06 07:16:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:16:29 | INFO | train_inner | epoch 523:      3 / 49 loss=0.112, ppl=1.08, wps=26312.5, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=25400, lr=0.000198419, gnorm=0.438, loss_scale=32, train_wall=205, gb_free=8.8, wall=60871
2022-03-06 07:18:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:18:17 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 22.477 | ppl 5.8387e+06 | wps 48500 | wpb 510.9 | bsz 1 | num_updates 25446 | best_loss 8.449
2022-03-06 07:18:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25446 updates
2022-03-06 07:18:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:18:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:18:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 523 @ 25446 updates, score 22.477) (writing took 2.0236422913149 seconds)
2022-03-06 07:18:19 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-06 07:18:19 | INFO | train | epoch 523 | loss 0.112 | ppl 1.08 | wps 27253.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25446 | lr 0.00019824 | gnorm 0.435 | loss_scale 64 | train_wall 99 | gb_free 8.8 | wall 60981
2022-03-06 07:18:19 | INFO | fairseq.trainer | begin training epoch 524
2022-03-06 07:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:18:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:20:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:20:13 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 22.511 | ppl 5.97781e+06 | wps 48634.8 | wpb 510.9 | bsz 1 | num_updates 25494 | best_loss 8.449
2022-03-06 07:20:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25494 updates
2022-03-06 07:20:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:20:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:20:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 524 @ 25494 updates, score 22.511) (writing took 1.9671645872294903 seconds)
2022-03-06 07:20:15 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-06 07:20:15 | INFO | train | epoch 524 | loss 0.112 | ppl 1.08 | wps 26717.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 25494 | lr 0.000198053 | gnorm 0.434 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 61097
2022-03-06 07:20:15 | INFO | fairseq.trainer | begin training epoch 525
2022-03-06 07:20:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:20:29 | INFO | train_inner | epoch 525:      6 / 49 loss=0.112, ppl=1.08, wps=27041.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25500, lr=0.00019803, gnorm=0.435, loss_scale=32, train_wall=204, gb_free=8.8, wall=61111
2022-03-06 07:22:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:22:10 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 22.411 | ppl 5.57736e+06 | wps 48390.1 | wpb 510.9 | bsz 1 | num_updates 25543 | best_loss 8.449
2022-03-06 07:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25543 updates
2022-03-06 07:22:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:22:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:22:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 525 @ 25543 updates, score 22.411) (writing took 2.010796556249261 seconds)
2022-03-06 07:22:12 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-06 07:22:12 | INFO | train | epoch 525 | loss 0.111 | ppl 1.08 | wps 27277.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25543 | lr 0.000197863 | gnorm 0.432 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 61214
2022-03-06 07:22:12 | INFO | fairseq.trainer | begin training epoch 526
2022-03-06 07:22:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:23:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:24:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:24:06 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 22.602 | ppl 6.36628e+06 | wps 48383.5 | wpb 510.9 | bsz 1 | num_updates 25591 | best_loss 8.449
2022-03-06 07:24:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25591 updates
2022-03-06 07:24:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:24:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:24:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 526 @ 25591 updates, score 22.602) (writing took 2.029134622775018 seconds)
2022-03-06 07:24:08 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-06 07:24:08 | INFO | train | epoch 526 | loss 0.111 | ppl 1.08 | wps 26699.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 25591 | lr 0.000197677 | gnorm 0.434 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 61330
2022-03-06 07:24:08 | INFO | fairseq.trainer | begin training epoch 527
2022-03-06 07:24:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:24:29 | INFO | train_inner | epoch 527:      9 / 49 loss=0.111, ppl=1.08, wps=27045.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.433, loss_scale=32, train_wall=204, gb_free=8.8, wall=61351
2022-03-06 07:25:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:26:03 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 22.529 | ppl 6.05218e+06 | wps 48537.6 | wpb 510.9 | bsz 1 | num_updates 25640 | best_loss 8.449
2022-03-06 07:26:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25640 updates
2022-03-06 07:26:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:26:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:26:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 527 @ 25640 updates, score 22.529) (writing took 2.0081017054617405 seconds)
2022-03-06 07:26:05 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-06 07:26:05 | INFO | train | epoch 527 | loss 0.111 | ppl 1.08 | wps 27284.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25640 | lr 0.000197488 | gnorm 0.431 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 61447
2022-03-06 07:26:05 | INFO | fairseq.trainer | begin training epoch 528
2022-03-06 07:26:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:27:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:27:59 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 22.62 | ppl 6.44445e+06 | wps 48540 | wpb 510.9 | bsz 1 | num_updates 25689 | best_loss 8.449
2022-03-06 07:27:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25689 updates
2022-03-06 07:27:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:28:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:28:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 528 @ 25689 updates, score 22.62) (writing took 1.9875648841261864 seconds)
2022-03-06 07:28:01 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-06 07:28:01 | INFO | train | epoch 528 | loss 0.112 | ppl 1.08 | wps 27268.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25689 | lr 0.0001973 | gnorm 0.437 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 61563
2022-03-06 07:28:01 | INFO | fairseq.trainer | begin training epoch 529
2022-03-06 07:28:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:28:26 | INFO | train_inner | epoch 529:     11 / 49 loss=0.111, ppl=1.08, wps=27304.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.434, loss_scale=32, train_wall=202, gb_free=8.8, wall=61588
2022-03-06 07:29:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:29:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:29:56 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 22.385 | ppl 5.4789e+06 | wps 48446.4 | wpb 510.9 | bsz 1 | num_updates 25737 | best_loss 8.449
2022-03-06 07:29:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25737 updates
2022-03-06 07:29:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:29:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:29:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 529 @ 25737 updates, score 22.385) (writing took 2.0017523635178804 seconds)
2022-03-06 07:29:58 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-06 07:29:58 | INFO | train | epoch 529 | loss 0.111 | ppl 1.08 | wps 26700.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 25737 | lr 0.000197116 | gnorm 0.432 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 61680
2022-03-06 07:29:58 | INFO | fairseq.trainer | begin training epoch 530
2022-03-06 07:29:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:31:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:31:52 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 22.545 | ppl 6.12046e+06 | wps 48532.6 | wpb 510.9 | bsz 1 | num_updates 25786 | best_loss 8.449
2022-03-06 07:31:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25786 updates
2022-03-06 07:31:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:31:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:31:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 530 @ 25786 updates, score 22.545) (writing took 1.9801759105175734 seconds)
2022-03-06 07:31:54 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-06 07:31:54 | INFO | train | epoch 530 | loss 0.111 | ppl 1.08 | wps 27288.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25786 | lr 0.000196928 | gnorm 0.434 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 61796
2022-03-06 07:31:54 | INFO | fairseq.trainer | begin training epoch 531
2022-03-06 07:31:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:32:26 | INFO | train_inner | epoch 531:     14 / 49 loss=0.11, ppl=1.08, wps=27053.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.433, loss_scale=32, train_wall=204, gb_free=8.8, wall=61828
2022-03-06 07:33:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:33:49 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 22.506 | ppl 5.95695e+06 | wps 48473.7 | wpb 510.9 | bsz 1 | num_updates 25835 | best_loss 8.449
2022-03-06 07:33:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25835 updates
2022-03-06 07:33:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:33:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:33:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 531 @ 25835 updates, score 22.506) (writing took 2.015237337909639 seconds)
2022-03-06 07:33:51 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-06 07:33:51 | INFO | train | epoch 531 | loss 0.111 | ppl 1.08 | wps 27270 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25835 | lr 0.000196741 | gnorm 0.433 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 61913
2022-03-06 07:33:51 | INFO | fairseq.trainer | begin training epoch 532
2022-03-06 07:33:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:34:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:35:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:35:45 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 22.647 | ppl 6.56653e+06 | wps 48535.7 | wpb 510.9 | bsz 1 | num_updates 25883 | best_loss 8.449
2022-03-06 07:35:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25883 updates
2022-03-06 07:35:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:35:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:35:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 532 @ 25883 updates, score 22.647) (writing took 1.9918923815712333 seconds)
2022-03-06 07:35:47 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-06 07:35:47 | INFO | train | epoch 532 | loss 0.111 | ppl 1.08 | wps 26723.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 25883 | lr 0.000196559 | gnorm 0.433 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 62029
2022-03-06 07:35:47 | INFO | fairseq.trainer | begin training epoch 533
2022-03-06 07:35:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:36:26 | INFO | train_inner | epoch 533:     17 / 49 loss=0.11, ppl=1.08, wps=27052.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.432, loss_scale=32, train_wall=204, gb_free=8.8, wall=62068
2022-03-06 07:37:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:37:42 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 22.587 | ppl 6.29998e+06 | wps 48489.7 | wpb 510.9 | bsz 1 | num_updates 25932 | best_loss 8.449
2022-03-06 07:37:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25932 updates
2022-03-06 07:37:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:37:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:37:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 533 @ 25932 updates, score 22.587) (writing took 2.0356544060632586 seconds)
2022-03-06 07:37:44 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-06 07:37:44 | INFO | train | epoch 533 | loss 0.11 | ppl 1.08 | wps 27257 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25932 | lr 0.000196373 | gnorm 0.436 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 62146
2022-03-06 07:37:44 | INFO | fairseq.trainer | begin training epoch 534
2022-03-06 07:37:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:39:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:39:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:39:38 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 22.622 | ppl 6.45693e+06 | wps 48502.4 | wpb 510.9 | bsz 1 | num_updates 25980 | best_loss 8.449
2022-03-06 07:39:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25980 updates
2022-03-06 07:39:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:39:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:39:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 534 @ 25980 updates, score 22.622) (writing took 1.991821376606822 seconds)
2022-03-06 07:39:40 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-06 07:39:40 | INFO | train | epoch 534 | loss 0.11 | ppl 1.08 | wps 26694.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 25980 | lr 0.000196192 | gnorm 0.432 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 62263
2022-03-06 07:39:40 | INFO | fairseq.trainer | begin training epoch 535
2022-03-06 07:39:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:40:26 | INFO | train_inner | epoch 535:     20 / 49 loss=0.11, ppl=1.08, wps=27029.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26000, lr=0.000196116, gnorm=0.433, loss_scale=32, train_wall=204, gb_free=8.8, wall=62308
2022-03-06 07:41:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:41:35 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 22.578 | ppl 6.25925e+06 | wps 48535.4 | wpb 510.9 | bsz 1 | num_updates 26029 | best_loss 8.449
2022-03-06 07:41:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26029 updates
2022-03-06 07:41:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:41:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:41:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 535 @ 26029 updates, score 22.578) (writing took 2.030500879511237 seconds)
2022-03-06 07:41:37 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-06 07:41:37 | INFO | train | epoch 535 | loss 0.11 | ppl 1.08 | wps 27270 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26029 | lr 0.000196007 | gnorm 0.431 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 62379
2022-03-06 07:41:37 | INFO | fairseq.trainer | begin training epoch 536
2022-03-06 07:41:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:43:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:43:32 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 22.573 | ppl 6.23846e+06 | wps 48492.6 | wpb 510.9 | bsz 1 | num_updates 26078 | best_loss 8.449
2022-03-06 07:43:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26078 updates
2022-03-06 07:43:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:43:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:43:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 536 @ 26078 updates, score 22.573) (writing took 2.010960596613586 seconds)
2022-03-06 07:43:34 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-06 07:43:34 | INFO | train | epoch 536 | loss 0.109 | ppl 1.08 | wps 27254.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26078 | lr 0.000195823 | gnorm 0.435 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 62496
2022-03-06 07:43:34 | INFO | fairseq.trainer | begin training epoch 537
2022-03-06 07:43:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:44:24 | INFO | train_inner | epoch 537:     22 / 49 loss=0.109, ppl=1.08, wps=27296.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.434, loss_scale=32, train_wall=202, gb_free=8.8, wall=62546
2022-03-06 07:45:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:45:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:45:28 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 22.555 | ppl 6.16247e+06 | wps 48404.6 | wpb 510.9 | bsz 1 | num_updates 26126 | best_loss 8.449
2022-03-06 07:45:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26126 updates
2022-03-06 07:45:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:45:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:45:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 537 @ 26126 updates, score 22.555) (writing took 1.9846699461340904 seconds)
2022-03-06 07:45:30 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-06 07:45:30 | INFO | train | epoch 537 | loss 0.109 | ppl 1.08 | wps 26712.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 26126 | lr 0.000195643 | gnorm 0.428 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 62612
2022-03-06 07:45:30 | INFO | fairseq.trainer | begin training epoch 538
2022-03-06 07:45:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:47:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:47:25 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 22.562 | ppl 6.19122e+06 | wps 48568.2 | wpb 510.9 | bsz 1 | num_updates 26175 | best_loss 8.449
2022-03-06 07:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26175 updates
2022-03-06 07:47:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:47:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:47:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 538 @ 26175 updates, score 22.562) (writing took 2.015654968097806 seconds)
2022-03-06 07:47:27 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-06 07:47:27 | INFO | train | epoch 538 | loss 0.108 | ppl 1.08 | wps 27268.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26175 | lr 0.000195459 | gnorm 0.428 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 62729
2022-03-06 07:47:27 | INFO | fairseq.trainer | begin training epoch 539
2022-03-06 07:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:48:23 | INFO | train_inner | epoch 539:     25 / 49 loss=0.109, ppl=1.08, wps=27041.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.428, loss_scale=32, train_wall=204, gb_free=8.8, wall=62785
2022-03-06 07:49:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:49:21 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 22.708 | ppl 6.85196e+06 | wps 48440.7 | wpb 510.9 | bsz 1 | num_updates 26224 | best_loss 8.449
2022-03-06 07:49:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26224 updates
2022-03-06 07:49:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:49:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:49:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 539 @ 26224 updates, score 22.708) (writing took 1.9812567317858338 seconds)
2022-03-06 07:49:23 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-06 07:49:23 | INFO | train | epoch 539 | loss 0.109 | ppl 1.08 | wps 27276.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26224 | lr 0.000195277 | gnorm 0.432 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 62845
2022-03-06 07:49:23 | INFO | fairseq.trainer | begin training epoch 540
2022-03-06 07:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:50:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:51:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:51:18 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 22.577 | ppl 6.25857e+06 | wps 48557.7 | wpb 510.9 | bsz 1 | num_updates 26272 | best_loss 8.449
2022-03-06 07:51:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26272 updates
2022-03-06 07:51:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:51:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:51:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 540 @ 26272 updates, score 22.577) (writing took 1.9686675667762756 seconds)
2022-03-06 07:51:20 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-06 07:51:20 | INFO | train | epoch 540 | loss 0.108 | ppl 1.08 | wps 26733.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 26272 | lr 0.000195098 | gnorm 0.426 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 62962
2022-03-06 07:51:20 | INFO | fairseq.trainer | begin training epoch 541
2022-03-06 07:51:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:52:23 | INFO | train_inner | epoch 541:     28 / 49 loss=0.108, ppl=1.08, wps=27057.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.428, loss_scale=32, train_wall=204, gb_free=8.8, wall=63025
2022-03-06 07:53:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:53:14 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 22.551 | ppl 6.14398e+06 | wps 48512.3 | wpb 510.9 | bsz 1 | num_updates 26321 | best_loss 8.449
2022-03-06 07:53:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26321 updates
2022-03-06 07:53:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:53:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:53:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 541 @ 26321 updates, score 22.551) (writing took 2.0066733611747622 seconds)
2022-03-06 07:53:16 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-06 07:53:16 | INFO | train | epoch 541 | loss 0.109 | ppl 1.08 | wps 27268 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26321 | lr 0.000194917 | gnorm 0.429 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 63078
2022-03-06 07:53:16 | INFO | fairseq.trainer | begin training epoch 542
2022-03-06 07:53:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:55:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:55:11 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 22.624 | ppl 6.46464e+06 | wps 48477.5 | wpb 510.9 | bsz 1 | num_updates 26370 | best_loss 8.449
2022-03-06 07:55:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26370 updates
2022-03-06 07:55:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:55:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:55:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 542 @ 26370 updates, score 22.624) (writing took 1.9894922189414501 seconds)
2022-03-06 07:55:13 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-06 07:55:13 | INFO | train | epoch 542 | loss 0.108 | ppl 1.08 | wps 27275.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26370 | lr 0.000194735 | gnorm 0.431 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 63195
2022-03-06 07:55:13 | INFO | fairseq.trainer | begin training epoch 543
2022-03-06 07:55:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:56:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:56:23 | INFO | train_inner | epoch 543:     31 / 49 loss=0.108, ppl=1.08, wps=27050.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.429, loss_scale=32, train_wall=204, gb_free=8.8, wall=63265
2022-03-06 07:57:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:57:07 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 22.556 | ppl 6.16591e+06 | wps 48582 | wpb 510.9 | bsz 1 | num_updates 26418 | best_loss 8.449
2022-03-06 07:57:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26418 updates
2022-03-06 07:57:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:57:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:57:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 543 @ 26418 updates, score 22.556) (writing took 2.01994108594954 seconds)
2022-03-06 07:57:09 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-06 07:57:09 | INFO | train | epoch 543 | loss 0.108 | ppl 1.08 | wps 26714 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 26418 | lr 0.000194558 | gnorm 0.426 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 63311
2022-03-06 07:57:09 | INFO | fairseq.trainer | begin training epoch 544
2022-03-06 07:57:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:58:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:59:04 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 22.655 | ppl 6.60536e+06 | wps 48430.6 | wpb 510.9 | bsz 1 | num_updates 26467 | best_loss 8.449
2022-03-06 07:59:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26467 updates
2022-03-06 07:59:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:59:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 07:59:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 544 @ 26467 updates, score 22.655) (writing took 1.9904811987653375 seconds)
2022-03-06 07:59:06 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-06 07:59:06 | INFO | train | epoch 544 | loss 0.108 | ppl 1.08 | wps 27254.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26467 | lr 0.000194378 | gnorm 0.429 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 63428
2022-03-06 07:59:06 | INFO | fairseq.trainer | begin training epoch 545
2022-03-06 07:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:00:21 | INFO | train_inner | epoch 545:     33 / 49 loss=0.108, ppl=1.08, wps=27300.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.428, loss_scale=32, train_wall=202, gb_free=8.8, wall=63503
2022-03-06 08:00:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:01:00 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 22.634 | ppl 6.51069e+06 | wps 48508.2 | wpb 510.9 | bsz 1 | num_updates 26516 | best_loss 8.449
2022-03-06 08:01:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26516 updates
2022-03-06 08:01:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:01:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:01:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 545 @ 26516 updates, score 22.634) (writing took 2.048587564378977 seconds)
2022-03-06 08:01:02 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-06 08:01:02 | INFO | train | epoch 545 | loss 0.108 | ppl 1.08 | wps 27269 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26516 | lr 0.000194199 | gnorm 0.428 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 63544
2022-03-06 08:01:02 | INFO | fairseq.trainer | begin training epoch 546
2022-03-06 08:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:01:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:02:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:02:57 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 22.59 | ppl 6.31427e+06 | wps 48469.5 | wpb 510.9 | bsz 1 | num_updates 26564 | best_loss 8.449
2022-03-06 08:02:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26564 updates
2022-03-06 08:02:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:02:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:02:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 546 @ 26564 updates, score 22.59) (writing took 2.007606765255332 seconds)
2022-03-06 08:02:59 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-06 08:02:59 | INFO | train | epoch 546 | loss 0.107 | ppl 1.08 | wps 26698.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 26564 | lr 0.000194023 | gnorm 0.425 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 63661
2022-03-06 08:02:59 | INFO | fairseq.trainer | begin training epoch 547
2022-03-06 08:02:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:04:21 | INFO | train_inner | epoch 547:     36 / 49 loss=0.108, ppl=1.08, wps=27038.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.428, loss_scale=32, train_wall=204, gb_free=8.8, wall=63743
2022-03-06 08:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:04:53 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 22.794 | ppl 7.27435e+06 | wps 48641.8 | wpb 510.9 | bsz 1 | num_updates 26613 | best_loss 8.449
2022-03-06 08:04:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26613 updates
2022-03-06 08:04:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:04:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:04:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 547 @ 26613 updates, score 22.794) (writing took 2.0080699482932687 seconds)
2022-03-06 08:04:55 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-06 08:04:55 | INFO | train | epoch 547 | loss 0.107 | ppl 1.08 | wps 27280.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26613 | lr 0.000193844 | gnorm 0.429 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 63777
2022-03-06 08:04:55 | INFO | fairseq.trainer | begin training epoch 548
2022-03-06 08:04:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:06:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:06:50 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 22.605 | ppl 6.37839e+06 | wps 48409.4 | wpb 510.9 | bsz 1 | num_updates 26662 | best_loss 8.449
2022-03-06 08:06:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26662 updates
2022-03-06 08:06:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:06:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:06:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 548 @ 26662 updates, score 22.605) (writing took 1.98942303750664 seconds)
2022-03-06 08:06:52 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-06 08:06:52 | INFO | train | epoch 548 | loss 0.107 | ppl 1.08 | wps 27251 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26662 | lr 0.000193666 | gnorm 0.432 | loss_scale 64 | train_wall 99 | gb_free 8.8 | wall 63894
2022-03-06 08:06:52 | INFO | fairseq.trainer | begin training epoch 549
2022-03-06 08:06:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:07:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:08:20 | INFO | train_inner | epoch 549:     39 / 49 loss=0.107, ppl=1.08, wps=27039.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.429, loss_scale=32, train_wall=204, gb_free=8.8, wall=63982
2022-03-06 08:08:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:08:47 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 22.675 | ppl 6.69772e+06 | wps 48534.4 | wpb 510.9 | bsz 1 | num_updates 26710 | best_loss 8.449
2022-03-06 08:08:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26710 updates
2022-03-06 08:08:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:08:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:08:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 549 @ 26710 updates, score 22.675) (writing took 1.888788292184472 seconds)
2022-03-06 08:08:48 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-06 08:08:48 | INFO | train | epoch 549 | loss 0.107 | ppl 1.08 | wps 26741.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 26710 | lr 0.000193492 | gnorm 0.427 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 64010
2022-03-06 08:08:48 | INFO | fairseq.trainer | begin training epoch 550
2022-03-06 08:08:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:10:43 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 22.589 | ppl 6.31118e+06 | wps 48672.2 | wpb 510.9 | bsz 1 | num_updates 26759 | best_loss 8.449
2022-03-06 08:10:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26759 updates
2022-03-06 08:10:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:10:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:10:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 550 @ 26759 updates, score 22.589) (writing took 1.8850743472576141 seconds)
2022-03-06 08:10:45 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-06 08:10:45 | INFO | train | epoch 550 | loss 0.106 | ppl 1.08 | wps 27325.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26759 | lr 0.000193315 | gnorm 0.42 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 64127
2022-03-06 08:10:45 | INFO | fairseq.trainer | begin training epoch 551
2022-03-06 08:10:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:12:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:12:20 | INFO | train_inner | epoch 551:     42 / 49 loss=0.106, ppl=1.08, wps=27078.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.422, loss_scale=32, train_wall=204, gb_free=8.8, wall=64222
2022-03-06 08:12:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:12:39 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 22.664 | ppl 6.64464e+06 | wps 48668.4 | wpb 510.9 | bsz 1 | num_updates 26807 | best_loss 8.449
2022-03-06 08:12:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26807 updates
2022-03-06 08:12:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:12:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:12:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 551 @ 26807 updates, score 22.664) (writing took 1.9063079077750444 seconds)
2022-03-06 08:12:41 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-06 08:12:41 | INFO | train | epoch 551 | loss 0.106 | ppl 1.08 | wps 26728.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 26807 | lr 0.000193142 | gnorm 0.424 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 64243
2022-03-06 08:12:41 | INFO | fairseq.trainer | begin training epoch 552
2022-03-06 08:12:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:14:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:14:36 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 22.588 | ppl 6.3055e+06 | wps 48655.1 | wpb 510.9 | bsz 1 | num_updates 26856 | best_loss 8.449
2022-03-06 08:14:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26856 updates
2022-03-06 08:14:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:14:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:14:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 552 @ 26856 updates, score 22.588) (writing took 1.8508104840293527 seconds)
2022-03-06 08:14:38 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-06 08:14:38 | INFO | train | epoch 552 | loss 0.106 | ppl 1.08 | wps 27322.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26856 | lr 0.000192965 | gnorm 0.427 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 64360
2022-03-06 08:14:38 | INFO | fairseq.trainer | begin training epoch 553
2022-03-06 08:14:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:16:17 | INFO | train_inner | epoch 553:     44 / 49 loss=0.106, ppl=1.08, wps=27339.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.423, loss_scale=32, train_wall=202, gb_free=8.8, wall=64459
2022-03-06 08:16:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:16:32 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 22.696 | ppl 6.79698e+06 | wps 48474.6 | wpb 510.9 | bsz 1 | num_updates 26905 | best_loss 8.449
2022-03-06 08:16:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26905 updates
2022-03-06 08:16:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:16:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:16:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 553 @ 26905 updates, score 22.696) (writing took 1.8652788689360023 seconds)
2022-03-06 08:16:34 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-06 08:16:34 | INFO | train | epoch 553 | loss 0.105 | ppl 1.08 | wps 27301.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26905 | lr 0.00019279 | gnorm 0.42 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 64476
2022-03-06 08:16:34 | INFO | fairseq.trainer | begin training epoch 554
2022-03-06 08:16:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:17:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:18:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:18:28 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 22.73 | ppl 6.95739e+06 | wps 48573.7 | wpb 510.9 | bsz 1 | num_updates 26953 | best_loss 8.449
2022-03-06 08:18:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26953 updates
2022-03-06 08:18:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:18:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:18:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 554 @ 26953 updates, score 22.73) (writing took 1.8508458556607366 seconds)
2022-03-06 08:18:30 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-06 08:18:30 | INFO | train | epoch 554 | loss 0.106 | ppl 1.08 | wps 26761.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 26953 | lr 0.000192618 | gnorm 0.422 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 64592
2022-03-06 08:18:30 | INFO | fairseq.trainer | begin training epoch 555
2022-03-06 08:18:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:20:17 | INFO | train_inner | epoch 555:     47 / 49 loss=0.106, ppl=1.08, wps=27096.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.424, loss_scale=32, train_wall=204, gb_free=8.8, wall=64699
2022-03-06 08:20:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:20:25 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 22.769 | ppl 7.14544e+06 | wps 48586.1 | wpb 510.9 | bsz 1 | num_updates 27002 | best_loss 8.449
2022-03-06 08:20:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27002 updates
2022-03-06 08:20:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:20:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:20:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 555 @ 27002 updates, score 22.769) (writing took 1.8848014092072845 seconds)
2022-03-06 08:20:27 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-06 08:20:27 | INFO | train | epoch 555 | loss 0.106 | ppl 1.08 | wps 27320.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27002 | lr 0.000192443 | gnorm 0.427 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 64709
2022-03-06 08:20:27 | INFO | fairseq.trainer | begin training epoch 556
2022-03-06 08:20:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:22:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:22:21 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 22.664 | ppl 6.64714e+06 | wps 48474.8 | wpb 510.9 | bsz 1 | num_updates 27051 | best_loss 8.449
2022-03-06 08:22:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27051 updates
2022-03-06 08:22:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:22:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:22:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 556 @ 27051 updates, score 22.664) (writing took 1.872718010097742 seconds)
2022-03-06 08:22:23 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-06 08:22:23 | INFO | train | epoch 556 | loss 0.105 | ppl 1.08 | wps 27312.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27051 | lr 0.000192269 | gnorm 0.419 | loss_scale 64 | train_wall 99 | gb_free 8.8 | wall 64825
2022-03-06 08:22:23 | INFO | fairseq.trainer | begin training epoch 557
2022-03-06 08:22:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:22:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:23:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 08:24:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:24:17 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 22.757 | ppl 7.09002e+06 | wps 48645.4 | wpb 510.9 | bsz 1 | num_updates 27098 | best_loss 8.449
2022-03-06 08:24:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27098 updates
2022-03-06 08:24:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:24:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:24:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 557 @ 27098 updates, score 22.757) (writing took 1.8778001964092255 seconds)
2022-03-06 08:24:19 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-06 08:24:19 | INFO | train | epoch 557 | loss 0.106 | ppl 1.08 | wps 26187.6 | ups 0.4 | wpb 64829.4 | bsz 126.6 | num_updates 27098 | lr 0.000192102 | gnorm 0.427 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 64941
2022-03-06 08:24:19 | INFO | fairseq.trainer | begin training epoch 558
2022-03-06 08:24:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:24:24 | INFO | train_inner | epoch 558:      2 / 49 loss=0.106, ppl=1.08, wps=26105.7, ups=0.4, wpb=64544.1, bsz=126.1, num_updates=27100, lr=0.000192095, gnorm=0.424, loss_scale=16, train_wall=206, gb_free=8.8, wall=64946
2022-03-06 08:26:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:26:14 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 22.749 | ppl 7.04864e+06 | wps 48681 | wpb 510.9 | bsz 1 | num_updates 27147 | best_loss 8.449
2022-03-06 08:26:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27147 updates
2022-03-06 08:26:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:26:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:26:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 558 @ 27147 updates, score 22.749) (writing took 1.8911091703921556 seconds)
2022-03-06 08:26:16 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-06 08:26:16 | INFO | train | epoch 558 | loss 0.106 | ppl 1.08 | wps 27302.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27147 | lr 0.000191928 | gnorm 0.424 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 65058
2022-03-06 08:26:16 | INFO | fairseq.trainer | begin training epoch 559
2022-03-06 08:26:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:28:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:28:10 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 22.667 | ppl 6.65798e+06 | wps 48659.7 | wpb 510.9 | bsz 1 | num_updates 27196 | best_loss 8.449
2022-03-06 08:28:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27196 updates
2022-03-06 08:28:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:28:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:28:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 559 @ 27196 updates, score 22.667) (writing took 1.8961065486073494 seconds)
2022-03-06 08:28:12 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-06 08:28:12 | INFO | train | epoch 559 | loss 0.105 | ppl 1.08 | wps 27311.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27196 | lr 0.000191755 | gnorm 0.423 | loss_scale 16 | train_wall 99 | gb_free 8.8 | wall 65174
2022-03-06 08:28:12 | INFO | fairseq.trainer | begin training epoch 560
2022-03-06 08:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:28:21 | INFO | train_inner | epoch 560:      4 / 49 loss=0.105, ppl=1.08, wps=27343.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27200, lr=0.000191741, gnorm=0.424, loss_scale=16, train_wall=202, gb_free=8.8, wall=65183
2022-03-06 08:30:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:30:07 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 22.777 | ppl 7.1869e+06 | wps 48645.7 | wpb 510.9 | bsz 1 | num_updates 27245 | best_loss 8.449
2022-03-06 08:30:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27245 updates
2022-03-06 08:30:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:30:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:30:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 560 @ 27245 updates, score 22.777) (writing took 1.8855513203889132 seconds)
2022-03-06 08:30:08 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-06 08:30:08 | INFO | train | epoch 560 | loss 0.104 | ppl 1.08 | wps 27303.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27245 | lr 0.000191583 | gnorm 0.42 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 65290
2022-03-06 08:30:08 | INFO | fairseq.trainer | begin training epoch 561
2022-03-06 08:30:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:31:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:32:03 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 22.888 | ppl 7.76323e+06 | wps 48466.2 | wpb 510.9 | bsz 1 | num_updates 27294 | best_loss 8.449
2022-03-06 08:32:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27294 updates
2022-03-06 08:32:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:32:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:32:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 561 @ 27294 updates, score 22.888) (writing took 1.8869005367159843 seconds)
2022-03-06 08:32:05 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-06 08:32:05 | INFO | train | epoch 561 | loss 0.104 | ppl 1.07 | wps 27295.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27294 | lr 0.000191411 | gnorm 0.419 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 65407
2022-03-06 08:32:05 | INFO | fairseq.trainer | begin training epoch 562
2022-03-06 08:32:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:32:19 | INFO | train_inner | epoch 562:      6 / 49 loss=0.104, ppl=1.07, wps=27332.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27300, lr=0.00019139, gnorm=0.42, loss_scale=32, train_wall=202, gb_free=8.8, wall=65421
2022-03-06 08:33:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:33:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:33:59 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 22.731 | ppl 6.95943e+06 | wps 48610.4 | wpb 510.9 | bsz 1 | num_updates 27342 | best_loss 8.449
2022-03-06 08:33:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27342 updates
2022-03-06 08:33:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:34:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:34:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 562 @ 27342 updates, score 22.731) (writing took 1.8789295461028814 seconds)
2022-03-06 08:34:01 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-06 08:34:01 | INFO | train | epoch 562 | loss 0.104 | ppl 1.07 | wps 26749.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 27342 | lr 0.000191243 | gnorm 0.419 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 65523
2022-03-06 08:34:01 | INFO | fairseq.trainer | begin training epoch 563
2022-03-06 08:34:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:35:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:35:56 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 22.741 | ppl 7.01077e+06 | wps 48754.2 | wpb 510.9 | bsz 1 | num_updates 27391 | best_loss 8.449
2022-03-06 08:35:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27391 updates
2022-03-06 08:35:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:35:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:35:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 563 @ 27391 updates, score 22.741) (writing took 1.8972441954538226 seconds)
2022-03-06 08:35:58 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-06 08:35:58 | INFO | train | epoch 563 | loss 0.104 | ppl 1.08 | wps 27294 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27391 | lr 0.000191072 | gnorm 0.422 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 65640
2022-03-06 08:35:58 | INFO | fairseq.trainer | begin training epoch 564
2022-03-06 08:35:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:36:18 | INFO | train_inner | epoch 564:      9 / 49 loss=0.104, ppl=1.07, wps=27077.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.42, loss_scale=32, train_wall=204, gb_free=8.8, wall=65660
2022-03-06 08:37:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:37:52 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 22.83 | ppl 7.45427e+06 | wps 48468.6 | wpb 510.9 | bsz 1 | num_updates 27440 | best_loss 8.449
2022-03-06 08:37:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27440 updates
2022-03-06 08:37:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:37:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:37:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 564 @ 27440 updates, score 22.83) (writing took 1.8773231701925397 seconds)
2022-03-06 08:37:54 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-06 08:37:54 | INFO | train | epoch 564 | loss 0.105 | ppl 1.08 | wps 27323.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27440 | lr 0.000190901 | gnorm 0.422 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 65756
2022-03-06 08:37:54 | INFO | fairseq.trainer | begin training epoch 565
2022-03-06 08:37:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:38:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:39:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:39:48 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 22.736 | ppl 6.98608e+06 | wps 48619.6 | wpb 510.9 | bsz 1 | num_updates 27488 | best_loss 8.449
2022-03-06 08:39:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27488 updates
2022-03-06 08:39:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:39:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:39:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 565 @ 27488 updates, score 22.736) (writing took 1.9034394975751638 seconds)
2022-03-06 08:39:50 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-06 08:39:50 | INFO | train | epoch 565 | loss 0.104 | ppl 1.07 | wps 26742.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 27488 | lr 0.000190734 | gnorm 0.424 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 65872
2022-03-06 08:39:50 | INFO | fairseq.trainer | begin training epoch 566
2022-03-06 08:39:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:40:18 | INFO | train_inner | epoch 566:     12 / 49 loss=0.104, ppl=1.07, wps=27085.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.422, loss_scale=32, train_wall=204, gb_free=8.8, wall=65900
2022-03-06 08:41:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:41:45 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 22.896 | ppl 7.80376e+06 | wps 48632.7 | wpb 510.9 | bsz 1 | num_updates 27537 | best_loss 8.449
2022-03-06 08:41:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27537 updates
2022-03-06 08:41:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:41:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:41:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 566 @ 27537 updates, score 22.896) (writing took 1.873665440827608 seconds)
2022-03-06 08:41:47 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-06 08:41:47 | INFO | train | epoch 566 | loss 0.103 | ppl 1.07 | wps 27303.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27537 | lr 0.000190564 | gnorm 0.417 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 65989
2022-03-06 08:41:47 | INFO | fairseq.trainer | begin training epoch 567
2022-03-06 08:41:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:43:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:43:41 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 22.887 | ppl 7.75598e+06 | wps 48175.4 | wpb 510.9 | bsz 1 | num_updates 27586 | best_loss 8.449
2022-03-06 08:43:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27586 updates
2022-03-06 08:43:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:43:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:43:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 567 @ 27586 updates, score 22.887) (writing took 1.8900339249521494 seconds)
2022-03-06 08:43:43 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-06 08:43:43 | INFO | train | epoch 567 | loss 0.103 | ppl 1.07 | wps 27290.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27586 | lr 0.000190395 | gnorm 0.416 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 66105
2022-03-06 08:43:43 | INFO | fairseq.trainer | begin training epoch 568
2022-03-06 08:43:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:43:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:44:17 | INFO | train_inner | epoch 568:     15 / 49 loss=0.103, ppl=1.07, wps=27072.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.417, loss_scale=32, train_wall=204, gb_free=8.8, wall=66139
2022-03-06 08:45:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:45:38 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 22.883 | ppl 7.73528e+06 | wps 48562.6 | wpb 510.9 | bsz 1 | num_updates 27634 | best_loss 8.449
2022-03-06 08:45:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27634 updates
2022-03-06 08:45:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:45:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:45:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 568 @ 27634 updates, score 22.883) (writing took 1.8748652106150985 seconds)
2022-03-06 08:45:40 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-06 08:45:40 | INFO | train | epoch 568 | loss 0.102 | ppl 1.07 | wps 26757.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 27634 | lr 0.00019023 | gnorm 0.416 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 66222
2022-03-06 08:45:40 | INFO | fairseq.trainer | begin training epoch 569
2022-03-06 08:45:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:47:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:47:34 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 22.772 | ppl 7.16115e+06 | wps 48504.7 | wpb 510.9 | bsz 1 | num_updates 27683 | best_loss 8.449
2022-03-06 08:47:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27683 updates
2022-03-06 08:47:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:47:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:47:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 569 @ 27683 updates, score 22.772) (writing took 1.8811890631914139 seconds)
2022-03-06 08:47:36 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-06 08:47:36 | INFO | train | epoch 569 | loss 0.103 | ppl 1.07 | wps 27309.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27683 | lr 0.000190061 | gnorm 0.416 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 66338
2022-03-06 08:47:36 | INFO | fairseq.trainer | begin training epoch 570
2022-03-06 08:47:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:48:14 | INFO | train_inner | epoch 570:     17 / 49 loss=0.103, ppl=1.07, wps=27345.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.416, loss_scale=32, train_wall=202, gb_free=8.8, wall=66377
2022-03-06 08:49:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:49:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:49:30 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 22.906 | ppl 7.85769e+06 | wps 48660.5 | wpb 510.9 | bsz 1 | num_updates 27731 | best_loss 8.449
2022-03-06 08:49:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27731 updates
2022-03-06 08:49:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:49:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:49:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 570 @ 27731 updates, score 22.906) (writing took 1.9004056947305799 seconds)
2022-03-06 08:49:32 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-06 08:49:32 | INFO | train | epoch 570 | loss 0.103 | ppl 1.07 | wps 26758.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 27731 | lr 0.000189897 | gnorm 0.42 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 66454
2022-03-06 08:49:32 | INFO | fairseq.trainer | begin training epoch 571
2022-03-06 08:49:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:51:27 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 22.809 | ppl 7.34738e+06 | wps 48585.3 | wpb 510.9 | bsz 1 | num_updates 27780 | best_loss 8.449
2022-03-06 08:51:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27780 updates
2022-03-06 08:51:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:51:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:51:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 571 @ 27780 updates, score 22.809) (writing took 1.8911349577829242 seconds)
2022-03-06 08:51:29 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-06 08:51:29 | INFO | train | epoch 571 | loss 0.103 | ppl 1.07 | wps 27301.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27780 | lr 0.000189729 | gnorm 0.418 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 66571
2022-03-06 08:51:29 | INFO | fairseq.trainer | begin training epoch 572
2022-03-06 08:51:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:52:14 | INFO | train_inner | epoch 572:     20 / 49 loss=0.103, ppl=1.07, wps=27083.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.419, loss_scale=32, train_wall=204, gb_free=8.8, wall=66616
2022-03-06 08:53:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:53:23 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 22.866 | ppl 7.64424e+06 | wps 48397.6 | wpb 510.9 | bsz 1 | num_updates 27829 | best_loss 8.449
2022-03-06 08:53:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27829 updates
2022-03-06 08:53:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:53:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:53:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 572 @ 27829 updates, score 22.866) (writing took 1.869174568913877 seconds)
2022-03-06 08:53:25 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-06 08:53:25 | INFO | train | epoch 572 | loss 0.103 | ppl 1.07 | wps 27299.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27829 | lr 0.000189562 | gnorm 0.419 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 66687
2022-03-06 08:53:25 | INFO | fairseq.trainer | begin training epoch 573
2022-03-06 08:53:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:54:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:55:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:55:20 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 22.717 | ppl 6.8966e+06 | wps 48680.8 | wpb 510.9 | bsz 1 | num_updates 27877 | best_loss 8.449
2022-03-06 08:55:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27877 updates
2022-03-06 08:55:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:55:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt
2022-03-06 08:55:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#1/checkpoint_last.pt (epoch 573 @ 27877 updates, score 22.717) (writing took 1.8904132647439837 seconds)
2022-03-06 08:55:21 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-06 08:55:21 | INFO | train | epoch 573 | loss 0.102 | ppl 1.07 | wps 26745.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 27877 | lr 0.000189399 | gnorm 0.42 | loss_scale 32 | train_wall 99 | gb_free 8.8 | wall 66803
2022-03-06 08:55:21 | INFO | fairseq.trainer | begin training epoch 574
2022-03-06 08:55:21 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
Exception in thread Thread-2294:
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/threading.py", line 932, in _bootstrap_inner
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    self.run()
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/threading.py", line 870, in run
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    self._target(*self._args, **self._kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/utils/data/_utils/pin_memory.py", line 25, in _pin_memory_loop
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 116, in get
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 324, in train
    return _ForkingPickler.loads(res)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    for i, samples in enumerate(progress):
  File "/cluster/home/andriusb/fq/fairseq/fairseq/logging/progress_bar.py", line 261, in __iter__
    for i, obj in enumerate(self.iterable, start=self.n):
  File "/cluster/home/andriusb/fq/fairseq/fairseq/data/iterators.py", line 56, in __next__
    fd = df.detach()
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    x = next(self._itr)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/data/iterators.py", line 509, in _chunk_iterator
    c = Client(address, authkey=process.current_process().authkey)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 508, in Client
    for x in itr:
  File "/cluster/home/andriusb/fq/fairseq/fairseq/data/iterators.py", line 56, in __next__
    x = next(self._itr)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/data/iterators.py", line 635, in __next__
    answer_challenge(c, authkey)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 757, in answer_challenge
    item = self._queue.get(True)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/queue.py", line 170, in get
    response = connection.recv_bytes(256)        # reject large message
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    self.not_empty.wait()
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/threading.py", line 302, in wait
    buf = self._recv(4)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 379, in _recv
    waiter.acquire()
KeyboardInterrupt
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
