Sender: LSF System <lsfadmin@eu-g3-074>
Subject: Job 207346371: <w103_fp16_size_0.03125_jelinek_0.02_0.06_0.92_#2> in cluster <euler> Exited

Job <w103_fp16_size_0.03125_jelinek_0.02_0.06_0.92_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 13:33:49 2022
Job was executed on host(s) <eu-g3-074>, in queue <gpuhe.120h>, as user <andriusb> in cluster <euler> at Sun Mar  6 20:39:15 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 20:39:15 2022
Terminated at Tue Mar  8 06:20:45 2022
Results reported at Tue Mar  8 06:20:45 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.02, 0.06, 0.92)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --no-epoch-checkpoints --no-last-checkpoints --seed 66575622 --no-epoch-checkpoints --fp16 --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   121203.37 sec.
    Max Memory :                                 6035 MB
    Average Memory :                             3014.21 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13965.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                16
    Run time :                                   121290 sec.
    Turnaround time :                            146816 sec.

The output (if any) follows:

2022-03-06 20:39:23 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575622, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575622, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.02, 0.06, 0.92)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 20:39:24 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-06 20:39:25 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
Calculating frequency stats:
  0%|          | 0/56292 [00:00<?, ?it/s]  1%|          | 633/56292 [00:00<00:08, 6318.30it/s]  2%|▏         | 1265/56292 [00:00<00:09, 5695.51it/s]  3%|▎         | 1839/56292 [00:00<00:09, 5516.58it/s]  4%|▍         | 2393/56292 [00:00<00:09, 5398.12it/s]  6%|▌         | 3155/56292 [00:00<00:08, 6152.73it/s]  7%|▋         | 3775/56292 [00:00<00:08, 5929.70it/s]  8%|▊         | 4474/56292 [00:00<00:08, 6245.89it/s]  9%|▉         | 5188/56292 [00:00<00:07, 6519.56it/s] 10%|█         | 5880/56292 [00:00<00:07, 6641.33it/s] 12%|█▏        | 6548/56292 [00:01<00:08, 6059.06it/s] 13%|█▎        | 7165/56292 [00:01<00:08, 5629.77it/s] 14%|█▎        | 7740/56292 [00:01<00:08, 5629.27it/s] 15%|█▍        | 8331/56292 [00:01<00:08, 5707.08it/s] 16%|█▌        | 8909/56292 [00:01<00:08, 5725.29it/s] 17%|█▋        | 9488/56292 [00:01<00:08, 5737.15it/s] 18%|█▊        | 10133/56292 [00:01<00:07, 5945.10it/s] 19%|█▉        | 10731/56292 [00:01<00:07, 5906.35it/s] 20%|██        | 11324/56292 [00:01<00:07, 5805.73it/s] 21%|██▏       | 12005/56292 [00:02<00:07, 6098.00it/s] 22%|██▏       | 12617/56292 [00:02<00:07, 5957.45it/s] 24%|██▎       | 13249/56292 [00:02<00:07, 6052.42it/s] 25%|██▍       | 13908/56292 [00:02<00:06, 6205.00it/s] 26%|██▌       | 14530/56292 [00:02<00:06, 6046.15it/s] 27%|██▋       | 15244/56292 [00:02<00:06, 6361.47it/s] 28%|██▊       | 15883/56292 [00:02<00:06, 6036.54it/s] 29%|██▉       | 16492/56292 [00:02<00:06, 5872.07it/s] 30%|███       | 17110/56292 [00:02<00:06, 5953.74it/s] 31%|███▏      | 17709/56292 [00:02<00:06, 5919.30it/s] 33%|███▎      | 18303/56292 [00:03<00:06, 5925.09it/s] 34%|███▍      | 19019/56292 [00:03<00:05, 6279.15it/s] 35%|███▍      | 19649/56292 [00:03<00:05, 6265.92it/s] 36%|███▌      | 20277/56292 [00:03<00:06, 5964.44it/s] 37%|███▋      | 20899/56292 [00:03<00:05, 6035.02it/s] 38%|███▊      | 21506/56292 [00:03<00:06, 5703.26it/s] 39%|███▉      | 22133/56292 [00:03<00:05, 5859.75it/s] 41%|████      | 22822/56292 [00:03<00:05, 6152.45it/s] 42%|████▏     | 23460/56292 [00:03<00:05, 6213.09it/s] 43%|████▎     | 24216/56292 [00:04<00:04, 6602.70it/s] 44%|████▍     | 24925/56292 [00:04<00:04, 6744.45it/s] 45%|████▌     | 25602/56292 [00:04<00:04, 6693.73it/s] 47%|████▋     | 26274/56292 [00:04<00:04, 6281.02it/s] 48%|████▊     | 26909/56292 [00:04<00:04, 6051.11it/s] 49%|████▉     | 27520/56292 [00:04<00:04, 5810.31it/s] 50%|█████     | 28165/56292 [00:04<00:04, 5980.60it/s] 51%|█████     | 28845/56292 [00:04<00:04, 6212.24it/s] 52%|█████▏    | 29471/56292 [00:04<00:04, 5956.16it/s] 54%|█████▎    | 30127/56292 [00:04<00:04, 6117.74it/s] 55%|█████▍    | 30743/56292 [00:05<00:04, 5824.28it/s] 56%|█████▌    | 31331/56292 [00:05<00:04, 5805.35it/s] 57%|█████▋    | 31916/56292 [00:05<00:04, 5814.83it/s] 58%|█████▊    | 32500/56292 [00:05<00:04, 5792.35it/s] 59%|█████▉    | 33081/56292 [00:05<00:04, 5564.18it/s] 60%|█████▉    | 33692/56292 [00:05<00:03, 5713.55it/s] 61%|██████    | 34270/56292 [00:05<00:03, 5728.41it/s] 62%|██████▏   | 34985/56292 [00:05<00:03, 6135.71it/s] 63%|██████▎   | 35601/56292 [00:05<00:03, 5978.36it/s] 64%|██████▍   | 36202/56292 [00:06<00:03, 5900.56it/s] 65%|██████▌   | 36794/56292 [00:06<00:03, 5856.04it/s] 66%|██████▋   | 37381/56292 [00:06<00:03, 5582.96it/s] 67%|██████▋   | 37943/56292 [00:06<00:03, 5520.01it/s] 68%|██████▊   | 38537/56292 [00:06<00:03, 5639.33it/s] 70%|██████▉   | 39157/56292 [00:06<00:02, 5800.60it/s] 71%|███████   | 39739/56292 [00:06<00:02, 5798.59it/s] 72%|███████▏  | 40404/56292 [00:06<00:02, 6049.27it/s] 73%|███████▎  | 41022/56292 [00:06<00:02, 6083.84it/s] 74%|███████▍  | 41632/56292 [00:06<00:02, 5953.29it/s] 75%|███████▌  | 42229/56292 [00:07<00:02, 5678.38it/s] 76%|███████▌  | 42800/56292 [00:07<00:02, 5664.86it/s] 77%|███████▋  | 43369/56292 [00:07<00:02, 5629.24it/s] 78%|███████▊  | 44034/56292 [00:07<00:02, 5919.21it/s] 79%|███████▉  | 44699/56292 [00:07<00:01, 6128.70it/s] 80%|████████  | 45314/56292 [00:07<00:01, 5983.74it/s] 82%|████████▏ | 45982/56292 [00:07<00:01, 6180.55it/s] 83%|████████▎ | 46624/56292 [00:07<00:01, 6249.73it/s] 84%|████████▍ | 47474/56292 [00:07<00:01, 6914.10it/s] 86%|████████▌ | 48241/56292 [00:08<00:01, 7135.84it/s] 87%|████████▋ | 48957/56292 [00:08<00:01, 6931.05it/s] 88%|████████▊ | 49653/56292 [00:08<00:00, 6938.21it/s] 89%|████████▉ | 50349/56292 [00:08<00:00, 6392.91it/s] 91%|█████████ | 50998/56292 [00:08<00:00, 6217.94it/s] 92%|█████████▏| 51627/56292 [00:08<00:00, 6213.29it/s] 93%|█████████▎| 52455/56292 [00:08<00:00, 6796.41it/s] 94%|█████████▍| 53141/56292 [00:08<00:00, 6499.90it/s] 96%|█████████▌| 53798/56292 [00:08<00:00, 6387.06it/s] 97%|█████████▋| 54442/56292 [00:09<00:00, 5941.70it/s] 98%|█████████▊| 55044/56292 [00:09<00:00, 5908.43it/s] 99%|█████████▉| 55737/56292 [00:09<00:00, 6186.72it/s]100%|██████████| 56292/56292 [00:09<00:00, 6048.91it/s]

gathering stats for n=1
  0%|          | 0/56292 [00:00<?, ?it/s]  3%|▎         | 1890/56292 [00:00<00:02, 18899.30it/s]  7%|▋         | 3942/56292 [00:00<00:02, 19852.04it/s] 11%|█         | 6168/56292 [00:00<00:02, 20945.27it/s] 15%|█▍        | 8263/56292 [00:00<00:02, 20101.94it/s] 18%|█▊        | 10306/56292 [00:00<00:02, 20216.61it/s] 22%|██▏       | 12332/56292 [00:00<00:02, 19745.89it/s] 26%|██▌       | 14399/56292 [00:00<00:02, 20029.07it/s] 29%|██▉       | 16406/56292 [00:00<00:02, 19863.87it/s] 33%|███▎      | 18421/56292 [00:00<00:01, 19942.96it/s] 36%|███▋      | 20544/56292 [00:01<00:01, 20326.24it/s] 40%|████      | 22579/56292 [00:01<00:01, 20242.56it/s] 44%|████▍     | 24874/56292 [00:01<00:01, 21048.89it/s] 48%|████▊     | 26981/56292 [00:01<00:01, 20499.10it/s] 52%|█████▏    | 29052/56292 [00:01<00:01, 20558.22it/s] 55%|█████▌    | 31111/56292 [00:01<00:01, 19854.96it/s] 59%|█████▉    | 33103/56292 [00:01<00:01, 19650.41it/s] 62%|██████▏   | 35138/56292 [00:01<00:01, 19853.19it/s] 66%|██████▌   | 37127/56292 [00:01<00:00, 19767.58it/s] 69%|██████▉   | 39107/56292 [00:01<00:00, 19522.91it/s] 73%|███████▎  | 41195/56292 [00:02<00:00, 19919.69it/s] 77%|███████▋  | 43190/56292 [00:02<00:00, 19351.93it/s] 80%|████████  | 45247/56292 [00:02<00:00, 19705.31it/s] 85%|████████▍ | 47604/56292 [00:02<00:00, 20838.23it/s] 89%|████████▊ | 49830/56292 [00:02<00:00, 21255.31it/s] 92%|█████████▏| 51961/56292 [00:02<00:00, 20821.20it/s] 96%|█████████▌| 54100/56292 [00:02<00:00, 20980.81it/s]100%|█████████▉| 56202/56292 [00:02<00:00, 20707.40it/s]100%|██████████| 56292/56292 [00:02<00:00, 20233.31it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 253.26it/s]2022-03-06 20:39:45 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-06 20:39:45 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 20:39:45 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 20:39:45 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-06 20:39:45 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-06 20:39:45 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 20:39:45 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-06 20:39:45 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 20:39:45 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 20:39:45 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = NVIDIA TITAN RTX                        
2022-03-06 20:39:45 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 20:39:45 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 20:39:45 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 20:39:45 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_last.pt
2022-03-06 20:39:45 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_last.pt
2022-03-06 20:39:45 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 20:39:45 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-06 20:39:45 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 20:39:45 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-06 20:39:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 20:39:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:40:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:40:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:41:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-06 20:42:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:42:24 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.356 | ppl 41952.7 | wps 38999.4 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-06 20:42:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-06 20:42:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:42:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:42:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.356) (writing took 1.9155639009550214 seconds)
2022-03-06 20:42:26 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 20:42:26 | INFO | train | epoch 001 | loss 16.524 | ppl 94265.9 | wps 21288.3 | ups 0.33 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 5.139 | loss_scale 4 | train_wall 143 | gb_free 21.5 | wall 161
2022-03-06 20:42:26 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 20:42:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:44:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:44:50 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.901 | ppl 15300.5 | wps 38692.8 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 13.901
2022-03-06 20:44:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-06 20:44:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:44:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:44:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 2 @ 93 updates, score 13.901) (writing took 1.8181610275059938 seconds)
2022-03-06 20:44:52 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 20:44:52 | INFO | train | epoch 002 | loss 14.647 | ppl 25664.6 | wps 21786.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.208 | loss_scale 4 | train_wall 127 | gb_free 21.5 | wall 307
2022-03-06 20:44:52 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 20:44:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:45:12 | INFO | train_inner | epoch 003:      7 / 49 loss=15.425, ppl=43996.1, wps=21641.7, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.448, loss_scale=4, train_wall=288, gb_free=21.5, wall=327
2022-03-06 20:47:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:47:16 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.243 | ppl 9694.11 | wps 38433.3 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.243
2022-03-06 20:47:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-06 20:47:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:47:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:47:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.243) (writing took 1.9197083758190274 seconds)
2022-03-06 20:47:18 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 20:47:18 | INFO | train | epoch 003 | loss 13.707 | ppl 13371.5 | wps 21778.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.402 | loss_scale 4 | train_wall 127 | gb_free 21.5 | wall 453
2022-03-06 20:47:18 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 20:47:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:49:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:49:42 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.446 | ppl 5578.47 | wps 38571.7 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.446
2022-03-06 20:49:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-06 20:49:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:49:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:49:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.446) (writing took 1.8088868474587798 seconds)
2022-03-06 20:49:44 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 20:49:44 | INFO | train | epoch 004 | loss 12.979 | ppl 8076.1 | wps 21798.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.231 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 599
2022-03-06 20:49:44 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 20:49:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:50:09 | INFO | train_inner | epoch 005:      9 / 49 loss=13.218, ppl=9527.16, wps=21806.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.283, loss_scale=8, train_wall=260, gb_free=21.5, wall=625
2022-03-06 20:52:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:52:08 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.662 | ppl 3240.35 | wps 38532.6 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 11.662
2022-03-06 20:52:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-06 20:52:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:52:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:52:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 5 @ 240 updates, score 11.662) (writing took 1.8428938463330269 seconds)
2022-03-06 20:52:09 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 20:52:09 | INFO | train | epoch 005 | loss 12.129 | ppl 4480.32 | wps 21771.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 0.977 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 745
2022-03-06 20:52:09 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 20:52:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:54:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:54:34 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.037 | ppl 2100.59 | wps 38502.6 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 11.037
2022-03-06 20:54:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-06 20:54:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:54:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 6 @ 289 updates, score 11.037) (writing took 1.8730551339685917 seconds)
2022-03-06 20:54:36 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 20:54:36 | INFO | train | epoch 006 | loss 11.386 | ppl 2676.37 | wps 21761.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.755 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 891
2022-03-06 20:54:36 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 20:54:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:55:07 | INFO | train_inner | epoch 007:     11 / 49 loss=11.609, ppl=3124.48, wps=21793.6, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.826, loss_scale=16, train_wall=260, gb_free=21.5, wall=922
2022-03-06 20:56:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:57:00 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.637 | ppl 1592.36 | wps 38676 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 10.637
2022-03-06 20:57:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-06 20:57:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:57:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:57:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 7 @ 338 updates, score 10.637) (writing took 1.8585785813629627 seconds)
2022-03-06 20:57:02 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 20:57:02 | INFO | train | epoch 007 | loss 10.832 | ppl 1823.44 | wps 21766.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.587 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 1037
2022-03-06 20:57:02 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 20:57:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:59:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:59:26 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.399 | ppl 1350.65 | wps 38893.1 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.399
2022-03-06 20:59:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-06 20:59:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:59:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 20:59:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.399) (writing took 1.8913274640217423 seconds)
2022-03-06 20:59:27 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 20:59:27 | INFO | train | epoch 008 | loss 10.491 | ppl 1438.77 | wps 21778.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.47 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 1183
2022-03-06 20:59:27 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 20:59:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:00:05 | INFO | train_inner | epoch 009:     13 / 49 loss=10.583, ppl=1533.4, wps=21795.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.496, loss_scale=16, train_wall=260, gb_free=21.5, wall=1220
2022-03-06 21:01:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:01:52 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.241 | ppl 1210.37 | wps 39242.3 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.241
2022-03-06 21:01:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-06 21:01:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:01:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:01:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.241) (writing took 1.8992370711639524 seconds)
2022-03-06 21:01:53 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 21:01:53 | INFO | train | epoch 009 | loss 10.28 | ppl 1242.98 | wps 21772.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.455 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 1329
2022-03-06 21:01:53 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 21:01:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:04:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:04:17 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.108 | ppl 1103.61 | wps 39152.4 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 10.108
2022-03-06 21:04:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-06 21:04:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:04:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:04:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 10 @ 485 updates, score 10.108) (writing took 1.9020805917680264 seconds)
2022-03-06 21:04:19 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 21:04:19 | INFO | train | epoch 010 | loss 10.116 | ppl 1110.07 | wps 21774.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.472 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 1475
2022-03-06 21:04:19 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 21:04:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:05:02 | INFO | train_inner | epoch 011:     15 / 49 loss=10.15, ppl=1135.92, wps=21790.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.471, loss_scale=32, train_wall=260, gb_free=21.5, wall=1518
2022-03-06 21:06:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:06:43 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.979 | ppl 1009.05 | wps 39325 | wpb 510.9 | bsz 1 | num_updates 534 | best_loss 9.979
2022-03-06 21:06:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 534 updates
2022-03-06 21:06:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:06:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:06:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 11 @ 534 updates, score 9.979) (writing took 2.152978628873825 seconds)
2022-03-06 21:06:46 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 21:06:46 | INFO | train | epoch 011 | loss 9.966 | ppl 1000.22 | wps 21732 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 534 | lr 6.68367e-05 | gnorm 0.523 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 1621
2022-03-06 21:06:46 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 21:06:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:07:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:09:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:09:10 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.866 | ppl 933.26 | wps 39223.3 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 9.866
2022-03-06 21:09:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-06 21:09:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:09:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:09:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 12 @ 582 updates, score 9.866) (writing took 1.8713393118232489 seconds)
2022-03-06 21:09:11 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 21:09:11 | INFO | train | epoch 012 | loss 9.823 | ppl 905.89 | wps 21336 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.586 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 1767
2022-03-06 21:09:12 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 21:09:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:10:03 | INFO | train_inner | epoch 013:     18 / 49 loss=9.846, ppl=920.58, wps=21582.3, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.578, loss_scale=32, train_wall=262, gb_free=21.5, wall=1818
2022-03-06 21:11:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:11:35 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.762 | ppl 868.03 | wps 39241.5 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 9.762
2022-03-06 21:11:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-06 21:11:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:11:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:11:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 13 @ 631 updates, score 9.762) (writing took 1.8418774344027042 seconds)
2022-03-06 21:11:37 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 21:11:37 | INFO | train | epoch 013 | loss 9.688 | ppl 825.07 | wps 21789.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.619 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 1913
2022-03-06 21:11:37 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 21:11:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:13:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:13:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:14:01 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.666 | ppl 812.36 | wps 39250.8 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 9.666
2022-03-06 21:14:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-06 21:14:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:14:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:14:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 14 @ 679 updates, score 9.666) (writing took 1.8197422018274665 seconds)
2022-03-06 21:14:03 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 21:14:03 | INFO | train | epoch 014 | loss 9.56 | ppl 754.75 | wps 21326 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.657 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 2059
2022-03-06 21:14:03 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 21:14:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:15:03 | INFO | train_inner | epoch 015:     21 / 49 loss=9.573, ppl=761.73, wps=21597.3, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.665, loss_scale=32, train_wall=263, gb_free=21.5, wall=2118
2022-03-06 21:16:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:16:27 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.566 | ppl 758.2 | wps 39121.6 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.566
2022-03-06 21:16:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-06 21:16:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:16:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:16:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.566) (writing took 1.834882172755897 seconds)
2022-03-06 21:16:29 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 21:16:29 | INFO | train | epoch 015 | loss 9.435 | ppl 691.97 | wps 21792.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.728 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 2204
2022-03-06 21:16:29 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 21:16:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:18:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:18:53 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.471 | ppl 709.83 | wps 39241.5 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 9.471
2022-03-06 21:18:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-06 21:18:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:18:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:18:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 16 @ 777 updates, score 9.471) (writing took 1.8353828890249133 seconds)
2022-03-06 21:18:55 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 21:18:55 | INFO | train | epoch 016 | loss 9.312 | ppl 635.8 | wps 21766.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.777 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 2350
2022-03-06 21:18:55 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 21:18:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:20:01 | INFO | train_inner | epoch 017:     23 / 49 loss=9.318, ppl=638.21, wps=21803.6, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.75, loss_scale=32, train_wall=260, gb_free=21.5, wall=2416
2022-03-06 21:20:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:21:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:21:19 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.383 | ppl 667.73 | wps 39357.4 | wpb 510.9 | bsz 1 | num_updates 825 | best_loss 9.383
2022-03-06 21:21:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 825 updates
2022-03-06 21:21:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:21:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:21:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 17 @ 825 updates, score 9.383) (writing took 1.8629493108019233 seconds)
2022-03-06 21:21:21 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 21:21:21 | INFO | train | epoch 017 | loss 9.193 | ppl 585.17 | wps 21334.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 825 | lr 0.000103204 | gnorm 0.779 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 2496
2022-03-06 21:21:21 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 21:21:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:23:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:23:45 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.301 | ppl 630.62 | wps 39306.5 | wpb 510.9 | bsz 1 | num_updates 874 | best_loss 9.301
2022-03-06 21:23:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 874 updates
2022-03-06 21:23:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:23:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:23:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 18 @ 874 updates, score 9.301) (writing took 1.841701908968389 seconds)
2022-03-06 21:23:47 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 21:23:47 | INFO | train | epoch 018 | loss 9.078 | ppl 540.61 | wps 21793.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 874 | lr 0.000109328 | gnorm 0.793 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 2642
2022-03-06 21:23:47 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 21:23:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:25:01 | INFO | train_inner | epoch 019:     26 / 49 loss=9.077, ppl=540.03, wps=21605.3, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.806, loss_scale=32, train_wall=263, gb_free=21.5, wall=2716
2022-03-06 21:26:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:26:11 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.224 | ppl 598.04 | wps 38602.3 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 9.224
2022-03-06 21:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-06 21:26:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:26:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:26:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 19 @ 923 updates, score 9.224) (writing took 1.8055651998147368 seconds)
2022-03-06 21:26:13 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 21:26:13 | INFO | train | epoch 019 | loss 8.969 | ppl 501.1 | wps 21781.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.873 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 2788
2022-03-06 21:26:13 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 21:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:28:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:28:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:28:37 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.166 | ppl 574.32 | wps 39059.1 | wpb 510.9 | bsz 1 | num_updates 971 | best_loss 9.166
2022-03-06 21:28:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 971 updates
2022-03-06 21:28:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:28:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:28:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 20 @ 971 updates, score 9.166) (writing took 1.838779223151505 seconds)
2022-03-06 21:28:39 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 21:28:39 | INFO | train | epoch 020 | loss 8.862 | ppl 465.42 | wps 21344.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 971 | lr 0.000121451 | gnorm 0.819 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 2934
2022-03-06 21:28:39 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 21:28:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:30:01 | INFO | train_inner | epoch 021:     29 / 49 loss=8.856, ppl=463.36, wps=21599.5, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.843, loss_scale=32, train_wall=263, gb_free=21.5, wall=3017
2022-03-06 21:30:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:31:03 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.106 | ppl 551.12 | wps 39097.9 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 9.106
2022-03-06 21:31:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-06 21:31:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:31:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:31:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 21 @ 1020 updates, score 9.106) (writing took 1.8831962496042252 seconds)
2022-03-06 21:31:05 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 21:31:05 | INFO | train | epoch 021 | loss 8.759 | ppl 433.23 | wps 21767.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.831 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 3080
2022-03-06 21:31:05 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 21:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:33:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:33:29 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.054 | ppl 531.52 | wps 39144.6 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 9.054
2022-03-06 21:33:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-06 21:33:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:33:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:33:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 22 @ 1069 updates, score 9.054) (writing took 1.795373311266303 seconds)
2022-03-06 21:33:30 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 21:33:30 | INFO | train | epoch 022 | loss 8.66 | ppl 404.57 | wps 21783.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.881 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 3226
2022-03-06 21:33:30 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 21:33:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:34:59 | INFO | train_inner | epoch 023:     31 / 49 loss=8.647, ppl=400.86, wps=21797.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.881, loss_scale=64, train_wall=260, gb_free=21.5, wall=3314
2022-03-06 21:35:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:35:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:35:55 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.009 | ppl 515.08 | wps 39218.7 | wpb 510.9 | bsz 1 | num_updates 1117 | best_loss 9.009
2022-03-06 21:35:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1117 updates
2022-03-06 21:35:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:35:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:35:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 23 @ 1117 updates, score 9.009) (writing took 1.8398737581446767 seconds)
2022-03-06 21:35:56 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 21:35:56 | INFO | train | epoch 023 | loss 8.563 | ppl 378.3 | wps 21327.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1117 | lr 0.000139697 | gnorm 0.884 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 3372
2022-03-06 21:35:56 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 21:35:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:38:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:38:21 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.963 | ppl 499.18 | wps 39220.5 | wpb 510.9 | bsz 1 | num_updates 1166 | best_loss 8.963
2022-03-06 21:38:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1166 updates
2022-03-06 21:38:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:38:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:38:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 24 @ 1166 updates, score 8.963) (writing took 1.864136871881783 seconds)
2022-03-06 21:38:22 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 21:38:22 | INFO | train | epoch 024 | loss 8.469 | ppl 354.39 | wps 21761.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1166 | lr 0.000145821 | gnorm 0.876 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 3518
2022-03-06 21:38:22 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 21:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:39:59 | INFO | train_inner | epoch 025:     34 / 49 loss=8.454, ppl=350.63, wps=21591, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.877, loss_scale=32, train_wall=263, gb_free=21.5, wall=3615
2022-03-06 21:40:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:40:46 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.914 | ppl 482.22 | wps 39300.8 | wpb 510.9 | bsz 1 | num_updates 1215 | best_loss 8.914
2022-03-06 21:40:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1215 updates
2022-03-06 21:40:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:40:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:40:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 25 @ 1215 updates, score 8.914) (writing took 1.9680937211960554 seconds)
2022-03-06 21:40:48 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 21:40:48 | INFO | train | epoch 025 | loss 8.376 | ppl 332.15 | wps 21767.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1215 | lr 0.000151945 | gnorm 0.865 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 3664
2022-03-06 21:40:48 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 21:40:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:41:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:43:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:43:13 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.886 | ppl 473.05 | wps 39128.7 | wpb 510.9 | bsz 1 | num_updates 1263 | best_loss 8.886
2022-03-06 21:43:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1263 updates
2022-03-06 21:43:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:43:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:43:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 26 @ 1263 updates, score 8.886) (writing took 1.8629739321768284 seconds)
2022-03-06 21:43:14 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 21:43:14 | INFO | train | epoch 026 | loss 8.283 | ppl 311.59 | wps 21320.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1263 | lr 0.000157943 | gnorm 0.923 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 3810
2022-03-06 21:43:14 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 21:43:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:45:00 | INFO | train_inner | epoch 027:     37 / 49 loss=8.263, ppl=307.21, wps=21580.4, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=0.897, loss_scale=32, train_wall=263, gb_free=21.5, wall=3915
2022-03-06 21:45:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:45:39 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.842 | ppl 459 | wps 39099.7 | wpb 510.9 | bsz 1 | num_updates 1312 | best_loss 8.842
2022-03-06 21:45:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1312 updates
2022-03-06 21:45:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:45:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:45:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 27 @ 1312 updates, score 8.842) (writing took 1.8501640809699893 seconds)
2022-03-06 21:45:40 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 21:45:40 | INFO | train | epoch 027 | loss 8.193 | ppl 292.56 | wps 21770.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1312 | lr 0.000164067 | gnorm 0.892 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 3956
2022-03-06 21:45:40 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 21:45:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:47:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:47:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:48:05 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.796 | ppl 444.49 | wps 39075.1 | wpb 510.9 | bsz 1 | num_updates 1360 | best_loss 8.796
2022-03-06 21:48:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1360 updates
2022-03-06 21:48:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:48:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:48:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 28 @ 1360 updates, score 8.796) (writing took 1.8470339169725776 seconds)
2022-03-06 21:48:06 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 21:48:06 | INFO | train | epoch 028 | loss 8.099 | ppl 274.21 | wps 21315.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1360 | lr 0.000170066 | gnorm 0.879 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 4102
2022-03-06 21:48:06 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 21:48:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:50:01 | INFO | train_inner | epoch 029:     40 / 49 loss=8.073, ppl=269.38, wps=21589.3, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=0.908, loss_scale=32, train_wall=262, gb_free=21.5, wall=4216
2022-03-06 21:50:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:50:30 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.771 | ppl 436.82 | wps 39302.3 | wpb 510.9 | bsz 1 | num_updates 1409 | best_loss 8.771
2022-03-06 21:50:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1409 updates
2022-03-06 21:50:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:50:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:50:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 29 @ 1409 updates, score 8.771) (writing took 1.8249573577195406 seconds)
2022-03-06 21:50:32 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 21:50:32 | INFO | train | epoch 029 | loss 8.011 | ppl 257.9 | wps 21792.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1409 | lr 0.00017619 | gnorm 0.93 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 4248
2022-03-06 21:50:32 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 21:50:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:52:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:52:56 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.738 | ppl 427.07 | wps 39174.5 | wpb 510.9 | bsz 1 | num_updates 1458 | best_loss 8.738
2022-03-06 21:52:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1458 updates
2022-03-06 21:52:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:52:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:52:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 30 @ 1458 updates, score 8.738) (writing took 1.8792510507628322 seconds)
2022-03-06 21:52:58 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 21:52:58 | INFO | train | epoch 030 | loss 7.917 | ppl 241.7 | wps 21780.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1458 | lr 0.000182314 | gnorm 0.885 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 4393
2022-03-06 21:52:58 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 21:52:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:54:58 | INFO | train_inner | epoch 031:     42 / 49 loss=7.884, ppl=236.23, wps=21798.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=0.886, loss_scale=64, train_wall=260, gb_free=21.5, wall=4513
2022-03-06 21:55:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:55:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:55:22 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.707 | ppl 417.84 | wps 39136.1 | wpb 510.9 | bsz 1 | num_updates 1506 | best_loss 8.707
2022-03-06 21:55:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1506 updates
2022-03-06 21:55:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:55:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:55:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 31 @ 1506 updates, score 8.707) (writing took 1.8854187093675137 seconds)
2022-03-06 21:55:24 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 21:55:24 | INFO | train | epoch 031 | loss 7.823 | ppl 226.39 | wps 21310.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1506 | lr 0.000188312 | gnorm 0.892 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 4539
2022-03-06 21:55:24 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 21:55:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:57:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:57:48 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.676 | ppl 409.03 | wps 39215.4 | wpb 510.9 | bsz 1 | num_updates 1555 | best_loss 8.676
2022-03-06 21:57:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1555 updates
2022-03-06 21:57:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:57:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 21:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 32 @ 1555 updates, score 8.676) (writing took 1.7831356571987271 seconds)
2022-03-06 21:57:50 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 21:57:50 | INFO | train | epoch 032 | loss 7.736 | ppl 213.13 | wps 21796.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1555 | lr 0.000194436 | gnorm 0.942 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 4685
2022-03-06 21:57:50 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 21:57:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:59:58 | INFO | train_inner | epoch 033:     45 / 49 loss=7.697, ppl=207.44, wps=21600.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=0.915, loss_scale=32, train_wall=263, gb_free=21.5, wall=4814
2022-03-06 22:00:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:00:14 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.661 | ppl 404.75 | wps 39086.9 | wpb 510.9 | bsz 1 | num_updates 1604 | best_loss 8.661
2022-03-06 22:00:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1604 updates
2022-03-06 22:00:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 22:00:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 22:00:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 33 @ 1604 updates, score 8.661) (writing took 1.873607357032597 seconds)
2022-03-06 22:00:16 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 22:00:16 | INFO | train | epoch 033 | loss 7.64 | ppl 199.46 | wps 21775.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1604 | lr 0.00020056 | gnorm 0.887 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 4831
2022-03-06 22:00:16 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 22:00:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:02:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:02:40 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.656 | ppl 403.36 | wps 39018.8 | wpb 510.9 | bsz 1 | num_updates 1653 | best_loss 8.656
2022-03-06 22:02:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1653 updates
2022-03-06 22:02:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 22:02:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 22:02:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 34 @ 1653 updates, score 8.656) (writing took 1.8297749692574143 seconds)
2022-03-06 22:02:42 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 22:02:42 | INFO | train | epoch 034 | loss 7.55 | ppl 187.37 | wps 21749.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1653 | lr 0.000206684 | gnorm 0.924 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 4977
2022-03-06 22:02:42 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 22:02:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:02:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:04:59 | INFO | train_inner | epoch 035:     48 / 49 loss=7.511, ppl=182.38, wps=21580.8, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=0.932, loss_scale=32, train_wall=263, gb_free=21.5, wall=5114
2022-03-06 22:05:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:05:06 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.642 | ppl 399.62 | wps 39113.9 | wpb 510.9 | bsz 1 | num_updates 1701 | best_loss 8.642
2022-03-06 22:05:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1701 updates
2022-03-06 22:05:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 22:05:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 22:05:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 35 @ 1701 updates, score 8.642) (writing took 1.837810411117971 seconds)
2022-03-06 22:05:08 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 22:05:08 | INFO | train | epoch 035 | loss 7.461 | ppl 176.19 | wps 21333.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1701 | lr 0.000212682 | gnorm 0.943 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 5123
2022-03-06 22:05:08 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 22:05:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:07:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:07:32 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.631 | ppl 396.49 | wps 39092.5 | wpb 510.9 | bsz 1 | num_updates 1750 | best_loss 8.631
2022-03-06 22:07:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1750 updates
2022-03-06 22:07:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 22:07:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 22:07:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 36 @ 1750 updates, score 8.631) (writing took 1.903273449279368 seconds)
2022-03-06 22:07:34 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 22:07:34 | INFO | train | epoch 036 | loss 7.373 | ppl 165.72 | wps 21771.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1750 | lr 0.000218806 | gnorm 0.972 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 5269
2022-03-06 22:07:34 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 22:07:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:09:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:09:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:09:58 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.621 | ppl 393.69 | wps 39106.1 | wpb 510.9 | bsz 1 | num_updates 1798 | best_loss 8.621
2022-03-06 22:09:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1798 updates
2022-03-06 22:09:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 22:10:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 22:10:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 37 @ 1798 updates, score 8.621) (writing took 1.8180315475910902 seconds)
2022-03-06 22:10:00 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 22:10:00 | INFO | train | epoch 037 | loss 7.284 | ppl 155.8 | wps 21332.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1798 | lr 0.000224805 | gnorm 0.952 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 5415
2022-03-06 22:10:00 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 22:10:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:10:06 | INFO | train_inner | epoch 038:      2 / 49 loss=7.327, ppl=160.56, wps=21049.7, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=0.964, loss_scale=32, train_wall=261, gb_free=21.5, wall=5421
2022-03-06 22:12:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:12:24 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.625 | ppl 394.87 | wps 39095.8 | wpb 510.9 | bsz 1 | num_updates 1847 | best_loss 8.621
2022-03-06 22:12:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1847 updates
2022-03-06 22:12:24 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 22:12:24 | INFO | train | epoch 038 | loss 7.198 | ppl 146.88 | wps 22055.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1847 | lr 0.000230929 | gnorm 0.984 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 5559
2022-03-06 22:12:24 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 22:12:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:14:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:14:48 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.621 | ppl 393.79 | wps 39838.7 | wpb 510.9 | bsz 1 | num_updates 1896 | best_loss 8.621
2022-03-06 22:14:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1896 updates
2022-03-06 22:14:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 22:14:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt
2022-03-06 22:14:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.02_0.06_0.92_#2/checkpoint_best.pt (epoch 39 @ 1896 updates, score 8.621) (writing took 1.9776390260085464 seconds)
2022-03-06 22:14:50 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 22:14:50 | INFO | train | epoch 039 | loss 7.11 | ppl 138.17 | wps 21752.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1896 | lr 0.000237053 | gnorm 0.965 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 5705
2022-03-06 22:14:50 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 22:14:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:15:02 | INFO | train_inner | epoch 040:      4 / 49 loss=7.147, ppl=141.74, wps=21923.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=0.97, loss_scale=32, train_wall=260, gb_free=21.5, wall=5717
2022-03-06 22:15:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:17:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:17:14 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.639 | ppl 398.66 | wps 39134.3 | wpb 510.9 | bsz 1 | num_updates 1944 | best_loss 8.621
2022-03-06 22:17:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1944 updates
2022-03-06 22:17:14 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 22:17:14 | INFO | train | epoch 040 | loss 7.024 | ppl 130.18 | wps 21601.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1944 | lr 0.000243051 | gnorm 1.017 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 5849
2022-03-06 22:17:14 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 22:17:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:19:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:19:38 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.624 | ppl 394.54 | wps 38972.4 | wpb 510.9 | bsz 1 | num_updates 1993 | best_loss 8.621
2022-03-06 22:19:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1993 updates
2022-03-06 22:19:38 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 22:19:38 | INFO | train | epoch 041 | loss 6.94 | ppl 122.75 | wps 22058.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1993 | lr 0.000249175 | gnorm 0.943 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 5993
2022-03-06 22:19:38 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 22:19:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:19:58 | INFO | train_inner | epoch 042:      7 / 49 loss=6.972, ppl=125.52, wps=21860.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=0.996, loss_scale=32, train_wall=262, gb_free=21.5, wall=6014
2022-03-06 22:21:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:22:02 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.671 | ppl 407.55 | wps 39042.9 | wpb 510.9 | bsz 1 | num_updates 2042 | best_loss 8.621
2022-03-06 22:22:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2042 updates
2022-03-06 22:22:02 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 22:22:02 | INFO | train | epoch 042 | loss 6.857 | ppl 115.94 | wps 22041.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2042 | lr 0.000255299 | gnorm 1.013 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 6138
2022-03-06 22:22:02 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 22:22:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:22:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:24:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:24:26 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.657 | ppl 403.64 | wps 39223.2 | wpb 510.9 | bsz 1 | num_updates 2090 | best_loss 8.621
2022-03-06 22:24:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2090 updates
2022-03-06 22:24:26 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 22:24:26 | INFO | train | epoch 043 | loss 6.773 | ppl 109.33 | wps 21611.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2090 | lr 0.000261298 | gnorm 1.034 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 6282
2022-03-06 22:24:26 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 22:24:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:24:55 | INFO | train_inner | epoch 044:     10 / 49 loss=6.799, ppl=111.35, wps=21864.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.016, loss_scale=32, train_wall=262, gb_free=21.5, wall=6310
2022-03-06 22:26:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:26:51 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.688 | ppl 412.4 | wps 39047.7 | wpb 510.9 | bsz 1 | num_updates 2139 | best_loss 8.621
2022-03-06 22:26:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2139 updates
2022-03-06 22:26:51 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 22:26:51 | INFO | train | epoch 044 | loss 6.693 | ppl 103.46 | wps 22051.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2139 | lr 0.000267422 | gnorm 1.089 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 6426
2022-03-06 22:26:51 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 22:26:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:29:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:29:15 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.736 | ppl 426.47 | wps 39218.3 | wpb 510.9 | bsz 1 | num_updates 2188 | best_loss 8.621
2022-03-06 22:29:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2188 updates
2022-03-06 22:29:15 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 22:29:15 | INFO | train | epoch 045 | loss 6.605 | ppl 97.37 | wps 22059.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2188 | lr 0.000273545 | gnorm 0.992 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 6570
2022-03-06 22:29:15 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 22:29:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:29:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:29:52 | INFO | train_inner | epoch 046:     13 / 49 loss=6.63, ppl=99.06, wps=21860.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.072, loss_scale=32, train_wall=262, gb_free=21.5, wall=6607
2022-03-06 22:31:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:31:39 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.747 | ppl 429.64 | wps 39750.7 | wpb 510.9 | bsz 1 | num_updates 2236 | best_loss 8.621
2022-03-06 22:31:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2236 updates
2022-03-06 22:31:39 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 22:31:39 | INFO | train | epoch 046 | loss 6.526 | ppl 92.16 | wps 21604.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2236 | lr 0.000279544 | gnorm 1.095 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 6714
2022-03-06 22:31:39 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 22:31:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:33:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:34:03 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.76 | ppl 433.44 | wps 39159.6 | wpb 510.9 | bsz 1 | num_updates 2285 | best_loss 8.621
2022-03-06 22:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2285 updates
2022-03-06 22:34:03 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 22:34:03 | INFO | train | epoch 047 | loss 6.446 | ppl 87.19 | wps 22071.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2285 | lr 0.000285668 | gnorm 1.094 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 6858
2022-03-06 22:34:03 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 22:34:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:34:46 | INFO | train_inner | epoch 048:     15 / 49 loss=6.46, ppl=88.05, wps=22082.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.062, loss_scale=32, train_wall=260, gb_free=21.5, wall=6901
2022-03-06 22:35:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:36:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:36:27 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.771 | ppl 436.84 | wps 39216.9 | wpb 510.9 | bsz 1 | num_updates 2333 | best_loss 8.621
2022-03-06 22:36:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2333 updates
2022-03-06 22:36:27 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 22:36:27 | INFO | train | epoch 048 | loss 6.362 | ppl 82.25 | wps 21601.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2333 | lr 0.000291667 | gnorm 1.076 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 7002
2022-03-06 22:36:27 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 22:36:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:37:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:38:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:38:51 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.815 | ppl 450.23 | wps 39153 | wpb 510.9 | bsz 1 | num_updates 2381 | best_loss 8.621
2022-03-06 22:38:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2381 updates
2022-03-06 22:38:51 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 22:38:51 | INFO | train | epoch 049 | loss 6.286 | ppl 78.01 | wps 21608.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2381 | lr 0.000297665 | gnorm 1.149 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 7146
2022-03-06 22:38:51 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 22:38:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:39:45 | INFO | train_inner | epoch 050:     19 / 49 loss=6.296, ppl=78.57, wps=21660.8, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.127, loss_scale=16, train_wall=265, gb_free=21.5, wall=7200
2022-03-06 22:41:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:41:15 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.857 | ppl 463.67 | wps 39058.2 | wpb 510.9 | bsz 1 | num_updates 2430 | best_loss 8.621
2022-03-06 22:41:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2430 updates
2022-03-06 22:41:15 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 22:41:15 | INFO | train | epoch 050 | loss 6.202 | ppl 73.63 | wps 22075 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2430 | lr 0.000303789 | gnorm 1.058 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 7290
2022-03-06 22:41:15 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 22:41:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:43:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:43:39 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 8.865 | ppl 466.41 | wps 39271.6 | wpb 510.9 | bsz 1 | num_updates 2479 | best_loss 8.621
2022-03-06 22:43:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2479 updates
2022-03-06 22:43:39 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 22:43:39 | INFO | train | epoch 051 | loss 6.131 | ppl 70.1 | wps 22056.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2479 | lr 0.000309913 | gnorm 1.185 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 7434
2022-03-06 22:43:39 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 22:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:44:39 | INFO | train_inner | epoch 052:     21 / 49 loss=6.132, ppl=70.14, wps=22079.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.118, loss_scale=32, train_wall=260, gb_free=21.5, wall=7494
2022-03-06 22:45:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:46:03 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 8.908 | ppl 480.43 | wps 39135.9 | wpb 510.9 | bsz 1 | num_updates 2528 | best_loss 8.621
2022-03-06 22:46:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2528 updates
2022-03-06 22:46:03 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 22:46:03 | INFO | train | epoch 052 | loss 6.045 | ppl 66.01 | wps 22057.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2528 | lr 0.000316037 | gnorm 1.127 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 7578
2022-03-06 22:46:03 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 22:46:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:48:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:48:27 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 8.922 | ppl 484.94 | wps 39086.2 | wpb 510.9 | bsz 1 | num_updates 2577 | best_loss 8.621
2022-03-06 22:48:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2577 updates
2022-03-06 22:48:27 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 22:48:27 | INFO | train | epoch 053 | loss 5.963 | ppl 62.4 | wps 22063.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2577 | lr 0.000322161 | gnorm 1.116 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 7722
2022-03-06 22:48:27 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 22:48:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:49:33 | INFO | train_inner | epoch 054:     23 / 49 loss=5.97, ppl=62.67, wps=22077.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.152, loss_scale=32, train_wall=260, gb_free=21.5, wall=7788
2022-03-06 22:50:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:50:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:50:51 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 8.977 | ppl 503.86 | wps 39116.6 | wpb 510.9 | bsz 1 | num_updates 2625 | best_loss 8.621
2022-03-06 22:50:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2625 updates
2022-03-06 22:50:51 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 22:50:51 | INFO | train | epoch 054 | loss 5.893 | ppl 59.41 | wps 21592.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2625 | lr 0.000328159 | gnorm 1.242 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 7866
2022-03-06 22:50:51 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 22:50:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:53:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:53:15 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.023 | ppl 520.37 | wps 39187.5 | wpb 510.9 | bsz 1 | num_updates 2674 | best_loss 8.621
2022-03-06 22:53:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2674 updates
2022-03-06 22:53:15 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 22:53:15 | INFO | train | epoch 055 | loss 5.813 | ppl 56.22 | wps 22052.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2674 | lr 0.000334283 | gnorm 1.184 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 8011
2022-03-06 22:53:15 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 22:53:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:54:30 | INFO | train_inner | epoch 056:     26 / 49 loss=5.812, ppl=56.17, wps=21851.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.186, loss_scale=32, train_wall=263, gb_free=21.5, wall=8085
2022-03-06 22:54:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:55:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:55:39 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.064 | ppl 535.23 | wps 39047.9 | wpb 510.9 | bsz 1 | num_updates 2722 | best_loss 8.621
2022-03-06 22:55:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2722 updates
2022-03-06 22:55:39 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 22:55:39 | INFO | train | epoch 056 | loss 5.733 | ppl 53.18 | wps 21589.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2722 | lr 0.000340282 | gnorm 1.209 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 8155
2022-03-06 22:55:39 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 22:55:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:57:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:58:04 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.097 | ppl 547.57 | wps 39209.1 | wpb 510.9 | bsz 1 | num_updates 2771 | best_loss 8.621
2022-03-06 22:58:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2771 updates
2022-03-06 22:58:04 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 22:58:04 | INFO | train | epoch 057 | loss 5.658 | ppl 50.51 | wps 22050 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2771 | lr 0.000346406 | gnorm 1.216 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 8299
2022-03-06 22:58:04 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 22:58:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:59:26 | INFO | train_inner | epoch 058:     29 / 49 loss=5.651, ppl=50.24, wps=21860.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.249, loss_scale=16, train_wall=262, gb_free=21.5, wall=8382
2022-03-06 23:00:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:00:28 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.147 | ppl 566.99 | wps 39169.3 | wpb 510.9 | bsz 1 | num_updates 2820 | best_loss 8.621
2022-03-06 23:00:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2820 updates
2022-03-06 23:00:28 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 23:00:28 | INFO | train | epoch 058 | loss 5.581 | ppl 47.87 | wps 22054.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2820 | lr 0.00035253 | gnorm 1.216 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 8443
2022-03-06 23:00:28 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 23:00:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:02:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:02:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:02:52 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.171 | ppl 576.39 | wps 39194.7 | wpb 510.9 | bsz 1 | num_updates 2868 | best_loss 8.621
2022-03-06 23:02:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2868 updates
2022-03-06 23:02:52 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 23:02:52 | INFO | train | epoch 059 | loss 5.508 | ppl 45.51 | wps 21592 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2868 | lr 0.000358528 | gnorm 1.332 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 8587
2022-03-06 23:02:52 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 23:02:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:04:23 | INFO | train_inner | epoch 060:     32 / 49 loss=5.498, ppl=45.19, wps=21853.8, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.227, loss_scale=16, train_wall=263, gb_free=21.5, wall=8678
2022-03-06 23:05:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:05:16 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.229 | ppl 599.87 | wps 39045.9 | wpb 510.9 | bsz 1 | num_updates 2917 | best_loss 8.621
2022-03-06 23:05:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2917 updates
2022-03-06 23:05:16 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 23:05:16 | INFO | train | epoch 060 | loss 5.432 | ppl 43.17 | wps 22051.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2917 | lr 0.000364652 | gnorm 1.199 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 8731
2022-03-06 23:05:16 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 23:05:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:07:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:07:40 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.286 | ppl 624.43 | wps 39129.8 | wpb 510.9 | bsz 1 | num_updates 2966 | best_loss 8.621
2022-03-06 23:07:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2966 updates
2022-03-06 23:07:40 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 23:07:40 | INFO | train | epoch 061 | loss 5.362 | ppl 41.13 | wps 22070.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2966 | lr 0.000370776 | gnorm 1.334 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 8875
2022-03-06 23:07:40 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 23:07:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:09:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:09:20 | INFO | train_inner | epoch 062:     35 / 49 loss=5.346, ppl=40.66, wps=21864.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.302, loss_scale=16, train_wall=263, gb_free=21.5, wall=8975
2022-03-06 23:09:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:10:04 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.305 | ppl 632.58 | wps 39088.8 | wpb 510.9 | bsz 1 | num_updates 3014 | best_loss 8.621
2022-03-06 23:10:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3014 updates
2022-03-06 23:10:04 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 23:10:04 | INFO | train | epoch 062 | loss 5.28 | ppl 38.87 | wps 21602.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3014 | lr 0.000376775 | gnorm 1.221 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 9019
2022-03-06 23:10:04 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 23:10:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:12:28 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.364 | ppl 659.1 | wps 39317.2 | wpb 510.9 | bsz 1 | num_updates 3063 | best_loss 8.621
2022-03-06 23:12:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3063 updates
2022-03-06 23:12:28 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 23:12:28 | INFO | train | epoch 063 | loss 5.211 | ppl 37.05 | wps 22063.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3063 | lr 0.000382898 | gnorm 1.28 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 9163
2022-03-06 23:12:28 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 23:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:14:14 | INFO | train_inner | epoch 064:     37 / 49 loss=5.195, ppl=36.64, wps=22090.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.292, loss_scale=16, train_wall=260, gb_free=21.5, wall=9269
2022-03-06 23:14:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:14:52 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.382 | ppl 667.23 | wps 39274.3 | wpb 510.9 | bsz 1 | num_updates 3112 | best_loss 8.621
2022-03-06 23:14:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3112 updates
2022-03-06 23:14:52 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 23:14:52 | INFO | train | epoch 064 | loss 5.139 | ppl 35.24 | wps 22084.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3112 | lr 0.000389022 | gnorm 1.343 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 9307
2022-03-06 23:14:52 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 23:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:16:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:17:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:17:16 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.437 | ppl 693.19 | wps 39280 | wpb 510.9 | bsz 1 | num_updates 3160 | best_loss 8.621
2022-03-06 23:17:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3160 updates
2022-03-06 23:17:16 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 23:17:16 | INFO | train | epoch 065 | loss 5.071 | ppl 33.61 | wps 21607.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3160 | lr 0.000395021 | gnorm 1.423 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 9451
2022-03-06 23:17:16 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 23:17:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:19:10 | INFO | train_inner | epoch 066:     40 / 49 loss=5.049, ppl=33.09, wps=21870.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.309, loss_scale=16, train_wall=262, gb_free=21.5, wall=9565
2022-03-06 23:19:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:19:40 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.532 | ppl 740.19 | wps 39334.6 | wpb 510.9 | bsz 1 | num_updates 3209 | best_loss 8.621
2022-03-06 23:19:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3209 updates
2022-03-06 23:19:40 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 23:19:40 | INFO | train | epoch 066 | loss 4.997 | ppl 31.94 | wps 22058 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3209 | lr 0.000401145 | gnorm 1.189 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 9595
2022-03-06 23:19:40 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 23:19:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:21:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:22:04 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.477 | ppl 712.56 | wps 39168.6 | wpb 510.9 | bsz 1 | num_updates 3258 | best_loss 8.621
2022-03-06 23:22:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3258 updates
2022-03-06 23:22:04 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 23:22:04 | INFO | train | epoch 067 | loss 4.935 | ppl 30.59 | wps 22082.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3258 | lr 0.000407269 | gnorm 1.411 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 9739
2022-03-06 23:22:04 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 23:22:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:23:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:24:07 | INFO | train_inner | epoch 068:     43 / 49 loss=4.909, ppl=30.05, wps=21880.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.398, loss_scale=16, train_wall=262, gb_free=21.5, wall=9862
2022-03-06 23:24:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:24:28 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.52 | ppl 734.15 | wps 39170.3 | wpb 510.9 | bsz 1 | num_updates 3306 | best_loss 8.621
2022-03-06 23:24:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3306 updates
2022-03-06 23:24:28 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 23:24:28 | INFO | train | epoch 068 | loss 4.863 | ppl 29.09 | wps 21618.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3306 | lr 0.000413267 | gnorm 1.412 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 9883
2022-03-06 23:24:28 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 23:24:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:26:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:26:52 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.604 | ppl 778.3 | wps 39072.8 | wpb 510.9 | bsz 1 | num_updates 3355 | best_loss 8.621
2022-03-06 23:26:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3355 updates
2022-03-06 23:26:52 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 23:26:52 | INFO | train | epoch 069 | loss 4.786 | ppl 27.59 | wps 22072.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3355 | lr 0.000419391 | gnorm 1.285 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 10027
2022-03-06 23:26:52 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 23:26:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:29:00 | INFO | train_inner | epoch 070:     45 / 49 loss=4.762, ppl=27.13, wps=22082.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.326, loss_scale=16, train_wall=260, gb_free=21.5, wall=10156
2022-03-06 23:29:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:29:16 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.636 | ppl 795.7 | wps 39048.5 | wpb 510.9 | bsz 1 | num_updates 3404 | best_loss 8.621
2022-03-06 23:29:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3404 updates
2022-03-06 23:29:16 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 23:29:16 | INFO | train | epoch 070 | loss 4.724 | ppl 26.42 | wps 22048.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3404 | lr 0.000425515 | gnorm 1.379 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 10171
2022-03-06 23:29:16 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 23:29:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:30:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:31:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:31:40 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.699 | ppl 831.21 | wps 39275.6 | wpb 510.9 | bsz 1 | num_updates 3452 | best_loss 8.621
2022-03-06 23:31:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3452 updates
2022-03-06 23:31:40 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 23:31:40 | INFO | train | epoch 071 | loss 4.649 | ppl 25.09 | wps 21607.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3452 | lr 0.000431514 | gnorm 1.304 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 10315
2022-03-06 23:31:40 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 23:31:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:33:57 | INFO | train_inner | epoch 072:     48 / 49 loss=4.622, ppl=24.62, wps=21865.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.323, loss_scale=16, train_wall=262, gb_free=21.5, wall=10452
2022-03-06 23:33:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:34:04 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.725 | ppl 846.22 | wps 39060.5 | wpb 510.9 | bsz 1 | num_updates 3501 | best_loss 8.621
2022-03-06 23:34:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3501 updates
2022-03-06 23:34:04 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 23:34:04 | INFO | train | epoch 072 | loss 4.582 | ppl 23.95 | wps 22058.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3501 | lr 0.000437637 | gnorm 1.32 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 10459
2022-03-06 23:34:04 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 23:34:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:36:28 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.777 | ppl 877.31 | wps 39098.7 | wpb 510.9 | bsz 1 | num_updates 3550 | best_loss 8.621
2022-03-06 23:36:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3550 updates
2022-03-06 23:36:28 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 23:36:28 | INFO | train | epoch 073 | loss 4.526 | ppl 23.03 | wps 22068.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3550 | lr 0.000443761 | gnorm 1.438 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 10603
2022-03-06 23:36:28 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 23:36:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:37:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:38:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:38:52 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.817 | ppl 901.71 | wps 39279.4 | wpb 510.9 | bsz 1 | num_updates 3598 | best_loss 8.621
2022-03-06 23:38:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3598 updates
2022-03-06 23:38:52 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 23:38:52 | INFO | train | epoch 074 | loss 4.454 | ppl 21.92 | wps 21615.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3598 | lr 0.00044976 | gnorm 1.33 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 10747
2022-03-06 23:38:52 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 23:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:38:58 | INFO | train_inner | epoch 075:      2 / 49 loss=4.488, ppl=22.44, wps=21454.4, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=3600, lr=0.00045001, gnorm=1.381, loss_scale=16, train_wall=261, gb_free=21.5, wall=10753
2022-03-06 23:41:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:41:16 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.832 | ppl 911.72 | wps 39104.7 | wpb 510.9 | bsz 1 | num_updates 3647 | best_loss 8.621
2022-03-06 23:41:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3647 updates
2022-03-06 23:41:16 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 23:41:16 | INFO | train | epoch 075 | loss 4.403 | ppl 21.16 | wps 22063.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3647 | lr 0.000455884 | gnorm 1.403 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 10891
2022-03-06 23:41:16 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 23:41:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:42:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 23:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:43:40 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.905 | ppl 958.77 | wps 39138.4 | wpb 510.9 | bsz 1 | num_updates 3695 | best_loss 8.621
2022-03-06 23:43:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3695 updates
2022-03-06 23:43:40 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 23:43:40 | INFO | train | epoch 076 | loss 4.351 | ppl 20.41 | wps 21607 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3695 | lr 0.000461883 | gnorm 1.448 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 11036
2022-03-06 23:43:40 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 23:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:43:55 | INFO | train_inner | epoch 077:      5 / 49 loss=4.371, ppl=20.69, wps=21866.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.413, loss_scale=8, train_wall=262, gb_free=21.5, wall=11050
2022-03-06 23:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:46:04 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.931 | ppl 975.94 | wps 39221.8 | wpb 510.9 | bsz 1 | num_updates 3744 | best_loss 8.621
2022-03-06 23:46:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3744 updates
2022-03-06 23:46:04 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 23:46:04 | INFO | train | epoch 077 | loss 4.264 | ppl 19.22 | wps 22074.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3744 | lr 0.000468006 | gnorm 1.251 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 11180
2022-03-06 23:46:04 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 23:46:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:48:28 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.997 | ppl 1021.65 | wps 39295.2 | wpb 510.9 | bsz 1 | num_updates 3793 | best_loss 8.621
2022-03-06 23:48:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3793 updates
2022-03-06 23:48:28 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 23:48:28 | INFO | train | epoch 078 | loss 4.213 | ppl 18.54 | wps 22078.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3793 | lr 0.00047413 | gnorm 1.412 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 11323
2022-03-06 23:48:28 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 23:48:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:48:48 | INFO | train_inner | epoch 079:      7 / 49 loss=4.23, ppl=18.77, wps=22094, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.349, loss_scale=16, train_wall=260, gb_free=21.5, wall=11343
2022-03-06 23:50:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:50:52 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 10.091 | ppl 1090.86 | wps 39044.1 | wpb 510.9 | bsz 1 | num_updates 3842 | best_loss 8.621
2022-03-06 23:50:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3842 updates
2022-03-06 23:50:52 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 23:50:52 | INFO | train | epoch 079 | loss 4.149 | ppl 17.74 | wps 22064.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3842 | lr 0.000480254 | gnorm 1.36 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 11467
2022-03-06 23:50:52 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 23:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:53:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:53:16 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 10.106 | ppl 1101.75 | wps 39144.4 | wpb 510.9 | bsz 1 | num_updates 3891 | best_loss 8.621
2022-03-06 23:53:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3891 updates
2022-03-06 23:53:16 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 23:53:16 | INFO | train | epoch 080 | loss 4.098 | ppl 17.12 | wps 22060.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3891 | lr 0.000486378 | gnorm 1.391 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 11612
2022-03-06 23:53:16 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 23:53:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:53:42 | INFO | train_inner | epoch 081:      9 / 49 loss=4.112, ppl=17.3, wps=22080.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.373, loss_scale=16, train_wall=260, gb_free=21.5, wall=11637
2022-03-06 23:55:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:55:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:55:40 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 10.134 | ppl 1123.63 | wps 39644.8 | wpb 510.9 | bsz 1 | num_updates 3939 | best_loss 8.621
2022-03-06 23:55:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3939 updates
2022-03-06 23:55:40 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 23:55:40 | INFO | train | epoch 081 | loss 4.039 | ppl 16.43 | wps 21639.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3939 | lr 0.000492377 | gnorm 1.39 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 11755
2022-03-06 23:55:40 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 23:55:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:58:04 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 10.187 | ppl 1165.95 | wps 39194.9 | wpb 510.9 | bsz 1 | num_updates 3988 | best_loss 8.621
2022-03-06 23:58:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3988 updates
2022-03-06 23:58:04 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-06 23:58:04 | INFO | train | epoch 082 | loss 3.976 | ppl 15.74 | wps 22061.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3988 | lr 0.0004985 | gnorm 1.342 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 11899
2022-03-06 23:58:04 | INFO | fairseq.trainer | begin training epoch 83
2022-03-06 23:58:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:58:38 | INFO | train_inner | epoch 083:     12 / 49 loss=3.995, ppl=15.95, wps=21885.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.39, loss_scale=16, train_wall=262, gb_free=21.5, wall=11934
2022-03-07 00:00:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:00:28 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 10.219 | ppl 1191.6 | wps 39324.7 | wpb 510.9 | bsz 1 | num_updates 4037 | best_loss 8.621
2022-03-07 00:00:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4037 updates
2022-03-07 00:00:28 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-07 00:00:28 | INFO | train | epoch 083 | loss 3.924 | ppl 15.17 | wps 22064.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4037 | lr 0.000497703 | gnorm 1.345 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 12043
2022-03-07 00:00:28 | INFO | fairseq.trainer | begin training epoch 84
2022-03-07 00:00:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:01:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:02:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:02:52 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 10.248 | ppl 1216.14 | wps 39290.7 | wpb 510.9 | bsz 1 | num_updates 4085 | best_loss 8.621
2022-03-07 00:02:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4085 updates
2022-03-07 00:02:52 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-07 00:02:52 | INFO | train | epoch 084 | loss 3.876 | ppl 14.68 | wps 21602.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 4085 | lr 0.000494771 | gnorm 1.387 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 12188
2022-03-07 00:02:52 | INFO | fairseq.trainer | begin training epoch 85
2022-03-07 00:02:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:03:35 | INFO | train_inner | epoch 085:     15 / 49 loss=3.88, ppl=14.73, wps=21865.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.323, loss_scale=16, train_wall=263, gb_free=21.5, wall=12230
2022-03-07 00:04:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:05:16 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 10.32 | ppl 1278.17 | wps 39339.9 | wpb 510.9 | bsz 1 | num_updates 4133 | best_loss 8.621
2022-03-07 00:05:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4133 updates
2022-03-07 00:05:16 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-07 00:05:16 | INFO | train | epoch 085 | loss 3.807 | ppl 14 | wps 21626.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 4133 | lr 0.000491889 | gnorm 1.343 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 12331
2022-03-07 00:05:16 | INFO | fairseq.trainer | begin training epoch 86
2022-03-07 00:05:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:07:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:07:40 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 10.341 | ppl 1297.07 | wps 39095.4 | wpb 510.9 | bsz 1 | num_updates 4182 | best_loss 8.621
2022-03-07 00:07:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4182 updates
2022-03-07 00:07:40 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-07 00:07:40 | INFO | train | epoch 086 | loss 3.748 | ppl 13.43 | wps 22065.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4182 | lr 0.000488999 | gnorm 1.212 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 12476
2022-03-07 00:07:40 | INFO | fairseq.trainer | begin training epoch 87
2022-03-07 00:07:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:08:32 | INFO | train_inner | epoch 087:     18 / 49 loss=3.758, ppl=13.53, wps=21873, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.284, loss_scale=8, train_wall=262, gb_free=21.5, wall=12527
2022-03-07 00:09:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:10:04 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 10.399 | ppl 1350.53 | wps 39026 | wpb 510.9 | bsz 1 | num_updates 4231 | best_loss 8.621
2022-03-07 00:10:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4231 updates
2022-03-07 00:10:04 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-07 00:10:04 | INFO | train | epoch 087 | loss 3.703 | ppl 13.02 | wps 22053.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4231 | lr 0.000486159 | gnorm 1.324 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 12620
2022-03-07 00:10:04 | INFO | fairseq.trainer | begin training epoch 88
2022-03-07 00:10:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:12:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:12:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:12:28 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 10.429 | ppl 1378.97 | wps 39177.7 | wpb 510.9 | bsz 1 | num_updates 4279 | best_loss 8.621
2022-03-07 00:12:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4279 updates
2022-03-07 00:12:28 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-07 00:12:28 | INFO | train | epoch 088 | loss 3.647 | ppl 12.53 | wps 21605.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 4279 | lr 0.000483425 | gnorm 1.297 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 12764
2022-03-07 00:12:28 | INFO | fairseq.trainer | begin training epoch 89
2022-03-07 00:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:13:28 | INFO | train_inner | epoch 089:     21 / 49 loss=3.653, ppl=12.58, wps=21870.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.289, loss_scale=8, train_wall=262, gb_free=21.5, wall=12824
2022-03-07 00:14:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:14:52 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 10.499 | ppl 1447.19 | wps 39092.8 | wpb 510.9 | bsz 1 | num_updates 4328 | best_loss 8.621
2022-03-07 00:14:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4328 updates
2022-03-07 00:14:52 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-07 00:14:52 | INFO | train | epoch 089 | loss 3.598 | ppl 12.11 | wps 22075.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4328 | lr 0.00048068 | gnorm 1.243 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 12908
2022-03-07 00:14:52 | INFO | fairseq.trainer | begin training epoch 90
2022-03-07 00:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:17:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:17:16 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 10.543 | ppl 1491.87 | wps 39225.3 | wpb 510.9 | bsz 1 | num_updates 4377 | best_loss 8.621
2022-03-07 00:17:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4377 updates
2022-03-07 00:17:16 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-07 00:17:16 | INFO | train | epoch 090 | loss 3.546 | ppl 11.68 | wps 22065.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4377 | lr 0.000477982 | gnorm 1.21 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 13052
2022-03-07 00:17:16 | INFO | fairseq.trainer | begin training epoch 91
2022-03-07 00:17:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:18:22 | INFO | train_inner | epoch 091:     23 / 49 loss=3.552, ppl=11.73, wps=22088.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.232, loss_scale=8, train_wall=260, gb_free=21.5, wall=13117
2022-03-07 00:19:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:19:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:19:40 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 10.638 | ppl 1593.68 | wps 38991.3 | wpb 510.9 | bsz 1 | num_updates 4425 | best_loss 8.621
2022-03-07 00:19:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4425 updates
2022-03-07 00:19:40 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-07 00:19:40 | INFO | train | epoch 091 | loss 3.5 | ppl 11.32 | wps 21621.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 4425 | lr 0.000475383 | gnorm 1.237 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 13196
2022-03-07 00:19:40 | INFO | fairseq.trainer | begin training epoch 92
2022-03-07 00:19:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:21:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:22:04 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 10.598 | ppl 1550.12 | wps 39598 | wpb 510.9 | bsz 1 | num_updates 4474 | best_loss 8.621
2022-03-07 00:22:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4474 updates
2022-03-07 00:22:04 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-07 00:22:04 | INFO | train | epoch 092 | loss 3.461 | ppl 11.01 | wps 22074.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4474 | lr 0.000472772 | gnorm 1.219 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 13340
2022-03-07 00:22:04 | INFO | fairseq.trainer | begin training epoch 93
2022-03-07 00:22:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:23:19 | INFO | train_inner | epoch 093:     26 / 49 loss=3.456, ppl=10.97, wps=21881.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.21, loss_scale=8, train_wall=262, gb_free=21.5, wall=13414
2022-03-07 00:24:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:24:28 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 10.665 | ppl 1623.1 | wps 39223 | wpb 510.9 | bsz 1 | num_updates 4523 | best_loss 8.621
2022-03-07 00:24:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4523 updates
2022-03-07 00:24:28 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-07 00:24:28 | INFO | train | epoch 093 | loss 3.414 | ppl 10.66 | wps 22079.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4523 | lr 0.000470204 | gnorm 1.222 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 13484
2022-03-07 00:24:28 | INFO | fairseq.trainer | begin training epoch 94
2022-03-07 00:24:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:26:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:26:52 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 10.719 | ppl 1685.34 | wps 39153.8 | wpb 510.9 | bsz 1 | num_updates 4572 | best_loss 8.621
2022-03-07 00:26:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4572 updates
2022-03-07 00:26:52 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-07 00:26:52 | INFO | train | epoch 094 | loss 3.369 | ppl 10.34 | wps 22055.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4572 | lr 0.000467678 | gnorm 1.157 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 13628
2022-03-07 00:26:52 | INFO | fairseq.trainer | begin training epoch 95
2022-03-07 00:26:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:27:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:28:15 | INFO | train_inner | epoch 095:     29 / 49 loss=3.37, ppl=10.34, wps=21867.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.188, loss_scale=8, train_wall=262, gb_free=21.5, wall=13710
2022-03-07 00:29:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:29:16 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 10.745 | ppl 1716.5 | wps 39280.7 | wpb 510.9 | bsz 1 | num_updates 4620 | best_loss 8.621
2022-03-07 00:29:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4620 updates
2022-03-07 00:29:16 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-07 00:29:16 | INFO | train | epoch 095 | loss 3.33 | ppl 10.05 | wps 21617.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 4620 | lr 0.000465242 | gnorm 1.192 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 13772
2022-03-07 00:29:16 | INFO | fairseq.trainer | begin training epoch 96
2022-03-07 00:29:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:31:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:31:40 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 10.766 | ppl 1741.11 | wps 39163 | wpb 510.9 | bsz 1 | num_updates 4669 | best_loss 8.621
2022-03-07 00:31:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4669 updates
2022-03-07 00:31:40 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-07 00:31:40 | INFO | train | epoch 096 | loss 3.293 | ppl 9.8 | wps 22080.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4669 | lr 0.000462794 | gnorm 1.152 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 13916
2022-03-07 00:31:40 | INFO | fairseq.trainer | begin training epoch 97
2022-03-07 00:31:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:33:09 | INFO | train_inner | epoch 097:     31 / 49 loss=3.285, ppl=9.74, wps=22094.8, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.152, loss_scale=8, train_wall=260, gb_free=21.5, wall=14004
2022-03-07 00:33:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:34:04 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 10.81 | ppl 1795.17 | wps 39400.4 | wpb 510.9 | bsz 1 | num_updates 4718 | best_loss 8.621
2022-03-07 00:34:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4718 updates
2022-03-07 00:34:04 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-07 00:34:04 | INFO | train | epoch 097 | loss 3.253 | ppl 9.53 | wps 22073.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4718 | lr 0.000460385 | gnorm 1.154 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 14060
2022-03-07 00:34:04 | INFO | fairseq.trainer | begin training epoch 98
2022-03-07 00:34:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:36:28 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 10.822 | ppl 1810.25 | wps 39309.5 | wpb 510.9 | bsz 1 | num_updates 4767 | best_loss 8.621
2022-03-07 00:36:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4767 updates
2022-03-07 00:36:28 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-07 00:36:28 | INFO | train | epoch 098 | loss 3.218 | ppl 9.3 | wps 22080 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4767 | lr 0.000458013 | gnorm 1.139 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 14203
2022-03-07 00:36:28 | INFO | fairseq.trainer | begin training epoch 99
2022-03-07 00:36:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:38:02 | INFO | train_inner | epoch 099:     33 / 49 loss=3.214, ppl=9.28, wps=22088.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.136, loss_scale=16, train_wall=260, gb_free=21.5, wall=14298
2022-03-07 00:38:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:38:52 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 10.892 | ppl 1900.87 | wps 39188.7 | wpb 510.9 | bsz 1 | num_updates 4816 | best_loss 8.621
2022-03-07 00:38:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4816 updates
2022-03-07 00:38:52 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-07 00:38:52 | INFO | train | epoch 099 | loss 3.185 | ppl 9.09 | wps 22060 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4816 | lr 0.000455677 | gnorm 1.156 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 14348
2022-03-07 00:38:52 | INFO | fairseq.trainer | begin training epoch 100
2022-03-07 00:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:39:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:41:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:41:16 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 10.929 | ppl 1949.76 | wps 39139.3 | wpb 510.9 | bsz 1 | num_updates 4864 | best_loss 8.621
2022-03-07 00:41:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4864 updates
2022-03-07 00:41:16 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-07 00:41:16 | INFO | train | epoch 100 | loss 3.142 | ppl 8.83 | wps 21630.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 4864 | lr 0.000453423 | gnorm 1.082 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 14491
2022-03-07 00:41:16 | INFO | fairseq.trainer | begin training epoch 101
2022-03-07 00:41:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:42:59 | INFO | train_inner | epoch 101:     36 / 49 loss=3.143, ppl=8.83, wps=21883.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.14, loss_scale=8, train_wall=262, gb_free=21.5, wall=14594
2022-03-07 00:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:43:40 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 10.956 | ppl 1986.24 | wps 39232 | wpb 510.9 | bsz 1 | num_updates 4913 | best_loss 8.621
2022-03-07 00:43:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4913 updates
2022-03-07 00:43:40 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-07 00:43:40 | INFO | train | epoch 101 | loss 3.115 | ppl 8.66 | wps 22075.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4913 | lr 0.000451156 | gnorm 1.119 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 14635
2022-03-07 00:43:40 | INFO | fairseq.trainer | begin training epoch 102
2022-03-07 00:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:46:04 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 11.002 | ppl 2050.79 | wps 39153.1 | wpb 510.9 | bsz 1 | num_updates 4962 | best_loss 8.621
2022-03-07 00:46:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4962 updates
2022-03-07 00:46:04 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-07 00:46:04 | INFO | train | epoch 102 | loss 3.08 | ppl 8.46 | wps 22057.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4962 | lr 0.000448923 | gnorm 1.05 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 14779
2022-03-07 00:46:04 | INFO | fairseq.trainer | begin training epoch 103
2022-03-07 00:46:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:47:53 | INFO | train_inner | epoch 103:     38 / 49 loss=3.075, ppl=8.43, wps=22089.1, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.082, loss_scale=16, train_wall=260, gb_free=21.5, wall=14888
2022-03-07 00:48:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:48:28 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 11.027 | ppl 2087.31 | wps 39099.2 | wpb 510.9 | bsz 1 | num_updates 5010 | best_loss 8.621
2022-03-07 00:48:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5010 updates
2022-03-07 00:48:28 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-07 00:48:28 | INFO | train | epoch 103 | loss 3.056 | ppl 8.32 | wps 21622.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 5010 | lr 0.000446767 | gnorm 1.125 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 14923
2022-03-07 00:48:28 | INFO | fairseq.trainer | begin training epoch 104
2022-03-07 00:48:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:50:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:50:52 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 11.023 | ppl 2081.4 | wps 39208.7 | wpb 510.9 | bsz 1 | num_updates 5059 | best_loss 8.621
2022-03-07 00:50:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5059 updates
2022-03-07 00:50:52 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-07 00:50:52 | INFO | train | epoch 104 | loss 3.026 | ppl 8.14 | wps 22058.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5059 | lr 0.000444598 | gnorm 1.086 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 15067
2022-03-07 00:50:52 | INFO | fairseq.trainer | begin training epoch 105
2022-03-07 00:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:52:49 | INFO | train_inner | epoch 105:     41 / 49 loss=3.016, ppl=8.09, wps=21864.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.071, loss_scale=8, train_wall=262, gb_free=21.5, wall=15185
2022-03-07 00:53:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:53:16 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 11.107 | ppl 2206.06 | wps 39357.2 | wpb 510.9 | bsz 1 | num_updates 5108 | best_loss 8.621
2022-03-07 00:53:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5108 updates
2022-03-07 00:53:16 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-07 00:53:16 | INFO | train | epoch 105 | loss 2.993 | ppl 7.96 | wps 22067.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5108 | lr 0.000442461 | gnorm 1.045 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 15211
2022-03-07 00:53:16 | INFO | fairseq.trainer | begin training epoch 106
2022-03-07 00:53:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:55:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:55:40 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 11.107 | ppl 2205.63 | wps 39163.5 | wpb 510.9 | bsz 1 | num_updates 5157 | best_loss 8.621
2022-03-07 00:55:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5157 updates
2022-03-07 00:55:40 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-07 00:55:40 | INFO | train | epoch 106 | loss 2.968 | ppl 7.83 | wps 22073 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5157 | lr 0.000440353 | gnorm 1.062 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 15355
2022-03-07 00:55:40 | INFO | fairseq.trainer | begin training epoch 107
2022-03-07 00:55:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:56:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:57:46 | INFO | train_inner | epoch 107:     44 / 49 loss=2.96, ppl=7.78, wps=21873.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.056, loss_scale=8, train_wall=262, gb_free=21.5, wall=15481
2022-03-07 00:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:58:04 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 11.133 | ppl 2246.17 | wps 39165.9 | wpb 510.9 | bsz 1 | num_updates 5205 | best_loss 8.621
2022-03-07 00:58:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5205 updates
2022-03-07 00:58:04 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-07 00:58:04 | INFO | train | epoch 107 | loss 2.941 | ppl 7.68 | wps 21599.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 5205 | lr 0.000438318 | gnorm 1.043 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 15500
2022-03-07 00:58:04 | INFO | fairseq.trainer | begin training epoch 108
2022-03-07 00:58:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:00:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:00:28 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 11.177 | ppl 2314.76 | wps 39114.7 | wpb 510.9 | bsz 1 | num_updates 5254 | best_loss 8.621
2022-03-07 01:00:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5254 updates
2022-03-07 01:00:28 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-07 01:00:28 | INFO | train | epoch 108 | loss 2.919 | ppl 7.56 | wps 22067 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5254 | lr 0.00043627 | gnorm 1.063 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 15644
2022-03-07 01:00:28 | INFO | fairseq.trainer | begin training epoch 109
2022-03-07 01:00:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:02:39 | INFO | train_inner | epoch 109:     46 / 49 loss=2.908, ppl=7.51, wps=22097.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.042, loss_scale=16, train_wall=260, gb_free=21.5, wall=15775
2022-03-07 01:02:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:02:52 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 11.21 | ppl 2369.69 | wps 39209.5 | wpb 510.9 | bsz 1 | num_updates 5303 | best_loss 8.621
2022-03-07 01:02:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5303 updates
2022-03-07 01:02:52 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-07 01:02:52 | INFO | train | epoch 109 | loss 2.893 | ppl 7.43 | wps 22095.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5303 | lr 0.000434249 | gnorm 1.017 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 15787
2022-03-07 01:02:52 | INFO | fairseq.trainer | begin training epoch 110
2022-03-07 01:02:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:04:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:05:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:05:16 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 11.187 | ppl 2330.94 | wps 39195.9 | wpb 510.9 | bsz 1 | num_updates 5351 | best_loss 8.621
2022-03-07 01:05:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5351 updates
2022-03-07 01:05:16 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-07 01:05:16 | INFO | train | epoch 110 | loss 2.868 | ppl 7.3 | wps 21628.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 5351 | lr 0.000432297 | gnorm 1.031 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 15931
2022-03-07 01:05:16 | INFO | fairseq.trainer | begin training epoch 111
2022-03-07 01:05:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:07:35 | INFO | train_inner | epoch 111:     49 / 49 loss=2.859, ppl=7.25, wps=21869.6, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=5400, lr=0.000430331, gnorm=1.015, loss_scale=8, train_wall=261, gb_free=21.5, wall=16070
2022-03-07 01:07:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:07:40 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 11.197 | ppl 2347.64 | wps 39173.4 | wpb 510.9 | bsz 1 | num_updates 5400 | best_loss 8.621
2022-03-07 01:07:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5400 updates
2022-03-07 01:07:40 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-07 01:07:40 | INFO | train | epoch 111 | loss 2.845 | ppl 7.18 | wps 22055.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5400 | lr 0.000430331 | gnorm 0.994 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 16075
2022-03-07 01:07:40 | INFO | fairseq.trainer | begin training epoch 112
2022-03-07 01:07:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:09:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:10:04 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 11.249 | ppl 2434.05 | wps 38959.5 | wpb 510.9 | bsz 1 | num_updates 5449 | best_loss 8.621
2022-03-07 01:10:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5449 updates
2022-03-07 01:10:04 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-07 01:10:04 | INFO | train | epoch 112 | loss 2.825 | ppl 7.09 | wps 22054.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5449 | lr 0.000428392 | gnorm 1.021 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 16220
2022-03-07 01:10:04 | INFO | fairseq.trainer | begin training epoch 113
2022-03-07 01:10:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:12:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:12:28 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 11.238 | ppl 2414.91 | wps 39325.1 | wpb 510.9 | bsz 1 | num_updates 5498 | best_loss 8.621
2022-03-07 01:12:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5498 updates
2022-03-07 01:12:28 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-07 01:12:28 | INFO | train | epoch 113 | loss 2.801 | ppl 6.97 | wps 22054.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5498 | lr 0.000426479 | gnorm 0.979 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 16364
2022-03-07 01:12:28 | INFO | fairseq.trainer | begin training epoch 114
2022-03-07 01:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:12:34 | INFO | train_inner | epoch 114:      2 / 49 loss=2.812, ppl=7.02, wps=21652.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=5500, lr=0.000426401, gnorm=0.999, loss_scale=16, train_wall=260, gb_free=21.5, wall=16369
2022-03-07 01:13:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:14:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:14:52 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 11.288 | ppl 2500.02 | wps 39118.6 | wpb 510.9 | bsz 1 | num_updates 5546 | best_loss 8.621
2022-03-07 01:14:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5546 updates
2022-03-07 01:14:52 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-07 01:14:52 | INFO | train | epoch 114 | loss 2.782 | ppl 6.88 | wps 21630.4 | ups 0.33 | wpb 64853.3 | bsz 126.7 | num_updates 5546 | lr 0.000424629 | gnorm 0.992 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 16508
2022-03-07 01:14:52 | INFO | fairseq.trainer | begin training epoch 115
2022-03-07 01:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:17:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:17:16 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 11.268 | ppl 2466.08 | wps 39144.8 | wpb 510.9 | bsz 1 | num_updates 5595 | best_loss 8.621
2022-03-07 01:17:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5595 updates
2022-03-07 01:17:16 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-07 01:17:16 | INFO | train | epoch 115 | loss 2.764 | ppl 6.79 | wps 22076.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5595 | lr 0.000422766 | gnorm 0.964 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 16651
2022-03-07 01:17:16 | INFO | fairseq.trainer | begin training epoch 116
2022-03-07 01:17:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:17:31 | INFO | train_inner | epoch 116:      5 / 49 loss=2.77, ppl=6.82, wps=21887.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=0.978, loss_scale=8, train_wall=262, gb_free=21.5, wall=16666
2022-03-07 01:19:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:19:40 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 11.31 | ppl 2539.26 | wps 39103.6 | wpb 510.9 | bsz 1 | num_updates 5644 | best_loss 8.621
2022-03-07 01:19:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5644 updates
2022-03-07 01:19:40 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-07 01:19:40 | INFO | train | epoch 116 | loss 2.744 | ppl 6.7 | wps 22072.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5644 | lr 0.000420927 | gnorm 0.96 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 16795
2022-03-07 01:19:40 | INFO | fairseq.trainer | begin training epoch 117
2022-03-07 01:19:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:21:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:22:04 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 11.318 | ppl 2552.9 | wps 39434.1 | wpb 510.9 | bsz 1 | num_updates 5693 | best_loss 8.621
2022-03-07 01:22:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5693 updates
2022-03-07 01:22:04 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-07 01:22:04 | INFO | train | epoch 117 | loss 2.725 | ppl 6.61 | wps 22086.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5693 | lr 0.000419111 | gnorm 0.96 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 16939
2022-03-07 01:22:04 | INFO | fairseq.trainer | begin training epoch 118
2022-03-07 01:22:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:22:24 | INFO | train_inner | epoch 118:      7 / 49 loss=2.731, ppl=6.64, wps=22091.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=0.957, loss_scale=16, train_wall=260, gb_free=21.5, wall=16959
2022-03-07 01:24:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:24:28 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 11.343 | ppl 2598.44 | wps 38996.5 | wpb 510.9 | bsz 1 | num_updates 5742 | best_loss 8.621
2022-03-07 01:24:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5742 updates
2022-03-07 01:24:28 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-07 01:24:28 | INFO | train | epoch 118 | loss 2.707 | ppl 6.53 | wps 22066.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5742 | lr 0.000417319 | gnorm 0.939 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 17083
2022-03-07 01:24:28 | INFO | fairseq.trainer | begin training epoch 119
2022-03-07 01:24:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:24:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:26:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:26:52 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 11.34 | ppl 2592.16 | wps 39074.4 | wpb 510.9 | bsz 1 | num_updates 5790 | best_loss 8.621
2022-03-07 01:26:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5790 updates
2022-03-07 01:26:52 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-07 01:26:52 | INFO | train | epoch 119 | loss 2.687 | ppl 6.44 | wps 21608.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 5790 | lr 0.000415586 | gnorm 0.95 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 17227
2022-03-07 01:26:52 | INFO | fairseq.trainer | begin training epoch 120
2022-03-07 01:26:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:27:21 | INFO | train_inner | epoch 120:     10 / 49 loss=2.693, ppl=6.47, wps=21877.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=0.943, loss_scale=8, train_wall=262, gb_free=21.5, wall=17256
2022-03-07 01:29:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:29:16 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 11.351 | ppl 2612.19 | wps 39066 | wpb 510.9 | bsz 1 | num_updates 5839 | best_loss 8.621
2022-03-07 01:29:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5839 updates
2022-03-07 01:29:16 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-07 01:29:16 | INFO | train | epoch 120 | loss 2.67 | ppl 6.36 | wps 22073.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5839 | lr 0.000413838 | gnorm 0.916 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 17371
2022-03-07 01:29:16 | INFO | fairseq.trainer | begin training epoch 121
2022-03-07 01:29:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:31:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:31:40 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 11.364 | ppl 2635.31 | wps 39099.3 | wpb 510.9 | bsz 1 | num_updates 5888 | best_loss 8.621
2022-03-07 01:31:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5888 updates
2022-03-07 01:31:40 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-07 01:31:40 | INFO | train | epoch 121 | loss 2.658 | ppl 6.31 | wps 22051 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5888 | lr 0.000412113 | gnorm 0.931 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 17516
2022-03-07 01:31:40 | INFO | fairseq.trainer | begin training epoch 122
2022-03-07 01:31:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:32:15 | INFO | train_inner | epoch 122:     12 / 49 loss=2.659, ppl=6.32, wps=22079.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=0.917, loss_scale=16, train_wall=260, gb_free=21.5, wall=17550
2022-03-07 01:33:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:33:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:34:04 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 11.345 | ppl 2601.54 | wps 39133.9 | wpb 510.9 | bsz 1 | num_updates 5936 | best_loss 8.621
2022-03-07 01:34:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5936 updates
2022-03-07 01:34:04 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-07 01:34:04 | INFO | train | epoch 122 | loss 2.636 | ppl 6.21 | wps 21609.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 5936 | lr 0.000410443 | gnorm 0.897 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 17660
2022-03-07 01:34:04 | INFO | fairseq.trainer | begin training epoch 123
2022-03-07 01:34:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:36:28 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 11.378 | ppl 2662.31 | wps 39169.1 | wpb 510.9 | bsz 1 | num_updates 5985 | best_loss 8.621
2022-03-07 01:36:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5985 updates
2022-03-07 01:36:28 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-07 01:36:28 | INFO | train | epoch 123 | loss 2.626 | ppl 6.17 | wps 22070.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5985 | lr 0.00040876 | gnorm 0.915 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 17804
2022-03-07 01:36:28 | INFO | fairseq.trainer | begin training epoch 124
2022-03-07 01:36:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:37:11 | INFO | train_inner | epoch 124:     15 / 49 loss=2.626, ppl=6.17, wps=21868.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=0.902, loss_scale=8, train_wall=262, gb_free=21.5, wall=17846
2022-03-07 01:38:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:38:52 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 11.367 | ppl 2641.79 | wps 39279.5 | wpb 510.9 | bsz 1 | num_updates 6034 | best_loss 8.621
2022-03-07 01:38:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6034 updates
2022-03-07 01:38:52 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-07 01:38:52 | INFO | train | epoch 124 | loss 2.609 | ppl 6.1 | wps 22063.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6034 | lr 0.000407096 | gnorm 0.901 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 17948
2022-03-07 01:38:52 | INFO | fairseq.trainer | begin training epoch 125
2022-03-07 01:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:41:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:41:16 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 11.42 | ppl 2740.6 | wps 39221.5 | wpb 510.9 | bsz 1 | num_updates 6083 | best_loss 8.621
2022-03-07 01:41:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6083 updates
2022-03-07 01:41:16 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-07 01:41:16 | INFO | train | epoch 125 | loss 2.594 | ppl 6.04 | wps 22058.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6083 | lr 0.000405454 | gnorm 0.877 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 18092
2022-03-07 01:41:16 | INFO | fairseq.trainer | begin training epoch 126
2022-03-07 01:41:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:42:05 | INFO | train_inner | epoch 126:     17 / 49 loss=2.598, ppl=6.05, wps=22082.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=0.895, loss_scale=16, train_wall=260, gb_free=21.5, wall=18140
2022-03-07 01:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:43:40 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 11.411 | ppl 2723.12 | wps 39251.2 | wpb 510.9 | bsz 1 | num_updates 6132 | best_loss 8.621
2022-03-07 01:43:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6132 updates
2022-03-07 01:43:40 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-07 01:43:40 | INFO | train | epoch 126 | loss 2.579 | ppl 5.98 | wps 22072.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6132 | lr 0.00040383 | gnorm 0.861 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 18236
2022-03-07 01:43:40 | INFO | fairseq.trainer | begin training epoch 127
2022-03-07 01:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:45:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:46:04 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 11.43 | ppl 2759.67 | wps 39189.4 | wpb 510.9 | bsz 1 | num_updates 6180 | best_loss 8.621
2022-03-07 01:46:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6180 updates
2022-03-07 01:46:04 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-07 01:46:04 | INFO | train | epoch 127 | loss 2.568 | ppl 5.93 | wps 21608.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 6180 | lr 0.000402259 | gnorm 0.888 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 18380
2022-03-07 01:46:04 | INFO | fairseq.trainer | begin training epoch 128
2022-03-07 01:46:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:47:02 | INFO | train_inner | epoch 128:     20 / 49 loss=2.567, ppl=5.93, wps=21870.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=0.865, loss_scale=8, train_wall=262, gb_free=21.5, wall=18437
2022-03-07 01:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:48:29 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 11.407 | ppl 2714.66 | wps 39145.4 | wpb 510.9 | bsz 1 | num_updates 6229 | best_loss 8.621
2022-03-07 01:48:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6229 updates
2022-03-07 01:48:29 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-07 01:48:29 | INFO | train | epoch 128 | loss 2.554 | ppl 5.87 | wps 22053 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6229 | lr 0.000400674 | gnorm 0.875 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 18524
2022-03-07 01:48:29 | INFO | fairseq.trainer | begin training epoch 129
2022-03-07 01:48:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:50:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:50:53 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 11.462 | ppl 2820.61 | wps 39043.7 | wpb 510.9 | bsz 1 | num_updates 6278 | best_loss 8.621
2022-03-07 01:50:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6278 updates
2022-03-07 01:50:53 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-07 01:50:53 | INFO | train | epoch 129 | loss 2.539 | ppl 5.81 | wps 22062 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6278 | lr 0.000399107 | gnorm 0.849 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 18668
2022-03-07 01:50:53 | INFO | fairseq.trainer | begin training epoch 130
2022-03-07 01:50:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:51:55 | INFO | train_inner | epoch 130:     22 / 49 loss=2.543, ppl=5.83, wps=22076.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=0.867, loss_scale=16, train_wall=260, gb_free=21.5, wall=18731
2022-03-07 01:53:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:53:17 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 11.449 | ppl 2796.19 | wps 39147.1 | wpb 510.9 | bsz 1 | num_updates 6327 | best_loss 8.621
2022-03-07 01:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6327 updates
2022-03-07 01:53:17 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-07 01:53:17 | INFO | train | epoch 130 | loss 2.53 | ppl 5.77 | wps 22053.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6327 | lr 0.000397559 | gnorm 0.86 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 18812
2022-03-07 01:53:17 | INFO | fairseq.trainer | begin training epoch 131
2022-03-07 01:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:55:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:55:41 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 11.459 | ppl 2815.27 | wps 39160.8 | wpb 510.9 | bsz 1 | num_updates 6376 | best_loss 8.621
2022-03-07 01:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6376 updates
2022-03-07 01:55:41 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-07 01:55:41 | INFO | train | epoch 131 | loss 2.516 | ppl 5.72 | wps 22075.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6376 | lr 0.000396028 | gnorm 0.845 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 18956
2022-03-07 01:55:41 | INFO | fairseq.trainer | begin training epoch 132
2022-03-07 01:55:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:56:49 | INFO | train_inner | epoch 132:     24 / 49 loss=2.516, ppl=5.72, wps=22084.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=0.84, loss_scale=16, train_wall=260, gb_free=21.5, wall=19024
2022-03-07 01:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:58:05 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 11.467 | ppl 2830.53 | wps 39052.2 | wpb 510.9 | bsz 1 | num_updates 6425 | best_loss 8.621
2022-03-07 01:58:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6425 updates
2022-03-07 01:58:05 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-07 01:58:05 | INFO | train | epoch 132 | loss 2.505 | ppl 5.68 | wps 22049 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6425 | lr 0.000394515 | gnorm 0.842 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 19100
2022-03-07 01:58:05 | INFO | fairseq.trainer | begin training epoch 133
2022-03-07 01:58:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:58:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:00:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:00:29 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 11.479 | ppl 2854.92 | wps 39277.2 | wpb 510.9 | bsz 1 | num_updates 6473 | best_loss 8.621
2022-03-07 02:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6473 updates
2022-03-07 02:00:29 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-07 02:00:29 | INFO | train | epoch 133 | loss 2.493 | ppl 5.63 | wps 21609.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 6473 | lr 0.000393049 | gnorm 0.825 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 19244
2022-03-07 02:00:29 | INFO | fairseq.trainer | begin training epoch 134
2022-03-07 02:00:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:01:46 | INFO | train_inner | epoch 134:     27 / 49 loss=2.494, ppl=5.63, wps=21852.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=0.832, loss_scale=16, train_wall=263, gb_free=21.5, wall=19321
2022-03-07 02:02:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:02:53 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 11.483 | ppl 2861.5 | wps 39197.7 | wpb 510.9 | bsz 1 | num_updates 6522 | best_loss 8.621
2022-03-07 02:02:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6522 updates
2022-03-07 02:02:53 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-07 02:02:53 | INFO | train | epoch 134 | loss 2.482 | ppl 5.59 | wps 22042.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6522 | lr 0.00039157 | gnorm 0.823 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 19388
2022-03-07 02:02:53 | INFO | fairseq.trainer | begin training epoch 135
2022-03-07 02:02:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:04:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:05:17 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 11.458 | ppl 2812.34 | wps 39330.2 | wpb 510.9 | bsz 1 | num_updates 6570 | best_loss 8.621
2022-03-07 02:05:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6570 updates
2022-03-07 02:05:17 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-07 02:05:17 | INFO | train | epoch 135 | loss 2.47 | ppl 5.54 | wps 21631.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 6570 | lr 0.000390137 | gnorm 0.837 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 19532
2022-03-07 02:05:17 | INFO | fairseq.trainer | begin training epoch 136
2022-03-07 02:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:06:43 | INFO | train_inner | epoch 136:     30 / 49 loss=2.469, ppl=5.54, wps=21881, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.823, loss_scale=16, train_wall=262, gb_free=21.5, wall=19618
2022-03-07 02:07:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:07:41 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 11.441 | ppl 2780.69 | wps 39109.2 | wpb 510.9 | bsz 1 | num_updates 6619 | best_loss 8.621
2022-03-07 02:07:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6619 updates
2022-03-07 02:07:41 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-07 02:07:41 | INFO | train | epoch 136 | loss 2.46 | ppl 5.5 | wps 22069.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6619 | lr 0.00038869 | gnorm 0.822 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 19676
2022-03-07 02:07:41 | INFO | fairseq.trainer | begin training epoch 137
2022-03-07 02:07:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:09:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:10:05 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 11.472 | ppl 2839.74 | wps 39331.7 | wpb 510.9 | bsz 1 | num_updates 6668 | best_loss 8.621
2022-03-07 02:10:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6668 updates
2022-03-07 02:10:05 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-07 02:10:05 | INFO | train | epoch 137 | loss 2.448 | ppl 5.46 | wps 22065.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6668 | lr 0.00038726 | gnorm 0.792 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 19820
2022-03-07 02:10:05 | INFO | fairseq.trainer | begin training epoch 138
2022-03-07 02:10:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:10:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:11:39 | INFO | train_inner | epoch 138:     33 / 49 loss=2.449, ppl=5.46, wps=21868.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.81, loss_scale=16, train_wall=262, gb_free=21.5, wall=19914
2022-03-07 02:12:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:12:29 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 11.463 | ppl 2823.07 | wps 39162 | wpb 510.9 | bsz 1 | num_updates 6716 | best_loss 8.621
2022-03-07 02:12:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6716 updates
2022-03-07 02:12:29 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-07 02:12:29 | INFO | train | epoch 138 | loss 2.44 | ppl 5.42 | wps 21612.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 6716 | lr 0.000385873 | gnorm 0.808 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 19964
2022-03-07 02:12:29 | INFO | fairseq.trainer | begin training epoch 139
2022-03-07 02:12:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:14:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:14:53 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 11.489 | ppl 2874.71 | wps 38701.1 | wpb 510.9 | bsz 1 | num_updates 6765 | best_loss 8.621
2022-03-07 02:14:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6765 updates
2022-03-07 02:14:53 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-07 02:14:53 | INFO | train | epoch 139 | loss 2.431 | ppl 5.39 | wps 22059.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6765 | lr 0.000384473 | gnorm 0.794 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 20108
2022-03-07 02:14:53 | INFO | fairseq.trainer | begin training epoch 140
2022-03-07 02:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:16:33 | INFO | train_inner | epoch 140:     35 / 49 loss=2.429, ppl=5.38, wps=22081.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.795, loss_scale=16, train_wall=260, gb_free=21.5, wall=20208
2022-03-07 02:17:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:17:17 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 11.483 | ppl 2861.99 | wps 39139 | wpb 510.9 | bsz 1 | num_updates 6814 | best_loss 8.621
2022-03-07 02:17:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6814 updates
2022-03-07 02:17:17 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-07 02:17:17 | INFO | train | epoch 140 | loss 2.421 | ppl 5.36 | wps 22062.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6814 | lr 0.000383088 | gnorm 0.795 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 20252
2022-03-07 02:17:17 | INFO | fairseq.trainer | begin training epoch 141
2022-03-07 02:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:17:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:19:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:19:41 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 11.471 | ppl 2839.31 | wps 39204 | wpb 510.9 | bsz 1 | num_updates 6862 | best_loss 8.621
2022-03-07 02:19:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6862 updates
2022-03-07 02:19:41 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-07 02:19:41 | INFO | train | epoch 141 | loss 2.412 | ppl 5.32 | wps 21622.6 | ups 0.33 | wpb 64853.3 | bsz 126.7 | num_updates 6862 | lr 0.000381746 | gnorm 0.788 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 20396
2022-03-07 02:19:41 | INFO | fairseq.trainer | begin training epoch 142
2022-03-07 02:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:21:29 | INFO | train_inner | epoch 142:     38 / 49 loss=2.41, ppl=5.31, wps=21884.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.781, loss_scale=16, train_wall=262, gb_free=21.5, wall=20505
2022-03-07 02:21:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 02:21:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:22:05 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 11.518 | ppl 2933.31 | wps 39547.7 | wpb 510.9 | bsz 1 | num_updates 6910 | best_loss 8.621
2022-03-07 02:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6910 updates
2022-03-07 02:22:05 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-07 02:22:05 | INFO | train | epoch 142 | loss 2.4 | ppl 5.28 | wps 21634.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 6910 | lr 0.000380418 | gnorm 0.769 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 20540
2022-03-07 02:22:05 | INFO | fairseq.trainer | begin training epoch 143
2022-03-07 02:22:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:24:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:24:29 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 11.499 | ppl 2894.42 | wps 39146.8 | wpb 510.9 | bsz 1 | num_updates 6959 | best_loss 8.621
2022-03-07 02:24:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6959 updates
2022-03-07 02:24:29 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-07 02:24:29 | INFO | train | epoch 143 | loss 2.394 | ppl 5.26 | wps 22077.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6959 | lr 0.000379076 | gnorm 0.778 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 20684
2022-03-07 02:24:29 | INFO | fairseq.trainer | begin training epoch 144
2022-03-07 02:24:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:26:26 | INFO | train_inner | epoch 144:     41 / 49 loss=2.392, ppl=5.25, wps=21877.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.783, loss_scale=8, train_wall=262, gb_free=21.5, wall=20801
2022-03-07 02:26:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:26:53 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 11.494 | ppl 2883.82 | wps 39162 | wpb 510.9 | bsz 1 | num_updates 7008 | best_loss 8.621
2022-03-07 02:26:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7008 updates
2022-03-07 02:26:53 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-07 02:26:53 | INFO | train | epoch 144 | loss 2.386 | ppl 5.23 | wps 22054.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7008 | lr 0.000377749 | gnorm 0.78 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 20828
2022-03-07 02:26:53 | INFO | fairseq.trainer | begin training epoch 145
2022-03-07 02:26:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:29:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:29:17 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 11.475 | ppl 2846.7 | wps 39071.9 | wpb 510.9 | bsz 1 | num_updates 7057 | best_loss 8.621
2022-03-07 02:29:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7057 updates
2022-03-07 02:29:17 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-07 02:29:17 | INFO | train | epoch 145 | loss 2.377 | ppl 5.19 | wps 22058.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7057 | lr 0.000376435 | gnorm 0.76 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 20972
2022-03-07 02:29:17 | INFO | fairseq.trainer | begin training epoch 146
2022-03-07 02:29:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:30:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 02:31:23 | INFO | train_inner | epoch 146:     44 / 49 loss=2.374, ppl=5.18, wps=21870, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.763, loss_scale=8, train_wall=262, gb_free=21.5, wall=21098
2022-03-07 02:31:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:31:41 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 11.487 | ppl 2870.04 | wps 39111.5 | wpb 510.9 | bsz 1 | num_updates 7105 | best_loss 8.621
2022-03-07 02:31:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7105 updates
2022-03-07 02:31:41 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-07 02:31:41 | INFO | train | epoch 146 | loss 2.367 | ppl 5.16 | wps 21617.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7105 | lr 0.000375161 | gnorm 0.767 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 21116
2022-03-07 02:31:41 | INFO | fairseq.trainer | begin training epoch 147
2022-03-07 02:31:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:33:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:34:05 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 11.491 | ppl 2878.93 | wps 39206 | wpb 510.9 | bsz 1 | num_updates 7154 | best_loss 8.621
2022-03-07 02:34:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7154 updates
2022-03-07 02:34:05 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-07 02:34:05 | INFO | train | epoch 147 | loss 2.359 | ppl 5.13 | wps 22061.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7154 | lr 0.000373874 | gnorm 0.757 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 21260
2022-03-07 02:34:05 | INFO | fairseq.trainer | begin training epoch 148
2022-03-07 02:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:36:16 | INFO | train_inner | epoch 148:     46 / 49 loss=2.355, ppl=5.12, wps=22084.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7200, lr=0.000372678, gnorm=0.746, loss_scale=8, train_wall=260, gb_free=21.5, wall=21392
2022-03-07 02:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:36:29 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 11.499 | ppl 2894.84 | wps 39228.5 | wpb 510.9 | bsz 1 | num_updates 7203 | best_loss 8.621
2022-03-07 02:36:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7203 updates
2022-03-07 02:36:29 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-07 02:36:29 | INFO | train | epoch 148 | loss 2.349 | ppl 5.1 | wps 22075.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7203 | lr 0.0003726 | gnorm 0.731 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 21404
2022-03-07 02:36:29 | INFO | fairseq.trainer | begin training epoch 149
2022-03-07 02:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:38:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:38:53 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 11.473 | ppl 2842.74 | wps 39163.5 | wpb 510.9 | bsz 1 | num_updates 7252 | best_loss 8.621
2022-03-07 02:38:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7252 updates
2022-03-07 02:38:53 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-07 02:38:53 | INFO | train | epoch 149 | loss 2.343 | ppl 5.07 | wps 22069.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7252 | lr 0.000371339 | gnorm 0.757 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 21548
2022-03-07 02:38:53 | INFO | fairseq.trainer | begin training epoch 150
2022-03-07 02:38:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:41:10 | INFO | train_inner | epoch 150:     48 / 49 loss=2.34, ppl=5.06, wps=22088.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7300, lr=0.000370117, gnorm=0.735, loss_scale=16, train_wall=260, gb_free=21.5, wall=21685
2022-03-07 02:41:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:41:17 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 11.491 | ppl 2878.57 | wps 39188.4 | wpb 510.9 | bsz 1 | num_updates 7301 | best_loss 8.621
2022-03-07 02:41:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7301 updates
2022-03-07 02:41:17 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-07 02:41:17 | INFO | train | epoch 150 | loss 2.336 | ppl 5.05 | wps 22070.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7301 | lr 0.000370091 | gnorm 0.712 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 21692
2022-03-07 02:41:17 | INFO | fairseq.trainer | begin training epoch 151
2022-03-07 02:41:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:43:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:43:41 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 11.489 | ppl 2873.43 | wps 39122.7 | wpb 510.9 | bsz 1 | num_updates 7349 | best_loss 8.621
2022-03-07 02:43:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7349 updates
2022-03-07 02:43:41 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-07 02:43:41 | INFO | train | epoch 151 | loss 2.327 | ppl 5.02 | wps 21611.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7349 | lr 0.000368881 | gnorm 0.737 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 21836
2022-03-07 02:43:41 | INFO | fairseq.trainer | begin training epoch 152
2022-03-07 02:43:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:46:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:46:05 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 11.485 | ppl 2866.06 | wps 39271.7 | wpb 510.9 | bsz 1 | num_updates 7398 | best_loss 8.621
2022-03-07 02:46:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7398 updates
2022-03-07 02:46:05 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-07 02:46:05 | INFO | train | epoch 152 | loss 2.321 | ppl 5 | wps 22059.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7398 | lr 0.000367657 | gnorm 0.723 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 21980
2022-03-07 02:46:05 | INFO | fairseq.trainer | begin training epoch 153
2022-03-07 02:46:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:46:11 | INFO | train_inner | epoch 153:      2 / 49 loss=2.324, ppl=5.01, wps=21447.2, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=7400, lr=0.000367607, gnorm=0.731, loss_scale=16, train_wall=261, gb_free=21.5, wall=21986
2022-03-07 02:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:48:29 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 11.481 | ppl 2857.46 | wps 39172.9 | wpb 510.9 | bsz 1 | num_updates 7447 | best_loss 8.621
2022-03-07 02:48:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7447 updates
2022-03-07 02:48:29 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-07 02:48:29 | INFO | train | epoch 153 | loss 2.316 | ppl 4.98 | wps 22086.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7447 | lr 0.000366445 | gnorm 0.738 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 22124
2022-03-07 02:48:29 | INFO | fairseq.trainer | begin training epoch 154
2022-03-07 02:48:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:50:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:50:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:50:53 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 11.483 | ppl 2863.12 | wps 39108 | wpb 510.9 | bsz 1 | num_updates 7495 | best_loss 8.621
2022-03-07 02:50:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7495 updates
2022-03-07 02:50:53 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-07 02:50:53 | INFO | train | epoch 154 | loss 2.307 | ppl 4.95 | wps 21598.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7495 | lr 0.00036527 | gnorm 0.729 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 22268
2022-03-07 02:50:53 | INFO | fairseq.trainer | begin training epoch 155
2022-03-07 02:50:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:51:07 | INFO | train_inner | epoch 155:      5 / 49 loss=2.311, ppl=4.96, wps=21875.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.732, loss_scale=16, train_wall=262, gb_free=21.5, wall=22283
2022-03-07 02:53:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:53:17 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 11.48 | ppl 2856.14 | wps 39083.1 | wpb 510.9 | bsz 1 | num_updates 7544 | best_loss 8.621
2022-03-07 02:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7544 updates
2022-03-07 02:53:17 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-07 02:53:17 | INFO | train | epoch 155 | loss 2.3 | ppl 4.92 | wps 22071.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7544 | lr 0.000364082 | gnorm 0.704 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 22412
2022-03-07 02:53:17 | INFO | fairseq.trainer | begin training epoch 156
2022-03-07 02:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:55:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:55:41 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 11.505 | ppl 2906.38 | wps 39100.4 | wpb 510.9 | bsz 1 | num_updates 7593 | best_loss 8.621
2022-03-07 02:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7593 updates
2022-03-07 02:55:41 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-07 02:55:41 | INFO | train | epoch 156 | loss 2.293 | ppl 4.9 | wps 22065.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7593 | lr 0.000362905 | gnorm 0.699 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 22556
2022-03-07 02:55:41 | INFO | fairseq.trainer | begin training epoch 157
2022-03-07 02:55:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:56:01 | INFO | train_inner | epoch 157:      7 / 49 loss=2.294, ppl=4.91, wps=22086.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.702, loss_scale=16, train_wall=260, gb_free=21.5, wall=22576
2022-03-07 02:57:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:58:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:58:05 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 11.509 | ppl 2915.16 | wps 39058.8 | wpb 510.9 | bsz 1 | num_updates 7641 | best_loss 8.621
2022-03-07 02:58:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7641 updates
2022-03-07 02:58:05 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-07 02:58:05 | INFO | train | epoch 157 | loss 2.287 | ppl 4.88 | wps 21616.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7641 | lr 0.000361764 | gnorm 0.721 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 22700
2022-03-07 02:58:05 | INFO | fairseq.trainer | begin training epoch 158
2022-03-07 02:58:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:00:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:00:29 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 11.493 | ppl 2881.89 | wps 39037.4 | wpb 510.9 | bsz 1 | num_updates 7690 | best_loss 8.621
2022-03-07 03:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7690 updates
2022-03-07 03:00:29 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-07 03:00:29 | INFO | train | epoch 158 | loss 2.283 | ppl 4.87 | wps 22063.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7690 | lr 0.000360609 | gnorm 0.711 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 22844
2022-03-07 03:00:29 | INFO | fairseq.trainer | begin training epoch 159
2022-03-07 03:00:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:00:58 | INFO | train_inner | epoch 159:     10 / 49 loss=2.283, ppl=4.87, wps=21868.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.714, loss_scale=16, train_wall=262, gb_free=21.5, wall=22873
2022-03-07 03:02:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:02:53 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 11.485 | ppl 2866.37 | wps 39129.6 | wpb 510.9 | bsz 1 | num_updates 7739 | best_loss 8.621
2022-03-07 03:02:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7739 updates
2022-03-07 03:02:53 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-07 03:02:53 | INFO | train | epoch 159 | loss 2.274 | ppl 4.84 | wps 22066.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7739 | lr 0.000359466 | gnorm 0.69 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 22988
2022-03-07 03:02:53 | INFO | fairseq.trainer | begin training epoch 160
2022-03-07 03:02:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:04:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:05:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:05:17 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 11.5 | ppl 2896.91 | wps 39238.1 | wpb 510.9 | bsz 1 | num_updates 7787 | best_loss 8.621
2022-03-07 03:05:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7787 updates
2022-03-07 03:05:17 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-07 03:05:17 | INFO | train | epoch 160 | loss 2.268 | ppl 4.82 | wps 21608 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7787 | lr 0.000358356 | gnorm 0.709 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 23132
2022-03-07 03:05:17 | INFO | fairseq.trainer | begin training epoch 161
2022-03-07 03:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:05:54 | INFO | train_inner | epoch 161:     13 / 49 loss=2.269, ppl=4.82, wps=21877, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.7, loss_scale=16, train_wall=262, gb_free=21.5, wall=23170
2022-03-07 03:07:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:07:41 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 11.495 | ppl 2886.18 | wps 39058.8 | wpb 510.9 | bsz 1 | num_updates 7836 | best_loss 8.621
2022-03-07 03:07:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7836 updates
2022-03-07 03:07:41 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-07 03:07:41 | INFO | train | epoch 161 | loss 2.261 | ppl 4.79 | wps 22081.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7836 | lr 0.000357234 | gnorm 0.695 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 23276
2022-03-07 03:07:41 | INFO | fairseq.trainer | begin training epoch 162
2022-03-07 03:07:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:10:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:10:05 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 11.477 | ppl 2850.93 | wps 39192.5 | wpb 510.9 | bsz 1 | num_updates 7885 | best_loss 8.621
2022-03-07 03:10:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7885 updates
2022-03-07 03:10:05 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-07 03:10:05 | INFO | train | epoch 162 | loss 2.255 | ppl 4.77 | wps 22042.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7885 | lr 0.000356122 | gnorm 0.698 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 23421
2022-03-07 03:10:05 | INFO | fairseq.trainer | begin training epoch 163
2022-03-07 03:10:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:10:48 | INFO | train_inner | epoch 163:     15 / 49 loss=2.256, ppl=4.78, wps=22077.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.691, loss_scale=32, train_wall=260, gb_free=21.5, wall=23463
2022-03-07 03:11:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:12:29 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 11.497 | ppl 2890.16 | wps 39328.9 | wpb 510.9 | bsz 1 | num_updates 7933 | best_loss 8.621
2022-03-07 03:12:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7933 updates
2022-03-07 03:12:29 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-07 03:12:29 | INFO | train | epoch 163 | loss 2.251 | ppl 4.76 | wps 21629.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7933 | lr 0.000355043 | gnorm 0.694 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 23565
2022-03-07 03:12:29 | INFO | fairseq.trainer | begin training epoch 164
2022-03-07 03:12:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:14:53 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 11.527 | ppl 2950.99 | wps 39082.8 | wpb 510.9 | bsz 1 | num_updates 7982 | best_loss 8.621
2022-03-07 03:14:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7982 updates
2022-03-07 03:14:53 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-07 03:14:53 | INFO | train | epoch 164 | loss 2.245 | ppl 4.74 | wps 22081 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7982 | lr 0.000353952 | gnorm 0.682 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 23708
2022-03-07 03:14:53 | INFO | fairseq.trainer | begin training epoch 165
2022-03-07 03:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:15:45 | INFO | train_inner | epoch 165:     18 / 49 loss=2.247, ppl=4.75, wps=21890.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.693, loss_scale=16, train_wall=262, gb_free=21.5, wall=23760
2022-03-07 03:17:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:17:17 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 11.491 | ppl 2878.2 | wps 39052 | wpb 510.9 | bsz 1 | num_updates 8031 | best_loss 8.621
2022-03-07 03:17:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8031 updates
2022-03-07 03:17:17 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-07 03:17:17 | INFO | train | epoch 165 | loss 2.24 | ppl 4.72 | wps 22083 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8031 | lr 0.00035287 | gnorm 0.694 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 23852
2022-03-07 03:17:17 | INFO | fairseq.trainer | begin training epoch 166
2022-03-07 03:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:17:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:19:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:19:41 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 11.477 | ppl 2849.56 | wps 39276.2 | wpb 510.9 | bsz 1 | num_updates 8079 | best_loss 8.621
2022-03-07 03:19:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8079 updates
2022-03-07 03:19:41 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-07 03:19:41 | INFO | train | epoch 166 | loss 2.231 | ppl 4.7 | wps 21601.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8079 | lr 0.000351821 | gnorm 0.662 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 23996
2022-03-07 03:19:41 | INFO | fairseq.trainer | begin training epoch 167
2022-03-07 03:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:20:41 | INFO | train_inner | epoch 167:     21 / 49 loss=2.232, ppl=4.7, wps=21871.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.672, loss_scale=16, train_wall=262, gb_free=21.5, wall=24056
2022-03-07 03:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:22:05 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 11.475 | ppl 2846.78 | wps 39175.4 | wpb 510.9 | bsz 1 | num_updates 8128 | best_loss 8.621
2022-03-07 03:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8128 updates
2022-03-07 03:22:05 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-07 03:22:05 | INFO | train | epoch 167 | loss 2.228 | ppl 4.68 | wps 22060.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8128 | lr 0.000350758 | gnorm 0.669 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 24141
2022-03-07 03:22:05 | INFO | fairseq.trainer | begin training epoch 168
2022-03-07 03:22:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:24:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:24:29 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 11.473 | ppl 2842.61 | wps 39104.8 | wpb 510.9 | bsz 1 | num_updates 8177 | best_loss 8.621
2022-03-07 03:24:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8177 updates
2022-03-07 03:24:29 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-07 03:24:29 | INFO | train | epoch 168 | loss 2.223 | ppl 4.67 | wps 22083.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8177 | lr 0.000349706 | gnorm 0.678 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 24284
2022-03-07 03:24:29 | INFO | fairseq.trainer | begin training epoch 169
2022-03-07 03:24:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:24:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:25:38 | INFO | train_inner | epoch 169:     24 / 49 loss=2.224, ppl=4.67, wps=21875.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.671, loss_scale=16, train_wall=262, gb_free=21.5, wall=24353
2022-03-07 03:26:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:26:53 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 11.482 | ppl 2861.12 | wps 39232.1 | wpb 510.9 | bsz 1 | num_updates 8225 | best_loss 8.621
2022-03-07 03:26:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8225 updates
2022-03-07 03:26:53 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-07 03:26:53 | INFO | train | epoch 169 | loss 2.219 | ppl 4.65 | wps 21613.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8225 | lr 0.000348684 | gnorm 0.672 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 24428
2022-03-07 03:26:53 | INFO | fairseq.trainer | begin training epoch 170
2022-03-07 03:26:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:29:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:29:17 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 11.468 | ppl 2832.97 | wps 39109 | wpb 510.9 | bsz 1 | num_updates 8274 | best_loss 8.621
2022-03-07 03:29:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8274 updates
2022-03-07 03:29:17 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-07 03:29:17 | INFO | train | epoch 170 | loss 2.212 | ppl 4.63 | wps 22054.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8274 | lr 0.00034765 | gnorm 0.646 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 24573
2022-03-07 03:29:17 | INFO | fairseq.trainer | begin training epoch 171
2022-03-07 03:29:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:30:31 | INFO | train_inner | epoch 171:     26 / 49 loss=2.212, ppl=4.63, wps=22083.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.655, loss_scale=16, train_wall=260, gb_free=21.5, wall=24647
2022-03-07 03:31:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:31:41 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 11.486 | ppl 2867.58 | wps 39176.2 | wpb 510.9 | bsz 1 | num_updates 8323 | best_loss 8.621
2022-03-07 03:31:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8323 updates
2022-03-07 03:31:41 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-07 03:31:41 | INFO | train | epoch 171 | loss 2.206 | ppl 4.61 | wps 22083.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8323 | lr 0.000346625 | gnorm 0.64 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 24716
2022-03-07 03:31:41 | INFO | fairseq.trainer | begin training epoch 172
2022-03-07 03:31:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:31:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:34:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:34:05 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 11.469 | ppl 2835.07 | wps 39183.7 | wpb 510.9 | bsz 1 | num_updates 8371 | best_loss 8.621
2022-03-07 03:34:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8371 updates
2022-03-07 03:34:05 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-07 03:34:05 | INFO | train | epoch 172 | loss 2.203 | ppl 4.6 | wps 21608.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8371 | lr 0.00034563 | gnorm 0.66 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 24860
2022-03-07 03:34:05 | INFO | fairseq.trainer | begin training epoch 173
2022-03-07 03:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:35:28 | INFO | train_inner | epoch 173:     29 / 49 loss=2.202, ppl=4.6, wps=21878.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.654, loss_scale=16, train_wall=262, gb_free=21.5, wall=24943
2022-03-07 03:36:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:36:29 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 11.474 | ppl 2844.24 | wps 39153.5 | wpb 510.9 | bsz 1 | num_updates 8420 | best_loss 8.621
2022-03-07 03:36:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8420 updates
2022-03-07 03:36:29 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-07 03:36:29 | INFO | train | epoch 173 | loss 2.199 | ppl 4.59 | wps 22077.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8420 | lr 0.000344623 | gnorm 0.669 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 25004
2022-03-07 03:36:29 | INFO | fairseq.trainer | begin training epoch 174
2022-03-07 03:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:38:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:38:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:38:53 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 11.46 | ppl 2817.6 | wps 39072.3 | wpb 510.9 | bsz 1 | num_updates 8468 | best_loss 8.621
2022-03-07 03:38:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8468 updates
2022-03-07 03:38:53 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-07 03:38:53 | INFO | train | epoch 174 | loss 2.192 | ppl 4.57 | wps 21611.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8468 | lr 0.000343645 | gnorm 0.641 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 25148
2022-03-07 03:38:53 | INFO | fairseq.trainer | begin training epoch 175
2022-03-07 03:38:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:40:24 | INFO | train_inner | epoch 175:     32 / 49 loss=2.192, ppl=4.57, wps=21879.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.646, loss_scale=16, train_wall=262, gb_free=21.5, wall=25240
2022-03-07 03:41:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:41:17 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 11.459 | ppl 2814.93 | wps 39050.4 | wpb 510.9 | bsz 1 | num_updates 8517 | best_loss 8.621
2022-03-07 03:41:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8517 updates
2022-03-07 03:41:17 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-07 03:41:17 | INFO | train | epoch 175 | loss 2.188 | ppl 4.56 | wps 22077.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8517 | lr 0.000342655 | gnorm 0.646 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 25292
2022-03-07 03:41:17 | INFO | fairseq.trainer | begin training epoch 176
2022-03-07 03:41:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:43:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:43:41 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 11.436 | ppl 2770.18 | wps 38988.9 | wpb 510.9 | bsz 1 | num_updates 8566 | best_loss 8.621
2022-03-07 03:43:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8566 updates
2022-03-07 03:43:41 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-07 03:43:41 | INFO | train | epoch 176 | loss 2.184 | ppl 4.54 | wps 22062.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8566 | lr 0.000341673 | gnorm 0.651 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 25436
2022-03-07 03:43:41 | INFO | fairseq.trainer | begin training epoch 177
2022-03-07 03:43:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:45:18 | INFO | train_inner | epoch 177:     34 / 49 loss=2.184, ppl=4.54, wps=22083.5, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.648, loss_scale=32, train_wall=260, gb_free=21.5, wall=25533
2022-03-07 03:46:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:46:05 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 11.441 | ppl 2780.15 | wps 38994.2 | wpb 510.9 | bsz 1 | num_updates 8615 | best_loss 8.621
2022-03-07 03:46:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8615 updates
2022-03-07 03:46:05 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-07 03:46:05 | INFO | train | epoch 177 | loss 2.179 | ppl 4.53 | wps 22060.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8615 | lr 0.0003407 | gnorm 0.634 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 25580
2022-03-07 03:46:05 | INFO | fairseq.trainer | begin training epoch 178
2022-03-07 03:46:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:47:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:48:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:48:29 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 11.45 | ppl 2797.83 | wps 39070.1 | wpb 510.9 | bsz 1 | num_updates 8663 | best_loss 8.621
2022-03-07 03:48:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8663 updates
2022-03-07 03:48:29 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-07 03:48:29 | INFO | train | epoch 178 | loss 2.174 | ppl 4.51 | wps 21629.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8663 | lr 0.000339755 | gnorm 0.628 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 25724
2022-03-07 03:48:29 | INFO | fairseq.trainer | begin training epoch 179
2022-03-07 03:48:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:50:15 | INFO | train_inner | epoch 179:     37 / 49 loss=2.174, ppl=4.51, wps=21880, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.628, loss_scale=16, train_wall=262, gb_free=21.5, wall=25830
2022-03-07 03:50:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:50:53 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 11.449 | ppl 2796.28 | wps 39128.4 | wpb 510.9 | bsz 1 | num_updates 8712 | best_loss 8.621
2022-03-07 03:50:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8712 updates
2022-03-07 03:50:53 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-07 03:50:53 | INFO | train | epoch 179 | loss 2.171 | ppl 4.5 | wps 22074 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8712 | lr 0.000338798 | gnorm 0.626 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 25868
2022-03-07 03:50:53 | INFO | fairseq.trainer | begin training epoch 180
2022-03-07 03:50:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:53:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:53:17 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 11.458 | ppl 2813.36 | wps 38889.4 | wpb 510.9 | bsz 1 | num_updates 8761 | best_loss 8.621
2022-03-07 03:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8761 updates
2022-03-07 03:53:17 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-07 03:53:17 | INFO | train | epoch 180 | loss 2.167 | ppl 4.49 | wps 22066.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8761 | lr 0.000337849 | gnorm 0.642 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 26012
2022-03-07 03:53:17 | INFO | fairseq.trainer | begin training epoch 181
2022-03-07 03:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:53:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:55:11 | INFO | train_inner | epoch 181:     40 / 49 loss=2.165, ppl=4.49, wps=21876.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.632, loss_scale=16, train_wall=262, gb_free=21.5, wall=26127
2022-03-07 03:55:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:55:41 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 11.452 | ppl 2800.85 | wps 39215.1 | wpb 510.9 | bsz 1 | num_updates 8809 | best_loss 8.621
2022-03-07 03:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8809 updates
2022-03-07 03:55:41 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-07 03:55:41 | INFO | train | epoch 181 | loss 2.161 | ppl 4.47 | wps 21616.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8809 | lr 0.000336928 | gnorm 0.623 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 26156
2022-03-07 03:55:41 | INFO | fairseq.trainer | begin training epoch 182
2022-03-07 03:55:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:58:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:58:05 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 11.448 | ppl 2792.88 | wps 39161 | wpb 510.9 | bsz 1 | num_updates 8858 | best_loss 8.621
2022-03-07 03:58:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8858 updates
2022-03-07 03:58:05 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-07 03:58:05 | INFO | train | epoch 182 | loss 2.159 | ppl 4.47 | wps 22067.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8858 | lr 0.000335994 | gnorm 0.634 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 26300
2022-03-07 03:58:05 | INFO | fairseq.trainer | begin training epoch 183
2022-03-07 03:58:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:00:05 | INFO | train_inner | epoch 183:     42 / 49 loss=2.157, ppl=4.46, wps=22079.8, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.633, loss_scale=16, train_wall=260, gb_free=21.5, wall=26420
2022-03-07 04:00:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:00:29 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 11.419 | ppl 2737.89 | wps 39082.8 | wpb 510.9 | bsz 1 | num_updates 8907 | best_loss 8.621
2022-03-07 04:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8907 updates
2022-03-07 04:00:29 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-07 04:00:29 | INFO | train | epoch 183 | loss 2.154 | ppl 4.45 | wps 22052.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8907 | lr 0.000335069 | gnorm 0.631 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 26445
2022-03-07 04:00:29 | INFO | fairseq.trainer | begin training epoch 184
2022-03-07 04:00:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:01:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:02:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:02:53 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 11.429 | ppl 2757.56 | wps 39048.2 | wpb 510.9 | bsz 1 | num_updates 8955 | best_loss 8.621
2022-03-07 04:02:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8955 updates
2022-03-07 04:02:53 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-07 04:02:53 | INFO | train | epoch 184 | loss 2.149 | ppl 4.43 | wps 21604.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8955 | lr 0.00033417 | gnorm 0.612 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 26589
2022-03-07 04:02:53 | INFO | fairseq.trainer | begin training epoch 185
2022-03-07 04:02:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:05:02 | INFO | train_inner | epoch 185:     45 / 49 loss=2.148, ppl=4.43, wps=21866, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.613, loss_scale=16, train_wall=262, gb_free=21.5, wall=26717
2022-03-07 04:05:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:05:17 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 11.436 | ppl 2770.8 | wps 39093.1 | wpb 510.9 | bsz 1 | num_updates 9004 | best_loss 8.621
2022-03-07 04:05:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9004 updates
2022-03-07 04:05:17 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-07 04:05:17 | INFO | train | epoch 185 | loss 2.145 | ppl 4.42 | wps 22062 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9004 | lr 0.000333259 | gnorm 0.613 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 26733
2022-03-07 04:05:17 | INFO | fairseq.trainer | begin training epoch 186
2022-03-07 04:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:07:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:07:41 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 11.461 | ppl 2818.23 | wps 39288.4 | wpb 510.9 | bsz 1 | num_updates 9053 | best_loss 8.621
2022-03-07 04:07:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9053 updates
2022-03-07 04:07:41 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-07 04:07:41 | INFO | train | epoch 186 | loss 2.14 | ppl 4.41 | wps 22058.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9053 | lr 0.000332356 | gnorm 0.607 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 26877
2022-03-07 04:07:41 | INFO | fairseq.trainer | begin training epoch 187
2022-03-07 04:07:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:08:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:09:58 | INFO | train_inner | epoch 187:     48 / 49 loss=2.14, ppl=4.41, wps=21868.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=9100, lr=0.000331497, gnorm=0.618, loss_scale=16, train_wall=262, gb_free=21.5, wall=27014
2022-03-07 04:10:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:10:05 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 11.433 | ppl 2764.06 | wps 39132.4 | wpb 510.9 | bsz 1 | num_updates 9101 | best_loss 8.621
2022-03-07 04:10:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9101 updates
2022-03-07 04:10:05 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-07 04:10:05 | INFO | train | epoch 187 | loss 2.138 | ppl 4.4 | wps 21615 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 9101 | lr 0.000331479 | gnorm 0.629 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 27021
2022-03-07 04:10:05 | INFO | fairseq.trainer | begin training epoch 188
2022-03-07 04:10:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:12:29 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 11.465 | ppl 2827.81 | wps 39272.9 | wpb 510.9 | bsz 1 | num_updates 9150 | best_loss 8.621
2022-03-07 04:12:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9150 updates
2022-03-07 04:12:29 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-07 04:12:29 | INFO | train | epoch 188 | loss 2.133 | ppl 4.39 | wps 22067.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9150 | lr 0.00033059 | gnorm 0.618 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 27165
2022-03-07 04:12:29 | INFO | fairseq.trainer | begin training epoch 189
2022-03-07 04:12:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:14:54 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 11.457 | ppl 2810.96 | wps 39191.6 | wpb 510.9 | bsz 1 | num_updates 9199 | best_loss 8.621
2022-03-07 04:14:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9199 updates
2022-03-07 04:14:54 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-07 04:14:54 | INFO | train | epoch 189 | loss 2.128 | ppl 4.37 | wps 22060.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9199 | lr 0.000329708 | gnorm 0.595 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 27309
2022-03-07 04:14:54 | INFO | fairseq.trainer | begin training epoch 190
2022-03-07 04:14:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:14:56 | INFO | train_inner | epoch 190:      1 / 49 loss=2.131, ppl=4.38, wps=21652.2, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=9200, lr=0.00032969, gnorm=0.609, loss_scale=32, train_wall=259, gb_free=21.5, wall=27312
2022-03-07 04:15:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:17:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:17:17 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 11.461 | ppl 2818.81 | wps 39070.1 | wpb 510.9 | bsz 1 | num_updates 9247 | best_loss 8.621
2022-03-07 04:17:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9247 updates
2022-03-07 04:17:17 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-07 04:17:17 | INFO | train | epoch 190 | loss 2.126 | ppl 4.37 | wps 21623.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 9247 | lr 0.000328851 | gnorm 0.606 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 27453
2022-03-07 04:17:17 | INFO | fairseq.trainer | begin training epoch 191
2022-03-07 04:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:19:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:19:41 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 11.427 | ppl 2753.34 | wps 39100.7 | wpb 510.9 | bsz 1 | num_updates 9296 | best_loss 8.621
2022-03-07 04:19:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9296 updates
2022-03-07 04:19:41 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-07 04:19:41 | INFO | train | epoch 191 | loss 2.124 | ppl 4.36 | wps 22070.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9296 | lr 0.000327983 | gnorm 0.608 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 27597
2022-03-07 04:19:41 | INFO | fairseq.trainer | begin training epoch 192
2022-03-07 04:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:19:53 | INFO | train_inner | epoch 192:      4 / 49 loss=2.124, ppl=4.36, wps=21879.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.608, loss_scale=16, train_wall=262, gb_free=21.5, wall=27608
2022-03-07 04:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:22:05 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 11.445 | ppl 2787.7 | wps 39185.9 | wpb 510.9 | bsz 1 | num_updates 9345 | best_loss 8.621
2022-03-07 04:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9345 updates
2022-03-07 04:22:05 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-07 04:22:05 | INFO | train | epoch 192 | loss 2.118 | ppl 4.34 | wps 22077 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9345 | lr 0.000327122 | gnorm 0.597 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 27741
2022-03-07 04:22:05 | INFO | fairseq.trainer | begin training epoch 193
2022-03-07 04:22:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:24:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:24:29 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 11.417 | ppl 2734.91 | wps 39166.7 | wpb 510.9 | bsz 1 | num_updates 9394 | best_loss 8.621
2022-03-07 04:24:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9394 updates
2022-03-07 04:24:29 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-07 04:24:29 | INFO | train | epoch 193 | loss 2.116 | ppl 4.33 | wps 22080.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9394 | lr 0.000326268 | gnorm 0.593 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 27885
2022-03-07 04:24:29 | INFO | fairseq.trainer | begin training epoch 194
2022-03-07 04:24:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:24:47 | INFO | train_inner | epoch 194:      6 / 49 loss=2.116, ppl=4.34, wps=22097, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.594, loss_scale=32, train_wall=260, gb_free=21.5, wall=27902
2022-03-07 04:26:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:26:53 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 11.427 | ppl 2752.88 | wps 39210.8 | wpb 510.9 | bsz 1 | num_updates 9443 | best_loss 8.621
2022-03-07 04:26:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9443 updates
2022-03-07 04:26:53 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-07 04:26:53 | INFO | train | epoch 194 | loss 2.113 | ppl 4.33 | wps 22073.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9443 | lr 0.000325421 | gnorm 0.606 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 28029
2022-03-07 04:26:53 | INFO | fairseq.trainer | begin training epoch 195
2022-03-07 04:26:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:27:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:29:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:29:17 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 11.425 | ppl 2748.67 | wps 39296.5 | wpb 510.9 | bsz 1 | num_updates 9491 | best_loss 8.621
2022-03-07 04:29:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9491 updates
2022-03-07 04:29:17 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-07 04:29:17 | INFO | train | epoch 195 | loss 2.109 | ppl 4.31 | wps 21639.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 9491 | lr 0.000324597 | gnorm 0.599 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 28172
2022-03-07 04:29:17 | INFO | fairseq.trainer | begin training epoch 196
2022-03-07 04:29:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:29:43 | INFO | train_inner | epoch 196:      9 / 49 loss=2.11, ppl=4.32, wps=21890.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.6, loss_scale=32, train_wall=262, gb_free=21.5, wall=28198
2022-03-07 04:31:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:31:41 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 11.409 | ppl 2719.36 | wps 39153.8 | wpb 510.9 | bsz 1 | num_updates 9540 | best_loss 8.621
2022-03-07 04:31:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9540 updates
2022-03-07 04:31:41 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-07 04:31:41 | INFO | train | epoch 196 | loss 2.105 | ppl 4.3 | wps 22067.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9540 | lr 0.000323762 | gnorm 0.584 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 28316
2022-03-07 04:31:41 | INFO | fairseq.trainer | begin training epoch 197
2022-03-07 04:31:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:31:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:33:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:34:05 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 11.426 | ppl 2751.62 | wps 39069.7 | wpb 510.9 | bsz 1 | num_updates 9588 | best_loss 8.621
2022-03-07 04:34:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9588 updates
2022-03-07 04:34:05 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-07 04:34:05 | INFO | train | epoch 197 | loss 2.102 | ppl 4.29 | wps 21629.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 9588 | lr 0.000322951 | gnorm 0.588 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 28460
2022-03-07 04:34:05 | INFO | fairseq.trainer | begin training epoch 198
2022-03-07 04:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:34:39 | INFO | train_inner | epoch 198:     12 / 49 loss=2.103, ppl=4.3, wps=21876.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.587, loss_scale=16, train_wall=262, gb_free=21.5, wall=28495
2022-03-07 04:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:36:29 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 11.44 | ppl 2778.93 | wps 39056.5 | wpb 510.9 | bsz 1 | num_updates 9637 | best_loss 8.621
2022-03-07 04:36:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9637 updates
2022-03-07 04:36:29 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-07 04:36:29 | INFO | train | epoch 198 | loss 2.099 | ppl 4.28 | wps 22067.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9637 | lr 0.000322128 | gnorm 0.586 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 28604
2022-03-07 04:36:29 | INFO | fairseq.trainer | begin training epoch 199
2022-03-07 04:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:38:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:38:53 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 11.444 | ppl 2786.78 | wps 39322.2 | wpb 510.9 | bsz 1 | num_updates 9686 | best_loss 8.621
2022-03-07 04:38:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9686 updates
2022-03-07 04:38:53 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-07 04:38:53 | INFO | train | epoch 199 | loss 2.096 | ppl 4.27 | wps 22080.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9686 | lr 0.000321313 | gnorm 0.587 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 28748
2022-03-07 04:38:53 | INFO | fairseq.trainer | begin training epoch 200
2022-03-07 04:38:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:39:33 | INFO | train_inner | epoch 200:     14 / 49 loss=2.096, ppl=4.28, wps=22096, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.583, loss_scale=32, train_wall=260, gb_free=21.5, wall=28788
2022-03-07 04:40:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:41:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:41:17 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 11.43 | ppl 2759.4 | wps 39210.1 | wpb 510.9 | bsz 1 | num_updates 9734 | best_loss 8.621
2022-03-07 04:41:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9734 updates
2022-03-07 04:41:17 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-07 04:41:17 | INFO | train | epoch 200 | loss 2.093 | ppl 4.26 | wps 21616.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 9734 | lr 0.000320519 | gnorm 0.58 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 28892
2022-03-07 04:41:17 | INFO | fairseq.trainer | begin training epoch 201
2022-03-07 04:41:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:43:41 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 11.423 | ppl 2746.1 | wps 39163.2 | wpb 510.9 | bsz 1 | num_updates 9783 | best_loss 8.621
2022-03-07 04:43:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9783 updates
2022-03-07 04:43:41 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-07 04:43:41 | INFO | train | epoch 201 | loss 2.09 | ppl 4.26 | wps 22068.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9783 | lr 0.000319716 | gnorm 0.578 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 29036
2022-03-07 04:43:41 | INFO | fairseq.trainer | begin training epoch 202
2022-03-07 04:43:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:44:30 | INFO | train_inner | epoch 202:     17 / 49 loss=2.09, ppl=4.26, wps=21876.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.584, loss_scale=16, train_wall=262, gb_free=21.5, wall=29085
2022-03-07 04:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:46:05 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 11.441 | ppl 2780.32 | wps 39182.7 | wpb 510.9 | bsz 1 | num_updates 9832 | best_loss 8.621
2022-03-07 04:46:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9832 updates
2022-03-07 04:46:05 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-07 04:46:05 | INFO | train | epoch 202 | loss 2.086 | ppl 4.25 | wps 22064.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9832 | lr 0.000318918 | gnorm 0.587 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 29180
2022-03-07 04:46:05 | INFO | fairseq.trainer | begin training epoch 203
2022-03-07 04:46:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:48:29 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 11.414 | ppl 2728.93 | wps 39106 | wpb 510.9 | bsz 1 | num_updates 9881 | best_loss 8.621
2022-03-07 04:48:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9881 updates
2022-03-07 04:48:29 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-07 04:48:29 | INFO | train | epoch 203 | loss 2.083 | ppl 4.24 | wps 22087.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9881 | lr 0.000318126 | gnorm 0.578 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 29324
2022-03-07 04:48:29 | INFO | fairseq.trainer | begin training epoch 204
2022-03-07 04:48:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:49:23 | INFO | train_inner | epoch 204:     19 / 49 loss=2.083, ppl=4.24, wps=22089.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.574, loss_scale=32, train_wall=260, gb_free=21.5, wall=29378
2022-03-07 04:50:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:50:53 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 11.458 | ppl 2813.39 | wps 39074.1 | wpb 510.9 | bsz 1 | num_updates 9930 | best_loss 8.621
2022-03-07 04:50:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9930 updates
2022-03-07 04:50:53 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-07 04:50:53 | INFO | train | epoch 204 | loss 2.08 | ppl 4.23 | wps 22065 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9930 | lr 0.00031734 | gnorm 0.567 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 29468
2022-03-07 04:50:53 | INFO | fairseq.trainer | begin training epoch 205
2022-03-07 04:50:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:50:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:53:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:53:17 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 11.479 | ppl 2854.27 | wps 39187.9 | wpb 510.9 | bsz 1 | num_updates 9978 | best_loss 8.621
2022-03-07 04:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9978 updates
2022-03-07 04:53:17 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-07 04:53:17 | INFO | train | epoch 205 | loss 2.076 | ppl 4.22 | wps 21607.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 9978 | lr 0.000316576 | gnorm 0.572 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 29612
2022-03-07 04:53:17 | INFO | fairseq.trainer | begin training epoch 206
2022-03-07 04:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:54:20 | INFO | train_inner | epoch 206:     22 / 49 loss=2.077, ppl=4.22, wps=21873.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.572, loss_scale=16, train_wall=262, gb_free=21.5, wall=29675
2022-03-07 04:55:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:55:41 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 11.431 | ppl 2761.49 | wps 39280.6 | wpb 510.9 | bsz 1 | num_updates 10027 | best_loss 8.621
2022-03-07 04:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10027 updates
2022-03-07 04:55:41 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-07 04:55:41 | INFO | train | epoch 206 | loss 2.074 | ppl 4.21 | wps 22079.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10027 | lr 0.000315802 | gnorm 0.574 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 29756
2022-03-07 04:55:41 | INFO | fairseq.trainer | begin training epoch 207
2022-03-07 04:55:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:58:05 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 11.43 | ppl 2759.24 | wps 38936.6 | wpb 510.9 | bsz 1 | num_updates 10076 | best_loss 8.621
2022-03-07 04:58:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10076 updates
2022-03-07 04:58:05 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-07 04:58:05 | INFO | train | epoch 207 | loss 2.071 | ppl 4.2 | wps 22050 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10076 | lr 0.000315033 | gnorm 0.563 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 29900
2022-03-07 04:58:05 | INFO | fairseq.trainer | begin training epoch 208
2022-03-07 04:58:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:59:14 | INFO | train_inner | epoch 208:     24 / 49 loss=2.072, ppl=4.2, wps=22079.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.574, loss_scale=32, train_wall=260, gb_free=21.5, wall=29969
2022-03-07 05:00:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:00:29 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 11.402 | ppl 2706.86 | wps 39048.2 | wpb 510.9 | bsz 1 | num_updates 10125 | best_loss 8.621
2022-03-07 05:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10125 updates
2022-03-07 05:00:29 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-07 05:00:29 | INFO | train | epoch 208 | loss 2.069 | ppl 4.2 | wps 22044 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10125 | lr 0.00031427 | gnorm 0.581 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 30045
2022-03-07 05:00:29 | INFO | fairseq.trainer | begin training epoch 209
2022-03-07 05:00:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:02:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:02:53 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 11.418 | ppl 2736.21 | wps 39226.3 | wpb 510.9 | bsz 1 | num_updates 10174 | best_loss 8.621
2022-03-07 05:02:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10174 updates
2022-03-07 05:02:53 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-07 05:02:53 | INFO | train | epoch 209 | loss 2.065 | ppl 4.18 | wps 22064.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10174 | lr 0.000313512 | gnorm 0.56 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 30189
2022-03-07 05:02:53 | INFO | fairseq.trainer | begin training epoch 210
2022-03-07 05:02:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:04:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:04:10 | INFO | train_inner | epoch 210:     27 / 49 loss=2.064, ppl=4.18, wps=21861.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.556, loss_scale=32, train_wall=263, gb_free=21.5, wall=30266
2022-03-07 05:05:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:05:17 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 11.391 | ppl 2686.4 | wps 39282.5 | wpb 510.9 | bsz 1 | num_updates 10222 | best_loss 8.621
2022-03-07 05:05:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10222 updates
2022-03-07 05:05:17 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-07 05:05:17 | INFO | train | epoch 210 | loss 2.061 | ppl 4.17 | wps 21612.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 10222 | lr 0.000312775 | gnorm 0.556 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 30333
2022-03-07 05:05:17 | INFO | fairseq.trainer | begin training epoch 211
2022-03-07 05:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:07:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:07:41 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 11.432 | ppl 2763.07 | wps 39259.8 | wpb 510.9 | bsz 1 | num_updates 10271 | best_loss 8.621
2022-03-07 05:07:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10271 updates
2022-03-07 05:07:41 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-07 05:07:41 | INFO | train | epoch 211 | loss 2.061 | ppl 4.17 | wps 22065.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10271 | lr 0.000312028 | gnorm 0.567 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 30477
2022-03-07 05:07:41 | INFO | fairseq.trainer | begin training epoch 212
2022-03-07 05:07:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:08:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:09:07 | INFO | train_inner | epoch 212:     30 / 49 loss=2.061, ppl=4.17, wps=21872.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.565, loss_scale=16, train_wall=262, gb_free=21.5, wall=30562
2022-03-07 05:10:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:10:05 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 11.399 | ppl 2700.51 | wps 39186.4 | wpb 510.9 | bsz 1 | num_updates 10319 | best_loss 8.621
2022-03-07 05:10:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10319 updates
2022-03-07 05:10:05 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-07 05:10:05 | INFO | train | epoch 212 | loss 2.057 | ppl 4.16 | wps 21613.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 10319 | lr 0.000311301 | gnorm 0.554 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 30621
2022-03-07 05:10:05 | INFO | fairseq.trainer | begin training epoch 213
2022-03-07 05:10:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:12:29 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 11.422 | ppl 2743.37 | wps 39182.1 | wpb 510.9 | bsz 1 | num_updates 10368 | best_loss 8.621
2022-03-07 05:12:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10368 updates
2022-03-07 05:12:29 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-07 05:12:29 | INFO | train | epoch 213 | loss 2.054 | ppl 4.15 | wps 22080.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10368 | lr 0.000310565 | gnorm 0.561 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 30765
2022-03-07 05:12:29 | INFO | fairseq.trainer | begin training epoch 214
2022-03-07 05:12:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:14:01 | INFO | train_inner | epoch 214:     32 / 49 loss=2.054, ppl=4.15, wps=22090.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.556, loss_scale=16, train_wall=260, gb_free=21.5, wall=30856
2022-03-07 05:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:14:53 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 11.408 | ppl 2716.57 | wps 39133.5 | wpb 510.9 | bsz 1 | num_updates 10417 | best_loss 8.621
2022-03-07 05:14:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10417 updates
2022-03-07 05:14:53 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-07 05:14:53 | INFO | train | epoch 214 | loss 2.052 | ppl 4.15 | wps 22065.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10417 | lr 0.000309834 | gnorm 0.553 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 30909
2022-03-07 05:14:53 | INFO | fairseq.trainer | begin training epoch 215
2022-03-07 05:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:17:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:17:17 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 11.408 | ppl 2717.56 | wps 39139.8 | wpb 510.9 | bsz 1 | num_updates 10466 | best_loss 8.621
2022-03-07 05:17:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10466 updates
2022-03-07 05:17:17 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-07 05:17:17 | INFO | train | epoch 215 | loss 2.05 | ppl 4.14 | wps 22062.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10466 | lr 0.000309108 | gnorm 0.556 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 31053
2022-03-07 05:17:17 | INFO | fairseq.trainer | begin training epoch 216
2022-03-07 05:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:18:54 | INFO | train_inner | epoch 216:     34 / 49 loss=2.049, ppl=4.14, wps=22083.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.554, loss_scale=32, train_wall=260, gb_free=21.5, wall=31150
2022-03-07 05:19:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:19:41 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 11.394 | ppl 2691.49 | wps 39185.4 | wpb 510.9 | bsz 1 | num_updates 10515 | best_loss 8.621
2022-03-07 05:19:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10515 updates
2022-03-07 05:19:41 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-07 05:19:41 | INFO | train | epoch 216 | loss 2.047 | ppl 4.13 | wps 22061.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10515 | lr 0.000308387 | gnorm 0.552 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 31197
2022-03-07 05:19:41 | INFO | fairseq.trainer | begin training epoch 217
2022-03-07 05:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:21:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:22:05 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 11.417 | ppl 2734.76 | wps 39228.6 | wpb 510.9 | bsz 1 | num_updates 10563 | best_loss 8.621
2022-03-07 05:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10563 updates
2022-03-07 05:22:05 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-07 05:22:05 | INFO | train | epoch 217 | loss 2.045 | ppl 4.13 | wps 21622.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 10563 | lr 0.000307685 | gnorm 0.559 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 31341
2022-03-07 05:22:05 | INFO | fairseq.trainer | begin training epoch 218
2022-03-07 05:22:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:23:51 | INFO | train_inner | epoch 218:     37 / 49 loss=2.044, ppl=4.12, wps=21868.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.553, loss_scale=32, train_wall=262, gb_free=21.5, wall=31446
2022-03-07 05:24:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:24:29 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 11.403 | ppl 2708.57 | wps 39674.5 | wpb 510.9 | bsz 1 | num_updates 10612 | best_loss 8.621
2022-03-07 05:24:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10612 updates
2022-03-07 05:24:29 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-07 05:24:29 | INFO | train | epoch 218 | loss 2.041 | ppl 4.12 | wps 22067.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10612 | lr 0.000306974 | gnorm 0.545 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 31485
2022-03-07 05:24:29 | INFO | fairseq.trainer | begin training epoch 219
2022-03-07 05:24:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:24:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:26:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:26:53 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 11.446 | ppl 2790.44 | wps 38692.5 | wpb 510.9 | bsz 1 | num_updates 10660 | best_loss 8.621
2022-03-07 05:26:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10660 updates
2022-03-07 05:26:53 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-07 05:26:53 | INFO | train | epoch 219 | loss 2.039 | ppl 4.11 | wps 21601.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 10660 | lr 0.000306282 | gnorm 0.553 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 31629
2022-03-07 05:26:53 | INFO | fairseq.trainer | begin training epoch 220
2022-03-07 05:26:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:28:48 | INFO | train_inner | epoch 220:     40 / 49 loss=2.039, ppl=4.11, wps=21875.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.556, loss_scale=16, train_wall=262, gb_free=21.5, wall=31743
2022-03-07 05:29:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:29:17 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 11.419 | ppl 2738.83 | wps 39271.9 | wpb 510.9 | bsz 1 | num_updates 10709 | best_loss 8.621
2022-03-07 05:29:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10709 updates
2022-03-07 05:29:17 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-07 05:29:17 | INFO | train | epoch 220 | loss 2.037 | ppl 4.1 | wps 22082.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10709 | lr 0.00030558 | gnorm 0.559 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 31773
2022-03-07 05:29:17 | INFO | fairseq.trainer | begin training epoch 221
2022-03-07 05:29:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:31:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:31:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:31:41 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 11.415 | ppl 2731.37 | wps 39214.7 | wpb 510.9 | bsz 1 | num_updates 10757 | best_loss 8.621
2022-03-07 05:31:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10757 updates
2022-03-07 05:31:41 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-07 05:31:41 | INFO | train | epoch 221 | loss 2.034 | ppl 4.09 | wps 21599.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 10757 | lr 0.000304898 | gnorm 0.545 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 31917
2022-03-07 05:31:42 | INFO | fairseq.trainer | begin training epoch 222
2022-03-07 05:31:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:33:44 | INFO | train_inner | epoch 222:     43 / 49 loss=2.034, ppl=4.09, wps=21872.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.547, loss_scale=16, train_wall=262, gb_free=21.5, wall=32039
2022-03-07 05:34:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:34:05 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 11.407 | ppl 2715.13 | wps 39030.9 | wpb 510.9 | bsz 1 | num_updates 10806 | best_loss 8.621
2022-03-07 05:34:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10806 updates
2022-03-07 05:34:05 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-07 05:34:05 | INFO | train | epoch 222 | loss 2.032 | ppl 4.09 | wps 22068.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10806 | lr 0.000304206 | gnorm 0.549 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 32061
2022-03-07 05:34:06 | INFO | fairseq.trainer | begin training epoch 223
2022-03-07 05:34:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:36:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:36:30 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 11.397 | ppl 2697.48 | wps 39346.6 | wpb 510.9 | bsz 1 | num_updates 10855 | best_loss 8.621
2022-03-07 05:36:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10855 updates
2022-03-07 05:36:30 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-07 05:36:30 | INFO | train | epoch 223 | loss 2.029 | ppl 4.08 | wps 22068.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10855 | lr 0.000303518 | gnorm 0.546 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 32205
2022-03-07 05:36:30 | INFO | fairseq.trainer | begin training epoch 224
2022-03-07 05:36:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:38:38 | INFO | train_inner | epoch 224:     45 / 49 loss=2.029, ppl=4.08, wps=22086.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10900, lr=0.000302891, gnorm=0.545, loss_scale=32, train_wall=260, gb_free=21.5, wall=32333
2022-03-07 05:38:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:38:53 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 11.386 | ppl 2675.76 | wps 39150.5 | wpb 510.9 | bsz 1 | num_updates 10904 | best_loss 8.621
2022-03-07 05:38:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10904 updates
2022-03-07 05:38:53 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-07 05:38:53 | INFO | train | epoch 224 | loss 2.028 | ppl 4.08 | wps 22071.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10904 | lr 0.000302836 | gnorm 0.542 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 32349
2022-03-07 05:38:54 | INFO | fairseq.trainer | begin training epoch 225
2022-03-07 05:38:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:38:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:41:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:41:17 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 11.422 | ppl 2744.31 | wps 39152.7 | wpb 510.9 | bsz 1 | num_updates 10952 | best_loss 8.621
2022-03-07 05:41:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10952 updates
2022-03-07 05:41:17 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-07 05:41:17 | INFO | train | epoch 225 | loss 2.024 | ppl 4.07 | wps 21626.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 10952 | lr 0.000302171 | gnorm 0.531 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 32493
2022-03-07 05:41:17 | INFO | fairseq.trainer | begin training epoch 226
2022-03-07 05:41:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:43:34 | INFO | train_inner | epoch 226:     48 / 49 loss=2.024, ppl=4.07, wps=21879.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11000, lr=0.000301511, gnorm=0.537, loss_scale=16, train_wall=262, gb_free=21.5, wall=32630
2022-03-07 05:43:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:43:41 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 11.39 | ppl 2684.01 | wps 39202.8 | wpb 510.9 | bsz 1 | num_updates 11001 | best_loss 8.621
2022-03-07 05:43:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 11001 updates
2022-03-07 05:43:41 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-07 05:43:41 | INFO | train | epoch 226 | loss 2.023 | ppl 4.06 | wps 22067.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11001 | lr 0.000301498 | gnorm 0.539 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 32637
2022-03-07 05:43:41 | INFO | fairseq.trainer | begin training epoch 227
2022-03-07 05:43:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:45:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:46:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:46:05 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 11.383 | ppl 2670.59 | wps 39041.9 | wpb 510.9 | bsz 1 | num_updates 11049 | best_loss 8.621
2022-03-07 05:46:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11049 updates
2022-03-07 05:46:05 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-07 05:46:05 | INFO | train | epoch 227 | loss 2.021 | ppl 4.06 | wps 21639.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 11049 | lr 0.000300842 | gnorm 0.545 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 32781
2022-03-07 05:46:05 | INFO | fairseq.trainer | begin training epoch 228
2022-03-07 05:46:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:48:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:48:29 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 11.355 | ppl 2619.05 | wps 39185.9 | wpb 510.9 | bsz 1 | num_updates 11098 | best_loss 8.621
2022-03-07 05:48:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11098 updates
2022-03-07 05:48:29 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-07 05:48:29 | INFO | train | epoch 228 | loss 2.018 | ppl 4.05 | wps 22081.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11098 | lr 0.000300177 | gnorm 0.532 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 32924
2022-03-07 05:48:29 | INFO | fairseq.trainer | begin training epoch 229
2022-03-07 05:48:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:48:35 | INFO | train_inner | epoch 229:      2 / 49 loss=2.019, ppl=4.05, wps=21471, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=11100, lr=0.00030015, gnorm=0.54, loss_scale=16, train_wall=261, gb_free=21.5, wall=32930
2022-03-07 05:50:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:50:53 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 11.383 | ppl 2671.06 | wps 39130.1 | wpb 510.9 | bsz 1 | num_updates 11147 | best_loss 8.621
2022-03-07 05:50:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11147 updates
2022-03-07 05:50:53 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-07 05:50:53 | INFO | train | epoch 229 | loss 2.017 | ppl 4.05 | wps 22078.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11147 | lr 0.000299517 | gnorm 0.544 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 33068
2022-03-07 05:50:53 | INFO | fairseq.trainer | begin training epoch 230
2022-03-07 05:50:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:53:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:53:17 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 11.34 | ppl 2591.92 | wps 39278.5 | wpb 510.9 | bsz 1 | num_updates 11196 | best_loss 8.621
2022-03-07 05:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11196 updates
2022-03-07 05:53:17 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-07 05:53:17 | INFO | train | epoch 230 | loss 2.014 | ppl 4.04 | wps 22085.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11196 | lr 0.000298861 | gnorm 0.528 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 33212
2022-03-07 05:53:17 | INFO | fairseq.trainer | begin training epoch 231
2022-03-07 05:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:53:29 | INFO | train_inner | epoch 231:      4 / 49 loss=2.015, ppl=4.04, wps=22099.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.535, loss_scale=32, train_wall=260, gb_free=21.5, wall=33224
2022-03-07 05:55:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:55:41 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 11.393 | ppl 2689.69 | wps 39179.5 | wpb 510.9 | bsz 1 | num_updates 11245 | best_loss 8.621
2022-03-07 05:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11245 updates
2022-03-07 05:55:41 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-07 05:55:41 | INFO | train | epoch 231 | loss 2.012 | ppl 4.03 | wps 22068.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11245 | lr 0.000298209 | gnorm 0.534 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 33356
2022-03-07 05:55:41 | INFO | fairseq.trainer | begin training epoch 232
2022-03-07 05:55:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:58:05 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 11.371 | ppl 2648.36 | wps 38997.9 | wpb 510.9 | bsz 1 | num_updates 11294 | best_loss 8.621
2022-03-07 05:58:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11294 updates
2022-03-07 05:58:05 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-07 05:58:05 | INFO | train | epoch 232 | loss 2.009 | ppl 4.02 | wps 22068 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11294 | lr 0.000297561 | gnorm 0.529 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 33500
2022-03-07 05:58:05 | INFO | fairseq.trainer | begin training epoch 233
2022-03-07 05:58:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:58:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:58:25 | INFO | train_inner | epoch 233:      7 / 49 loss=2.01, ppl=4.03, wps=21874, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.53, loss_scale=32, train_wall=262, gb_free=21.5, wall=33520
2022-03-07 06:00:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:00:29 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 11.388 | ppl 2680.87 | wps 39246.7 | wpb 510.9 | bsz 1 | num_updates 11342 | best_loss 8.621
2022-03-07 06:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11342 updates
2022-03-07 06:00:29 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-07 06:00:29 | INFO | train | epoch 233 | loss 2.006 | ppl 4.02 | wps 21629.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 11342 | lr 0.000296931 | gnorm 0.514 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 33644
2022-03-07 06:00:29 | INFO | fairseq.trainer | begin training epoch 234
2022-03-07 06:00:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:02:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:02:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:02:53 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 11.387 | ppl 2678.81 | wps 39300.5 | wpb 510.9 | bsz 1 | num_updates 11390 | best_loss 8.621
2022-03-07 06:02:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11390 updates
2022-03-07 06:02:53 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-07 06:02:53 | INFO | train | epoch 234 | loss 2.005 | ppl 4.01 | wps 21624.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 11390 | lr 0.000296304 | gnorm 0.527 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 33788
2022-03-07 06:02:53 | INFO | fairseq.trainer | begin training epoch 235
2022-03-07 06:02:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:03:21 | INFO | train_inner | epoch 235:     10 / 49 loss=2.005, ppl=4.01, wps=21887.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.521, loss_scale=16, train_wall=262, gb_free=21.5, wall=33817
2022-03-07 06:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:05:17 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 11.344 | ppl 2599.03 | wps 39217 | wpb 510.9 | bsz 1 | num_updates 11439 | best_loss 8.621
2022-03-07 06:05:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11439 updates
2022-03-07 06:05:17 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-07 06:05:17 | INFO | train | epoch 235 | loss 2.003 | ppl 4.01 | wps 22065.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11439 | lr 0.000295669 | gnorm 0.527 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 33932
2022-03-07 06:05:17 | INFO | fairseq.trainer | begin training epoch 236
2022-03-07 06:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:07:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:07:41 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 11.383 | ppl 2671.55 | wps 39165 | wpb 510.9 | bsz 1 | num_updates 11488 | best_loss 8.621
2022-03-07 06:07:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11488 updates
2022-03-07 06:07:41 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-07 06:07:41 | INFO | train | epoch 236 | loss 2.001 | ppl 4 | wps 22075.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11488 | lr 0.000295038 | gnorm 0.518 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 34076
2022-03-07 06:07:41 | INFO | fairseq.trainer | begin training epoch 237
2022-03-07 06:07:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:08:15 | INFO | train_inner | epoch 237:     12 / 49 loss=2.002, ppl=4, wps=22088.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.524, loss_scale=16, train_wall=260, gb_free=21.5, wall=34110
2022-03-07 06:09:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:09:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:10:05 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 11.402 | ppl 2706.03 | wps 39266 | wpb 510.9 | bsz 1 | num_updates 11536 | best_loss 8.621
2022-03-07 06:10:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11536 updates
2022-03-07 06:10:05 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-07 06:10:05 | INFO | train | epoch 237 | loss 1.999 | ppl 4 | wps 21621 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 11536 | lr 0.000294423 | gnorm 0.53 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 34220
2022-03-07 06:10:05 | INFO | fairseq.trainer | begin training epoch 238
2022-03-07 06:10:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:12:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:12:29 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 11.424 | ppl 2747.32 | wps 39101.8 | wpb 510.9 | bsz 1 | num_updates 11585 | best_loss 8.621
2022-03-07 06:12:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11585 updates
2022-03-07 06:12:29 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-07 06:12:29 | INFO | train | epoch 238 | loss 1.997 | ppl 3.99 | wps 22092.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11585 | lr 0.0002938 | gnorm 0.512 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 34364
2022-03-07 06:12:29 | INFO | fairseq.trainer | begin training epoch 239
2022-03-07 06:12:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:13:12 | INFO | train_inner | epoch 239:     15 / 49 loss=1.997, ppl=3.99, wps=21885.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.519, loss_scale=16, train_wall=262, gb_free=21.5, wall=34407
2022-03-07 06:14:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:14:53 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 11.343 | ppl 2597.36 | wps 39177.1 | wpb 510.9 | bsz 1 | num_updates 11634 | best_loss 8.621
2022-03-07 06:14:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11634 updates
2022-03-07 06:14:53 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-07 06:14:53 | INFO | train | epoch 239 | loss 1.995 | ppl 3.99 | wps 22059.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11634 | lr 0.000293181 | gnorm 0.524 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 34508
2022-03-07 06:14:53 | INFO | fairseq.trainer | begin training epoch 240
2022-03-07 06:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:17:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:17:17 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 11.375 | ppl 2655.39 | wps 39250.7 | wpb 510.9 | bsz 1 | num_updates 11683 | best_loss 8.621
2022-03-07 06:17:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11683 updates
2022-03-07 06:17:17 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-07 06:17:17 | INFO | train | epoch 240 | loss 1.993 | ppl 3.98 | wps 22058.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11683 | lr 0.000292565 | gnorm 0.508 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 34652
2022-03-07 06:17:17 | INFO | fairseq.trainer | begin training epoch 241
2022-03-07 06:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:18:05 | INFO | train_inner | epoch 241:     17 / 49 loss=1.994, ppl=3.98, wps=22079.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.514, loss_scale=32, train_wall=260, gb_free=21.5, wall=34701
2022-03-07 06:19:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:19:41 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 11.419 | ppl 2737.75 | wps 39016 | wpb 510.9 | bsz 1 | num_updates 11732 | best_loss 8.621
2022-03-07 06:19:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11732 updates
2022-03-07 06:19:41 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-07 06:19:41 | INFO | train | epoch 241 | loss 1.99 | ppl 3.97 | wps 22067.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11732 | lr 0.000291954 | gnorm 0.51 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 34796
2022-03-07 06:19:41 | INFO | fairseq.trainer | begin training epoch 242
2022-03-07 06:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:21:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:21:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:22:05 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 11.382 | ppl 2668.8 | wps 39122.5 | wpb 510.9 | bsz 1 | num_updates 11780 | best_loss 8.621
2022-03-07 06:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11780 updates
2022-03-07 06:22:05 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-07 06:22:05 | INFO | train | epoch 242 | loss 1.99 | ppl 3.97 | wps 21604.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 11780 | lr 0.000291358 | gnorm 0.52 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 34940
2022-03-07 06:22:05 | INFO | fairseq.trainer | begin training epoch 243
2022-03-07 06:22:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:23:02 | INFO | train_inner | epoch 243:     20 / 49 loss=1.99, ppl=3.97, wps=21868.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.515, loss_scale=32, train_wall=262, gb_free=21.5, wall=34997
2022-03-07 06:24:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:24:29 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 11.356 | ppl 2620.48 | wps 39059.5 | wpb 510.9 | bsz 1 | num_updates 11829 | best_loss 8.621
2022-03-07 06:24:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11829 updates
2022-03-07 06:24:29 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-07 06:24:29 | INFO | train | epoch 243 | loss 1.988 | ppl 3.97 | wps 22057.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11829 | lr 0.000290754 | gnorm 0.51 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 35084
2022-03-07 06:24:29 | INFO | fairseq.trainer | begin training epoch 244
2022-03-07 06:24:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:26:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:26:53 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 11.397 | ppl 2697.18 | wps 39303.7 | wpb 510.9 | bsz 1 | num_updates 11878 | best_loss 8.621
2022-03-07 06:26:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11878 updates
2022-03-07 06:26:53 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-07 06:26:53 | INFO | train | epoch 244 | loss 1.985 | ppl 3.96 | wps 22063.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11878 | lr 0.000290154 | gnorm 0.509 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 35228
2022-03-07 06:26:53 | INFO | fairseq.trainer | begin training epoch 245
2022-03-07 06:26:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:27:56 | INFO | train_inner | epoch 245:     22 / 49 loss=1.985, ppl=3.96, wps=22081.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.509, loss_scale=32, train_wall=260, gb_free=21.5, wall=35291
2022-03-07 06:28:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:29:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:29:17 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 11.37 | ppl 2646.99 | wps 38933.4 | wpb 510.9 | bsz 1 | num_updates 11926 | best_loss 8.621
2022-03-07 06:29:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11926 updates
2022-03-07 06:29:17 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-07 06:29:17 | INFO | train | epoch 245 | loss 1.984 | ppl 3.95 | wps 21607.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 11926 | lr 0.000289569 | gnorm 0.513 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 35372
2022-03-07 06:29:17 | INFO | fairseq.trainer | begin training epoch 246
2022-03-07 06:29:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:31:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:31:41 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 11.397 | ppl 2696.95 | wps 39095.4 | wpb 510.9 | bsz 1 | num_updates 11975 | best_loss 8.621
2022-03-07 06:31:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11975 updates
2022-03-07 06:31:41 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-07 06:31:41 | INFO | train | epoch 246 | loss 1.983 | ppl 3.95 | wps 22058.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11975 | lr 0.000288976 | gnorm 0.509 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 35516
2022-03-07 06:31:41 | INFO | fairseq.trainer | begin training epoch 247
2022-03-07 06:31:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:32:53 | INFO | train_inner | epoch 247:     25 / 49 loss=1.982, ppl=3.95, wps=21859.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.511, loss_scale=16, train_wall=263, gb_free=21.5, wall=35588
2022-03-07 06:34:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:34:05 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 11.358 | ppl 2624.61 | wps 39004.5 | wpb 510.9 | bsz 1 | num_updates 12024 | best_loss 8.621
2022-03-07 06:34:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12024 updates
2022-03-07 06:34:05 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-07 06:34:05 | INFO | train | epoch 247 | loss 1.98 | ppl 3.95 | wps 22048.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12024 | lr 0.000288387 | gnorm 0.509 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 35661
2022-03-07 06:34:05 | INFO | fairseq.trainer | begin training epoch 248
2022-03-07 06:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:36:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:36:29 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 11.371 | ppl 2648.14 | wps 39358.1 | wpb 510.9 | bsz 1 | num_updates 12073 | best_loss 8.621
2022-03-07 06:36:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12073 updates
2022-03-07 06:36:29 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-07 06:36:29 | INFO | train | epoch 248 | loss 1.978 | ppl 3.94 | wps 22075.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12073 | lr 0.000287801 | gnorm 0.505 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 35805
2022-03-07 06:36:29 | INFO | fairseq.trainer | begin training epoch 249
2022-03-07 06:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:37:46 | INFO | train_inner | epoch 249:     27 / 49 loss=1.978, ppl=3.94, wps=22088.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.507, loss_scale=32, train_wall=260, gb_free=21.5, wall=35881
2022-03-07 06:38:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:38:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:38:53 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 11.377 | ppl 2658.8 | wps 39121.7 | wpb 510.9 | bsz 1 | num_updates 12121 | best_loss 8.621
2022-03-07 06:38:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12121 updates
2022-03-07 06:38:53 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-07 06:38:53 | INFO | train | epoch 249 | loss 1.977 | ppl 3.94 | wps 21628.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 12121 | lr 0.000287231 | gnorm 0.512 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 35948
2022-03-07 06:38:53 | INFO | fairseq.trainer | begin training epoch 250
2022-03-07 06:38:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:41:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:41:17 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 11.364 | ppl 2636.36 | wps 39221.6 | wpb 510.9 | bsz 1 | num_updates 12170 | best_loss 8.621
2022-03-07 06:41:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12170 updates
2022-03-07 06:41:17 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-07 06:41:17 | INFO | train | epoch 250 | loss 1.975 | ppl 3.93 | wps 22073.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12170 | lr 0.000286652 | gnorm 0.503 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 36092
2022-03-07 06:41:17 | INFO | fairseq.trainer | begin training epoch 251
2022-03-07 06:41:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:42:43 | INFO | train_inner | epoch 251:     30 / 49 loss=1.974, ppl=3.93, wps=21885.5, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.503, loss_scale=16, train_wall=262, gb_free=21.5, wall=36178
2022-03-07 06:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:43:41 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 11.36 | ppl 2628.8 | wps 39218.5 | wpb 510.9 | bsz 1 | num_updates 12219 | best_loss 8.621
2022-03-07 06:43:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12219 updates
2022-03-07 06:43:41 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-07 06:43:41 | INFO | train | epoch 251 | loss 1.973 | ppl 3.92 | wps 22080.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12219 | lr 0.000286076 | gnorm 0.499 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 36236
2022-03-07 06:43:41 | INFO | fairseq.trainer | begin training epoch 252
2022-03-07 06:43:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:46:05 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 11.355 | ppl 2620.24 | wps 39045.5 | wpb 510.9 | bsz 1 | num_updates 12268 | best_loss 8.621
2022-03-07 06:46:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12268 updates
2022-03-07 06:46:05 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-07 06:46:05 | INFO | train | epoch 252 | loss 1.971 | ppl 3.92 | wps 22071.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12268 | lr 0.000285505 | gnorm 0.499 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 36380
2022-03-07 06:46:05 | INFO | fairseq.trainer | begin training epoch 253
2022-03-07 06:46:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:47:36 | INFO | train_inner | epoch 253:     32 / 49 loss=1.971, ppl=3.92, wps=22087, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.5, loss_scale=32, train_wall=260, gb_free=21.5, wall=36472
2022-03-07 06:48:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:48:29 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 11.31 | ppl 2539.4 | wps 39097 | wpb 510.9 | bsz 1 | num_updates 12317 | best_loss 8.621
2022-03-07 06:48:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12317 updates
2022-03-07 06:48:29 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-07 06:48:29 | INFO | train | epoch 253 | loss 1.971 | ppl 3.92 | wps 22056 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12317 | lr 0.000284936 | gnorm 0.504 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 36524
2022-03-07 06:48:29 | INFO | fairseq.trainer | begin training epoch 254
2022-03-07 06:48:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:50:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:50:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:50:53 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 11.361 | ppl 2630.29 | wps 39375.4 | wpb 510.9 | bsz 1 | num_updates 12365 | best_loss 8.621
2022-03-07 06:50:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12365 updates
2022-03-07 06:50:53 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-07 06:50:53 | INFO | train | epoch 254 | loss 1.967 | ppl 3.91 | wps 21612.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 12365 | lr 0.000284383 | gnorm 0.495 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 36668
2022-03-07 06:50:53 | INFO | fairseq.trainer | begin training epoch 255
2022-03-07 06:50:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:52:33 | INFO | train_inner | epoch 255:     35 / 49 loss=1.967, ppl=3.91, wps=21862.8, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.5, loss_scale=16, train_wall=262, gb_free=21.5, wall=36768
2022-03-07 06:53:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:53:17 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 11.372 | ppl 2650.68 | wps 39198.6 | wpb 510.9 | bsz 1 | num_updates 12414 | best_loss 8.621
2022-03-07 06:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12414 updates
2022-03-07 06:53:17 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-07 06:53:17 | INFO | train | epoch 255 | loss 1.966 | ppl 3.91 | wps 22061.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12414 | lr 0.000283821 | gnorm 0.505 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 36812
2022-03-07 06:53:17 | INFO | fairseq.trainer | begin training epoch 256
2022-03-07 06:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:55:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:55:41 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 11.366 | ppl 2638.66 | wps 39054.1 | wpb 510.9 | bsz 1 | num_updates 12463 | best_loss 8.621
2022-03-07 06:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12463 updates
2022-03-07 06:55:41 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-07 06:55:41 | INFO | train | epoch 256 | loss 1.965 | ppl 3.9 | wps 22058.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12463 | lr 0.000283262 | gnorm 0.499 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 36957
2022-03-07 06:55:41 | INFO | fairseq.trainer | begin training epoch 257
2022-03-07 06:55:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:57:27 | INFO | train_inner | epoch 257:     37 / 49 loss=1.965, ppl=3.9, wps=22079.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.5, loss_scale=32, train_wall=260, gb_free=21.5, wall=37062
2022-03-07 06:58:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:58:05 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 11.342 | ppl 2595.13 | wps 39319 | wpb 510.9 | bsz 1 | num_updates 12512 | best_loss 8.621
2022-03-07 06:58:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12512 updates
2022-03-07 06:58:05 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-07 06:58:05 | INFO | train | epoch 257 | loss 1.963 | ppl 3.9 | wps 22062.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12512 | lr 0.000282707 | gnorm 0.497 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 37101
2022-03-07 06:58:05 | INFO | fairseq.trainer | begin training epoch 258
2022-03-07 06:58:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:58:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:00:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:00:29 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 11.366 | ppl 2638.67 | wps 39241.7 | wpb 510.9 | bsz 1 | num_updates 12560 | best_loss 8.621
2022-03-07 07:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12560 updates
2022-03-07 07:00:29 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-07 07:00:29 | INFO | train | epoch 258 | loss 1.962 | ppl 3.9 | wps 21607.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 12560 | lr 0.000282166 | gnorm 0.506 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 37245
2022-03-07 07:00:29 | INFO | fairseq.trainer | begin training epoch 259
2022-03-07 07:00:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:02:23 | INFO | train_inner | epoch 259:     40 / 49 loss=1.962, ppl=3.9, wps=21873.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.502, loss_scale=16, train_wall=262, gb_free=21.5, wall=37359
2022-03-07 07:02:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:02:53 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 11.353 | ppl 2616.28 | wps 39227.8 | wpb 510.9 | bsz 1 | num_updates 12609 | best_loss 8.621
2022-03-07 07:02:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12609 updates
2022-03-07 07:02:53 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-07 07:02:53 | INFO | train | epoch 259 | loss 1.96 | ppl 3.89 | wps 22073.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12609 | lr 0.000281618 | gnorm 0.5 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 37389
2022-03-07 07:02:53 | INFO | fairseq.trainer | begin training epoch 260
2022-03-07 07:02:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:05:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:05:18 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 11.354 | ppl 2617.83 | wps 39106.3 | wpb 510.9 | bsz 1 | num_updates 12658 | best_loss 8.621
2022-03-07 07:05:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12658 updates
2022-03-07 07:05:18 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-07 07:05:18 | INFO | train | epoch 260 | loss 1.958 | ppl 3.89 | wps 22046.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12658 | lr 0.000281072 | gnorm 0.493 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 37533
2022-03-07 07:05:18 | INFO | fairseq.trainer | begin training epoch 261
2022-03-07 07:05:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:06:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:07:20 | INFO | train_inner | epoch 261:     43 / 49 loss=1.958, ppl=3.89, wps=21861.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=12700, lr=0.000280607, gnorm=0.495, loss_scale=16, train_wall=263, gb_free=21.5, wall=37655
2022-03-07 07:07:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:07:42 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 11.334 | ppl 2580.96 | wps 39130.7 | wpb 510.9 | bsz 1 | num_updates 12706 | best_loss 8.621
2022-03-07 07:07:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12706 updates
2022-03-07 07:07:42 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-07 07:07:42 | INFO | train | epoch 261 | loss 1.957 | ppl 3.88 | wps 21609.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 12706 | lr 0.000280541 | gnorm 0.5 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 37677
2022-03-07 07:07:42 | INFO | fairseq.trainer | begin training epoch 262
2022-03-07 07:07:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:10:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:10:05 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 11.374 | ppl 2654.45 | wps 39302.5 | wpb 510.9 | bsz 1 | num_updates 12755 | best_loss 8.621
2022-03-07 07:10:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12755 updates
2022-03-07 07:10:05 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-07 07:10:05 | INFO | train | epoch 262 | loss 1.955 | ppl 3.88 | wps 22081.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12755 | lr 0.000280001 | gnorm 0.494 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 37821
2022-03-07 07:10:06 | INFO | fairseq.trainer | begin training epoch 263
2022-03-07 07:10:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:12:14 | INFO | train_inner | epoch 263:     45 / 49 loss=1.955, ppl=3.88, wps=22089.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=12800, lr=0.000279508, gnorm=0.498, loss_scale=16, train_wall=260, gb_free=21.5, wall=37949
2022-03-07 07:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:12:30 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 11.349 | ppl 2607.91 | wps 39183 | wpb 510.9 | bsz 1 | num_updates 12804 | best_loss 8.621
2022-03-07 07:12:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12804 updates
2022-03-07 07:12:30 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-07 07:12:30 | INFO | train | epoch 263 | loss 1.954 | ppl 3.88 | wps 22059.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12804 | lr 0.000279465 | gnorm 0.501 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 37965
2022-03-07 07:12:30 | INFO | fairseq.trainer | begin training epoch 264
2022-03-07 07:12:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:12:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:14:54 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 11.329 | ppl 2572.14 | wps 38777.7 | wpb 510.9 | bsz 1 | num_updates 12852 | best_loss 8.621
2022-03-07 07:14:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12852 updates
2022-03-07 07:14:54 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-07 07:14:54 | INFO | train | epoch 264 | loss 1.951 | ppl 3.87 | wps 21610 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 12852 | lr 0.000278942 | gnorm 0.481 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 38109
2022-03-07 07:14:54 | INFO | fairseq.trainer | begin training epoch 265
2022-03-07 07:14:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:17:11 | INFO | train_inner | epoch 265:     48 / 49 loss=1.951, ppl=3.87, wps=21868.9, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=12900, lr=0.000278423, gnorm=0.484, loss_scale=16, train_wall=262, gb_free=21.5, wall=38246
2022-03-07 07:17:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:17:18 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 11.351 | ppl 2612.46 | wps 39113.3 | wpb 510.9 | bsz 1 | num_updates 12901 | best_loss 8.621
2022-03-07 07:17:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12901 updates
2022-03-07 07:17:18 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-07 07:17:18 | INFO | train | epoch 265 | loss 1.951 | ppl 3.87 | wps 22065.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12901 | lr 0.000278412 | gnorm 0.485 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 38253
2022-03-07 07:17:18 | INFO | fairseq.trainer | begin training epoch 266
2022-03-07 07:17:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:19:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:19:42 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 11.367 | ppl 2640.96 | wps 39146.7 | wpb 510.9 | bsz 1 | num_updates 12950 | best_loss 8.621
2022-03-07 07:19:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12950 updates
2022-03-07 07:19:42 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-07 07:19:42 | INFO | train | epoch 266 | loss 1.949 | ppl 3.86 | wps 22059 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12950 | lr 0.000277885 | gnorm 0.484 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 38397
2022-03-07 07:19:42 | INFO | fairseq.trainer | begin training epoch 267
2022-03-07 07:19:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:22:06 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 11.336 | ppl 2584.27 | wps 39175.8 | wpb 510.9 | bsz 1 | num_updates 12999 | best_loss 8.621
2022-03-07 07:22:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12999 updates
2022-03-07 07:22:06 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-07 07:22:06 | INFO | train | epoch 267 | loss 1.948 | ppl 3.86 | wps 22059.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12999 | lr 0.000277361 | gnorm 0.485 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 38541
2022-03-07 07:22:06 | INFO | fairseq.trainer | begin training epoch 268
2022-03-07 07:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:22:09 | INFO | train_inner | epoch 268:      1 / 49 loss=1.948, ppl=3.86, wps=21647.8, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=13000, lr=0.00027735, gnorm=0.486, loss_scale=32, train_wall=259, gb_free=21.5, wall=38544
2022-03-07 07:23:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:24:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:24:30 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 11.354 | ppl 2617.3 | wps 39175.9 | wpb 510.9 | bsz 1 | num_updates 13047 | best_loss 8.621
2022-03-07 07:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13047 updates
2022-03-07 07:24:30 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-07 07:24:30 | INFO | train | epoch 268 | loss 1.945 | ppl 3.85 | wps 21629.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 13047 | lr 0.00027685 | gnorm 0.489 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 38685
2022-03-07 07:24:30 | INFO | fairseq.trainer | begin training epoch 269
2022-03-07 07:24:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:26:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:26:54 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 11.327 | ppl 2568.97 | wps 39200.4 | wpb 510.9 | bsz 1 | num_updates 13096 | best_loss 8.621
2022-03-07 07:26:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13096 updates
2022-03-07 07:26:54 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-07 07:26:54 | INFO | train | epoch 269 | loss 1.944 | ppl 3.85 | wps 22058.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13096 | lr 0.000276332 | gnorm 0.49 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 38829
2022-03-07 07:26:54 | INFO | fairseq.trainer | begin training epoch 270
2022-03-07 07:26:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:27:05 | INFO | train_inner | epoch 270:      4 / 49 loss=1.944, ppl=3.85, wps=21876.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.488, loss_scale=16, train_wall=262, gb_free=21.5, wall=38840
2022-03-07 07:29:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:29:18 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 11.327 | ppl 2569.38 | wps 39127.4 | wpb 510.9 | bsz 1 | num_updates 13145 | best_loss 8.621
2022-03-07 07:29:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13145 updates
2022-03-07 07:29:18 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-07 07:29:18 | INFO | train | epoch 270 | loss 1.943 | ppl 3.84 | wps 22079.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13145 | lr 0.000275816 | gnorm 0.492 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 38973
2022-03-07 07:29:18 | INFO | fairseq.trainer | begin training epoch 271
2022-03-07 07:29:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:31:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:31:42 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 11.388 | ppl 2679.5 | wps 39184.2 | wpb 510.9 | bsz 1 | num_updates 13194 | best_loss 8.621
2022-03-07 07:31:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13194 updates
2022-03-07 07:31:42 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-07 07:31:42 | INFO | train | epoch 271 | loss 1.942 | ppl 3.84 | wps 22069.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13194 | lr 0.000275304 | gnorm 0.499 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 39117
2022-03-07 07:31:42 | INFO | fairseq.trainer | begin training epoch 272
2022-03-07 07:31:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:31:59 | INFO | train_inner | epoch 272:      6 / 49 loss=1.942, ppl=3.84, wps=22094.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.495, loss_scale=32, train_wall=260, gb_free=21.5, wall=39134
2022-03-07 07:34:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:34:06 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 11.324 | ppl 2562.85 | wps 39232.3 | wpb 510.9 | bsz 1 | num_updates 13243 | best_loss 8.621
2022-03-07 07:34:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13243 updates
2022-03-07 07:34:06 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-07 07:34:06 | INFO | train | epoch 272 | loss 1.939 | ppl 3.83 | wps 22079.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13243 | lr 0.000274794 | gnorm 0.472 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 39261
2022-03-07 07:34:06 | INFO | fairseq.trainer | begin training epoch 273
2022-03-07 07:34:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:35:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:36:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:36:30 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 11.302 | ppl 2525.65 | wps 39139.4 | wpb 510.9 | bsz 1 | num_updates 13291 | best_loss 8.621
2022-03-07 07:36:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13291 updates
2022-03-07 07:36:30 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-07 07:36:30 | INFO | train | epoch 273 | loss 1.938 | ppl 3.83 | wps 21600 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 13291 | lr 0.000274297 | gnorm 0.476 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 39405
2022-03-07 07:36:30 | INFO | fairseq.trainer | begin training epoch 274
2022-03-07 07:36:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:36:55 | INFO | train_inner | epoch 274:      9 / 49 loss=1.938, ppl=3.83, wps=21872.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.477, loss_scale=32, train_wall=262, gb_free=21.5, wall=39431
2022-03-07 07:38:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:38:54 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 11.334 | ppl 2581.74 | wps 39226.2 | wpb 510.9 | bsz 1 | num_updates 13340 | best_loss 8.621
2022-03-07 07:38:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13340 updates
2022-03-07 07:38:54 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-07 07:38:54 | INFO | train | epoch 274 | loss 1.938 | ppl 3.83 | wps 22073.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13340 | lr 0.000273793 | gnorm 0.486 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 39549
2022-03-07 07:38:54 | INFO | fairseq.trainer | begin training epoch 275
2022-03-07 07:38:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:41:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:41:18 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 11.341 | ppl 2593.48 | wps 39158.1 | wpb 510.9 | bsz 1 | num_updates 13389 | best_loss 8.621
2022-03-07 07:41:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13389 updates
2022-03-07 07:41:18 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-07 07:41:18 | INFO | train | epoch 275 | loss 1.935 | ppl 3.83 | wps 22069.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13389 | lr 0.000273291 | gnorm 0.482 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 39693
2022-03-07 07:41:18 | INFO | fairseq.trainer | begin training epoch 276
2022-03-07 07:41:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:41:49 | INFO | train_inner | epoch 276:     11 / 49 loss=1.936, ppl=3.83, wps=22090.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.482, loss_scale=32, train_wall=260, gb_free=21.5, wall=39724
2022-03-07 07:42:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:43:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:43:42 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 11.323 | ppl 2561.87 | wps 39240.1 | wpb 510.9 | bsz 1 | num_updates 13437 | best_loss 8.621
2022-03-07 07:43:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13437 updates
2022-03-07 07:43:42 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-07 07:43:42 | INFO | train | epoch 276 | loss 1.935 | ppl 3.82 | wps 21620.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 13437 | lr 0.000272803 | gnorm 0.477 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 39837
2022-03-07 07:43:42 | INFO | fairseq.trainer | begin training epoch 277
2022-03-07 07:43:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:43:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:46:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:46:06 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 11.305 | ppl 2529.85 | wps 39153.4 | wpb 510.9 | bsz 1 | num_updates 13485 | best_loss 8.621
2022-03-07 07:46:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13485 updates
2022-03-07 07:46:06 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-07 07:46:06 | INFO | train | epoch 277 | loss 1.933 | ppl 3.82 | wps 21610.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 13485 | lr 0.000272317 | gnorm 0.475 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 39981
2022-03-07 07:46:06 | INFO | fairseq.trainer | begin training epoch 278
2022-03-07 07:46:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:46:48 | INFO | train_inner | epoch 278:     15 / 49 loss=1.933, ppl=3.82, wps=21668.8, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.473, loss_scale=16, train_wall=265, gb_free=21.5, wall=40024
2022-03-07 07:48:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:48:30 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 11.338 | ppl 2588.4 | wps 39099.9 | wpb 510.9 | bsz 1 | num_updates 13534 | best_loss 8.621
2022-03-07 07:48:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13534 updates
2022-03-07 07:48:30 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-07 07:48:30 | INFO | train | epoch 278 | loss 1.931 | ppl 3.81 | wps 22077 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13534 | lr 0.000271823 | gnorm 0.471 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 40125
2022-03-07 07:48:30 | INFO | fairseq.trainer | begin training epoch 279
2022-03-07 07:48:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:50:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:50:54 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 11.359 | ppl 2626.97 | wps 39270 | wpb 510.9 | bsz 1 | num_updates 13583 | best_loss 8.621
2022-03-07 07:50:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13583 updates
2022-03-07 07:50:54 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-07 07:50:54 | INFO | train | epoch 279 | loss 1.931 | ppl 3.81 | wps 22061.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13583 | lr 0.000271333 | gnorm 0.479 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 40269
2022-03-07 07:50:54 | INFO | fairseq.trainer | begin training epoch 280
2022-03-07 07:50:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:51:42 | INFO | train_inner | epoch 280:     17 / 49 loss=1.931, ppl=3.81, wps=22088.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.477, loss_scale=32, train_wall=260, gb_free=21.5, wall=40317
2022-03-07 07:53:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:53:18 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 11.335 | ppl 2582.45 | wps 39148.4 | wpb 510.9 | bsz 1 | num_updates 13632 | best_loss 8.621
2022-03-07 07:53:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13632 updates
2022-03-07 07:53:18 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-07 07:53:18 | INFO | train | epoch 280 | loss 1.929 | ppl 3.81 | wps 22066.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13632 | lr 0.000270845 | gnorm 0.468 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 40413
2022-03-07 07:53:18 | INFO | fairseq.trainer | begin training epoch 281
2022-03-07 07:53:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:54:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:55:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:55:42 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 11.338 | ppl 2588.97 | wps 39062.9 | wpb 510.9 | bsz 1 | num_updates 13680 | best_loss 8.621
2022-03-07 07:55:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13680 updates
2022-03-07 07:55:42 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-07 07:55:42 | INFO | train | epoch 281 | loss 1.928 | ppl 3.81 | wps 21598 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 13680 | lr 0.000270369 | gnorm 0.473 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 40557
2022-03-07 07:55:42 | INFO | fairseq.trainer | begin training epoch 282
2022-03-07 07:55:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:56:39 | INFO | train_inner | epoch 282:     20 / 49 loss=1.928, ppl=3.81, wps=21860, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.473, loss_scale=16, train_wall=263, gb_free=21.5, wall=40614
2022-03-07 07:58:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:58:06 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 11.341 | ppl 2594.34 | wps 39191.8 | wpb 510.9 | bsz 1 | num_updates 13729 | best_loss 8.621
2022-03-07 07:58:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13729 updates
2022-03-07 07:58:06 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-07 07:58:06 | INFO | train | epoch 282 | loss 1.928 | ppl 3.8 | wps 22052.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13729 | lr 0.000269886 | gnorm 0.483 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 40701
2022-03-07 07:58:06 | INFO | fairseq.trainer | begin training epoch 283
2022-03-07 07:58:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:00:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:00:30 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 11.322 | ppl 2559.52 | wps 39024.1 | wpb 510.9 | bsz 1 | num_updates 13778 | best_loss 8.621
2022-03-07 08:00:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13778 updates
2022-03-07 08:00:30 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-07 08:00:30 | INFO | train | epoch 283 | loss 1.926 | ppl 3.8 | wps 22054.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13778 | lr 0.000269406 | gnorm 0.475 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 40845
2022-03-07 08:00:30 | INFO | fairseq.trainer | begin training epoch 284
2022-03-07 08:00:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:01:33 | INFO | train_inner | epoch 284:     22 / 49 loss=1.926, ppl=3.8, wps=22067.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.477, loss_scale=32, train_wall=260, gb_free=21.5, wall=40908
2022-03-07 08:02:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:02:54 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 11.333 | ppl 2580.23 | wps 39198.7 | wpb 510.9 | bsz 1 | num_updates 13827 | best_loss 8.621
2022-03-07 08:02:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13827 updates
2022-03-07 08:02:54 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-07 08:02:54 | INFO | train | epoch 284 | loss 1.924 | ppl 3.79 | wps 22051.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13827 | lr 0.000268928 | gnorm 0.474 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 40989
2022-03-07 08:02:54 | INFO | fairseq.trainer | begin training epoch 285
2022-03-07 08:02:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:03:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:05:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:05:18 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 11.309 | ppl 2537.39 | wps 39051.3 | wpb 510.9 | bsz 1 | num_updates 13875 | best_loss 8.621
2022-03-07 08:05:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13875 updates
2022-03-07 08:05:18 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-07 08:05:18 | INFO | train | epoch 285 | loss 1.922 | ppl 3.79 | wps 21593.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 13875 | lr 0.000268462 | gnorm 0.476 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 41134
2022-03-07 08:05:18 | INFO | fairseq.trainer | begin training epoch 286
2022-03-07 08:05:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:06:30 | INFO | train_inner | epoch 286:     25 / 49 loss=1.922, ppl=3.79, wps=21859.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.473, loss_scale=16, train_wall=262, gb_free=21.5, wall=41205
2022-03-07 08:07:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:07:42 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 11.322 | ppl 2560.54 | wps 39127.3 | wpb 510.9 | bsz 1 | num_updates 13924 | best_loss 8.621
2022-03-07 08:07:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13924 updates
2022-03-07 08:07:42 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-07 08:07:42 | INFO | train | epoch 286 | loss 1.921 | ppl 3.79 | wps 22073.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13924 | lr 0.00026799 | gnorm 0.468 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 41278
2022-03-07 08:07:42 | INFO | fairseq.trainer | begin training epoch 287
2022-03-07 08:07:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:10:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:10:06 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 11.354 | ppl 2617.52 | wps 39010.5 | wpb 510.9 | bsz 1 | num_updates 13973 | best_loss 8.621
2022-03-07 08:10:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13973 updates
2022-03-07 08:10:06 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-07 08:10:06 | INFO | train | epoch 287 | loss 1.921 | ppl 3.79 | wps 22053 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13973 | lr 0.000267519 | gnorm 0.476 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 41422
2022-03-07 08:10:06 | INFO | fairseq.trainer | begin training epoch 288
2022-03-07 08:10:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:10:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:11:26 | INFO | train_inner | epoch 288:     28 / 49 loss=1.921, ppl=3.79, wps=21868.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.471, loss_scale=16, train_wall=262, gb_free=21.5, wall=41502
2022-03-07 08:12:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:12:30 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 11.337 | ppl 2587.03 | wps 39267.1 | wpb 510.9 | bsz 1 | num_updates 14021 | best_loss 8.621
2022-03-07 08:12:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14021 updates
2022-03-07 08:12:30 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-07 08:12:30 | INFO | train | epoch 288 | loss 1.918 | ppl 3.78 | wps 21603.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 14021 | lr 0.000267061 | gnorm 0.466 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 41566
2022-03-07 08:12:30 | INFO | fairseq.trainer | begin training epoch 289
2022-03-07 08:12:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:14:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:14:55 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 11.305 | ppl 2530.62 | wps 39282.4 | wpb 510.9 | bsz 1 | num_updates 14070 | best_loss 8.621
2022-03-07 08:14:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14070 updates
2022-03-07 08:14:55 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-07 08:14:55 | INFO | train | epoch 289 | loss 1.919 | ppl 3.78 | wps 22058.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14070 | lr 0.000266596 | gnorm 0.48 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 41710
2022-03-07 08:14:55 | INFO | fairseq.trainer | begin training epoch 290
2022-03-07 08:14:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:16:20 | INFO | train_inner | epoch 290:     30 / 49 loss=1.918, ppl=3.78, wps=22078.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.471, loss_scale=16, train_wall=260, gb_free=21.5, wall=41795
2022-03-07 08:17:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:17:19 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 11.34 | ppl 2592.64 | wps 39234.8 | wpb 510.9 | bsz 1 | num_updates 14119 | best_loss 8.621
2022-03-07 08:17:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14119 updates
2022-03-07 08:17:19 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-07 08:17:19 | INFO | train | epoch 290 | loss 1.916 | ppl 3.78 | wps 22065.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14119 | lr 0.000266133 | gnorm 0.469 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 41854
2022-03-07 08:17:19 | INFO | fairseq.trainer | begin training epoch 291
2022-03-07 08:17:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:19:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:19:43 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 11.342 | ppl 2595.31 | wps 39399.5 | wpb 510.9 | bsz 1 | num_updates 14168 | best_loss 8.621
2022-03-07 08:19:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14168 updates
2022-03-07 08:19:43 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-07 08:19:43 | INFO | train | epoch 291 | loss 1.916 | ppl 3.77 | wps 22073.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14168 | lr 0.000265672 | gnorm 0.468 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 41998
2022-03-07 08:19:43 | INFO | fairseq.trainer | begin training epoch 292
2022-03-07 08:19:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:20:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:21:17 | INFO | train_inner | epoch 292:     33 / 49 loss=1.916, ppl=3.77, wps=21872.1, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.468, loss_scale=16, train_wall=263, gb_free=21.5, wall=42092
2022-03-07 08:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:22:07 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 11.331 | ppl 2576.58 | wps 39191.2 | wpb 510.9 | bsz 1 | num_updates 14216 | best_loss 8.621
2022-03-07 08:22:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14216 updates
2022-03-07 08:22:07 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-07 08:22:07 | INFO | train | epoch 292 | loss 1.914 | ppl 3.77 | wps 21599.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 14216 | lr 0.000265223 | gnorm 0.461 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 42142
2022-03-07 08:22:07 | INFO | fairseq.trainer | begin training epoch 293
2022-03-07 08:22:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:24:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:24:31 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 11.324 | ppl 2563.42 | wps 39255 | wpb 510.9 | bsz 1 | num_updates 14265 | best_loss 8.621
2022-03-07 08:24:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14265 updates
2022-03-07 08:24:31 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-07 08:24:31 | INFO | train | epoch 293 | loss 1.913 | ppl 3.77 | wps 22070.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14265 | lr 0.000264767 | gnorm 0.466 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 42286
2022-03-07 08:24:31 | INFO | fairseq.trainer | begin training epoch 294
2022-03-07 08:24:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:26:10 | INFO | train_inner | epoch 294:     35 / 49 loss=1.913, ppl=3.77, wps=22087.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.465, loss_scale=16, train_wall=260, gb_free=21.5, wall=42386
2022-03-07 08:26:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:26:55 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 11.308 | ppl 2534.74 | wps 39153.7 | wpb 510.9 | bsz 1 | num_updates 14314 | best_loss 8.621
2022-03-07 08:26:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14314 updates
2022-03-07 08:26:55 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-07 08:26:55 | INFO | train | epoch 294 | loss 1.913 | ppl 3.77 | wps 22076.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14314 | lr 0.000264314 | gnorm 0.467 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 42430
2022-03-07 08:26:55 | INFO | fairseq.trainer | begin training epoch 295
2022-03-07 08:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:29:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:29:19 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 11.295 | ppl 2513.15 | wps 39181.6 | wpb 510.9 | bsz 1 | num_updates 14363 | best_loss 8.621
2022-03-07 08:29:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14363 updates
2022-03-07 08:29:19 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 08:29:19 | INFO | train | epoch 295 | loss 1.912 | ppl 3.76 | wps 22038.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14363 | lr 0.000263862 | gnorm 0.468 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 42574
2022-03-07 08:29:19 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 08:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:30:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:31:07 | INFO | train_inner | epoch 296:     38 / 49 loss=1.911, ppl=3.76, wps=21860, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.464, loss_scale=16, train_wall=263, gb_free=21.5, wall=42682
2022-03-07 08:31:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:31:43 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 11.315 | ppl 2547.31 | wps 38994.7 | wpb 510.9 | bsz 1 | num_updates 14411 | best_loss 8.621
2022-03-07 08:31:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14411 updates
2022-03-07 08:31:43 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 08:31:43 | INFO | train | epoch 296 | loss 1.909 | ppl 3.76 | wps 21607.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 14411 | lr 0.000263423 | gnorm 0.462 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 42718
2022-03-07 08:31:43 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 08:31:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:34:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:34:07 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 11.321 | ppl 2558.34 | wps 39367.7 | wpb 510.9 | bsz 1 | num_updates 14460 | best_loss 8.621
2022-03-07 08:34:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14460 updates
2022-03-07 08:34:07 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 08:34:07 | INFO | train | epoch 297 | loss 1.909 | ppl 3.76 | wps 22063.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14460 | lr 0.000262976 | gnorm 0.463 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 42862
2022-03-07 08:34:07 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 08:34:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:36:01 | INFO | train_inner | epoch 298:     40 / 49 loss=1.909, ppl=3.75, wps=22079.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14500, lr=0.000262613, gnorm=0.466, loss_scale=16, train_wall=260, gb_free=21.5, wall=42976
2022-03-07 08:36:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:36:31 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 11.298 | ppl 2517.25 | wps 39250.4 | wpb 510.9 | bsz 1 | num_updates 14509 | best_loss 8.621
2022-03-07 08:36:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14509 updates
2022-03-07 08:36:31 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 08:36:31 | INFO | train | epoch 298 | loss 1.908 | ppl 3.75 | wps 22066.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14509 | lr 0.000262531 | gnorm 0.466 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 43006
2022-03-07 08:36:31 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 08:36:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:38:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:38:55 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 11.295 | ppl 2512.56 | wps 39390.7 | wpb 510.9 | bsz 1 | num_updates 14558 | best_loss 8.621
2022-03-07 08:38:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14558 updates
2022-03-07 08:38:55 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 08:38:55 | INFO | train | epoch 299 | loss 1.906 | ppl 3.75 | wps 22068.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14558 | lr 0.000262089 | gnorm 0.454 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 43150
2022-03-07 08:38:55 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 08:38:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:40:55 | INFO | train_inner | epoch 300:     42 / 49 loss=1.906, ppl=3.75, wps=22084.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14600, lr=0.000261712, gnorm=0.457, loss_scale=32, train_wall=260, gb_free=21.5, wall=43270
2022-03-07 08:41:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:41:19 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 11.315 | ppl 2548.24 | wps 39056.8 | wpb 510.9 | bsz 1 | num_updates 14607 | best_loss 8.621
2022-03-07 08:41:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14607 updates
2022-03-07 08:41:19 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 08:41:19 | INFO | train | epoch 300 | loss 1.905 | ppl 3.74 | wps 22056.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14607 | lr 0.000261649 | gnorm 0.461 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 43294
2022-03-07 08:41:19 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 08:41:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:41:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:43:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:43:43 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 11.332 | ppl 2578.65 | wps 39271 | wpb 510.9 | bsz 1 | num_updates 14655 | best_loss 8.621
2022-03-07 08:43:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14655 updates
2022-03-07 08:43:43 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 08:43:43 | INFO | train | epoch 301 | loss 1.904 | ppl 3.74 | wps 21622.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 14655 | lr 0.00026122 | gnorm 0.468 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 43438
2022-03-07 08:43:43 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 08:43:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:45:51 | INFO | train_inner | epoch 302:     45 / 49 loss=1.904, ppl=3.74, wps=21873.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14700, lr=0.00026082, gnorm=0.459, loss_scale=16, train_wall=262, gb_free=21.5, wall=43567
2022-03-07 08:46:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:46:07 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 11.326 | ppl 2567 | wps 39109.5 | wpb 510.9 | bsz 1 | num_updates 14704 | best_loss 8.621
2022-03-07 08:46:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14704 updates
2022-03-07 08:46:07 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 08:46:07 | INFO | train | epoch 302 | loss 1.903 | ppl 3.74 | wps 22068.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14704 | lr 0.000260785 | gnorm 0.45 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 43582
2022-03-07 08:46:07 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 08:46:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:48:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:48:31 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 11.346 | ppl 2602.93 | wps 39018.2 | wpb 510.9 | bsz 1 | num_updates 14753 | best_loss 8.621
2022-03-07 08:48:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14753 updates
2022-03-07 08:48:31 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 08:48:31 | INFO | train | epoch 303 | loss 1.902 | ppl 3.74 | wps 22057.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14753 | lr 0.000260351 | gnorm 0.457 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 43726
2022-03-07 08:48:31 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 08:48:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:50:45 | INFO | train_inner | epoch 304:     47 / 49 loss=1.902, ppl=3.74, wps=22086.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.455, loss_scale=32, train_wall=260, gb_free=21.5, wall=43860
2022-03-07 08:50:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:50:55 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 11.294 | ppl 2510.99 | wps 39650.8 | wpb 510.9 | bsz 1 | num_updates 14802 | best_loss 8.621
2022-03-07 08:50:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14802 updates
2022-03-07 08:50:55 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 08:50:55 | INFO | train | epoch 304 | loss 1.901 | ppl 3.73 | wps 22089.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14802 | lr 0.00025992 | gnorm 0.454 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 43870
2022-03-07 08:50:55 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 08:50:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:53:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:53:19 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 11.312 | ppl 2542.67 | wps 39122.9 | wpb 510.9 | bsz 1 | num_updates 14851 | best_loss 8.621
2022-03-07 08:53:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14851 updates
2022-03-07 08:53:19 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 08:53:19 | INFO | train | epoch 305 | loss 1.901 | ppl 3.73 | wps 22057.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14851 | lr 0.000259491 | gnorm 0.458 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 44014
2022-03-07 08:53:19 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 08:53:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:54:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:55:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:55:43 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 11.316 | ppl 2548.87 | wps 39165.9 | wpb 510.9 | bsz 1 | num_updates 14899 | best_loss 8.621
2022-03-07 08:55:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14899 updates
2022-03-07 08:55:43 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 08:55:43 | INFO | train | epoch 306 | loss 1.899 | ppl 3.73 | wps 21614.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 14899 | lr 0.000259073 | gnorm 0.454 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 44158
2022-03-07 08:55:43 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 08:55:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:55:46 | INFO | train_inner | epoch 307:      1 / 49 loss=1.9, ppl=3.73, wps=21452.8, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=14900, lr=0.000259064, gnorm=0.458, loss_scale=32, train_wall=261, gb_free=21.5, wall=44161
2022-03-07 08:58:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:58:07 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 11.317 | ppl 2551.56 | wps 39128 | wpb 510.9 | bsz 1 | num_updates 14948 | best_loss 8.621
2022-03-07 08:58:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14948 updates
2022-03-07 08:58:07 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 08:58:07 | INFO | train | epoch 307 | loss 1.898 | ppl 3.73 | wps 22062.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14948 | lr 0.000258648 | gnorm 0.46 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 44302
2022-03-07 08:58:07 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 08:58:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:58:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:00:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:00:31 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 11.287 | ppl 2498.92 | wps 39057.9 | wpb 510.9 | bsz 1 | num_updates 14996 | best_loss 8.621
2022-03-07 09:00:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14996 updates
2022-03-07 09:00:31 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 09:00:31 | INFO | train | epoch 308 | loss 1.896 | ppl 3.72 | wps 21619.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 14996 | lr 0.000258233 | gnorm 0.455 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 44446
2022-03-07 09:00:31 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 09:00:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:00:42 | INFO | train_inner | epoch 309:      4 / 49 loss=1.897, ppl=3.72, wps=21874.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.457, loss_scale=16, train_wall=262, gb_free=21.5, wall=44458
2022-03-07 09:02:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:02:55 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 11.305 | ppl 2529.87 | wps 39153.6 | wpb 510.9 | bsz 1 | num_updates 15045 | best_loss 8.621
2022-03-07 09:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15045 updates
2022-03-07 09:02:55 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 09:02:55 | INFO | train | epoch 309 | loss 1.895 | ppl 3.72 | wps 22061.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15045 | lr 0.000257812 | gnorm 0.454 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 44590
2022-03-07 09:02:55 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 09:02:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:05:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:05:19 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 11.331 | ppl 2575.74 | wps 39236.9 | wpb 510.9 | bsz 1 | num_updates 15094 | best_loss 8.621
2022-03-07 09:05:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15094 updates
2022-03-07 09:05:19 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 09:05:19 | INFO | train | epoch 310 | loss 1.894 | ppl 3.72 | wps 22060.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15094 | lr 0.000257394 | gnorm 0.447 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 44734
2022-03-07 09:05:19 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 09:05:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:05:36 | INFO | train_inner | epoch 311:      6 / 49 loss=1.895, ppl=3.72, wps=22078.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.451, loss_scale=32, train_wall=260, gb_free=21.5, wall=44752
2022-03-07 09:07:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:07:43 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 11.319 | ppl 2554.27 | wps 39224.3 | wpb 510.9 | bsz 1 | num_updates 15143 | best_loss 8.621
2022-03-07 09:07:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15143 updates
2022-03-07 09:07:43 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 09:07:43 | INFO | train | epoch 311 | loss 1.894 | ppl 3.72 | wps 22062.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15143 | lr 0.000256977 | gnorm 0.45 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 44878
2022-03-07 09:07:43 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 09:07:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:10:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:10:07 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 11.323 | ppl 2561.42 | wps 39017.4 | wpb 510.9 | bsz 1 | num_updates 15192 | best_loss 8.621
2022-03-07 09:10:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15192 updates
2022-03-07 09:10:07 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 09:10:07 | INFO | train | epoch 312 | loss 1.893 | ppl 3.71 | wps 22049.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15192 | lr 0.000256562 | gnorm 0.455 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 45023
2022-03-07 09:10:07 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 09:10:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:10:30 | INFO | train_inner | epoch 313:      8 / 49 loss=1.893, ppl=3.71, wps=22074.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.452, loss_scale=32, train_wall=260, gb_free=21.5, wall=45045
2022-03-07 09:10:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:11:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:12:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:12:31 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 11.311 | ppl 2539.82 | wps 39144.5 | wpb 510.9 | bsz 1 | num_updates 15239 | best_loss 8.621
2022-03-07 09:12:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15239 updates
2022-03-07 09:12:31 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 09:12:31 | INFO | train | epoch 313 | loss 1.891 | ppl 3.71 | wps 21145.6 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 15239 | lr 0.000256166 | gnorm 0.452 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 45167
2022-03-07 09:12:31 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 09:12:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:14:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:14:55 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 11.295 | ppl 2513.47 | wps 39232.6 | wpb 510.9 | bsz 1 | num_updates 15288 | best_loss 8.621
2022-03-07 09:14:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15288 updates
2022-03-07 09:14:55 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 09:14:55 | INFO | train | epoch 314 | loss 1.89 | ppl 3.71 | wps 22056.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15288 | lr 0.000255755 | gnorm 0.446 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 45311
2022-03-07 09:14:55 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 09:14:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:15:30 | INFO | train_inner | epoch 315:     12 / 49 loss=1.89, ppl=3.71, wps=21649.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.449, loss_scale=16, train_wall=265, gb_free=21.5, wall=45345
2022-03-07 09:17:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:17:19 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 11.275 | ppl 2478.6 | wps 39141.8 | wpb 510.9 | bsz 1 | num_updates 15337 | best_loss 8.621
2022-03-07 09:17:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15337 updates
2022-03-07 09:17:19 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 09:17:19 | INFO | train | epoch 315 | loss 1.891 | ppl 3.71 | wps 22069.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15337 | lr 0.000255346 | gnorm 0.454 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 45455
2022-03-07 09:17:19 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 09:17:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:19:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:19:43 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 11.32 | ppl 2556.68 | wps 39317.3 | wpb 510.9 | bsz 1 | num_updates 15386 | best_loss 8.621
2022-03-07 09:19:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15386 updates
2022-03-07 09:19:43 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 09:19:43 | INFO | train | epoch 316 | loss 1.889 | ppl 3.7 | wps 22072.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15386 | lr 0.00025494 | gnorm 0.447 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 45599
2022-03-07 09:19:43 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 09:19:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:20:23 | INFO | train_inner | epoch 317:     14 / 49 loss=1.889, ppl=3.7, wps=22093.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.451, loss_scale=32, train_wall=260, gb_free=21.5, wall=45639
2022-03-07 09:22:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:22:07 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 11.292 | ppl 2506.67 | wps 39146.2 | wpb 510.9 | bsz 1 | num_updates 15435 | best_loss 8.621
2022-03-07 09:22:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15435 updates
2022-03-07 09:22:07 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 09:22:07 | INFO | train | epoch 317 | loss 1.887 | ppl 3.7 | wps 22068.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15435 | lr 0.000254535 | gnorm 0.453 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 45743
2022-03-07 09:22:07 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 09:22:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:23:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:24:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:24:31 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 11.29 | ppl 2503.38 | wps 39273.4 | wpb 510.9 | bsz 1 | num_updates 15483 | best_loss 8.621
2022-03-07 09:24:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15483 updates
2022-03-07 09:24:31 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 09:24:31 | INFO | train | epoch 318 | loss 1.887 | ppl 3.7 | wps 21613.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 15483 | lr 0.00025414 | gnorm 0.441 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 45887
2022-03-07 09:24:31 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 09:24:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:25:20 | INFO | train_inner | epoch 319:     17 / 49 loss=1.886, ppl=3.7, wps=21880, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.446, loss_scale=32, train_wall=262, gb_free=21.5, wall=45935
2022-03-07 09:26:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:26:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:26:55 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 11.327 | ppl 2569.81 | wps 39148.2 | wpb 510.9 | bsz 1 | num_updates 15531 | best_loss 8.621
2022-03-07 09:26:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15531 updates
2022-03-07 09:26:55 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 09:26:55 | INFO | train | epoch 319 | loss 1.886 | ppl 3.7 | wps 21620 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 15531 | lr 0.000253747 | gnorm 0.452 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 46031
2022-03-07 09:26:55 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 09:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:29:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:29:19 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 11.275 | ppl 2478.44 | wps 39198.9 | wpb 510.9 | bsz 1 | num_updates 15580 | best_loss 8.621
2022-03-07 09:29:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15580 updates
2022-03-07 09:29:19 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 09:29:19 | INFO | train | epoch 320 | loss 1.884 | ppl 3.69 | wps 22078.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15580 | lr 0.000253347 | gnorm 0.444 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 46175
2022-03-07 09:29:19 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 09:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:30:16 | INFO | train_inner | epoch 321:     20 / 49 loss=1.885, ppl=3.69, wps=21876.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.447, loss_scale=16, train_wall=262, gb_free=21.5, wall=46232
2022-03-07 09:31:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:31:43 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 11.31 | ppl 2538.57 | wps 39043.2 | wpb 510.9 | bsz 1 | num_updates 15629 | best_loss 8.621
2022-03-07 09:31:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15629 updates
2022-03-07 09:31:43 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 09:31:43 | INFO | train | epoch 321 | loss 1.884 | ppl 3.69 | wps 22061.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15629 | lr 0.00025295 | gnorm 0.444 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 46319
2022-03-07 09:31:43 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 09:31:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:33:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:34:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:34:07 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 11.285 | ppl 2495.83 | wps 39131.3 | wpb 510.9 | bsz 1 | num_updates 15677 | best_loss 8.621
2022-03-07 09:34:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15677 updates
2022-03-07 09:34:07 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 09:34:07 | INFO | train | epoch 322 | loss 1.883 | ppl 3.69 | wps 21617.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 15677 | lr 0.000252562 | gnorm 0.446 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 46463
2022-03-07 09:34:07 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 09:34:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:35:13 | INFO | train_inner | epoch 323:     23 / 49 loss=1.883, ppl=3.69, wps=21869.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.444, loss_scale=16, train_wall=262, gb_free=21.5, wall=46528
2022-03-07 09:36:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:36:31 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 11.31 | ppl 2538.19 | wps 39420.1 | wpb 510.9 | bsz 1 | num_updates 15726 | best_loss 8.621
2022-03-07 09:36:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15726 updates
2022-03-07 09:36:31 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 09:36:31 | INFO | train | epoch 323 | loss 1.882 | ppl 3.69 | wps 22067.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15726 | lr 0.000252169 | gnorm 0.443 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 46607
2022-03-07 09:36:31 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 09:36:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:38:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:38:55 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 11.299 | ppl 2519.31 | wps 39120.3 | wpb 510.9 | bsz 1 | num_updates 15775 | best_loss 8.621
2022-03-07 09:38:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15775 updates
2022-03-07 09:38:55 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 09:38:55 | INFO | train | epoch 324 | loss 1.88 | ppl 3.68 | wps 22064.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15775 | lr 0.000251777 | gnorm 0.436 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 46751
2022-03-07 09:38:55 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 09:38:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:40:07 | INFO | train_inner | epoch 325:     25 / 49 loss=1.881, ppl=3.68, wps=22088.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.439, loss_scale=32, train_wall=260, gb_free=21.5, wall=46822
2022-03-07 09:41:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:41:19 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 11.301 | ppl 2522.92 | wps 39135.5 | wpb 510.9 | bsz 1 | num_updates 15824 | best_loss 8.621
2022-03-07 09:41:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15824 updates
2022-03-07 09:41:19 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 09:41:19 | INFO | train | epoch 325 | loss 1.88 | ppl 3.68 | wps 22069.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15824 | lr 0.000251386 | gnorm 0.438 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 46895
2022-03-07 09:41:19 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 09:41:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:43:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:43:43 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 11.316 | ppl 2548.82 | wps 39111.9 | wpb 510.9 | bsz 1 | num_updates 15873 | best_loss 8.621
2022-03-07 09:43:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15873 updates
2022-03-07 09:43:43 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 09:43:43 | INFO | train | epoch 326 | loss 1.879 | ppl 3.68 | wps 22076.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15873 | lr 0.000250998 | gnorm 0.444 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 47039
2022-03-07 09:43:43 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 09:43:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:44:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:45:03 | INFO | train_inner | epoch 327:     28 / 49 loss=1.879, ppl=3.68, wps=21874.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.445, loss_scale=16, train_wall=262, gb_free=21.5, wall=47119
2022-03-07 09:46:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:46:08 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 11.284 | ppl 2493.5 | wps 38933.9 | wpb 510.9 | bsz 1 | num_updates 15921 | best_loss 8.621
2022-03-07 09:46:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15921 updates
2022-03-07 09:46:08 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 09:46:08 | INFO | train | epoch 327 | loss 1.878 | ppl 3.68 | wps 21592.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 15921 | lr 0.000250619 | gnorm 0.449 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 47183
2022-03-07 09:46:08 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 09:46:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:48:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:48:32 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 11.289 | ppl 2501.9 | wps 39067.9 | wpb 510.9 | bsz 1 | num_updates 15970 | best_loss 8.621
2022-03-07 09:48:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15970 updates
2022-03-07 09:48:32 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 09:48:32 | INFO | train | epoch 328 | loss 1.878 | ppl 3.67 | wps 22050.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15970 | lr 0.000250235 | gnorm 0.444 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 47327
2022-03-07 09:48:32 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 09:48:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:49:57 | INFO | train_inner | epoch 329:     30 / 49 loss=1.878, ppl=3.67, wps=22068.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.445, loss_scale=16, train_wall=260, gb_free=21.5, wall=47413
2022-03-07 09:50:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:50:56 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 11.327 | ppl 2569.02 | wps 39148.1 | wpb 510.9 | bsz 1 | num_updates 16019 | best_loss 8.621
2022-03-07 09:50:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16019 updates
2022-03-07 09:50:56 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 09:50:56 | INFO | train | epoch 329 | loss 1.877 | ppl 3.67 | wps 22071.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16019 | lr 0.000249852 | gnorm 0.445 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 47471
2022-03-07 09:50:56 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 09:50:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:53:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:53:20 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 11.326 | ppl 2568.04 | wps 39244.1 | wpb 510.9 | bsz 1 | num_updates 16068 | best_loss 8.621
2022-03-07 09:53:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16068 updates
2022-03-07 09:53:20 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 09:53:20 | INFO | train | epoch 330 | loss 1.875 | ppl 3.67 | wps 22079.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16068 | lr 0.00024947 | gnorm 0.436 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 47615
2022-03-07 09:53:20 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 09:53:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:54:51 | INFO | train_inner | epoch 331:     32 / 49 loss=1.875, ppl=3.67, wps=22092.4, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.437, loss_scale=32, train_wall=260, gb_free=21.5, wall=47706
2022-03-07 09:55:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:55:44 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 11.316 | ppl 2548.7 | wps 39245.9 | wpb 510.9 | bsz 1 | num_updates 16117 | best_loss 8.621
2022-03-07 09:55:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16117 updates
2022-03-07 09:55:44 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 09:55:44 | INFO | train | epoch 331 | loss 1.875 | ppl 3.67 | wps 22060.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16117 | lr 0.000249091 | gnorm 0.437 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 47759
2022-03-07 09:55:44 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 09:55:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:57:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:58:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:58:08 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 11.295 | ppl 2513.26 | wps 39174.6 | wpb 510.9 | bsz 1 | num_updates 16165 | best_loss 8.621
2022-03-07 09:58:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16165 updates
2022-03-07 09:58:08 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 09:58:08 | INFO | train | epoch 332 | loss 1.874 | ppl 3.66 | wps 21596.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 16165 | lr 0.000248721 | gnorm 0.438 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 47903
2022-03-07 09:58:08 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 09:58:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:59:48 | INFO | train_inner | epoch 333:     35 / 49 loss=1.873, ppl=3.66, wps=21870.9, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.436, loss_scale=32, train_wall=262, gb_free=21.5, wall=48003
2022-03-07 10:00:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:00:32 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 11.317 | ppl 2550.8 | wps 39058.9 | wpb 510.9 | bsz 1 | num_updates 16214 | best_loss 8.621
2022-03-07 10:00:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16214 updates
2022-03-07 10:00:32 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 10:00:32 | INFO | train | epoch 333 | loss 1.873 | ppl 3.66 | wps 22078.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16214 | lr 0.000248345 | gnorm 0.437 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 48047
2022-03-07 10:00:32 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 10:00:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:00:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:02:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:02:56 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 11.283 | ppl 2492.12 | wps 39097 | wpb 510.9 | bsz 1 | num_updates 16262 | best_loss 8.621
2022-03-07 10:02:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16262 updates
2022-03-07 10:02:56 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 10:02:56 | INFO | train | epoch 334 | loss 1.872 | ppl 3.66 | wps 21614.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 16262 | lr 0.000247978 | gnorm 0.434 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 48191
2022-03-07 10:02:56 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 10:02:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:04:44 | INFO | train_inner | epoch 335:     38 / 49 loss=1.872, ppl=3.66, wps=21868.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.438, loss_scale=16, train_wall=262, gb_free=21.5, wall=48299
2022-03-07 10:05:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:05:20 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 11.251 | ppl 2437.99 | wps 38959.9 | wpb 510.9 | bsz 1 | num_updates 16311 | best_loss 8.621
2022-03-07 10:05:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16311 updates
2022-03-07 10:05:20 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 10:05:20 | INFO | train | epoch 335 | loss 1.871 | ppl 3.66 | wps 22055 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16311 | lr 0.000247605 | gnorm 0.437 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 48335
2022-03-07 10:05:20 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 10:05:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:07:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:07:44 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 11.273 | ppl 2473.81 | wps 39157.8 | wpb 510.9 | bsz 1 | num_updates 16360 | best_loss 8.621
2022-03-07 10:07:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16360 updates
2022-03-07 10:07:44 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 10:07:44 | INFO | train | epoch 336 | loss 1.871 | ppl 3.66 | wps 22082.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16360 | lr 0.000247234 | gnorm 0.438 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 48479
2022-03-07 10:07:44 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 10:07:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:09:38 | INFO | train_inner | epoch 337:     40 / 49 loss=1.87, ppl=3.66, wps=22086.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16400, lr=0.000246932, gnorm=0.434, loss_scale=32, train_wall=260, gb_free=21.5, wall=48593
2022-03-07 10:10:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:10:08 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 11.302 | ppl 2525.75 | wps 39009.7 | wpb 510.9 | bsz 1 | num_updates 16409 | best_loss 8.621
2022-03-07 10:10:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16409 updates
2022-03-07 10:10:08 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 10:10:08 | INFO | train | epoch 337 | loss 1.869 | ppl 3.65 | wps 22054.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16409 | lr 0.000246865 | gnorm 0.43 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 48623
2022-03-07 10:10:08 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 10:10:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:12:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:12:32 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 11.292 | ppl 2507.62 | wps 39054 | wpb 510.9 | bsz 1 | num_updates 16458 | best_loss 8.621
2022-03-07 10:12:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16458 updates
2022-03-07 10:12:32 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 10:12:32 | INFO | train | epoch 338 | loss 1.869 | ppl 3.65 | wps 22063.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16458 | lr 0.000246497 | gnorm 0.431 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 48767
2022-03-07 10:12:32 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 10:12:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:13:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:14:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:14:37 | INFO | train_inner | epoch 339:     44 / 49 loss=1.868, ppl=3.65, wps=21659, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=16500, lr=0.000246183, gnorm=0.43, loss_scale=16, train_wall=265, gb_free=21.5, wall=48893
2022-03-07 10:14:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:14:56 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 11.293 | ppl 2509.17 | wps 39095.1 | wpb 510.9 | bsz 1 | num_updates 16505 | best_loss 8.621
2022-03-07 10:14:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16505 updates
2022-03-07 10:14:56 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 10:14:56 | INFO | train | epoch 339 | loss 1.867 | ppl 3.65 | wps 21151.2 | ups 0.33 | wpb 64838.8 | bsz 126.6 | num_updates 16505 | lr 0.000246146 | gnorm 0.43 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 48911
2022-03-07 10:14:56 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 10:14:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:17:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:17:20 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 11.282 | ppl 2490.52 | wps 39139.3 | wpb 510.9 | bsz 1 | num_updates 16554 | best_loss 8.621
2022-03-07 10:17:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16554 updates
2022-03-07 10:17:20 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 10:17:20 | INFO | train | epoch 340 | loss 1.867 | ppl 3.65 | wps 22075.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16554 | lr 0.000245781 | gnorm 0.437 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 49055
2022-03-07 10:17:20 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 10:17:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:19:31 | INFO | train_inner | epoch 341:     46 / 49 loss=1.867, ppl=3.65, wps=22083.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16600, lr=0.00024544, gnorm=0.435, loss_scale=16, train_wall=260, gb_free=21.5, wall=49186
2022-03-07 10:19:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:19:44 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 11.295 | ppl 2512.24 | wps 39053.7 | wpb 510.9 | bsz 1 | num_updates 16603 | best_loss 8.621
2022-03-07 10:19:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16603 updates
2022-03-07 10:19:44 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 10:19:44 | INFO | train | epoch 341 | loss 1.866 | ppl 3.65 | wps 22057.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16603 | lr 0.000245418 | gnorm 0.433 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 49199
2022-03-07 10:19:44 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 10:19:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:22:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:22:08 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 11.291 | ppl 2504.89 | wps 38993.1 | wpb 510.9 | bsz 1 | num_updates 16652 | best_loss 8.621
2022-03-07 10:22:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16652 updates
2022-03-07 10:22:08 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 10:22:08 | INFO | train | epoch 342 | loss 1.865 | ppl 3.64 | wps 22058.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16652 | lr 0.000245057 | gnorm 0.431 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 49343
2022-03-07 10:22:08 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 10:22:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:24:25 | INFO | train_inner | epoch 343:     48 / 49 loss=1.865, ppl=3.64, wps=22083.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.433, loss_scale=32, train_wall=260, gb_free=21.5, wall=49480
2022-03-07 10:24:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:24:32 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 11.288 | ppl 2500.23 | wps 39077.6 | wpb 510.9 | bsz 1 | num_updates 16701 | best_loss 8.621
2022-03-07 10:24:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16701 updates
2022-03-07 10:24:32 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 10:24:32 | INFO | train | epoch 343 | loss 1.865 | ppl 3.64 | wps 22074.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16701 | lr 0.000244697 | gnorm 0.435 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 49487
2022-03-07 10:24:32 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 10:24:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:26:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:26:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:26:56 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 11.284 | ppl 2492.85 | wps 39044.2 | wpb 510.9 | bsz 1 | num_updates 16749 | best_loss 8.621
2022-03-07 10:26:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16749 updates
2022-03-07 10:26:56 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 10:26:56 | INFO | train | epoch 344 | loss 1.864 | ppl 3.64 | wps 21604.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 16749 | lr 0.000244346 | gnorm 0.432 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 49631
2022-03-07 10:26:56 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 10:26:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:29:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:29:20 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 11.327 | ppl 2568.51 | wps 39103.6 | wpb 510.9 | bsz 1 | num_updates 16798 | best_loss 8.621
2022-03-07 10:29:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16798 updates
2022-03-07 10:29:20 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 10:29:20 | INFO | train | epoch 345 | loss 1.864 | ppl 3.64 | wps 22046.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16798 | lr 0.00024399 | gnorm 0.434 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 49776
2022-03-07 10:29:20 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 10:29:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:29:26 | INFO | train_inner | epoch 346:      2 / 49 loss=1.864, ppl=3.64, wps=21435.2, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=16800, lr=0.000243975, gnorm=0.434, loss_scale=32, train_wall=261, gb_free=21.5, wall=49781
2022-03-07 10:31:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:31:44 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 11.288 | ppl 2500.54 | wps 38960.1 | wpb 510.9 | bsz 1 | num_updates 16847 | best_loss 8.621
2022-03-07 10:31:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16847 updates
2022-03-07 10:31:44 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 10:31:44 | INFO | train | epoch 346 | loss 1.862 | ppl 3.63 | wps 22065.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16847 | lr 0.000243634 | gnorm 0.425 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 49920
2022-03-07 10:31:44 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 10:31:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:33:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:34:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:34:08 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 11.273 | ppl 2474.99 | wps 38907.4 | wpb 510.9 | bsz 1 | num_updates 16895 | best_loss 8.621
2022-03-07 10:34:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16895 updates
2022-03-07 10:34:08 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 10:34:08 | INFO | train | epoch 347 | loss 1.862 | ppl 3.63 | wps 21597.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 16895 | lr 0.000243288 | gnorm 0.433 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 50064
2022-03-07 10:34:08 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 10:34:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:34:23 | INFO | train_inner | epoch 348:      5 / 49 loss=1.861, ppl=3.63, wps=21863.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.429, loss_scale=32, train_wall=262, gb_free=21.5, wall=50078
2022-03-07 10:36:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:36:33 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 11.3 | ppl 2520.58 | wps 39074.9 | wpb 510.9 | bsz 1 | num_updates 16944 | best_loss 8.621
2022-03-07 10:36:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16944 updates
2022-03-07 10:36:33 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 10:36:33 | INFO | train | epoch 348 | loss 1.86 | ppl 3.63 | wps 22059.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16944 | lr 0.000242936 | gnorm 0.432 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 50208
2022-03-07 10:36:33 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 10:36:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:37:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:38:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:38:56 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 11.288 | ppl 2499.88 | wps 38917.8 | wpb 510.9 | bsz 1 | num_updates 16992 | best_loss 8.621
2022-03-07 10:38:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16992 updates
2022-03-07 10:38:56 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 10:38:56 | INFO | train | epoch 349 | loss 1.859 | ppl 3.63 | wps 21615.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 16992 | lr 0.000242593 | gnorm 0.425 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 50352
2022-03-07 10:38:57 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 10:38:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:39:19 | INFO | train_inner | epoch 350:      8 / 49 loss=1.859, ppl=3.63, wps=21872.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.428, loss_scale=16, train_wall=262, gb_free=21.5, wall=50375
2022-03-07 10:41:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:41:20 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 11.298 | ppl 2518.51 | wps 39113.7 | wpb 510.9 | bsz 1 | num_updates 17041 | best_loss 8.621
2022-03-07 10:41:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17041 updates
2022-03-07 10:41:21 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 10:41:21 | INFO | train | epoch 350 | loss 1.859 | ppl 3.63 | wps 22069.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17041 | lr 0.000242244 | gnorm 0.429 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 50496
2022-03-07 10:41:21 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 10:41:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:43:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:43:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:43:45 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 11.269 | ppl 2466.98 | wps 39138 | wpb 510.9 | bsz 1 | num_updates 17089 | best_loss 8.621
2022-03-07 10:43:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17089 updates
2022-03-07 10:43:45 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 10:43:45 | INFO | train | epoch 351 | loss 1.859 | ppl 3.63 | wps 21613 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 17089 | lr 0.000241903 | gnorm 0.432 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 50640
2022-03-07 10:43:45 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 10:43:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:44:16 | INFO | train_inner | epoch 352:     11 / 49 loss=1.859, ppl=3.63, wps=21875.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.431, loss_scale=16, train_wall=262, gb_free=21.5, wall=50671
2022-03-07 10:46:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:46:08 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 11.261 | ppl 2453.34 | wps 38927.3 | wpb 510.9 | bsz 1 | num_updates 17138 | best_loss 8.621
2022-03-07 10:46:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17138 updates
2022-03-07 10:46:08 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 10:46:08 | INFO | train | epoch 352 | loss 1.857 | ppl 3.62 | wps 22076.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17138 | lr 0.000241557 | gnorm 0.433 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 50784
2022-03-07 10:46:08 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 10:46:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:48:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:48:32 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 11.292 | ppl 2508.25 | wps 38955.6 | wpb 510.9 | bsz 1 | num_updates 17187 | best_loss 8.621
2022-03-07 10:48:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17187 updates
2022-03-07 10:48:32 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 10:48:32 | INFO | train | epoch 353 | loss 1.857 | ppl 3.62 | wps 22071.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17187 | lr 0.000241213 | gnorm 0.424 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 50928
2022-03-07 10:48:32 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 10:48:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:49:10 | INFO | train_inner | epoch 354:     13 / 49 loss=1.857, ppl=3.62, wps=22094.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.427, loss_scale=16, train_wall=260, gb_free=21.5, wall=50965
2022-03-07 10:50:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:50:56 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 11.268 | ppl 2466.65 | wps 39014.5 | wpb 510.9 | bsz 1 | num_updates 17236 | best_loss 8.621
2022-03-07 10:50:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17236 updates
2022-03-07 10:50:56 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 10:50:56 | INFO | train | epoch 354 | loss 1.855 | ppl 3.62 | wps 22074.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17236 | lr 0.000240869 | gnorm 0.421 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 51072
2022-03-07 10:50:56 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 10:50:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:53:21 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 11.278 | ppl 2483.17 | wps 38990.4 | wpb 510.9 | bsz 1 | num_updates 17285 | best_loss 8.621
2022-03-07 10:53:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17285 updates
2022-03-07 10:53:21 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 10:53:21 | INFO | train | epoch 355 | loss 1.856 | ppl 3.62 | wps 22054.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17285 | lr 0.000240528 | gnorm 0.424 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 51216
2022-03-07 10:53:21 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 10:53:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:54:03 | INFO | train_inner | epoch 356:     15 / 49 loss=1.855, ppl=3.62, wps=22077, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.422, loss_scale=32, train_wall=260, gb_free=21.5, wall=51259
2022-03-07 10:55:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:55:45 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 11.274 | ppl 2476.65 | wps 39128.2 | wpb 510.9 | bsz 1 | num_updates 17334 | best_loss 8.621
2022-03-07 10:55:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17334 updates
2022-03-07 10:55:45 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 10:55:45 | INFO | train | epoch 356 | loss 1.855 | ppl 3.62 | wps 22072.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17334 | lr 0.000240188 | gnorm 0.428 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 51360
2022-03-07 10:55:45 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 10:55:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:56:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:58:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:58:09 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 11.246 | ppl 2429.25 | wps 38890.5 | wpb 510.9 | bsz 1 | num_updates 17382 | best_loss 8.621
2022-03-07 10:58:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17382 updates
2022-03-07 10:58:09 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 10:58:09 | INFO | train | epoch 357 | loss 1.853 | ppl 3.61 | wps 21585 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 17382 | lr 0.000239856 | gnorm 0.42 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 51504
2022-03-07 10:58:09 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 10:58:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:59:00 | INFO | train_inner | epoch 358:     18 / 49 loss=1.854, ppl=3.61, wps=21861.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.425, loss_scale=32, train_wall=262, gb_free=21.5, wall=51555
2022-03-07 11:00:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:00:33 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 11.271 | ppl 2470.41 | wps 38866.3 | wpb 510.9 | bsz 1 | num_updates 17431 | best_loss 8.621
2022-03-07 11:00:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17431 updates
2022-03-07 11:00:33 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 11:00:33 | INFO | train | epoch 358 | loss 1.853 | ppl 3.61 | wps 22062.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17431 | lr 0.000239518 | gnorm 0.432 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 51648
2022-03-07 11:00:33 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 11:00:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:02:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:02:57 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 11.247 | ppl 2429.89 | wps 38958.4 | wpb 510.9 | bsz 1 | num_updates 17479 | best_loss 8.621
2022-03-07 11:02:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17479 updates
2022-03-07 11:02:57 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 11:02:57 | INFO | train | epoch 359 | loss 1.852 | ppl 3.61 | wps 21607.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 17479 | lr 0.000239189 | gnorm 0.421 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 51792
2022-03-07 11:02:57 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 11:02:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:03:57 | INFO | train_inner | epoch 360:     21 / 49 loss=1.852, ppl=3.61, wps=21869.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.427, loss_scale=32, train_wall=262, gb_free=21.5, wall=51852
2022-03-07 11:05:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:05:21 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 11.249 | ppl 2433.6 | wps 39025.6 | wpb 510.9 | bsz 1 | num_updates 17528 | best_loss 8.621
2022-03-07 11:05:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17528 updates
2022-03-07 11:05:21 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 11:05:21 | INFO | train | epoch 360 | loss 1.852 | ppl 3.61 | wps 22069.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17528 | lr 0.000238855 | gnorm 0.43 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 51936
2022-03-07 11:05:21 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 11:05:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:06:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:07:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:07:45 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 11.259 | ppl 2450.85 | wps 38846.9 | wpb 510.9 | bsz 1 | num_updates 17576 | best_loss 8.621
2022-03-07 11:07:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17576 updates
2022-03-07 11:07:45 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 11:07:45 | INFO | train | epoch 361 | loss 1.851 | ppl 3.61 | wps 21610.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 17576 | lr 0.000238528 | gnorm 0.422 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 52080
2022-03-07 11:07:45 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 11:07:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:08:53 | INFO | train_inner | epoch 362:     24 / 49 loss=1.851, ppl=3.61, wps=21877.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.424, loss_scale=16, train_wall=262, gb_free=21.5, wall=52149
2022-03-07 11:10:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:10:09 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 11.247 | ppl 2430.2 | wps 38967.3 | wpb 510.9 | bsz 1 | num_updates 17625 | best_loss 8.621
2022-03-07 11:10:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17625 updates
2022-03-07 11:10:09 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 11:10:09 | INFO | train | epoch 362 | loss 1.85 | ppl 3.61 | wps 22081 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17625 | lr 0.000238197 | gnorm 0.424 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 52224
2022-03-07 11:10:09 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 11:10:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:12:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:12:33 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 11.267 | ppl 2464.27 | wps 38918.6 | wpb 510.9 | bsz 1 | num_updates 17674 | best_loss 8.621
2022-03-07 11:12:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17674 updates
2022-03-07 11:12:33 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 11:12:33 | INFO | train | epoch 363 | loss 1.848 | ppl 3.6 | wps 22061.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17674 | lr 0.000237866 | gnorm 0.413 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 52368
2022-03-07 11:12:33 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 11:12:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:13:47 | INFO | train_inner | epoch 364:     26 / 49 loss=1.849, ppl=3.6, wps=22083, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.419, loss_scale=32, train_wall=260, gb_free=21.5, wall=52442
2022-03-07 11:14:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:14:57 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 11.26 | ppl 2451.64 | wps 39049.4 | wpb 510.9 | bsz 1 | num_updates 17723 | best_loss 8.621
2022-03-07 11:14:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17723 updates
2022-03-07 11:14:57 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 11:14:57 | INFO | train | epoch 364 | loss 1.849 | ppl 3.6 | wps 22056.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17723 | lr 0.000237537 | gnorm 0.421 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 52512
2022-03-07 11:14:57 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 11:14:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:17:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:17:21 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 11.298 | ppl 2518.74 | wps 39169.8 | wpb 510.9 | bsz 1 | num_updates 17772 | best_loss 8.621
2022-03-07 11:17:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17772 updates
2022-03-07 11:17:21 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 11:17:21 | INFO | train | epoch 365 | loss 1.848 | ppl 3.6 | wps 22062.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17772 | lr 0.000237209 | gnorm 0.418 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 52656
2022-03-07 11:17:21 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 11:17:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:18:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:18:44 | INFO | train_inner | epoch 366:     29 / 49 loss=1.848, ppl=3.6, wps=21860.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.421, loss_scale=16, train_wall=262, gb_free=21.5, wall=52739
2022-03-07 11:19:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:19:45 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 11.263 | ppl 2458.19 | wps 39254.5 | wpb 510.9 | bsz 1 | num_updates 17820 | best_loss 8.621
2022-03-07 11:19:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17820 updates
2022-03-07 11:19:45 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 11:19:45 | INFO | train | epoch 366 | loss 1.848 | ppl 3.6 | wps 21593.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 17820 | lr 0.00023689 | gnorm 0.425 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 52800
2022-03-07 11:19:45 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 11:19:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:22:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:22:09 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 11.256 | ppl 2444.84 | wps 39064.9 | wpb 510.9 | bsz 1 | num_updates 17869 | best_loss 8.621
2022-03-07 11:22:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17869 updates
2022-03-07 11:22:09 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 11:22:09 | INFO | train | epoch 367 | loss 1.847 | ppl 3.6 | wps 22053.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17869 | lr 0.000236565 | gnorm 0.422 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 52944
2022-03-07 11:22:09 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 11:22:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:23:38 | INFO | train_inner | epoch 368:     31 / 49 loss=1.847, ppl=3.6, wps=22077.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.423, loss_scale=16, train_wall=260, gb_free=21.5, wall=53033
2022-03-07 11:24:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:24:33 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 11.305 | ppl 2529.72 | wps 39179.8 | wpb 510.9 | bsz 1 | num_updates 17918 | best_loss 8.621
2022-03-07 11:24:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17918 updates
2022-03-07 11:24:33 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 11:24:33 | INFO | train | epoch 368 | loss 1.846 | ppl 3.6 | wps 22074.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17918 | lr 0.000236241 | gnorm 0.424 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 53088
2022-03-07 11:24:33 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 11:24:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:26:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:26:57 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 11.282 | ppl 2490.91 | wps 39138.7 | wpb 510.9 | bsz 1 | num_updates 17967 | best_loss 8.621
2022-03-07 11:26:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17967 updates
2022-03-07 11:26:57 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 11:26:57 | INFO | train | epoch 369 | loss 1.845 | ppl 3.59 | wps 22052.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17967 | lr 0.000235919 | gnorm 0.413 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 53233
2022-03-07 11:26:57 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 11:26:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:28:32 | INFO | train_inner | epoch 370:     33 / 49 loss=1.845, ppl=3.59, wps=22073.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.417, loss_scale=32, train_wall=260, gb_free=21.5, wall=53327
2022-03-07 11:29:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:29:21 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 11.301 | ppl 2523.58 | wps 39223.7 | wpb 510.9 | bsz 1 | num_updates 18016 | best_loss 8.621
2022-03-07 11:29:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18016 updates
2022-03-07 11:29:21 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 11:29:21 | INFO | train | epoch 370 | loss 1.844 | ppl 3.59 | wps 22058.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18016 | lr 0.000235598 | gnorm 0.418 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 53377
2022-03-07 11:29:21 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 11:29:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:29:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:31:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:31:45 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 11.266 | ppl 2462.33 | wps 39022 | wpb 510.9 | bsz 1 | num_updates 18064 | best_loss 8.621
2022-03-07 11:31:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18064 updates
2022-03-07 11:31:45 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 11:31:45 | INFO | train | epoch 371 | loss 1.844 | ppl 3.59 | wps 21609 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18064 | lr 0.000235284 | gnorm 0.424 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 53521
2022-03-07 11:31:45 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 11:31:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:33:28 | INFO | train_inner | epoch 372:     36 / 49 loss=1.844, ppl=3.59, wps=21871.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.418, loss_scale=16, train_wall=262, gb_free=21.5, wall=53623
2022-03-07 11:34:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:34:09 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 11.302 | ppl 2524.8 | wps 39148.5 | wpb 510.9 | bsz 1 | num_updates 18113 | best_loss 8.621
2022-03-07 11:34:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18113 updates
2022-03-07 11:34:09 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 11:34:09 | INFO | train | epoch 372 | loss 1.843 | ppl 3.59 | wps 22067.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18113 | lr 0.000234966 | gnorm 0.412 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 53665
2022-03-07 11:34:09 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 11:34:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:36:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:36:33 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 11.297 | ppl 2516.8 | wps 39197.1 | wpb 510.9 | bsz 1 | num_updates 18162 | best_loss 8.621
2022-03-07 11:36:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18162 updates
2022-03-07 11:36:33 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 11:36:33 | INFO | train | epoch 373 | loss 1.842 | ppl 3.59 | wps 22074 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18162 | lr 0.000234649 | gnorm 0.418 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 53809
2022-03-07 11:36:33 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 11:36:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:37:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:38:25 | INFO | train_inner | epoch 374:     39 / 49 loss=1.842, ppl=3.59, wps=21869.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18200, lr=0.000234404, gnorm=0.421, loss_scale=16, train_wall=262, gb_free=21.5, wall=53920
2022-03-07 11:38:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:38:58 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 11.281 | ppl 2488.81 | wps 39107.9 | wpb 510.9 | bsz 1 | num_updates 18210 | best_loss 8.621
2022-03-07 11:38:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18210 updates
2022-03-07 11:38:58 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 11:38:58 | INFO | train | epoch 374 | loss 1.842 | ppl 3.58 | wps 21596.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18210 | lr 0.000234339 | gnorm 0.424 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 53953
2022-03-07 11:38:58 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 11:38:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:41:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:41:22 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 11.257 | ppl 2448.08 | wps 39085.7 | wpb 510.9 | bsz 1 | num_updates 18259 | best_loss 8.621
2022-03-07 11:41:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18259 updates
2022-03-07 11:41:22 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 11:41:22 | INFO | train | epoch 375 | loss 1.84 | ppl 3.58 | wps 22068 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18259 | lr 0.000234025 | gnorm 0.414 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 54097
2022-03-07 11:41:22 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 11:41:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:43:19 | INFO | train_inner | epoch 376:     41 / 49 loss=1.841, ppl=3.58, wps=22081.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18300, lr=0.000233762, gnorm=0.415, loss_scale=16, train_wall=260, gb_free=21.5, wall=54214
2022-03-07 11:43:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:43:46 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 11.27 | ppl 2470.21 | wps 38997.5 | wpb 510.9 | bsz 1 | num_updates 18308 | best_loss 8.621
2022-03-07 11:43:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18308 updates
2022-03-07 11:43:46 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 11:43:46 | INFO | train | epoch 376 | loss 1.84 | ppl 3.58 | wps 22058.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18308 | lr 0.000233711 | gnorm 0.415 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 54241
2022-03-07 11:43:46 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 11:43:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:46:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:46:10 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 11.271 | ppl 2471.3 | wps 39068.3 | wpb 510.9 | bsz 1 | num_updates 18357 | best_loss 8.621
2022-03-07 11:46:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18357 updates
2022-03-07 11:46:10 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 11:46:10 | INFO | train | epoch 377 | loss 1.84 | ppl 3.58 | wps 22054.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18357 | lr 0.000233399 | gnorm 0.422 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 54385
2022-03-07 11:46:10 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 11:46:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:48:12 | INFO | train_inner | epoch 378:     43 / 49 loss=1.84, ppl=3.58, wps=22073.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18400, lr=0.000233126, gnorm=0.419, loss_scale=32, train_wall=260, gb_free=21.5, wall=54508
2022-03-07 11:48:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:48:34 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 11.278 | ppl 2482.67 | wps 39141.6 | wpb 510.9 | bsz 1 | num_updates 18406 | best_loss 8.621
2022-03-07 11:48:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18406 updates
2022-03-07 11:48:34 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 11:48:34 | INFO | train | epoch 378 | loss 1.839 | ppl 3.58 | wps 22060.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18406 | lr 0.000233088 | gnorm 0.415 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 54529
2022-03-07 11:48:34 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 11:48:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:49:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:50:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:50:58 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 11.282 | ppl 2490.69 | wps 39175.8 | wpb 510.9 | bsz 1 | num_updates 18454 | best_loss 8.621
2022-03-07 11:50:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18454 updates
2022-03-07 11:50:58 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 11:50:58 | INFO | train | epoch 379 | loss 1.838 | ppl 3.57 | wps 21625.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18454 | lr 0.000232785 | gnorm 0.411 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 54673
2022-03-07 11:50:58 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 11:50:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:53:09 | INFO | train_inner | epoch 380:     46 / 49 loss=1.838, ppl=3.57, wps=21881.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.414, loss_scale=32, train_wall=262, gb_free=21.5, wall=54804
2022-03-07 11:53:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:53:22 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 11.297 | ppl 2515.33 | wps 39089.8 | wpb 510.9 | bsz 1 | num_updates 18503 | best_loss 8.621
2022-03-07 11:53:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18503 updates
2022-03-07 11:53:22 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 11:53:22 | INFO | train | epoch 380 | loss 1.838 | ppl 3.58 | wps 22066.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18503 | lr 0.000232476 | gnorm 0.417 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 54817
2022-03-07 11:53:22 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 11:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:55:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:55:46 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 11.286 | ppl 2496.53 | wps 39215.4 | wpb 510.9 | bsz 1 | num_updates 18552 | best_loss 8.621
2022-03-07 11:55:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18552 updates
2022-03-07 11:55:46 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 11:55:46 | INFO | train | epoch 381 | loss 1.837 | ppl 3.57 | wps 22050.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18552 | lr 0.000232169 | gnorm 0.415 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 54961
2022-03-07 11:55:46 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 11:55:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:56:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:58:04 | INFO | train_inner | epoch 382:     49 / 49 loss=1.837, ppl=3.57, wps=21858, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=18600, lr=0.000231869, gnorm=0.416, loss_scale=32, train_wall=261, gb_free=21.5, wall=55099
2022-03-07 11:58:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:58:10 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 11.258 | ppl 2449.71 | wps 39062 | wpb 510.9 | bsz 1 | num_updates 18600 | best_loss 8.621
2022-03-07 11:58:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18600 updates
2022-03-07 11:58:10 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 11:58:10 | INFO | train | epoch 382 | loss 1.837 | ppl 3.57 | wps 21616.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18600 | lr 0.000231869 | gnorm 0.415 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 55105
2022-03-07 11:58:10 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 11:58:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:00:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:00:34 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 11.252 | ppl 2439.35 | wps 39052.9 | wpb 510.9 | bsz 1 | num_updates 18649 | best_loss 8.621
2022-03-07 12:00:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18649 updates
2022-03-07 12:00:34 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 12:00:34 | INFO | train | epoch 383 | loss 1.835 | ppl 3.57 | wps 22047.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18649 | lr 0.000231565 | gnorm 0.416 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 55249
2022-03-07 12:00:34 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 12:00:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:02:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:02:58 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 11.255 | ppl 2444.75 | wps 39304.4 | wpb 510.9 | bsz 1 | num_updates 18698 | best_loss 8.621
2022-03-07 12:02:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18698 updates
2022-03-07 12:02:58 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 12:02:58 | INFO | train | epoch 384 | loss 1.835 | ppl 3.57 | wps 22066.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18698 | lr 0.000231261 | gnorm 0.411 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 55393
2022-03-07 12:02:58 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 12:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:03:04 | INFO | train_inner | epoch 385:      2 / 49 loss=1.835, ppl=3.57, wps=21653, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.413, loss_scale=32, train_wall=260, gb_free=21.5, wall=55399
2022-03-07 12:03:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:05:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:05:22 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 11.299 | ppl 2520.29 | wps 39232.5 | wpb 510.9 | bsz 1 | num_updates 18746 | best_loss 8.621
2022-03-07 12:05:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18746 updates
2022-03-07 12:05:22 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 12:05:22 | INFO | train | epoch 385 | loss 1.834 | ppl 3.57 | wps 21612.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18746 | lr 0.000230965 | gnorm 0.41 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 55537
2022-03-07 12:05:22 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 12:05:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:06:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:07:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:07:46 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 11.264 | ppl 2458.99 | wps 39116.6 | wpb 510.9 | bsz 1 | num_updates 18794 | best_loss 8.621
2022-03-07 12:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18794 updates
2022-03-07 12:07:46 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 12:07:46 | INFO | train | epoch 386 | loss 1.833 | ppl 3.56 | wps 21619.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18794 | lr 0.00023067 | gnorm 0.414 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 55681
2022-03-07 12:07:46 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 12:07:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:08:03 | INFO | train_inner | epoch 387:      6 / 49 loss=1.834, ppl=3.56, wps=21667.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.412, loss_scale=16, train_wall=265, gb_free=21.5, wall=55698
2022-03-07 12:10:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:10:10 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 11.285 | ppl 2495.6 | wps 39291.7 | wpb 510.9 | bsz 1 | num_updates 18843 | best_loss 8.621
2022-03-07 12:10:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18843 updates
2022-03-07 12:10:10 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 12:10:10 | INFO | train | epoch 387 | loss 1.832 | ppl 3.56 | wps 22079.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18843 | lr 0.000230369 | gnorm 0.406 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 55825
2022-03-07 12:10:10 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 12:10:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:12:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:12:34 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 11.267 | ppl 2463.95 | wps 39165.4 | wpb 510.9 | bsz 1 | num_updates 18892 | best_loss 8.621
2022-03-07 12:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18892 updates
2022-03-07 12:12:34 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 12:12:34 | INFO | train | epoch 388 | loss 1.833 | ppl 3.56 | wps 22088.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18892 | lr 0.000230071 | gnorm 0.404 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 55969
2022-03-07 12:12:34 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 12:12:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:12:57 | INFO | train_inner | epoch 389:      8 / 49 loss=1.832, ppl=3.56, wps=22098.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.405, loss_scale=16, train_wall=260, gb_free=21.5, wall=55992
2022-03-07 12:14:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:14:58 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 11.256 | ppl 2445.47 | wps 39113.3 | wpb 510.9 | bsz 1 | num_updates 18941 | best_loss 8.621
2022-03-07 12:14:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18941 updates
2022-03-07 12:14:58 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 12:14:58 | INFO | train | epoch 389 | loss 1.832 | ppl 3.56 | wps 22072.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18941 | lr 0.000229773 | gnorm 0.407 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 56113
2022-03-07 12:14:58 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 12:14:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:17:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:17:22 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 11.262 | ppl 2456.64 | wps 39211.3 | wpb 510.9 | bsz 1 | num_updates 18990 | best_loss 8.621
2022-03-07 12:17:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18990 updates
2022-03-07 12:17:22 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 12:17:22 | INFO | train | epoch 390 | loss 1.832 | ppl 3.56 | wps 22063.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18990 | lr 0.000229476 | gnorm 0.406 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 56257
2022-03-07 12:17:22 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 12:17:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:17:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:17:53 | INFO | train_inner | epoch 391:     11 / 49 loss=1.832, ppl=3.56, wps=21881.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.409, loss_scale=16, train_wall=262, gb_free=21.5, wall=56288
2022-03-07 12:19:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:19:46 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 11.271 | ppl 2471.78 | wps 39042.3 | wpb 510.9 | bsz 1 | num_updates 19038 | best_loss 8.621
2022-03-07 12:19:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19038 updates
2022-03-07 12:19:46 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 12:19:46 | INFO | train | epoch 391 | loss 1.831 | ppl 3.56 | wps 21628.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 19038 | lr 0.000229187 | gnorm 0.411 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 56401
2022-03-07 12:19:46 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 12:19:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:22:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:22:10 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 11.256 | ppl 2445.7 | wps 39286.9 | wpb 510.9 | bsz 1 | num_updates 19087 | best_loss 8.621
2022-03-07 12:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19087 updates
2022-03-07 12:22:10 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 12:22:10 | INFO | train | epoch 392 | loss 1.83 | ppl 3.56 | wps 22058.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19087 | lr 0.000228892 | gnorm 0.406 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 56545
2022-03-07 12:22:10 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 12:22:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:22:47 | INFO | train_inner | epoch 393:     13 / 49 loss=1.83, ppl=3.55, wps=22085.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.406, loss_scale=16, train_wall=260, gb_free=21.5, wall=56582
2022-03-07 12:24:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:24:34 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 11.236 | ppl 2411.32 | wps 39156.2 | wpb 510.9 | bsz 1 | num_updates 19136 | best_loss 8.621
2022-03-07 12:24:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19136 updates
2022-03-07 12:24:34 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 12:24:34 | INFO | train | epoch 393 | loss 1.829 | ppl 3.55 | wps 22067.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19136 | lr 0.000228599 | gnorm 0.41 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 56689
2022-03-07 12:24:34 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 12:24:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:26:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:26:58 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 11.268 | ppl 2465.37 | wps 39259.1 | wpb 510.9 | bsz 1 | num_updates 19185 | best_loss 8.621
2022-03-07 12:26:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19185 updates
2022-03-07 12:26:58 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 12:26:58 | INFO | train | epoch 394 | loss 1.828 | ppl 3.55 | wps 22072.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19185 | lr 0.000228307 | gnorm 0.399 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 56833
2022-03-07 12:26:58 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 12:26:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:27:41 | INFO | train_inner | epoch 395:     15 / 49 loss=1.829, ppl=3.55, wps=22090.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.405, loss_scale=32, train_wall=260, gb_free=21.5, wall=56876
2022-03-07 12:29:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:29:22 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 11.252 | ppl 2439.28 | wps 39154.5 | wpb 510.9 | bsz 1 | num_updates 19234 | best_loss 8.621
2022-03-07 12:29:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19234 updates
2022-03-07 12:29:22 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 12:29:22 | INFO | train | epoch 395 | loss 1.828 | ppl 3.55 | wps 22071.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19234 | lr 0.000228016 | gnorm 0.408 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 56977
2022-03-07 12:29:22 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 12:29:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:31:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:31:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:31:46 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 11.258 | ppl 2449.02 | wps 39101.6 | wpb 510.9 | bsz 1 | num_updates 19282 | best_loss 8.621
2022-03-07 12:31:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19282 updates
2022-03-07 12:31:46 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 12:31:46 | INFO | train | epoch 396 | loss 1.827 | ppl 3.55 | wps 21609.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 19282 | lr 0.000227732 | gnorm 0.402 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 57121
2022-03-07 12:31:46 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 12:31:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:32:37 | INFO | train_inner | epoch 397:     18 / 49 loss=1.828, ppl=3.55, wps=21874.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.408, loss_scale=32, train_wall=262, gb_free=21.5, wall=57172
2022-03-07 12:33:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:34:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:34:10 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 11.253 | ppl 2440.4 | wps 39105.7 | wpb 510.9 | bsz 1 | num_updates 19330 | best_loss 8.621
2022-03-07 12:34:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19330 updates
2022-03-07 12:34:10 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 12:34:10 | INFO | train | epoch 397 | loss 1.829 | ppl 3.55 | wps 21632.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 19330 | lr 0.000227449 | gnorm 0.421 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 57265
2022-03-07 12:34:10 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 12:34:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:36:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:36:34 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 11.254 | ppl 2441.68 | wps 39313.8 | wpb 510.9 | bsz 1 | num_updates 19379 | best_loss 8.621
2022-03-07 12:36:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19379 updates
2022-03-07 12:36:34 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-07 12:36:34 | INFO | train | epoch 398 | loss 1.827 | ppl 3.55 | wps 22052.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19379 | lr 0.000227161 | gnorm 0.415 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 57409
2022-03-07 12:36:34 | INFO | fairseq.trainer | begin training epoch 399
2022-03-07 12:36:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:37:34 | INFO | train_inner | epoch 399:     21 / 49 loss=1.827, ppl=3.55, wps=21870.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.413, loss_scale=16, train_wall=262, gb_free=21.5, wall=57469
2022-03-07 12:38:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:38:58 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 11.253 | ppl 2441.22 | wps 39118.3 | wpb 510.9 | bsz 1 | num_updates 19428 | best_loss 8.621
2022-03-07 12:38:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19428 updates
2022-03-07 12:38:58 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-07 12:38:58 | INFO | train | epoch 399 | loss 1.825 | ppl 3.54 | wps 22051 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19428 | lr 0.000226875 | gnorm 0.403 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 57553
2022-03-07 12:38:58 | INFO | fairseq.trainer | begin training epoch 400
2022-03-07 12:38:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:41:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:41:22 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 11.264 | ppl 2458.63 | wps 39057.5 | wpb 510.9 | bsz 1 | num_updates 19477 | best_loss 8.621
2022-03-07 12:41:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19477 updates
2022-03-07 12:41:22 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-07 12:41:22 | INFO | train | epoch 400 | loss 1.825 | ppl 3.54 | wps 22072.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19477 | lr 0.000226589 | gnorm 0.402 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 57697
2022-03-07 12:41:22 | INFO | fairseq.trainer | begin training epoch 401
2022-03-07 12:41:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:42:28 | INFO | train_inner | epoch 401:     23 / 49 loss=1.825, ppl=3.54, wps=22077.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.403, loss_scale=32, train_wall=260, gb_free=21.5, wall=57763
2022-03-07 12:43:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:43:46 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 11.268 | ppl 2466.23 | wps 39302.5 | wpb 510.9 | bsz 1 | num_updates 19526 | best_loss 8.621
2022-03-07 12:43:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19526 updates
2022-03-07 12:43:46 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-07 12:43:46 | INFO | train | epoch 401 | loss 1.824 | ppl 3.54 | wps 22059.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19526 | lr 0.000226305 | gnorm 0.403 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 57841
2022-03-07 12:43:46 | INFO | fairseq.trainer | begin training epoch 402
2022-03-07 12:43:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:46:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:46:10 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 11.276 | ppl 2479.31 | wps 39103.7 | wpb 510.9 | bsz 1 | num_updates 19575 | best_loss 8.621
2022-03-07 12:46:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19575 updates
2022-03-07 12:46:10 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-07 12:46:10 | INFO | train | epoch 402 | loss 1.825 | ppl 3.54 | wps 22051.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19575 | lr 0.000226021 | gnorm 0.411 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 57985
2022-03-07 12:46:10 | INFO | fairseq.trainer | begin training epoch 403
2022-03-07 12:46:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:46:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:47:24 | INFO | train_inner | epoch 403:     26 / 49 loss=1.825, ppl=3.54, wps=21868.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.405, loss_scale=32, train_wall=263, gb_free=21.5, wall=58060
2022-03-07 12:48:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:48:34 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 11.254 | ppl 2441.64 | wps 39141.1 | wpb 510.9 | bsz 1 | num_updates 19623 | best_loss 8.621
2022-03-07 12:48:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19623 updates
2022-03-07 12:48:34 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-07 12:48:34 | INFO | train | epoch 403 | loss 1.823 | ppl 3.54 | wps 21626.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 19623 | lr 0.000225745 | gnorm 0.398 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 58129
2022-03-07 12:48:34 | INFO | fairseq.trainer | begin training epoch 404
2022-03-07 12:48:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:50:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:50:58 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 11.262 | ppl 2455.32 | wps 39239.3 | wpb 510.9 | bsz 1 | num_updates 19672 | best_loss 8.621
2022-03-07 12:50:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19672 updates
2022-03-07 12:50:58 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-07 12:50:58 | INFO | train | epoch 404 | loss 1.823 | ppl 3.54 | wps 22070.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19672 | lr 0.000225463 | gnorm 0.411 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 58273
2022-03-07 12:50:58 | INFO | fairseq.trainer | begin training epoch 405
2022-03-07 12:50:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:52:18 | INFO | train_inner | epoch 405:     28 / 49 loss=1.823, ppl=3.54, wps=22091.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.406, loss_scale=32, train_wall=260, gb_free=21.5, wall=58353
2022-03-07 12:53:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:53:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:53:22 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 11.207 | ppl 2364.38 | wps 39219.7 | wpb 510.9 | bsz 1 | num_updates 19720 | best_loss 8.621
2022-03-07 12:53:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19720 updates
2022-03-07 12:53:22 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-07 12:53:22 | INFO | train | epoch 405 | loss 1.821 | ppl 3.53 | wps 21617.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 19720 | lr 0.000225189 | gnorm 0.403 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 58417
2022-03-07 12:53:22 | INFO | fairseq.trainer | begin training epoch 406
2022-03-07 12:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:55:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:55:46 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 11.242 | ppl 2421.3 | wps 39029.5 | wpb 510.9 | bsz 1 | num_updates 19769 | best_loss 8.621
2022-03-07 12:55:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19769 updates
2022-03-07 12:55:46 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-07 12:55:46 | INFO | train | epoch 406 | loss 1.823 | ppl 3.54 | wps 22051.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19769 | lr 0.000224909 | gnorm 0.408 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 58561
2022-03-07 12:55:46 | INFO | fairseq.trainer | begin training epoch 407
2022-03-07 12:55:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:57:15 | INFO | train_inner | epoch 407:     31 / 49 loss=1.822, ppl=3.54, wps=21860.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.405, loss_scale=32, train_wall=262, gb_free=21.5, wall=58650
2022-03-07 12:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:58:10 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 11.236 | ppl 2412.31 | wps 39212.1 | wpb 510.9 | bsz 1 | num_updates 19818 | best_loss 8.621
2022-03-07 12:58:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19818 updates
2022-03-07 12:58:10 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-07 12:58:10 | INFO | train | epoch 407 | loss 1.822 | ppl 3.53 | wps 22059.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19818 | lr 0.000224631 | gnorm 0.404 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 58705
2022-03-07 12:58:10 | INFO | fairseq.trainer | begin training epoch 408
2022-03-07 12:58:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:59:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:00:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:00:34 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 11.248 | ppl 2432.23 | wps 38674.1 | wpb 510.9 | bsz 1 | num_updates 19866 | best_loss 8.621
2022-03-07 13:00:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19866 updates
2022-03-07 13:00:34 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-07 13:00:34 | INFO | train | epoch 408 | loss 1.821 | ppl 3.53 | wps 21607 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 19866 | lr 0.00022436 | gnorm 0.4 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 58850
2022-03-07 13:00:34 | INFO | fairseq.trainer | begin training epoch 409
2022-03-07 13:00:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:02:11 | INFO | train_inner | epoch 409:     34 / 49 loss=1.821, ppl=3.53, wps=21871.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.403, loss_scale=32, train_wall=262, gb_free=21.5, wall=58947
2022-03-07 13:02:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:02:58 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 11.236 | ppl 2412.26 | wps 39165.5 | wpb 510.9 | bsz 1 | num_updates 19915 | best_loss 8.621
2022-03-07 13:02:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19915 updates
2022-03-07 13:02:58 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-07 13:02:58 | INFO | train | epoch 409 | loss 1.821 | ppl 3.53 | wps 22071.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19915 | lr 0.000224083 | gnorm 0.401 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 58993
2022-03-07 13:02:58 | INFO | fairseq.trainer | begin training epoch 410
2022-03-07 13:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:05:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:05:22 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 11.227 | ppl 2396.84 | wps 39085.7 | wpb 510.9 | bsz 1 | num_updates 19964 | best_loss 8.621
2022-03-07 13:05:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19964 updates
2022-03-07 13:05:22 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-07 13:05:22 | INFO | train | epoch 410 | loss 1.82 | ppl 3.53 | wps 22063.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19964 | lr 0.000223808 | gnorm 0.403 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 59138
2022-03-07 13:05:22 | INFO | fairseq.trainer | begin training epoch 411
2022-03-07 13:05:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:05:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:07:08 | INFO | train_inner | epoch 411:     37 / 49 loss=1.82, ppl=3.53, wps=21879.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20000, lr=0.000223607, gnorm=0.402, loss_scale=32, train_wall=262, gb_free=21.5, wall=59243
2022-03-07 13:07:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:07:46 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 11.262 | ppl 2455.36 | wps 39206.3 | wpb 510.9 | bsz 1 | num_updates 20012 | best_loss 8.621
2022-03-07 13:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 20012 updates
2022-03-07 13:07:46 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-07 13:07:46 | INFO | train | epoch 411 | loss 1.819 | ppl 3.53 | wps 21622.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 20012 | lr 0.00022354 | gnorm 0.404 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 59281
2022-03-07 13:07:46 | INFO | fairseq.trainer | begin training epoch 412
2022-03-07 13:07:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:08:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:10:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:10:10 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 11.254 | ppl 2441.99 | wps 39094.7 | wpb 510.9 | bsz 1 | num_updates 20060 | best_loss 8.621
2022-03-07 13:10:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20060 updates
2022-03-07 13:10:10 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-07 13:10:10 | INFO | train | epoch 412 | loss 1.819 | ppl 3.53 | wps 21614.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 20060 | lr 0.000223272 | gnorm 0.407 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 59425
2022-03-07 13:10:10 | INFO | fairseq.trainer | begin training epoch 413
2022-03-07 13:10:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:12:04 | INFO | train_inner | epoch 413:     40 / 49 loss=1.819, ppl=3.53, wps=21866.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20100, lr=0.00022305, gnorm=0.404, loss_scale=16, train_wall=262, gb_free=21.5, wall=59540
2022-03-07 13:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:12:34 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 11.235 | ppl 2409.72 | wps 39149.8 | wpb 510.9 | bsz 1 | num_updates 20109 | best_loss 8.621
2022-03-07 13:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20109 updates
2022-03-07 13:12:34 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-07 13:12:34 | INFO | train | epoch 413 | loss 1.819 | ppl 3.53 | wps 22054.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20109 | lr 0.000223 | gnorm 0.401 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 59570
2022-03-07 13:12:34 | INFO | fairseq.trainer | begin training epoch 414
2022-03-07 13:12:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:14:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:14:58 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 11.277 | ppl 2480.76 | wps 39152.1 | wpb 510.9 | bsz 1 | num_updates 20158 | best_loss 8.621
2022-03-07 13:14:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20158 updates
2022-03-07 13:14:58 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-07 13:14:58 | INFO | train | epoch 414 | loss 1.817 | ppl 3.52 | wps 22045.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20158 | lr 0.000222729 | gnorm 0.398 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 59714
2022-03-07 13:14:59 | INFO | fairseq.trainer | begin training epoch 415
2022-03-07 13:14:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:16:58 | INFO | train_inner | epoch 415:     42 / 49 loss=1.817, ppl=3.52, wps=22073.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.4, loss_scale=32, train_wall=260, gb_free=21.5, wall=59834
2022-03-07 13:17:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:17:22 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 11.235 | ppl 2410.39 | wps 39216.8 | wpb 510.9 | bsz 1 | num_updates 20207 | best_loss 8.621
2022-03-07 13:17:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20207 updates
2022-03-07 13:17:22 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-07 13:17:22 | INFO | train | epoch 415 | loss 1.817 | ppl 3.52 | wps 22071.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20207 | lr 0.000222459 | gnorm 0.402 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 59858
2022-03-07 13:17:23 | INFO | fairseq.trainer | begin training epoch 416
2022-03-07 13:17:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:19:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:19:47 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 11.266 | ppl 2462.52 | wps 39205 | wpb 510.9 | bsz 1 | num_updates 20256 | best_loss 8.621
2022-03-07 13:19:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20256 updates
2022-03-07 13:19:47 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-07 13:19:47 | INFO | train | epoch 416 | loss 1.816 | ppl 3.52 | wps 22057.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20256 | lr 0.000222189 | gnorm 0.399 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 60002
2022-03-07 13:19:47 | INFO | fairseq.trainer | begin training epoch 417
2022-03-07 13:19:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:20:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:21:55 | INFO | train_inner | epoch 417:     45 / 49 loss=1.817, ppl=3.52, wps=21876.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.399, loss_scale=32, train_wall=262, gb_free=21.5, wall=60130
2022-03-07 13:22:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:22:11 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 11.269 | ppl 2468.62 | wps 39064.6 | wpb 510.9 | bsz 1 | num_updates 20304 | best_loss 8.621
2022-03-07 13:22:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20304 updates
2022-03-07 13:22:11 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-07 13:22:11 | INFO | train | epoch 417 | loss 1.816 | ppl 3.52 | wps 21623.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 20304 | lr 0.000221927 | gnorm 0.399 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 60146
2022-03-07 13:22:11 | INFO | fairseq.trainer | begin training epoch 418
2022-03-07 13:22:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:24:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:24:35 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 11.248 | ppl 2432.17 | wps 39061.3 | wpb 510.9 | bsz 1 | num_updates 20353 | best_loss 8.621
2022-03-07 13:24:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20353 updates
2022-03-07 13:24:35 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-07 13:24:35 | INFO | train | epoch 418 | loss 1.816 | ppl 3.52 | wps 22055.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20353 | lr 0.000221659 | gnorm 0.398 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 60290
2022-03-07 13:24:35 | INFO | fairseq.trainer | begin training epoch 419
2022-03-07 13:24:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:26:49 | INFO | train_inner | epoch 419:     47 / 49 loss=1.815, ppl=3.52, wps=22079.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.397, loss_scale=32, train_wall=260, gb_free=21.5, wall=60424
2022-03-07 13:26:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:26:59 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 11.249 | ppl 2433.54 | wps 39150.7 | wpb 510.9 | bsz 1 | num_updates 20402 | best_loss 8.621
2022-03-07 13:26:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20402 updates
2022-03-07 13:26:59 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-07 13:26:59 | INFO | train | epoch 419 | loss 1.814 | ppl 3.52 | wps 22068.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20402 | lr 0.000221393 | gnorm 0.394 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 60434
2022-03-07 13:26:59 | INFO | fairseq.trainer | begin training epoch 420
2022-03-07 13:26:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:27:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:29:23 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 11.24 | ppl 2418.94 | wps 39024.7 | wpb 510.9 | bsz 1 | num_updates 20450 | best_loss 8.621
2022-03-07 13:29:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20450 updates
2022-03-07 13:29:23 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-07 13:29:23 | INFO | train | epoch 420 | loss 1.815 | ppl 3.52 | wps 21604.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 20450 | lr 0.000221133 | gnorm 0.399 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 60578
2022-03-07 13:29:23 | INFO | fairseq.trainer | begin training epoch 421
2022-03-07 13:29:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:31:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:31:47 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 11.23 | ppl 2401.22 | wps 39154.5 | wpb 510.9 | bsz 1 | num_updates 20499 | best_loss 8.621
2022-03-07 13:31:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20499 updates
2022-03-07 13:31:47 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-07 13:31:47 | INFO | train | epoch 421 | loss 1.814 | ppl 3.52 | wps 22081 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20499 | lr 0.000220868 | gnorm 0.399 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 60722
2022-03-07 13:31:47 | INFO | fairseq.trainer | begin training epoch 422
2022-03-07 13:31:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:31:50 | INFO | train_inner | epoch 422:      1 / 49 loss=1.815, ppl=3.52, wps=21453.5, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=20500, lr=0.000220863, gnorm=0.4, loss_scale=32, train_wall=261, gb_free=21.5, wall=60725
2022-03-07 13:33:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:34:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:34:11 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 11.24 | ppl 2419.28 | wps 39319 | wpb 510.9 | bsz 1 | num_updates 20547 | best_loss 8.621
2022-03-07 13:34:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20547 updates
2022-03-07 13:34:11 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-07 13:34:11 | INFO | train | epoch 422 | loss 1.814 | ppl 3.51 | wps 21622.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 20547 | lr 0.00022061 | gnorm 0.403 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 60866
2022-03-07 13:34:11 | INFO | fairseq.trainer | begin training epoch 423
2022-03-07 13:34:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:34:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:36:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:36:35 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 11.24 | ppl 2417.94 | wps 39261.1 | wpb 510.9 | bsz 1 | num_updates 20595 | best_loss 8.621
2022-03-07 13:36:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20595 updates
2022-03-07 13:36:35 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-07 13:36:35 | INFO | train | epoch 423 | loss 1.813 | ppl 3.51 | wps 21607.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 20595 | lr 0.000220353 | gnorm 0.397 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 61010
2022-03-07 13:36:35 | INFO | fairseq.trainer | begin training epoch 424
2022-03-07 13:36:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:36:49 | INFO | train_inner | epoch 424:      5 / 49 loss=1.813, ppl=3.51, wps=21667.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.399, loss_scale=16, train_wall=265, gb_free=21.5, wall=61024
2022-03-07 13:38:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:38:59 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 11.254 | ppl 2442.97 | wps 39180.4 | wpb 510.9 | bsz 1 | num_updates 20644 | best_loss 8.621
2022-03-07 13:38:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20644 updates
2022-03-07 13:38:59 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-07 13:38:59 | INFO | train | epoch 424 | loss 1.812 | ppl 3.51 | wps 22070.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20644 | lr 0.000220091 | gnorm 0.396 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 61154
2022-03-07 13:38:59 | INFO | fairseq.trainer | begin training epoch 425
2022-03-07 13:38:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:41:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:41:23 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 11.249 | ppl 2433.31 | wps 38979.4 | wpb 510.9 | bsz 1 | num_updates 20693 | best_loss 8.621
2022-03-07 13:41:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20693 updates
2022-03-07 13:41:23 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-07 13:41:23 | INFO | train | epoch 425 | loss 1.812 | ppl 3.51 | wps 22065.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20693 | lr 0.000219831 | gnorm 0.395 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 61298
2022-03-07 13:41:23 | INFO | fairseq.trainer | begin training epoch 426
2022-03-07 13:41:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:41:43 | INFO | train_inner | epoch 426:      7 / 49 loss=1.812, ppl=3.51, wps=22085.9, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.396, loss_scale=32, train_wall=260, gb_free=21.5, wall=61318
2022-03-07 13:43:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:43:47 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 11.21 | ppl 2368.8 | wps 39212.5 | wpb 510.9 | bsz 1 | num_updates 20742 | best_loss 8.621
2022-03-07 13:43:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20742 updates
2022-03-07 13:43:47 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-07 13:43:47 | INFO | train | epoch 426 | loss 1.812 | ppl 3.51 | wps 22067.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20742 | lr 0.000219571 | gnorm 0.396 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 61442
2022-03-07 13:43:47 | INFO | fairseq.trainer | begin training epoch 427
2022-03-07 13:43:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:46:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:46:11 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 11.231 | ppl 2404.17 | wps 38715.5 | wpb 510.9 | bsz 1 | num_updates 20791 | best_loss 8.621
2022-03-07 13:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20791 updates
2022-03-07 13:46:11 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-07 13:46:11 | INFO | train | epoch 427 | loss 1.812 | ppl 3.51 | wps 22047.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20791 | lr 0.000219312 | gnorm 0.399 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 61586
2022-03-07 13:46:11 | INFO | fairseq.trainer | begin training epoch 428
2022-03-07 13:46:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:46:37 | INFO | train_inner | epoch 428:      9 / 49 loss=1.811, ppl=3.51, wps=22074.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.398, loss_scale=32, train_wall=260, gb_free=21.5, wall=61612
2022-03-07 13:47:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:48:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:48:35 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 11.233 | ppl 2407.11 | wps 39226.6 | wpb 510.9 | bsz 1 | num_updates 20839 | best_loss 8.621
2022-03-07 13:48:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20839 updates
2022-03-07 13:48:35 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-07 13:48:35 | INFO | train | epoch 428 | loss 1.811 | ppl 3.51 | wps 21627.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 20839 | lr 0.000219059 | gnorm 0.4 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 61730
2022-03-07 13:48:35 | INFO | fairseq.trainer | begin training epoch 429
2022-03-07 13:48:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:50:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:50:59 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 11.251 | ppl 2436.47 | wps 39015.6 | wpb 510.9 | bsz 1 | num_updates 20888 | best_loss 8.621
2022-03-07 13:50:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20888 updates
2022-03-07 13:50:59 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-07 13:50:59 | INFO | train | epoch 429 | loss 1.81 | ppl 3.51 | wps 22064.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20888 | lr 0.000218802 | gnorm 0.396 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 61874
2022-03-07 13:50:59 | INFO | fairseq.trainer | begin training epoch 430
2022-03-07 13:50:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:51:33 | INFO | train_inner | epoch 430:     12 / 49 loss=1.81, ppl=3.51, wps=21880.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.398, loss_scale=32, train_wall=262, gb_free=21.5, wall=61908
2022-03-07 13:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:53:23 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 11.239 | ppl 2416.94 | wps 39118.3 | wpb 510.9 | bsz 1 | num_updates 20937 | best_loss 8.621
2022-03-07 13:53:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20937 updates
2022-03-07 13:53:23 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-07 13:53:23 | INFO | train | epoch 430 | loss 1.809 | ppl 3.5 | wps 22067.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20937 | lr 0.000218546 | gnorm 0.393 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 62018
2022-03-07 13:53:23 | INFO | fairseq.trainer | begin training epoch 431
2022-03-07 13:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:54:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:55:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:55:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:55:47 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 11.26 | ppl 2453 | wps 39149 | wpb 510.9 | bsz 1 | num_updates 20984 | best_loss 8.621
2022-03-07 13:55:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20984 updates
2022-03-07 13:55:47 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-07 13:55:47 | INFO | train | epoch 431 | loss 1.808 | ppl 3.5 | wps 21166.7 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 20984 | lr 0.000218301 | gnorm 0.39 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 62162
2022-03-07 13:55:47 | INFO | fairseq.trainer | begin training epoch 432
2022-03-07 13:55:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:56:32 | INFO | train_inner | epoch 432:     16 / 49 loss=1.808, ppl=3.5, wps=21670.1, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.391, loss_scale=16, train_wall=265, gb_free=21.5, wall=62208
2022-03-07 13:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:58:11 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 11.213 | ppl 2374.06 | wps 39281.7 | wpb 510.9 | bsz 1 | num_updates 21033 | best_loss 8.621
2022-03-07 13:58:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21033 updates
2022-03-07 13:58:11 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-07 13:58:11 | INFO | train | epoch 432 | loss 1.809 | ppl 3.5 | wps 22076.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21033 | lr 0.000218047 | gnorm 0.394 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 62306
2022-03-07 13:58:11 | INFO | fairseq.trainer | begin training epoch 433
2022-03-07 13:58:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:00:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:00:35 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 11.265 | ppl 2461.01 | wps 39171.3 | wpb 510.9 | bsz 1 | num_updates 21082 | best_loss 8.621
2022-03-07 14:00:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21082 updates
2022-03-07 14:00:35 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-07 14:00:35 | INFO | train | epoch 433 | loss 1.808 | ppl 3.5 | wps 22075.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21082 | lr 0.000217793 | gnorm 0.399 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 62450
2022-03-07 14:00:35 | INFO | fairseq.trainer | begin training epoch 434
2022-03-07 14:00:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:01:26 | INFO | train_inner | epoch 434:     18 / 49 loss=1.808, ppl=3.5, wps=22087, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.398, loss_scale=32, train_wall=260, gb_free=21.5, wall=62501
2022-03-07 14:02:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:02:59 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 11.232 | ppl 2405.69 | wps 39048.9 | wpb 510.9 | bsz 1 | num_updates 21131 | best_loss 8.621
2022-03-07 14:02:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21131 updates
2022-03-07 14:02:59 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-07 14:02:59 | INFO | train | epoch 434 | loss 1.808 | ppl 3.5 | wps 22048.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21131 | lr 0.00021754 | gnorm 0.399 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 62594
2022-03-07 14:02:59 | INFO | fairseq.trainer | begin training epoch 435
2022-03-07 14:02:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:05:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:05:23 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 11.253 | ppl 2439.86 | wps 39324.1 | wpb 510.9 | bsz 1 | num_updates 21180 | best_loss 8.621
2022-03-07 14:05:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21180 updates
2022-03-07 14:05:23 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-07 14:05:23 | INFO | train | epoch 435 | loss 1.806 | ppl 3.5 | wps 22068.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21180 | lr 0.000217289 | gnorm 0.387 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 62738
2022-03-07 14:05:23 | INFO | fairseq.trainer | begin training epoch 436
2022-03-07 14:05:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:06:20 | INFO | train_inner | epoch 436:     20 / 49 loss=1.806, ppl=3.5, wps=22075.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.392, loss_scale=32, train_wall=260, gb_free=21.5, wall=62795
2022-03-07 14:07:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:07:47 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 11.259 | ppl 2450.05 | wps 39240.4 | wpb 510.9 | bsz 1 | num_updates 21229 | best_loss 8.621
2022-03-07 14:07:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21229 updates
2022-03-07 14:07:47 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-07 14:07:47 | INFO | train | epoch 436 | loss 1.806 | ppl 3.5 | wps 22057.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21229 | lr 0.000217038 | gnorm 0.391 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 62882
2022-03-07 14:07:47 | INFO | fairseq.trainer | begin training epoch 437
2022-03-07 14:07:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:07:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:10:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:10:11 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 11.249 | ppl 2434.12 | wps 39093.3 | wpb 510.9 | bsz 1 | num_updates 21277 | best_loss 8.621
2022-03-07 14:10:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21277 updates
2022-03-07 14:10:11 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-07 14:10:11 | INFO | train | epoch 437 | loss 1.805 | ppl 3.49 | wps 21603.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 21277 | lr 0.000216793 | gnorm 0.387 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 63026
2022-03-07 14:10:11 | INFO | fairseq.trainer | begin training epoch 438
2022-03-07 14:10:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:11:17 | INFO | train_inner | epoch 438:     23 / 49 loss=1.806, ppl=3.5, wps=21868, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.39, loss_scale=32, train_wall=262, gb_free=21.5, wall=63092
2022-03-07 14:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:12:35 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 11.214 | ppl 2374.9 | wps 39136.3 | wpb 510.9 | bsz 1 | num_updates 21326 | best_loss 8.621
2022-03-07 14:12:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21326 updates
2022-03-07 14:12:35 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-07 14:12:35 | INFO | train | epoch 438 | loss 1.805 | ppl 3.5 | wps 22077 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21326 | lr 0.000216544 | gnorm 0.393 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 63170
2022-03-07 14:12:35 | INFO | fairseq.trainer | begin training epoch 439
2022-03-07 14:12:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:14:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:14:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:14:59 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 11.206 | ppl 2362.52 | wps 39277.5 | wpb 510.9 | bsz 1 | num_updates 21374 | best_loss 8.621
2022-03-07 14:14:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21374 updates
2022-03-07 14:14:59 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-07 14:14:59 | INFO | train | epoch 439 | loss 1.805 | ppl 3.49 | wps 21622.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 21374 | lr 0.0002163 | gnorm 0.394 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 63314
2022-03-07 14:14:59 | INFO | fairseq.trainer | begin training epoch 440
2022-03-07 14:14:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:16:13 | INFO | train_inner | epoch 440:     26 / 49 loss=1.805, ppl=3.49, wps=21882, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.392, loss_scale=32, train_wall=262, gb_free=21.5, wall=63388
2022-03-07 14:17:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:17:23 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 11.248 | ppl 2432.77 | wps 39238.9 | wpb 510.9 | bsz 1 | num_updates 21423 | best_loss 8.621
2022-03-07 14:17:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21423 updates
2022-03-07 14:17:23 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-07 14:17:23 | INFO | train | epoch 440 | loss 1.804 | ppl 3.49 | wps 22066.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21423 | lr 0.000216053 | gnorm 0.392 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 63458
2022-03-07 14:17:23 | INFO | fairseq.trainer | begin training epoch 441
2022-03-07 14:17:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:19:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:19:47 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 11.233 | ppl 2407.62 | wps 39092.2 | wpb 510.9 | bsz 1 | num_updates 21472 | best_loss 8.621
2022-03-07 14:19:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21472 updates
2022-03-07 14:19:47 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-07 14:19:47 | INFO | train | epoch 441 | loss 1.804 | ppl 3.49 | wps 22069.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21472 | lr 0.000215806 | gnorm 0.391 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 63602
2022-03-07 14:19:47 | INFO | fairseq.trainer | begin training epoch 442
2022-03-07 14:19:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:21:07 | INFO | train_inner | epoch 442:     28 / 49 loss=1.804, ppl=3.49, wps=22082.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.391, loss_scale=64, train_wall=260, gb_free=21.5, wall=63682
2022-03-07 14:21:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:22:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:22:11 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 11.242 | ppl 2422.12 | wps 39170.5 | wpb 510.9 | bsz 1 | num_updates 21520 | best_loss 8.621
2022-03-07 14:22:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21520 updates
2022-03-07 14:22:11 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-07 14:22:11 | INFO | train | epoch 442 | loss 1.803 | ppl 3.49 | wps 21610.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 21520 | lr 0.000215565 | gnorm 0.39 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 63746
2022-03-07 14:22:11 | INFO | fairseq.trainer | begin training epoch 443
2022-03-07 14:22:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:24:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:24:35 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 11.231 | ppl 2404.34 | wps 39252.6 | wpb 510.9 | bsz 1 | num_updates 21569 | best_loss 8.621
2022-03-07 14:24:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21569 updates
2022-03-07 14:24:35 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-07 14:24:35 | INFO | train | epoch 443 | loss 1.803 | ppl 3.49 | wps 22052.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21569 | lr 0.00021532 | gnorm 0.39 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 63890
2022-03-07 14:24:35 | INFO | fairseq.trainer | begin training epoch 444
2022-03-07 14:24:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:26:03 | INFO | train_inner | epoch 444:     31 / 49 loss=1.803, ppl=3.49, wps=21868.6, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.391, loss_scale=32, train_wall=262, gb_free=21.5, wall=63979
2022-03-07 14:26:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:26:59 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 11.208 | ppl 2365.79 | wps 39123.1 | wpb 510.9 | bsz 1 | num_updates 21618 | best_loss 8.621
2022-03-07 14:26:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21618 updates
2022-03-07 14:26:59 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-07 14:26:59 | INFO | train | epoch 444 | loss 1.803 | ppl 3.49 | wps 22062.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21618 | lr 0.000215076 | gnorm 0.393 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 64034
2022-03-07 14:26:59 | INFO | fairseq.trainer | begin training epoch 445
2022-03-07 14:26:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:27:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:29:23 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 11.244 | ppl 2425.77 | wps 39139.8 | wpb 510.9 | bsz 1 | num_updates 21666 | best_loss 8.621
2022-03-07 14:29:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21666 updates
2022-03-07 14:29:23 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-07 14:29:23 | INFO | train | epoch 445 | loss 1.802 | ppl 3.49 | wps 21613.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 21666 | lr 0.000214838 | gnorm 0.393 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 64178
2022-03-07 14:29:23 | INFO | fairseq.trainer | begin training epoch 446
2022-03-07 14:29:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:31:00 | INFO | train_inner | epoch 446:     34 / 49 loss=1.802, ppl=3.49, wps=21872.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.39, loss_scale=32, train_wall=262, gb_free=21.5, wall=64275
2022-03-07 14:31:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:31:47 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 11.244 | ppl 2424.61 | wps 39768.4 | wpb 510.9 | bsz 1 | num_updates 21715 | best_loss 8.621
2022-03-07 14:31:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21715 updates
2022-03-07 14:31:47 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-07 14:31:47 | INFO | train | epoch 446 | loss 1.801 | ppl 3.48 | wps 22070.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21715 | lr 0.000214595 | gnorm 0.387 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 64322
2022-03-07 14:31:47 | INFO | fairseq.trainer | begin training epoch 447
2022-03-07 14:31:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:34:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:34:11 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 11.238 | ppl 2414.79 | wps 39236.6 | wpb 510.9 | bsz 1 | num_updates 21764 | best_loss 8.621
2022-03-07 14:34:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21764 updates
2022-03-07 14:34:11 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-07 14:34:11 | INFO | train | epoch 447 | loss 1.801 | ppl 3.48 | wps 22039.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21764 | lr 0.000214354 | gnorm 0.387 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 64466
2022-03-07 14:34:11 | INFO | fairseq.trainer | begin training epoch 448
2022-03-07 14:34:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:34:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:35:57 | INFO | train_inner | epoch 448:     37 / 49 loss=1.801, ppl=3.48, wps=21851.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=21800, lr=0.000214176, gnorm=0.387, loss_scale=32, train_wall=263, gb_free=21.5, wall=64572
2022-03-07 14:36:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:36:35 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 11.234 | ppl 2408.25 | wps 39184.7 | wpb 510.9 | bsz 1 | num_updates 21812 | best_loss 8.621
2022-03-07 14:36:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21812 updates
2022-03-07 14:36:35 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-07 14:36:35 | INFO | train | epoch 448 | loss 1.801 | ppl 3.48 | wps 21594.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 21812 | lr 0.000214118 | gnorm 0.386 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 64611
2022-03-07 14:36:35 | INFO | fairseq.trainer | begin training epoch 449
2022-03-07 14:36:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:38:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:38:59 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 11.247 | ppl 2430.16 | wps 39064.7 | wpb 510.9 | bsz 1 | num_updates 21861 | best_loss 8.621
2022-03-07 14:38:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21861 updates
2022-03-07 14:38:59 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-07 14:38:59 | INFO | train | epoch 449 | loss 1.801 | ppl 3.48 | wps 22064.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21861 | lr 0.000213877 | gnorm 0.389 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 64755
2022-03-07 14:38:59 | INFO | fairseq.trainer | begin training epoch 450
2022-03-07 14:38:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:40:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:40:54 | INFO | train_inner | epoch 450:     40 / 49 loss=1.801, ppl=3.48, wps=21867.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=21900, lr=0.000213687, gnorm=0.391, loss_scale=32, train_wall=262, gb_free=21.5, wall=64869
2022-03-07 14:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:41:23 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 11.234 | ppl 2408.97 | wps 39219.8 | wpb 510.9 | bsz 1 | num_updates 21909 | best_loss 8.621
2022-03-07 14:41:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21909 updates
2022-03-07 14:41:23 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-07 14:41:23 | INFO | train | epoch 450 | loss 1.8 | ppl 3.48 | wps 21608.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 21909 | lr 0.000213643 | gnorm 0.393 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 64899
2022-03-07 14:41:23 | INFO | fairseq.trainer | begin training epoch 451
2022-03-07 14:41:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:43:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:43:47 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 11.239 | ppl 2416.6 | wps 39115.2 | wpb 510.9 | bsz 1 | num_updates 21958 | best_loss 8.621
2022-03-07 14:43:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21958 updates
2022-03-07 14:43:47 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-07 14:43:47 | INFO | train | epoch 451 | loss 1.799 | ppl 3.48 | wps 22080.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21958 | lr 0.000213405 | gnorm 0.388 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 65043
2022-03-07 14:43:47 | INFO | fairseq.trainer | begin training epoch 452
2022-03-07 14:43:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:45:47 | INFO | train_inner | epoch 452:     42 / 49 loss=1.799, ppl=3.48, wps=22088.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.387, loss_scale=32, train_wall=260, gb_free=21.5, wall=65163
2022-03-07 14:46:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:46:11 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 11.238 | ppl 2415.57 | wps 39112.2 | wpb 510.9 | bsz 1 | num_updates 22007 | best_loss 8.621
2022-03-07 14:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 22007 updates
2022-03-07 14:46:11 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-07 14:46:11 | INFO | train | epoch 452 | loss 1.799 | ppl 3.48 | wps 22055.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22007 | lr 0.000213167 | gnorm 0.387 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 65187
2022-03-07 14:46:11 | INFO | fairseq.trainer | begin training epoch 453
2022-03-07 14:46:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:47:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:48:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:48:35 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 11.217 | ppl 2379.78 | wps 39791.6 | wpb 510.9 | bsz 1 | num_updates 22055 | best_loss 8.621
2022-03-07 14:48:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22055 updates
2022-03-07 14:48:35 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-07 14:48:35 | INFO | train | epoch 453 | loss 1.798 | ppl 3.48 | wps 21633.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 22055 | lr 0.000212935 | gnorm 0.387 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 65331
2022-03-07 14:48:35 | INFO | fairseq.trainer | begin training epoch 454
2022-03-07 14:48:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:50:44 | INFO | train_inner | epoch 454:     45 / 49 loss=1.798, ppl=3.48, wps=21882.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.387, loss_scale=32, train_wall=262, gb_free=21.5, wall=65459
2022-03-07 14:50:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:50:59 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 11.239 | ppl 2416.29 | wps 39325.2 | wpb 510.9 | bsz 1 | num_updates 22104 | best_loss 8.621
2022-03-07 14:50:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22104 updates
2022-03-07 14:50:59 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-07 14:50:59 | INFO | train | epoch 454 | loss 1.798 | ppl 3.48 | wps 22069.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22104 | lr 0.000212699 | gnorm 0.386 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 65475
2022-03-07 14:50:59 | INFO | fairseq.trainer | begin training epoch 455
2022-03-07 14:50:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:53:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:53:23 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 11.227 | ppl 2396.32 | wps 39071.3 | wpb 510.9 | bsz 1 | num_updates 22153 | best_loss 8.621
2022-03-07 14:53:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22153 updates
2022-03-07 14:53:23 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-07 14:53:23 | INFO | train | epoch 455 | loss 1.797 | ppl 3.48 | wps 22055.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22153 | lr 0.000212463 | gnorm 0.384 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 65619
2022-03-07 14:53:23 | INFO | fairseq.trainer | begin training epoch 456
2022-03-07 14:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:54:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:55:40 | INFO | train_inner | epoch 456:     48 / 49 loss=1.798, ppl=3.48, wps=21865.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.389, loss_scale=32, train_wall=262, gb_free=21.5, wall=65756
2022-03-07 14:55:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:55:48 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 11.202 | ppl 2356.15 | wps 39071.2 | wpb 510.9 | bsz 1 | num_updates 22201 | best_loss 8.621
2022-03-07 14:55:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22201 updates
2022-03-07 14:55:48 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-07 14:55:48 | INFO | train | epoch 456 | loss 1.798 | ppl 3.48 | wps 21605.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 22201 | lr 0.000212233 | gnorm 0.392 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 65763
2022-03-07 14:55:48 | INFO | fairseq.trainer | begin training epoch 457
2022-03-07 14:55:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:58:12 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 11.235 | ppl 2409.95 | wps 39052.8 | wpb 510.9 | bsz 1 | num_updates 22250 | best_loss 8.621
2022-03-07 14:58:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22250 updates
2022-03-07 14:58:12 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-07 14:58:12 | INFO | train | epoch 457 | loss 1.797 | ppl 3.47 | wps 22058 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22250 | lr 0.000212 | gnorm 0.388 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 65907
2022-03-07 14:58:12 | INFO | fairseq.trainer | begin training epoch 458
2022-03-07 14:58:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:00:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:00:36 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 11.238 | ppl 2414.71 | wps 38986.1 | wpb 510.9 | bsz 1 | num_updates 22299 | best_loss 8.621
2022-03-07 15:00:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22299 updates
2022-03-07 15:00:36 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-07 15:00:36 | INFO | train | epoch 458 | loss 1.796 | ppl 3.47 | wps 22041.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22299 | lr 0.000211767 | gnorm 0.386 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 66051
2022-03-07 15:00:36 | INFO | fairseq.trainer | begin training epoch 459
2022-03-07 15:00:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:00:39 | INFO | train_inner | epoch 459:      1 / 49 loss=1.796, ppl=3.47, wps=21638.3, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=22300, lr=0.000211762, gnorm=0.387, loss_scale=32, train_wall=259, gb_free=21.5, wall=66054
2022-03-07 15:01:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:02:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:03:00 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 11.237 | ppl 2413.69 | wps 39265.5 | wpb 510.9 | bsz 1 | num_updates 22347 | best_loss 8.621
2022-03-07 15:03:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22347 updates
2022-03-07 15:03:00 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-07 15:03:00 | INFO | train | epoch 459 | loss 1.795 | ppl 3.47 | wps 21622.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 22347 | lr 0.000211539 | gnorm 0.383 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 66195
2022-03-07 15:03:00 | INFO | fairseq.trainer | begin training epoch 460
2022-03-07 15:03:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:05:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:05:24 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 11.203 | ppl 2357.56 | wps 39633 | wpb 510.9 | bsz 1 | num_updates 22396 | best_loss 8.621
2022-03-07 15:05:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22396 updates
2022-03-07 15:05:24 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-07 15:05:24 | INFO | train | epoch 460 | loss 1.796 | ppl 3.47 | wps 22065.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22396 | lr 0.000211307 | gnorm 0.384 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 66339
2022-03-07 15:05:24 | INFO | fairseq.trainer | begin training epoch 461
2022-03-07 15:05:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:05:35 | INFO | train_inner | epoch 461:      4 / 49 loss=1.795, ppl=3.47, wps=21878.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.383, loss_scale=32, train_wall=262, gb_free=21.5, wall=66350
2022-03-07 15:07:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:07:48 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 11.232 | ppl 2404.99 | wps 39016.8 | wpb 510.9 | bsz 1 | num_updates 22445 | best_loss 8.621
2022-03-07 15:07:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22445 updates
2022-03-07 15:07:48 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-07 15:07:48 | INFO | train | epoch 461 | loss 1.794 | ppl 3.47 | wps 22043.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22445 | lr 0.000211077 | gnorm 0.383 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 66483
2022-03-07 15:07:48 | INFO | fairseq.trainer | begin training epoch 462
2022-03-07 15:07:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:07:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:10:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:10:12 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 11.254 | ppl 2442.17 | wps 39143.7 | wpb 510.9 | bsz 1 | num_updates 22493 | best_loss 8.621
2022-03-07 15:10:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22493 updates
2022-03-07 15:10:12 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-07 15:10:12 | INFO | train | epoch 462 | loss 1.794 | ppl 3.47 | wps 21623.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 22493 | lr 0.000210851 | gnorm 0.382 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 66627
2022-03-07 15:10:12 | INFO | fairseq.trainer | begin training epoch 463
2022-03-07 15:10:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:10:32 | INFO | train_inner | epoch 463:      7 / 49 loss=1.794, ppl=3.47, wps=21866.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.383, loss_scale=32, train_wall=262, gb_free=21.5, wall=66647
2022-03-07 15:12:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:12:36 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 11.236 | ppl 2412.69 | wps 39275.8 | wpb 510.9 | bsz 1 | num_updates 22542 | best_loss 8.621
2022-03-07 15:12:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22542 updates
2022-03-07 15:12:36 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-07 15:12:36 | INFO | train | epoch 463 | loss 1.794 | ppl 3.47 | wps 22058.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22542 | lr 0.000210622 | gnorm 0.381 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 66771
2022-03-07 15:12:36 | INFO | fairseq.trainer | begin training epoch 464
2022-03-07 15:12:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:14:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:15:00 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 11.247 | ppl 2430.83 | wps 39272.6 | wpb 510.9 | bsz 1 | num_updates 22591 | best_loss 8.621
2022-03-07 15:15:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22591 updates
2022-03-07 15:15:00 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-07 15:15:00 | INFO | train | epoch 464 | loss 1.793 | ppl 3.47 | wps 22068.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22591 | lr 0.000210393 | gnorm 0.38 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 66915
2022-03-07 15:15:00 | INFO | fairseq.trainer | begin training epoch 465
2022-03-07 15:15:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:15:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:15:29 | INFO | train_inner | epoch 465:     10 / 49 loss=1.793, ppl=3.47, wps=21869.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.38, loss_scale=32, train_wall=262, gb_free=21.5, wall=66944
2022-03-07 15:17:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:17:24 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 11.251 | ppl 2436.58 | wps 39105.6 | wpb 510.9 | bsz 1 | num_updates 22639 | best_loss 8.621
2022-03-07 15:17:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22639 updates
2022-03-07 15:17:24 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-07 15:17:24 | INFO | train | epoch 465 | loss 1.793 | ppl 3.46 | wps 21608.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 22639 | lr 0.00021017 | gnorm 0.389 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 67059
2022-03-07 15:17:24 | INFO | fairseq.trainer | begin training epoch 466
2022-03-07 15:17:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:19:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:19:48 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 11.213 | ppl 2373.66 | wps 39040.3 | wpb 510.9 | bsz 1 | num_updates 22688 | best_loss 8.621
2022-03-07 15:19:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22688 updates
2022-03-07 15:19:48 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-07 15:19:48 | INFO | train | epoch 466 | loss 1.793 | ppl 3.47 | wps 22066.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22688 | lr 0.000209943 | gnorm 0.39 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 67203
2022-03-07 15:19:48 | INFO | fairseq.trainer | begin training epoch 467
2022-03-07 15:19:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:20:22 | INFO | train_inner | epoch 467:     12 / 49 loss=1.793, ppl=3.46, wps=22082.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.388, loss_scale=32, train_wall=260, gb_free=21.5, wall=67238
2022-03-07 15:21:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:22:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:22:12 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 11.237 | ppl 2413.64 | wps 39420.9 | wpb 510.9 | bsz 1 | num_updates 22736 | best_loss 8.621
2022-03-07 15:22:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22736 updates
2022-03-07 15:22:12 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-07 15:22:12 | INFO | train | epoch 467 | loss 1.792 | ppl 3.46 | wps 21607.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 22736 | lr 0.000209722 | gnorm 0.379 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 67347
2022-03-07 15:22:12 | INFO | fairseq.trainer | begin training epoch 468
2022-03-07 15:22:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:24:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:24:36 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 11.23 | ppl 2401.36 | wps 39196.9 | wpb 510.9 | bsz 1 | num_updates 22785 | best_loss 8.621
2022-03-07 15:24:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22785 updates
2022-03-07 15:24:36 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-07 15:24:36 | INFO | train | epoch 468 | loss 1.792 | ppl 3.46 | wps 22050.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22785 | lr 0.000209496 | gnorm 0.383 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 67491
2022-03-07 15:24:36 | INFO | fairseq.trainer | begin training epoch 469
2022-03-07 15:24:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:25:19 | INFO | train_inner | epoch 469:     15 / 49 loss=1.792, ppl=3.46, wps=21863.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.382, loss_scale=32, train_wall=263, gb_free=21.5, wall=67534
2022-03-07 15:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:27:00 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 11.217 | ppl 2379.98 | wps 39201.4 | wpb 510.9 | bsz 1 | num_updates 22834 | best_loss 8.621
2022-03-07 15:27:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22834 updates
2022-03-07 15:27:00 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-07 15:27:00 | INFO | train | epoch 469 | loss 1.792 | ppl 3.46 | wps 22070.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22834 | lr 0.000209271 | gnorm 0.381 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 67635
2022-03-07 15:27:00 | INFO | fairseq.trainer | begin training epoch 470
2022-03-07 15:27:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:27:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:29:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:29:24 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 11.222 | ppl 2387.94 | wps 39154.9 | wpb 510.9 | bsz 1 | num_updates 22882 | best_loss 8.621
2022-03-07 15:29:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22882 updates
2022-03-07 15:29:24 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-07 15:29:24 | INFO | train | epoch 470 | loss 1.791 | ppl 3.46 | wps 21606.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 22882 | lr 0.000209051 | gnorm 0.38 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 67779
2022-03-07 15:29:24 | INFO | fairseq.trainer | begin training epoch 471
2022-03-07 15:29:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:30:16 | INFO | train_inner | epoch 471:     18 / 49 loss=1.791, ppl=3.46, wps=21869.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.38, loss_scale=32, train_wall=262, gb_free=21.5, wall=67831
2022-03-07 15:31:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:31:48 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 11.256 | ppl 2445.3 | wps 38902.1 | wpb 510.9 | bsz 1 | num_updates 22931 | best_loss 8.621
2022-03-07 15:31:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22931 updates
2022-03-07 15:31:48 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-07 15:31:48 | INFO | train | epoch 471 | loss 1.79 | ppl 3.46 | wps 22061 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22931 | lr 0.000208828 | gnorm 0.382 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 67924
2022-03-07 15:31:48 | INFO | fairseq.trainer | begin training epoch 472
2022-03-07 15:31:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:34:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:34:12 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 11.189 | ppl 2335.15 | wps 39124.3 | wpb 510.9 | bsz 1 | num_updates 22980 | best_loss 8.621
2022-03-07 15:34:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22980 updates
2022-03-07 15:34:12 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-07 15:34:12 | INFO | train | epoch 472 | loss 1.791 | ppl 3.46 | wps 22063.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22980 | lr 0.000208605 | gnorm 0.387 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 68068
2022-03-07 15:34:12 | INFO | fairseq.trainer | begin training epoch 473
2022-03-07 15:34:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:34:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:35:12 | INFO | train_inner | epoch 473:     21 / 49 loss=1.791, ppl=3.46, wps=21863.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.385, loss_scale=32, train_wall=263, gb_free=21.5, wall=68128
2022-03-07 15:36:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:36:36 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 11.245 | ppl 2427.75 | wps 39157.1 | wpb 510.9 | bsz 1 | num_updates 23028 | best_loss 8.621
2022-03-07 15:36:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23028 updates
2022-03-07 15:36:36 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-07 15:36:36 | INFO | train | epoch 473 | loss 1.789 | ppl 3.46 | wps 21599.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 23028 | lr 0.000208388 | gnorm 0.381 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 68212
2022-03-07 15:36:36 | INFO | fairseq.trainer | begin training epoch 474
2022-03-07 15:36:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:38:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:39:00 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 11.193 | ppl 2341.31 | wps 39201 | wpb 510.9 | bsz 1 | num_updates 23077 | best_loss 8.621
2022-03-07 15:39:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23077 updates
2022-03-07 15:39:00 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-07 15:39:00 | INFO | train | epoch 474 | loss 1.789 | ppl 3.46 | wps 22068.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23077 | lr 0.000208166 | gnorm 0.379 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 68356
2022-03-07 15:39:00 | INFO | fairseq.trainer | begin training epoch 475
2022-03-07 15:39:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:40:06 | INFO | train_inner | epoch 475:     23 / 49 loss=1.789, ppl=3.46, wps=22083.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.379, loss_scale=32, train_wall=260, gb_free=21.5, wall=68421
2022-03-07 15:41:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:41:24 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 11.221 | ppl 2387.1 | wps 39046.9 | wpb 510.9 | bsz 1 | num_updates 23126 | best_loss 8.621
2022-03-07 15:41:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23126 updates
2022-03-07 15:41:24 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-07 15:41:24 | INFO | train | epoch 475 | loss 1.789 | ppl 3.46 | wps 22062 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23126 | lr 0.000207946 | gnorm 0.38 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 68500
2022-03-07 15:41:25 | INFO | fairseq.trainer | begin training epoch 476
2022-03-07 15:41:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:41:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:43:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:43:49 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 11.203 | ppl 2356.87 | wps 39100.7 | wpb 510.9 | bsz 1 | num_updates 23174 | best_loss 8.621
2022-03-07 15:43:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23174 updates
2022-03-07 15:43:49 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-07 15:43:49 | INFO | train | epoch 476 | loss 1.788 | ppl 3.45 | wps 21589.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 23174 | lr 0.00020773 | gnorm 0.378 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 68644
2022-03-07 15:43:49 | INFO | fairseq.trainer | begin training epoch 477
2022-03-07 15:43:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:45:03 | INFO | train_inner | epoch 477:     26 / 49 loss=1.789, ppl=3.45, wps=21852.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.38, loss_scale=32, train_wall=263, gb_free=21.5, wall=68718
2022-03-07 15:46:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:46:13 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 11.193 | ppl 2341.65 | wps 39225.9 | wpb 510.9 | bsz 1 | num_updates 23223 | best_loss 8.621
2022-03-07 15:46:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23223 updates
2022-03-07 15:46:13 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-07 15:46:13 | INFO | train | epoch 477 | loss 1.788 | ppl 3.45 | wps 22048.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23223 | lr 0.000207511 | gnorm 0.381 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 68788
2022-03-07 15:46:13 | INFO | fairseq.trainer | begin training epoch 478
2022-03-07 15:46:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:48:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:48:37 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 11.222 | ppl 2389.42 | wps 39162.7 | wpb 510.9 | bsz 1 | num_updates 23272 | best_loss 8.621
2022-03-07 15:48:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23272 updates
2022-03-07 15:48:37 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-07 15:48:37 | INFO | train | epoch 478 | loss 1.788 | ppl 3.45 | wps 22068.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23272 | lr 0.000207292 | gnorm 0.377 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 68932
2022-03-07 15:48:37 | INFO | fairseq.trainer | begin training epoch 479
2022-03-07 15:48:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:48:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:50:00 | INFO | train_inner | epoch 479:     29 / 49 loss=1.788, ppl=3.45, wps=21865.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.377, loss_scale=32, train_wall=262, gb_free=21.5, wall=69015
2022-03-07 15:50:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:51:01 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 11.216 | ppl 2378.15 | wps 39170.1 | wpb 510.9 | bsz 1 | num_updates 23320 | best_loss 8.621
2022-03-07 15:51:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23320 updates
2022-03-07 15:51:01 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-07 15:51:01 | INFO | train | epoch 479 | loss 1.787 | ppl 3.45 | wps 21599.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 23320 | lr 0.000207079 | gnorm 0.375 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 69076
2022-03-07 15:51:01 | INFO | fairseq.trainer | begin training epoch 480
2022-03-07 15:51:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:53:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:53:25 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 11.182 | ppl 2324.04 | wps 39218 | wpb 510.9 | bsz 1 | num_updates 23369 | best_loss 8.621
2022-03-07 15:53:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23369 updates
2022-03-07 15:53:25 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-07 15:53:25 | INFO | train | epoch 480 | loss 1.787 | ppl 3.45 | wps 22064.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23369 | lr 0.000206862 | gnorm 0.376 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 69220
2022-03-07 15:53:25 | INFO | fairseq.trainer | begin training epoch 481
2022-03-07 15:53:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:54:53 | INFO | train_inner | epoch 481:     31 / 49 loss=1.787, ppl=3.45, wps=22081.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.376, loss_scale=32, train_wall=260, gb_free=21.5, wall=69309
2022-03-07 15:55:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:55:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:55:49 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 11.201 | ppl 2354.63 | wps 39139.3 | wpb 510.9 | bsz 1 | num_updates 23417 | best_loss 8.621
2022-03-07 15:55:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23417 updates
2022-03-07 15:55:49 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-07 15:55:49 | INFO | train | epoch 481 | loss 1.786 | ppl 3.45 | wps 21616.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 23417 | lr 0.00020665 | gnorm 0.378 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 69364
2022-03-07 15:55:49 | INFO | fairseq.trainer | begin training epoch 482
2022-03-07 15:55:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:58:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:58:13 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 11.191 | ppl 2337.46 | wps 39118.4 | wpb 510.9 | bsz 1 | num_updates 23466 | best_loss 8.621
2022-03-07 15:58:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23466 updates
2022-03-07 15:58:13 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-07 15:58:13 | INFO | train | epoch 482 | loss 1.786 | ppl 3.45 | wps 22052.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23466 | lr 0.000206434 | gnorm 0.379 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 69508
2022-03-07 15:58:13 | INFO | fairseq.trainer | begin training epoch 483
2022-03-07 15:58:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:59:50 | INFO | train_inner | epoch 483:     34 / 49 loss=1.787, ppl=3.45, wps=21869.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.381, loss_scale=32, train_wall=263, gb_free=21.5, wall=69605
2022-03-07 16:00:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:00:37 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 11.214 | ppl 2375.64 | wps 39249.1 | wpb 510.9 | bsz 1 | num_updates 23515 | best_loss 8.621
2022-03-07 16:00:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23515 updates
2022-03-07 16:00:37 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-07 16:00:37 | INFO | train | epoch 483 | loss 1.787 | ppl 3.45 | wps 22068.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23515 | lr 0.000206218 | gnorm 0.382 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 69652
2022-03-07 16:00:37 | INFO | fairseq.trainer | begin training epoch 484
2022-03-07 16:00:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:01:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:02:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:03:01 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 11.213 | ppl 2373.06 | wps 39186.5 | wpb 510.9 | bsz 1 | num_updates 23563 | best_loss 8.621
2022-03-07 16:03:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23563 updates
2022-03-07 16:03:01 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-07 16:03:01 | INFO | train | epoch 484 | loss 1.786 | ppl 3.45 | wps 21602.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 23563 | lr 0.000206008 | gnorm 0.382 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 69796
2022-03-07 16:03:01 | INFO | fairseq.trainer | begin training epoch 485
2022-03-07 16:03:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:04:47 | INFO | train_inner | epoch 485:     37 / 49 loss=1.786, ppl=3.45, wps=21870.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23600, lr=0.000205847, gnorm=0.381, loss_scale=16, train_wall=263, gb_free=21.5, wall=69902
2022-03-07 16:05:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:05:25 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 11.208 | ppl 2364.88 | wps 39178.3 | wpb 510.9 | bsz 1 | num_updates 23612 | best_loss 8.621
2022-03-07 16:05:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23612 updates
2022-03-07 16:05:25 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-07 16:05:25 | INFO | train | epoch 485 | loss 1.786 | ppl 3.45 | wps 22063.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23612 | lr 0.000205794 | gnorm 0.382 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 69940
2022-03-07 16:05:25 | INFO | fairseq.trainer | begin training epoch 486
2022-03-07 16:05:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:07:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:07:49 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 11.227 | ppl 2397.21 | wps 39236.4 | wpb 510.9 | bsz 1 | num_updates 23661 | best_loss 8.621
2022-03-07 16:07:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23661 updates
2022-03-07 16:07:49 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-07 16:07:49 | INFO | train | epoch 486 | loss 1.785 | ppl 3.45 | wps 22070.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23661 | lr 0.000205581 | gnorm 0.381 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 70084
2022-03-07 16:07:49 | INFO | fairseq.trainer | begin training epoch 487
2022-03-07 16:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:09:41 | INFO | train_inner | epoch 487:     39 / 49 loss=1.785, ppl=3.45, wps=22076.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=23700, lr=0.000205412, gnorm=0.382, loss_scale=32, train_wall=260, gb_free=21.5, wall=70196
2022-03-07 16:10:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:10:13 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 11.196 | ppl 2345.75 | wps 39153.8 | wpb 510.9 | bsz 1 | num_updates 23710 | best_loss 8.621
2022-03-07 16:10:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23710 updates
2022-03-07 16:10:13 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-07 16:10:13 | INFO | train | epoch 487 | loss 1.785 | ppl 3.45 | wps 22058.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23710 | lr 0.000205369 | gnorm 0.382 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 70228
2022-03-07 16:10:13 | INFO | fairseq.trainer | begin training epoch 488
2022-03-07 16:10:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:12:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:12:37 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 11.207 | ppl 2364.45 | wps 39585.1 | wpb 510.9 | bsz 1 | num_updates 23759 | best_loss 8.621
2022-03-07 16:12:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23759 updates
2022-03-07 16:12:37 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-07 16:12:37 | INFO | train | epoch 488 | loss 1.784 | ppl 3.44 | wps 22058.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23759 | lr 0.000205157 | gnorm 0.379 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 70373
2022-03-07 16:12:37 | INFO | fairseq.trainer | begin training epoch 489
2022-03-07 16:12:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:14:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:14:37 | INFO | train_inner | epoch 489:     42 / 49 loss=1.784, ppl=3.44, wps=21866.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.376, loss_scale=32, train_wall=262, gb_free=21.5, wall=70492
2022-03-07 16:14:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:15:01 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 11.208 | ppl 2365.33 | wps 39300.1 | wpb 510.9 | bsz 1 | num_updates 23807 | best_loss 8.621
2022-03-07 16:15:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23807 updates
2022-03-07 16:15:01 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-07 16:15:01 | INFO | train | epoch 489 | loss 1.783 | ppl 3.44 | wps 21606 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 23807 | lr 0.00020495 | gnorm 0.371 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 70517
2022-03-07 16:15:01 | INFO | fairseq.trainer | begin training epoch 490
2022-03-07 16:15:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:17:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:17:25 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 11.206 | ppl 2362.49 | wps 39193.3 | wpb 510.9 | bsz 1 | num_updates 23856 | best_loss 8.621
2022-03-07 16:17:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23856 updates
2022-03-07 16:17:25 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-07 16:17:25 | INFO | train | epoch 490 | loss 1.783 | ppl 3.44 | wps 22056.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23856 | lr 0.000204739 | gnorm 0.375 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 70661
2022-03-07 16:17:25 | INFO | fairseq.trainer | begin training epoch 491
2022-03-07 16:17:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:19:31 | INFO | train_inner | epoch 491:     44 / 49 loss=1.783, ppl=3.44, wps=22085.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.374, loss_scale=32, train_wall=260, gb_free=21.5, wall=70786
2022-03-07 16:19:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:19:49 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 11.21 | ppl 2368.32 | wps 38944.1 | wpb 510.9 | bsz 1 | num_updates 23905 | best_loss 8.621
2022-03-07 16:19:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23905 updates
2022-03-07 16:19:49 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-07 16:19:49 | INFO | train | epoch 491 | loss 1.783 | ppl 3.44 | wps 22075.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23905 | lr 0.000204529 | gnorm 0.373 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 70805
2022-03-07 16:19:49 | INFO | fairseq.trainer | begin training epoch 492
2022-03-07 16:19:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:20:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:22:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:22:13 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 11.22 | ppl 2386.11 | wps 39235.8 | wpb 510.9 | bsz 1 | num_updates 23953 | best_loss 8.621
2022-03-07 16:22:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23953 updates
2022-03-07 16:22:13 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-07 16:22:13 | INFO | train | epoch 492 | loss 1.783 | ppl 3.44 | wps 21620.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 23953 | lr 0.000204324 | gnorm 0.382 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 70949
2022-03-07 16:22:13 | INFO | fairseq.trainer | begin training epoch 493
2022-03-07 16:22:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:24:28 | INFO | train_inner | epoch 493:     47 / 49 loss=1.783, ppl=3.44, wps=21873.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.378, loss_scale=32, train_wall=262, gb_free=21.5, wall=71083
2022-03-07 16:24:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:24:37 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 11.195 | ppl 2344.98 | wps 39139.1 | wpb 510.9 | bsz 1 | num_updates 24002 | best_loss 8.621
2022-03-07 16:24:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 24002 updates
2022-03-07 16:24:37 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-07 16:24:37 | INFO | train | epoch 493 | loss 1.782 | ppl 3.44 | wps 22061.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24002 | lr 0.000204116 | gnorm 0.374 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 71093
2022-03-07 16:24:37 | INFO | fairseq.trainer | begin training epoch 494
2022-03-07 16:24:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:26:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:27:01 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 11.205 | ppl 2360.23 | wps 39143.2 | wpb 510.9 | bsz 1 | num_updates 24051 | best_loss 8.621
2022-03-07 16:27:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24051 updates
2022-03-07 16:27:02 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-07 16:27:02 | INFO | train | epoch 494 | loss 1.782 | ppl 3.44 | wps 22061.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24051 | lr 0.000203908 | gnorm 0.38 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 71237
2022-03-07 16:27:02 | INFO | fairseq.trainer | begin training epoch 495
2022-03-07 16:27:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:27:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:29:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:29:26 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 11.21 | ppl 2368.08 | wps 39075.2 | wpb 510.9 | bsz 1 | num_updates 24099 | best_loss 8.621
2022-03-07 16:29:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24099 updates
2022-03-07 16:29:26 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-07 16:29:26 | INFO | train | epoch 495 | loss 1.781 | ppl 3.44 | wps 21586.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24099 | lr 0.000203704 | gnorm 0.372 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 71381
2022-03-07 16:29:26 | INFO | fairseq.trainer | begin training epoch 496
2022-03-07 16:29:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:29:29 | INFO | train_inner | epoch 496:      1 / 49 loss=1.782, ppl=3.44, wps=21434.5, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=24100, lr=0.0002037, gnorm=0.377, loss_scale=32, train_wall=261, gb_free=21.5, wall=71384
2022-03-07 16:31:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:31:50 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 11.212 | ppl 2372.24 | wps 39073.1 | wpb 510.9 | bsz 1 | num_updates 24148 | best_loss 8.621
2022-03-07 16:31:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24148 updates
2022-03-07 16:31:50 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-07 16:31:50 | INFO | train | epoch 496 | loss 1.78 | ppl 3.44 | wps 22055.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24148 | lr 0.000203498 | gnorm 0.373 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 71525
2022-03-07 16:31:50 | INFO | fairseq.trainer | begin training epoch 497
2022-03-07 16:31:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:33:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:34:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:34:14 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 11.222 | ppl 2387.99 | wps 39139 | wpb 510.9 | bsz 1 | num_updates 24196 | best_loss 8.621
2022-03-07 16:34:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24196 updates
2022-03-07 16:34:14 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-07 16:34:14 | INFO | train | epoch 497 | loss 1.78 | ppl 3.44 | wps 21618.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24196 | lr 0.000203296 | gnorm 0.373 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 71669
2022-03-07 16:34:14 | INFO | fairseq.trainer | begin training epoch 498
2022-03-07 16:34:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:34:25 | INFO | train_inner | epoch 498:      4 / 49 loss=1.78, ppl=3.44, wps=21870.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.373, loss_scale=32, train_wall=262, gb_free=21.5, wall=71680
2022-03-07 16:36:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:36:38 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 11.205 | ppl 2361.07 | wps 39211.5 | wpb 510.9 | bsz 1 | num_updates 24245 | best_loss 8.621
2022-03-07 16:36:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24245 updates
2022-03-07 16:36:38 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-07 16:36:38 | INFO | train | epoch 498 | loss 1.78 | ppl 3.43 | wps 22057.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24245 | lr 0.00020309 | gnorm 0.374 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 71813
2022-03-07 16:36:38 | INFO | fairseq.trainer | begin training epoch 499
2022-03-07 16:36:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:38:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:39:02 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 11.223 | ppl 2390.64 | wps 39076.6 | wpb 510.9 | bsz 1 | num_updates 24294 | best_loss 8.621
2022-03-07 16:39:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24294 updates
2022-03-07 16:39:02 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-07 16:39:02 | INFO | train | epoch 499 | loss 1.78 | ppl 3.43 | wps 22061.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24294 | lr 0.000202885 | gnorm 0.375 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 71957
2022-03-07 16:39:02 | INFO | fairseq.trainer | begin training epoch 500
2022-03-07 16:39:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:39:19 | INFO | train_inner | epoch 500:      6 / 49 loss=1.78, ppl=3.43, wps=22078.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.374, loss_scale=32, train_wall=260, gb_free=21.5, wall=71974
2022-03-07 16:40:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:41:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:41:26 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 11.217 | ppl 2380.8 | wps 39130.1 | wpb 510.9 | bsz 1 | num_updates 24342 | best_loss 8.621
2022-03-07 16:41:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24342 updates
2022-03-07 16:41:26 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-07 16:41:26 | INFO | train | epoch 500 | loss 1.779 | ppl 3.43 | wps 21608.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24342 | lr 0.000202685 | gnorm 0.369 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 72101
2022-03-07 16:41:26 | INFO | fairseq.trainer | begin training epoch 501
2022-03-07 16:41:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:43:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:43:51 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 11.236 | ppl 2411.5 | wps 36945.6 | wpb 510.9 | bsz 1 | num_updates 24391 | best_loss 8.621
2022-03-07 16:43:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24391 updates
2022-03-07 16:43:51 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-07 16:43:51 | INFO | train | epoch 501 | loss 1.78 | ppl 3.43 | wps 21944 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24391 | lr 0.000202481 | gnorm 0.379 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 72246
2022-03-07 16:43:51 | INFO | fairseq.trainer | begin training epoch 502
2022-03-07 16:43:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:44:17 | INFO | train_inner | epoch 502:      9 / 49 loss=1.779, ppl=3.43, wps=21769.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.375, loss_scale=32, train_wall=263, gb_free=21.5, wall=72272
2022-03-07 16:46:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:46:17 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 11.207 | ppl 2364.22 | wps 38114.6 | wpb 510.9 | bsz 1 | num_updates 24440 | best_loss 8.621
2022-03-07 16:46:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24440 updates
2022-03-07 16:46:17 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-07 16:46:17 | INFO | train | epoch 502 | loss 1.778 | ppl 3.43 | wps 21783.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24440 | lr 0.000202278 | gnorm 0.375 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 72392
2022-03-07 16:46:17 | INFO | fairseq.trainer | begin training epoch 503
2022-03-07 16:46:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:47:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:48:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:48:42 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 11.19 | ppl 2336.91 | wps 38239.7 | wpb 510.9 | bsz 1 | num_updates 24488 | best_loss 8.621
2022-03-07 16:48:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24488 updates
2022-03-07 16:48:42 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-07 16:48:42 | INFO | train | epoch 503 | loss 1.778 | ppl 3.43 | wps 21371.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24488 | lr 0.00020208 | gnorm 0.373 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 72538
2022-03-07 16:48:42 | INFO | fairseq.trainer | begin training epoch 504
2022-03-07 16:48:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:49:17 | INFO | train_inner | epoch 504:     12 / 49 loss=1.778, ppl=3.43, wps=21630.2, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.376, loss_scale=32, train_wall=265, gb_free=21.5, wall=72572
2022-03-07 16:51:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:51:08 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 11.232 | ppl 2406.09 | wps 38055.1 | wpb 510.9 | bsz 1 | num_updates 24537 | best_loss 8.621
2022-03-07 16:51:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24537 updates
2022-03-07 16:51:08 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-07 16:51:08 | INFO | train | epoch 504 | loss 1.778 | ppl 3.43 | wps 21811.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24537 | lr 0.000201878 | gnorm 0.379 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 72683
2022-03-07 16:51:08 | INFO | fairseq.trainer | begin training epoch 505
2022-03-07 16:51:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:53:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:53:34 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 11.21 | ppl 2369.04 | wps 38034.7 | wpb 510.9 | bsz 1 | num_updates 24586 | best_loss 8.621
2022-03-07 16:53:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24586 updates
2022-03-07 16:53:34 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-07 16:53:34 | INFO | train | epoch 505 | loss 1.778 | ppl 3.43 | wps 21807.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24586 | lr 0.000201677 | gnorm 0.374 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 72829
2022-03-07 16:53:34 | INFO | fairseq.trainer | begin training epoch 506
2022-03-07 16:53:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:54:14 | INFO | train_inner | epoch 506:     14 / 49 loss=1.778, ppl=3.43, wps=21822.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.376, loss_scale=64, train_wall=262, gb_free=21.5, wall=72869
2022-03-07 16:54:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:55:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:56:00 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 11.237 | ppl 2414.23 | wps 38007.8 | wpb 510.9 | bsz 1 | num_updates 24634 | best_loss 8.621
2022-03-07 16:56:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24634 updates
2022-03-07 16:56:00 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-07 16:56:00 | INFO | train | epoch 506 | loss 1.778 | ppl 3.43 | wps 21336 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24634 | lr 0.00020148 | gnorm 0.379 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 72975
2022-03-07 16:56:00 | INFO | fairseq.trainer | begin training epoch 507
2022-03-07 16:56:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:58:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:58:25 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 11.221 | ppl 2386.39 | wps 38073.2 | wpb 510.9 | bsz 1 | num_updates 24683 | best_loss 8.621
2022-03-07 16:58:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24683 updates
2022-03-07 16:58:25 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-07 16:58:25 | INFO | train | epoch 507 | loss 1.777 | ppl 3.43 | wps 21797.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24683 | lr 0.00020128 | gnorm 0.38 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 73121
2022-03-07 16:58:25 | INFO | fairseq.trainer | begin training epoch 508
2022-03-07 16:58:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:59:15 | INFO | train_inner | epoch 508:     17 / 49 loss=1.777, ppl=3.43, wps=21600.6, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.379, loss_scale=32, train_wall=265, gb_free=21.5, wall=73170
2022-03-07 17:00:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:00:51 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 11.228 | ppl 2397.84 | wps 38096.7 | wpb 510.9 | bsz 1 | num_updates 24732 | best_loss 8.621
2022-03-07 17:00:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24732 updates
2022-03-07 17:00:51 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-07 17:00:51 | INFO | train | epoch 508 | loss 1.777 | ppl 3.43 | wps 21804.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24732 | lr 0.000201081 | gnorm 0.376 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 73266
2022-03-07 17:00:51 | INFO | fairseq.trainer | begin training epoch 509
2022-03-07 17:00:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:01:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:03:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:03:17 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 11.199 | ppl 2350.35 | wps 38212.2 | wpb 510.9 | bsz 1 | num_updates 24780 | best_loss 8.621
2022-03-07 17:03:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24780 updates
2022-03-07 17:03:17 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-07 17:03:17 | INFO | train | epoch 509 | loss 1.776 | ppl 3.42 | wps 21341.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24780 | lr 0.000200886 | gnorm 0.37 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 73412
2022-03-07 17:03:17 | INFO | fairseq.trainer | begin training epoch 510
2022-03-07 17:03:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:04:15 | INFO | train_inner | epoch 510:     20 / 49 loss=1.776, ppl=3.42, wps=21611.4, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.369, loss_scale=32, train_wall=265, gb_free=21.5, wall=73470
2022-03-07 17:05:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:05:43 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 11.232 | ppl 2404.92 | wps 38061.3 | wpb 510.9 | bsz 1 | num_updates 24829 | best_loss 8.621
2022-03-07 17:05:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24829 updates
2022-03-07 17:05:43 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-07 17:05:43 | INFO | train | epoch 510 | loss 1.776 | ppl 3.42 | wps 21803.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24829 | lr 0.000200688 | gnorm 0.374 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 73558
2022-03-07 17:05:43 | INFO | fairseq.trainer | begin training epoch 511
2022-03-07 17:05:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:07:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:08:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:08:09 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 11.229 | ppl 2400.43 | wps 38065.5 | wpb 510.9 | bsz 1 | num_updates 24877 | best_loss 8.621
2022-03-07 17:08:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24877 updates
2022-03-07 17:08:09 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-07 17:08:09 | INFO | train | epoch 511 | loss 1.775 | ppl 3.42 | wps 21330.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24877 | lr 0.000200494 | gnorm 0.374 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 73704
2022-03-07 17:08:09 | INFO | fairseq.trainer | begin training epoch 512
2022-03-07 17:08:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:09:15 | INFO | train_inner | epoch 512:     23 / 49 loss=1.776, ppl=3.42, wps=21595.8, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.376, loss_scale=32, train_wall=265, gb_free=21.5, wall=73770
2022-03-07 17:10:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:10:35 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 11.21 | ppl 2369.32 | wps 37920.3 | wpb 510.9 | bsz 1 | num_updates 24926 | best_loss 8.621
2022-03-07 17:10:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24926 updates
2022-03-07 17:10:35 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-07 17:10:35 | INFO | train | epoch 512 | loss 1.775 | ppl 3.42 | wps 21783.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24926 | lr 0.000200297 | gnorm 0.375 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 73850
2022-03-07 17:10:35 | INFO | fairseq.trainer | begin training epoch 513
2022-03-07 17:10:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:12:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:13:00 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 11.212 | ppl 2372.53 | wps 38102.7 | wpb 510.9 | bsz 1 | num_updates 24975 | best_loss 8.621
2022-03-07 17:13:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24975 updates
2022-03-07 17:13:00 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-07 17:13:00 | INFO | train | epoch 513 | loss 1.774 | ppl 3.42 | wps 21805.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24975 | lr 0.0002001 | gnorm 0.365 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 73996
2022-03-07 17:13:00 | INFO | fairseq.trainer | begin training epoch 514
2022-03-07 17:13:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:14:13 | INFO | train_inner | epoch 514:     25 / 49 loss=1.774, ppl=3.42, wps=21800.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.368, loss_scale=32, train_wall=262, gb_free=21.5, wall=74068
2022-03-07 17:14:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:15:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:15:26 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 11.188 | ppl 2332.93 | wps 38073.9 | wpb 510.9 | bsz 1 | num_updates 25023 | best_loss 8.621
2022-03-07 17:15:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25023 updates
2022-03-07 17:15:26 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-07 17:15:26 | INFO | train | epoch 514 | loss 1.774 | ppl 3.42 | wps 21323 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25023 | lr 0.000199908 | gnorm 0.367 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 74142
2022-03-07 17:15:26 | INFO | fairseq.trainer | begin training epoch 515
2022-03-07 17:15:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:17:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:17:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:17:52 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 11.209 | ppl 2368.04 | wps 37853 | wpb 510.9 | bsz 1 | num_updates 25071 | best_loss 8.621
2022-03-07 17:17:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25071 updates
2022-03-07 17:17:52 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-07 17:17:52 | INFO | train | epoch 515 | loss 1.774 | ppl 3.42 | wps 21342.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25071 | lr 0.000199717 | gnorm 0.37 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 74287
2022-03-07 17:17:52 | INFO | fairseq.trainer | begin training epoch 516
2022-03-07 17:17:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:19:16 | INFO | train_inner | epoch 516:     29 / 49 loss=1.774, ppl=3.42, wps=21390.3, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.369, loss_scale=16, train_wall=268, gb_free=21.5, wall=74371
2022-03-07 17:20:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:20:18 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 11.208 | ppl 2366.43 | wps 38115.1 | wpb 510.9 | bsz 1 | num_updates 25120 | best_loss 8.621
2022-03-07 17:20:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25120 updates
2022-03-07 17:20:18 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-07 17:20:18 | INFO | train | epoch 516 | loss 1.774 | ppl 3.42 | wps 21791 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25120 | lr 0.000199522 | gnorm 0.37 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 74433
2022-03-07 17:20:18 | INFO | fairseq.trainer | begin training epoch 517
2022-03-07 17:20:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:22:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:22:44 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 11.21 | ppl 2369.35 | wps 38038.5 | wpb 510.9 | bsz 1 | num_updates 25169 | best_loss 8.621
2022-03-07 17:22:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25169 updates
2022-03-07 17:22:44 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-07 17:22:44 | INFO | train | epoch 517 | loss 1.773 | ppl 3.42 | wps 21788.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25169 | lr 0.000199327 | gnorm 0.37 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 74579
2022-03-07 17:22:44 | INFO | fairseq.trainer | begin training epoch 518
2022-03-07 17:22:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:24:13 | INFO | train_inner | epoch 518:     31 / 49 loss=1.773, ppl=3.42, wps=21815.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.371, loss_scale=32, train_wall=262, gb_free=21.5, wall=74669
2022-03-07 17:25:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:25:10 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 11.197 | ppl 2347.41 | wps 37993.2 | wpb 510.9 | bsz 1 | num_updates 25218 | best_loss 8.621
2022-03-07 17:25:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25218 updates
2022-03-07 17:25:10 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-07 17:25:10 | INFO | train | epoch 518 | loss 1.772 | ppl 3.42 | wps 21806.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25218 | lr 0.000199134 | gnorm 0.371 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 74725
2022-03-07 17:25:10 | INFO | fairseq.trainer | begin training epoch 519
2022-03-07 17:25:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:27:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:27:36 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 11.187 | ppl 2331.08 | wps 37910.6 | wpb 510.9 | bsz 1 | num_updates 25267 | best_loss 8.621
2022-03-07 17:27:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25267 updates
2022-03-07 17:27:36 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-07 17:27:36 | INFO | train | epoch 519 | loss 1.772 | ppl 3.42 | wps 21751.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25267 | lr 0.00019894 | gnorm 0.369 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 74871
2022-03-07 17:27:36 | INFO | fairseq.trainer | begin training epoch 520
2022-03-07 17:27:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:29:11 | INFO | train_inner | epoch 520:     33 / 49 loss=1.772, ppl=3.42, wps=21798.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.37, loss_scale=32, train_wall=262, gb_free=21.5, wall=74966
2022-03-07 17:29:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:29:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:30:02 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 11.22 | ppl 2385.21 | wps 37972.9 | wpb 510.9 | bsz 1 | num_updates 25315 | best_loss 8.621
2022-03-07 17:30:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25315 updates
2022-03-07 17:30:02 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-07 17:30:02 | INFO | train | epoch 520 | loss 1.772 | ppl 3.42 | wps 21338 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25315 | lr 0.000198752 | gnorm 0.37 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 75017
2022-03-07 17:30:02 | INFO | fairseq.trainer | begin training epoch 521
2022-03-07 17:30:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:32:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:32:27 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 11.213 | ppl 2373.17 | wps 38007.6 | wpb 510.9 | bsz 1 | num_updates 25364 | best_loss 8.621
2022-03-07 17:32:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25364 updates
2022-03-07 17:32:27 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-07 17:32:27 | INFO | train | epoch 521 | loss 1.772 | ppl 3.41 | wps 21808.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25364 | lr 0.00019856 | gnorm 0.368 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 75163
2022-03-07 17:32:27 | INFO | fairseq.trainer | begin training epoch 522
2022-03-07 17:32:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:34:11 | INFO | train_inner | epoch 522:     36 / 49 loss=1.772, ppl=3.42, wps=21596.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=25400, lr=0.000198419, gnorm=0.369, loss_scale=32, train_wall=265, gb_free=21.5, wall=75267
2022-03-07 17:34:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:34:53 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 11.201 | ppl 2354.67 | wps 38071.6 | wpb 510.9 | bsz 1 | num_updates 25413 | best_loss 8.621
2022-03-07 17:34:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25413 updates
2022-03-07 17:34:53 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-07 17:34:53 | INFO | train | epoch 522 | loss 1.772 | ppl 3.41 | wps 21779.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25413 | lr 0.000198368 | gnorm 0.37 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 75308
2022-03-07 17:34:53 | INFO | fairseq.trainer | begin training epoch 523
2022-03-07 17:34:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:36:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:37:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:37:19 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 11.222 | ppl 2388.8 | wps 37476 | wpb 510.9 | bsz 1 | num_updates 25461 | best_loss 8.621
2022-03-07 17:37:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25461 updates
2022-03-07 17:37:19 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-07 17:37:19 | INFO | train | epoch 523 | loss 1.771 | ppl 3.41 | wps 21354.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25461 | lr 0.000198181 | gnorm 0.367 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 75454
2022-03-07 17:37:19 | INFO | fairseq.trainer | begin training epoch 524
2022-03-07 17:37:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:39:12 | INFO | train_inner | epoch 524:     39 / 49 loss=1.771, ppl=3.41, wps=21607.1, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=25500, lr=0.00019803, gnorm=0.37, loss_scale=32, train_wall=265, gb_free=21.5, wall=75567
2022-03-07 17:39:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:39:45 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 11.204 | ppl 2359 | wps 37908.1 | wpb 510.9 | bsz 1 | num_updates 25510 | best_loss 8.621
2022-03-07 17:39:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25510 updates
2022-03-07 17:39:45 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-07 17:39:45 | INFO | train | epoch 524 | loss 1.771 | ppl 3.41 | wps 21795.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25510 | lr 0.000197991 | gnorm 0.37 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 75600
2022-03-07 17:39:45 | INFO | fairseq.trainer | begin training epoch 525
2022-03-07 17:39:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:42:11 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 11.191 | ppl 2338.41 | wps 37922.3 | wpb 510.9 | bsz 1 | num_updates 25559 | best_loss 8.621
2022-03-07 17:42:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25559 updates
2022-03-07 17:42:11 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-07 17:42:11 | INFO | train | epoch 525 | loss 1.771 | ppl 3.41 | wps 21782.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25559 | lr 0.000197801 | gnorm 0.371 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 75746
2022-03-07 17:42:11 | INFO | fairseq.trainer | begin training epoch 526
2022-03-07 17:42:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:43:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:44:12 | INFO | train_inner | epoch 526:     42 / 49 loss=1.77, ppl=3.41, wps=21607.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.368, loss_scale=32, train_wall=265, gb_free=21.5, wall=75867
2022-03-07 17:44:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:44:36 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 11.205 | ppl 2360.59 | wps 38099.9 | wpb 510.9 | bsz 1 | num_updates 25607 | best_loss 8.621
2022-03-07 17:44:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25607 updates
2022-03-07 17:44:36 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-07 17:44:36 | INFO | train | epoch 526 | loss 1.77 | ppl 3.41 | wps 21364.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25607 | lr 0.000197615 | gnorm 0.366 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 75892
2022-03-07 17:44:36 | INFO | fairseq.trainer | begin training epoch 527
2022-03-07 17:44:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:46:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:47:02 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 11.215 | ppl 2377.62 | wps 37931.8 | wpb 510.9 | bsz 1 | num_updates 25656 | best_loss 8.621
2022-03-07 17:47:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25656 updates
2022-03-07 17:47:02 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-07 17:47:02 | INFO | train | epoch 527 | loss 1.77 | ppl 3.41 | wps 21798.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25656 | lr 0.000197427 | gnorm 0.371 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 76037
2022-03-07 17:47:02 | INFO | fairseq.trainer | begin training epoch 528
2022-03-07 17:47:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:49:09 | INFO | train_inner | epoch 528:     44 / 49 loss=1.77, ppl=3.41, wps=21807.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.37, loss_scale=32, train_wall=262, gb_free=21.5, wall=76164
2022-03-07 17:49:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:49:28 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 11.185 | ppl 2328.56 | wps 37908.3 | wpb 510.9 | bsz 1 | num_updates 25705 | best_loss 8.621
2022-03-07 17:49:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25705 updates
2022-03-07 17:49:28 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-07 17:49:28 | INFO | train | epoch 528 | loss 1.77 | ppl 3.41 | wps 21781.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25705 | lr 0.000197238 | gnorm 0.369 | loss_scale 64 | train_wall 129 | gb_free 21.5 | wall 76183
2022-03-07 17:49:28 | INFO | fairseq.trainer | begin training epoch 529
2022-03-07 17:49:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:49:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:51:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:51:54 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 11.213 | ppl 2374.22 | wps 37938.1 | wpb 510.9 | bsz 1 | num_updates 25753 | best_loss 8.621
2022-03-07 17:51:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25753 updates
2022-03-07 17:51:54 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-07 17:51:54 | INFO | train | epoch 529 | loss 1.769 | ppl 3.41 | wps 21319.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25753 | lr 0.000197054 | gnorm 0.37 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 76329
2022-03-07 17:51:54 | INFO | fairseq.trainer | begin training epoch 530
2022-03-07 17:51:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:54:09 | INFO | train_inner | epoch 530:     47 / 49 loss=1.769, ppl=3.41, wps=21605.1, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.368, loss_scale=32, train_wall=265, gb_free=21.5, wall=76465
2022-03-07 17:54:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:54:20 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 11.197 | ppl 2348.03 | wps 38114.7 | wpb 510.9 | bsz 1 | num_updates 25802 | best_loss 8.621
2022-03-07 17:54:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25802 updates
2022-03-07 17:54:20 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-07 17:54:20 | INFO | train | epoch 530 | loss 1.769 | ppl 3.41 | wps 21828.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25802 | lr 0.000196867 | gnorm 0.367 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 76475
2022-03-07 17:54:20 | INFO | fairseq.trainer | begin training epoch 531
2022-03-07 17:54:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:56:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:56:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:56:45 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 11.183 | ppl 2324.74 | wps 38153.8 | wpb 510.9 | bsz 1 | num_updates 25850 | best_loss 8.621
2022-03-07 17:56:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25850 updates
2022-03-07 17:56:45 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-07 17:56:45 | INFO | train | epoch 531 | loss 1.768 | ppl 3.41 | wps 21345.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25850 | lr 0.000196684 | gnorm 0.365 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 76621
2022-03-07 17:56:45 | INFO | fairseq.trainer | begin training epoch 532
2022-03-07 17:56:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:59:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:59:11 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 11.191 | ppl 2338.59 | wps 38041.1 | wpb 510.9 | bsz 1 | num_updates 25899 | best_loss 8.621
2022-03-07 17:59:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25899 updates
2022-03-07 17:59:11 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-07 17:59:11 | INFO | train | epoch 532 | loss 1.769 | ppl 3.41 | wps 21804.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25899 | lr 0.000196498 | gnorm 0.365 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 76766
2022-03-07 17:59:11 | INFO | fairseq.trainer | begin training epoch 533
2022-03-07 17:59:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:59:14 | INFO | train_inner | epoch 533:      1 / 49 loss=1.768, ppl=3.41, wps=21185, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=25900, lr=0.000196494, gnorm=0.366, loss_scale=32, train_wall=264, gb_free=21.5, wall=76769
2022-03-07 18:01:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:01:37 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 11.194 | ppl 2342.37 | wps 37994.4 | wpb 510.9 | bsz 1 | num_updates 25948 | best_loss 8.621
2022-03-07 18:01:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25948 updates
2022-03-07 18:01:37 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-07 18:01:37 | INFO | train | epoch 533 | loss 1.768 | ppl 3.41 | wps 21798.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25948 | lr 0.000196313 | gnorm 0.369 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 76912
2022-03-07 18:01:37 | INFO | fairseq.trainer | begin training epoch 534
2022-03-07 18:01:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:02:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:03:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:04:03 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 11.174 | ppl 2309.85 | wps 37896.1 | wpb 510.9 | bsz 1 | num_updates 25996 | best_loss 8.621
2022-03-07 18:04:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25996 updates
2022-03-07 18:04:03 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-07 18:04:03 | INFO | train | epoch 534 | loss 1.767 | ppl 3.4 | wps 21333 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25996 | lr 0.000196131 | gnorm 0.366 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 77058
2022-03-07 18:04:03 | INFO | fairseq.trainer | begin training epoch 535
2022-03-07 18:04:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:04:15 | INFO | train_inner | epoch 535:      4 / 49 loss=1.768, ppl=3.4, wps=21598, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=26000, lr=0.000196116, gnorm=0.368, loss_scale=32, train_wall=265, gb_free=21.5, wall=77070
2022-03-07 18:06:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:06:29 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 11.204 | ppl 2358.88 | wps 37999.7 | wpb 510.9 | bsz 1 | num_updates 26045 | best_loss 8.621
2022-03-07 18:06:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26045 updates
2022-03-07 18:06:29 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-07 18:06:29 | INFO | train | epoch 535 | loss 1.767 | ppl 3.4 | wps 21811.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26045 | lr 0.000195947 | gnorm 0.364 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 77204
2022-03-07 18:06:29 | INFO | fairseq.trainer | begin training epoch 536
2022-03-07 18:06:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:08:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:08:54 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 11.187 | ppl 2331.38 | wps 37841.1 | wpb 510.9 | bsz 1 | num_updates 26094 | best_loss 8.621
2022-03-07 18:08:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26094 updates
2022-03-07 18:08:54 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-07 18:08:54 | INFO | train | epoch 536 | loss 1.767 | ppl 3.4 | wps 21790.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26094 | lr 0.000195763 | gnorm 0.367 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 77350
2022-03-07 18:08:54 | INFO | fairseq.trainer | begin training epoch 537
2022-03-07 18:08:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:09:12 | INFO | train_inner | epoch 537:      6 / 49 loss=1.767, ppl=3.4, wps=21821.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.366, loss_scale=32, train_wall=262, gb_free=21.5, wall=77367
2022-03-07 18:09:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:11:20 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 11.193 | ppl 2341.61 | wps 37758.4 | wpb 510.9 | bsz 1 | num_updates 26142 | best_loss 8.621
2022-03-07 18:11:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26142 updates
2022-03-07 18:11:20 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-07 18:11:20 | INFO | train | epoch 537 | loss 1.767 | ppl 3.4 | wps 21337.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26142 | lr 0.000195583 | gnorm 0.365 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 77496
2022-03-07 18:11:20 | INFO | fairseq.trainer | begin training epoch 538
2022-03-07 18:11:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:13:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:13:46 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 11.2 | ppl 2352.02 | wps 37912.5 | wpb 510.9 | bsz 1 | num_updates 26191 | best_loss 8.621
2022-03-07 18:13:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26191 updates
2022-03-07 18:13:46 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-07 18:13:46 | INFO | train | epoch 538 | loss 1.766 | ppl 3.4 | wps 21776.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26191 | lr 0.0001954 | gnorm 0.369 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 77641
2022-03-07 18:13:46 | INFO | fairseq.trainer | begin training epoch 539
2022-03-07 18:13:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:14:12 | INFO | train_inner | epoch 539:      9 / 49 loss=1.767, ppl=3.4, wps=21586.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.368, loss_scale=32, train_wall=265, gb_free=21.5, wall=77668
2022-03-07 18:15:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:16:12 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 11.174 | ppl 2310.37 | wps 37996.3 | wpb 510.9 | bsz 1 | num_updates 26239 | best_loss 8.621
2022-03-07 18:16:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26239 updates
2022-03-07 18:16:12 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-07 18:16:12 | INFO | train | epoch 539 | loss 1.766 | ppl 3.4 | wps 21348.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26239 | lr 0.000195221 | gnorm 0.368 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 77787
2022-03-07 18:16:12 | INFO | fairseq.trainer | begin training epoch 540
2022-03-07 18:16:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:18:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:18:38 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 11.214 | ppl 2375.03 | wps 37895.1 | wpb 510.9 | bsz 1 | num_updates 26288 | best_loss 8.621
2022-03-07 18:18:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26288 updates
2022-03-07 18:18:38 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-07 18:18:38 | INFO | train | epoch 540 | loss 1.765 | ppl 3.4 | wps 21788.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26288 | lr 0.000195039 | gnorm 0.364 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 77933
2022-03-07 18:18:38 | INFO | fairseq.trainer | begin training epoch 541
2022-03-07 18:18:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:19:13 | INFO | train_inner | epoch 541:     12 / 49 loss=1.766, ppl=3.4, wps=21604.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.365, loss_scale=32, train_wall=265, gb_free=21.5, wall=77968
2022-03-07 18:20:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:21:04 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 11.194 | ppl 2343.24 | wps 37847.4 | wpb 510.9 | bsz 1 | num_updates 26337 | best_loss 8.621
2022-03-07 18:21:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26337 updates
2022-03-07 18:21:04 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-07 18:21:04 | INFO | train | epoch 541 | loss 1.766 | ppl 3.4 | wps 21789.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26337 | lr 0.000194857 | gnorm 0.368 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 78079
2022-03-07 18:21:04 | INFO | fairseq.trainer | begin training epoch 542
2022-03-07 18:21:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:23:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:23:30 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 11.192 | ppl 2339.46 | wps 38241.8 | wpb 510.9 | bsz 1 | num_updates 26386 | best_loss 8.621
2022-03-07 18:23:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26386 updates
2022-03-07 18:23:30 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-07 18:23:30 | INFO | train | epoch 542 | loss 1.765 | ppl 3.4 | wps 21789.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26386 | lr 0.000194676 | gnorm 0.366 | loss_scale 64 | train_wall 129 | gb_free 21.5 | wall 78225
2022-03-07 18:23:30 | INFO | fairseq.trainer | begin training epoch 543
2022-03-07 18:23:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:24:10 | INFO | train_inner | epoch 543:     14 / 49 loss=1.765, ppl=3.4, wps=21809, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.366, loss_scale=64, train_wall=262, gb_free=21.5, wall=78265
2022-03-07 18:25:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:25:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:25:55 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 11.187 | ppl 2330.89 | wps 37885.5 | wpb 510.9 | bsz 1 | num_updates 26434 | best_loss 8.621
2022-03-07 18:25:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26434 updates
2022-03-07 18:25:55 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-07 18:25:55 | INFO | train | epoch 543 | loss 1.764 | ppl 3.4 | wps 21350.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26434 | lr 0.0001945 | gnorm 0.366 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 78371
2022-03-07 18:25:55 | INFO | fairseq.trainer | begin training epoch 544
2022-03-07 18:25:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:28:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:28:21 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 11.203 | ppl 2357.63 | wps 38038.2 | wpb 510.9 | bsz 1 | num_updates 26483 | best_loss 8.621
2022-03-07 18:28:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26483 updates
2022-03-07 18:28:21 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-07 18:28:21 | INFO | train | epoch 544 | loss 1.764 | ppl 3.4 | wps 21801.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26483 | lr 0.00019432 | gnorm 0.367 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 78516
2022-03-07 18:28:21 | INFO | fairseq.trainer | begin training epoch 545
2022-03-07 18:28:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:29:10 | INFO | train_inner | epoch 545:     17 / 49 loss=1.764, ppl=3.4, wps=21610.1, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.367, loss_scale=32, train_wall=265, gb_free=21.5, wall=78565
2022-03-07 18:30:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:30:47 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 11.193 | ppl 2340.35 | wps 38046.7 | wpb 510.9 | bsz 1 | num_updates 26532 | best_loss 8.621
2022-03-07 18:30:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26532 updates
2022-03-07 18:30:47 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-07 18:30:47 | INFO | train | epoch 545 | loss 1.764 | ppl 3.4 | wps 21782.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26532 | lr 0.00019414 | gnorm 0.363 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 78662
2022-03-07 18:30:47 | INFO | fairseq.trainer | begin training epoch 546
2022-03-07 18:30:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:31:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:33:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:33:13 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 11.191 | ppl 2337.78 | wps 37982.5 | wpb 510.9 | bsz 1 | num_updates 26580 | best_loss 8.621
2022-03-07 18:33:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26580 updates
2022-03-07 18:33:13 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-07 18:33:13 | INFO | train | epoch 546 | loss 1.764 | ppl 3.4 | wps 21348.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26580 | lr 0.000193965 | gnorm 0.366 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 78808
2022-03-07 18:33:13 | INFO | fairseq.trainer | begin training epoch 547
2022-03-07 18:33:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:34:11 | INFO | train_inner | epoch 547:     20 / 49 loss=1.764, ppl=3.4, wps=21597.1, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.363, loss_scale=32, train_wall=265, gb_free=21.5, wall=78866
2022-03-07 18:34:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:35:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:35:39 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 11.197 | ppl 2347.65 | wps 38214 | wpb 510.9 | bsz 1 | num_updates 26628 | best_loss 8.621
2022-03-07 18:35:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26628 updates
2022-03-07 18:35:39 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-07 18:35:39 | INFO | train | epoch 547 | loss 1.764 | ppl 3.4 | wps 21335.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26628 | lr 0.00019379 | gnorm 0.363 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 78954
2022-03-07 18:35:39 | INFO | fairseq.trainer | begin training epoch 548
2022-03-07 18:35:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:37:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:38:04 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 11.195 | ppl 2345.15 | wps 37961 | wpb 510.9 | bsz 1 | num_updates 26677 | best_loss 8.621
2022-03-07 18:38:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26677 updates
2022-03-07 18:38:04 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-07 18:38:04 | INFO | train | epoch 548 | loss 1.763 | ppl 3.39 | wps 21815.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26677 | lr 0.000193612 | gnorm 0.364 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 79100
2022-03-07 18:38:04 | INFO | fairseq.trainer | begin training epoch 549
2022-03-07 18:38:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:39:11 | INFO | train_inner | epoch 549:     23 / 49 loss=1.763, ppl=3.4, wps=21601.4, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.366, loss_scale=16, train_wall=265, gb_free=21.5, wall=79166
2022-03-07 18:40:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:40:30 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 11.192 | ppl 2339.12 | wps 37999.8 | wpb 510.9 | bsz 1 | num_updates 26726 | best_loss 8.621
2022-03-07 18:40:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26726 updates
2022-03-07 18:40:30 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-07 18:40:30 | INFO | train | epoch 549 | loss 1.763 | ppl 3.39 | wps 21789.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26726 | lr 0.000193434 | gnorm 0.369 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 79246
2022-03-07 18:40:30 | INFO | fairseq.trainer | begin training epoch 550
2022-03-07 18:40:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:42:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:42:56 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 11.193 | ppl 2341.87 | wps 37472.9 | wpb 510.9 | bsz 1 | num_updates 26775 | best_loss 8.621
2022-03-07 18:42:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26775 updates
2022-03-07 18:42:56 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-07 18:42:56 | INFO | train | epoch 550 | loss 1.763 | ppl 3.39 | wps 21787.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26775 | lr 0.000193257 | gnorm 0.362 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 79391
2022-03-07 18:42:56 | INFO | fairseq.trainer | begin training epoch 551
2022-03-07 18:42:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:44:08 | INFO | train_inner | epoch 551:     25 / 49 loss=1.762, ppl=3.39, wps=21818.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.364, loss_scale=32, train_wall=262, gb_free=21.5, wall=79463
2022-03-07 18:45:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:45:22 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 11.203 | ppl 2357.79 | wps 38418.3 | wpb 510.9 | bsz 1 | num_updates 26824 | best_loss 8.621
2022-03-07 18:45:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26824 updates
2022-03-07 18:45:22 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-07 18:45:22 | INFO | train | epoch 551 | loss 1.762 | ppl 3.39 | wps 21858.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26824 | lr 0.00019308 | gnorm 0.364 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 79537
2022-03-07 18:45:22 | INFO | fairseq.trainer | begin training epoch 552
2022-03-07 18:45:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:47:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:47:47 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 11.197 | ppl 2348.06 | wps 38025.6 | wpb 510.9 | bsz 1 | num_updates 26873 | best_loss 8.621
2022-03-07 18:47:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26873 updates
2022-03-07 18:47:47 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-07 18:47:47 | INFO | train | epoch 552 | loss 1.762 | ppl 3.39 | wps 21866 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26873 | lr 0.000192904 | gnorm 0.362 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 79682
2022-03-07 18:47:47 | INFO | fairseq.trainer | begin training epoch 553
2022-03-07 18:47:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:49:05 | INFO | train_inner | epoch 553:     27 / 49 loss=1.762, ppl=3.39, wps=21895.1, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.363, loss_scale=64, train_wall=262, gb_free=21.5, wall=79760
2022-03-07 18:49:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:50:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:50:12 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 11.218 | ppl 2382.23 | wps 38004.8 | wpb 510.9 | bsz 1 | num_updates 26921 | best_loss 8.621
2022-03-07 18:50:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26921 updates
2022-03-07 18:50:12 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-07 18:50:12 | INFO | train | epoch 553 | loss 1.762 | ppl 3.39 | wps 21411.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26921 | lr 0.000192732 | gnorm 0.364 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 79827
2022-03-07 18:50:12 | INFO | fairseq.trainer | begin training epoch 554
2022-03-07 18:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:52:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:52:38 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 11.19 | ppl 2336.41 | wps 38063.1 | wpb 510.9 | bsz 1 | num_updates 26970 | best_loss 8.621
2022-03-07 18:52:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26970 updates
2022-03-07 18:52:38 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-07 18:52:38 | INFO | train | epoch 554 | loss 1.762 | ppl 3.39 | wps 21808.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26970 | lr 0.000192557 | gnorm 0.367 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 79973
2022-03-07 18:52:38 | INFO | fairseq.trainer | begin training epoch 555
2022-03-07 18:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:54:05 | INFO | train_inner | epoch 555:     30 / 49 loss=1.761, ppl=3.39, wps=21624.4, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.366, loss_scale=32, train_wall=265, gb_free=21.5, wall=80060
2022-03-07 18:54:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:55:04 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 11.168 | ppl 2300.64 | wps 38070.4 | wpb 510.9 | bsz 1 | num_updates 27019 | best_loss 8.621
2022-03-07 18:55:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27019 updates
2022-03-07 18:55:04 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-07 18:55:04 | INFO | train | epoch 555 | loss 1.761 | ppl 3.39 | wps 21804.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27019 | lr 0.000192382 | gnorm 0.366 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 80119
2022-03-07 18:55:04 | INFO | fairseq.trainer | begin training epoch 556
2022-03-07 18:55:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:55:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:57:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:57:30 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 11.18 | ppl 2320.69 | wps 38075 | wpb 510.9 | bsz 1 | num_updates 27067 | best_loss 8.621
2022-03-07 18:57:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27067 updates
2022-03-07 18:57:30 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-07 18:57:30 | INFO | train | epoch 556 | loss 1.761 | ppl 3.39 | wps 21349.8 | ups 0.33 | wpb 64853.3 | bsz 126.7 | num_updates 27067 | lr 0.000192212 | gnorm 0.364 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 80265
2022-03-07 18:57:30 | INFO | fairseq.trainer | begin training epoch 557
2022-03-07 18:57:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:59:05 | INFO | train_inner | epoch 557:     33 / 49 loss=1.761, ppl=3.39, wps=21609.9, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=27100, lr=0.000192095, gnorm=0.364, loss_scale=32, train_wall=265, gb_free=21.5, wall=80360
2022-03-07 18:59:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:59:55 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 11.197 | ppl 2348.44 | wps 38077.4 | wpb 510.9 | bsz 1 | num_updates 27116 | best_loss 8.621
2022-03-07 18:59:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27116 updates
2022-03-07 18:59:55 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-07 18:59:55 | INFO | train | epoch 557 | loss 1.76 | ppl 3.39 | wps 21811.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27116 | lr 0.000192038 | gnorm 0.364 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 80410
2022-03-07 18:59:55 | INFO | fairseq.trainer | begin training epoch 558
2022-03-07 18:59:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:02:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:02:21 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 11.19 | ppl 2337 | wps 38056.5 | wpb 510.9 | bsz 1 | num_updates 27165 | best_loss 8.621
2022-03-07 19:02:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27165 updates
2022-03-07 19:02:21 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-07 19:02:21 | INFO | train | epoch 558 | loss 1.761 | ppl 3.39 | wps 21789.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27165 | lr 0.000191865 | gnorm 0.367 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 80556
2022-03-07 19:02:21 | INFO | fairseq.trainer | begin training epoch 559
2022-03-07 19:02:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:02:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:04:05 | INFO | train_inner | epoch 559:     36 / 49 loss=1.76, ppl=3.39, wps=21620.1, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=27200, lr=0.000191741, gnorm=0.366, loss_scale=32, train_wall=265, gb_free=21.5, wall=80660
2022-03-07 19:04:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:04:47 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 11.193 | ppl 2341.47 | wps 38029.1 | wpb 510.9 | bsz 1 | num_updates 27213 | best_loss 8.621
2022-03-07 19:04:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27213 updates
2022-03-07 19:04:47 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-07 19:04:47 | INFO | train | epoch 559 | loss 1.76 | ppl 3.39 | wps 21374.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27213 | lr 0.000191695 | gnorm 0.363 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 80702
2022-03-07 19:04:47 | INFO | fairseq.trainer | begin training epoch 560
2022-03-07 19:04:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:07:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:07:12 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 11.194 | ppl 2342.04 | wps 38270.5 | wpb 510.9 | bsz 1 | num_updates 27262 | best_loss 8.621
2022-03-07 19:07:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27262 updates
2022-03-07 19:07:12 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-07 19:07:12 | INFO | train | epoch 560 | loss 1.759 | ppl 3.39 | wps 21801.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27262 | lr 0.000191523 | gnorm 0.362 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 80848
2022-03-07 19:07:12 | INFO | fairseq.trainer | begin training epoch 561
2022-03-07 19:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:09:02 | INFO | train_inner | epoch 561:     38 / 49 loss=1.759, ppl=3.39, wps=21817.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=27300, lr=0.00019139, gnorm=0.362, loss_scale=64, train_wall=262, gb_free=21.5, wall=80957
2022-03-07 19:09:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:09:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:09:38 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 11.185 | ppl 2328.03 | wps 37478.1 | wpb 510.9 | bsz 1 | num_updates 27310 | best_loss 8.621
2022-03-07 19:09:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27310 updates
2022-03-07 19:09:38 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-07 19:09:38 | INFO | train | epoch 561 | loss 1.759 | ppl 3.38 | wps 21341 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27310 | lr 0.000191355 | gnorm 0.361 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 80994
2022-03-07 19:09:38 | INFO | fairseq.trainer | begin training epoch 562
2022-03-07 19:09:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:11:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:12:04 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 11.197 | ppl 2348.39 | wps 38112.2 | wpb 510.9 | bsz 1 | num_updates 27359 | best_loss 8.621
2022-03-07 19:12:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27359 updates
2022-03-07 19:12:04 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-07 19:12:04 | INFO | train | epoch 562 | loss 1.759 | ppl 3.39 | wps 21813.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27359 | lr 0.000191183 | gnorm 0.366 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 81139
2022-03-07 19:12:04 | INFO | fairseq.trainer | begin training epoch 563
2022-03-07 19:12:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:14:02 | INFO | train_inner | epoch 563:     41 / 49 loss=1.759, ppl=3.38, wps=21601.1, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.364, loss_scale=32, train_wall=265, gb_free=21.5, wall=81258
2022-03-07 19:14:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:14:30 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 11.189 | ppl 2335.35 | wps 38017.1 | wpb 510.9 | bsz 1 | num_updates 27408 | best_loss 8.621
2022-03-07 19:14:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27408 updates
2022-03-07 19:14:30 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-07 19:14:30 | INFO | train | epoch 563 | loss 1.759 | ppl 3.38 | wps 21780.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27408 | lr 0.000191012 | gnorm 0.362 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 81285
2022-03-07 19:14:30 | INFO | fairseq.trainer | begin training epoch 564
2022-03-07 19:14:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:15:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:16:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:16:56 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 11.19 | ppl 2336.28 | wps 38030.2 | wpb 510.9 | bsz 1 | num_updates 27456 | best_loss 8.621
2022-03-07 19:16:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27456 updates
2022-03-07 19:16:56 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-07 19:16:56 | INFO | train | epoch 564 | loss 1.758 | ppl 3.38 | wps 21331.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27456 | lr 0.000190845 | gnorm 0.36 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 81431
2022-03-07 19:16:56 | INFO | fairseq.trainer | begin training epoch 565
2022-03-07 19:16:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:19:03 | INFO | train_inner | epoch 565:     44 / 49 loss=1.758, ppl=3.38, wps=21596.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.362, loss_scale=32, train_wall=265, gb_free=21.5, wall=81558
2022-03-07 19:19:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:19:22 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 11.186 | ppl 2329.27 | wps 38040.9 | wpb 510.9 | bsz 1 | num_updates 27505 | best_loss 8.621
2022-03-07 19:19:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27505 updates
2022-03-07 19:19:22 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-07 19:19:22 | INFO | train | epoch 565 | loss 1.758 | ppl 3.38 | wps 21801.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27505 | lr 0.000190675 | gnorm 0.362 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 81577
2022-03-07 19:19:22 | INFO | fairseq.trainer | begin training epoch 566
2022-03-07 19:19:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:21:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:21:48 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 11.182 | ppl 2324.02 | wps 37952.6 | wpb 510.9 | bsz 1 | num_updates 27554 | best_loss 8.621
2022-03-07 19:21:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27554 updates
2022-03-07 19:21:48 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-07 19:21:48 | INFO | train | epoch 566 | loss 1.758 | ppl 3.38 | wps 21771 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27554 | lr 0.000190506 | gnorm 0.36 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 81723
2022-03-07 19:21:48 | INFO | fairseq.trainer | begin training epoch 567
2022-03-07 19:21:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:22:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:24:03 | INFO | train_inner | epoch 567:     47 / 49 loss=1.758, ppl=3.38, wps=21597.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.36, loss_scale=32, train_wall=265, gb_free=21.5, wall=81858
2022-03-07 19:24:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:24:13 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 11.197 | ppl 2347.73 | wps 38040.4 | wpb 510.9 | bsz 1 | num_updates 27602 | best_loss 8.621
2022-03-07 19:24:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27602 updates
2022-03-07 19:24:13 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-07 19:24:13 | INFO | train | epoch 567 | loss 1.758 | ppl 3.38 | wps 21355.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27602 | lr 0.00019034 | gnorm 0.361 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 81869
2022-03-07 19:24:13 | INFO | fairseq.trainer | begin training epoch 568
2022-03-07 19:24:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:26:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:26:39 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 11.186 | ppl 2330.45 | wps 38082.4 | wpb 510.9 | bsz 1 | num_updates 27651 | best_loss 8.621
2022-03-07 19:26:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27651 updates
2022-03-07 19:26:39 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-07 19:26:39 | INFO | train | epoch 568 | loss 1.758 | ppl 3.38 | wps 21784.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27651 | lr 0.000190171 | gnorm 0.366 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 82014
2022-03-07 19:26:39 | INFO | fairseq.trainer | begin training epoch 569
2022-03-07 19:26:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:28:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:28:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:29:05 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 11.194 | ppl 2343.2 | wps 37961.9 | wpb 510.9 | bsz 1 | num_updates 27699 | best_loss 8.621
2022-03-07 19:29:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27699 updates
2022-03-07 19:29:05 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-07 19:29:05 | INFO | train | epoch 569 | loss 1.757 | ppl 3.38 | wps 21348.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27699 | lr 0.000190006 | gnorm 0.368 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 82160
2022-03-07 19:29:05 | INFO | fairseq.trainer | begin training epoch 570
2022-03-07 19:29:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:29:08 | INFO | train_inner | epoch 570:      1 / 49 loss=1.757, ppl=3.38, wps=21176.1, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=27700, lr=0.000190003, gnorm=0.368, loss_scale=32, train_wall=264, gb_free=21.5, wall=82163
2022-03-07 19:31:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:31:31 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 11.183 | ppl 2324.99 | wps 37984.5 | wpb 510.9 | bsz 1 | num_updates 27748 | best_loss 8.621
2022-03-07 19:31:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27748 updates
2022-03-07 19:31:31 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-07 19:31:31 | INFO | train | epoch 570 | loss 1.757 | ppl 3.38 | wps 21800 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27748 | lr 0.000189838 | gnorm 0.364 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 82306
2022-03-07 19:31:31 | INFO | fairseq.trainer | begin training epoch 571
2022-03-07 19:31:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:33:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:33:57 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 11.168 | ppl 2301.59 | wps 38206.3 | wpb 510.9 | bsz 1 | num_updates 27797 | best_loss 8.621
2022-03-07 19:33:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27797 updates
2022-03-07 19:33:57 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-07 19:33:57 | INFO | train | epoch 571 | loss 1.757 | ppl 3.38 | wps 21789.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27797 | lr 0.000189671 | gnorm 0.361 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 82452
2022-03-07 19:33:57 | INFO | fairseq.trainer | begin training epoch 572
2022-03-07 19:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:34:05 | INFO | train_inner | epoch 572:      3 / 49 loss=1.757, ppl=3.38, wps=21813.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.362, loss_scale=32, train_wall=262, gb_free=21.5, wall=82461
2022-03-07 19:35:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:36:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:36:22 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 11.179 | ppl 2319.23 | wps 37968.8 | wpb 510.9 | bsz 1 | num_updates 27845 | best_loss 8.621
2022-03-07 19:36:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27845 updates
2022-03-07 19:36:22 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-07 19:36:22 | INFO | train | epoch 572 | loss 1.756 | ppl 3.38 | wps 21355.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27845 | lr 0.000189507 | gnorm 0.358 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 82598
2022-03-07 19:36:22 | INFO | fairseq.trainer | begin training epoch 573
2022-03-07 19:36:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:38:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:38:48 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 11.196 | ppl 2346.45 | wps 38125.4 | wpb 510.9 | bsz 1 | num_updates 27894 | best_loss 8.621
2022-03-07 19:38:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27894 updates
2022-03-07 19:38:48 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-07 19:38:48 | INFO | train | epoch 573 | loss 1.756 | ppl 3.38 | wps 21785.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27894 | lr 0.000189341 | gnorm 0.36 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 82744
2022-03-07 19:38:48 | INFO | fairseq.trainer | begin training epoch 574
2022-03-07 19:38:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:39:06 | INFO | train_inner | epoch 574:      6 / 49 loss=1.756, ppl=3.38, wps=21604.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=27900, lr=0.000189321, gnorm=0.359, loss_scale=32, train_wall=265, gb_free=21.5, wall=82761
2022-03-07 19:41:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:41:14 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 11.193 | ppl 2340.87 | wps 37847 | wpb 510.9 | bsz 1 | num_updates 27943 | best_loss 8.621
2022-03-07 19:41:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27943 updates
2022-03-07 19:41:14 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-07 19:41:14 | INFO | train | epoch 574 | loss 1.756 | ppl 3.38 | wps 21793.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27943 | lr 0.000189175 | gnorm 0.365 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 82889
2022-03-07 19:41:14 | INFO | fairseq.trainer | begin training epoch 575
2022-03-07 19:41:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:41:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:43:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:43:40 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 11.197 | ppl 2346.9 | wps 38084.8 | wpb 510.9 | bsz 1 | num_updates 27991 | best_loss 8.621
2022-03-07 19:43:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27991 updates
2022-03-07 19:43:40 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-07 19:43:40 | INFO | train | epoch 575 | loss 1.755 | ppl 3.38 | wps 21367 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27991 | lr 0.000189013 | gnorm 0.356 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 83035
2022-03-07 19:43:40 | INFO | fairseq.trainer | begin training epoch 576
2022-03-07 19:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:44:06 | INFO | train_inner | epoch 576:      9 / 49 loss=1.755, ppl=3.38, wps=21608.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.36, loss_scale=32, train_wall=265, gb_free=21.5, wall=83061
2022-03-07 19:46:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:46:06 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 11.197 | ppl 2347.41 | wps 37821.7 | wpb 510.9 | bsz 1 | num_updates 28040 | best_loss 8.621
2022-03-07 19:46:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28040 updates
2022-03-07 19:46:06 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-07 19:46:06 | INFO | train | epoch 576 | loss 1.755 | ppl 3.37 | wps 21787.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28040 | lr 0.000188847 | gnorm 0.358 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 83181
2022-03-07 19:46:06 | INFO | fairseq.trainer | begin training epoch 577
2022-03-07 19:46:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:48:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:48:31 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 11.196 | ppl 2345.59 | wps 38084.2 | wpb 510.9 | bsz 1 | num_updates 28089 | best_loss 8.621
2022-03-07 19:48:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28089 updates
2022-03-07 19:48:31 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-07 19:48:31 | INFO | train | epoch 577 | loss 1.754 | ppl 3.37 | wps 21801.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28089 | lr 0.000188683 | gnorm 0.357 | loss_scale 64 | train_wall 129 | gb_free 21.5 | wall 83327
2022-03-07 19:48:31 | INFO | fairseq.trainer | begin training epoch 578
2022-03-07 19:48:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:49:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:49:06 | INFO | train_inner | epoch 578:     12 / 49 loss=1.755, ppl=3.37, wps=21604.2, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.358, loss_scale=32, train_wall=265, gb_free=21.5, wall=83361
2022-03-07 19:50:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:50:57 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 11.211 | ppl 2370.73 | wps 37972.5 | wpb 510.9 | bsz 1 | num_updates 28137 | best_loss 8.621
2022-03-07 19:50:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28137 updates
2022-03-07 19:50:57 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-07 19:50:57 | INFO | train | epoch 578 | loss 1.755 | ppl 3.37 | wps 21339.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28137 | lr 0.000188522 | gnorm 0.362 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 83473
2022-03-07 19:50:57 | INFO | fairseq.trainer | begin training epoch 579
2022-03-07 19:50:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:53:23 | INFO | valid | epoch 579 | valid on 'valid' subset | loss 11.189 | ppl 2334.21 | wps 38030.7 | wpb 510.9 | bsz 1 | num_updates 28186 | best_loss 8.621
2022-03-07 19:53:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 28186 updates
2022-03-07 19:53:23 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2022-03-07 19:53:23 | INFO | train | epoch 579 | loss 1.754 | ppl 3.37 | wps 21797.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28186 | lr 0.000188358 | gnorm 0.36 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 83618
2022-03-07 19:53:23 | INFO | fairseq.trainer | begin training epoch 580
2022-03-07 19:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:54:04 | INFO | train_inner | epoch 580:     14 / 49 loss=1.754, ppl=3.37, wps=21813.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=28200, lr=0.000188311, gnorm=0.36, loss_scale=32, train_wall=262, gb_free=21.5, wall=83659
2022-03-07 19:55:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:55:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:55:49 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 11.217 | ppl 2380.99 | wps 37557.2 | wpb 510.9 | bsz 1 | num_updates 28234 | best_loss 8.621
2022-03-07 19:55:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 28234 updates
2022-03-07 19:55:49 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2022-03-07 19:55:49 | INFO | train | epoch 580 | loss 1.754 | ppl 3.37 | wps 21338.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28234 | lr 0.000188197 | gnorm 0.36 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 83764
2022-03-07 19:55:49 | INFO | fairseq.trainer | begin training epoch 581
2022-03-07 19:55:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:58:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:58:15 | INFO | valid | epoch 581 | valid on 'valid' subset | loss 11.192 | ppl 2340.03 | wps 38035.3 | wpb 510.9 | bsz 1 | num_updates 28283 | best_loss 8.621
2022-03-07 19:58:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 581 @ 28283 updates
2022-03-07 19:58:15 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)
2022-03-07 19:58:15 | INFO | train | epoch 581 | loss 1.754 | ppl 3.37 | wps 21785.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28283 | lr 0.000188034 | gnorm 0.362 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 83910
2022-03-07 19:58:15 | INFO | fairseq.trainer | begin training epoch 582
2022-03-07 19:58:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:59:04 | INFO | train_inner | epoch 582:     17 / 49 loss=1.754, ppl=3.37, wps=21590.3, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=28300, lr=0.000187978, gnorm=0.362, loss_scale=32, train_wall=265, gb_free=21.5, wall=83959
2022-03-07 20:00:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:00:41 | INFO | valid | epoch 582 | valid on 'valid' subset | loss 11.202 | ppl 2355.34 | wps 38232.2 | wpb 510.9 | bsz 1 | num_updates 28332 | best_loss 8.621
2022-03-07 20:00:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 582 @ 28332 updates
2022-03-07 20:00:41 | INFO | fairseq_cli.train | end of epoch 582 (average epoch stats below)
2022-03-07 20:00:41 | INFO | train | epoch 582 | loss 1.753 | ppl 3.37 | wps 21783.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28332 | lr 0.000187872 | gnorm 0.36 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 84056
2022-03-07 20:00:41 | INFO | fairseq.trainer | begin training epoch 583
2022-03-07 20:00:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:02:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:03:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:03:07 | INFO | valid | epoch 583 | valid on 'valid' subset | loss 11.181 | ppl 2321.82 | wps 38004.5 | wpb 510.9 | bsz 1 | num_updates 28380 | best_loss 8.621
2022-03-07 20:03:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 583 @ 28380 updates
2022-03-07 20:03:07 | INFO | fairseq_cli.train | end of epoch 583 (average epoch stats below)
2022-03-07 20:03:07 | INFO | train | epoch 583 | loss 1.753 | ppl 3.37 | wps 21333.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28380 | lr 0.000187713 | gnorm 0.359 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 84202
2022-03-07 20:03:07 | INFO | fairseq.trainer | begin training epoch 584
2022-03-07 20:03:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:04:04 | INFO | train_inner | epoch 584:     20 / 49 loss=1.753, ppl=3.37, wps=21595.6, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=28400, lr=0.000187647, gnorm=0.357, loss_scale=32, train_wall=265, gb_free=21.5, wall=84260
2022-03-07 20:05:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:05:32 | INFO | valid | epoch 584 | valid on 'valid' subset | loss 11.188 | ppl 2333.07 | wps 37929.8 | wpb 510.9 | bsz 1 | num_updates 28429 | best_loss 8.621
2022-03-07 20:05:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 584 @ 28429 updates
2022-03-07 20:05:32 | INFO | fairseq_cli.train | end of epoch 584 (average epoch stats below)
2022-03-07 20:05:32 | INFO | train | epoch 584 | loss 1.753 | ppl 3.37 | wps 21794.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28429 | lr 0.000187551 | gnorm 0.357 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 84348
2022-03-07 20:05:32 | INFO | fairseq.trainer | begin training epoch 585
2022-03-07 20:05:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:07:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:07:58 | INFO | valid | epoch 585 | valid on 'valid' subset | loss 11.176 | ppl 2313.51 | wps 38169.3 | wpb 510.9 | bsz 1 | num_updates 28478 | best_loss 8.621
2022-03-07 20:07:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 585 @ 28478 updates
2022-03-07 20:07:58 | INFO | fairseq_cli.train | end of epoch 585 (average epoch stats below)
2022-03-07 20:07:58 | INFO | train | epoch 585 | loss 1.752 | ppl 3.37 | wps 21797.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28478 | lr 0.00018739 | gnorm 0.357 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 84493
2022-03-07 20:07:58 | INFO | fairseq.trainer | begin training epoch 586
2022-03-07 20:07:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:09:02 | INFO | train_inner | epoch 586:     22 / 49 loss=1.753, ppl=3.37, wps=21818.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=28500, lr=0.000187317, gnorm=0.357, loss_scale=32, train_wall=262, gb_free=21.5, wall=84557
2022-03-07 20:09:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:10:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:10:24 | INFO | valid | epoch 586 | valid on 'valid' subset | loss 11.17 | ppl 2304.86 | wps 37949.9 | wpb 510.9 | bsz 1 | num_updates 28526 | best_loss 8.621
2022-03-07 20:10:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 586 @ 28526 updates
2022-03-07 20:10:24 | INFO | fairseq_cli.train | end of epoch 586 (average epoch stats below)
2022-03-07 20:10:24 | INFO | train | epoch 586 | loss 1.753 | ppl 3.37 | wps 21345 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28526 | lr 0.000187232 | gnorm 0.355 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 84639
2022-03-07 20:10:24 | INFO | fairseq.trainer | begin training epoch 587
2022-03-07 20:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:12:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:12:50 | INFO | valid | epoch 587 | valid on 'valid' subset | loss 11.172 | ppl 2306.85 | wps 38111.6 | wpb 510.9 | bsz 1 | num_updates 28575 | best_loss 8.621
2022-03-07 20:12:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 587 @ 28575 updates
2022-03-07 20:12:50 | INFO | fairseq_cli.train | end of epoch 587 (average epoch stats below)
2022-03-07 20:12:50 | INFO | train | epoch 587 | loss 1.752 | ppl 3.37 | wps 21831.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28575 | lr 0.000187071 | gnorm 0.357 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 84785
2022-03-07 20:12:50 | INFO | fairseq.trainer | begin training epoch 588
2022-03-07 20:12:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:14:02 | INFO | train_inner | epoch 588:     25 / 49 loss=1.753, ppl=3.37, wps=21610.9, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=28600, lr=0.000186989, gnorm=0.358, loss_scale=32, train_wall=265, gb_free=21.5, wall=84857
2022-03-07 20:15:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:15:15 | INFO | valid | epoch 588 | valid on 'valid' subset | loss 11.18 | ppl 2320.73 | wps 38058.4 | wpb 510.9 | bsz 1 | num_updates 28624 | best_loss 8.621
2022-03-07 20:15:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 588 @ 28624 updates
2022-03-07 20:15:15 | INFO | fairseq_cli.train | end of epoch 588 (average epoch stats below)
2022-03-07 20:15:15 | INFO | train | epoch 588 | loss 1.752 | ppl 3.37 | wps 21788.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28624 | lr 0.000186911 | gnorm 0.361 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 84931
2022-03-07 20:15:15 | INFO | fairseq.trainer | begin training epoch 589
2022-03-07 20:15:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:16:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:17:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:17:41 | INFO | valid | epoch 589 | valid on 'valid' subset | loss 11.167 | ppl 2299.35 | wps 37789 | wpb 510.9 | bsz 1 | num_updates 28672 | best_loss 8.621
2022-03-07 20:17:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 589 @ 28672 updates
2022-03-07 20:17:41 | INFO | fairseq_cli.train | end of epoch 589 (average epoch stats below)
2022-03-07 20:17:41 | INFO | train | epoch 589 | loss 1.751 | ppl 3.37 | wps 21351.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28672 | lr 0.000186754 | gnorm 0.361 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 85076
2022-03-07 20:17:41 | INFO | fairseq.trainer | begin training epoch 590
2022-03-07 20:17:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:19:02 | INFO | train_inner | epoch 590:     28 / 49 loss=1.751, ppl=3.37, wps=21609.1, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=28700, lr=0.000186663, gnorm=0.36, loss_scale=32, train_wall=265, gb_free=21.5, wall=85157
2022-03-07 20:20:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:20:07 | INFO | valid | epoch 590 | valid on 'valid' subset | loss 11.183 | ppl 2324.61 | wps 38040 | wpb 510.9 | bsz 1 | num_updates 28721 | best_loss 8.621
2022-03-07 20:20:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 590 @ 28721 updates
2022-03-07 20:20:07 | INFO | fairseq_cli.train | end of epoch 590 (average epoch stats below)
2022-03-07 20:20:07 | INFO | train | epoch 590 | loss 1.751 | ppl 3.37 | wps 21795.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28721 | lr 0.000186595 | gnorm 0.358 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 85222
2022-03-07 20:20:07 | INFO | fairseq.trainer | begin training epoch 591
2022-03-07 20:20:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:22:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:22:33 | INFO | valid | epoch 591 | valid on 'valid' subset | loss 11.157 | ppl 2283.89 | wps 38352.3 | wpb 510.9 | bsz 1 | num_updates 28770 | best_loss 8.621
2022-03-07 20:22:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 591 @ 28770 updates
2022-03-07 20:22:33 | INFO | fairseq_cli.train | end of epoch 591 (average epoch stats below)
2022-03-07 20:22:33 | INFO | train | epoch 591 | loss 1.751 | ppl 3.37 | wps 21834.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28770 | lr 0.000186436 | gnorm 0.36 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 85368
2022-03-07 20:22:33 | INFO | fairseq.trainer | begin training epoch 592
2022-03-07 20:22:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:23:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:24:02 | INFO | train_inner | epoch 592:     31 / 49 loss=1.751, ppl=3.37, wps=21643.2, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=28800, lr=0.000186339, gnorm=0.358, loss_scale=32, train_wall=265, gb_free=21.5, wall=85457
2022-03-07 20:24:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:24:58 | INFO | valid | epoch 592 | valid on 'valid' subset | loss 11.189 | ppl 2334.09 | wps 37813.5 | wpb 510.9 | bsz 1 | num_updates 28818 | best_loss 8.621
2022-03-07 20:24:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 592 @ 28818 updates
2022-03-07 20:24:58 | INFO | fairseq_cli.train | end of epoch 592 (average epoch stats below)
2022-03-07 20:24:58 | INFO | train | epoch 592 | loss 1.75 | ppl 3.36 | wps 21388.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28818 | lr 0.000186281 | gnorm 0.354 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 85513
2022-03-07 20:24:58 | INFO | fairseq.trainer | begin training epoch 593
2022-03-07 20:24:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:27:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:27:24 | INFO | valid | epoch 593 | valid on 'valid' subset | loss 11.154 | ppl 2279.03 | wps 38093.6 | wpb 510.9 | bsz 1 | num_updates 28867 | best_loss 8.621
2022-03-07 20:27:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 593 @ 28867 updates
2022-03-07 20:27:24 | INFO | fairseq_cli.train | end of epoch 593 (average epoch stats below)
2022-03-07 20:27:24 | INFO | train | epoch 593 | loss 1.751 | ppl 3.37 | wps 21769.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28867 | lr 0.000186123 | gnorm 0.359 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 85659
2022-03-07 20:27:24 | INFO | fairseq.trainer | begin training epoch 594
2022-03-07 20:27:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:28:59 | INFO | train_inner | epoch 594:     33 / 49 loss=1.75, ppl=3.36, wps=21811.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=28900, lr=0.000186016, gnorm=0.356, loss_scale=32, train_wall=262, gb_free=21.5, wall=85754
2022-03-07 20:29:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:29:50 | INFO | valid | epoch 594 | valid on 'valid' subset | loss 11.166 | ppl 2297.55 | wps 37905.7 | wpb 510.9 | bsz 1 | num_updates 28916 | best_loss 8.621
2022-03-07 20:29:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 594 @ 28916 updates
2022-03-07 20:29:50 | INFO | fairseq_cli.train | end of epoch 594 (average epoch stats below)
2022-03-07 20:29:50 | INFO | train | epoch 594 | loss 1.75 | ppl 3.36 | wps 21812.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28916 | lr 0.000185965 | gnorm 0.354 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 85805
2022-03-07 20:29:50 | INFO | fairseq.trainer | begin training epoch 595
2022-03-07 20:29:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:32:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:32:16 | INFO | valid | epoch 595 | valid on 'valid' subset | loss 11.167 | ppl 2298.84 | wps 38166.4 | wpb 510.9 | bsz 1 | num_updates 28965 | best_loss 8.621
2022-03-07 20:32:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 595 @ 28965 updates
2022-03-07 20:32:16 | INFO | fairseq_cli.train | end of epoch 595 (average epoch stats below)
2022-03-07 20:32:16 | INFO | train | epoch 595 | loss 1.75 | ppl 3.36 | wps 21799.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28965 | lr 0.000185807 | gnorm 0.357 | loss_scale 64 | train_wall 129 | gb_free 21.5 | wall 85951
2022-03-07 20:32:16 | INFO | fairseq.trainer | begin training epoch 596
2022-03-07 20:32:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:32:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:33:59 | INFO | train_inner | epoch 596:     36 / 49 loss=1.75, ppl=3.36, wps=21611.4, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=29000, lr=0.000185695, gnorm=0.357, loss_scale=32, train_wall=265, gb_free=21.5, wall=86055
2022-03-07 20:34:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:34:41 | INFO | valid | epoch 596 | valid on 'valid' subset | loss 11.159 | ppl 2286.56 | wps 38169.2 | wpb 510.9 | bsz 1 | num_updates 29013 | best_loss 8.621
2022-03-07 20:34:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 596 @ 29013 updates
2022-03-07 20:34:41 | INFO | fairseq_cli.train | end of epoch 596 (average epoch stats below)
2022-03-07 20:34:41 | INFO | train | epoch 596 | loss 1.75 | ppl 3.36 | wps 21362.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29013 | lr 0.000185654 | gnorm 0.359 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 86097
2022-03-07 20:34:41 | INFO | fairseq.trainer | begin training epoch 597
2022-03-07 20:34:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:37:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:37:07 | INFO | valid | epoch 597 | valid on 'valid' subset | loss 11.189 | ppl 2334.55 | wps 38028.6 | wpb 510.9 | bsz 1 | num_updates 29062 | best_loss 8.621
2022-03-07 20:37:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 597 @ 29062 updates
2022-03-07 20:37:07 | INFO | fairseq_cli.train | end of epoch 597 (average epoch stats below)
2022-03-07 20:37:07 | INFO | train | epoch 597 | loss 1.749 | ppl 3.36 | wps 21803.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29062 | lr 0.000185497 | gnorm 0.352 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 86242
2022-03-07 20:37:07 | INFO | fairseq.trainer | begin training epoch 598
2022-03-07 20:37:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:38:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:39:00 | INFO | train_inner | epoch 598:     39 / 49 loss=1.749, ppl=3.36, wps=21602.6, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=29100, lr=0.000185376, gnorm=0.355, loss_scale=32, train_wall=265, gb_free=21.5, wall=86355
2022-03-07 20:39:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:39:33 | INFO | valid | epoch 598 | valid on 'valid' subset | loss 11.163 | ppl 2292.86 | wps 37848.1 | wpb 510.9 | bsz 1 | num_updates 29110 | best_loss 8.621
2022-03-07 20:39:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 598 @ 29110 updates
2022-03-07 20:39:33 | INFO | fairseq_cli.train | end of epoch 598 (average epoch stats below)
2022-03-07 20:39:33 | INFO | train | epoch 598 | loss 1.749 | ppl 3.36 | wps 21332.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29110 | lr 0.000185344 | gnorm 0.355 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 86388
2022-03-07 20:39:33 | INFO | fairseq.trainer | begin training epoch 599
2022-03-07 20:39:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:41:59 | INFO | valid | epoch 599 | valid on 'valid' subset | loss 11.177 | ppl 2315.89 | wps 38085.9 | wpb 510.9 | bsz 1 | num_updates 29159 | best_loss 8.621
2022-03-07 20:41:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 599 @ 29159 updates
2022-03-07 20:41:59 | INFO | fairseq_cli.train | end of epoch 599 (average epoch stats below)
2022-03-07 20:41:59 | INFO | train | epoch 599 | loss 1.748 | ppl 3.36 | wps 21810.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29159 | lr 0.000185188 | gnorm 0.354 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 86534
2022-03-07 20:41:59 | INFO | fairseq.trainer | begin training epoch 600
2022-03-07 20:41:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:43:57 | INFO | train_inner | epoch 600:     41 / 49 loss=1.748, ppl=3.36, wps=21812.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=29200, lr=0.000185058, gnorm=0.356, loss_scale=32, train_wall=262, gb_free=21.5, wall=86652
2022-03-07 20:44:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:44:25 | INFO | valid | epoch 600 | valid on 'valid' subset | loss 11.169 | ppl 2302 | wps 37784.7 | wpb 510.9 | bsz 1 | num_updates 29208 | best_loss 8.621
2022-03-07 20:44:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 600 @ 29208 updates
2022-03-07 20:44:25 | INFO | fairseq_cli.train | end of epoch 600 (average epoch stats below)
2022-03-07 20:44:25 | INFO | train | epoch 600 | loss 1.749 | ppl 3.36 | wps 21772.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29208 | lr 0.000185033 | gnorm 0.358 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 86680
2022-03-07 20:44:25 | INFO | fairseq.trainer | begin training epoch 601
2022-03-07 20:44:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:45:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:46:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:46:51 | INFO | valid | epoch 601 | valid on 'valid' subset | loss 11.165 | ppl 2295.69 | wps 38073.3 | wpb 510.9 | bsz 1 | num_updates 29256 | best_loss 8.621
2022-03-07 20:46:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 601 @ 29256 updates
2022-03-07 20:46:51 | INFO | fairseq_cli.train | end of epoch 601 (average epoch stats below)
2022-03-07 20:46:51 | INFO | train | epoch 601 | loss 1.748 | ppl 3.36 | wps 21333.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29256 | lr 0.000184881 | gnorm 0.355 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 86826
2022-03-07 20:46:51 | INFO | fairseq.trainer | begin training epoch 602
2022-03-07 20:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:48:58 | INFO | train_inner | epoch 602:     44 / 49 loss=1.748, ppl=3.36, wps=21594.3, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=29300, lr=0.000184742, gnorm=0.354, loss_scale=32, train_wall=265, gb_free=21.5, wall=86953
2022-03-07 20:49:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:49:16 | INFO | valid | epoch 602 | valid on 'valid' subset | loss 11.18 | ppl 2319.74 | wps 38206.9 | wpb 510.9 | bsz 1 | num_updates 29305 | best_loss 8.621
2022-03-07 20:49:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 602 @ 29305 updates
2022-03-07 20:49:16 | INFO | fairseq_cli.train | end of epoch 602 (average epoch stats below)
2022-03-07 20:49:16 | INFO | train | epoch 602 | loss 1.748 | ppl 3.36 | wps 21802.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29305 | lr 0.000184726 | gnorm 0.352 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 86972
2022-03-07 20:49:16 | INFO | fairseq.trainer | begin training epoch 603
2022-03-07 20:49:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:51:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:51:42 | INFO | valid | epoch 603 | valid on 'valid' subset | loss 11.182 | ppl 2323.83 | wps 37913.4 | wpb 510.9 | bsz 1 | num_updates 29354 | best_loss 8.621
2022-03-07 20:51:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 603 @ 29354 updates
2022-03-07 20:51:42 | INFO | fairseq_cli.train | end of epoch 603 (average epoch stats below)
2022-03-07 20:51:42 | INFO | train | epoch 603 | loss 1.747 | ppl 3.36 | wps 21771.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29354 | lr 0.000184572 | gnorm 0.351 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 87118
2022-03-07 20:51:42 | INFO | fairseq.trainer | begin training epoch 604
2022-03-07 20:51:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:52:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:53:58 | INFO | train_inner | epoch 604:     47 / 49 loss=1.748, ppl=3.36, wps=21596, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=29400, lr=0.000184428, gnorm=0.352, loss_scale=32, train_wall=265, gb_free=21.5, wall=87253
2022-03-07 20:54:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:54:08 | INFO | valid | epoch 604 | valid on 'valid' subset | loss 11.162 | ppl 2291.38 | wps 37894.9 | wpb 510.9 | bsz 1 | num_updates 29402 | best_loss 8.621
2022-03-07 20:54:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 604 @ 29402 updates
2022-03-07 20:54:08 | INFO | fairseq_cli.train | end of epoch 604 (average epoch stats below)
2022-03-07 20:54:08 | INFO | train | epoch 604 | loss 1.748 | ppl 3.36 | wps 21346.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29402 | lr 0.000184422 | gnorm 0.354 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 87263
2022-03-07 20:54:08 | INFO | fairseq.trainer | begin training epoch 605
2022-03-07 20:54:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:56:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:56:34 | INFO | valid | epoch 605 | valid on 'valid' subset | loss 11.201 | ppl 2354.17 | wps 37995.4 | wpb 510.9 | bsz 1 | num_updates 29451 | best_loss 8.621
2022-03-07 20:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 605 @ 29451 updates
2022-03-07 20:56:34 | INFO | fairseq_cli.train | end of epoch 605 (average epoch stats below)
2022-03-07 20:56:34 | INFO | train | epoch 605 | loss 1.747 | ppl 3.36 | wps 21792.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29451 | lr 0.000184268 | gnorm 0.352 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 87409
2022-03-07 20:56:34 | INFO | fairseq.trainer | begin training epoch 606
2022-03-07 20:56:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:58:54 | INFO | train_inner | epoch 606:     49 / 49 loss=1.747, ppl=3.36, wps=21799.9, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=29500, lr=0.000184115, gnorm=0.355, loss_scale=32, train_wall=261, gb_free=21.5, wall=87549
2022-03-07 20:58:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:59:00 | INFO | valid | epoch 606 | valid on 'valid' subset | loss 11.165 | ppl 2296.54 | wps 37872.1 | wpb 510.9 | bsz 1 | num_updates 29500 | best_loss 8.621
2022-03-07 20:59:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 606 @ 29500 updates
2022-03-07 20:59:00 | INFO | fairseq_cli.train | end of epoch 606 (average epoch stats below)
2022-03-07 20:59:00 | INFO | train | epoch 606 | loss 1.747 | ppl 3.36 | wps 21782.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29500 | lr 0.000184115 | gnorm 0.356 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 87555
2022-03-07 20:59:00 | INFO | fairseq.trainer | begin training epoch 607
2022-03-07 20:59:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:59:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:01:26 | INFO | valid | epoch 607 | valid on 'valid' subset | loss 11.168 | ppl 2301.51 | wps 38031 | wpb 510.9 | bsz 1 | num_updates 29548 | best_loss 8.621
2022-03-07 21:01:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 607 @ 29548 updates
2022-03-07 21:01:26 | INFO | fairseq_cli.train | end of epoch 607 (average epoch stats below)
2022-03-07 21:01:26 | INFO | train | epoch 607 | loss 1.747 | ppl 3.36 | wps 21340 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29548 | lr 0.000183965 | gnorm 0.353 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 87701
2022-03-07 21:01:26 | INFO | fairseq.trainer | begin training epoch 608
2022-03-07 21:01:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:03:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:03:52 | INFO | valid | epoch 608 | valid on 'valid' subset | loss 11.169 | ppl 2301.87 | wps 37771.9 | wpb 510.9 | bsz 1 | num_updates 29597 | best_loss 8.621
2022-03-07 21:03:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 608 @ 29597 updates
2022-03-07 21:03:52 | INFO | fairseq_cli.train | end of epoch 608 (average epoch stats below)
2022-03-07 21:03:52 | INFO | train | epoch 608 | loss 1.747 | ppl 3.36 | wps 21783.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29597 | lr 0.000183813 | gnorm 0.36 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 87847
2022-03-07 21:03:52 | INFO | fairseq.trainer | begin training epoch 609
2022-03-07 21:03:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:04:00 | INFO | train_inner | epoch 609:      3 / 49 loss=1.747, ppl=3.36, wps=21180, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=29600, lr=0.000183804, gnorm=0.357, loss_scale=32, train_wall=265, gb_free=21.5, wall=87856
2022-03-07 21:05:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:06:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:06:17 | INFO | valid | epoch 609 | valid on 'valid' subset | loss 11.161 | ppl 2289.62 | wps 38151.2 | wpb 510.9 | bsz 1 | num_updates 29645 | best_loss 8.621
2022-03-07 21:06:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 609 @ 29645 updates
2022-03-07 21:06:17 | INFO | fairseq_cli.train | end of epoch 609 (average epoch stats below)
2022-03-07 21:06:17 | INFO | train | epoch 609 | loss 1.746 | ppl 3.35 | wps 21350.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29645 | lr 0.000183664 | gnorm 0.357 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 87993
2022-03-07 21:06:17 | INFO | fairseq.trainer | begin training epoch 610
2022-03-07 21:06:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:08:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:08:43 | INFO | valid | epoch 610 | valid on 'valid' subset | loss 11.177 | ppl 2316.12 | wps 37970.3 | wpb 510.9 | bsz 1 | num_updates 29694 | best_loss 8.621
2022-03-07 21:08:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 610 @ 29694 updates
2022-03-07 21:08:43 | INFO | fairseq_cli.train | end of epoch 610 (average epoch stats below)
2022-03-07 21:08:43 | INFO | train | epoch 610 | loss 1.746 | ppl 3.35 | wps 21803.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29694 | lr 0.000183512 | gnorm 0.355 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 88138
2022-03-07 21:08:43 | INFO | fairseq.trainer | begin training epoch 611
2022-03-07 21:08:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:09:00 | INFO | train_inner | epoch 611:      6 / 49 loss=1.746, ppl=3.35, wps=21608.8, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=29700, lr=0.000183494, gnorm=0.356, loss_scale=32, train_wall=265, gb_free=21.5, wall=88156
2022-03-07 21:11:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:11:09 | INFO | valid | epoch 611 | valid on 'valid' subset | loss 11.174 | ppl 2310.12 | wps 37851.1 | wpb 510.9 | bsz 1 | num_updates 29743 | best_loss 8.621
2022-03-07 21:11:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 611 @ 29743 updates
2022-03-07 21:11:09 | INFO | fairseq_cli.train | end of epoch 611 (average epoch stats below)
2022-03-07 21:11:09 | INFO | train | epoch 611 | loss 1.745 | ppl 3.35 | wps 21772.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29743 | lr 0.000183361 | gnorm 0.351 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 88284
2022-03-07 21:11:09 | INFO | fairseq.trainer | begin training epoch 612
2022-03-07 21:11:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:12:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:13:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:13:35 | INFO | valid | epoch 612 | valid on 'valid' subset | loss 11.185 | ppl 2327.54 | wps 37987.8 | wpb 510.9 | bsz 1 | num_updates 29791 | best_loss 8.621
2022-03-07 21:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 612 @ 29791 updates
2022-03-07 21:13:35 | INFO | fairseq_cli.train | end of epoch 612 (average epoch stats below)
2022-03-07 21:13:35 | INFO | train | epoch 612 | loss 1.745 | ppl 3.35 | wps 21339 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29791 | lr 0.000183213 | gnorm 0.349 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 88430
2022-03-07 21:13:35 | INFO | fairseq.trainer | begin training epoch 613
2022-03-07 21:13:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:14:01 | INFO | train_inner | epoch 613:      9 / 49 loss=1.745, ppl=3.35, wps=21591, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=29800, lr=0.000183186, gnorm=0.35, loss_scale=32, train_wall=265, gb_free=21.5, wall=88456
2022-03-07 21:15:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:16:01 | INFO | valid | epoch 613 | valid on 'valid' subset | loss 11.176 | ppl 2314.08 | wps 38196.5 | wpb 510.9 | bsz 1 | num_updates 29840 | best_loss 8.621
2022-03-07 21:16:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 613 @ 29840 updates
2022-03-07 21:16:01 | INFO | fairseq_cli.train | end of epoch 613 (average epoch stats below)
2022-03-07 21:16:01 | INFO | train | epoch 613 | loss 1.746 | ppl 3.35 | wps 21791.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29840 | lr 0.000183063 | gnorm 0.355 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 88576
2022-03-07 21:16:01 | INFO | fairseq.trainer | begin training epoch 614
2022-03-07 21:16:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:18:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:18:27 | INFO | valid | epoch 614 | valid on 'valid' subset | loss 11.168 | ppl 2300.24 | wps 37979.6 | wpb 510.9 | bsz 1 | num_updates 29889 | best_loss 8.621
2022-03-07 21:18:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 614 @ 29889 updates
2022-03-07 21:18:27 | INFO | fairseq_cli.train | end of epoch 614 (average epoch stats below)
2022-03-07 21:18:27 | INFO | train | epoch 614 | loss 1.745 | ppl 3.35 | wps 21785.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29889 | lr 0.000182913 | gnorm 0.357 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 88722
2022-03-07 21:18:27 | INFO | fairseq.trainer | begin training epoch 615
2022-03-07 21:18:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:18:58 | INFO | train_inner | epoch 615:     11 / 49 loss=1.746, ppl=3.35, wps=21800.8, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=29900, lr=0.000182879, gnorm=0.356, loss_scale=64, train_wall=262, gb_free=21.5, wall=88754
2022-03-07 21:19:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:20:53 | INFO | valid | epoch 615 | valid on 'valid' subset | loss 11.155 | ppl 2279.85 | wps 38020.1 | wpb 510.9 | bsz 1 | num_updates 29937 | best_loss 8.621
2022-03-07 21:20:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 615 @ 29937 updates
2022-03-07 21:20:53 | INFO | fairseq_cli.train | end of epoch 615 (average epoch stats below)
2022-03-07 21:20:53 | INFO | train | epoch 615 | loss 1.745 | ppl 3.35 | wps 21327.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29937 | lr 0.000182766 | gnorm 0.351 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 88868
2022-03-07 21:20:53 | INFO | fairseq.trainer | begin training epoch 616
2022-03-07 21:20:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:23:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:23:18 | INFO | valid | epoch 616 | valid on 'valid' subset | loss 11.195 | ppl 2345.18 | wps 38058.6 | wpb 510.9 | bsz 1 | num_updates 29986 | best_loss 8.621
2022-03-07 21:23:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 616 @ 29986 updates
2022-03-07 21:23:18 | INFO | fairseq_cli.train | end of epoch 616 (average epoch stats below)
2022-03-07 21:23:18 | INFO | train | epoch 616 | loss 1.743 | ppl 3.35 | wps 21786 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29986 | lr 0.000182617 | gnorm 0.347 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 89014
2022-03-07 21:23:18 | INFO | fairseq.trainer | begin training epoch 617
2022-03-07 21:23:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:23:59 | INFO | train_inner | epoch 617:     14 / 49 loss=1.744, ppl=3.35, wps=21594, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=30000, lr=0.000182574, gnorm=0.35, loss_scale=32, train_wall=265, gb_free=21.5, wall=89054
2022-03-07 21:25:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:25:44 | INFO | valid | epoch 617 | valid on 'valid' subset | loss 11.178 | ppl 2316.56 | wps 37999.7 | wpb 510.9 | bsz 1 | num_updates 30035 | best_loss 8.621
2022-03-07 21:25:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 617 @ 30035 updates
2022-03-07 21:25:44 | INFO | fairseq_cli.train | end of epoch 617 (average epoch stats below)
2022-03-07 21:25:44 | INFO | train | epoch 617 | loss 1.745 | ppl 3.35 | wps 21781.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30035 | lr 0.000182468 | gnorm 0.355 | loss_scale 64 | train_wall 129 | gb_free 21.5 | wall 89160
2022-03-07 21:25:44 | INFO | fairseq.trainer | begin training epoch 618
2022-03-07 21:25:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:27:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:28:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:28:10 | INFO | valid | epoch 618 | valid on 'valid' subset | loss 11.157 | ppl 2284.21 | wps 38031.9 | wpb 510.9 | bsz 1 | num_updates 30083 | best_loss 8.621
2022-03-07 21:28:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 618 @ 30083 updates
2022-03-07 21:28:10 | INFO | fairseq_cli.train | end of epoch 618 (average epoch stats below)
2022-03-07 21:28:10 | INFO | train | epoch 618 | loss 1.744 | ppl 3.35 | wps 21333.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30083 | lr 0.000182322 | gnorm 0.353 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 89306
2022-03-07 21:28:10 | INFO | fairseq.trainer | begin training epoch 619
2022-03-07 21:28:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:28:59 | INFO | train_inner | epoch 619:     17 / 49 loss=1.744, ppl=3.35, wps=21589.9, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=30100, lr=0.000182271, gnorm=0.352, loss_scale=32, train_wall=265, gb_free=21.5, wall=89355
2022-03-07 21:30:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:30:36 | INFO | valid | epoch 619 | valid on 'valid' subset | loss 11.171 | ppl 2305.09 | wps 38034.5 | wpb 510.9 | bsz 1 | num_updates 30132 | best_loss 8.621
2022-03-07 21:30:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 619 @ 30132 updates
2022-03-07 21:30:36 | INFO | fairseq_cli.train | end of epoch 619 (average epoch stats below)
2022-03-07 21:30:36 | INFO | train | epoch 619 | loss 1.743 | ppl 3.35 | wps 21797.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30132 | lr 0.000182174 | gnorm 0.348 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 89451
2022-03-07 21:30:36 | INFO | fairseq.trainer | begin training epoch 620
2022-03-07 21:30:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:32:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:33:02 | INFO | valid | epoch 620 | valid on 'valid' subset | loss 11.191 | ppl 2338.68 | wps 37896.9 | wpb 510.9 | bsz 1 | num_updates 30181 | best_loss 8.621
2022-03-07 21:33:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 620 @ 30181 updates
2022-03-07 21:33:02 | INFO | fairseq_cli.train | end of epoch 620 (average epoch stats below)
2022-03-07 21:33:02 | INFO | train | epoch 620 | loss 1.744 | ppl 3.35 | wps 21795 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30181 | lr 0.000182026 | gnorm 0.346 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 89597
2022-03-07 21:33:02 | INFO | fairseq.trainer | begin training epoch 621
2022-03-07 21:33:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:33:57 | INFO | train_inner | epoch 621:     19 / 49 loss=1.743, ppl=3.35, wps=21817.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=30200, lr=0.000181969, gnorm=0.348, loss_scale=64, train_wall=262, gb_free=21.5, wall=89652
2022-03-07 21:34:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:35:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:35:28 | INFO | valid | epoch 621 | valid on 'valid' subset | loss 11.164 | ppl 2294.48 | wps 38072.2 | wpb 510.9 | bsz 1 | num_updates 30229 | best_loss 8.621
2022-03-07 21:35:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 621 @ 30229 updates
2022-03-07 21:35:28 | INFO | fairseq_cli.train | end of epoch 621 (average epoch stats below)
2022-03-07 21:35:28 | INFO | train | epoch 621 | loss 1.744 | ppl 3.35 | wps 21344.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30229 | lr 0.000181881 | gnorm 0.354 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 89743
2022-03-07 21:35:28 | INFO | fairseq.trainer | begin training epoch 622
2022-03-07 21:35:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:37:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:37:54 | INFO | valid | epoch 622 | valid on 'valid' subset | loss 11.184 | ppl 2326.25 | wps 37990.9 | wpb 510.9 | bsz 1 | num_updates 30278 | best_loss 8.621
2022-03-07 21:37:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 622 @ 30278 updates
2022-03-07 21:37:54 | INFO | fairseq_cli.train | end of epoch 622 (average epoch stats below)
2022-03-07 21:37:54 | INFO | train | epoch 622 | loss 1.744 | ppl 3.35 | wps 21781.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30278 | lr 0.000181734 | gnorm 0.352 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 89889
2022-03-07 21:37:54 | INFO | fairseq.trainer | begin training epoch 623
2022-03-07 21:37:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:38:57 | INFO | train_inner | epoch 623:     22 / 49 loss=1.744, ppl=3.35, wps=21593.7, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=30300, lr=0.000181668, gnorm=0.352, loss_scale=32, train_wall=265, gb_free=21.5, wall=89952
2022-03-07 21:40:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:40:20 | INFO | valid | epoch 623 | valid on 'valid' subset | loss 11.173 | ppl 2308.32 | wps 38021.6 | wpb 510.9 | bsz 1 | num_updates 30327 | best_loss 8.621
2022-03-07 21:40:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 623 @ 30327 updates
2022-03-07 21:40:20 | INFO | fairseq_cli.train | end of epoch 623 (average epoch stats below)
2022-03-07 21:40:20 | INFO | train | epoch 623 | loss 1.743 | ppl 3.35 | wps 21764.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30327 | lr 0.000181587 | gnorm 0.348 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 90035
2022-03-07 21:40:20 | INFO | fairseq.trainer | begin training epoch 624
2022-03-07 21:40:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:41:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:42:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:42:45 | INFO | valid | epoch 624 | valid on 'valid' subset | loss 11.183 | ppl 2325.38 | wps 37969.1 | wpb 510.9 | bsz 1 | num_updates 30375 | best_loss 8.621
2022-03-07 21:42:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 624 @ 30375 updates
2022-03-07 21:42:45 | INFO | fairseq_cli.train | end of epoch 624 (average epoch stats below)
2022-03-07 21:42:45 | INFO | train | epoch 624 | loss 1.742 | ppl 3.35 | wps 21348.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30375 | lr 0.000181444 | gnorm 0.348 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 90181
2022-03-07 21:42:45 | INFO | fairseq.trainer | begin training epoch 625
2022-03-07 21:42:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:43:58 | INFO | train_inner | epoch 625:     25 / 49 loss=1.742, ppl=3.35, wps=21585.2, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=30400, lr=0.000181369, gnorm=0.348, loss_scale=32, train_wall=265, gb_free=21.5, wall=90253
2022-03-07 21:45:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:45:11 | INFO | valid | epoch 625 | valid on 'valid' subset | loss 11.178 | ppl 2317.53 | wps 37921.4 | wpb 510.9 | bsz 1 | num_updates 30424 | best_loss 8.621
2022-03-07 21:45:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 625 @ 30424 updates
2022-03-07 21:45:11 | INFO | fairseq_cli.train | end of epoch 625 (average epoch stats below)
2022-03-07 21:45:11 | INFO | train | epoch 625 | loss 1.742 | ppl 3.34 | wps 21778.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30424 | lr 0.000181298 | gnorm 0.348 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 90327
2022-03-07 21:45:11 | INFO | fairseq.trainer | begin training epoch 626
2022-03-07 21:45:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:47:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:47:37 | INFO | valid | epoch 626 | valid on 'valid' subset | loss 11.158 | ppl 2284.4 | wps 38065.7 | wpb 510.9 | bsz 1 | num_updates 30473 | best_loss 8.621
2022-03-07 21:47:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 626 @ 30473 updates
2022-03-07 21:47:37 | INFO | fairseq_cli.train | end of epoch 626 (average epoch stats below)
2022-03-07 21:47:37 | INFO | train | epoch 626 | loss 1.742 | ppl 3.35 | wps 21797.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30473 | lr 0.000181152 | gnorm 0.359 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 90472
2022-03-07 21:47:37 | INFO | fairseq.trainer | begin training epoch 627
2022-03-07 21:47:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:48:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:48:58 | INFO | train_inner | epoch 627:     28 / 49 loss=1.742, ppl=3.35, wps=21604, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=30500, lr=0.000181071, gnorm=0.354, loss_scale=32, train_wall=265, gb_free=21.5, wall=90553
2022-03-07 21:49:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:50:03 | INFO | valid | epoch 627 | valid on 'valid' subset | loss 11.173 | ppl 2309.21 | wps 38134.5 | wpb 510.9 | bsz 1 | num_updates 30521 | best_loss 8.621
2022-03-07 21:50:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 627 @ 30521 updates
2022-03-07 21:50:03 | INFO | fairseq_cli.train | end of epoch 627 (average epoch stats below)
2022-03-07 21:50:03 | INFO | train | epoch 627 | loss 1.742 | ppl 3.34 | wps 21363.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30521 | lr 0.000181009 | gnorm 0.351 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 90618
2022-03-07 21:50:03 | INFO | fairseq.trainer | begin training epoch 628
2022-03-07 21:50:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:52:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:52:29 | INFO | valid | epoch 628 | valid on 'valid' subset | loss 11.168 | ppl 2301.45 | wps 37912.6 | wpb 510.9 | bsz 1 | num_updates 30570 | best_loss 8.621
2022-03-07 21:52:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 628 @ 30570 updates
2022-03-07 21:52:29 | INFO | fairseq_cli.train | end of epoch 628 (average epoch stats below)
2022-03-07 21:52:29 | INFO | train | epoch 628 | loss 1.741 | ppl 3.34 | wps 21784.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30570 | lr 0.000180864 | gnorm 0.35 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 90764
2022-03-07 21:52:29 | INFO | fairseq.trainer | begin training epoch 629
2022-03-07 21:52:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:53:55 | INFO | train_inner | epoch 629:     30 / 49 loss=1.741, ppl=3.34, wps=21819.9, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=30600, lr=0.000180775, gnorm=0.35, loss_scale=32, train_wall=262, gb_free=21.5, wall=90851
2022-03-07 21:54:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:54:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:54:54 | INFO | valid | epoch 629 | valid on 'valid' subset | loss 11.181 | ppl 2322.19 | wps 37892.6 | wpb 510.9 | bsz 1 | num_updates 30618 | best_loss 8.621
2022-03-07 21:54:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 629 @ 30618 updates
2022-03-07 21:54:54 | INFO | fairseq_cli.train | end of epoch 629 (average epoch stats below)
2022-03-07 21:54:54 | INFO | train | epoch 629 | loss 1.741 | ppl 3.34 | wps 21367.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30618 | lr 0.000180722 | gnorm 0.353 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 90910
2022-03-07 21:54:54 | INFO | fairseq.trainer | begin training epoch 630
2022-03-07 21:54:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:57:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:57:20 | INFO | valid | epoch 630 | valid on 'valid' subset | loss 11.19 | ppl 2336.19 | wps 37980.8 | wpb 510.9 | bsz 1 | num_updates 30667 | best_loss 8.621
2022-03-07 21:57:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 630 @ 30667 updates
2022-03-07 21:57:20 | INFO | fairseq_cli.train | end of epoch 630 (average epoch stats below)
2022-03-07 21:57:20 | INFO | train | epoch 630 | loss 1.741 | ppl 3.34 | wps 21805.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30667 | lr 0.000180578 | gnorm 0.354 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 91055
2022-03-07 21:57:20 | INFO | fairseq.trainer | begin training epoch 631
2022-03-07 21:57:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:58:55 | INFO | train_inner | epoch 631:     33 / 49 loss=1.741, ppl=3.34, wps=21610.4, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=30700, lr=0.000180481, gnorm=0.352, loss_scale=32, train_wall=265, gb_free=21.5, wall=91151
2022-03-07 21:59:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:59:46 | INFO | valid | epoch 631 | valid on 'valid' subset | loss 11.168 | ppl 2301.61 | wps 38095.1 | wpb 510.9 | bsz 1 | num_updates 30716 | best_loss 8.621
2022-03-07 21:59:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 631 @ 30716 updates
2022-03-07 21:59:46 | INFO | fairseq_cli.train | end of epoch 631 (average epoch stats below)
2022-03-07 21:59:46 | INFO | train | epoch 631 | loss 1.741 | ppl 3.34 | wps 21780.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30716 | lr 0.000180434 | gnorm 0.348 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 91201
2022-03-07 21:59:46 | INFO | fairseq.trainer | begin training epoch 632
2022-03-07 21:59:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:00:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:02:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:02:12 | INFO | valid | epoch 632 | valid on 'valid' subset | loss 11.19 | ppl 2335.79 | wps 38122.8 | wpb 510.9 | bsz 1 | num_updates 30764 | best_loss 8.621
2022-03-07 22:02:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 632 @ 30764 updates
2022-03-07 22:02:12 | INFO | fairseq_cli.train | end of epoch 632 (average epoch stats below)
2022-03-07 22:02:12 | INFO | train | epoch 632 | loss 1.741 | ppl 3.34 | wps 21383 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30764 | lr 0.000180293 | gnorm 0.353 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 91347
2022-03-07 22:02:12 | INFO | fairseq.trainer | begin training epoch 633
2022-03-07 22:02:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:03:56 | INFO | train_inner | epoch 633:     36 / 49 loss=1.741, ppl=3.34, wps=21612.1, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=30800, lr=0.000180187, gnorm=0.351, loss_scale=32, train_wall=265, gb_free=21.5, wall=91451
2022-03-07 22:04:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:04:37 | INFO | valid | epoch 633 | valid on 'valid' subset | loss 11.147 | ppl 2267.37 | wps 37948.6 | wpb 510.9 | bsz 1 | num_updates 30813 | best_loss 8.621
2022-03-07 22:04:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 633 @ 30813 updates
2022-03-07 22:04:37 | INFO | fairseq_cli.train | end of epoch 633 (average epoch stats below)
2022-03-07 22:04:37 | INFO | train | epoch 633 | loss 1.74 | ppl 3.34 | wps 21786.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30813 | lr 0.000180149 | gnorm 0.348 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 91493
2022-03-07 22:04:38 | INFO | fairseq.trainer | begin training epoch 634
2022-03-07 22:04:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:06:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:07:03 | INFO | valid | epoch 634 | valid on 'valid' subset | loss 11.169 | ppl 2302.11 | wps 38003.1 | wpb 510.9 | bsz 1 | num_updates 30862 | best_loss 8.621
2022-03-07 22:07:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 634 @ 30862 updates
2022-03-07 22:07:03 | INFO | fairseq_cli.train | end of epoch 634 (average epoch stats below)
2022-03-07 22:07:03 | INFO | train | epoch 634 | loss 1.74 | ppl 3.34 | wps 21786.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30862 | lr 0.000180006 | gnorm 0.353 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 91639
2022-03-07 22:07:03 | INFO | fairseq.trainer | begin training epoch 635
2022-03-07 22:07:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:07:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:08:56 | INFO | train_inner | epoch 635:     39 / 49 loss=1.74, ppl=3.34, wps=21621.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=30900, lr=0.000179896, gnorm=0.351, loss_scale=32, train_wall=265, gb_free=21.5, wall=91751
2022-03-07 22:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:09:29 | INFO | valid | epoch 635 | valid on 'valid' subset | loss 11.18 | ppl 2320.47 | wps 37751.7 | wpb 510.9 | bsz 1 | num_updates 30910 | best_loss 8.621
2022-03-07 22:09:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 635 @ 30910 updates
2022-03-07 22:09:29 | INFO | fairseq_cli.train | end of epoch 635 (average epoch stats below)
2022-03-07 22:09:29 | INFO | train | epoch 635 | loss 1.74 | ppl 3.34 | wps 21385.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30910 | lr 0.000179867 | gnorm 0.347 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 91784
2022-03-07 22:09:29 | INFO | fairseq.trainer | begin training epoch 636
2022-03-07 22:09:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:11:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:11:55 | INFO | valid | epoch 636 | valid on 'valid' subset | loss 11.162 | ppl 2291.28 | wps 38075.8 | wpb 510.9 | bsz 1 | num_updates 30959 | best_loss 8.621
2022-03-07 22:11:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 636 @ 30959 updates
2022-03-07 22:11:55 | INFO | fairseq_cli.train | end of epoch 636 (average epoch stats below)
2022-03-07 22:11:55 | INFO | train | epoch 636 | loss 1.74 | ppl 3.34 | wps 21789 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30959 | lr 0.000179724 | gnorm 0.35 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 91930
2022-03-07 22:11:55 | INFO | fairseq.trainer | begin training epoch 637
2022-03-07 22:11:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:13:53 | INFO | train_inner | epoch 637:     41 / 49 loss=1.74, ppl=3.34, wps=21810.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=31000, lr=0.000179605, gnorm=0.351, loss_scale=64, train_wall=262, gb_free=21.5, wall=92048
2022-03-07 22:14:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:14:20 | INFO | valid | epoch 637 | valid on 'valid' subset | loss 11.175 | ppl 2312.13 | wps 38239.6 | wpb 510.9 | bsz 1 | num_updates 31008 | best_loss 8.621
2022-03-07 22:14:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 637 @ 31008 updates
2022-03-07 22:14:21 | INFO | fairseq_cli.train | end of epoch 637 (average epoch stats below)
2022-03-07 22:14:21 | INFO | train | epoch 637 | loss 1.74 | ppl 3.34 | wps 21806.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31008 | lr 0.000179582 | gnorm 0.352 | loss_scale 64 | train_wall 129 | gb_free 21.5 | wall 92076
2022-03-07 22:14:21 | INFO | fairseq.trainer | begin training epoch 638
2022-03-07 22:14:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:14:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:16:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:16:46 | INFO | valid | epoch 638 | valid on 'valid' subset | loss 11.164 | ppl 2294.08 | wps 37942.6 | wpb 510.9 | bsz 1 | num_updates 31056 | best_loss 8.621
2022-03-07 22:16:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 638 @ 31056 updates
2022-03-07 22:16:46 | INFO | fairseq_cli.train | end of epoch 638 (average epoch stats below)
2022-03-07 22:16:46 | INFO | train | epoch 638 | loss 1.739 | ppl 3.34 | wps 21334.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31056 | lr 0.000179443 | gnorm 0.353 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 92222
2022-03-07 22:16:46 | INFO | fairseq.trainer | begin training epoch 639
2022-03-07 22:16:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:17:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:18:56 | INFO | train_inner | epoch 639:     45 / 49 loss=1.739, ppl=3.34, wps=21396.1, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=31100, lr=0.000179316, gnorm=0.352, loss_scale=16, train_wall=268, gb_free=21.5, wall=92352
2022-03-07 22:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:19:12 | INFO | valid | epoch 639 | valid on 'valid' subset | loss 11.15 | ppl 2271.89 | wps 38155.5 | wpb 510.9 | bsz 1 | num_updates 31104 | best_loss 8.621
2022-03-07 22:19:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 639 @ 31104 updates
2022-03-07 22:19:12 | INFO | fairseq_cli.train | end of epoch 639 (average epoch stats below)
2022-03-07 22:19:12 | INFO | train | epoch 639 | loss 1.739 | ppl 3.34 | wps 21352.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31104 | lr 0.000179305 | gnorm 0.35 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 92367
2022-03-07 22:19:12 | INFO | fairseq.trainer | begin training epoch 640
2022-03-07 22:19:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:21:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:21:38 | INFO | valid | epoch 640 | valid on 'valid' subset | loss 11.178 | ppl 2317.25 | wps 37984.7 | wpb 510.9 | bsz 1 | num_updates 31153 | best_loss 8.621
2022-03-07 22:21:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 640 @ 31153 updates
2022-03-07 22:21:38 | INFO | fairseq_cli.train | end of epoch 640 (average epoch stats below)
2022-03-07 22:21:38 | INFO | train | epoch 640 | loss 1.739 | ppl 3.34 | wps 21796.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31153 | lr 0.000179164 | gnorm 0.349 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 92513
2022-03-07 22:21:38 | INFO | fairseq.trainer | begin training epoch 641
2022-03-07 22:21:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:23:54 | INFO | train_inner | epoch 641:     47 / 49 loss=1.739, ppl=3.34, wps=21805, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=31200, lr=0.000179029, gnorm=0.35, loss_scale=32, train_wall=263, gb_free=21.5, wall=92649
2022-03-07 22:23:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:24:04 | INFO | valid | epoch 641 | valid on 'valid' subset | loss 11.176 | ppl 2314.22 | wps 37939.3 | wpb 510.9 | bsz 1 | num_updates 31202 | best_loss 8.621
2022-03-07 22:24:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 641 @ 31202 updates
2022-03-07 22:24:04 | INFO | fairseq_cli.train | end of epoch 641 (average epoch stats below)
2022-03-07 22:24:04 | INFO | train | epoch 641 | loss 1.739 | ppl 3.34 | wps 21770 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31202 | lr 0.000179023 | gnorm 0.351 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 92659
2022-03-07 22:24:04 | INFO | fairseq.trainer | begin training epoch 642
2022-03-07 22:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:26:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:26:30 | INFO | valid | epoch 642 | valid on 'valid' subset | loss 11.168 | ppl 2300.92 | wps 38046.7 | wpb 510.9 | bsz 1 | num_updates 31251 | best_loss 8.621
2022-03-07 22:26:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 642 @ 31251 updates
2022-03-07 22:26:30 | INFO | fairseq_cli.train | end of epoch 642 (average epoch stats below)
2022-03-07 22:26:30 | INFO | train | epoch 642 | loss 1.739 | ppl 3.34 | wps 21788 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31251 | lr 0.000178883 | gnorm 0.349 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 92805
2022-03-07 22:26:30 | INFO | fairseq.trainer | begin training epoch 643
2022-03-07 22:26:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:28:50 | INFO | train_inner | epoch 643:     49 / 49 loss=1.739, ppl=3.34, wps=21793.4, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=31300, lr=0.000178743, gnorm=0.351, loss_scale=32, train_wall=261, gb_free=21.5, wall=92945
2022-03-07 22:28:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:28:56 | INFO | valid | epoch 643 | valid on 'valid' subset | loss 11.162 | ppl 2290.81 | wps 37941.7 | wpb 510.9 | bsz 1 | num_updates 31300 | best_loss 8.621
2022-03-07 22:28:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 643 @ 31300 updates
2022-03-07 22:28:56 | INFO | fairseq_cli.train | end of epoch 643 (average epoch stats below)
2022-03-07 22:28:56 | INFO | train | epoch 643 | loss 1.738 | ppl 3.34 | wps 21776.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31300 | lr 0.000178743 | gnorm 0.351 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 92951
2022-03-07 22:28:56 | INFO | fairseq.trainer | begin training epoch 644
2022-03-07 22:28:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:29:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:31:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:31:22 | INFO | valid | epoch 644 | valid on 'valid' subset | loss 11.148 | ppl 2269.07 | wps 37963.5 | wpb 510.9 | bsz 1 | num_updates 31348 | best_loss 8.621
2022-03-07 22:31:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 644 @ 31348 updates
2022-03-07 22:31:22 | INFO | fairseq_cli.train | end of epoch 644 (average epoch stats below)
2022-03-07 22:31:22 | INFO | train | epoch 644 | loss 1.738 | ppl 3.33 | wps 21354.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31348 | lr 0.000178606 | gnorm 0.349 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 93097
2022-03-07 22:31:22 | INFO | fairseq.trainer | begin training epoch 645
2022-03-07 22:31:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:33:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:33:47 | INFO | valid | epoch 645 | valid on 'valid' subset | loss 11.185 | ppl 2327.77 | wps 37918.6 | wpb 510.9 | bsz 1 | num_updates 31397 | best_loss 8.621
2022-03-07 22:33:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 645 @ 31397 updates
2022-03-07 22:33:47 | INFO | fairseq_cli.train | end of epoch 645 (average epoch stats below)
2022-03-07 22:33:47 | INFO | train | epoch 645 | loss 1.738 | ppl 3.34 | wps 21780.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31397 | lr 0.000178466 | gnorm 0.35 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 93243
2022-03-07 22:33:47 | INFO | fairseq.trainer | begin training epoch 646
2022-03-07 22:33:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:33:56 | INFO | train_inner | epoch 646:      3 / 49 loss=1.738, ppl=3.34, wps=21184.1, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=31400, lr=0.000178458, gnorm=0.349, loss_scale=32, train_wall=265, gb_free=21.5, wall=93251
2022-03-07 22:36:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:36:13 | INFO | valid | epoch 646 | valid on 'valid' subset | loss 11.187 | ppl 2331.61 | wps 37971.2 | wpb 510.9 | bsz 1 | num_updates 31446 | best_loss 8.621
2022-03-07 22:36:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 646 @ 31446 updates
2022-03-07 22:36:13 | INFO | fairseq_cli.train | end of epoch 646 (average epoch stats below)
2022-03-07 22:36:13 | INFO | train | epoch 646 | loss 1.738 | ppl 3.34 | wps 21783.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31446 | lr 0.000178327 | gnorm 0.349 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 93389
2022-03-07 22:36:13 | INFO | fairseq.trainer | begin training epoch 647
2022-03-07 22:36:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:36:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:38:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:38:39 | INFO | valid | epoch 647 | valid on 'valid' subset | loss 11.16 | ppl 2288.93 | wps 38069.3 | wpb 510.9 | bsz 1 | num_updates 31494 | best_loss 8.621
2022-03-07 22:38:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 647 @ 31494 updates
2022-03-07 22:38:39 | INFO | fairseq_cli.train | end of epoch 647 (average epoch stats below)
2022-03-07 22:38:39 | INFO | train | epoch 647 | loss 1.737 | ppl 3.33 | wps 21365 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31494 | lr 0.000178191 | gnorm 0.344 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 93534
2022-03-07 22:38:39 | INFO | fairseq.trainer | begin training epoch 648
2022-03-07 22:38:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:38:56 | INFO | train_inner | epoch 648:      6 / 49 loss=1.737, ppl=3.33, wps=21610.3, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=31500, lr=0.000178174, gnorm=0.346, loss_scale=32, train_wall=265, gb_free=21.5, wall=93552
2022-03-07 22:40:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:41:05 | INFO | valid | epoch 648 | valid on 'valid' subset | loss 11.159 | ppl 2286.9 | wps 37949.7 | wpb 510.9 | bsz 1 | num_updates 31543 | best_loss 8.621
2022-03-07 22:41:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 648 @ 31543 updates
2022-03-07 22:41:05 | INFO | fairseq_cli.train | end of epoch 648 (average epoch stats below)
2022-03-07 22:41:05 | INFO | train | epoch 648 | loss 1.737 | ppl 3.33 | wps 21788.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31543 | lr 0.000178053 | gnorm 0.348 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 93680
2022-03-07 22:41:05 | INFO | fairseq.trainer | begin training epoch 649
2022-03-07 22:41:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:43:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:43:31 | INFO | valid | epoch 649 | valid on 'valid' subset | loss 11.148 | ppl 2269.44 | wps 37957.6 | wpb 510.9 | bsz 1 | num_updates 31592 | best_loss 8.621
2022-03-07 22:43:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 649 @ 31592 updates
2022-03-07 22:43:31 | INFO | fairseq_cli.train | end of epoch 649 (average epoch stats below)
2022-03-07 22:43:31 | INFO | train | epoch 649 | loss 1.737 | ppl 3.33 | wps 21779.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31592 | lr 0.000177915 | gnorm 0.349 | loss_scale 64 | train_wall 129 | gb_free 21.5 | wall 93826
2022-03-07 22:43:31 | INFO | fairseq.trainer | begin training epoch 650
2022-03-07 22:43:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:43:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:43:57 | INFO | train_inner | epoch 650:      9 / 49 loss=1.737, ppl=3.33, wps=21592.8, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=31600, lr=0.000177892, gnorm=0.349, loss_scale=32, train_wall=265, gb_free=21.5, wall=93852
2022-03-07 22:45:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:45:57 | INFO | valid | epoch 650 | valid on 'valid' subset | loss 11.168 | ppl 2301.58 | wps 37445.4 | wpb 510.9 | bsz 1 | num_updates 31640 | best_loss 8.621
2022-03-07 22:45:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 650 @ 31640 updates
2022-03-07 22:45:57 | INFO | fairseq_cli.train | end of epoch 650 (average epoch stats below)
2022-03-07 22:45:57 | INFO | train | epoch 650 | loss 1.736 | ppl 3.33 | wps 21342.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31640 | lr 0.00017778 | gnorm 0.348 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 93972
2022-03-07 22:45:57 | INFO | fairseq.trainer | begin training epoch 651
2022-03-07 22:45:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:48:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:48:23 | INFO | valid | epoch 651 | valid on 'valid' subset | loss 11.157 | ppl 2283.32 | wps 38003.9 | wpb 510.9 | bsz 1 | num_updates 31689 | best_loss 8.621
2022-03-07 22:48:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 651 @ 31689 updates
2022-03-07 22:48:23 | INFO | fairseq_cli.train | end of epoch 651 (average epoch stats below)
2022-03-07 22:48:23 | INFO | train | epoch 651 | loss 1.736 | ppl 3.33 | wps 21784.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31689 | lr 0.000177642 | gnorm 0.346 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 94118
2022-03-07 22:48:23 | INFO | fairseq.trainer | begin training epoch 652
2022-03-07 22:48:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:48:54 | INFO | train_inner | epoch 652:     11 / 49 loss=1.736, ppl=3.33, wps=21803.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=31700, lr=0.000177611, gnorm=0.348, loss_scale=32, train_wall=262, gb_free=21.5, wall=94150
2022-03-07 22:50:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:50:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:50:48 | INFO | valid | epoch 652 | valid on 'valid' subset | loss 11.178 | ppl 2317 | wps 38062.2 | wpb 510.9 | bsz 1 | num_updates 31737 | best_loss 8.621
2022-03-07 22:50:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 652 @ 31737 updates
2022-03-07 22:50:48 | INFO | fairseq_cli.train | end of epoch 652 (average epoch stats below)
2022-03-07 22:50:48 | INFO | train | epoch 652 | loss 1.736 | ppl 3.33 | wps 21347.6 | ups 0.33 | wpb 64853.3 | bsz 126.7 | num_updates 31737 | lr 0.000177508 | gnorm 0.349 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 94264
2022-03-07 22:50:48 | INFO | fairseq.trainer | begin training epoch 653
2022-03-07 22:50:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:53:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:53:14 | INFO | valid | epoch 653 | valid on 'valid' subset | loss 11.171 | ppl 2305.61 | wps 38223.4 | wpb 510.9 | bsz 1 | num_updates 31786 | best_loss 8.621
2022-03-07 22:53:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 653 @ 31786 updates
2022-03-07 22:53:14 | INFO | fairseq_cli.train | end of epoch 653 (average epoch stats below)
2022-03-07 22:53:14 | INFO | train | epoch 653 | loss 1.736 | ppl 3.33 | wps 21796.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31786 | lr 0.000177371 | gnorm 0.348 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 94409
2022-03-07 22:53:14 | INFO | fairseq.trainer | begin training epoch 654
2022-03-07 22:53:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:53:55 | INFO | train_inner | epoch 654:     14 / 49 loss=1.736, ppl=3.33, wps=21609.1, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=31800, lr=0.000177332, gnorm=0.346, loss_scale=32, train_wall=265, gb_free=21.5, wall=94450
2022-03-07 22:55:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:55:40 | INFO | valid | epoch 654 | valid on 'valid' subset | loss 11.166 | ppl 2297.49 | wps 38248.6 | wpb 510.9 | bsz 1 | num_updates 31835 | best_loss 8.621
2022-03-07 22:55:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 654 @ 31835 updates
2022-03-07 22:55:40 | INFO | fairseq_cli.train | end of epoch 654 (average epoch stats below)
2022-03-07 22:55:40 | INFO | train | epoch 654 | loss 1.736 | ppl 3.33 | wps 21802 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31835 | lr 0.000177234 | gnorm 0.343 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 94555
2022-03-07 22:55:40 | INFO | fairseq.trainer | begin training epoch 655
2022-03-07 22:55:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:58:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:58:06 | INFO | valid | epoch 655 | valid on 'valid' subset | loss 11.187 | ppl 2331.62 | wps 38172.8 | wpb 510.9 | bsz 1 | num_updates 31884 | best_loss 8.621
2022-03-07 22:58:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 655 @ 31884 updates
2022-03-07 22:58:06 | INFO | fairseq_cli.train | end of epoch 655 (average epoch stats below)
2022-03-07 22:58:06 | INFO | train | epoch 655 | loss 1.736 | ppl 3.33 | wps 21808.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31884 | lr 0.000177098 | gnorm 0.345 | loss_scale 64 | train_wall 129 | gb_free 21.5 | wall 94701
2022-03-07 22:58:06 | INFO | fairseq.trainer | begin training epoch 656
2022-03-07 22:58:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:58:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:58:55 | INFO | train_inner | epoch 656:     17 / 49 loss=1.736, ppl=3.33, wps=21606.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=31900, lr=0.000177054, gnorm=0.344, loss_scale=32, train_wall=265, gb_free=21.5, wall=94750
2022-03-07 23:00:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:00:32 | INFO | valid | epoch 656 | valid on 'valid' subset | loss 11.156 | ppl 2282.65 | wps 38060.9 | wpb 510.9 | bsz 1 | num_updates 31932 | best_loss 8.621
2022-03-07 23:00:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 656 @ 31932 updates
2022-03-07 23:00:32 | INFO | fairseq_cli.train | end of epoch 656 (average epoch stats below)
2022-03-07 23:00:32 | INFO | train | epoch 656 | loss 1.735 | ppl 3.33 | wps 21330.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31932 | lr 0.000176965 | gnorm 0.345 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 94847
2022-03-07 23:00:32 | INFO | fairseq.trainer | begin training epoch 657
2022-03-07 23:00:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:02:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:02:57 | INFO | valid | epoch 657 | valid on 'valid' subset | loss 11.159 | ppl 2287.03 | wps 38128.7 | wpb 510.9 | bsz 1 | num_updates 31981 | best_loss 8.621
2022-03-07 23:02:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 657 @ 31981 updates
2022-03-07 23:02:57 | INFO | fairseq_cli.train | end of epoch 657 (average epoch stats below)
2022-03-07 23:02:57 | INFO | train | epoch 657 | loss 1.736 | ppl 3.33 | wps 21801.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31981 | lr 0.000176829 | gnorm 0.35 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 94993
2022-03-07 23:02:57 | INFO | fairseq.trainer | begin training epoch 658
2022-03-07 23:02:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:03:52 | INFO | train_inner | epoch 658:     19 / 49 loss=1.736, ppl=3.33, wps=21809.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=32000, lr=0.000176777, gnorm=0.349, loss_scale=32, train_wall=262, gb_free=21.5, wall=95047
2022-03-07 23:05:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:05:23 | INFO | valid | epoch 658 | valid on 'valid' subset | loss 11.156 | ppl 2282.24 | wps 38028.8 | wpb 510.9 | bsz 1 | num_updates 32030 | best_loss 8.621
2022-03-07 23:05:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 658 @ 32030 updates
2022-03-07 23:05:23 | INFO | fairseq_cli.train | end of epoch 658 (average epoch stats below)
2022-03-07 23:05:23 | INFO | train | epoch 658 | loss 1.736 | ppl 3.33 | wps 21793.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32030 | lr 0.000176694 | gnorm 0.352 | loss_scale 64 | train_wall 129 | gb_free 21.5 | wall 95138
2022-03-07 23:05:23 | INFO | fairseq.trainer | begin training epoch 659
2022-03-07 23:05:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:06:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:07:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:07:49 | INFO | valid | epoch 659 | valid on 'valid' subset | loss 11.161 | ppl 2289.87 | wps 37811.7 | wpb 510.9 | bsz 1 | num_updates 32078 | best_loss 8.621
2022-03-07 23:07:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 659 @ 32078 updates
2022-03-07 23:07:49 | INFO | fairseq_cli.train | end of epoch 659 (average epoch stats below)
2022-03-07 23:07:49 | INFO | train | epoch 659 | loss 1.734 | ppl 3.33 | wps 21343.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32078 | lr 0.000176562 | gnorm 0.346 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 95284
2022-03-07 23:07:49 | INFO | fairseq.trainer | begin training epoch 660
2022-03-07 23:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:08:53 | INFO | train_inner | epoch 660:     22 / 49 loss=1.735, ppl=3.33, wps=21600.9, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=32100, lr=0.000176501, gnorm=0.347, loss_scale=32, train_wall=265, gb_free=21.5, wall=95348
2022-03-07 23:10:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:10:15 | INFO | valid | epoch 660 | valid on 'valid' subset | loss 11.153 | ppl 2277.57 | wps 37832.1 | wpb 510.9 | bsz 1 | num_updates 32127 | best_loss 8.621
2022-03-07 23:10:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 660 @ 32127 updates
2022-03-07 23:10:15 | INFO | fairseq_cli.train | end of epoch 660 (average epoch stats below)
2022-03-07 23:10:15 | INFO | train | epoch 660 | loss 1.734 | ppl 3.33 | wps 21794.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32127 | lr 0.000176427 | gnorm 0.346 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 95430
2022-03-07 23:10:15 | INFO | fairseq.trainer | begin training epoch 661
2022-03-07 23:10:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:12:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:12:41 | INFO | valid | epoch 661 | valid on 'valid' subset | loss 11.157 | ppl 2284.16 | wps 37973.9 | wpb 510.9 | bsz 1 | num_updates 32176 | best_loss 8.621
2022-03-07 23:12:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 661 @ 32176 updates
2022-03-07 23:12:41 | INFO | fairseq_cli.train | end of epoch 661 (average epoch stats below)
2022-03-07 23:12:41 | INFO | train | epoch 661 | loss 1.735 | ppl 3.33 | wps 21784.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32176 | lr 0.000176293 | gnorm 0.348 | loss_scale 64 | train_wall 129 | gb_free 21.5 | wall 95576
2022-03-07 23:12:41 | INFO | fairseq.trainer | begin training epoch 662
2022-03-07 23:12:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:13:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:13:53 | INFO | train_inner | epoch 662:     25 / 49 loss=1.735, ppl=3.33, wps=21602.4, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=32200, lr=0.000176227, gnorm=0.346, loss_scale=32, train_wall=265, gb_free=21.5, wall=95648
2022-03-07 23:15:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:15:06 | INFO | valid | epoch 662 | valid on 'valid' subset | loss 11.191 | ppl 2337.19 | wps 38047.4 | wpb 510.9 | bsz 1 | num_updates 32224 | best_loss 8.621
2022-03-07 23:15:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 662 @ 32224 updates
2022-03-07 23:15:06 | INFO | fairseq_cli.train | end of epoch 662 (average epoch stats below)
2022-03-07 23:15:06 | INFO | train | epoch 662 | loss 1.734 | ppl 3.33 | wps 21349.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32224 | lr 0.000176161 | gnorm 0.348 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 95722
2022-03-07 23:15:06 | INFO | fairseq.trainer | begin training epoch 663
2022-03-07 23:15:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:17:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:17:32 | INFO | valid | epoch 663 | valid on 'valid' subset | loss 11.171 | ppl 2305.14 | wps 38093.8 | wpb 510.9 | bsz 1 | num_updates 32273 | best_loss 8.621
2022-03-07 23:17:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 663 @ 32273 updates
2022-03-07 23:17:32 | INFO | fairseq_cli.train | end of epoch 663 (average epoch stats below)
2022-03-07 23:17:32 | INFO | train | epoch 663 | loss 1.734 | ppl 3.33 | wps 21787.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32273 | lr 0.000176027 | gnorm 0.351 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 95868
2022-03-07 23:17:32 | INFO | fairseq.trainer | begin training epoch 664
2022-03-07 23:17:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:18:50 | INFO | train_inner | epoch 664:     27 / 49 loss=1.734, ppl=3.33, wps=21806.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=32300, lr=0.000175954, gnorm=0.349, loss_scale=32, train_wall=262, gb_free=21.5, wall=95946
2022-03-07 23:19:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:19:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:19:58 | INFO | valid | epoch 664 | valid on 'valid' subset | loss 11.151 | ppl 2273.4 | wps 37853 | wpb 510.9 | bsz 1 | num_updates 32321 | best_loss 8.621
2022-03-07 23:19:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 664 @ 32321 updates
2022-03-07 23:19:58 | INFO | fairseq_cli.train | end of epoch 664 (average epoch stats below)
2022-03-07 23:19:58 | INFO | train | epoch 664 | loss 1.733 | ppl 3.32 | wps 21332.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32321 | lr 0.000175897 | gnorm 0.344 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 96013
2022-03-07 23:19:58 | INFO | fairseq.trainer | begin training epoch 665
2022-03-07 23:19:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:22:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:22:24 | INFO | valid | epoch 665 | valid on 'valid' subset | loss 11.161 | ppl 2289.04 | wps 38018.2 | wpb 510.9 | bsz 1 | num_updates 32370 | best_loss 8.621
2022-03-07 23:22:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 665 @ 32370 updates
2022-03-07 23:22:24 | INFO | fairseq_cli.train | end of epoch 665 (average epoch stats below)
2022-03-07 23:22:24 | INFO | train | epoch 665 | loss 1.733 | ppl 3.32 | wps 21780.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32370 | lr 0.000175763 | gnorm 0.348 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 96159
2022-03-07 23:22:24 | INFO | fairseq.trainer | begin training epoch 666
2022-03-07 23:22:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:23:51 | INFO | train_inner | epoch 666:     30 / 49 loss=1.733, ppl=3.32, wps=21599.5, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=32400, lr=0.000175682, gnorm=0.345, loss_scale=32, train_wall=265, gb_free=21.5, wall=96246
2022-03-07 23:24:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:24:50 | INFO | valid | epoch 666 | valid on 'valid' subset | loss 11.164 | ppl 2294.94 | wps 37842.6 | wpb 510.9 | bsz 1 | num_updates 32419 | best_loss 8.621
2022-03-07 23:24:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 666 @ 32419 updates
2022-03-07 23:24:50 | INFO | fairseq_cli.train | end of epoch 666 (average epoch stats below)
2022-03-07 23:24:50 | INFO | train | epoch 666 | loss 1.733 | ppl 3.32 | wps 21798.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32419 | lr 0.000175631 | gnorm 0.344 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 96305
2022-03-07 23:24:50 | INFO | fairseq.trainer | begin training epoch 667
2022-03-07 23:24:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:26:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:27:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:27:16 | INFO | valid | epoch 667 | valid on 'valid' subset | loss 11.156 | ppl 2281.51 | wps 38408.3 | wpb 510.9 | bsz 1 | num_updates 32467 | best_loss 8.621
2022-03-07 23:27:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 667 @ 32467 updates
2022-03-07 23:27:16 | INFO | fairseq_cli.train | end of epoch 667 (average epoch stats below)
2022-03-07 23:27:16 | INFO | train | epoch 667 | loss 1.733 | ppl 3.32 | wps 21352 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32467 | lr 0.000175501 | gnorm 0.348 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 96451
2022-03-07 23:27:16 | INFO | fairseq.trainer | begin training epoch 668
2022-03-07 23:27:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:28:51 | INFO | train_inner | epoch 668:     33 / 49 loss=1.733, ppl=3.32, wps=21601, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=32500, lr=0.000175412, gnorm=0.347, loss_scale=32, train_wall=265, gb_free=21.5, wall=96546
2022-03-07 23:29:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:29:42 | INFO | valid | epoch 668 | valid on 'valid' subset | loss 11.175 | ppl 2311.8 | wps 38026.2 | wpb 510.9 | bsz 1 | num_updates 32516 | best_loss 8.621
2022-03-07 23:29:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 668 @ 32516 updates
2022-03-07 23:29:42 | INFO | fairseq_cli.train | end of epoch 668 (average epoch stats below)
2022-03-07 23:29:42 | INFO | train | epoch 668 | loss 1.733 | ppl 3.32 | wps 21792.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32516 | lr 0.000175368 | gnorm 0.347 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 96597
2022-03-07 23:29:42 | INFO | fairseq.trainer | begin training epoch 669
2022-03-07 23:29:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:32:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:32:07 | INFO | valid | epoch 669 | valid on 'valid' subset | loss 11.141 | ppl 2259.04 | wps 39101.4 | wpb 510.9 | bsz 1 | num_updates 32565 | best_loss 8.621
2022-03-07 23:32:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 669 @ 32565 updates
2022-03-07 23:32:07 | INFO | fairseq_cli.train | end of epoch 669 (average epoch stats below)
2022-03-07 23:32:07 | INFO | train | epoch 669 | loss 1.732 | ppl 3.32 | wps 21835 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32565 | lr 0.000175236 | gnorm 0.347 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 96742
2022-03-07 23:32:07 | INFO | fairseq.trainer | begin training epoch 670
2022-03-07 23:32:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:33:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:33:50 | INFO | train_inner | epoch 670:     36 / 49 loss=1.732, ppl=3.32, wps=21697.5, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=32600, lr=0.000175142, gnorm=0.345, loss_scale=32, train_wall=264, gb_free=21.5, wall=96845
2022-03-07 23:34:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:34:31 | INFO | valid | epoch 670 | valid on 'valid' subset | loss 11.144 | ppl 2262.87 | wps 39027.5 | wpb 510.9 | bsz 1 | num_updates 32613 | best_loss 8.621
2022-03-07 23:34:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 670 @ 32613 updates
2022-03-07 23:34:31 | INFO | fairseq_cli.train | end of epoch 670 (average epoch stats below)
2022-03-07 23:34:31 | INFO | train | epoch 670 | loss 1.732 | ppl 3.32 | wps 21588.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32613 | lr 0.000175107 | gnorm 0.343 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 96887
2022-03-07 23:34:31 | INFO | fairseq.trainer | begin training epoch 671
2022-03-07 23:34:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:36:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:36:55 | INFO | valid | epoch 671 | valid on 'valid' subset | loss 11.167 | ppl 2299.76 | wps 39081.7 | wpb 510.9 | bsz 1 | num_updates 32662 | best_loss 8.621
2022-03-07 23:36:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 671 @ 32662 updates
2022-03-07 23:36:55 | INFO | fairseq_cli.train | end of epoch 671 (average epoch stats below)
2022-03-07 23:36:55 | INFO | train | epoch 671 | loss 1.732 | ppl 3.32 | wps 22058.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32662 | lr 0.000174976 | gnorm 0.344 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 97031
2022-03-07 23:36:55 | INFO | fairseq.trainer | begin training epoch 672
2022-03-07 23:36:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:38:44 | INFO | train_inner | epoch 672:     38 / 49 loss=1.732, ppl=3.32, wps=22075.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=32700, lr=0.000174874, gnorm=0.342, loss_scale=32, train_wall=260, gb_free=21.5, wall=97139
2022-03-07 23:39:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:39:19 | INFO | valid | epoch 672 | valid on 'valid' subset | loss 11.155 | ppl 2280.87 | wps 38862 | wpb 510.9 | bsz 1 | num_updates 32711 | best_loss 8.621
2022-03-07 23:39:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 672 @ 32711 updates
2022-03-07 23:39:19 | INFO | fairseq_cli.train | end of epoch 672 (average epoch stats below)
2022-03-07 23:39:19 | INFO | train | epoch 672 | loss 1.732 | ppl 3.32 | wps 22049.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32711 | lr 0.000174845 | gnorm 0.341 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 97175
2022-03-07 23:39:19 | INFO | fairseq.trainer | begin training epoch 673
2022-03-07 23:39:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:40:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:41:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:41:44 | INFO | valid | epoch 673 | valid on 'valid' subset | loss 11.176 | ppl 2313.57 | wps 39016.2 | wpb 510.9 | bsz 1 | num_updates 32759 | best_loss 8.621
2022-03-07 23:41:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 673 @ 32759 updates
2022-03-07 23:41:44 | INFO | fairseq_cli.train | end of epoch 673 (average epoch stats below)
2022-03-07 23:41:44 | INFO | train | epoch 673 | loss 1.732 | ppl 3.32 | wps 21598 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32759 | lr 0.000174717 | gnorm 0.345 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 97319
2022-03-07 23:41:44 | INFO | fairseq.trainer | begin training epoch 674
2022-03-07 23:41:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:43:41 | INFO | train_inner | epoch 674:     41 / 49 loss=1.732, ppl=3.32, wps=21861.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=32800, lr=0.000174608, gnorm=0.346, loss_scale=32, train_wall=263, gb_free=21.5, wall=97436
2022-03-07 23:44:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:44:08 | INFO | valid | epoch 674 | valid on 'valid' subset | loss 11.152 | ppl 2275.06 | wps 39014.6 | wpb 510.9 | bsz 1 | num_updates 32808 | best_loss 8.621
2022-03-07 23:44:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 674 @ 32808 updates
2022-03-07 23:44:08 | INFO | fairseq_cli.train | end of epoch 674 (average epoch stats below)
2022-03-07 23:44:08 | INFO | train | epoch 674 | loss 1.732 | ppl 3.32 | wps 22060.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32808 | lr 0.000174586 | gnorm 0.348 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 97463
2022-03-07 23:44:08 | INFO | fairseq.trainer | begin training epoch 675
2022-03-07 23:44:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:46:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:46:32 | INFO | valid | epoch 675 | valid on 'valid' subset | loss 11.156 | ppl 2282.43 | wps 39119.4 | wpb 510.9 | bsz 1 | num_updates 32857 | best_loss 8.621
2022-03-07 23:46:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 675 @ 32857 updates
2022-03-07 23:46:32 | INFO | fairseq_cli.train | end of epoch 675 (average epoch stats below)
2022-03-07 23:46:32 | INFO | train | epoch 675 | loss 1.731 | ppl 3.32 | wps 22051.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32857 | lr 0.000174456 | gnorm 0.344 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 97607
2022-03-07 23:46:32 | INFO | fairseq.trainer | begin training epoch 676
2022-03-07 23:46:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:46:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:48:37 | INFO | train_inner | epoch 676:     44 / 49 loss=1.731, ppl=3.32, wps=21860, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=32900, lr=0.000174342, gnorm=0.345, loss_scale=32, train_wall=263, gb_free=21.5, wall=97733
2022-03-07 23:48:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:48:56 | INFO | valid | epoch 676 | valid on 'valid' subset | loss 11.145 | ppl 2264.53 | wps 39009.7 | wpb 510.9 | bsz 1 | num_updates 32905 | best_loss 8.621
2022-03-07 23:48:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 676 @ 32905 updates
2022-03-07 23:48:56 | INFO | fairseq_cli.train | end of epoch 676 (average epoch stats below)
2022-03-07 23:48:56 | INFO | train | epoch 676 | loss 1.731 | ppl 3.32 | wps 21603 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32905 | lr 0.000174329 | gnorm 0.346 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 97751
2022-03-07 23:48:56 | INFO | fairseq.trainer | begin training epoch 677
2022-03-07 23:48:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:51:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:51:20 | INFO | valid | epoch 677 | valid on 'valid' subset | loss 11.155 | ppl 2280.26 | wps 39181.4 | wpb 510.9 | bsz 1 | num_updates 32954 | best_loss 8.621
2022-03-07 23:51:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 677 @ 32954 updates
2022-03-07 23:51:20 | INFO | fairseq_cli.train | end of epoch 677 (average epoch stats below)
2022-03-07 23:51:20 | INFO | train | epoch 677 | loss 1.731 | ppl 3.32 | wps 22063 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32954 | lr 0.000174199 | gnorm 0.344 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 97895
2022-03-07 23:51:20 | INFO | fairseq.trainer | begin training epoch 678
2022-03-07 23:51:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:53:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:53:34 | INFO | train_inner | epoch 678:     47 / 49 loss=1.731, ppl=3.32, wps=21868, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33000, lr=0.000174078, gnorm=0.344, loss_scale=32, train_wall=262, gb_free=21.5, wall=98029
2022-03-07 23:53:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:53:44 | INFO | valid | epoch 678 | valid on 'valid' subset | loss 11.159 | ppl 2287.41 | wps 39200.4 | wpb 510.9 | bsz 1 | num_updates 33002 | best_loss 8.621
2022-03-07 23:53:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 678 @ 33002 updates
2022-03-07 23:53:44 | INFO | fairseq_cli.train | end of epoch 678 (average epoch stats below)
2022-03-07 23:53:44 | INFO | train | epoch 678 | loss 1.73 | ppl 3.32 | wps 21612 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33002 | lr 0.000174072 | gnorm 0.344 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 98039
2022-03-07 23:53:44 | INFO | fairseq.trainer | begin training epoch 679
2022-03-07 23:53:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:56:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:56:08 | INFO | valid | epoch 679 | valid on 'valid' subset | loss 11.15 | ppl 2273.15 | wps 39028.4 | wpb 510.9 | bsz 1 | num_updates 33051 | best_loss 8.621
2022-03-07 23:56:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 679 @ 33051 updates
2022-03-07 23:56:08 | INFO | fairseq_cli.train | end of epoch 679 (average epoch stats below)
2022-03-07 23:56:08 | INFO | train | epoch 679 | loss 1.731 | ppl 3.32 | wps 22045.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33051 | lr 0.000173943 | gnorm 0.344 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 98183
2022-03-07 23:56:08 | INFO | fairseq.trainer | begin training epoch 680
2022-03-07 23:56:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:58:27 | INFO | train_inner | epoch 680:     49 / 49 loss=1.73, ppl=3.32, wps=22063, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=33100, lr=0.000173814, gnorm=0.344, loss_scale=32, train_wall=259, gb_free=21.5, wall=98322
2022-03-07 23:58:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:58:32 | INFO | valid | epoch 680 | valid on 'valid' subset | loss 11.164 | ppl 2293.8 | wps 39108.2 | wpb 510.9 | bsz 1 | num_updates 33100 | best_loss 8.621
2022-03-07 23:58:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 680 @ 33100 updates
2022-03-07 23:58:32 | INFO | fairseq_cli.train | end of epoch 680 (average epoch stats below)
2022-03-07 23:58:32 | INFO | train | epoch 680 | loss 1.73 | ppl 3.32 | wps 22055 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33100 | lr 0.000173814 | gnorm 0.343 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 98327
2022-03-07 23:58:32 | INFO | fairseq.trainer | begin training epoch 681
2022-03-07 23:58:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:59:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:00:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:00:56 | INFO | valid | epoch 681 | valid on 'valid' subset | loss 11.136 | ppl 2251.05 | wps 39126.6 | wpb 510.9 | bsz 1 | num_updates 33148 | best_loss 8.621
2022-03-08 00:00:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 681 @ 33148 updates
2022-03-08 00:00:56 | INFO | fairseq_cli.train | end of epoch 681 (average epoch stats below)
2022-03-08 00:00:56 | INFO | train | epoch 681 | loss 1.73 | ppl 3.32 | wps 21606.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33148 | lr 0.000173689 | gnorm 0.347 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 98471
2022-03-08 00:00:56 | INFO | fairseq.trainer | begin training epoch 682
2022-03-08 00:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:03:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:03:20 | INFO | valid | epoch 682 | valid on 'valid' subset | loss 11.137 | ppl 2251.45 | wps 39276.9 | wpb 510.9 | bsz 1 | num_updates 33197 | best_loss 8.621
2022-03-08 00:03:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 682 @ 33197 updates
2022-03-08 00:03:20 | INFO | fairseq_cli.train | end of epoch 682 (average epoch stats below)
2022-03-08 00:03:20 | INFO | train | epoch 682 | loss 1.729 | ppl 3.32 | wps 22039.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33197 | lr 0.00017356 | gnorm 0.341 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 98616
2022-03-08 00:03:20 | INFO | fairseq.trainer | begin training epoch 683
2022-03-08 00:03:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:03:29 | INFO | train_inner | epoch 683:      3 / 49 loss=1.73, ppl=3.32, wps=21444.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=33200, lr=0.000173553, gnorm=0.344, loss_scale=32, train_wall=263, gb_free=21.5, wall=98624
2022-03-08 00:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:05:45 | INFO | valid | epoch 683 | valid on 'valid' subset | loss 11.145 | ppl 2265.21 | wps 38788.8 | wpb 510.9 | bsz 1 | num_updates 33246 | best_loss 8.621
2022-03-08 00:05:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 683 @ 33246 updates
2022-03-08 00:05:45 | INFO | fairseq_cli.train | end of epoch 683 (average epoch stats below)
2022-03-08 00:05:45 | INFO | train | epoch 683 | loss 1.73 | ppl 3.32 | wps 22055.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33246 | lr 0.000173432 | gnorm 0.341 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 98760
2022-03-08 00:05:45 | INFO | fairseq.trainer | begin training epoch 684
2022-03-08 00:05:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:06:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:08:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:08:09 | INFO | valid | epoch 684 | valid on 'valid' subset | loss 11.169 | ppl 2302.44 | wps 39221.2 | wpb 510.9 | bsz 1 | num_updates 33294 | best_loss 8.621
2022-03-08 00:08:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 684 @ 33294 updates
2022-03-08 00:08:09 | INFO | fairseq_cli.train | end of epoch 684 (average epoch stats below)
2022-03-08 00:08:09 | INFO | train | epoch 684 | loss 1.73 | ppl 3.32 | wps 21605.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33294 | lr 0.000173307 | gnorm 0.35 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 98904
2022-03-08 00:08:09 | INFO | fairseq.trainer | begin training epoch 685
2022-03-08 00:08:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:08:26 | INFO | train_inner | epoch 685:      6 / 49 loss=1.729, ppl=3.32, wps=21863.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33300, lr=0.000173292, gnorm=0.346, loss_scale=32, train_wall=263, gb_free=21.5, wall=98921
2022-03-08 00:10:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:10:33 | INFO | valid | epoch 685 | valid on 'valid' subset | loss 11.186 | ppl 2329.78 | wps 39267.9 | wpb 510.9 | bsz 1 | num_updates 33343 | best_loss 8.621
2022-03-08 00:10:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 685 @ 33343 updates
2022-03-08 00:10:33 | INFO | fairseq_cli.train | end of epoch 685 (average epoch stats below)
2022-03-08 00:10:33 | INFO | train | epoch 685 | loss 1.729 | ppl 3.32 | wps 22067.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33343 | lr 0.00017318 | gnorm 0.344 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 99048
2022-03-08 00:10:33 | INFO | fairseq.trainer | begin training epoch 686
2022-03-08 00:10:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:12:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:12:57 | INFO | valid | epoch 686 | valid on 'valid' subset | loss 11.128 | ppl 2238.53 | wps 39101.2 | wpb 510.9 | bsz 1 | num_updates 33392 | best_loss 8.621
2022-03-08 00:12:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 686 @ 33392 updates
2022-03-08 00:12:57 | INFO | fairseq_cli.train | end of epoch 686 (average epoch stats below)
2022-03-08 00:12:57 | INFO | train | epoch 686 | loss 1.729 | ppl 3.32 | wps 22056 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33392 | lr 0.000173053 | gnorm 0.343 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 99192
2022-03-08 00:12:57 | INFO | fairseq.trainer | begin training epoch 687
2022-03-08 00:12:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:13:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:13:22 | INFO | train_inner | epoch 687:      9 / 49 loss=1.729, ppl=3.31, wps=21869.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33400, lr=0.000173032, gnorm=0.343, loss_scale=32, train_wall=263, gb_free=21.5, wall=99218
2022-03-08 00:15:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:15:21 | INFO | valid | epoch 687 | valid on 'valid' subset | loss 11.159 | ppl 2287.03 | wps 39033.2 | wpb 510.9 | bsz 1 | num_updates 33440 | best_loss 8.621
2022-03-08 00:15:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 687 @ 33440 updates
2022-03-08 00:15:21 | INFO | fairseq_cli.train | end of epoch 687 (average epoch stats below)
2022-03-08 00:15:21 | INFO | train | epoch 687 | loss 1.728 | ppl 3.31 | wps 21620.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33440 | lr 0.000172929 | gnorm 0.339 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 99336
2022-03-08 00:15:21 | INFO | fairseq.trainer | begin training epoch 688
2022-03-08 00:15:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:17:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:17:45 | INFO | valid | epoch 688 | valid on 'valid' subset | loss 11.161 | ppl 2289.79 | wps 39144.4 | wpb 510.9 | bsz 1 | num_updates 33489 | best_loss 8.621
2022-03-08 00:17:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 688 @ 33489 updates
2022-03-08 00:17:45 | INFO | fairseq_cli.train | end of epoch 688 (average epoch stats below)
2022-03-08 00:17:45 | INFO | train | epoch 688 | loss 1.729 | ppl 3.31 | wps 22084.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33489 | lr 0.000172802 | gnorm 0.345 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 99480
2022-03-08 00:17:45 | INFO | fairseq.trainer | begin training epoch 689
2022-03-08 00:17:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:18:16 | INFO | train_inner | epoch 689:     11 / 49 loss=1.729, ppl=3.31, wps=22089.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33500, lr=0.000172774, gnorm=0.343, loss_scale=32, train_wall=260, gb_free=21.5, wall=99511
2022-03-08 00:20:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:20:09 | INFO | valid | epoch 689 | valid on 'valid' subset | loss 11.169 | ppl 2303.16 | wps 39156.1 | wpb 510.9 | bsz 1 | num_updates 33538 | best_loss 8.621
2022-03-08 00:20:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 689 @ 33538 updates
2022-03-08 00:20:09 | INFO | fairseq_cli.train | end of epoch 689 (average epoch stats below)
2022-03-08 00:20:09 | INFO | train | epoch 689 | loss 1.729 | ppl 3.31 | wps 22059.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33538 | lr 0.000172676 | gnorm 0.346 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 99624
2022-03-08 00:20:09 | INFO | fairseq.trainer | begin training epoch 690
2022-03-08 00:20:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:20:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:22:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:22:33 | INFO | valid | epoch 690 | valid on 'valid' subset | loss 11.163 | ppl 2293.08 | wps 39125.9 | wpb 510.9 | bsz 1 | num_updates 33586 | best_loss 8.621
2022-03-08 00:22:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 690 @ 33586 updates
2022-03-08 00:22:33 | INFO | fairseq_cli.train | end of epoch 690 (average epoch stats below)
2022-03-08 00:22:33 | INFO | train | epoch 690 | loss 1.728 | ppl 3.31 | wps 21597.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33586 | lr 0.000172552 | gnorm 0.34 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 99768
2022-03-08 00:22:33 | INFO | fairseq.trainer | begin training epoch 691
2022-03-08 00:22:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:23:13 | INFO | train_inner | epoch 691:     14 / 49 loss=1.728, ppl=3.31, wps=21866.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33600, lr=0.000172516, gnorm=0.341, loss_scale=32, train_wall=262, gb_free=21.5, wall=99808
2022-03-08 00:24:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:24:57 | INFO | valid | epoch 691 | valid on 'valid' subset | loss 11.143 | ppl 2261.34 | wps 39110.5 | wpb 510.9 | bsz 1 | num_updates 33635 | best_loss 8.621
2022-03-08 00:24:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 691 @ 33635 updates
2022-03-08 00:24:57 | INFO | fairseq_cli.train | end of epoch 691 (average epoch stats below)
2022-03-08 00:24:57 | INFO | train | epoch 691 | loss 1.728 | ppl 3.31 | wps 22066.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33635 | lr 0.000172427 | gnorm 0.342 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 99912
2022-03-08 00:24:57 | INFO | fairseq.trainer | begin training epoch 692
2022-03-08 00:24:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:26:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:27:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:27:21 | INFO | valid | epoch 692 | valid on 'valid' subset | loss 11.153 | ppl 2276.81 | wps 39164 | wpb 510.9 | bsz 1 | num_updates 33683 | best_loss 8.621
2022-03-08 00:27:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 692 @ 33683 updates
2022-03-08 00:27:21 | INFO | fairseq_cli.train | end of epoch 692 (average epoch stats below)
2022-03-08 00:27:21 | INFO | train | epoch 692 | loss 1.728 | ppl 3.31 | wps 21615.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33683 | lr 0.000172304 | gnorm 0.343 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 100056
2022-03-08 00:27:21 | INFO | fairseq.trainer | begin training epoch 693
2022-03-08 00:27:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:28:09 | INFO | train_inner | epoch 693:     17 / 49 loss=1.728, ppl=3.31, wps=21872, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=33700, lr=0.00017226, gnorm=0.343, loss_scale=32, train_wall=262, gb_free=21.5, wall=100105
2022-03-08 00:29:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:29:45 | INFO | valid | epoch 693 | valid on 'valid' subset | loss 11.133 | ppl 2246.04 | wps 38763.5 | wpb 510.9 | bsz 1 | num_updates 33732 | best_loss 8.621
2022-03-08 00:29:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 693 @ 33732 updates
2022-03-08 00:29:45 | INFO | fairseq_cli.train | end of epoch 693 (average epoch stats below)
2022-03-08 00:29:45 | INFO | train | epoch 693 | loss 1.728 | ppl 3.31 | wps 22057.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33732 | lr 0.000172179 | gnorm 0.344 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 100200
2022-03-08 00:29:45 | INFO | fairseq.trainer | begin training epoch 694
2022-03-08 00:29:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:32:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:32:09 | INFO | valid | epoch 694 | valid on 'valid' subset | loss 11.152 | ppl 2275.69 | wps 39057.4 | wpb 510.9 | bsz 1 | num_updates 33781 | best_loss 8.621
2022-03-08 00:32:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 694 @ 33781 updates
2022-03-08 00:32:09 | INFO | fairseq_cli.train | end of epoch 694 (average epoch stats below)
2022-03-08 00:32:09 | INFO | train | epoch 694 | loss 1.727 | ppl 3.31 | wps 22061.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33781 | lr 0.000172054 | gnorm 0.342 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 100344
2022-03-08 00:32:09 | INFO | fairseq.trainer | begin training epoch 695
2022-03-08 00:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:33:03 | INFO | train_inner | epoch 695:     19 / 49 loss=1.728, ppl=3.31, wps=22077, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=33800, lr=0.000172005, gnorm=0.343, loss_scale=32, train_wall=260, gb_free=21.5, wall=100398
2022-03-08 00:34:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:34:33 | INFO | valid | epoch 695 | valid on 'valid' subset | loss 11.137 | ppl 2251.55 | wps 39132.8 | wpb 510.9 | bsz 1 | num_updates 33829 | best_loss 8.621
2022-03-08 00:34:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 695 @ 33829 updates
2022-03-08 00:34:33 | INFO | fairseq_cli.train | end of epoch 695 (average epoch stats below)
2022-03-08 00:34:33 | INFO | train | epoch 695 | loss 1.727 | ppl 3.31 | wps 21608.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33829 | lr 0.000171931 | gnorm 0.339 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 100488
2022-03-08 00:34:33 | INFO | fairseq.trainer | begin training epoch 696
2022-03-08 00:34:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:36:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:36:57 | INFO | valid | epoch 696 | valid on 'valid' subset | loss 11.158 | ppl 2284.33 | wps 39226.8 | wpb 510.9 | bsz 1 | num_updates 33878 | best_loss 8.621
2022-03-08 00:36:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 696 @ 33878 updates
2022-03-08 00:36:57 | INFO | fairseq_cli.train | end of epoch 696 (average epoch stats below)
2022-03-08 00:36:57 | INFO | train | epoch 696 | loss 1.727 | ppl 3.31 | wps 22065.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33878 | lr 0.000171807 | gnorm 0.342 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 100632
2022-03-08 00:36:57 | INFO | fairseq.trainer | begin training epoch 697
2022-03-08 00:36:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:38:00 | INFO | train_inner | epoch 697:     22 / 49 loss=1.727, ppl=3.31, wps=21874.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33900, lr=0.000171751, gnorm=0.34, loss_scale=32, train_wall=262, gb_free=21.5, wall=100695
2022-03-08 00:39:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:39:21 | INFO | valid | epoch 697 | valid on 'valid' subset | loss 11.175 | ppl 2311.85 | wps 39103.8 | wpb 510.9 | bsz 1 | num_updates 33927 | best_loss 8.621
2022-03-08 00:39:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 697 @ 33927 updates
2022-03-08 00:39:21 | INFO | fairseq_cli.train | end of epoch 697 (average epoch stats below)
2022-03-08 00:39:21 | INFO | train | epoch 697 | loss 1.727 | ppl 3.31 | wps 22070.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33927 | lr 0.000171683 | gnorm 0.338 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 100776
2022-03-08 00:39:21 | INFO | fairseq.trainer | begin training epoch 698
2022-03-08 00:39:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:40:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:41:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:41:45 | INFO | valid | epoch 698 | valid on 'valid' subset | loss 11.146 | ppl 2266.29 | wps 39190.3 | wpb 510.9 | bsz 1 | num_updates 33975 | best_loss 8.621
2022-03-08 00:41:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 698 @ 33975 updates
2022-03-08 00:41:45 | INFO | fairseq_cli.train | end of epoch 698 (average epoch stats below)
2022-03-08 00:41:45 | INFO | train | epoch 698 | loss 1.726 | ppl 3.31 | wps 21608.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33975 | lr 0.000171562 | gnorm 0.341 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 100920
2022-03-08 00:41:45 | INFO | fairseq.trainer | begin training epoch 699
2022-03-08 00:41:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:42:56 | INFO | train_inner | epoch 699:     25 / 49 loss=1.726, ppl=3.31, wps=21875, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=34000, lr=0.000171499, gnorm=0.339, loss_scale=32, train_wall=262, gb_free=21.5, wall=100992
2022-03-08 00:44:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:44:09 | INFO | valid | epoch 699 | valid on 'valid' subset | loss 11.127 | ppl 2236.39 | wps 39154.8 | wpb 510.9 | bsz 1 | num_updates 34024 | best_loss 8.621
2022-03-08 00:44:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 699 @ 34024 updates
2022-03-08 00:44:09 | INFO | fairseq_cli.train | end of epoch 699 (average epoch stats below)
2022-03-08 00:44:09 | INFO | train | epoch 699 | loss 1.726 | ppl 3.31 | wps 22076.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34024 | lr 0.000171438 | gnorm 0.339 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 101064
2022-03-08 00:44:09 | INFO | fairseq.trainer | begin training epoch 700
2022-03-08 00:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:46:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:46:33 | INFO | valid | epoch 700 | valid on 'valid' subset | loss 11.144 | ppl 2263.66 | wps 39113.5 | wpb 510.9 | bsz 1 | num_updates 34073 | best_loss 8.621
2022-03-08 00:46:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 700 @ 34073 updates
2022-03-08 00:46:33 | INFO | fairseq_cli.train | end of epoch 700 (average epoch stats below)
2022-03-08 00:46:33 | INFO | train | epoch 700 | loss 1.727 | ppl 3.31 | wps 22038.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34073 | lr 0.000171315 | gnorm 0.341 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 101208
2022-03-08 00:46:33 | INFO | fairseq.trainer | begin training epoch 701
2022-03-08 00:46:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:47:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:47:53 | INFO | train_inner | epoch 701:     28 / 49 loss=1.726, ppl=3.31, wps=21857.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=34100, lr=0.000171247, gnorm=0.34, loss_scale=32, train_wall=263, gb_free=21.5, wall=101288
2022-03-08 00:48:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:48:57 | INFO | valid | epoch 701 | valid on 'valid' subset | loss 11.165 | ppl 2296.33 | wps 39141.1 | wpb 510.9 | bsz 1 | num_updates 34121 | best_loss 8.621
2022-03-08 00:48:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 701 @ 34121 updates
2022-03-08 00:48:57 | INFO | fairseq_cli.train | end of epoch 701 (average epoch stats below)
2022-03-08 00:48:57 | INFO | train | epoch 701 | loss 1.726 | ppl 3.31 | wps 21589.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34121 | lr 0.000171194 | gnorm 0.341 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 101353
2022-03-08 00:48:57 | INFO | fairseq.trainer | begin training epoch 702
2022-03-08 00:48:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:51:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:51:21 | INFO | valid | epoch 702 | valid on 'valid' subset | loss 11.166 | ppl 2297.42 | wps 39278.9 | wpb 510.9 | bsz 1 | num_updates 34170 | best_loss 8.621
2022-03-08 00:51:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 702 @ 34170 updates
2022-03-08 00:51:21 | INFO | fairseq_cli.train | end of epoch 702 (average epoch stats below)
2022-03-08 00:51:21 | INFO | train | epoch 702 | loss 1.726 | ppl 3.31 | wps 22075.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34170 | lr 0.000171071 | gnorm 0.339 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 101497
2022-03-08 00:51:21 | INFO | fairseq.trainer | begin training epoch 703
2022-03-08 00:51:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:52:47 | INFO | train_inner | epoch 703:     30 / 49 loss=1.726, ppl=3.31, wps=22067.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=34200, lr=0.000170996, gnorm=0.341, loss_scale=32, train_wall=260, gb_free=21.5, wall=101582
2022-03-08 00:53:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:53:45 | INFO | valid | epoch 703 | valid on 'valid' subset | loss 11.127 | ppl 2236.53 | wps 39128.9 | wpb 510.9 | bsz 1 | num_updates 34219 | best_loss 8.621
2022-03-08 00:53:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 703 @ 34219 updates
2022-03-08 00:53:45 | INFO | fairseq_cli.train | end of epoch 703 (average epoch stats below)
2022-03-08 00:53:45 | INFO | train | epoch 703 | loss 1.726 | ppl 3.31 | wps 22043 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34219 | lr 0.000170949 | gnorm 0.341 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 101641
2022-03-08 00:53:45 | INFO | fairseq.trainer | begin training epoch 704
2022-03-08 00:53:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:53:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:56:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:56:10 | INFO | valid | epoch 704 | valid on 'valid' subset | loss 11.158 | ppl 2284.98 | wps 39107.2 | wpb 510.9 | bsz 1 | num_updates 34267 | best_loss 8.621
2022-03-08 00:56:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 704 @ 34267 updates
2022-03-08 00:56:10 | INFO | fairseq_cli.train | end of epoch 704 (average epoch stats below)
2022-03-08 00:56:10 | INFO | train | epoch 704 | loss 1.726 | ppl 3.31 | wps 21586.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34267 | lr 0.000170829 | gnorm 0.344 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 101785
2022-03-08 00:56:10 | INFO | fairseq.trainer | begin training epoch 705
2022-03-08 00:56:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:57:44 | INFO | train_inner | epoch 705:     33 / 49 loss=1.725, ppl=3.31, wps=21859.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34300, lr=0.000170747, gnorm=0.343, loss_scale=32, train_wall=263, gb_free=21.5, wall=101879
2022-03-08 00:58:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:58:34 | INFO | valid | epoch 705 | valid on 'valid' subset | loss 11.154 | ppl 2278.81 | wps 39290 | wpb 510.9 | bsz 1 | num_updates 34316 | best_loss 8.621
2022-03-08 00:58:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 705 @ 34316 updates
2022-03-08 00:58:34 | INFO | fairseq_cli.train | end of epoch 705 (average epoch stats below)
2022-03-08 00:58:34 | INFO | train | epoch 705 | loss 1.725 | ppl 3.31 | wps 22067.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34316 | lr 0.000170707 | gnorm 0.341 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 101929
2022-03-08 00:58:34 | INFO | fairseq.trainer | begin training epoch 706
2022-03-08 00:58:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:00:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:00:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:00:58 | INFO | valid | epoch 706 | valid on 'valid' subset | loss 11.137 | ppl 2252.51 | wps 39110.5 | wpb 510.9 | bsz 1 | num_updates 34364 | best_loss 8.621
2022-03-08 01:00:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 706 @ 34364 updates
2022-03-08 01:00:58 | INFO | fairseq_cli.train | end of epoch 706 (average epoch stats below)
2022-03-08 01:00:58 | INFO | train | epoch 706 | loss 1.725 | ppl 3.3 | wps 21598.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34364 | lr 0.000170588 | gnorm 0.338 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 102073
2022-03-08 01:00:58 | INFO | fairseq.trainer | begin training epoch 707
2022-03-08 01:00:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:02:40 | INFO | train_inner | epoch 707:     36 / 49 loss=1.725, ppl=3.3, wps=21868.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34400, lr=0.000170499, gnorm=0.338, loss_scale=32, train_wall=263, gb_free=21.5, wall=102176
2022-03-08 01:03:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:03:22 | INFO | valid | epoch 707 | valid on 'valid' subset | loss 11.151 | ppl 2273.55 | wps 39242.1 | wpb 510.9 | bsz 1 | num_updates 34413 | best_loss 8.621
2022-03-08 01:03:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 707 @ 34413 updates
2022-03-08 01:03:22 | INFO | fairseq_cli.train | end of epoch 707 (average epoch stats below)
2022-03-08 01:03:22 | INFO | train | epoch 707 | loss 1.724 | ppl 3.3 | wps 22069.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34413 | lr 0.000170466 | gnorm 0.338 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 102217
2022-03-08 01:03:22 | INFO | fairseq.trainer | begin training epoch 708
2022-03-08 01:03:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:05:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:05:46 | INFO | valid | epoch 708 | valid on 'valid' subset | loss 11.162 | ppl 2291.69 | wps 39053.9 | wpb 510.9 | bsz 1 | num_updates 34462 | best_loss 8.621
2022-03-08 01:05:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 708 @ 34462 updates
2022-03-08 01:05:46 | INFO | fairseq_cli.train | end of epoch 708 (average epoch stats below)
2022-03-08 01:05:46 | INFO | train | epoch 708 | loss 1.725 | ppl 3.31 | wps 22053.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34462 | lr 0.000170345 | gnorm 0.342 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 102361
2022-03-08 01:05:46 | INFO | fairseq.trainer | begin training epoch 709
2022-03-08 01:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:06:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:07:37 | INFO | train_inner | epoch 709:     39 / 49 loss=1.725, ppl=3.31, wps=21868, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34500, lr=0.000170251, gnorm=0.34, loss_scale=32, train_wall=262, gb_free=21.5, wall=102472
2022-03-08 01:08:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:08:10 | INFO | valid | epoch 709 | valid on 'valid' subset | loss 11.159 | ppl 2287.02 | wps 39228.9 | wpb 510.9 | bsz 1 | num_updates 34510 | best_loss 8.621
2022-03-08 01:08:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 709 @ 34510 updates
2022-03-08 01:08:10 | INFO | fairseq_cli.train | end of epoch 709 (average epoch stats below)
2022-03-08 01:08:10 | INFO | train | epoch 709 | loss 1.725 | ppl 3.31 | wps 21616.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34510 | lr 0.000170227 | gnorm 0.341 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 102505
2022-03-08 01:08:10 | INFO | fairseq.trainer | begin training epoch 710
2022-03-08 01:08:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:10:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:10:34 | INFO | valid | epoch 710 | valid on 'valid' subset | loss 11.149 | ppl 2270.57 | wps 39176.2 | wpb 510.9 | bsz 1 | num_updates 34559 | best_loss 8.621
2022-03-08 01:10:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 710 @ 34559 updates
2022-03-08 01:10:34 | INFO | fairseq_cli.train | end of epoch 710 (average epoch stats below)
2022-03-08 01:10:34 | INFO | train | epoch 710 | loss 1.724 | ppl 3.3 | wps 22052.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34559 | lr 0.000170106 | gnorm 0.34 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 102649
2022-03-08 01:10:34 | INFO | fairseq.trainer | begin training epoch 711
2022-03-08 01:10:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:12:31 | INFO | train_inner | epoch 711:     41 / 49 loss=1.725, ppl=3.3, wps=22070.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34600, lr=0.000170005, gnorm=0.345, loss_scale=32, train_wall=260, gb_free=21.5, wall=102766
2022-03-08 01:12:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:12:58 | INFO | valid | epoch 711 | valid on 'valid' subset | loss 11.145 | ppl 2264.11 | wps 39223.7 | wpb 510.9 | bsz 1 | num_updates 34608 | best_loss 8.621
2022-03-08 01:12:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 711 @ 34608 updates
2022-03-08 01:12:58 | INFO | fairseq_cli.train | end of epoch 711 (average epoch stats below)
2022-03-08 01:12:58 | INFO | train | epoch 711 | loss 1.724 | ppl 3.3 | wps 22053.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34608 | lr 0.000169985 | gnorm 0.347 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 102793
2022-03-08 01:12:58 | INFO | fairseq.trainer | begin training epoch 712
2022-03-08 01:12:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:13:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:15:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:15:22 | INFO | valid | epoch 712 | valid on 'valid' subset | loss 11.144 | ppl 2262.87 | wps 39073.3 | wpb 510.9 | bsz 1 | num_updates 34656 | best_loss 8.621
2022-03-08 01:15:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 712 @ 34656 updates
2022-03-08 01:15:22 | INFO | fairseq_cli.train | end of epoch 712 (average epoch stats below)
2022-03-08 01:15:22 | INFO | train | epoch 712 | loss 1.723 | ppl 3.3 | wps 21597.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34656 | lr 0.000169868 | gnorm 0.343 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 102937
2022-03-08 01:15:22 | INFO | fairseq.trainer | begin training epoch 713
2022-03-08 01:15:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:17:28 | INFO | train_inner | epoch 713:     44 / 49 loss=1.723, ppl=3.3, wps=21872.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34700, lr=0.00016976, gnorm=0.342, loss_scale=32, train_wall=262, gb_free=21.5, wall=103063
2022-03-08 01:17:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:17:46 | INFO | valid | epoch 713 | valid on 'valid' subset | loss 11.169 | ppl 2302.78 | wps 38951.7 | wpb 510.9 | bsz 1 | num_updates 34705 | best_loss 8.621
2022-03-08 01:17:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 713 @ 34705 updates
2022-03-08 01:17:46 | INFO | fairseq_cli.train | end of epoch 713 (average epoch stats below)
2022-03-08 01:17:46 | INFO | train | epoch 713 | loss 1.723 | ppl 3.3 | wps 22080.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34705 | lr 0.000169748 | gnorm 0.342 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 103081
2022-03-08 01:17:46 | INFO | fairseq.trainer | begin training epoch 714
2022-03-08 01:17:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:20:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:20:10 | INFO | valid | epoch 714 | valid on 'valid' subset | loss 11.132 | ppl 2244.03 | wps 39234.5 | wpb 510.9 | bsz 1 | num_updates 34754 | best_loss 8.621
2022-03-08 01:20:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 714 @ 34754 updates
2022-03-08 01:20:10 | INFO | fairseq_cli.train | end of epoch 714 (average epoch stats below)
2022-03-08 01:20:10 | INFO | train | epoch 714 | loss 1.724 | ppl 3.3 | wps 22060.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34754 | lr 0.000169628 | gnorm 0.339 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 103225
2022-03-08 01:20:10 | INFO | fairseq.trainer | begin training epoch 715
2022-03-08 01:20:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:21:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:22:24 | INFO | train_inner | epoch 715:     47 / 49 loss=1.723, ppl=3.3, wps=21867.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34800, lr=0.000169516, gnorm=0.34, loss_scale=32, train_wall=263, gb_free=21.5, wall=103360
2022-03-08 01:22:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:22:34 | INFO | valid | epoch 715 | valid on 'valid' subset | loss 11.144 | ppl 2263.56 | wps 39295.2 | wpb 510.9 | bsz 1 | num_updates 34802 | best_loss 8.621
2022-03-08 01:22:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 715 @ 34802 updates
2022-03-08 01:22:34 | INFO | fairseq_cli.train | end of epoch 715 (average epoch stats below)
2022-03-08 01:22:34 | INFO | train | epoch 715 | loss 1.723 | ppl 3.3 | wps 21612.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34802 | lr 0.000169511 | gnorm 0.34 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 103369
2022-03-08 01:22:34 | INFO | fairseq.trainer | begin training epoch 716
2022-03-08 01:22:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:24:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:24:58 | INFO | valid | epoch 716 | valid on 'valid' subset | loss 11.164 | ppl 2294.7 | wps 39357.3 | wpb 510.9 | bsz 1 | num_updates 34851 | best_loss 8.621
2022-03-08 01:24:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 716 @ 34851 updates
2022-03-08 01:24:58 | INFO | fairseq_cli.train | end of epoch 716 (average epoch stats below)
2022-03-08 01:24:58 | INFO | train | epoch 716 | loss 1.723 | ppl 3.3 | wps 22075.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34851 | lr 0.000169392 | gnorm 0.345 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 103513
2022-03-08 01:24:58 | INFO | fairseq.trainer | begin training epoch 717
2022-03-08 01:24:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:27:17 | INFO | train_inner | epoch 717:     49 / 49 loss=1.723, ppl=3.3, wps=22078, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=34900, lr=0.000169273, gnorm=0.344, loss_scale=32, train_wall=259, gb_free=21.5, wall=103652
2022-03-08 01:27:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:27:22 | INFO | valid | epoch 717 | valid on 'valid' subset | loss 11.131 | ppl 2242.71 | wps 39004 | wpb 510.9 | bsz 1 | num_updates 34900 | best_loss 8.621
2022-03-08 01:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 717 @ 34900 updates
2022-03-08 01:27:22 | INFO | fairseq_cli.train | end of epoch 717 (average epoch stats below)
2022-03-08 01:27:22 | INFO | train | epoch 717 | loss 1.723 | ppl 3.3 | wps 22049.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34900 | lr 0.000169273 | gnorm 0.34 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 103658
2022-03-08 01:27:22 | INFO | fairseq.trainer | begin training epoch 718
2022-03-08 01:27:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:28:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:29:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:29:46 | INFO | valid | epoch 718 | valid on 'valid' subset | loss 11.15 | ppl 2273.12 | wps 38948.5 | wpb 510.9 | bsz 1 | num_updates 34948 | best_loss 8.621
2022-03-08 01:29:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 718 @ 34948 updates
2022-03-08 01:29:46 | INFO | fairseq_cli.train | end of epoch 718 (average epoch stats below)
2022-03-08 01:29:46 | INFO | train | epoch 718 | loss 1.722 | ppl 3.3 | wps 21600.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34948 | lr 0.000169157 | gnorm 0.338 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 103802
2022-03-08 01:29:46 | INFO | fairseq.trainer | begin training epoch 719
2022-03-08 01:29:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:32:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:32:11 | INFO | valid | epoch 719 | valid on 'valid' subset | loss 11.141 | ppl 2258.52 | wps 38932.3 | wpb 510.9 | bsz 1 | num_updates 34997 | best_loss 8.621
2022-03-08 01:32:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 719 @ 34997 updates
2022-03-08 01:32:11 | INFO | fairseq_cli.train | end of epoch 719 (average epoch stats below)
2022-03-08 01:32:11 | INFO | train | epoch 719 | loss 1.722 | ppl 3.3 | wps 22052.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34997 | lr 0.000169038 | gnorm 0.34 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 103946
2022-03-08 01:32:11 | INFO | fairseq.trainer | begin training epoch 720
2022-03-08 01:32:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:32:19 | INFO | train_inner | epoch 720:      3 / 49 loss=1.722, ppl=3.3, wps=21444.3, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=35000, lr=0.000169031, gnorm=0.339, loss_scale=32, train_wall=263, gb_free=21.5, wall=103954
2022-03-08 01:34:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:34:35 | INFO | valid | epoch 720 | valid on 'valid' subset | loss 11.162 | ppl 2291.59 | wps 39149.7 | wpb 510.9 | bsz 1 | num_updates 35046 | best_loss 8.621
2022-03-08 01:34:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 720 @ 35046 updates
2022-03-08 01:34:35 | INFO | fairseq_cli.train | end of epoch 720 (average epoch stats below)
2022-03-08 01:34:35 | INFO | train | epoch 720 | loss 1.722 | ppl 3.3 | wps 22062.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35046 | lr 0.00016892 | gnorm 0.34 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 104090
2022-03-08 01:34:35 | INFO | fairseq.trainer | begin training epoch 721
2022-03-08 01:34:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:35:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:36:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:36:59 | INFO | valid | epoch 721 | valid on 'valid' subset | loss 11.135 | ppl 2248.95 | wps 38620.4 | wpb 510.9 | bsz 1 | num_updates 35094 | best_loss 8.621
2022-03-08 01:36:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 721 @ 35094 updates
2022-03-08 01:36:59 | INFO | fairseq_cli.train | end of epoch 721 (average epoch stats below)
2022-03-08 01:36:59 | INFO | train | epoch 721 | loss 1.722 | ppl 3.3 | wps 21623.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 35094 | lr 0.000168804 | gnorm 0.339 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 104234
2022-03-08 01:36:59 | INFO | fairseq.trainer | begin training epoch 722
2022-03-08 01:36:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:37:16 | INFO | train_inner | epoch 722:      6 / 49 loss=1.722, ppl=3.3, wps=21875.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35100, lr=0.00016879, gnorm=0.339, loss_scale=32, train_wall=262, gb_free=21.5, wall=104251
2022-03-08 01:39:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:39:23 | INFO | valid | epoch 722 | valid on 'valid' subset | loss 11.151 | ppl 2274.03 | wps 38930.5 | wpb 510.9 | bsz 1 | num_updates 35143 | best_loss 8.621
2022-03-08 01:39:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 722 @ 35143 updates
2022-03-08 01:39:23 | INFO | fairseq_cli.train | end of epoch 722 (average epoch stats below)
2022-03-08 01:39:23 | INFO | train | epoch 722 | loss 1.722 | ppl 3.3 | wps 22054.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35143 | lr 0.000168687 | gnorm 0.342 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 104378
2022-03-08 01:39:23 | INFO | fairseq.trainer | begin training epoch 723
2022-03-08 01:39:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:41:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:41:47 | INFO | valid | epoch 723 | valid on 'valid' subset | loss 11.142 | ppl 2259.74 | wps 38608.3 | wpb 510.9 | bsz 1 | num_updates 35192 | best_loss 8.621
2022-03-08 01:41:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 723 @ 35192 updates
2022-03-08 01:41:47 | INFO | fairseq_cli.train | end of epoch 723 (average epoch stats below)
2022-03-08 01:41:47 | INFO | train | epoch 723 | loss 1.722 | ppl 3.3 | wps 22065.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35192 | lr 0.000168569 | gnorm 0.343 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 104522
2022-03-08 01:41:47 | INFO | fairseq.trainer | begin training epoch 724
2022-03-08 01:41:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:41:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:42:12 | INFO | train_inner | epoch 724:      9 / 49 loss=1.722, ppl=3.3, wps=21870.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35200, lr=0.00016855, gnorm=0.343, loss_scale=32, train_wall=262, gb_free=21.5, wall=104548
2022-03-08 01:44:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:44:11 | INFO | valid | epoch 724 | valid on 'valid' subset | loss 11.169 | ppl 2302.87 | wps 38924.4 | wpb 510.9 | bsz 1 | num_updates 35240 | best_loss 8.621
2022-03-08 01:44:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 724 @ 35240 updates
2022-03-08 01:44:11 | INFO | fairseq_cli.train | end of epoch 724 (average epoch stats below)
2022-03-08 01:44:11 | INFO | train | epoch 724 | loss 1.722 | ppl 3.3 | wps 21614.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 35240 | lr 0.000168454 | gnorm 0.343 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 104666
2022-03-08 01:44:11 | INFO | fairseq.trainer | begin training epoch 725
2022-03-08 01:44:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:46:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:46:35 | INFO | valid | epoch 725 | valid on 'valid' subset | loss 11.157 | ppl 2283.09 | wps 38994.3 | wpb 510.9 | bsz 1 | num_updates 35289 | best_loss 8.621
2022-03-08 01:46:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 725 @ 35289 updates
2022-03-08 01:46:35 | INFO | fairseq_cli.train | end of epoch 725 (average epoch stats below)
2022-03-08 01:46:35 | INFO | train | epoch 725 | loss 1.722 | ppl 3.3 | wps 22051.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35289 | lr 0.000168337 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 104810
2022-03-08 01:46:35 | INFO | fairseq.trainer | begin training epoch 726
2022-03-08 01:46:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:47:06 | INFO | train_inner | epoch 726:     11 / 49 loss=1.721, ppl=3.3, wps=22074.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35300, lr=0.000168311, gnorm=0.341, loss_scale=32, train_wall=260, gb_free=21.5, wall=104841
2022-03-08 01:48:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:48:59 | INFO | valid | epoch 726 | valid on 'valid' subset | loss 11.138 | ppl 2253.84 | wps 39097.2 | wpb 510.9 | bsz 1 | num_updates 35338 | best_loss 8.621
2022-03-08 01:48:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 726 @ 35338 updates
2022-03-08 01:48:59 | INFO | fairseq_cli.train | end of epoch 726 (average epoch stats below)
2022-03-08 01:48:59 | INFO | train | epoch 726 | loss 1.721 | ppl 3.3 | wps 22055.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35338 | lr 0.000168221 | gnorm 0.343 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 104954
2022-03-08 01:48:59 | INFO | fairseq.trainer | begin training epoch 727
2022-03-08 01:48:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:49:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:51:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:51:23 | INFO | valid | epoch 727 | valid on 'valid' subset | loss 11.159 | ppl 2286.27 | wps 39046.7 | wpb 510.9 | bsz 1 | num_updates 35386 | best_loss 8.621
2022-03-08 01:51:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 727 @ 35386 updates
2022-03-08 01:51:23 | INFO | fairseq_cli.train | end of epoch 727 (average epoch stats below)
2022-03-08 01:51:23 | INFO | train | epoch 727 | loss 1.721 | ppl 3.3 | wps 21608.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 35386 | lr 0.000168106 | gnorm 0.342 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 105098
2022-03-08 01:51:23 | INFO | fairseq.trainer | begin training epoch 728
2022-03-08 01:51:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:52:03 | INFO | train_inner | epoch 728:     14 / 49 loss=1.721, ppl=3.3, wps=21864.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35400, lr=0.000168073, gnorm=0.341, loss_scale=32, train_wall=262, gb_free=21.5, wall=105138
2022-03-08 01:53:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:53:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:53:47 | INFO | valid | epoch 728 | valid on 'valid' subset | loss 11.131 | ppl 2242.45 | wps 39040.5 | wpb 510.9 | bsz 1 | num_updates 35434 | best_loss 8.621
2022-03-08 01:53:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 728 @ 35434 updates
2022-03-08 01:53:47 | INFO | fairseq_cli.train | end of epoch 728 (average epoch stats below)
2022-03-08 01:53:47 | INFO | train | epoch 728 | loss 1.721 | ppl 3.3 | wps 21587.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 35434 | lr 0.000167993 | gnorm 0.342 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 105242
2022-03-08 01:53:47 | INFO | fairseq.trainer | begin training epoch 729
2022-03-08 01:53:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:56:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:56:11 | INFO | valid | epoch 729 | valid on 'valid' subset | loss 11.137 | ppl 2251.4 | wps 39217.2 | wpb 510.9 | bsz 1 | num_updates 35483 | best_loss 8.621
2022-03-08 01:56:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 729 @ 35483 updates
2022-03-08 01:56:11 | INFO | fairseq_cli.train | end of epoch 729 (average epoch stats below)
2022-03-08 01:56:11 | INFO | train | epoch 729 | loss 1.721 | ppl 3.3 | wps 22077.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35483 | lr 0.000167876 | gnorm 0.34 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 105386
2022-03-08 01:56:11 | INFO | fairseq.trainer | begin training epoch 730
2022-03-08 01:56:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:57:00 | INFO | train_inner | epoch 730:     17 / 49 loss=1.72, ppl=3.3, wps=21866.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35500, lr=0.000167836, gnorm=0.341, loss_scale=16, train_wall=262, gb_free=21.5, wall=105435
2022-03-08 01:58:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:58:35 | INFO | valid | epoch 730 | valid on 'valid' subset | loss 11.155 | ppl 2280.94 | wps 39313.8 | wpb 510.9 | bsz 1 | num_updates 35532 | best_loss 8.621
2022-03-08 01:58:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 730 @ 35532 updates
2022-03-08 01:58:35 | INFO | fairseq_cli.train | end of epoch 730 (average epoch stats below)
2022-03-08 01:58:35 | INFO | train | epoch 730 | loss 1.72 | ppl 3.29 | wps 22082.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35532 | lr 0.000167761 | gnorm 0.338 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 105530
2022-03-08 01:58:35 | INFO | fairseq.trainer | begin training epoch 731
2022-03-08 01:58:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:00:59 | INFO | valid | epoch 731 | valid on 'valid' subset | loss 11.151 | ppl 2273.2 | wps 39134 | wpb 510.9 | bsz 1 | num_updates 35581 | best_loss 8.621
2022-03-08 02:00:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 731 @ 35581 updates
2022-03-08 02:00:59 | INFO | fairseq_cli.train | end of epoch 731 (average epoch stats below)
2022-03-08 02:00:59 | INFO | train | epoch 731 | loss 1.72 | ppl 3.29 | wps 22077.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35581 | lr 0.000167645 | gnorm 0.336 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 105674
2022-03-08 02:00:59 | INFO | fairseq.trainer | begin training epoch 732
2022-03-08 02:00:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:01:53 | INFO | train_inner | epoch 732:     19 / 49 loss=1.72, ppl=3.3, wps=22100, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35600, lr=0.0001676, gnorm=0.337, loss_scale=32, train_wall=260, gb_free=21.5, wall=105728
2022-03-08 02:03:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:03:23 | INFO | valid | epoch 732 | valid on 'valid' subset | loss 11.157 | ppl 2283.56 | wps 39110 | wpb 510.9 | bsz 1 | num_updates 35630 | best_loss 8.621
2022-03-08 02:03:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 732 @ 35630 updates
2022-03-08 02:03:23 | INFO | fairseq_cli.train | end of epoch 732 (average epoch stats below)
2022-03-08 02:03:23 | INFO | train | epoch 732 | loss 1.72 | ppl 3.3 | wps 22073.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35630 | lr 0.00016753 | gnorm 0.338 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 105818
2022-03-08 02:03:23 | INFO | fairseq.trainer | begin training epoch 733
2022-03-08 02:03:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:05:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:05:47 | INFO | valid | epoch 733 | valid on 'valid' subset | loss 11.157 | ppl 2283.57 | wps 39101.7 | wpb 510.9 | bsz 1 | num_updates 35679 | best_loss 8.621
2022-03-08 02:05:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 733 @ 35679 updates
2022-03-08 02:05:47 | INFO | fairseq_cli.train | end of epoch 733 (average epoch stats below)
2022-03-08 02:05:47 | INFO | train | epoch 733 | loss 1.72 | ppl 3.29 | wps 22043.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35679 | lr 0.000167415 | gnorm 0.335 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 105962
2022-03-08 02:05:47 | INFO | fairseq.trainer | begin training epoch 734
2022-03-08 02:05:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:06:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:06:50 | INFO | train_inner | epoch 734:     22 / 49 loss=1.72, ppl=3.29, wps=21865.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35700, lr=0.000167365, gnorm=0.337, loss_scale=32, train_wall=262, gb_free=21.5, wall=106025
2022-03-08 02:08:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:08:11 | INFO | valid | epoch 734 | valid on 'valid' subset | loss 11.135 | ppl 2249.43 | wps 39088.7 | wpb 510.9 | bsz 1 | num_updates 35727 | best_loss 8.621
2022-03-08 02:08:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 734 @ 35727 updates
2022-03-08 02:08:11 | INFO | fairseq_cli.train | end of epoch 734 (average epoch stats below)
2022-03-08 02:08:11 | INFO | train | epoch 734 | loss 1.72 | ppl 3.29 | wps 21610.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 35727 | lr 0.000167302 | gnorm 0.338 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 106106
2022-03-08 02:08:11 | INFO | fairseq.trainer | begin training epoch 735
2022-03-08 02:08:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:10:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:10:35 | INFO | valid | epoch 735 | valid on 'valid' subset | loss 11.142 | ppl 2260.33 | wps 39245 | wpb 510.9 | bsz 1 | num_updates 35776 | best_loss 8.621
2022-03-08 02:10:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 735 @ 35776 updates
2022-03-08 02:10:35 | INFO | fairseq_cli.train | end of epoch 735 (average epoch stats below)
2022-03-08 02:10:35 | INFO | train | epoch 735 | loss 1.719 | ppl 3.29 | wps 22068.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35776 | lr 0.000167188 | gnorm 0.334 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 106250
2022-03-08 02:10:35 | INFO | fairseq.trainer | begin training epoch 736
2022-03-08 02:10:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:11:44 | INFO | train_inner | epoch 736:     24 / 49 loss=1.719, ppl=3.29, wps=22074.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=35800, lr=0.000167132, gnorm=0.335, loss_scale=32, train_wall=260, gb_free=21.5, wall=106319
2022-03-08 02:12:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:12:59 | INFO | valid | epoch 736 | valid on 'valid' subset | loss 11.128 | ppl 2238.09 | wps 39056.1 | wpb 510.9 | bsz 1 | num_updates 35825 | best_loss 8.621
2022-03-08 02:12:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 736 @ 35825 updates
2022-03-08 02:12:59 | INFO | fairseq_cli.train | end of epoch 736 (average epoch stats below)
2022-03-08 02:12:59 | INFO | train | epoch 736 | loss 1.719 | ppl 3.29 | wps 22037 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35825 | lr 0.000167073 | gnorm 0.338 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 106395
2022-03-08 02:12:59 | INFO | fairseq.trainer | begin training epoch 737
2022-03-08 02:12:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:13:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:15:23 | INFO | valid | epoch 737 | valid on 'valid' subset | loss 11.128 | ppl 2238.18 | wps 39099 | wpb 510.9 | bsz 1 | num_updates 35873 | best_loss 8.621
2022-03-08 02:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 737 @ 35873 updates
2022-03-08 02:15:23 | INFO | fairseq_cli.train | end of epoch 737 (average epoch stats below)
2022-03-08 02:15:23 | INFO | train | epoch 737 | loss 1.72 | ppl 3.29 | wps 21600.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 35873 | lr 0.000166961 | gnorm 0.345 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 106539
2022-03-08 02:15:23 | INFO | fairseq.trainer | begin training epoch 738
2022-03-08 02:15:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:16:40 | INFO | train_inner | epoch 738:     27 / 49 loss=1.72, ppl=3.29, wps=21857.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35900, lr=0.000166899, gnorm=0.342, loss_scale=32, train_wall=262, gb_free=21.5, wall=106616
2022-03-08 02:17:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:17:47 | INFO | valid | epoch 738 | valid on 'valid' subset | loss 11.15 | ppl 2272.35 | wps 39024.5 | wpb 510.9 | bsz 1 | num_updates 35922 | best_loss 8.621
2022-03-08 02:17:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 738 @ 35922 updates
2022-03-08 02:17:47 | INFO | fairseq_cli.train | end of epoch 738 (average epoch stats below)
2022-03-08 02:17:47 | INFO | train | epoch 738 | loss 1.719 | ppl 3.29 | wps 22056.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35922 | lr 0.000166848 | gnorm 0.34 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 106683
2022-03-08 02:17:47 | INFO | fairseq.trainer | begin training epoch 739
2022-03-08 02:17:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:19:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:20:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:20:12 | INFO | valid | epoch 739 | valid on 'valid' subset | loss 11.148 | ppl 2269.85 | wps 39188.7 | wpb 510.9 | bsz 1 | num_updates 35970 | best_loss 8.621
2022-03-08 02:20:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 739 @ 35970 updates
2022-03-08 02:20:12 | INFO | fairseq_cli.train | end of epoch 739 (average epoch stats below)
2022-03-08 02:20:12 | INFO | train | epoch 739 | loss 1.719 | ppl 3.29 | wps 21592.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 35970 | lr 0.000166736 | gnorm 0.338 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 106827
2022-03-08 02:20:12 | INFO | fairseq.trainer | begin training epoch 740
2022-03-08 02:20:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:21:37 | INFO | train_inner | epoch 740:     30 / 49 loss=1.719, ppl=3.29, wps=21854.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=36000, lr=0.000166667, gnorm=0.339, loss_scale=32, train_wall=263, gb_free=21.5, wall=106913
2022-03-08 02:22:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:22:36 | INFO | valid | epoch 740 | valid on 'valid' subset | loss 11.132 | ppl 2243.9 | wps 39218.9 | wpb 510.9 | bsz 1 | num_updates 36019 | best_loss 8.621
2022-03-08 02:22:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 740 @ 36019 updates
2022-03-08 02:22:36 | INFO | fairseq_cli.train | end of epoch 740 (average epoch stats below)
2022-03-08 02:22:36 | INFO | train | epoch 740 | loss 1.719 | ppl 3.29 | wps 22049 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36019 | lr 0.000166623 | gnorm 0.339 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 106971
2022-03-08 02:22:36 | INFO | fairseq.trainer | begin training epoch 741
2022-03-08 02:22:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:24:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:25:00 | INFO | valid | epoch 741 | valid on 'valid' subset | loss 11.129 | ppl 2239.32 | wps 39187.8 | wpb 510.9 | bsz 1 | num_updates 36068 | best_loss 8.621
2022-03-08 02:25:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 741 @ 36068 updates
2022-03-08 02:25:00 | INFO | fairseq_cli.train | end of epoch 741 (average epoch stats below)
2022-03-08 02:25:00 | INFO | train | epoch 741 | loss 1.719 | ppl 3.29 | wps 22042.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36068 | lr 0.000166509 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 107115
2022-03-08 02:25:00 | INFO | fairseq.trainer | begin training epoch 742
2022-03-08 02:25:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:26:31 | INFO | train_inner | epoch 742:     32 / 49 loss=1.719, ppl=3.29, wps=22062.4, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=36100, lr=0.000166436, gnorm=0.336, loss_scale=64, train_wall=260, gb_free=21.5, wall=107207
2022-03-08 02:26:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:27:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:27:24 | INFO | valid | epoch 742 | valid on 'valid' subset | loss 11.145 | ppl 2264.69 | wps 39097.8 | wpb 510.9 | bsz 1 | num_updates 36116 | best_loss 8.621
2022-03-08 02:27:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 742 @ 36116 updates
2022-03-08 02:27:24 | INFO | fairseq_cli.train | end of epoch 742 (average epoch stats below)
2022-03-08 02:27:24 | INFO | train | epoch 742 | loss 1.718 | ppl 3.29 | wps 21597 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 36116 | lr 0.000166399 | gnorm 0.335 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 107259
2022-03-08 02:27:24 | INFO | fairseq.trainer | begin training epoch 743
2022-03-08 02:27:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:29:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:29:48 | INFO | valid | epoch 743 | valid on 'valid' subset | loss 11.129 | ppl 2239.97 | wps 39186.4 | wpb 510.9 | bsz 1 | num_updates 36165 | best_loss 8.621
2022-03-08 02:29:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 743 @ 36165 updates
2022-03-08 02:29:48 | INFO | fairseq_cli.train | end of epoch 743 (average epoch stats below)
2022-03-08 02:29:48 | INFO | train | epoch 743 | loss 1.719 | ppl 3.29 | wps 22067.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36165 | lr 0.000166286 | gnorm 0.34 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 107403
2022-03-08 02:29:48 | INFO | fairseq.trainer | begin training epoch 744
2022-03-08 02:29:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:31:28 | INFO | train_inner | epoch 744:     35 / 49 loss=1.718, ppl=3.29, wps=21863.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=36200, lr=0.000166206, gnorm=0.34, loss_scale=32, train_wall=262, gb_free=21.5, wall=107503
2022-03-08 02:32:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:32:12 | INFO | valid | epoch 744 | valid on 'valid' subset | loss 11.157 | ppl 2284.14 | wps 39086.3 | wpb 510.9 | bsz 1 | num_updates 36214 | best_loss 8.621
2022-03-08 02:32:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 744 @ 36214 updates
2022-03-08 02:32:12 | INFO | fairseq_cli.train | end of epoch 744 (average epoch stats below)
2022-03-08 02:32:12 | INFO | train | epoch 744 | loss 1.718 | ppl 3.29 | wps 22043.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36214 | lr 0.000166173 | gnorm 0.342 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 107547
2022-03-08 02:32:12 | INFO | fairseq.trainer | begin training epoch 745
2022-03-08 02:32:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:34:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:34:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:34:36 | INFO | valid | epoch 745 | valid on 'valid' subset | loss 11.138 | ppl 2253.42 | wps 39233 | wpb 510.9 | bsz 1 | num_updates 36262 | best_loss 8.621
2022-03-08 02:34:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 745 @ 36262 updates
2022-03-08 02:34:36 | INFO | fairseq_cli.train | end of epoch 745 (average epoch stats below)
2022-03-08 02:34:36 | INFO | train | epoch 745 | loss 1.718 | ppl 3.29 | wps 21598.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 36262 | lr 0.000166063 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 107692
2022-03-08 02:34:36 | INFO | fairseq.trainer | begin training epoch 746
2022-03-08 02:34:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:36:25 | INFO | train_inner | epoch 746:     38 / 49 loss=1.718, ppl=3.29, wps=21860.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=36300, lr=0.000165977, gnorm=0.339, loss_scale=32, train_wall=263, gb_free=21.5, wall=107800
2022-03-08 02:36:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:37:00 | INFO | valid | epoch 746 | valid on 'valid' subset | loss 11.13 | ppl 2241.63 | wps 39266.1 | wpb 510.9 | bsz 1 | num_updates 36311 | best_loss 8.621
2022-03-08 02:37:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 746 @ 36311 updates
2022-03-08 02:37:00 | INFO | fairseq_cli.train | end of epoch 746 (average epoch stats below)
2022-03-08 02:37:00 | INFO | train | epoch 746 | loss 1.718 | ppl 3.29 | wps 22058.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36311 | lr 0.000165951 | gnorm 0.339 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 107836
2022-03-08 02:37:00 | INFO | fairseq.trainer | begin training epoch 747
2022-03-08 02:37:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:39:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:39:25 | INFO | valid | epoch 747 | valid on 'valid' subset | loss 11.11 | ppl 2210.71 | wps 39159.1 | wpb 510.9 | bsz 1 | num_updates 36360 | best_loss 8.621
2022-03-08 02:39:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 747 @ 36360 updates
2022-03-08 02:39:25 | INFO | fairseq_cli.train | end of epoch 747 (average epoch stats below)
2022-03-08 02:39:25 | INFO | train | epoch 747 | loss 1.717 | ppl 3.29 | wps 22035 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36360 | lr 0.00016584 | gnorm 0.332 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 107980
2022-03-08 02:39:25 | INFO | fairseq.trainer | begin training epoch 748
2022-03-08 02:39:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:41:19 | INFO | train_inner | epoch 748:     40 / 49 loss=1.717, ppl=3.29, wps=22071.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=36400, lr=0.000165748, gnorm=0.334, loss_scale=64, train_wall=260, gb_free=21.5, wall=108094
2022-03-08 02:41:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:41:49 | INFO | valid | epoch 748 | valid on 'valid' subset | loss 11.14 | ppl 2256.59 | wps 39070.3 | wpb 510.9 | bsz 1 | num_updates 36409 | best_loss 8.621
2022-03-08 02:41:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 748 @ 36409 updates
2022-03-08 02:41:49 | INFO | fairseq_cli.train | end of epoch 748 (average epoch stats below)
2022-03-08 02:41:49 | INFO | train | epoch 748 | loss 1.717 | ppl 3.29 | wps 22062 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36409 | lr 0.000165728 | gnorm 0.336 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 108124
2022-03-08 02:41:49 | INFO | fairseq.trainer | begin training epoch 749
2022-03-08 02:41:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:42:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:44:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:44:13 | INFO | valid | epoch 749 | valid on 'valid' subset | loss 11.145 | ppl 2264.22 | wps 39053.9 | wpb 510.9 | bsz 1 | num_updates 36457 | best_loss 8.621
2022-03-08 02:44:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 749 @ 36457 updates
2022-03-08 02:44:13 | INFO | fairseq_cli.train | end of epoch 749 (average epoch stats below)
2022-03-08 02:44:13 | INFO | train | epoch 749 | loss 1.717 | ppl 3.29 | wps 21587.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 36457 | lr 0.000165619 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 108268
2022-03-08 02:44:13 | INFO | fairseq.trainer | begin training epoch 750
2022-03-08 02:44:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:46:16 | INFO | train_inner | epoch 750:     43 / 49 loss=1.717, ppl=3.29, wps=21844.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=36500, lr=0.000165521, gnorm=0.337, loss_scale=32, train_wall=263, gb_free=21.5, wall=108391
2022-03-08 02:46:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:46:37 | INFO | valid | epoch 750 | valid on 'valid' subset | loss 11.129 | ppl 2239.22 | wps 39253.6 | wpb 510.9 | bsz 1 | num_updates 36506 | best_loss 8.621
2022-03-08 02:46:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 750 @ 36506 updates
2022-03-08 02:46:37 | INFO | fairseq_cli.train | end of epoch 750 (average epoch stats below)
2022-03-08 02:46:37 | INFO | train | epoch 750 | loss 1.717 | ppl 3.29 | wps 22046.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36506 | lr 0.000165508 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 108412
2022-03-08 02:46:37 | INFO | fairseq.trainer | begin training epoch 751
2022-03-08 02:46:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:48:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:49:01 | INFO | valid | epoch 751 | valid on 'valid' subset | loss 11.167 | ppl 2300.08 | wps 39056.7 | wpb 510.9 | bsz 1 | num_updates 36555 | best_loss 8.621
2022-03-08 02:49:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 751 @ 36555 updates
2022-03-08 02:49:01 | INFO | fairseq_cli.train | end of epoch 751 (average epoch stats below)
2022-03-08 02:49:01 | INFO | train | epoch 751 | loss 1.717 | ppl 3.29 | wps 22059.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36555 | lr 0.000165397 | gnorm 0.333 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 108556
2022-03-08 02:49:01 | INFO | fairseq.trainer | begin training epoch 752
2022-03-08 02:49:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:50:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:51:12 | INFO | train_inner | epoch 752:     46 / 49 loss=1.717, ppl=3.29, wps=21862.6, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=36600, lr=0.000165295, gnorm=0.333, loss_scale=32, train_wall=262, gb_free=21.5, wall=108688
2022-03-08 02:51:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:51:25 | INFO | valid | epoch 752 | valid on 'valid' subset | loss 11.14 | ppl 2256.56 | wps 39005.9 | wpb 510.9 | bsz 1 | num_updates 36603 | best_loss 8.621
2022-03-08 02:51:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 752 @ 36603 updates
2022-03-08 02:51:25 | INFO | fairseq_cli.train | end of epoch 752 (average epoch stats below)
2022-03-08 02:51:25 | INFO | train | epoch 752 | loss 1.717 | ppl 3.29 | wps 21596 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 36603 | lr 0.000165288 | gnorm 0.334 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 108700
2022-03-08 02:51:25 | INFO | fairseq.trainer | begin training epoch 753
2022-03-08 02:51:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:53:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:53:49 | INFO | valid | epoch 753 | valid on 'valid' subset | loss 11.119 | ppl 2223.45 | wps 39128 | wpb 510.9 | bsz 1 | num_updates 36652 | best_loss 8.621
2022-03-08 02:53:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 753 @ 36652 updates
2022-03-08 02:53:49 | INFO | fairseq_cli.train | end of epoch 753 (average epoch stats below)
2022-03-08 02:53:49 | INFO | train | epoch 753 | loss 1.717 | ppl 3.29 | wps 22042.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36652 | lr 0.000165178 | gnorm 0.335 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 108845
2022-03-08 02:53:49 | INFO | fairseq.trainer | begin training epoch 754
2022-03-08 02:53:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:56:06 | INFO | train_inner | epoch 754:     48 / 49 loss=1.717, ppl=3.29, wps=22058, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=36700, lr=0.00016507, gnorm=0.336, loss_scale=32, train_wall=260, gb_free=21.5, wall=108982
2022-03-08 02:56:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:56:14 | INFO | valid | epoch 754 | valid on 'valid' subset | loss 11.119 | ppl 2223.85 | wps 39661 | wpb 510.9 | bsz 1 | num_updates 36701 | best_loss 8.621
2022-03-08 02:56:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 754 @ 36701 updates
2022-03-08 02:56:14 | INFO | fairseq_cli.train | end of epoch 754 (average epoch stats below)
2022-03-08 02:56:14 | INFO | train | epoch 754 | loss 1.717 | ppl 3.29 | wps 22050.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36701 | lr 0.000165067 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 108989
2022-03-08 02:56:14 | INFO | fairseq.trainer | begin training epoch 755
2022-03-08 02:56:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:57:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:58:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:58:38 | INFO | valid | epoch 755 | valid on 'valid' subset | loss 11.117 | ppl 2221.19 | wps 38882 | wpb 510.9 | bsz 1 | num_updates 36749 | best_loss 8.621
2022-03-08 02:58:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 755 @ 36749 updates
2022-03-08 02:58:38 | INFO | fairseq_cli.train | end of epoch 755 (average epoch stats below)
2022-03-08 02:58:38 | INFO | train | epoch 755 | loss 1.717 | ppl 3.29 | wps 21605.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 36749 | lr 0.000164959 | gnorm 0.334 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 109133
2022-03-08 02:58:38 | INFO | fairseq.trainer | begin training epoch 756
2022-03-08 02:58:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:00:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:01:02 | INFO | valid | epoch 756 | valid on 'valid' subset | loss 11.128 | ppl 2237.8 | wps 39085.5 | wpb 510.9 | bsz 1 | num_updates 36798 | best_loss 8.621
2022-03-08 03:01:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 756 @ 36798 updates
2022-03-08 03:01:02 | INFO | fairseq_cli.train | end of epoch 756 (average epoch stats below)
2022-03-08 03:01:02 | INFO | train | epoch 756 | loss 1.716 | ppl 3.29 | wps 22060.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36798 | lr 0.00016485 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 109277
2022-03-08 03:01:02 | INFO | fairseq.trainer | begin training epoch 757
2022-03-08 03:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:01:07 | INFO | train_inner | epoch 757:      2 / 49 loss=1.716, ppl=3.29, wps=21446.6, ups=0.33, wpb=64539.7, bsz=126.1, num_updates=36800, lr=0.000164845, gnorm=0.337, loss_scale=32, train_wall=261, gb_free=21.5, wall=109283
2022-03-08 03:03:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:03:26 | INFO | valid | epoch 757 | valid on 'valid' subset | loss 11.145 | ppl 2264.79 | wps 39009.1 | wpb 510.9 | bsz 1 | num_updates 36847 | best_loss 8.621
2022-03-08 03:03:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 757 @ 36847 updates
2022-03-08 03:03:26 | INFO | fairseq_cli.train | end of epoch 757 (average epoch stats below)
2022-03-08 03:03:26 | INFO | train | epoch 757 | loss 1.716 | ppl 3.28 | wps 22069.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36847 | lr 0.00016474 | gnorm 0.332 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 109421
2022-03-08 03:03:26 | INFO | fairseq.trainer | begin training epoch 758
2022-03-08 03:03:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:04:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:05:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:05:50 | INFO | valid | epoch 758 | valid on 'valid' subset | loss 11.162 | ppl 2291.14 | wps 39038.2 | wpb 510.9 | bsz 1 | num_updates 36895 | best_loss 8.621
2022-03-08 03:05:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 758 @ 36895 updates
2022-03-08 03:05:50 | INFO | fairseq_cli.train | end of epoch 758 (average epoch stats below)
2022-03-08 03:05:50 | INFO | train | epoch 758 | loss 1.716 | ppl 3.28 | wps 21597.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 36895 | lr 0.000164633 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 109565
2022-03-08 03:05:50 | INFO | fairseq.trainer | begin training epoch 759
2022-03-08 03:05:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:06:04 | INFO | train_inner | epoch 759:      5 / 49 loss=1.716, ppl=3.28, wps=21867.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=36900, lr=0.000164622, gnorm=0.334, loss_scale=32, train_wall=263, gb_free=21.5, wall=109579
2022-03-08 03:08:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:08:14 | INFO | valid | epoch 759 | valid on 'valid' subset | loss 11.143 | ppl 2261.65 | wps 38972.9 | wpb 510.9 | bsz 1 | num_updates 36944 | best_loss 8.621
2022-03-08 03:08:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 759 @ 36944 updates
2022-03-08 03:08:14 | INFO | fairseq_cli.train | end of epoch 759 (average epoch stats below)
2022-03-08 03:08:14 | INFO | train | epoch 759 | loss 1.716 | ppl 3.28 | wps 22052.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36944 | lr 0.000164524 | gnorm 0.335 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 109709
2022-03-08 03:08:14 | INFO | fairseq.trainer | begin training epoch 760
2022-03-08 03:08:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:10:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:10:38 | INFO | valid | epoch 760 | valid on 'valid' subset | loss 11.142 | ppl 2259.07 | wps 38981.2 | wpb 510.9 | bsz 1 | num_updates 36993 | best_loss 8.621
2022-03-08 03:10:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 760 @ 36993 updates
2022-03-08 03:10:38 | INFO | fairseq_cli.train | end of epoch 760 (average epoch stats below)
2022-03-08 03:10:38 | INFO | train | epoch 760 | loss 1.715 | ppl 3.28 | wps 22048 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36993 | lr 0.000164415 | gnorm 0.334 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 109853
2022-03-08 03:10:38 | INFO | fairseq.trainer | begin training epoch 761
2022-03-08 03:10:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:10:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:11:01 | INFO | train_inner | epoch 761:      8 / 49 loss=1.715, ppl=3.28, wps=21857.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37000, lr=0.000164399, gnorm=0.335, loss_scale=32, train_wall=262, gb_free=21.5, wall=109876
2022-03-08 03:12:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:13:02 | INFO | valid | epoch 761 | valid on 'valid' subset | loss 11.149 | ppl 2271.39 | wps 38965 | wpb 510.9 | bsz 1 | num_updates 37041 | best_loss 8.621
2022-03-08 03:13:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 761 @ 37041 updates
2022-03-08 03:13:02 | INFO | fairseq_cli.train | end of epoch 761 (average epoch stats below)
2022-03-08 03:13:02 | INFO | train | epoch 761 | loss 1.714 | ppl 3.28 | wps 21604.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37041 | lr 0.000164308 | gnorm 0.333 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 109997
2022-03-08 03:13:02 | INFO | fairseq.trainer | begin training epoch 762
2022-03-08 03:13:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:15:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:15:26 | INFO | valid | epoch 762 | valid on 'valid' subset | loss 11.143 | ppl 2261.81 | wps 38985.6 | wpb 510.9 | bsz 1 | num_updates 37090 | best_loss 8.621
2022-03-08 03:15:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 762 @ 37090 updates
2022-03-08 03:15:26 | INFO | fairseq_cli.train | end of epoch 762 (average epoch stats below)
2022-03-08 03:15:26 | INFO | train | epoch 762 | loss 1.715 | ppl 3.28 | wps 22034.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37090 | lr 0.000164199 | gnorm 0.332 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 110142
2022-03-08 03:15:26 | INFO | fairseq.trainer | begin training epoch 763
2022-03-08 03:15:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:15:55 | INFO | train_inner | epoch 763:     10 / 49 loss=1.714, ppl=3.28, wps=22067, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37100, lr=0.000164177, gnorm=0.332, loss_scale=32, train_wall=260, gb_free=21.5, wall=110170
2022-03-08 03:17:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:17:50 | INFO | valid | epoch 763 | valid on 'valid' subset | loss 11.131 | ppl 2242.43 | wps 38930.7 | wpb 510.9 | bsz 1 | num_updates 37138 | best_loss 8.621
2022-03-08 03:17:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 763 @ 37138 updates
2022-03-08 03:17:50 | INFO | fairseq_cli.train | end of epoch 763 (average epoch stats below)
2022-03-08 03:17:50 | INFO | train | epoch 763 | loss 1.715 | ppl 3.28 | wps 21599.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37138 | lr 0.000164093 | gnorm 0.334 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 110286
2022-03-08 03:17:50 | INFO | fairseq.trainer | begin training epoch 764
2022-03-08 03:17:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:20:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:20:15 | INFO | valid | epoch 764 | valid on 'valid' subset | loss 11.139 | ppl 2255.32 | wps 38894.8 | wpb 510.9 | bsz 1 | num_updates 37187 | best_loss 8.621
2022-03-08 03:20:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 764 @ 37187 updates
2022-03-08 03:20:15 | INFO | fairseq_cli.train | end of epoch 764 (average epoch stats below)
2022-03-08 03:20:15 | INFO | train | epoch 764 | loss 1.715 | ppl 3.28 | wps 22043.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37187 | lr 0.000163985 | gnorm 0.334 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 110430
2022-03-08 03:20:15 | INFO | fairseq.trainer | begin training epoch 765
2022-03-08 03:20:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:20:52 | INFO | train_inner | epoch 765:     13 / 49 loss=1.715, ppl=3.28, wps=21855.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=37200, lr=0.000163956, gnorm=0.334, loss_scale=32, train_wall=263, gb_free=21.5, wall=110467
2022-03-08 03:22:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:22:39 | INFO | valid | epoch 765 | valid on 'valid' subset | loss 11.123 | ppl 2229.97 | wps 39114.4 | wpb 510.9 | bsz 1 | num_updates 37236 | best_loss 8.621
2022-03-08 03:22:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 765 @ 37236 updates
2022-03-08 03:22:39 | INFO | fairseq_cli.train | end of epoch 765 (average epoch stats below)
2022-03-08 03:22:39 | INFO | train | epoch 765 | loss 1.714 | ppl 3.28 | wps 22070.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37236 | lr 0.000163877 | gnorm 0.334 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 110574
2022-03-08 03:22:39 | INFO | fairseq.trainer | begin training epoch 766
2022-03-08 03:22:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:24:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:25:03 | INFO | valid | epoch 766 | valid on 'valid' subset | loss 11.13 | ppl 2240.73 | wps 38854.2 | wpb 510.9 | bsz 1 | num_updates 37285 | best_loss 8.621
2022-03-08 03:25:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 766 @ 37285 updates
2022-03-08 03:25:03 | INFO | fairseq_cli.train | end of epoch 766 (average epoch stats below)
2022-03-08 03:25:03 | INFO | train | epoch 766 | loss 1.714 | ppl 3.28 | wps 22049.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37285 | lr 0.000163769 | gnorm 0.328 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 110718
2022-03-08 03:25:03 | INFO | fairseq.trainer | begin training epoch 767
2022-03-08 03:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:25:46 | INFO | train_inner | epoch 767:     15 / 49 loss=1.714, ppl=3.28, wps=22075.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37300, lr=0.000163737, gnorm=0.332, loss_scale=64, train_wall=260, gb_free=21.5, wall=110761
2022-03-08 03:25:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:27:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:27:27 | INFO | valid | epoch 767 | valid on 'valid' subset | loss 11.143 | ppl 2261.19 | wps 38822 | wpb 510.9 | bsz 1 | num_updates 37333 | best_loss 8.621
2022-03-08 03:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 767 @ 37333 updates
2022-03-08 03:27:27 | INFO | fairseq_cli.train | end of epoch 767 (average epoch stats below)
2022-03-08 03:27:27 | INFO | train | epoch 767 | loss 1.714 | ppl 3.28 | wps 21604.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37333 | lr 0.000163664 | gnorm 0.338 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 110862
2022-03-08 03:27:27 | INFO | fairseq.trainer | begin training epoch 768
2022-03-08 03:27:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:29:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:29:51 | INFO | valid | epoch 768 | valid on 'valid' subset | loss 11.143 | ppl 2262.11 | wps 38979.6 | wpb 510.9 | bsz 1 | num_updates 37382 | best_loss 8.621
2022-03-08 03:29:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 768 @ 37382 updates
2022-03-08 03:29:51 | INFO | fairseq_cli.train | end of epoch 768 (average epoch stats below)
2022-03-08 03:29:51 | INFO | train | epoch 768 | loss 1.714 | ppl 3.28 | wps 22057.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37382 | lr 0.000163557 | gnorm 0.336 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 111006
2022-03-08 03:29:51 | INFO | fairseq.trainer | begin training epoch 769
2022-03-08 03:29:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:30:42 | INFO | train_inner | epoch 769:     18 / 49 loss=1.714, ppl=3.28, wps=21858.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37400, lr=0.000163517, gnorm=0.337, loss_scale=32, train_wall=263, gb_free=21.5, wall=111058
2022-03-08 03:32:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:32:15 | INFO | valid | epoch 769 | valid on 'valid' subset | loss 11.137 | ppl 2251.5 | wps 38973.7 | wpb 510.9 | bsz 1 | num_updates 37431 | best_loss 8.621
2022-03-08 03:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 769 @ 37431 updates
2022-03-08 03:32:15 | INFO | fairseq_cli.train | end of epoch 769 (average epoch stats below)
2022-03-08 03:32:15 | INFO | train | epoch 769 | loss 1.714 | ppl 3.28 | wps 22037.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37431 | lr 0.00016345 | gnorm 0.336 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 111150
2022-03-08 03:32:15 | INFO | fairseq.trainer | begin training epoch 770
2022-03-08 03:32:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:32:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:34:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:34:39 | INFO | valid | epoch 770 | valid on 'valid' subset | loss 11.151 | ppl 2273.67 | wps 39177.5 | wpb 510.9 | bsz 1 | num_updates 37479 | best_loss 8.621
2022-03-08 03:34:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 770 @ 37479 updates
2022-03-08 03:34:39 | INFO | fairseq_cli.train | end of epoch 770 (average epoch stats below)
2022-03-08 03:34:39 | INFO | train | epoch 770 | loss 1.714 | ppl 3.28 | wps 21609.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37479 | lr 0.000163345 | gnorm 0.333 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 111294
2022-03-08 03:34:39 | INFO | fairseq.trainer | begin training epoch 771
2022-03-08 03:34:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:35:39 | INFO | train_inner | epoch 771:     21 / 49 loss=1.714, ppl=3.28, wps=21863.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37500, lr=0.000163299, gnorm=0.334, loss_scale=32, train_wall=262, gb_free=21.5, wall=111354
2022-03-08 03:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:37:03 | INFO | valid | epoch 771 | valid on 'valid' subset | loss 11.139 | ppl 2254.41 | wps 39224.7 | wpb 510.9 | bsz 1 | num_updates 37528 | best_loss 8.621
2022-03-08 03:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 771 @ 37528 updates
2022-03-08 03:37:03 | INFO | fairseq_cli.train | end of epoch 771 (average epoch stats below)
2022-03-08 03:37:03 | INFO | train | epoch 771 | loss 1.714 | ppl 3.28 | wps 22065.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37528 | lr 0.000163238 | gnorm 0.335 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 111438
2022-03-08 03:37:03 | INFO | fairseq.trainer | begin training epoch 772
2022-03-08 03:37:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:39:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:39:27 | INFO | valid | epoch 772 | valid on 'valid' subset | loss 11.137 | ppl 2252.66 | wps 39195.6 | wpb 510.9 | bsz 1 | num_updates 37577 | best_loss 8.621
2022-03-08 03:39:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 772 @ 37577 updates
2022-03-08 03:39:27 | INFO | fairseq_cli.train | end of epoch 772 (average epoch stats below)
2022-03-08 03:39:27 | INFO | train | epoch 772 | loss 1.714 | ppl 3.28 | wps 22061.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37577 | lr 0.000163132 | gnorm 0.333 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 111582
2022-03-08 03:39:27 | INFO | fairseq.trainer | begin training epoch 773
2022-03-08 03:39:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:40:33 | INFO | train_inner | epoch 773:     23 / 49 loss=1.713, ppl=3.28, wps=22082.5, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=37600, lr=0.000163082, gnorm=0.334, loss_scale=64, train_wall=260, gb_free=21.5, wall=111648
2022-03-08 03:40:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:41:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:41:51 | INFO | valid | epoch 773 | valid on 'valid' subset | loss 11.151 | ppl 2273.43 | wps 38996 | wpb 510.9 | bsz 1 | num_updates 37625 | best_loss 8.621
2022-03-08 03:41:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 773 @ 37625 updates
2022-03-08 03:41:51 | INFO | fairseq_cli.train | end of epoch 773 (average epoch stats below)
2022-03-08 03:41:51 | INFO | train | epoch 773 | loss 1.713 | ppl 3.28 | wps 21616.2 | ups 0.33 | wpb 64853.3 | bsz 126.7 | num_updates 37625 | lr 0.000163028 | gnorm 0.333 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 111726
2022-03-08 03:41:51 | INFO | fairseq.trainer | begin training epoch 774
2022-03-08 03:41:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:44:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:44:15 | INFO | valid | epoch 774 | valid on 'valid' subset | loss 11.141 | ppl 2257.68 | wps 39113.1 | wpb 510.9 | bsz 1 | num_updates 37674 | best_loss 8.621
2022-03-08 03:44:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 774 @ 37674 updates
2022-03-08 03:44:15 | INFO | fairseq_cli.train | end of epoch 774 (average epoch stats below)
2022-03-08 03:44:15 | INFO | train | epoch 774 | loss 1.713 | ppl 3.28 | wps 22052 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37674 | lr 0.000162922 | gnorm 0.334 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 111871
2022-03-08 03:44:15 | INFO | fairseq.trainer | begin training epoch 775
2022-03-08 03:44:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:45:30 | INFO | train_inner | epoch 775:     26 / 49 loss=1.713, ppl=3.28, wps=21864, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37700, lr=0.000162866, gnorm=0.333, loss_scale=32, train_wall=262, gb_free=21.5, wall=111945
2022-03-08 03:46:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:46:39 | INFO | valid | epoch 775 | valid on 'valid' subset | loss 11.139 | ppl 2255.19 | wps 39078.4 | wpb 510.9 | bsz 1 | num_updates 37723 | best_loss 8.621
2022-03-08 03:46:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 775 @ 37723 updates
2022-03-08 03:46:39 | INFO | fairseq_cli.train | end of epoch 775 (average epoch stats below)
2022-03-08 03:46:39 | INFO | train | epoch 775 | loss 1.713 | ppl 3.28 | wps 22055.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37723 | lr 0.000162816 | gnorm 0.333 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 112015
2022-03-08 03:46:39 | INFO | fairseq.trainer | begin training epoch 776
2022-03-08 03:46:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:48:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:48:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:49:03 | INFO | valid | epoch 776 | valid on 'valid' subset | loss 11.135 | ppl 2248.87 | wps 38974.3 | wpb 510.9 | bsz 1 | num_updates 37771 | best_loss 8.621
2022-03-08 03:49:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 776 @ 37771 updates
2022-03-08 03:49:03 | INFO | fairseq_cli.train | end of epoch 776 (average epoch stats below)
2022-03-08 03:49:03 | INFO | train | epoch 776 | loss 1.713 | ppl 3.28 | wps 21610.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37771 | lr 0.000162712 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 112159
2022-03-08 03:49:03 | INFO | fairseq.trainer | begin training epoch 777
2022-03-08 03:49:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:50:26 | INFO | train_inner | epoch 777:     29 / 49 loss=1.713, ppl=3.28, wps=21859.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37800, lr=0.00016265, gnorm=0.335, loss_scale=32, train_wall=262, gb_free=21.5, wall=112242
2022-03-08 03:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:51:28 | INFO | valid | epoch 777 | valid on 'valid' subset | loss 11.128 | ppl 2238.37 | wps 39222.5 | wpb 510.9 | bsz 1 | num_updates 37820 | best_loss 8.621
2022-03-08 03:51:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 777 @ 37820 updates
2022-03-08 03:51:28 | INFO | fairseq_cli.train | end of epoch 777 (average epoch stats below)
2022-03-08 03:51:28 | INFO | train | epoch 777 | loss 1.712 | ppl 3.28 | wps 22049.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37820 | lr 0.000162607 | gnorm 0.332 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 112303
2022-03-08 03:51:28 | INFO | fairseq.trainer | begin training epoch 778
2022-03-08 03:51:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:53:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:53:52 | INFO | valid | epoch 778 | valid on 'valid' subset | loss 11.127 | ppl 2236.57 | wps 39179.2 | wpb 510.9 | bsz 1 | num_updates 37869 | best_loss 8.621
2022-03-08 03:53:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 778 @ 37869 updates
2022-03-08 03:53:52 | INFO | fairseq_cli.train | end of epoch 778 (average epoch stats below)
2022-03-08 03:53:52 | INFO | train | epoch 778 | loss 1.712 | ppl 3.28 | wps 22061.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37869 | lr 0.000162502 | gnorm 0.333 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 112447
2022-03-08 03:53:52 | INFO | fairseq.trainer | begin training epoch 779
2022-03-08 03:53:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:55:20 | INFO | train_inner | epoch 779:     31 / 49 loss=1.712, ppl=3.28, wps=22081.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37900, lr=0.000162435, gnorm=0.332, loss_scale=64, train_wall=260, gb_free=21.5, wall=112535
2022-03-08 03:55:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:56:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:56:16 | INFO | valid | epoch 779 | valid on 'valid' subset | loss 11.113 | ppl 2214.63 | wps 39215.1 | wpb 510.9 | bsz 1 | num_updates 37917 | best_loss 8.621
2022-03-08 03:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 779 @ 37917 updates
2022-03-08 03:56:16 | INFO | fairseq_cli.train | end of epoch 779 (average epoch stats below)
2022-03-08 03:56:16 | INFO | train | epoch 779 | loss 1.712 | ppl 3.28 | wps 21611.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37917 | lr 0.000162399 | gnorm 0.332 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 112591
2022-03-08 03:56:16 | INFO | fairseq.trainer | begin training epoch 780
2022-03-08 03:56:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:58:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:58:40 | INFO | valid | epoch 780 | valid on 'valid' subset | loss 11.14 | ppl 2256.5 | wps 39163.2 | wpb 510.9 | bsz 1 | num_updates 37966 | best_loss 8.621
2022-03-08 03:58:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 780 @ 37966 updates
2022-03-08 03:58:40 | INFO | fairseq_cli.train | end of epoch 780 (average epoch stats below)
2022-03-08 03:58:40 | INFO | train | epoch 780 | loss 1.711 | ppl 3.27 | wps 22048.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37966 | lr 0.000162294 | gnorm 0.33 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 112735
2022-03-08 03:58:40 | INFO | fairseq.trainer | begin training epoch 781
2022-03-08 03:58:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:00:17 | INFO | train_inner | epoch 781:     34 / 49 loss=1.712, ppl=3.28, wps=21860.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38000, lr=0.000162221, gnorm=0.333, loss_scale=32, train_wall=263, gb_free=21.5, wall=112832
2022-03-08 04:00:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:01:04 | INFO | valid | epoch 781 | valid on 'valid' subset | loss 11.119 | ppl 2224.18 | wps 39026 | wpb 510.9 | bsz 1 | num_updates 38015 | best_loss 8.621
2022-03-08 04:01:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 781 @ 38015 updates
2022-03-08 04:01:04 | INFO | fairseq_cli.train | end of epoch 781 (average epoch stats below)
2022-03-08 04:01:04 | INFO | train | epoch 781 | loss 1.712 | ppl 3.28 | wps 22049.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38015 | lr 0.000162189 | gnorm 0.336 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 112879
2022-03-08 04:01:04 | INFO | fairseq.trainer | begin training epoch 782
2022-03-08 04:01:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:02:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:03:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:03:28 | INFO | valid | epoch 782 | valid on 'valid' subset | loss 11.137 | ppl 2252.55 | wps 39031 | wpb 510.9 | bsz 1 | num_updates 38063 | best_loss 8.621
2022-03-08 04:03:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 782 @ 38063 updates
2022-03-08 04:03:28 | INFO | fairseq_cli.train | end of epoch 782 (average epoch stats below)
2022-03-08 04:03:28 | INFO | train | epoch 782 | loss 1.712 | ppl 3.28 | wps 21624.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 38063 | lr 0.000162087 | gnorm 0.336 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 113023
2022-03-08 04:03:28 | INFO | fairseq.trainer | begin training epoch 783
2022-03-08 04:03:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:05:14 | INFO | train_inner | epoch 783:     37 / 49 loss=1.712, ppl=3.28, wps=21863.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38100, lr=0.000162008, gnorm=0.333, loss_scale=32, train_wall=262, gb_free=21.5, wall=113129
2022-03-08 04:05:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:05:52 | INFO | valid | epoch 783 | valid on 'valid' subset | loss 11.126 | ppl 2234.63 | wps 39089.4 | wpb 510.9 | bsz 1 | num_updates 38112 | best_loss 8.621
2022-03-08 04:05:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 783 @ 38112 updates
2022-03-08 04:05:52 | INFO | fairseq_cli.train | end of epoch 783 (average epoch stats below)
2022-03-08 04:05:52 | INFO | train | epoch 783 | loss 1.711 | ppl 3.27 | wps 22048.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38112 | lr 0.000161983 | gnorm 0.329 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 113167
2022-03-08 04:05:52 | INFO | fairseq.trainer | begin training epoch 784
2022-03-08 04:05:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:08:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:08:16 | INFO | valid | epoch 784 | valid on 'valid' subset | loss 11.137 | ppl 2251.88 | wps 39028.9 | wpb 510.9 | bsz 1 | num_updates 38161 | best_loss 8.621
2022-03-08 04:08:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 784 @ 38161 updates
2022-03-08 04:08:16 | INFO | fairseq_cli.train | end of epoch 784 (average epoch stats below)
2022-03-08 04:08:16 | INFO | train | epoch 784 | loss 1.711 | ppl 3.27 | wps 22052.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38161 | lr 0.000161879 | gnorm 0.329 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 113311
2022-03-08 04:08:16 | INFO | fairseq.trainer | begin training epoch 785
2022-03-08 04:08:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:09:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:10:10 | INFO | train_inner | epoch 785:     40 / 49 loss=1.711, ppl=3.27, wps=21869.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=38200, lr=0.000161796, gnorm=0.33, loss_scale=32, train_wall=263, gb_free=21.5, wall=113425
2022-03-08 04:10:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:10:40 | INFO | valid | epoch 785 | valid on 'valid' subset | loss 11.143 | ppl 2261.71 | wps 39071.7 | wpb 510.9 | bsz 1 | num_updates 38209 | best_loss 8.621
2022-03-08 04:10:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 785 @ 38209 updates
2022-03-08 04:10:40 | INFO | fairseq_cli.train | end of epoch 785 (average epoch stats below)
2022-03-08 04:10:40 | INFO | train | epoch 785 | loss 1.712 | ppl 3.28 | wps 21619.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 38209 | lr 0.000161777 | gnorm 0.331 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 113455
2022-03-08 04:10:40 | INFO | fairseq.trainer | begin training epoch 786
2022-03-08 04:10:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:12:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:13:04 | INFO | valid | epoch 786 | valid on 'valid' subset | loss 11.129 | ppl 2239.35 | wps 39115 | wpb 510.9 | bsz 1 | num_updates 38258 | best_loss 8.621
2022-03-08 04:13:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 786 @ 38258 updates
2022-03-08 04:13:04 | INFO | fairseq_cli.train | end of epoch 786 (average epoch stats below)
2022-03-08 04:13:04 | INFO | train | epoch 786 | loss 1.711 | ppl 3.27 | wps 22061.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38258 | lr 0.000161674 | gnorm 0.331 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 113599
2022-03-08 04:13:04 | INFO | fairseq.trainer | begin training epoch 787
2022-03-08 04:13:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:15:04 | INFO | train_inner | epoch 787:     42 / 49 loss=1.711, ppl=3.27, wps=22081.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=38300, lr=0.000161585, gnorm=0.332, loss_scale=32, train_wall=260, gb_free=21.5, wall=113719
2022-03-08 04:15:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:15:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:15:28 | INFO | valid | epoch 787 | valid on 'valid' subset | loss 11.11 | ppl 2209.98 | wps 38983.9 | wpb 510.9 | bsz 1 | num_updates 38306 | best_loss 8.621
2022-03-08 04:15:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 787 @ 38306 updates
2022-03-08 04:15:28 | INFO | fairseq_cli.train | end of epoch 787 (average epoch stats below)
2022-03-08 04:15:28 | INFO | train | epoch 787 | loss 1.711 | ppl 3.27 | wps 21604 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 38306 | lr 0.000161572 | gnorm 0.332 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 113743
2022-03-08 04:15:28 | INFO | fairseq.trainer | begin training epoch 788
2022-03-08 04:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:17:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:17:52 | INFO | valid | epoch 788 | valid on 'valid' subset | loss 11.134 | ppl 2247.95 | wps 39062.5 | wpb 510.9 | bsz 1 | num_updates 38355 | best_loss 8.621
2022-03-08 04:17:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 788 @ 38355 updates
2022-03-08 04:17:52 | INFO | fairseq_cli.train | end of epoch 788 (average epoch stats below)
2022-03-08 04:17:52 | INFO | train | epoch 788 | loss 1.71 | ppl 3.27 | wps 22044.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38355 | lr 0.000161469 | gnorm 0.329 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 113888
2022-03-08 04:17:52 | INFO | fairseq.trainer | begin training epoch 789
2022-03-08 04:17:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:20:01 | INFO | train_inner | epoch 789:     45 / 49 loss=1.71, ppl=3.27, wps=21866.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38400, lr=0.000161374, gnorm=0.33, loss_scale=32, train_wall=262, gb_free=21.5, wall=114016
2022-03-08 04:20:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:20:16 | INFO | valid | epoch 789 | valid on 'valid' subset | loss 11.133 | ppl 2245.83 | wps 39112.9 | wpb 510.9 | bsz 1 | num_updates 38404 | best_loss 8.621
2022-03-08 04:20:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 789 @ 38404 updates
2022-03-08 04:20:16 | INFO | fairseq_cli.train | end of epoch 789 (average epoch stats below)
2022-03-08 04:20:16 | INFO | train | epoch 789 | loss 1.71 | ppl 3.27 | wps 22085.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38404 | lr 0.000161366 | gnorm 0.331 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 114032
2022-03-08 04:20:16 | INFO | fairseq.trainer | begin training epoch 790
2022-03-08 04:20:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:22:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:22:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:22:40 | INFO | valid | epoch 790 | valid on 'valid' subset | loss 11.124 | ppl 2232.38 | wps 39081.3 | wpb 510.9 | bsz 1 | num_updates 38452 | best_loss 8.621
2022-03-08 04:22:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 790 @ 38452 updates
2022-03-08 04:22:40 | INFO | fairseq_cli.train | end of epoch 790 (average epoch stats below)
2022-03-08 04:22:40 | INFO | train | epoch 790 | loss 1.71 | ppl 3.27 | wps 21593.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 38452 | lr 0.000161265 | gnorm 0.33 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 114176
2022-03-08 04:22:40 | INFO | fairseq.trainer | begin training epoch 791
2022-03-08 04:22:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:24:58 | INFO | train_inner | epoch 791:     48 / 49 loss=1.71, ppl=3.27, wps=21850.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38500, lr=0.000161165, gnorm=0.33, loss_scale=32, train_wall=263, gb_free=21.5, wall=114313
2022-03-08 04:24:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:25:05 | INFO | valid | epoch 791 | valid on 'valid' subset | loss 11.128 | ppl 2238.78 | wps 39085.9 | wpb 510.9 | bsz 1 | num_updates 38501 | best_loss 8.621
2022-03-08 04:25:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 791 @ 38501 updates
2022-03-08 04:25:05 | INFO | fairseq_cli.train | end of epoch 791 (average epoch stats below)
2022-03-08 04:25:05 | INFO | train | epoch 791 | loss 1.71 | ppl 3.27 | wps 22037.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38501 | lr 0.000161162 | gnorm 0.33 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 114320
2022-03-08 04:25:05 | INFO | fairseq.trainer | begin training epoch 792
2022-03-08 04:25:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:27:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:27:29 | INFO | valid | epoch 792 | valid on 'valid' subset | loss 11.137 | ppl 2252.33 | wps 39095.8 | wpb 510.9 | bsz 1 | num_updates 38550 | best_loss 8.621
2022-03-08 04:27:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 792 @ 38550 updates
2022-03-08 04:27:29 | INFO | fairseq_cli.train | end of epoch 792 (average epoch stats below)
2022-03-08 04:27:29 | INFO | train | epoch 792 | loss 1.71 | ppl 3.27 | wps 22062.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38550 | lr 0.00016106 | gnorm 0.332 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 114464
2022-03-08 04:27:29 | INFO | fairseq.trainer | begin training epoch 793
2022-03-08 04:27:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:29:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:29:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:29:53 | INFO | valid | epoch 793 | valid on 'valid' subset | loss 11.136 | ppl 2249.99 | wps 39203.4 | wpb 510.9 | bsz 1 | num_updates 38598 | best_loss 8.621
2022-03-08 04:29:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 793 @ 38598 updates
2022-03-08 04:29:53 | INFO | fairseq_cli.train | end of epoch 793 (average epoch stats below)
2022-03-08 04:29:53 | INFO | train | epoch 793 | loss 1.71 | ppl 3.27 | wps 21601.7 | ups 0.33 | wpb 64853.3 | bsz 126.7 | num_updates 38598 | lr 0.00016096 | gnorm 0.327 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 114608
2022-03-08 04:29:53 | INFO | fairseq.trainer | begin training epoch 794
2022-03-08 04:29:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:29:59 | INFO | train_inner | epoch 794:      2 / 49 loss=1.71, ppl=3.27, wps=21441.4, ups=0.33, wpb=64548.5, bsz=126.1, num_updates=38600, lr=0.000160956, gnorm=0.331, loss_scale=32, train_wall=261, gb_free=21.5, wall=114614
2022-03-08 04:32:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:32:17 | INFO | valid | epoch 794 | valid on 'valid' subset | loss 11.121 | ppl 2226.6 | wps 39025.6 | wpb 510.9 | bsz 1 | num_updates 38647 | best_loss 8.621
2022-03-08 04:32:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 794 @ 38647 updates
2022-03-08 04:32:17 | INFO | fairseq_cli.train | end of epoch 794 (average epoch stats below)
2022-03-08 04:32:17 | INFO | train | epoch 794 | loss 1.71 | ppl 3.27 | wps 22032.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38647 | lr 0.000160858 | gnorm 0.335 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 114752
2022-03-08 04:32:17 | INFO | fairseq.trainer | begin training epoch 795
2022-03-08 04:32:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:34:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:34:41 | INFO | valid | epoch 795 | valid on 'valid' subset | loss 11.128 | ppl 2237.95 | wps 39160.1 | wpb 510.9 | bsz 1 | num_updates 38696 | best_loss 8.621
2022-03-08 04:34:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 795 @ 38696 updates
2022-03-08 04:34:41 | INFO | fairseq_cli.train | end of epoch 795 (average epoch stats below)
2022-03-08 04:34:41 | INFO | train | epoch 795 | loss 1.71 | ppl 3.27 | wps 22059.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38696 | lr 0.000160756 | gnorm 0.333 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 114896
2022-03-08 04:34:41 | INFO | fairseq.trainer | begin training epoch 796
2022-03-08 04:34:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:34:53 | INFO | train_inner | epoch 796:      4 / 49 loss=1.71, ppl=3.27, wps=22059.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38700, lr=0.000160748, gnorm=0.333, loss_scale=32, train_wall=260, gb_free=21.5, wall=114908
2022-03-08 04:36:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:36:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:37:05 | INFO | valid | epoch 796 | valid on 'valid' subset | loss 11.142 | ppl 2260.23 | wps 39367.3 | wpb 510.9 | bsz 1 | num_updates 38744 | best_loss 8.621
2022-03-08 04:37:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 796 @ 38744 updates
2022-03-08 04:37:05 | INFO | fairseq_cli.train | end of epoch 796 (average epoch stats below)
2022-03-08 04:37:05 | INFO | train | epoch 796 | loss 1.709 | ppl 3.27 | wps 21616.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 38744 | lr 0.000160656 | gnorm 0.329 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 115040
2022-03-08 04:37:05 | INFO | fairseq.trainer | begin training epoch 797
2022-03-08 04:37:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:39:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:39:29 | INFO | valid | epoch 797 | valid on 'valid' subset | loss 11.136 | ppl 2250.96 | wps 39194.8 | wpb 510.9 | bsz 1 | num_updates 38793 | best_loss 8.621
2022-03-08 04:39:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 797 @ 38793 updates
2022-03-08 04:39:29 | INFO | fairseq_cli.train | end of epoch 797 (average epoch stats below)
2022-03-08 04:39:29 | INFO | train | epoch 797 | loss 1.709 | ppl 3.27 | wps 22057.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38793 | lr 0.000160555 | gnorm 0.328 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 115184
2022-03-08 04:39:29 | INFO | fairseq.trainer | begin training epoch 798
2022-03-08 04:39:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:39:49 | INFO | train_inner | epoch 798:      7 / 49 loss=1.709, ppl=3.27, wps=21875.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38800, lr=0.00016054, gnorm=0.329, loss_scale=32, train_wall=262, gb_free=21.5, wall=115204
2022-03-08 04:41:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:41:53 | INFO | valid | epoch 798 | valid on 'valid' subset | loss 11.139 | ppl 2254.74 | wps 39195 | wpb 510.9 | bsz 1 | num_updates 38842 | best_loss 8.621
2022-03-08 04:41:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 798 @ 38842 updates
2022-03-08 04:41:53 | INFO | fairseq_cli.train | end of epoch 798 (average epoch stats below)
2022-03-08 04:41:53 | INFO | train | epoch 798 | loss 1.709 | ppl 3.27 | wps 22060.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38842 | lr 0.000160454 | gnorm 0.331 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 115328
2022-03-08 04:41:53 | INFO | fairseq.trainer | begin training epoch 799
2022-03-08 04:41:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:44:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:44:17 | INFO | valid | epoch 799 | valid on 'valid' subset | loss 11.126 | ppl 2234.98 | wps 38960.3 | wpb 510.9 | bsz 1 | num_updates 38891 | best_loss 8.621
2022-03-08 04:44:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 799 @ 38891 updates
2022-03-08 04:44:17 | INFO | fairseq_cli.train | end of epoch 799 (average epoch stats below)
2022-03-08 04:44:17 | INFO | train | epoch 799 | loss 1.709 | ppl 3.27 | wps 22036.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38891 | lr 0.000160352 | gnorm 0.332 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 115473
2022-03-08 04:44:17 | INFO | fairseq.trainer | begin training epoch 800
2022-03-08 04:44:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:44:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:44:46 | INFO | train_inner | epoch 800:     10 / 49 loss=1.709, ppl=3.27, wps=21854.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38900, lr=0.000160334, gnorm=0.332, loss_scale=32, train_wall=263, gb_free=21.5, wall=115501
2022-03-08 04:46:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:46:41 | INFO | valid | epoch 800 | valid on 'valid' subset | loss 11.129 | ppl 2239.91 | wps 39106.7 | wpb 510.9 | bsz 1 | num_updates 38939 | best_loss 8.621
2022-03-08 04:46:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 800 @ 38939 updates
2022-03-08 04:46:41 | INFO | fairseq_cli.train | end of epoch 800 (average epoch stats below)
2022-03-08 04:46:41 | INFO | train | epoch 800 | loss 1.709 | ppl 3.27 | wps 21616.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 38939 | lr 0.000160254 | gnorm 0.331 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 115617
2022-03-08 04:46:41 | INFO | fairseq.trainer | begin training epoch 801
2022-03-08 04:46:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:49:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:49:06 | INFO | valid | epoch 801 | valid on 'valid' subset | loss 11.149 | ppl 2270.22 | wps 39044 | wpb 510.9 | bsz 1 | num_updates 38988 | best_loss 8.621
2022-03-08 04:49:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 801 @ 38988 updates
2022-03-08 04:49:06 | INFO | fairseq_cli.train | end of epoch 801 (average epoch stats below)
2022-03-08 04:49:06 | INFO | train | epoch 801 | loss 1.709 | ppl 3.27 | wps 22040.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38988 | lr 0.000160153 | gnorm 0.331 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 115761
2022-03-08 04:49:06 | INFO | fairseq.trainer | begin training epoch 802
2022-03-08 04:49:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:49:40 | INFO | train_inner | epoch 802:     12 / 49 loss=1.709, ppl=3.27, wps=22074, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39000, lr=0.000160128, gnorm=0.332, loss_scale=32, train_wall=260, gb_free=21.5, wall=115795
2022-03-08 04:51:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:51:30 | INFO | valid | epoch 802 | valid on 'valid' subset | loss 11.125 | ppl 2233.68 | wps 39050.4 | wpb 510.9 | bsz 1 | num_updates 39037 | best_loss 8.621
2022-03-08 04:51:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 802 @ 39037 updates
2022-03-08 04:51:30 | INFO | fairseq_cli.train | end of epoch 802 (average epoch stats below)
2022-03-08 04:51:30 | INFO | train | epoch 802 | loss 1.709 | ppl 3.27 | wps 22046.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39037 | lr 0.000160052 | gnorm 0.333 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 115905
2022-03-08 04:51:30 | INFO | fairseq.trainer | begin training epoch 803
2022-03-08 04:51:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:53:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:53:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:53:54 | INFO | valid | epoch 803 | valid on 'valid' subset | loss 11.15 | ppl 2272.83 | wps 39691.5 | wpb 510.9 | bsz 1 | num_updates 39085 | best_loss 8.621
2022-03-08 04:53:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 803 @ 39085 updates
2022-03-08 04:53:54 | INFO | fairseq_cli.train | end of epoch 803 (average epoch stats below)
2022-03-08 04:53:54 | INFO | train | epoch 803 | loss 1.708 | ppl 3.27 | wps 21614.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39085 | lr 0.000159954 | gnorm 0.331 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 116049
2022-03-08 04:53:54 | INFO | fairseq.trainer | begin training epoch 804
2022-03-08 04:53:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:54:37 | INFO | train_inner | epoch 804:     15 / 49 loss=1.709, ppl=3.27, wps=21866.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39100, lr=0.000159923, gnorm=0.33, loss_scale=32, train_wall=263, gb_free=21.5, wall=116092
2022-03-08 04:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:56:18 | INFO | valid | epoch 804 | valid on 'valid' subset | loss 11.136 | ppl 2250.38 | wps 39212.1 | wpb 510.9 | bsz 1 | num_updates 39134 | best_loss 8.621
2022-03-08 04:56:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 804 @ 39134 updates
2022-03-08 04:56:18 | INFO | fairseq_cli.train | end of epoch 804 (average epoch stats below)
2022-03-08 04:56:18 | INFO | train | epoch 804 | loss 1.709 | ppl 3.27 | wps 22068.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39134 | lr 0.000159854 | gnorm 0.33 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 116193
2022-03-08 04:56:18 | INFO | fairseq.trainer | begin training epoch 805
2022-03-08 04:56:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:58:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:58:42 | INFO | valid | epoch 805 | valid on 'valid' subset | loss 11.136 | ppl 2251.01 | wps 39113.5 | wpb 510.9 | bsz 1 | num_updates 39183 | best_loss 8.621
2022-03-08 04:58:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 805 @ 39183 updates
2022-03-08 04:58:42 | INFO | fairseq_cli.train | end of epoch 805 (average epoch stats below)
2022-03-08 04:58:42 | INFO | train | epoch 805 | loss 1.708 | ppl 3.27 | wps 22058.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39183 | lr 0.000159754 | gnorm 0.328 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 116337
2022-03-08 04:58:42 | INFO | fairseq.trainer | begin training epoch 806
2022-03-08 04:58:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:59:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:59:33 | INFO | train_inner | epoch 806:     18 / 49 loss=1.708, ppl=3.27, wps=21861.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39200, lr=0.000159719, gnorm=0.329, loss_scale=32, train_wall=263, gb_free=21.5, wall=116389
2022-03-08 05:01:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:01:06 | INFO | valid | epoch 806 | valid on 'valid' subset | loss 11.122 | ppl 2228.21 | wps 39042.1 | wpb 510.9 | bsz 1 | num_updates 39231 | best_loss 8.621
2022-03-08 05:01:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 806 @ 39231 updates
2022-03-08 05:01:06 | INFO | fairseq_cli.train | end of epoch 806 (average epoch stats below)
2022-03-08 05:01:06 | INFO | train | epoch 806 | loss 1.708 | ppl 3.27 | wps 21599.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39231 | lr 0.000159656 | gnorm 0.329 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 116481
2022-03-08 05:01:06 | INFO | fairseq.trainer | begin training epoch 807
2022-03-08 05:01:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:03:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:03:30 | INFO | valid | epoch 807 | valid on 'valid' subset | loss 11.14 | ppl 2256.23 | wps 39139.3 | wpb 510.9 | bsz 1 | num_updates 39280 | best_loss 8.621
2022-03-08 05:03:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 807 @ 39280 updates
2022-03-08 05:03:30 | INFO | fairseq_cli.train | end of epoch 807 (average epoch stats below)
2022-03-08 05:03:30 | INFO | train | epoch 807 | loss 1.708 | ppl 3.27 | wps 22055.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39280 | lr 0.000159556 | gnorm 0.333 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 116625
2022-03-08 05:03:30 | INFO | fairseq.trainer | begin training epoch 808
2022-03-08 05:03:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:04:27 | INFO | train_inner | epoch 808:     20 / 49 loss=1.707, ppl=3.27, wps=22074, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=39300, lr=0.000159516, gnorm=0.33, loss_scale=32, train_wall=260, gb_free=21.5, wall=116682
2022-03-08 05:05:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:05:54 | INFO | valid | epoch 808 | valid on 'valid' subset | loss 11.106 | ppl 2203.88 | wps 39147.1 | wpb 510.9 | bsz 1 | num_updates 39329 | best_loss 8.621
2022-03-08 05:05:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 808 @ 39329 updates
2022-03-08 05:05:54 | INFO | fairseq_cli.train | end of epoch 808 (average epoch stats below)
2022-03-08 05:05:54 | INFO | train | epoch 808 | loss 1.707 | ppl 3.27 | wps 22057.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39329 | lr 0.000159457 | gnorm 0.33 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 116769
2022-03-08 05:05:54 | INFO | fairseq.trainer | begin training epoch 809
2022-03-08 05:05:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:07:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:08:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:08:18 | INFO | valid | epoch 809 | valid on 'valid' subset | loss 11.134 | ppl 2247.71 | wps 39196.1 | wpb 510.9 | bsz 1 | num_updates 39377 | best_loss 8.621
2022-03-08 05:08:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 809 @ 39377 updates
2022-03-08 05:08:18 | INFO | fairseq_cli.train | end of epoch 809 (average epoch stats below)
2022-03-08 05:08:18 | INFO | train | epoch 809 | loss 1.708 | ppl 3.27 | wps 21606 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39377 | lr 0.00015936 | gnorm 0.331 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 116913
2022-03-08 05:08:18 | INFO | fairseq.trainer | begin training epoch 810
2022-03-08 05:08:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:09:24 | INFO | train_inner | epoch 810:     23 / 49 loss=1.708, ppl=3.27, wps=21864.5, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=39400, lr=0.000159313, gnorm=0.331, loss_scale=32, train_wall=263, gb_free=21.5, wall=116979
2022-03-08 05:10:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:10:42 | INFO | valid | epoch 810 | valid on 'valid' subset | loss 11.132 | ppl 2244.44 | wps 39136.5 | wpb 510.9 | bsz 1 | num_updates 39426 | best_loss 8.621
2022-03-08 05:10:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 810 @ 39426 updates
2022-03-08 05:10:42 | INFO | fairseq_cli.train | end of epoch 810 (average epoch stats below)
2022-03-08 05:10:42 | INFO | train | epoch 810 | loss 1.707 | ppl 3.27 | wps 22044.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39426 | lr 0.000159261 | gnorm 0.329 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 117058
2022-03-08 05:10:42 | INFO | fairseq.trainer | begin training epoch 811
2022-03-08 05:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:13:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:13:06 | INFO | valid | epoch 811 | valid on 'valid' subset | loss 11.13 | ppl 2241 | wps 39125.6 | wpb 510.9 | bsz 1 | num_updates 39475 | best_loss 8.621
2022-03-08 05:13:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 811 @ 39475 updates
2022-03-08 05:13:06 | INFO | fairseq_cli.train | end of epoch 811 (average epoch stats below)
2022-03-08 05:13:06 | INFO | train | epoch 811 | loss 1.708 | ppl 3.27 | wps 22076.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39475 | lr 0.000159162 | gnorm 0.328 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 117202
2022-03-08 05:13:06 | INFO | fairseq.trainer | begin training epoch 812
2022-03-08 05:13:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:14:18 | INFO | train_inner | epoch 812:     25 / 49 loss=1.707, ppl=3.27, wps=22073.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=39500, lr=0.000159111, gnorm=0.329, loss_scale=64, train_wall=260, gb_free=21.5, wall=117273
2022-03-08 05:15:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:15:30 | INFO | valid | epoch 812 | valid on 'valid' subset | loss 11.124 | ppl 2231.08 | wps 39122.5 | wpb 510.9 | bsz 1 | num_updates 39524 | best_loss 8.621
2022-03-08 05:15:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 812 @ 39524 updates
2022-03-08 05:15:30 | INFO | fairseq_cli.train | end of epoch 812 (average epoch stats below)
2022-03-08 05:15:30 | INFO | train | epoch 812 | loss 1.707 | ppl 3.26 | wps 22043.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39524 | lr 0.000159063 | gnorm 0.327 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 117346
2022-03-08 05:15:31 | INFO | fairseq.trainer | begin training epoch 813
2022-03-08 05:15:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:15:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:17:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:17:55 | INFO | valid | epoch 813 | valid on 'valid' subset | loss 11.133 | ppl 2245.88 | wps 39035.3 | wpb 510.9 | bsz 1 | num_updates 39572 | best_loss 8.621
2022-03-08 05:17:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 813 @ 39572 updates
2022-03-08 05:17:55 | INFO | fairseq_cli.train | end of epoch 813 (average epoch stats below)
2022-03-08 05:17:55 | INFO | train | epoch 813 | loss 1.707 | ppl 3.26 | wps 21595.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39572 | lr 0.000158967 | gnorm 0.331 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 117490
2022-03-08 05:17:55 | INFO | fairseq.trainer | begin training epoch 814
2022-03-08 05:17:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:19:15 | INFO | train_inner | epoch 814:     28 / 49 loss=1.707, ppl=3.26, wps=21857.1, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=39600, lr=0.00015891, gnorm=0.328, loss_scale=32, train_wall=263, gb_free=21.5, wall=117570
2022-03-08 05:20:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:20:19 | INFO | valid | epoch 814 | valid on 'valid' subset | loss 11.121 | ppl 2227.67 | wps 39052 | wpb 510.9 | bsz 1 | num_updates 39621 | best_loss 8.621
2022-03-08 05:20:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 814 @ 39621 updates
2022-03-08 05:20:19 | INFO | fairseq_cli.train | end of epoch 814 (average epoch stats below)
2022-03-08 05:20:19 | INFO | train | epoch 814 | loss 1.707 | ppl 3.27 | wps 22060.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39621 | lr 0.000158868 | gnorm 0.329 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 117634
2022-03-08 05:20:19 | INFO | fairseq.trainer | begin training epoch 815
2022-03-08 05:20:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:22:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:22:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:22:43 | INFO | valid | epoch 815 | valid on 'valid' subset | loss 11.137 | ppl 2251.82 | wps 39199.4 | wpb 510.9 | bsz 1 | num_updates 39669 | best_loss 8.621
2022-03-08 05:22:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 815 @ 39669 updates
2022-03-08 05:22:43 | INFO | fairseq_cli.train | end of epoch 815 (average epoch stats below)
2022-03-08 05:22:43 | INFO | train | epoch 815 | loss 1.706 | ppl 3.26 | wps 21600 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39669 | lr 0.000158772 | gnorm 0.327 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 117778
2022-03-08 05:22:43 | INFO | fairseq.trainer | begin training epoch 816
2022-03-08 05:22:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:24:11 | INFO | train_inner | epoch 816:     31 / 49 loss=1.707, ppl=3.26, wps=21863.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=39700, lr=0.00015871, gnorm=0.327, loss_scale=32, train_wall=263, gb_free=21.5, wall=117867
2022-03-08 05:25:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:25:07 | INFO | valid | epoch 816 | valid on 'valid' subset | loss 11.124 | ppl 2232.56 | wps 39055.4 | wpb 510.9 | bsz 1 | num_updates 39718 | best_loss 8.621
2022-03-08 05:25:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 816 @ 39718 updates
2022-03-08 05:25:07 | INFO | fairseq_cli.train | end of epoch 816 (average epoch stats below)
2022-03-08 05:25:07 | INFO | train | epoch 816 | loss 1.706 | ppl 3.26 | wps 22047.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39718 | lr 0.000158674 | gnorm 0.325 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 117922
2022-03-08 05:25:07 | INFO | fairseq.trainer | begin training epoch 817
2022-03-08 05:25:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:27:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:27:31 | INFO | valid | epoch 817 | valid on 'valid' subset | loss 11.121 | ppl 2226.98 | wps 39094 | wpb 510.9 | bsz 1 | num_updates 39767 | best_loss 8.621
2022-03-08 05:27:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 817 @ 39767 updates
2022-03-08 05:27:31 | INFO | fairseq_cli.train | end of epoch 817 (average epoch stats below)
2022-03-08 05:27:31 | INFO | train | epoch 817 | loss 1.706 | ppl 3.26 | wps 22065.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39767 | lr 0.000158576 | gnorm 0.325 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 118066
2022-03-08 05:27:31 | INFO | fairseq.trainer | begin training epoch 818
2022-03-08 05:27:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:29:05 | INFO | train_inner | epoch 818:     33 / 49 loss=1.706, ppl=3.26, wps=22077.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39800, lr=0.000158511, gnorm=0.326, loss_scale=64, train_wall=260, gb_free=21.5, wall=118160
2022-03-08 05:29:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:29:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:29:55 | INFO | valid | epoch 818 | valid on 'valid' subset | loss 11.156 | ppl 2281.82 | wps 39228.6 | wpb 510.9 | bsz 1 | num_updates 39815 | best_loss 8.621
2022-03-08 05:29:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 818 @ 39815 updates
2022-03-08 05:29:55 | INFO | fairseq_cli.train | end of epoch 818 (average epoch stats below)
2022-03-08 05:29:55 | INFO | train | epoch 818 | loss 1.706 | ppl 3.26 | wps 21614 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39815 | lr 0.000158481 | gnorm 0.327 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 118210
2022-03-08 05:29:55 | INFO | fairseq.trainer | begin training epoch 819
2022-03-08 05:29:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:32:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:32:19 | INFO | valid | epoch 819 | valid on 'valid' subset | loss 11.132 | ppl 2244.4 | wps 39198.2 | wpb 510.9 | bsz 1 | num_updates 39864 | best_loss 8.621
2022-03-08 05:32:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 819 @ 39864 updates
2022-03-08 05:32:19 | INFO | fairseq_cli.train | end of epoch 819 (average epoch stats below)
2022-03-08 05:32:19 | INFO | train | epoch 819 | loss 1.706 | ppl 3.26 | wps 22055.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39864 | lr 0.000158383 | gnorm 0.329 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 118354
2022-03-08 05:32:19 | INFO | fairseq.trainer | begin training epoch 820
2022-03-08 05:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:34:02 | INFO | train_inner | epoch 820:     36 / 49 loss=1.706, ppl=3.26, wps=21862.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39900, lr=0.000158312, gnorm=0.329, loss_scale=32, train_wall=263, gb_free=21.5, wall=118457
2022-03-08 05:34:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:34:43 | INFO | valid | epoch 820 | valid on 'valid' subset | loss 11.137 | ppl 2252.17 | wps 39261.7 | wpb 510.9 | bsz 1 | num_updates 39913 | best_loss 8.621
2022-03-08 05:34:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 820 @ 39913 updates
2022-03-08 05:34:43 | INFO | fairseq_cli.train | end of epoch 820 (average epoch stats below)
2022-03-08 05:34:43 | INFO | train | epoch 820 | loss 1.706 | ppl 3.26 | wps 22056.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39913 | lr 0.000158286 | gnorm 0.329 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 118498
2022-03-08 05:34:43 | INFO | fairseq.trainer | begin training epoch 821
2022-03-08 05:34:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:37:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:37:07 | INFO | valid | epoch 821 | valid on 'valid' subset | loss 11.131 | ppl 2242.34 | wps 39272.7 | wpb 510.9 | bsz 1 | num_updates 39962 | best_loss 8.621
2022-03-08 05:37:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 821 @ 39962 updates
2022-03-08 05:37:07 | INFO | fairseq_cli.train | end of epoch 821 (average epoch stats below)
2022-03-08 05:37:07 | INFO | train | epoch 821 | loss 1.706 | ppl 3.26 | wps 22065.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39962 | lr 0.000158189 | gnorm 0.332 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 118642
2022-03-08 05:37:07 | INFO | fairseq.trainer | begin training epoch 822
2022-03-08 05:37:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:38:56 | INFO | train_inner | epoch 822:     38 / 49 loss=1.706, ppl=3.26, wps=22082.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40000, lr=0.000158114, gnorm=0.329, loss_scale=64, train_wall=260, gb_free=21.5, wall=118751
2022-03-08 05:39:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:39:31 | INFO | valid | epoch 822 | valid on 'valid' subset | loss 11.13 | ppl 2241.56 | wps 39236.4 | wpb 510.9 | bsz 1 | num_updates 40011 | best_loss 8.621
2022-03-08 05:39:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 822 @ 40011 updates
2022-03-08 05:39:31 | INFO | fairseq_cli.train | end of epoch 822 (average epoch stats below)
2022-03-08 05:39:31 | INFO | train | epoch 822 | loss 1.706 | ppl 3.26 | wps 22066.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40011 | lr 0.000158092 | gnorm 0.328 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 118786
2022-03-08 05:39:31 | INFO | fairseq.trainer | begin training epoch 823
2022-03-08 05:39:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:40:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:41:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:41:55 | INFO | valid | epoch 823 | valid on 'valid' subset | loss 11.141 | ppl 2258.41 | wps 38999 | wpb 510.9 | bsz 1 | num_updates 40059 | best_loss 8.621
2022-03-08 05:41:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 823 @ 40059 updates
2022-03-08 05:41:55 | INFO | fairseq_cli.train | end of epoch 823 (average epoch stats below)
2022-03-08 05:41:55 | INFO | train | epoch 823 | loss 1.705 | ppl 3.26 | wps 21601.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 40059 | lr 0.000157997 | gnorm 0.328 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 118931
2022-03-08 05:41:55 | INFO | fairseq.trainer | begin training epoch 824
2022-03-08 05:41:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:43:52 | INFO | train_inner | epoch 824:     41 / 49 loss=1.706, ppl=3.26, wps=21862.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40100, lr=0.000157917, gnorm=0.329, loss_scale=32, train_wall=262, gb_free=21.5, wall=119048
2022-03-08 05:44:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:44:19 | INFO | valid | epoch 824 | valid on 'valid' subset | loss 11.121 | ppl 2227.4 | wps 38909.2 | wpb 510.9 | bsz 1 | num_updates 40108 | best_loss 8.621
2022-03-08 05:44:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 824 @ 40108 updates
2022-03-08 05:44:19 | INFO | fairseq_cli.train | end of epoch 824 (average epoch stats below)
2022-03-08 05:44:19 | INFO | train | epoch 824 | loss 1.706 | ppl 3.26 | wps 22040.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40108 | lr 0.000157901 | gnorm 0.328 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 119075
2022-03-08 05:44:19 | INFO | fairseq.trainer | begin training epoch 825
2022-03-08 05:44:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:46:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:46:44 | INFO | valid | epoch 825 | valid on 'valid' subset | loss 11.125 | ppl 2233.78 | wps 39008.8 | wpb 510.9 | bsz 1 | num_updates 40157 | best_loss 8.621
2022-03-08 05:46:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 825 @ 40157 updates
2022-03-08 05:46:44 | INFO | fairseq_cli.train | end of epoch 825 (average epoch stats below)
2022-03-08 05:46:44 | INFO | train | epoch 825 | loss 1.705 | ppl 3.26 | wps 22063.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40157 | lr 0.000157804 | gnorm 0.332 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 119219
2022-03-08 05:46:44 | INFO | fairseq.trainer | begin training epoch 826
2022-03-08 05:46:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:48:46 | INFO | train_inner | epoch 826:     43 / 49 loss=1.705, ppl=3.26, wps=22063.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40200, lr=0.00015772, gnorm=0.33, loss_scale=64, train_wall=260, gb_free=21.5, wall=119342
2022-03-08 05:48:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:49:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:49:08 | INFO | valid | epoch 826 | valid on 'valid' subset | loss 11.118 | ppl 2222.07 | wps 39106.5 | wpb 510.9 | bsz 1 | num_updates 40205 | best_loss 8.621
2022-03-08 05:49:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 826 @ 40205 updates
2022-03-08 05:49:08 | INFO | fairseq_cli.train | end of epoch 826 (average epoch stats below)
2022-03-08 05:49:08 | INFO | train | epoch 826 | loss 1.704 | ppl 3.26 | wps 21579.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 40205 | lr 0.00015771 | gnorm 0.327 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 119363
2022-03-08 05:49:08 | INFO | fairseq.trainer | begin training epoch 827
2022-03-08 05:49:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:51:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:51:32 | INFO | valid | epoch 827 | valid on 'valid' subset | loss 11.116 | ppl 2219.98 | wps 39184.2 | wpb 510.9 | bsz 1 | num_updates 40254 | best_loss 8.621
2022-03-08 05:51:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 827 @ 40254 updates
2022-03-08 05:51:32 | INFO | fairseq_cli.train | end of epoch 827 (average epoch stats below)
2022-03-08 05:51:32 | INFO | train | epoch 827 | loss 1.704 | ppl 3.26 | wps 22066.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40254 | lr 0.000157614 | gnorm 0.326 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 119507
2022-03-08 05:51:32 | INFO | fairseq.trainer | begin training epoch 828
2022-03-08 05:51:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:53:43 | INFO | train_inner | epoch 828:     46 / 49 loss=1.705, ppl=3.26, wps=21865.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40300, lr=0.000157524, gnorm=0.326, loss_scale=32, train_wall=263, gb_free=21.5, wall=119638
2022-03-08 05:53:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:53:56 | INFO | valid | epoch 828 | valid on 'valid' subset | loss 11.114 | ppl 2216.84 | wps 39104.8 | wpb 510.9 | bsz 1 | num_updates 40303 | best_loss 8.621
2022-03-08 05:53:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 828 @ 40303 updates
2022-03-08 05:53:56 | INFO | fairseq_cli.train | end of epoch 828 (average epoch stats below)
2022-03-08 05:53:56 | INFO | train | epoch 828 | loss 1.705 | ppl 3.26 | wps 22056.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40303 | lr 0.000157518 | gnorm 0.326 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 119651
2022-03-08 05:53:56 | INFO | fairseq.trainer | begin training epoch 829
2022-03-08 05:53:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:56:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:56:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:56:20 | INFO | valid | epoch 829 | valid on 'valid' subset | loss 11.129 | ppl 2239.81 | wps 39091.7 | wpb 510.9 | bsz 1 | num_updates 40351 | best_loss 8.621
2022-03-08 05:56:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 829 @ 40351 updates
2022-03-08 05:56:20 | INFO | fairseq_cli.train | end of epoch 829 (average epoch stats below)
2022-03-08 05:56:20 | INFO | train | epoch 829 | loss 1.705 | ppl 3.26 | wps 21601.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 40351 | lr 0.000157425 | gnorm 0.326 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 119795
2022-03-08 05:56:20 | INFO | fairseq.trainer | begin training epoch 830
2022-03-08 05:56:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:58:38 | INFO | train_inner | epoch 830:     49 / 49 loss=1.705, ppl=3.26, wps=21850.5, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=40400, lr=0.000157329, gnorm=0.329, loss_scale=32, train_wall=261, gb_free=21.5, wall=119934
2022-03-08 05:58:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:58:44 | INFO | valid | epoch 830 | valid on 'valid' subset | loss 11.139 | ppl 2255.54 | wps 39141.9 | wpb 510.9 | bsz 1 | num_updates 40400 | best_loss 8.621
2022-03-08 05:58:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 830 @ 40400 updates
2022-03-08 05:58:44 | INFO | fairseq_cli.train | end of epoch 830 (average epoch stats below)
2022-03-08 05:58:44 | INFO | train | epoch 830 | loss 1.705 | ppl 3.26 | wps 22047.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40400 | lr 0.000157329 | gnorm 0.329 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 119939
2022-03-08 05:58:44 | INFO | fairseq.trainer | begin training epoch 831
2022-03-08 05:58:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:01:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:01:08 | INFO | valid | epoch 831 | valid on 'valid' subset | loss 11.116 | ppl 2219.16 | wps 39136 | wpb 510.9 | bsz 1 | num_updates 40449 | best_loss 8.621
2022-03-08 06:01:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 831 @ 40449 updates
2022-03-08 06:01:08 | INFO | fairseq_cli.train | end of epoch 831 (average epoch stats below)
2022-03-08 06:01:08 | INFO | train | epoch 831 | loss 1.704 | ppl 3.26 | wps 22071.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40449 | lr 0.000157234 | gnorm 0.326 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 120083
2022-03-08 06:01:08 | INFO | fairseq.trainer | begin training epoch 832
2022-03-08 06:01:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:02:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 06:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:03:32 | INFO | valid | epoch 832 | valid on 'valid' subset | loss 11.134 | ppl 2247.53 | wps 39113.7 | wpb 510.9 | bsz 1 | num_updates 40497 | best_loss 8.621
2022-03-08 06:03:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 832 @ 40497 updates
2022-03-08 06:03:32 | INFO | fairseq_cli.train | end of epoch 832 (average epoch stats below)
2022-03-08 06:03:32 | INFO | train | epoch 832 | loss 1.704 | ppl 3.26 | wps 21611.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 40497 | lr 0.000157141 | gnorm 0.326 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 120227
2022-03-08 06:03:32 | INFO | fairseq.trainer | begin training epoch 833
2022-03-08 06:03:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:03:41 | INFO | train_inner | epoch 833:      3 / 49 loss=1.704, ppl=3.26, wps=21460.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=40500, lr=0.000157135, gnorm=0.326, loss_scale=32, train_wall=262, gb_free=21.5, wall=120236
2022-03-08 06:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:05:56 | INFO | valid | epoch 833 | valid on 'valid' subset | loss 11.125 | ppl 2233.91 | wps 39040.6 | wpb 510.9 | bsz 1 | num_updates 40546 | best_loss 8.621
2022-03-08 06:05:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 833 @ 40546 updates
2022-03-08 06:05:56 | INFO | fairseq_cli.train | end of epoch 833 (average epoch stats below)
2022-03-08 06:05:56 | INFO | train | epoch 833 | loss 1.704 | ppl 3.26 | wps 22034.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40546 | lr 0.000157046 | gnorm 0.327 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 120372
2022-03-08 06:05:56 | INFO | fairseq.trainer | begin training epoch 834
2022-03-08 06:05:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:08:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:08:20 | INFO | valid | epoch 834 | valid on 'valid' subset | loss 11.142 | ppl 2260.48 | wps 39293.6 | wpb 510.9 | bsz 1 | num_updates 40595 | best_loss 8.621
2022-03-08 06:08:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 834 @ 40595 updates
2022-03-08 06:08:20 | INFO | fairseq_cli.train | end of epoch 834 (average epoch stats below)
2022-03-08 06:08:20 | INFO | train | epoch 834 | loss 1.704 | ppl 3.26 | wps 22060.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40595 | lr 0.000156951 | gnorm 0.325 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 120516
2022-03-08 06:08:20 | INFO | fairseq.trainer | begin training epoch 835
2022-03-08 06:08:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:08:35 | INFO | train_inner | epoch 835:      5 / 49 loss=1.704, ppl=3.26, wps=22065.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40600, lr=0.000156941, gnorm=0.326, loss_scale=32, train_wall=260, gb_free=21.5, wall=120530
2022-03-08 06:09:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 06:10:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:10:44 | INFO | valid | epoch 835 | valid on 'valid' subset | loss 11.11 | ppl 2210.6 | wps 39178.8 | wpb 510.9 | bsz 1 | num_updates 40643 | best_loss 8.621
2022-03-08 06:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 835 @ 40643 updates
2022-03-08 06:10:44 | INFO | fairseq_cli.train | end of epoch 835 (average epoch stats below)
2022-03-08 06:10:44 | INFO | train | epoch 835 | loss 1.704 | ppl 3.26 | wps 21606 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 40643 | lr 0.000156858 | gnorm 0.328 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 120660
2022-03-08 06:10:44 | INFO | fairseq.trainer | begin training epoch 836
2022-03-08 06:10:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:13:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:13:08 | INFO | valid | epoch 836 | valid on 'valid' subset | loss 11.12 | ppl 2225.84 | wps 39085.5 | wpb 510.9 | bsz 1 | num_updates 40692 | best_loss 8.621
2022-03-08 06:13:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 836 @ 40692 updates
2022-03-08 06:13:08 | INFO | fairseq_cli.train | end of epoch 836 (average epoch stats below)
2022-03-08 06:13:08 | INFO | train | epoch 836 | loss 1.704 | ppl 3.26 | wps 22068.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40692 | lr 0.000156764 | gnorm 0.325 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 120804
2022-03-08 06:13:08 | INFO | fairseq.trainer | begin training epoch 837
2022-03-08 06:13:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:13:31 | INFO | train_inner | epoch 837:      8 / 49 loss=1.704, ppl=3.26, wps=21869.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40700, lr=0.000156748, gnorm=0.326, loss_scale=32, train_wall=263, gb_free=21.5, wall=120827
2022-03-08 06:15:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:15:33 | INFO | valid | epoch 837 | valid on 'valid' subset | loss 11.126 | ppl 2234.68 | wps 39337 | wpb 510.9 | bsz 1 | num_updates 40741 | best_loss 8.621
2022-03-08 06:15:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 837 @ 40741 updates
2022-03-08 06:15:33 | INFO | fairseq_cli.train | end of epoch 837 (average epoch stats below)
2022-03-08 06:15:33 | INFO | train | epoch 837 | loss 1.704 | ppl 3.26 | wps 22045.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40741 | lr 0.000156669 | gnorm 0.326 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 120948
2022-03-08 06:15:33 | INFO | fairseq.trainer | begin training epoch 838
2022-03-08 06:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:17:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 06:17:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:17:57 | INFO | valid | epoch 838 | valid on 'valid' subset | loss 11.136 | ppl 2249.85 | wps 39121.9 | wpb 510.9 | bsz 1 | num_updates 40789 | best_loss 8.621
2022-03-08 06:17:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 838 @ 40789 updates
2022-03-08 06:17:57 | INFO | fairseq_cli.train | end of epoch 838 (average epoch stats below)
2022-03-08 06:17:57 | INFO | train | epoch 838 | loss 1.704 | ppl 3.26 | wps 21596.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 40789 | lr 0.000156577 | gnorm 0.328 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 121092
2022-03-08 06:17:57 | INFO | fairseq.trainer | begin training epoch 839
2022-03-08 06:17:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:18:28 | INFO | train_inner | epoch 839:     11 / 49 loss=1.704, ppl=3.26, wps=21855, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40800, lr=0.000156556, gnorm=0.328, loss_scale=32, train_wall=263, gb_free=21.5, wall=121123
2022-03-08 06:20:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:20:21 | INFO | valid | epoch 839 | valid on 'valid' subset | loss 11.136 | ppl 2249.72 | wps 39063.2 | wpb 510.9 | bsz 1 | num_updates 40838 | best_loss 8.621
2022-03-08 06:20:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 839 @ 40838 updates
2022-03-08 06:20:21 | INFO | fairseq_cli.train | end of epoch 839 (average epoch stats below)
2022-03-08 06:20:21 | INFO | train | epoch 839 | loss 1.704 | ppl 3.26 | wps 22086.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40838 | lr 0.000156483 | gnorm 0.332 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 121236
2022-03-08 06:20:21 | INFO | fairseq.trainer | begin training epoch 840
2022-03-08 06:20:21 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 496, in train_step
    optimizer.backward(loss)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/optim/fp16_optimizer.py", line 105, in backward
    loss.backward()
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt
