Sender: LSF System <lsfadmin@eu-g2-10>
Subject: Job 207345754: <w103_size_0.03125_fp16_label_smoothing_0.1_#2> in cluster <euler> Done

Job <w103_size_0.03125_fp16_label_smoothing_0.1_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 13:01:59 2022
Job was executed on host(s) <eu-g2-10>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sun Mar  6 13:02:20 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 13:02:20 2022
Terminated at Tue Mar  8 02:51:59 2022
Results reported at Tue Mar  8 02:51:59 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575622 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   144360.11 sec.
    Max Memory :                                 6799 MB
    Average Memory :                             3261.70 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13201.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   136179 sec.
    Turnaround time :                            136200 sec.

The output (if any) follows:

2022-03-06 13:02:30 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575622, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575622, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 13:02:30 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-06 13:02:32 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-06 13:02:32 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 13:02:32 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 13:02:32 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-06 13:02:32 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-06 13:02:32 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 13:02:32 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-06 13:02:35 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 13:02:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 13:02:35 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-06 13:02:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 13:02:35 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 13:02:35 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 13:02:35 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 13:02:35 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 13:02:35 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 13:02:35 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-06 13:02:35 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 13:02:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:02:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 13:02:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:02:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 13:02:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 13:04:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-06 13:04:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:04:56 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.52 | nll_loss 15.316 | ppl 40797.9 | wps 45273.2 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-06 13:04:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-06 13:04:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:04:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:05:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.52) (writing took 4.305377586744726 seconds)
2022-03-06 13:05:00 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 13:05:00 | INFO | train | epoch 001 | loss 16.595 | nll_loss 16.509 | ppl 93283.9 | wps 23593.4 | ups 0.36 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 4.746 | loss_scale 4 | train_wall 123 | gb_free 8.8 | wall 145
2022-03-06 13:05:00 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 13:05:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:07:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:07:06 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 14.183 | nll_loss 13.828 | ppl 14546.1 | wps 45223.2 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 14.183
2022-03-06 13:07:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-06 13:07:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:07:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:07:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 2 @ 93 updates, score 14.183) (writing took 4.581660658121109 seconds)
2022-03-06 13:07:11 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 13:07:11 | INFO | train | epoch 002 | loss 14.872 | nll_loss 14.597 | ppl 24785.2 | wps 24271.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.021 | loss_scale 4 | train_wall 109 | gb_free 8.8 | wall 276
2022-03-06 13:07:11 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 13:07:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:07:29 | INFO | train_inner | epoch 003:      7 / 49 loss=15.585, nll_loss=15.389, ppl=42913.9, wps=24077.8, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.174, loss_scale=4, train_wall=249, gb_free=8.8, wall=293
2022-03-06 13:09:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:09:18 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.574 | nll_loss 13.159 | ppl 9145.33 | wps 44831.5 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.574
2022-03-06 13:09:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-06 13:09:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:09:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:09:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.574) (writing took 4.488177543040365 seconds)
2022-03-06 13:09:22 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 13:09:22 | INFO | train | epoch 003 | loss 14.005 | nll_loss 13.637 | ppl 12742.1 | wps 24232.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.273 | loss_scale 4 | train_wall 110 | gb_free 8.8 | wall 407
2022-03-06 13:09:22 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 13:09:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:11:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:11:29 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.837 | nll_loss 12.333 | ppl 5159.1 | wps 44508.5 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.837
2022-03-06 13:11:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-06 13:11:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:11:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:11:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.837) (writing took 4.4927186537534 seconds)
2022-03-06 13:11:33 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 13:11:33 | INFO | train | epoch 004 | loss 13.331 | nll_loss 12.89 | ppl 7591.46 | wps 24227.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.11 | loss_scale 8 | train_wall 110 | gb_free 8.8 | wall 538
2022-03-06 13:11:33 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 13:11:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:11:56 | INFO | train_inner | epoch 005:      9 / 49 loss=13.552, nll_loss=13.135, ppl=8994.58, wps=24282.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.16, loss_scale=8, train_wall=224, gb_free=8.8, wall=560
2022-03-06 13:13:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:13:39 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 12.128 | nll_loss 11.527 | ppl 2951.9 | wps 45329.3 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 12.128
2022-03-06 13:13:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-06 13:13:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:13:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:13:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 5 @ 240 updates, score 12.128) (writing took 4.429180696140975 seconds)
2022-03-06 13:13:43 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 13:13:43 | INFO | train | epoch 005 | loss 12.553 | nll_loss 12.014 | ppl 4136.99 | wps 24409.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 0.88 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 668
2022-03-06 13:13:43 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 13:13:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:15:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:15:49 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.568 | nll_loss 10.874 | ppl 1877.36 | wps 45061.5 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 11.568
2022-03-06 13:15:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-06 13:15:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:15:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:15:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 6 @ 289 updates, score 11.568) (writing took 4.542747897095978 seconds)
2022-03-06 13:15:54 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 13:15:54 | INFO | train | epoch 006 | loss 11.881 | nll_loss 11.245 | ppl 2427.36 | wps 24372 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.683 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 799
2022-03-06 13:15:54 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 13:15:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:16:21 | INFO | train_inner | epoch 007:     11 / 49 loss=12.083, nll_loss=11.476, ppl=2848.41, wps=24421.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.745, loss_scale=16, train_wall=222, gb_free=8.8, wall=826
2022-03-06 13:17:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:18:00 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.214 | nll_loss 10.442 | ppl 1391.26 | wps 44277 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 11.214
2022-03-06 13:18:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-06 13:18:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:18:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:18:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 7 @ 338 updates, score 11.214) (writing took 4.59558406798169 seconds)
2022-03-06 13:18:05 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 13:18:05 | INFO | train | epoch 007 | loss 11.386 | nll_loss 10.66 | ppl 1617.88 | wps 24225 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.535 | loss_scale 16 | train_wall 110 | gb_free 8.8 | wall 930
2022-03-06 13:18:05 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 13:18:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:20:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:20:12 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.998 | nll_loss 10.165 | ppl 1148.01 | wps 44499.6 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.998
2022-03-06 13:20:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-06 13:20:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:20:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:20:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.998) (writing took 4.526653845794499 seconds)
2022-03-06 13:20:16 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 13:20:16 | INFO | train | epoch 008 | loss 11.083 | nll_loss 10.285 | ppl 1247.65 | wps 24229.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.45 | loss_scale 16 | train_wall 110 | gb_free 8.8 | wall 1061
2022-03-06 13:20:16 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 13:20:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:20:49 | INFO | train_inner | epoch 009:     13 / 49 loss=11.164, nll_loss=10.385, ppl=1337.32, wps=24261.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.466, loss_scale=16, train_wall=224, gb_free=8.8, wall=1094
2022-03-06 13:22:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:22:23 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.845 | nll_loss 9.969 | ppl 1002.17 | wps 44858.7 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.845
2022-03-06 13:22:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-06 13:22:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:22:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:22:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.845) (writing took 4.53206815989688 seconds)
2022-03-06 13:22:27 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 13:22:27 | INFO | train | epoch 009 | loss 10.889 | nll_loss 10.038 | ppl 1051.59 | wps 24218.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.447 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 1192
2022-03-06 13:22:27 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 13:22:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:24:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:24:34 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.707 | nll_loss 9.805 | ppl 894.51 | wps 44595.6 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 10.707
2022-03-06 13:24:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-06 13:24:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:24:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:24:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 10 @ 485 updates, score 10.707) (writing took 4.481581953819841 seconds)
2022-03-06 13:24:39 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 13:24:39 | INFO | train | epoch 010 | loss 10.73 | nll_loss 9.844 | ppl 919.11 | wps 24231 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.47 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 1323
2022-03-06 13:24:39 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 13:24:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:25:16 | INFO | train_inner | epoch 011:     15 / 49 loss=10.762, nll_loss=9.884, ppl=944.97, wps=24246.2, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.473, loss_scale=32, train_wall=224, gb_free=8.8, wall=1361
2022-03-06 13:26:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:26:45 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.565 | nll_loss 9.639 | ppl 797.26 | wps 45060.7 | wpb 510.9 | bsz 1 | num_updates 534 | best_loss 10.565
2022-03-06 13:26:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 534 updates
2022-03-06 13:26:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:26:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:26:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 11 @ 534 updates, score 10.565) (writing took 4.501081071328372 seconds)
2022-03-06 13:26:50 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 13:26:50 | INFO | train | epoch 011 | loss 10.579 | nll_loss 9.668 | ppl 813.48 | wps 24224.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 534 | lr 6.68367e-05 | gnorm 0.529 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 1454
2022-03-06 13:26:50 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 13:26:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:28:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:28:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:28:57 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.449 | nll_loss 9.502 | ppl 724.93 | wps 45353.4 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 10.449
2022-03-06 13:28:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-06 13:28:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:28:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:29:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 12 @ 582 updates, score 10.449) (writing took 4.4996107392944396 seconds)
2022-03-06 13:29:01 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 13:29:01 | INFO | train | epoch 012 | loss 10.433 | nll_loss 9.499 | ppl 723.7 | wps 23701.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.557 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 1586
2022-03-06 13:29:01 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 13:29:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:29:46 | INFO | train_inner | epoch 013:     18 / 49 loss=10.458, nll_loss=9.528, ppl=738.25, wps=24034.4, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.583, loss_scale=32, train_wall=226, gb_free=8.8, wall=1631
2022-03-06 13:31:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:31:08 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.341 | nll_loss 9.381 | ppl 666.9 | wps 45706.8 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 10.341
2022-03-06 13:31:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-06 13:31:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:31:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:31:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 13 @ 631 updates, score 10.341) (writing took 4.4773244936950505 seconds)
2022-03-06 13:31:12 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 13:31:12 | INFO | train | epoch 013 | loss 10.302 | nll_loss 9.348 | ppl 651.77 | wps 24237.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.683 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 1717
2022-03-06 13:31:12 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 13:31:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:33:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:33:19 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.24 | nll_loss 9.264 | ppl 614.9 | wps 45308 | wpb 510.9 | bsz 1 | num_updates 680 | best_loss 10.24
2022-03-06 13:33:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 680 updates
2022-03-06 13:33:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:33:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:33:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 14 @ 680 updates, score 10.24) (writing took 4.483033860102296 seconds)
2022-03-06 13:33:23 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 13:33:23 | INFO | train | epoch 014 | loss 10.174 | nll_loss 9.201 | ppl 588.44 | wps 24250.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 680 | lr 8.5083e-05 | gnorm 0.695 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 1848
2022-03-06 13:33:23 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 13:33:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:34:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:34:16 | INFO | train_inner | epoch 015:     21 / 49 loss=10.188, nll_loss=9.217, ppl=595.21, wps=24055.2, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.693, loss_scale=32, train_wall=226, gb_free=8.8, wall=1901
2022-03-06 13:35:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:35:30 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.137 | nll_loss 9.143 | ppl 565.16 | wps 45357.1 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 10.137
2022-03-06 13:35:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-06 13:35:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:35:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:35:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 15 @ 728 updates, score 10.137) (writing took 4.499661287758499 seconds)
2022-03-06 13:35:34 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 13:35:34 | INFO | train | epoch 015 | loss 10.051 | nll_loss 9.059 | ppl 533.19 | wps 23737 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.677 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 1979
2022-03-06 13:35:34 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 13:35:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:37:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:37:41 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.046 | nll_loss 9.032 | ppl 523.62 | wps 45434.5 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 10.046
2022-03-06 13:37:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-06 13:37:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:37:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:37:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 16 @ 777 updates, score 10.046) (writing took 4.484287369996309 seconds)
2022-03-06 13:37:45 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 13:37:45 | INFO | train | epoch 016 | loss 9.935 | nll_loss 8.925 | ppl 486.04 | wps 24246.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.781 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 2110
2022-03-06 13:37:45 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 13:37:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:38:43 | INFO | train_inner | epoch 017:     23 / 49 loss=9.94, nll_loss=8.931, ppl=488.03, wps=24263.8, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.743, loss_scale=32, train_wall=224, gb_free=8.8, wall=2168
2022-03-06 13:39:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:39:52 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.958 | nll_loss 8.932 | ppl 488.33 | wps 45512.1 | wpb 510.9 | bsz 1 | num_updates 826 | best_loss 9.958
2022-03-06 13:39:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 826 updates
2022-03-06 13:39:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:39:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:39:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 17 @ 826 updates, score 9.958) (writing took 4.489558830857277 seconds)
2022-03-06 13:39:57 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 13:39:57 | INFO | train | epoch 017 | loss 9.82 | nll_loss 8.791 | ppl 442.94 | wps 24217 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 826 | lr 0.000103329 | gnorm 0.794 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 2241
2022-03-06 13:39:57 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 13:39:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:40:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:41:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:42:03 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.874 | nll_loss 8.834 | ppl 456.24 | wps 45583.1 | wpb 510.9 | bsz 1 | num_updates 874 | best_loss 9.874
2022-03-06 13:42:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 874 updates
2022-03-06 13:42:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:42:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:42:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 18 @ 874 updates, score 9.874) (writing took 4.469253520015627 seconds)
2022-03-06 13:42:08 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 13:42:08 | INFO | train | epoch 018 | loss 9.709 | nll_loss 8.663 | ppl 405.26 | wps 23741.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 874 | lr 0.000109328 | gnorm 0.79 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 2373
2022-03-06 13:42:08 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 13:42:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:43:13 | INFO | train_inner | epoch 019:     26 / 49 loss=9.709, nll_loss=8.663, ppl=405.25, wps=24048.6, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.797, loss_scale=32, train_wall=226, gb_free=8.8, wall=2438
2022-03-06 13:44:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:44:14 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.797 | nll_loss 8.743 | ppl 428.48 | wps 45211 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 9.797
2022-03-06 13:44:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-06 13:44:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:44:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:44:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 19 @ 923 updates, score 9.797) (writing took 4.493416108656675 seconds)
2022-03-06 13:44:19 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 13:44:19 | INFO | train | epoch 019 | loss 9.606 | nll_loss 8.543 | ppl 373.03 | wps 24234.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.886 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 2504
2022-03-06 13:44:19 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 13:44:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:46:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:46:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:46:25 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.736 | nll_loss 8.665 | ppl 406.04 | wps 45305 | wpb 510.9 | bsz 1 | num_updates 971 | best_loss 9.736
2022-03-06 13:46:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 971 updates
2022-03-06 13:46:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:46:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:46:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 20 @ 971 updates, score 9.736) (writing took 4.473976492881775 seconds)
2022-03-06 13:46:30 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 13:46:30 | INFO | train | epoch 020 | loss 9.503 | nll_loss 8.424 | ppl 343.44 | wps 23743.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 971 | lr 0.000121451 | gnorm 0.814 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 2635
2022-03-06 13:46:30 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 13:46:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:47:43 | INFO | train_inner | epoch 021:     29 / 49 loss=9.497, nll_loss=8.417, ppl=341.8, wps=24050.2, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.842, loss_scale=32, train_wall=226, gb_free=8.8, wall=2708
2022-03-06 13:48:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:48:37 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.686 | nll_loss 8.608 | ppl 390.19 | wps 45237.4 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 9.686
2022-03-06 13:48:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-06 13:48:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:48:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:48:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 21 @ 1020 updates, score 9.686) (writing took 4.506682940758765 seconds)
2022-03-06 13:48:41 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 13:48:41 | INFO | train | epoch 021 | loss 9.404 | nll_loss 8.309 | ppl 317.13 | wps 24238.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.825 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 2766
2022-03-06 13:48:41 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 13:48:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:50:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:50:48 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.623 | nll_loss 8.532 | ppl 370.19 | wps 45518.6 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 9.623
2022-03-06 13:50:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-06 13:50:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:50:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:50:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 22 @ 1069 updates, score 9.623) (writing took 4.490870229899883 seconds)
2022-03-06 13:50:52 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 13:50:52 | INFO | train | epoch 022 | loss 9.311 | nll_loss 8.2 | ppl 294.08 | wps 24220.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.898 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 2897
2022-03-06 13:50:52 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 13:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:52:10 | INFO | train_inner | epoch 023:     31 / 49 loss=9.297, nll_loss=8.184, ppl=290.86, wps=24266.6, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.87, loss_scale=64, train_wall=224, gb_free=8.8, wall=2975
2022-03-06 13:52:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:52:59 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.574 | nll_loss 8.478 | ppl 356.45 | wps 45266.2 | wpb 510.9 | bsz 1 | num_updates 1118 | best_loss 9.574
2022-03-06 13:52:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1118 updates
2022-03-06 13:52:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:53:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:53:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 23 @ 1118 updates, score 9.574) (writing took 4.480302020907402 seconds)
2022-03-06 13:53:03 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 13:53:03 | INFO | train | epoch 023 | loss 9.216 | nll_loss 8.09 | ppl 272.44 | wps 24233.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 1118 | lr 0.000139822 | gnorm 0.85 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 3028
2022-03-06 13:53:03 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 13:53:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:53:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:55:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:55:10 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.525 | nll_loss 8.415 | ppl 341.33 | wps 45358.1 | wpb 510.9 | bsz 1 | num_updates 1166 | best_loss 9.525
2022-03-06 13:55:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1166 updates
2022-03-06 13:55:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:55:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:55:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 24 @ 1166 updates, score 9.525) (writing took 4.4890823238529265 seconds)
2022-03-06 13:55:15 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 13:55:15 | INFO | train | epoch 024 | loss 9.127 | nll_loss 7.986 | ppl 253.53 | wps 23730.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 1166 | lr 0.000145821 | gnorm 0.864 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 3159
2022-03-06 13:55:15 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 13:55:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:56:40 | INFO | train_inner | epoch 025:     34 / 49 loss=9.113, nll_loss=7.971, ppl=250.85, wps=24036.8, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.885, loss_scale=32, train_wall=226, gb_free=8.8, wall=3245
2022-03-06 13:57:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:57:21 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.475 | nll_loss 8.352 | ppl 326.84 | wps 45443.3 | wpb 510.9 | bsz 1 | num_updates 1215 | best_loss 9.475
2022-03-06 13:57:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1215 updates
2022-03-06 13:57:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:57:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:57:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 25 @ 1215 updates, score 9.475) (writing took 4.5040434380061924 seconds)
2022-03-06 13:57:26 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 13:57:26 | INFO | train | epoch 025 | loss 9.039 | nll_loss 7.884 | ppl 236.18 | wps 24228.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 1215 | lr 0.000151945 | gnorm 0.889 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 3291
2022-03-06 13:57:26 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 13:57:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:59:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:59:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:59:32 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.432 | nll_loss 8.303 | ppl 315.82 | wps 44927.6 | wpb 510.9 | bsz 1 | num_updates 1263 | best_loss 9.432
2022-03-06 13:59:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1263 updates
2022-03-06 13:59:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:59:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:59:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 26 @ 1263 updates, score 9.432) (writing took 4.504457643721253 seconds)
2022-03-06 13:59:37 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 13:59:37 | INFO | train | epoch 026 | loss 8.951 | nll_loss 7.782 | ppl 220.06 | wps 23722.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 1263 | lr 0.000157943 | gnorm 0.893 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 3422
2022-03-06 13:59:37 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 13:59:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:01:10 | INFO | train_inner | epoch 027:     37 / 49 loss=8.93, nll_loss=7.758, ppl=216.41, wps=24037.6, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=0.867, loss_scale=32, train_wall=226, gb_free=8.8, wall=3515
2022-03-06 14:01:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:01:44 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.394 | nll_loss 8.256 | ppl 305.67 | wps 45518.3 | wpb 510.9 | bsz 1 | num_updates 1312 | best_loss 9.394
2022-03-06 14:01:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1312 updates
2022-03-06 14:01:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:01:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:01:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 27 @ 1312 updates, score 9.394) (writing took 4.519171622116119 seconds)
2022-03-06 14:01:48 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 14:01:48 | INFO | train | epoch 027 | loss 8.861 | nll_loss 7.678 | ppl 204.72 | wps 24233.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 1312 | lr 0.000164067 | gnorm 0.846 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 3553
2022-03-06 14:01:48 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 14:01:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:01:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 14:03:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:03:55 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.343 | nll_loss 8.19 | ppl 291.95 | wps 45384.6 | wpb 510.9 | bsz 1 | num_updates 1360 | best_loss 9.343
2022-03-06 14:03:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1360 updates
2022-03-06 14:03:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:03:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:03:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 28 @ 1360 updates, score 9.343) (writing took 4.507826420944184 seconds)
2022-03-06 14:03:59 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 14:03:59 | INFO | train | epoch 028 | loss 8.776 | nll_loss 7.578 | ppl 191.13 | wps 23727.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 1360 | lr 0.000170066 | gnorm 0.936 | loss_scale 16 | train_wall 110 | gb_free 8.8 | wall 3684
2022-03-06 14:03:59 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 14:03:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:05:40 | INFO | train_inner | epoch 029:     40 / 49 loss=8.749, nll_loss=7.547, ppl=187.03, wps=24027.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=0.905, loss_scale=16, train_wall=226, gb_free=8.8, wall=3785
2022-03-06 14:06:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:06:06 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.32 | nll_loss 8.146 | ppl 283.22 | wps 45410.8 | wpb 510.9 | bsz 1 | num_updates 1409 | best_loss 9.32
2022-03-06 14:06:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1409 updates
2022-03-06 14:06:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:06:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:06:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 29 @ 1409 updates, score 9.32) (writing took 4.497281802818179 seconds)
2022-03-06 14:06:11 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 14:06:11 | INFO | train | epoch 029 | loss 8.687 | nll_loss 7.475 | ppl 177.92 | wps 24210.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 1409 | lr 0.00017619 | gnorm 0.886 | loss_scale 16 | train_wall 110 | gb_free 8.8 | wall 3815
2022-03-06 14:06:11 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 14:06:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:08:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:08:17 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.281 | nll_loss 8.105 | ppl 275.35 | wps 45476.3 | wpb 510.9 | bsz 1 | num_updates 1458 | best_loss 9.281
2022-03-06 14:08:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1458 updates
2022-03-06 14:08:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:08:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:08:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 30 @ 1458 updates, score 9.281) (writing took 4.52675962401554 seconds)
2022-03-06 14:08:22 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 14:08:22 | INFO | train | epoch 030 | loss 8.599 | nll_loss 7.372 | ppl 165.7 | wps 24234 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 1458 | lr 0.000182314 | gnorm 0.903 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 3946
2022-03-06 14:08:22 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 14:08:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:10:07 | INFO | train_inner | epoch 031:     42 / 49 loss=8.568, nll_loss=7.336, ppl=161.57, wps=24269.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=0.903, loss_scale=32, train_wall=224, gb_free=8.8, wall=4052
2022-03-06 14:10:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:10:28 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.262 | nll_loss 8.077 | ppl 270.02 | wps 45245.8 | wpb 510.9 | bsz 1 | num_updates 1507 | best_loss 9.262
2022-03-06 14:10:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1507 updates
2022-03-06 14:10:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:10:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:10:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 31 @ 1507 updates, score 9.262) (writing took 4.4787465133704245 seconds)
2022-03-06 14:10:33 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 14:10:33 | INFO | train | epoch 031 | loss 8.509 | nll_loss 7.268 | ppl 154.16 | wps 24230 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 1507 | lr 0.000188437 | gnorm 0.911 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 4078
2022-03-06 14:10:33 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 14:10:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:12:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:12:39 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.235 | nll_loss 8.052 | ppl 265.4 | wps 45582.5 | wpb 510.9 | bsz 1 | num_updates 1556 | best_loss 9.235
2022-03-06 14:12:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1556 updates
2022-03-06 14:12:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:12:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:12:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 32 @ 1556 updates, score 9.235) (writing took 4.477175646927208 seconds)
2022-03-06 14:12:44 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 14:12:44 | INFO | train | epoch 032 | loss 8.421 | nll_loss 7.165 | ppl 143.53 | wps 24255.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 1556 | lr 0.000194561 | gnorm 0.895 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 4209
2022-03-06 14:12:44 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 14:12:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:14:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:14:37 | INFO | train_inner | epoch 033:     45 / 49 loss=8.388, nll_loss=7.127, ppl=139.74, wps=24052.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=0.909, loss_scale=32, train_wall=226, gb_free=8.8, wall=4322
2022-03-06 14:14:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:14:50 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.214 | nll_loss 8.017 | ppl 259 | wps 45480.2 | wpb 510.9 | bsz 1 | num_updates 1604 | best_loss 9.214
2022-03-06 14:14:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1604 updates
2022-03-06 14:14:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:14:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:14:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 33 @ 1604 updates, score 9.214) (writing took 4.511304755695164 seconds)
2022-03-06 14:14:55 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 14:14:55 | INFO | train | epoch 033 | loss 8.334 | nll_loss 7.064 | ppl 133.78 | wps 23739.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 1604 | lr 0.00020056 | gnorm 0.919 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 4340
2022-03-06 14:14:55 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 14:14:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:16:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:17:02 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.201 | nll_loss 8.001 | ppl 256.25 | wps 45470.1 | wpb 510.9 | bsz 1 | num_updates 1653 | best_loss 9.201
2022-03-06 14:17:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1653 updates
2022-03-06 14:17:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:17:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:17:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 34 @ 1653 updates, score 9.201) (writing took 4.497198609635234 seconds)
2022-03-06 14:17:06 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 14:17:06 | INFO | train | epoch 034 | loss 8.248 | nll_loss 6.964 | ppl 124.81 | wps 24218.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 1653 | lr 0.000206684 | gnorm 0.905 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 4471
2022-03-06 14:17:06 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 14:17:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:19:04 | INFO | train_inner | epoch 035:     47 / 49 loss=8.211, nll_loss=6.92, ppl=121.13, wps=24255.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=0.923, loss_scale=32, train_wall=224, gb_free=8.8, wall=4589
2022-03-06 14:19:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:19:13 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.202 | nll_loss 7.98 | ppl 252.45 | wps 45188.8 | wpb 510.9 | bsz 1 | num_updates 1702 | best_loss 9.201
2022-03-06 14:19:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1702 updates
2022-03-06 14:19:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:19:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:19:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 35 @ 1702 updates, score 9.202) (writing took 2.346268444787711 seconds)
2022-03-06 14:19:15 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 14:19:15 | INFO | train | epoch 035 | loss 8.163 | nll_loss 6.864 | ppl 116.51 | wps 24621.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1702 | lr 0.000212807 | gnorm 0.96 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 4600
2022-03-06 14:19:15 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 14:19:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:20:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:21:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:21:22 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.183 | nll_loss 7.98 | ppl 252.45 | wps 45388.9 | wpb 510.9 | bsz 1 | num_updates 1750 | best_loss 9.183
2022-03-06 14:21:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1750 updates
2022-03-06 14:21:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:21:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:21:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 36 @ 1750 updates, score 9.183) (writing took 4.429205362685025 seconds)
2022-03-06 14:21:26 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 14:21:26 | INFO | train | epoch 036 | loss 8.077 | nll_loss 6.764 | ppl 108.68 | wps 23739.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 1750 | lr 0.000218806 | gnorm 0.938 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 4731
2022-03-06 14:21:26 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 14:21:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:23:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:23:33 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.157 | nll_loss 7.934 | ppl 244.51 | wps 45419.1 | wpb 510.9 | bsz 1 | num_updates 1799 | best_loss 9.157
2022-03-06 14:23:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1799 updates
2022-03-06 14:23:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:23:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:23:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 37 @ 1799 updates, score 9.157) (writing took 4.424651722889394 seconds)
2022-03-06 14:23:38 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 14:23:38 | INFO | train | epoch 037 | loss 7.994 | nll_loss 6.668 | ppl 101.67 | wps 24225.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 1799 | lr 0.00022493 | gnorm 0.951 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 4862
2022-03-06 14:23:38 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 14:23:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:23:40 | INFO | train_inner | epoch 038:      1 / 49 loss=8.035, nll_loss=6.715, ppl=105.09, wps=23392.6, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=0.953, loss_scale=32, train_wall=225, gb_free=8.8, wall=4865
2022-03-06 14:25:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:25:44 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.172 | nll_loss 7.947 | ppl 246.69 | wps 45537.4 | wpb 510.9 | bsz 1 | num_updates 1848 | best_loss 9.157
2022-03-06 14:25:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1848 updates
2022-03-06 14:25:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:25:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:25:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 38 @ 1848 updates, score 9.172) (writing took 2.4501766529865563 seconds)
2022-03-06 14:25:47 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 14:25:47 | INFO | train | epoch 038 | loss 7.91 | nll_loss 6.57 | ppl 95 | wps 24603.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1848 | lr 0.000231054 | gnorm 0.993 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 4992
2022-03-06 14:25:47 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 14:25:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:25:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:27:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:27:53 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.163 | nll_loss 7.939 | ppl 245.42 | wps 45543 | wpb 510.9 | bsz 1 | num_updates 1896 | best_loss 9.157
2022-03-06 14:27:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1896 updates
2022-03-06 14:27:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:27:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:27:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 39 @ 1896 updates, score 9.163) (writing took 2.395679275970906 seconds)
2022-03-06 14:27:56 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 14:27:56 | INFO | train | epoch 039 | loss 7.83 | nll_loss 6.476 | ppl 89.04 | wps 24125.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 1896 | lr 0.000237053 | gnorm 1.013 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 5121
2022-03-06 14:27:56 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 14:27:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:28:06 | INFO | train_inner | epoch 040:      4 / 49 loss=7.865, nll_loss=6.517, ppl=91.56, wps=24412.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=0.998, loss_scale=32, train_wall=226, gb_free=8.8, wall=5131
2022-03-06 14:29:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:30:02 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.173 | nll_loss 7.964 | ppl 249.71 | wps 45428.9 | wpb 510.9 | bsz 1 | num_updates 1945 | best_loss 9.157
2022-03-06 14:30:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1945 updates
2022-03-06 14:30:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:30:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:30:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 40 @ 1945 updates, score 9.173) (writing took 2.4040044751018286 seconds)
2022-03-06 14:30:05 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 14:30:05 | INFO | train | epoch 040 | loss 7.746 | nll_loss 6.377 | ppl 83.11 | wps 24630.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1945 | lr 0.000243176 | gnorm 0.962 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 5250
2022-03-06 14:30:05 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 14:30:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:31:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:32:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:32:11 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.179 | nll_loss 7.937 | ppl 245.08 | wps 45553.7 | wpb 510.9 | bsz 1 | num_updates 1993 | best_loss 9.157
2022-03-06 14:32:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1993 updates
2022-03-06 14:32:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:32:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:32:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 41 @ 1993 updates, score 9.179) (writing took 2.3609181009233 seconds)
2022-03-06 14:32:14 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 14:32:14 | INFO | train | epoch 041 | loss 7.663 | nll_loss 6.281 | ppl 77.76 | wps 24133 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 1993 | lr 0.000249175 | gnorm 0.978 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 5379
2022-03-06 14:32:14 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 14:32:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:32:31 | INFO | train_inner | epoch 042:      7 / 49 loss=7.695, nll_loss=6.319, ppl=79.81, wps=24433.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=0.991, loss_scale=32, train_wall=226, gb_free=8.8, wall=5396
2022-03-06 14:34:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:34:20 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.239 | nll_loss 8.025 | ppl 260.52 | wps 45316.3 | wpb 510.9 | bsz 1 | num_updates 2042 | best_loss 9.157
2022-03-06 14:34:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2042 updates
2022-03-06 14:34:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:34:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:34:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 42 @ 2042 updates, score 9.239) (writing took 2.4390901592560112 seconds)
2022-03-06 14:34:23 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 14:34:23 | INFO | train | epoch 042 | loss 7.587 | nll_loss 6.191 | ppl 73.07 | wps 24612.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2042 | lr 0.000255299 | gnorm 1.042 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 5508
2022-03-06 14:34:23 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 14:34:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:36:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:36:29 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.244 | nll_loss 8.015 | ppl 258.71 | wps 46034.8 | wpb 510.9 | bsz 1 | num_updates 2091 | best_loss 9.157
2022-03-06 14:36:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2091 updates
2022-03-06 14:36:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:36:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:36:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 43 @ 2091 updates, score 9.244) (writing took 2.2860264889895916 seconds)
2022-03-06 14:36:32 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 14:36:32 | INFO | train | epoch 043 | loss 7.508 | nll_loss 6.098 | ppl 68.52 | wps 24671.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2091 | lr 0.000261423 | gnorm 1.066 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 5636
2022-03-06 14:36:32 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 14:36:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:36:54 | INFO | train_inner | epoch 044:      9 / 49 loss=7.532, nll_loss=6.128, ppl=69.91, wps=24692.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.027, loss_scale=32, train_wall=224, gb_free=8.8, wall=5659
2022-03-06 14:37:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:38:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:38:37 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.29 | nll_loss 8.076 | ppl 269.89 | wps 46936.7 | wpb 510.9 | bsz 1 | num_updates 2139 | best_loss 9.157
2022-03-06 14:38:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2139 updates
2022-03-06 14:38:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:38:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:38:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 44 @ 2139 updates, score 9.29) (writing took 2.253088667988777 seconds)
2022-03-06 14:38:39 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 14:38:39 | INFO | train | epoch 044 | loss 7.422 | nll_loss 5.999 | ppl 63.96 | wps 24377.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2139 | lr 0.000267422 | gnorm 1.007 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 5764
2022-03-06 14:38:39 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 14:38:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:40:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:40:45 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.307 | nll_loss 8.088 | ppl 272.12 | wps 46036.4 | wpb 510.9 | bsz 1 | num_updates 2188 | best_loss 9.157
2022-03-06 14:40:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2188 updates
2022-03-06 14:40:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:40:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:40:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 45 @ 2188 updates, score 9.307) (writing took 2.255819461774081 seconds)
2022-03-06 14:40:47 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 14:40:47 | INFO | train | epoch 045 | loss 7.353 | nll_loss 5.917 | ppl 60.42 | wps 24894 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2188 | lr 0.000273545 | gnorm 1.096 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 5892
2022-03-06 14:40:47 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 14:40:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:41:17 | INFO | train_inner | epoch 046:     12 / 49 loss=7.368, nll_loss=5.935, ppl=61.18, wps=24680.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.053, loss_scale=32, train_wall=224, gb_free=8.8, wall=5922
2022-03-06 14:41:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 14:42:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:42:53 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.363 | nll_loss 8.128 | ppl 279.8 | wps 44355.5 | wpb 510.9 | bsz 1 | num_updates 2236 | best_loss 9.157
2022-03-06 14:42:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2236 updates
2022-03-06 14:42:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:42:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:42:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 46 @ 2236 updates, score 9.363) (writing took 2.3131967089138925 seconds)
2022-03-06 14:42:55 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 14:42:55 | INFO | train | epoch 046 | loss 7.267 | nll_loss 5.816 | ppl 56.35 | wps 24354 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2236 | lr 0.000279544 | gnorm 1.033 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 6020
2022-03-06 14:42:55 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 14:42:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:44:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:45:00 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.367 | nll_loss 8.148 | ppl 283.57 | wps 47021.5 | wpb 510.9 | bsz 1 | num_updates 2285 | best_loss 9.157
2022-03-06 14:45:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2285 updates
2022-03-06 14:45:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:45:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:45:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 47 @ 2285 updates, score 9.367) (writing took 2.2530156690627337 seconds)
2022-03-06 14:45:02 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 14:45:02 | INFO | train | epoch 047 | loss 7.192 | nll_loss 5.729 | ppl 53.03 | wps 24917.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2285 | lr 0.000285668 | gnorm 1.102 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 6147
2022-03-06 14:45:02 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 14:45:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:45:40 | INFO | train_inner | epoch 048:     15 / 49 loss=7.206, nll_loss=5.745, ppl=53.64, wps=24672.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.079, loss_scale=16, train_wall=224, gb_free=8.8, wall=6185
2022-03-06 14:47:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:47:08 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.405 | nll_loss 8.2 | ppl 294 | wps 47104.7 | wpb 510.9 | bsz 1 | num_updates 2334 | best_loss 9.157
2022-03-06 14:47:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2334 updates
2022-03-06 14:47:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:47:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:47:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 48 @ 2334 updates, score 9.405) (writing took 2.2299636118113995 seconds)
2022-03-06 14:47:10 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 14:47:10 | INFO | train | epoch 048 | loss 7.114 | nll_loss 5.636 | ppl 49.74 | wps 24909 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2334 | lr 0.000291792 | gnorm 1.126 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 6275
2022-03-06 14:47:10 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 14:47:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:48:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 14:49:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:49:15 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.472 | nll_loss 8.248 | ppl 304.09 | wps 47694.7 | wpb 510.9 | bsz 1 | num_updates 2382 | best_loss 9.157
2022-03-06 14:49:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2382 updates
2022-03-06 14:49:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:49:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:49:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 49 @ 2382 updates, score 9.472) (writing took 2.2301051220856607 seconds)
2022-03-06 14:49:17 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 14:49:17 | INFO | train | epoch 049 | loss 7.035 | nll_loss 5.544 | ppl 46.66 | wps 24438.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2382 | lr 0.00029779 | gnorm 1.09 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 6402
2022-03-06 14:49:17 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 14:49:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:50:02 | INFO | train_inner | epoch 050:     18 / 49 loss=7.047, nll_loss=5.559, ppl=47.13, wps=24745.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.099, loss_scale=16, train_wall=224, gb_free=8.8, wall=6447
2022-03-06 14:51:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:51:22 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.479 | nll_loss 8.272 | ppl 309.16 | wps 47955.3 | wpb 510.9 | bsz 1 | num_updates 2431 | best_loss 9.157
2022-03-06 14:51:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2431 updates
2022-03-06 14:51:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:51:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:51:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 50 @ 2431 updates, score 9.479) (writing took 2.252608709037304 seconds)
2022-03-06 14:51:24 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 14:51:24 | INFO | train | epoch 050 | loss 6.96 | nll_loss 5.456 | ppl 43.89 | wps 25088.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2431 | lr 0.000303914 | gnorm 1.112 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 6529
2022-03-06 14:51:24 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 14:51:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:53:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:53:28 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.529 | nll_loss 8.315 | ppl 318.41 | wps 47814.7 | wpb 510.9 | bsz 1 | num_updates 2480 | best_loss 9.157
2022-03-06 14:53:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2480 updates
2022-03-06 14:53:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:53:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:53:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 51 @ 2480 updates, score 9.529) (writing took 2.3739829109981656 seconds)
2022-03-06 14:53:31 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 14:53:31 | INFO | train | epoch 051 | loss 6.881 | nll_loss 5.363 | ppl 41.15 | wps 25082.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2480 | lr 0.000310038 | gnorm 1.108 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 6656
2022-03-06 14:53:31 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 14:53:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:54:21 | INFO | train_inner | epoch 052:     20 / 49 loss=6.891, nll_loss=5.375, ppl=41.49, wps=25104.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.133, loss_scale=32, train_wall=220, gb_free=8.8, wall=6705
2022-03-06 14:55:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:55:36 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.56 | nll_loss 8.336 | ppl 323.06 | wps 47274.2 | wpb 510.9 | bsz 1 | num_updates 2529 | best_loss 9.157
2022-03-06 14:55:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2529 updates
2022-03-06 14:55:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:55:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:55:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 52 @ 2529 updates, score 9.56) (writing took 2.2098141880705953 seconds)
2022-03-06 14:55:38 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 14:55:38 | INFO | train | epoch 052 | loss 6.805 | nll_loss 5.273 | ppl 38.68 | wps 24971.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2529 | lr 0.000316162 | gnorm 1.162 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 6783
2022-03-06 14:55:38 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 14:55:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:56:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 14:57:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:57:43 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.576 | nll_loss 8.352 | ppl 326.63 | wps 46777.3 | wpb 510.9 | bsz 1 | num_updates 2577 | best_loss 9.157
2022-03-06 14:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2577 updates
2022-03-06 14:57:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:57:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:57:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 53 @ 2577 updates, score 9.576) (writing took 2.264764450956136 seconds)
2022-03-06 14:57:46 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 14:57:46 | INFO | train | epoch 053 | loss 6.729 | nll_loss 5.184 | ppl 36.36 | wps 24383.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2577 | lr 0.000322161 | gnorm 1.145 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 6910
2022-03-06 14:57:46 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 14:57:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:58:43 | INFO | train_inner | epoch 054:     23 / 49 loss=6.735, nll_loss=5.19, ppl=36.51, wps=24732.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.183, loss_scale=16, train_wall=224, gb_free=8.8, wall=6968
2022-03-06 14:59:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:59:51 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.618 | nll_loss 8.388 | ppl 334.96 | wps 47045.9 | wpb 510.9 | bsz 1 | num_updates 2626 | best_loss 9.157
2022-03-06 14:59:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2626 updates
2022-03-06 14:59:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:59:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 14:59:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 54 @ 2626 updates, score 9.618) (writing took 2.2600565389730036 seconds)
2022-03-06 14:59:53 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 14:59:53 | INFO | train | epoch 054 | loss 6.66 | nll_loss 5.102 | ppl 34.33 | wps 24918.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2626 | lr 0.000328284 | gnorm 1.227 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 7038
2022-03-06 14:59:53 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 14:59:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:01:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:01:59 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.709 | nll_loss 8.517 | ppl 366.38 | wps 46784.3 | wpb 510.9 | bsz 1 | num_updates 2675 | best_loss 9.157
2022-03-06 15:01:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2675 updates
2022-03-06 15:01:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:02:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:02:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 55 @ 2675 updates, score 9.709) (writing took 2.249468475114554 seconds)
2022-03-06 15:02:01 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 15:02:01 | INFO | train | epoch 055 | loss 6.581 | nll_loss 5.009 | ppl 32.2 | wps 24914.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2675 | lr 0.000334408 | gnorm 1.229 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 7166
2022-03-06 15:02:01 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 15:02:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:03:03 | INFO | train_inner | epoch 056:     25 / 49 loss=6.582, nll_loss=5.01, ppl=32.23, wps=24935.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.181, loss_scale=32, train_wall=222, gb_free=8.8, wall=7228
2022-03-06 15:03:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:04:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:04:06 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.721 | nll_loss 8.501 | ppl 362.19 | wps 46735.3 | wpb 510.9 | bsz 1 | num_updates 2723 | best_loss 9.157
2022-03-06 15:04:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2723 updates
2022-03-06 15:04:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:04:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:04:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 56 @ 2723 updates, score 9.721) (writing took 2.433305745013058 seconds)
2022-03-06 15:04:09 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 15:04:09 | INFO | train | epoch 056 | loss 6.513 | nll_loss 4.928 | ppl 30.45 | wps 24333 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2723 | lr 0.000340407 | gnorm 1.284 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 7293
2022-03-06 15:04:09 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 15:04:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:06:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:06:14 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.808 | nll_loss 8.582 | ppl 383.3 | wps 46693.2 | wpb 510.9 | bsz 1 | num_updates 2772 | best_loss 9.157
2022-03-06 15:06:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2772 updates
2022-03-06 15:06:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:06:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:06:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 57 @ 2772 updates, score 9.808) (writing took 2.4004407138563693 seconds)
2022-03-06 15:06:17 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 15:06:17 | INFO | train | epoch 057 | loss 6.43 | nll_loss 4.83 | ppl 28.44 | wps 24847.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2772 | lr 0.000346531 | gnorm 1.128 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 7421
2022-03-06 15:06:17 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 15:06:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:07:27 | INFO | train_inner | epoch 058:     28 / 49 loss=6.427, nll_loss=4.826, ppl=28.37, wps=24612.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.236, loss_scale=16, train_wall=225, gb_free=8.8, wall=7491
2022-03-06 15:08:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:08:23 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.847 | nll_loss 8.641 | ppl 399.21 | wps 45478.4 | wpb 510.9 | bsz 1 | num_updates 2821 | best_loss 9.157
2022-03-06 15:08:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2821 updates
2022-03-06 15:08:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:08:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:08:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 58 @ 2821 updates, score 9.847) (writing took 2.4072096250019968 seconds)
2022-03-06 15:08:25 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 15:08:25 | INFO | train | epoch 058 | loss 6.353 | nll_loss 4.74 | ppl 26.72 | wps 24738.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2821 | lr 0.000352654 | gnorm 1.206 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 7550
2022-03-06 15:08:25 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 15:08:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:10:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:10:31 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.868 | nll_loss 8.656 | ppl 403.36 | wps 46318.9 | wpb 510.9 | bsz 1 | num_updates 2870 | best_loss 9.157
2022-03-06 15:10:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2870 updates
2022-03-06 15:10:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:10:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:10:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 59 @ 2870 updates, score 9.868) (writing took 2.3767560962587595 seconds)
2022-03-06 15:10:33 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 15:10:33 | INFO | train | epoch 059 | loss 6.283 | nll_loss 4.656 | ppl 25.21 | wps 24756.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2870 | lr 0.000358778 | gnorm 1.268 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 7678
2022-03-06 15:10:33 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 15:10:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:11:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:11:51 | INFO | train_inner | epoch 060:     31 / 49 loss=6.275, nll_loss=4.646, ppl=25.04, wps=24541.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.253, loss_scale=16, train_wall=225, gb_free=8.8, wall=7756
2022-03-06 15:12:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:12:39 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.961 | nll_loss 8.731 | ppl 425.01 | wps 46531.9 | wpb 510.9 | bsz 1 | num_updates 2918 | best_loss 9.157
2022-03-06 15:12:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2918 updates
2022-03-06 15:12:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:12:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:12:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 60 @ 2918 updates, score 9.961) (writing took 2.383839099202305 seconds)
2022-03-06 15:12:42 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 15:12:42 | INFO | train | epoch 060 | loss 6.204 | nll_loss 4.564 | ppl 23.65 | wps 24263.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 2918 | lr 0.000364777 | gnorm 1.224 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 7806
2022-03-06 15:12:42 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 15:12:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:14:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:14:48 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 10.022 | nll_loss 8.814 | ppl 449.99 | wps 44988.3 | wpb 510.9 | bsz 1 | num_updates 2967 | best_loss 9.157
2022-03-06 15:14:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2967 updates
2022-03-06 15:14:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:14:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:14:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 61 @ 2967 updates, score 10.022) (writing took 2.393775953911245 seconds)
2022-03-06 15:14:50 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 15:14:50 | INFO | train | epoch 061 | loss 6.14 | nll_loss 4.486 | ppl 22.42 | wps 24741.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2967 | lr 0.000370901 | gnorm 1.297 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 7935
2022-03-06 15:14:50 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 15:14:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:16:13 | INFO | train_inner | epoch 062:     33 / 49 loss=6.126, nll_loss=4.47, ppl=22.16, wps=24785.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.291, loss_scale=16, train_wall=223, gb_free=8.8, wall=8017
2022-03-06 15:16:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:16:56 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 10.09 | nll_loss 8.872 | ppl 468.63 | wps 46642.6 | wpb 510.9 | bsz 1 | num_updates 3016 | best_loss 9.157
2022-03-06 15:16:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3016 updates
2022-03-06 15:16:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:16:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:16:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 62 @ 3016 updates, score 10.09) (writing took 2.3272033305838704 seconds)
2022-03-06 15:16:58 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 15:16:58 | INFO | train | epoch 062 | loss 6.066 | nll_loss 4.398 | ppl 21.09 | wps 24778.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3016 | lr 0.000377025 | gnorm 1.303 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 8063
2022-03-06 15:16:58 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 15:16:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:17:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:19:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:19:05 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 10.122 | nll_loss 8.914 | ppl 482.49 | wps 45823.9 | wpb 510.9 | bsz 1 | num_updates 3064 | best_loss 9.157
2022-03-06 15:19:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3064 updates
2022-03-06 15:19:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:19:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:19:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 63 @ 3064 updates, score 10.122) (writing took 2.3855508216656744 seconds)
2022-03-06 15:19:07 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 15:19:07 | INFO | train | epoch 063 | loss 5.994 | nll_loss 4.312 | ppl 19.86 | wps 24209.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 3064 | lr 0.000383023 | gnorm 1.329 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 8192
2022-03-06 15:19:07 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 15:19:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:20:37 | INFO | train_inner | epoch 064:     36 / 49 loss=5.981, nll_loss=4.297, ppl=19.66, wps=24537.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.299, loss_scale=16, train_wall=225, gb_free=8.8, wall=8282
2022-03-06 15:21:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:21:13 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 10.133 | nll_loss 8.915 | ppl 482.63 | wps 46009.4 | wpb 510.9 | bsz 1 | num_updates 3113 | best_loss 9.157
2022-03-06 15:21:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3113 updates
2022-03-06 15:21:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:21:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:21:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 64 @ 3113 updates, score 10.133) (writing took 2.313478648662567 seconds)
2022-03-06 15:21:15 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 15:21:15 | INFO | train | epoch 064 | loss 5.925 | nll_loss 4.23 | ppl 18.77 | wps 24758.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3113 | lr 0.000389147 | gnorm 1.351 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 8320
2022-03-06 15:21:15 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 15:21:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:23:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:23:21 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 10.205 | nll_loss 8.968 | ppl 500.84 | wps 46883.5 | wpb 510.9 | bsz 1 | num_updates 3162 | best_loss 9.157
2022-03-06 15:23:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3162 updates
2022-03-06 15:23:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:23:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:23:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 65 @ 3162 updates, score 10.205) (writing took 2.352795375045389 seconds)
2022-03-06 15:23:24 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 15:23:24 | INFO | train | epoch 065 | loss 5.852 | nll_loss 4.144 | ppl 17.67 | wps 24774.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3162 | lr 0.000395271 | gnorm 1.301 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 8448
2022-03-06 15:23:24 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 15:23:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:23:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:25:01 | INFO | train_inner | epoch 066:     39 / 49 loss=5.834, nll_loss=4.122, ppl=17.41, wps=24560, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.329, loss_scale=16, train_wall=225, gb_free=8.8, wall=8546
2022-03-06 15:25:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:25:30 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 10.345 | nll_loss 9.174 | ppl 577.56 | wps 45273.7 | wpb 510.9 | bsz 1 | num_updates 3210 | best_loss 9.157
2022-03-06 15:25:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3210 updates
2022-03-06 15:25:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:25:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:25:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 66 @ 3210 updates, score 10.345) (writing took 2.345093003939837 seconds)
2022-03-06 15:25:32 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 15:25:32 | INFO | train | epoch 066 | loss 5.781 | nll_loss 4.059 | ppl 16.66 | wps 24236.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 3210 | lr 0.00040127 | gnorm 1.34 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 8577
2022-03-06 15:25:32 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 15:25:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:27:38 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 10.412 | nll_loss 9.24 | ppl 604.87 | wps 46418.5 | wpb 510.9 | bsz 1 | num_updates 3259 | best_loss 9.157
2022-03-06 15:27:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3259 updates
2022-03-06 15:27:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:27:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:27:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 67 @ 3259 updates, score 10.412) (writing took 2.285140475258231 seconds)
2022-03-06 15:27:40 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 15:27:40 | INFO | train | epoch 067 | loss 5.717 | nll_loss 3.983 | ppl 15.81 | wps 24745.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3259 | lr 0.000407394 | gnorm 1.34 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 8705
2022-03-06 15:27:40 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 15:27:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:29:23 | INFO | train_inner | epoch 068:     41 / 49 loss=5.697, nll_loss=3.958, ppl=15.54, wps=24778.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.366, loss_scale=32, train_wall=223, gb_free=8.8, wall=8808
2022-03-06 15:29:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:29:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:29:46 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 10.422 | nll_loss 9.24 | ppl 604.84 | wps 45925.1 | wpb 510.9 | bsz 1 | num_updates 3307 | best_loss 9.157
2022-03-06 15:29:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3307 updates
2022-03-06 15:29:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:29:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:29:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 68 @ 3307 updates, score 10.422) (writing took 2.3699583606794477 seconds)
2022-03-06 15:29:49 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 15:29:49 | INFO | train | epoch 068 | loss 5.646 | nll_loss 3.897 | ppl 14.9 | wps 24254.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 3307 | lr 0.000413392 | gnorm 1.345 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 8834
2022-03-06 15:29:49 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 15:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:31:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:31:55 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 10.439 | nll_loss 9.235 | ppl 602.64 | wps 45909.9 | wpb 510.9 | bsz 1 | num_updates 3356 | best_loss 9.157
2022-03-06 15:31:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3356 updates
2022-03-06 15:31:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:31:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:31:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 69 @ 3356 updates, score 10.439) (writing took 2.3263874780386686 seconds)
2022-03-06 15:31:57 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 15:31:57 | INFO | train | epoch 069 | loss 5.581 | nll_loss 3.819 | ppl 14.12 | wps 24737.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3356 | lr 0.000419516 | gnorm 1.36 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 8962
2022-03-06 15:31:57 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 15:31:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:32:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 15:33:50 | INFO | train_inner | epoch 070:     45 / 49 loss=5.555, nll_loss=3.788, ppl=13.82, wps=24313.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.376, loss_scale=8, train_wall=227, gb_free=8.8, wall=9074
2022-03-06 15:33:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:34:03 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 10.558 | nll_loss 9.371 | ppl 662.34 | wps 46691.4 | wpb 510.9 | bsz 1 | num_updates 3404 | best_loss 9.157
2022-03-06 15:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3404 updates
2022-03-06 15:34:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:34:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:34:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 70 @ 3404 updates, score 10.558) (writing took 2.3371426830999553 seconds)
2022-03-06 15:34:06 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 15:34:06 | INFO | train | epoch 070 | loss 5.516 | nll_loss 3.741 | ppl 13.37 | wps 24263.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 3404 | lr 0.000425515 | gnorm 1.398 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 9090
2022-03-06 15:34:06 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 15:34:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:36:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:36:12 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 10.686 | nll_loss 9.5 | ppl 724.23 | wps 45297.3 | wpb 510.9 | bsz 1 | num_updates 3453 | best_loss 9.157
2022-03-06 15:36:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3453 updates
2022-03-06 15:36:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:36:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:36:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 71 @ 3453 updates, score 10.686) (writing took 2.387326552066952 seconds)
2022-03-06 15:36:14 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 15:36:14 | INFO | train | epoch 071 | loss 5.442 | nll_loss 3.654 | ppl 12.59 | wps 24748.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3453 | lr 0.000431639 | gnorm 1.303 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 9219
2022-03-06 15:36:14 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 15:36:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:38:11 | INFO | train_inner | epoch 072:     47 / 49 loss=5.422, nll_loss=3.629, ppl=12.37, wps=24783.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.369, loss_scale=8, train_wall=223, gb_free=8.8, wall=9336
2022-03-06 15:38:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:38:20 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 10.729 | nll_loss 9.556 | ppl 752.6 | wps 46399.2 | wpb 510.9 | bsz 1 | num_updates 3502 | best_loss 9.157
2022-03-06 15:38:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3502 updates
2022-03-06 15:38:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:38:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:38:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 72 @ 3502 updates, score 10.729) (writing took 2.304489590227604 seconds)
2022-03-06 15:38:22 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 15:38:22 | INFO | train | epoch 072 | loss 5.392 | nll_loss 3.592 | ppl 12.06 | wps 24757.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3502 | lr 0.000437762 | gnorm 1.449 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 9347
2022-03-06 15:38:22 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 15:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:40:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:40:28 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 10.804 | nll_loss 9.65 | ppl 803.28 | wps 45875.2 | wpb 510.9 | bsz 1 | num_updates 3551 | best_loss 9.157
2022-03-06 15:40:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3551 updates
2022-03-06 15:40:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:40:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 73 @ 3551 updates, score 10.804) (writing took 2.368605358991772 seconds)
2022-03-06 15:40:31 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 15:40:31 | INFO | train | epoch 073 | loss 5.323 | nll_loss 3.509 | ppl 11.39 | wps 24734.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3551 | lr 0.000443886 | gnorm 1.433 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 9476
2022-03-06 15:40:31 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 15:40:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:42:32 | INFO | train_inner | epoch 074:     49 / 49 loss=5.289, nll_loss=3.469, ppl=11.07, wps=24776.2, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=3600, lr=0.00045001, gnorm=1.376, loss_scale=16, train_wall=222, gb_free=8.8, wall=9597
2022-03-06 15:42:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:42:37 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.863 | nll_loss 9.694 | ppl 828.29 | wps 45855.6 | wpb 510.9 | bsz 1 | num_updates 3600 | best_loss 9.157
2022-03-06 15:42:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3600 updates
2022-03-06 15:42:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:42:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:42:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 74 @ 3600 updates, score 10.863) (writing took 2.3166737500578165 seconds)
2022-03-06 15:42:39 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 15:42:39 | INFO | train | epoch 074 | loss 5.25 | nll_loss 3.423 | ppl 10.73 | wps 24765.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3600 | lr 0.00045001 | gnorm 1.321 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 9604
2022-03-06 15:42:39 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 15:42:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:43:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 15:44:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:44:45 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.904 | nll_loss 9.747 | ppl 859.07 | wps 46796 | wpb 510.9 | bsz 1 | num_updates 3648 | best_loss 9.157
2022-03-06 15:44:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3648 updates
2022-03-06 15:44:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:44:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:44:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 75 @ 3648 updates, score 10.904) (writing took 2.363953620195389 seconds)
2022-03-06 15:44:47 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 15:44:47 | INFO | train | epoch 075 | loss 5.196 | nll_loss 3.357 | ppl 10.24 | wps 24266.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 3648 | lr 0.000456009 | gnorm 1.414 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 9732
2022-03-06 15:44:47 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 15:44:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:46:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:46:53 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.968 | nll_loss 9.798 | ppl 890.14 | wps 45707.6 | wpb 510.9 | bsz 1 | num_updates 3697 | best_loss 9.157
2022-03-06 15:46:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3697 updates
2022-03-06 15:46:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:46:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:46:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 76 @ 3697 updates, score 10.968) (writing took 2.3121152259409428 seconds)
2022-03-06 15:46:56 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 15:46:56 | INFO | train | epoch 076 | loss 5.137 | nll_loss 3.286 | ppl 9.75 | wps 24769 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3697 | lr 0.000462133 | gnorm 1.452 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 9860
2022-03-06 15:46:56 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 15:46:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:47:03 | INFO | train_inner | epoch 077:      3 / 49 loss=5.162, nll_loss=3.316, ppl=9.96, wps=23910.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.428, loss_scale=8, train_wall=225, gb_free=8.8, wall=9868
2022-03-06 15:48:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:49:02 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 11.021 | nll_loss 9.851 | ppl 923.58 | wps 46555.1 | wpb 510.9 | bsz 1 | num_updates 3746 | best_loss 9.157
2022-03-06 15:49:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3746 updates
2022-03-06 15:49:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:49:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:49:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 77 @ 3746 updates, score 11.021) (writing took 2.3356845267117023 seconds)
2022-03-06 15:49:04 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 15:49:04 | INFO | train | epoch 077 | loss 5.067 | nll_loss 3.202 | ppl 9.2 | wps 24774.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3746 | lr 0.000468256 | gnorm 1.336 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 9989
2022-03-06 15:49:04 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 15:49:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:50:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 15:51:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:51:10 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 11.155 | nll_loss 9.993 | ppl 1019.07 | wps 46283.5 | wpb 510.9 | bsz 1 | num_updates 3794 | best_loss 9.157
2022-03-06 15:51:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3794 updates
2022-03-06 15:51:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:51:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:51:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 78 @ 3794 updates, score 11.155) (writing took 2.4159764740616083 seconds)
2022-03-06 15:51:12 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 15:51:12 | INFO | train | epoch 078 | loss 5.008 | nll_loss 3.13 | ppl 8.76 | wps 24224.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 3794 | lr 0.000474255 | gnorm 1.372 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 10117
2022-03-06 15:51:12 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 15:51:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:51:28 | INFO | train_inner | epoch 079:      6 / 49 loss=5.029, nll_loss=3.156, ppl=8.92, wps=24549, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.346, loss_scale=8, train_wall=225, gb_free=8.8, wall=10132
2022-03-06 15:53:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:53:19 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 11.219 | nll_loss 10.081 | ppl 1082.78 | wps 45682.2 | wpb 510.9 | bsz 1 | num_updates 3843 | best_loss 9.157
2022-03-06 15:53:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3843 updates
2022-03-06 15:53:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:53:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:53:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 79 @ 3843 updates, score 11.219) (writing took 2.307485920842737 seconds)
2022-03-06 15:53:21 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 15:53:21 | INFO | train | epoch 079 | loss 4.96 | nll_loss 3.071 | ppl 8.41 | wps 24748.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3843 | lr 0.000480379 | gnorm 1.4 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 10246
2022-03-06 15:53:21 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 15:53:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:55:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:55:27 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 11.354 | nll_loss 10.22 | ppl 1192.73 | wps 46539.7 | wpb 510.9 | bsz 1 | num_updates 3892 | best_loss 9.157
2022-03-06 15:55:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3892 updates
2022-03-06 15:55:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:55:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:55:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 80 @ 3892 updates, score 11.354) (writing took 2.3331145718693733 seconds)
2022-03-06 15:55:29 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 15:55:29 | INFO | train | epoch 080 | loss 4.888 | nll_loss 2.987 | ppl 7.93 | wps 24785.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3892 | lr 0.000486503 | gnorm 1.358 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 10374
2022-03-06 15:55:29 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 15:55:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:55:49 | INFO | train_inner | epoch 081:      8 / 49 loss=4.915, nll_loss=3.019, ppl=8.1, wps=24795.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.4, loss_scale=8, train_wall=223, gb_free=8.8, wall=10394
2022-03-06 15:56:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 15:57:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:57:35 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 11.401 | nll_loss 10.292 | ppl 1253.46 | wps 45651.9 | wpb 510.9 | bsz 1 | num_updates 3940 | best_loss 9.157
2022-03-06 15:57:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3940 updates
2022-03-06 15:57:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:57:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:57:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 81 @ 3940 updates, score 11.401) (writing took 2.377279588021338 seconds)
2022-03-06 15:57:37 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 15:57:37 | INFO | train | epoch 081 | loss 4.833 | nll_loss 2.919 | ppl 7.56 | wps 24250.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 3940 | lr 0.000492502 | gnorm 1.409 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 10502
2022-03-06 15:57:37 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 15:57:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:59:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:59:43 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 11.434 | nll_loss 10.309 | ppl 1268.35 | wps 46561.1 | wpb 510.9 | bsz 1 | num_updates 3989 | best_loss 9.157
2022-03-06 15:59:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3989 updates
2022-03-06 15:59:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:59:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 15:59:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 82 @ 3989 updates, score 11.434) (writing took 2.323052705731243 seconds)
2022-03-06 15:59:46 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-06 15:59:46 | INFO | train | epoch 082 | loss 4.783 | nll_loss 2.859 | ppl 7.26 | wps 24779.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3989 | lr 0.000498625 | gnorm 1.455 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 10630
2022-03-06 15:59:46 | INFO | fairseq.trainer | begin training epoch 83
2022-03-06 15:59:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:00:13 | INFO | train_inner | epoch 083:     11 / 49 loss=4.793, nll_loss=2.872, ppl=7.32, wps=24562.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.418, loss_scale=8, train_wall=225, gb_free=8.8, wall=10658
2022-03-06 16:01:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:01:52 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 11.474 | nll_loss 10.321 | ppl 1278.75 | wps 46272.3 | wpb 510.9 | bsz 1 | num_updates 4038 | best_loss 9.157
2022-03-06 16:01:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4038 updates
2022-03-06 16:01:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:01:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:01:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 83 @ 4038 updates, score 11.474) (writing took 2.4119745893403888 seconds)
2022-03-06 16:01:54 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-06 16:01:54 | INFO | train | epoch 083 | loss 4.724 | nll_loss 2.787 | ppl 6.9 | wps 24723.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 4038 | lr 0.000497642 | gnorm 1.402 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 10759
2022-03-06 16:01:54 | INFO | fairseq.trainer | begin training epoch 84
2022-03-06 16:01:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:03:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:03:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:04:00 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.542 | nll_loss 10.429 | ppl 1378.37 | wps 44926.5 | wpb 510.9 | bsz 1 | num_updates 4086 | best_loss 9.157
2022-03-06 16:04:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4086 updates
2022-03-06 16:04:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:04:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:04:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 84 @ 4086 updates, score 11.542) (writing took 2.3378169648349285 seconds)
2022-03-06 16:04:03 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-06 16:04:03 | INFO | train | epoch 084 | loss 4.663 | nll_loss 2.714 | ppl 6.56 | wps 24244.8 | ups 0.37 | wpb 64853.3 | bsz 126.7 | num_updates 4086 | lr 0.00049471 | gnorm 1.374 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 10887
2022-03-06 16:04:03 | INFO | fairseq.trainer | begin training epoch 85
2022-03-06 16:04:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:04:38 | INFO | train_inner | epoch 085:     14 / 49 loss=4.678, nll_loss=2.733, ppl=6.65, wps=24533.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.371, loss_scale=8, train_wall=225, gb_free=8.8, wall=10922
2022-03-06 16:06:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:06:09 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.658 | nll_loss 10.524 | ppl 1472.14 | wps 46728.2 | wpb 510.9 | bsz 1 | num_updates 4135 | best_loss 9.157
2022-03-06 16:06:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4135 updates
2022-03-06 16:06:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:06:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:06:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 85 @ 4135 updates, score 11.658) (writing took 2.303423868957907 seconds)
2022-03-06 16:06:11 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-06 16:06:11 | INFO | train | epoch 085 | loss 4.606 | nll_loss 2.646 | ppl 6.26 | wps 24781.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 4135 | lr 0.00049177 | gnorm 1.343 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 11016
2022-03-06 16:06:11 | INFO | fairseq.trainer | begin training epoch 86
2022-03-06 16:06:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:08:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:08:17 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.752 | nll_loss 10.645 | ppl 1601.24 | wps 45644 | wpb 510.9 | bsz 1 | num_updates 4184 | best_loss 9.157
2022-03-06 16:08:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4184 updates
2022-03-06 16:08:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:08:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:08:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 86 @ 4184 updates, score 11.752) (writing took 2.3695234800688922 seconds)
2022-03-06 16:08:19 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-06 16:08:19 | INFO | train | epoch 086 | loss 4.554 | nll_loss 2.582 | ppl 5.99 | wps 24742.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 4184 | lr 0.000488882 | gnorm 1.341 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 11144
2022-03-06 16:08:19 | INFO | fairseq.trainer | begin training epoch 87
2022-03-06 16:08:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:08:59 | INFO | train_inner | epoch 087:     16 / 49 loss=4.562, nll_loss=2.593, ppl=6.03, wps=24792.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.353, loss_scale=8, train_wall=223, gb_free=8.8, wall=11184
2022-03-06 16:10:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:10:25 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.837 | nll_loss 10.756 | ppl 1729.43 | wps 46292.4 | wpb 510.9 | bsz 1 | num_updates 4233 | best_loss 9.157
2022-03-06 16:10:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4233 updates
2022-03-06 16:10:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:10:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:10:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 87 @ 4233 updates, score 11.837) (writing took 2.3207385828718543 seconds)
2022-03-06 16:10:28 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-06 16:10:28 | INFO | train | epoch 087 | loss 4.497 | nll_loss 2.514 | ppl 5.71 | wps 24765.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 4233 | lr 0.000486044 | gnorm 1.276 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 11272
2022-03-06 16:10:28 | INFO | fairseq.trainer | begin training epoch 88
2022-03-06 16:10:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:10:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:12:34 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.936 | nll_loss 10.836 | ppl 1827.31 | wps 46437.8 | wpb 510.9 | bsz 1 | num_updates 4281 | best_loss 9.157
2022-03-06 16:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4281 updates
2022-03-06 16:12:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:12:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 88 @ 4281 updates, score 11.936) (writing took 2.3647403749637306 seconds)
2022-03-06 16:12:36 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-06 16:12:36 | INFO | train | epoch 088 | loss 4.444 | nll_loss 2.451 | ppl 5.47 | wps 24264.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 4281 | lr 0.000483312 | gnorm 1.322 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 11401
2022-03-06 16:12:36 | INFO | fairseq.trainer | begin training epoch 89
2022-03-06 16:12:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:13:24 | INFO | train_inner | epoch 089:     19 / 49 loss=4.45, nll_loss=2.459, ppl=5.5, wps=24559, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.287, loss_scale=8, train_wall=225, gb_free=8.8, wall=11448
2022-03-06 16:14:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:14:42 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.986 | nll_loss 10.917 | ppl 1933.18 | wps 45100.6 | wpb 510.9 | bsz 1 | num_updates 4330 | best_loss 9.157
2022-03-06 16:14:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4330 updates
2022-03-06 16:14:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:14:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:14:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 89 @ 4330 updates, score 11.986) (writing took 2.3170641330070794 seconds)
2022-03-06 16:14:44 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-06 16:14:44 | INFO | train | epoch 089 | loss 4.394 | nll_loss 2.39 | ppl 5.24 | wps 24737.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 4330 | lr 0.000480569 | gnorm 1.297 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 11529
2022-03-06 16:14:44 | INFO | fairseq.trainer | begin training epoch 90
2022-03-06 16:14:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:16:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:16:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:16:50 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 12.014 | nll_loss 10.947 | ppl 1974.48 | wps 46137.4 | wpb 510.9 | bsz 1 | num_updates 4378 | best_loss 9.157
2022-03-06 16:16:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4378 updates
2022-03-06 16:16:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:16:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:16:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 90 @ 4378 updates, score 12.014) (writing took 2.2985792509280145 seconds)
2022-03-06 16:16:53 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-06 16:16:53 | INFO | train | epoch 090 | loss 4.344 | nll_loss 2.33 | ppl 5.03 | wps 24255.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 4378 | lr 0.000477928 | gnorm 1.311 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 11658
2022-03-06 16:16:53 | INFO | fairseq.trainer | begin training epoch 91
2022-03-06 16:16:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:17:48 | INFO | train_inner | epoch 091:     22 / 49 loss=4.349, nll_loss=2.337, ppl=5.05, wps=24552.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.302, loss_scale=8, train_wall=225, gb_free=8.8, wall=11713
2022-03-06 16:18:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:18:59 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 12.049 | nll_loss 10.992 | ppl 2036.19 | wps 45873.4 | wpb 510.9 | bsz 1 | num_updates 4427 | best_loss 9.157
2022-03-06 16:18:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4427 updates
2022-03-06 16:18:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:19:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:19:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 91 @ 4427 updates, score 12.049) (writing took 2.3514624000526965 seconds)
2022-03-06 16:19:01 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-06 16:19:01 | INFO | train | epoch 091 | loss 4.294 | nll_loss 2.271 | ppl 4.83 | wps 24762.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 4427 | lr 0.000475275 | gnorm 1.234 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 11786
2022-03-06 16:19:01 | INFO | fairseq.trainer | begin training epoch 92
2022-03-06 16:19:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:21:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:21:09 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 12.146 | nll_loss 11.087 | ppl 2175.94 | wps 40736.9 | wpb 510.9 | bsz 1 | num_updates 4476 | best_loss 9.157
2022-03-06 16:21:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4476 updates
2022-03-06 16:21:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:21:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:21:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 92 @ 4476 updates, score 12.146) (writing took 2.4459320441819727 seconds)
2022-03-06 16:21:12 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-06 16:21:12 | INFO | train | epoch 092 | loss 4.254 | nll_loss 2.222 | ppl 4.67 | wps 24318.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 4476 | lr 0.000472667 | gnorm 1.278 | loss_scale 8 | train_wall 111 | gb_free 8.8 | wall 11917
2022-03-06 16:21:12 | INFO | fairseq.trainer | begin training epoch 93
2022-03-06 16:21:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:22:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:22:19 | INFO | train_inner | epoch 093:     25 / 49 loss=4.251, nll_loss=2.219, ppl=4.65, wps=23952, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.255, loss_scale=8, train_wall=231, gb_free=8.8, wall=11983
2022-03-06 16:23:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:23:27 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 12.273 | nll_loss 11.215 | ppl 2376.7 | wps 39461.2 | wpb 510.9 | bsz 1 | num_updates 4524 | best_loss 9.157
2022-03-06 16:23:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4524 updates
2022-03-06 16:23:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:23:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:23:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 93 @ 4524 updates, score 12.273) (writing took 2.496629803907126 seconds)
2022-03-06 16:23:30 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-06 16:23:30 | INFO | train | epoch 093 | loss 4.204 | nll_loss 2.162 | ppl 4.48 | wps 22585 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 4524 | lr 0.000470152 | gnorm 1.243 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 12054
2022-03-06 16:23:30 | INFO | fairseq.trainer | begin training epoch 94
2022-03-06 16:23:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:25:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:25:45 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 12.257 | nll_loss 11.195 | ppl 2343.72 | wps 40678.3 | wpb 510.9 | bsz 1 | num_updates 4573 | best_loss 9.157
2022-03-06 16:25:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4573 updates
2022-03-06 16:25:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:25:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:25:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 94 @ 4573 updates, score 12.257) (writing took 2.592635830398649 seconds)
2022-03-06 16:25:47 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-06 16:25:47 | INFO | train | epoch 094 | loss 4.164 | nll_loss 2.113 | ppl 4.33 | wps 23065.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4573 | lr 0.000467627 | gnorm 1.226 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 12192
2022-03-06 16:25:47 | INFO | fairseq.trainer | begin training epoch 95
2022-03-06 16:25:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:26:59 | INFO | train_inner | epoch 095:     27 / 49 loss=4.161, nll_loss=2.111, ppl=4.32, wps=23105.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.215, loss_scale=8, train_wall=239, gb_free=8.8, wall=12264
2022-03-06 16:27:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:28:02 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 12.199 | nll_loss 11.13 | ppl 2241.34 | wps 40310.2 | wpb 510.9 | bsz 1 | num_updates 4622 | best_loss 9.157
2022-03-06 16:28:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4622 updates
2022-03-06 16:28:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:28:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:28:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 95 @ 4622 updates, score 12.199) (writing took 2.473205686081201 seconds)
2022-03-06 16:28:04 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-06 16:28:04 | INFO | train | epoch 095 | loss 4.121 | nll_loss 2.062 | ppl 4.17 | wps 23177.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4622 | lr 0.000465141 | gnorm 1.208 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 12329
2022-03-06 16:28:05 | INFO | fairseq.trainer | begin training epoch 96
2022-03-06 16:28:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:28:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:30:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:30:19 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 12.212 | nll_loss 11.125 | ppl 2233.55 | wps 40411.1 | wpb 510.9 | bsz 1 | num_updates 4670 | best_loss 9.157
2022-03-06 16:30:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4670 updates
2022-03-06 16:30:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:30:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:30:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 96 @ 4670 updates, score 12.212) (writing took 2.4189205816946924 seconds)
2022-03-06 16:30:21 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-06 16:30:21 | INFO | train | epoch 096 | loss 4.085 | nll_loss 2.019 | ppl 4.05 | wps 22730.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 4670 | lr 0.000462745 | gnorm 1.239 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 12466
2022-03-06 16:30:21 | INFO | fairseq.trainer | begin training epoch 97
2022-03-06 16:30:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:31:42 | INFO | train_inner | epoch 097:     30 / 49 loss=4.079, nll_loss=2.012, ppl=4.03, wps=22991.1, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.213, loss_scale=8, train_wall=240, gb_free=8.8, wall=12546
2022-03-06 16:32:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:32:36 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 12.437 | nll_loss 11.419 | ppl 2738.69 | wps 40474.2 | wpb 510.9 | bsz 1 | num_updates 4719 | best_loss 9.157
2022-03-06 16:32:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4719 updates
2022-03-06 16:32:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:32:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:32:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 97 @ 4719 updates, score 12.437) (writing took 2.457251608837396 seconds)
2022-03-06 16:32:39 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-06 16:32:39 | INFO | train | epoch 097 | loss 4.042 | nll_loss 1.968 | ppl 3.91 | wps 23130.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4719 | lr 0.000460336 | gnorm 1.167 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 12604
2022-03-06 16:32:39 | INFO | fairseq.trainer | begin training epoch 98
2022-03-06 16:32:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:34:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:34:54 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 12.413 | nll_loss 11.384 | ppl 2673.4 | wps 39937.2 | wpb 510.9 | bsz 1 | num_updates 4768 | best_loss 9.157
2022-03-06 16:34:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4768 updates
2022-03-06 16:34:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:34:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:34:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 98 @ 4768 updates, score 12.413) (writing took 2.4325597127899528 seconds)
2022-03-06 16:34:56 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-06 16:34:56 | INFO | train | epoch 098 | loss 4.009 | nll_loss 1.928 | ppl 3.81 | wps 23089.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4768 | lr 0.000457965 | gnorm 1.186 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 12741
2022-03-06 16:34:56 | INFO | fairseq.trainer | begin training epoch 99
2022-03-06 16:34:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:35:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:36:25 | INFO | train_inner | epoch 099:     33 / 49 loss=4.006, nll_loss=1.925, ppl=3.8, wps=22908.5, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.19, loss_scale=8, train_wall=241, gb_free=8.8, wall=12829
2022-03-06 16:37:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:37:12 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 12.416 | nll_loss 11.375 | ppl 2655.04 | wps 40081.6 | wpb 510.9 | bsz 1 | num_updates 4816 | best_loss 9.157
2022-03-06 16:37:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4816 updates
2022-03-06 16:37:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:37:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:37:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 99 @ 4816 updates, score 12.416) (writing took 2.578540917020291 seconds)
2022-03-06 16:37:14 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-06 16:37:14 | INFO | train | epoch 099 | loss 3.974 | nll_loss 1.886 | ppl 3.7 | wps 22601.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 4816 | lr 0.000455677 | gnorm 1.219 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 12879
2022-03-06 16:37:14 | INFO | fairseq.trainer | begin training epoch 100
2022-03-06 16:37:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:39:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:39:29 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.471 | nll_loss 11.422 | ppl 2743.27 | wps 40484.1 | wpb 510.9 | bsz 1 | num_updates 4865 | best_loss 9.157
2022-03-06 16:39:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4865 updates
2022-03-06 16:39:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:39:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:39:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 100 @ 4865 updates, score 12.471) (writing took 2.391100373119116 seconds)
2022-03-06 16:39:32 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-06 16:39:32 | INFO | train | epoch 100 | loss 3.936 | nll_loss 1.841 | ppl 3.58 | wps 23097.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4865 | lr 0.000453376 | gnorm 1.161 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 13017
2022-03-06 16:39:32 | INFO | fairseq.trainer | begin training epoch 101
2022-03-06 16:39:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:41:05 | INFO | train_inner | epoch 101:     35 / 49 loss=3.932, nll_loss=1.835, ppl=3.57, wps=23106, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.17, loss_scale=8, train_wall=239, gb_free=8.8, wall=13110
2022-03-06 16:41:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:41:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:41:47 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.527 | nll_loss 11.509 | ppl 2914.03 | wps 39622.2 | wpb 510.9 | bsz 1 | num_updates 4913 | best_loss 9.157
2022-03-06 16:41:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4913 updates
2022-03-06 16:41:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:41:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:41:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 101 @ 4913 updates, score 12.527) (writing took 2.5358164706267416 seconds)
2022-03-06 16:41:50 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-06 16:41:50 | INFO | train | epoch 101 | loss 3.901 | nll_loss 1.798 | ppl 3.48 | wps 22569.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 4913 | lr 0.000451156 | gnorm 1.157 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 13154
2022-03-06 16:41:50 | INFO | fairseq.trainer | begin training epoch 102
2022-03-06 16:41:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:43:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:44:05 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.519 | nll_loss 11.485 | ppl 2866.6 | wps 40367.8 | wpb 510.9 | bsz 1 | num_updates 4962 | best_loss 9.157
2022-03-06 16:44:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4962 updates
2022-03-06 16:44:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:44:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:44:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 102 @ 4962 updates, score 12.519) (writing took 2.5326194940134883 seconds)
2022-03-06 16:44:07 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-06 16:44:07 | INFO | train | epoch 102 | loss 3.872 | nll_loss 1.765 | ppl 3.4 | wps 23076.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4962 | lr 0.000448923 | gnorm 1.134 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 13292
2022-03-06 16:44:07 | INFO | fairseq.trainer | begin training epoch 103
2022-03-06 16:44:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:45:48 | INFO | train_inner | epoch 103:     38 / 49 loss=3.862, nll_loss=1.752, ppl=3.37, wps=22967.7, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.143, loss_scale=8, train_wall=241, gb_free=8.8, wall=13393
2022-03-06 16:46:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:46:21 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.569 | nll_loss 11.546 | ppl 2989.24 | wps 41387.8 | wpb 510.9 | bsz 1 | num_updates 5011 | best_loss 9.157
2022-03-06 16:46:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5011 updates
2022-03-06 16:46:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:46:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:46:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 103 @ 5011 updates, score 12.569) (writing took 2.419295623898506 seconds)
2022-03-06 16:46:23 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-06 16:46:23 | INFO | train | epoch 103 | loss 3.838 | nll_loss 1.724 | ppl 3.3 | wps 23377.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5011 | lr 0.000446722 | gnorm 1.119 | loss_scale 8 | train_wall 116 | gb_free 8.8 | wall 13428
2022-03-06 16:46:23 | INFO | fairseq.trainer | begin training epoch 104
2022-03-06 16:46:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:48:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:48:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:48:36 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.599 | nll_loss 11.59 | ppl 3083.25 | wps 41196.7 | wpb 510.9 | bsz 1 | num_updates 5059 | best_loss 9.157
2022-03-06 16:48:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5059 updates
2022-03-06 16:48:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:48:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:48:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 104 @ 5059 updates, score 12.599) (writing took 2.372765173204243 seconds)
2022-03-06 16:48:39 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-06 16:48:39 | INFO | train | epoch 104 | loss 3.807 | nll_loss 1.687 | ppl 3.22 | wps 23027.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 5059 | lr 0.000444598 | gnorm 1.126 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 13563
2022-03-06 16:48:39 | INFO | fairseq.trainer | begin training epoch 105
2022-03-06 16:48:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:50:27 | INFO | train_inner | epoch 105:     41 / 49 loss=3.802, nll_loss=1.681, ppl=3.21, wps=23283.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.127, loss_scale=8, train_wall=238, gb_free=8.8, wall=13671
2022-03-06 16:50:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:50:52 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.673 | nll_loss 11.674 | ppl 3267.64 | wps 41848.5 | wpb 510.9 | bsz 1 | num_updates 5108 | best_loss 9.157
2022-03-06 16:50:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5108 updates
2022-03-06 16:50:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:50:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:50:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 105 @ 5108 updates, score 12.673) (writing took 2.3827908751554787 seconds)
2022-03-06 16:50:54 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-06 16:50:54 | INFO | train | epoch 105 | loss 3.783 | nll_loss 1.659 | ppl 3.16 | wps 23474.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5108 | lr 0.000442461 | gnorm 1.132 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 13699
2022-03-06 16:50:54 | INFO | fairseq.trainer | begin training epoch 106
2022-03-06 16:50:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:53:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:53:07 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.646 | nll_loss 11.624 | ppl 3155.21 | wps 40854 | wpb 510.9 | bsz 1 | num_updates 5157 | best_loss 9.157
2022-03-06 16:53:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5157 updates
2022-03-06 16:53:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:53:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:53:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 106 @ 5157 updates, score 12.646) (writing took 2.427648941986263 seconds)
2022-03-06 16:53:09 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-06 16:53:09 | INFO | train | epoch 106 | loss 3.753 | nll_loss 1.623 | ppl 3.08 | wps 23445.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5157 | lr 0.000440353 | gnorm 1.118 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 13834
2022-03-06 16:53:09 | INFO | fairseq.trainer | begin training epoch 107
2022-03-06 16:53:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:54:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:55:05 | INFO | train_inner | epoch 107:     44 / 49 loss=3.744, nll_loss=1.612, ppl=3.06, wps=23279, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.12, loss_scale=8, train_wall=238, gb_free=8.8, wall=13950
2022-03-06 16:55:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:55:22 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.732 | nll_loss 11.741 | ppl 3421.92 | wps 41448 | wpb 510.9 | bsz 1 | num_updates 5205 | best_loss 9.157
2022-03-06 16:55:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5205 updates
2022-03-06 16:55:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:55:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:55:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 107 @ 5205 updates, score 12.732) (writing took 2.4138773079030216 seconds)
2022-03-06 16:55:25 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-06 16:55:25 | INFO | train | epoch 107 | loss 3.723 | nll_loss 1.588 | ppl 3.01 | wps 22990.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5205 | lr 0.000438318 | gnorm 1.114 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 13970
2022-03-06 16:55:25 | INFO | fairseq.trainer | begin training epoch 108
2022-03-06 16:55:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:57:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:57:38 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.734 | nll_loss 11.727 | ppl 3389.79 | wps 41885.4 | wpb 510.9 | bsz 1 | num_updates 5254 | best_loss 9.157
2022-03-06 16:57:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5254 updates
2022-03-06 16:57:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:57:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 108 @ 5254 updates, score 12.734) (writing took 2.3903861129656434 seconds)
2022-03-06 16:57:40 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-06 16:57:40 | INFO | train | epoch 108 | loss 3.698 | nll_loss 1.558 | ppl 2.94 | wps 23436.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5254 | lr 0.00043627 | gnorm 1.063 | loss_scale 8 | train_wall 116 | gb_free 8.8 | wall 14105
2022-03-06 16:57:40 | INFO | fairseq.trainer | begin training epoch 109
2022-03-06 16:57:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:59:43 | INFO | train_inner | epoch 109:     46 / 49 loss=3.688, nll_loss=1.547, ppl=2.92, wps=23343.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.066, loss_scale=8, train_wall=237, gb_free=8.8, wall=14228
2022-03-06 16:59:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:59:55 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.86 | nll_loss 11.885 | ppl 3783.18 | wps 39514.1 | wpb 510.9 | bsz 1 | num_updates 5303 | best_loss 9.157
2022-03-06 16:59:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5303 updates
2022-03-06 16:59:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:59:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 16:59:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 109 @ 5303 updates, score 12.86) (writing took 2.4036260722205043 seconds)
2022-03-06 16:59:58 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-06 16:59:58 | INFO | train | epoch 109 | loss 3.674 | nll_loss 1.53 | ppl 2.89 | wps 23137.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5303 | lr 0.000434249 | gnorm 1.07 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 14243
2022-03-06 16:59:58 | INFO | fairseq.trainer | begin training epoch 110
2022-03-06 16:59:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:01:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:02:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:02:13 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.798 | nll_loss 11.813 | ppl 3599.06 | wps 40529.7 | wpb 510.9 | bsz 1 | num_updates 5351 | best_loss 9.157
2022-03-06 17:02:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5351 updates
2022-03-06 17:02:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:02:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:02:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 110 @ 5351 updates, score 12.798) (writing took 2.540379196871072 seconds)
2022-03-06 17:02:16 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-06 17:02:16 | INFO | train | epoch 110 | loss 3.65 | nll_loss 1.503 | ppl 2.83 | wps 22583.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5351 | lr 0.000432297 | gnorm 1.088 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 14380
2022-03-06 17:02:16 | INFO | fairseq.trainer | begin training epoch 111
2022-03-06 17:02:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:04:25 | INFO | train_inner | epoch 111:     49 / 49 loss=3.64, nll_loss=1.491, ppl=2.81, wps=22864.7, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=5400, lr=0.000430331, gnorm=1.07, loss_scale=8, train_wall=240, gb_free=8.8, wall=14510
2022-03-06 17:04:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:04:31 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.876 | nll_loss 11.899 | ppl 3818.79 | wps 40388.2 | wpb 510.9 | bsz 1 | num_updates 5400 | best_loss 9.157
2022-03-06 17:04:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5400 updates
2022-03-06 17:04:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:04:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:04:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 111 @ 5400 updates, score 12.876) (writing took 2.5034351111389697 seconds)
2022-03-06 17:04:33 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-06 17:04:33 | INFO | train | epoch 111 | loss 3.625 | nll_loss 1.473 | ppl 2.78 | wps 23068 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5400 | lr 0.000430331 | gnorm 1.051 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 14518
2022-03-06 17:04:33 | INFO | fairseq.trainer | begin training epoch 112
2022-03-06 17:04:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:06:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:06:49 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 12.825 | nll_loss 11.822 | ppl 3621.35 | wps 39614 | wpb 510.9 | bsz 1 | num_updates 5449 | best_loss 9.157
2022-03-06 17:06:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5449 updates
2022-03-06 17:06:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:06:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:06:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 112 @ 5449 updates, score 12.825) (writing took 2.48036523303017 seconds)
2022-03-06 17:06:51 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-06 17:06:51 | INFO | train | epoch 112 | loss 3.603 | nll_loss 1.447 | ppl 2.73 | wps 23075.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5449 | lr 0.000428392 | gnorm 1.04 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 14656
2022-03-06 17:06:51 | INFO | fairseq.trainer | begin training epoch 113
2022-03-06 17:06:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:07:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:09:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:09:06 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 12.862 | nll_loss 11.872 | ppl 3749.23 | wps 40392.1 | wpb 510.9 | bsz 1 | num_updates 5497 | best_loss 9.157
2022-03-06 17:09:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5497 updates
2022-03-06 17:09:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:09:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:09:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 113 @ 5497 updates, score 12.862) (writing took 2.4252705513499677 seconds)
2022-03-06 17:09:09 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-06 17:09:09 | INFO | train | epoch 113 | loss 3.579 | nll_loss 1.42 | ppl 2.67 | wps 22599.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5497 | lr 0.000426518 | gnorm 1.036 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 14794
2022-03-06 17:09:09 | INFO | fairseq.trainer | begin training epoch 114
2022-03-06 17:09:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:09:17 | INFO | train_inner | epoch 114:      3 / 49 loss=3.589, nll_loss=1.431, ppl=2.7, wps=22248.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5500, lr=0.000426401, gnorm=1.04, loss_scale=8, train_wall=242, gb_free=8.8, wall=14802
2022-03-06 17:11:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:11:24 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 12.844 | nll_loss 11.855 | ppl 3703.15 | wps 39848.5 | wpb 510.9 | bsz 1 | num_updates 5546 | best_loss 9.157
2022-03-06 17:11:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5546 updates
2022-03-06 17:11:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:11:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:11:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 114 @ 5546 updates, score 12.844) (writing took 2.462214943021536 seconds)
2022-03-06 17:11:27 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-06 17:11:27 | INFO | train | epoch 114 | loss 3.561 | nll_loss 1.399 | ppl 2.64 | wps 23056.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5546 | lr 0.000424629 | gnorm 1.03 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 14931
2022-03-06 17:11:27 | INFO | fairseq.trainer | begin training epoch 115
2022-03-06 17:11:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:13:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:13:42 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 12.814 | nll_loss 11.816 | ppl 3605.74 | wps 40188.8 | wpb 510.9 | bsz 1 | num_updates 5595 | best_loss 9.157
2022-03-06 17:13:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5595 updates
2022-03-06 17:13:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:13:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:13:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 115 @ 5595 updates, score 12.814) (writing took 2.5142251322977245 seconds)
2022-03-06 17:13:45 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-06 17:13:45 | INFO | train | epoch 115 | loss 3.543 | nll_loss 1.377 | ppl 2.6 | wps 23006 | ups 0.35 | wpb 64858.2 | bsz 126.7 | num_updates 5595 | lr 0.000422766 | gnorm 1.029 | loss_scale 8 | train_wall 118 | gb_free 8.8 | wall 15070
2022-03-06 17:13:45 | INFO | fairseq.trainer | begin training epoch 116
2022-03-06 17:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:13:58 | INFO | train_inner | epoch 116:      5 / 49 loss=3.549, nll_loss=1.385, ppl=2.61, wps=23060.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=1.025, loss_scale=16, train_wall=240, gb_free=8.8, wall=15083
2022-03-06 17:14:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:15:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:16:00 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 12.962 | nll_loss 12.002 | ppl 4101.07 | wps 40121.8 | wpb 510.9 | bsz 1 | num_updates 5643 | best_loss 9.157
2022-03-06 17:16:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5643 updates
2022-03-06 17:16:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:16:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:16:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 116 @ 5643 updates, score 12.962) (writing took 2.371409598737955 seconds)
2022-03-06 17:16:03 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-06 17:16:03 | INFO | train | epoch 116 | loss 3.52 | nll_loss 1.352 | ppl 2.55 | wps 22599.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5643 | lr 0.000420964 | gnorm 1.027 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 15207
2022-03-06 17:16:03 | INFO | fairseq.trainer | begin training epoch 117
2022-03-06 17:16:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:18:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:18:18 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 12.956 | nll_loss 11.996 | ppl 4084.42 | wps 39521.4 | wpb 510.9 | bsz 1 | num_updates 5692 | best_loss 9.157
2022-03-06 17:18:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5692 updates
2022-03-06 17:18:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:18:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:18:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 117 @ 5692 updates, score 12.956) (writing took 2.4489254117943347 seconds)
2022-03-06 17:18:20 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-06 17:18:20 | INFO | train | epoch 117 | loss 3.499 | nll_loss 1.328 | ppl 2.51 | wps 23052.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5692 | lr 0.000419148 | gnorm 0.994 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 15345
2022-03-06 17:18:20 | INFO | fairseq.trainer | begin training epoch 118
2022-03-06 17:18:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:18:42 | INFO | train_inner | epoch 118:      8 / 49 loss=3.506, nll_loss=1.336, ppl=2.52, wps=22882.6, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=1.012, loss_scale=8, train_wall=242, gb_free=8.8, wall=15367
2022-03-06 17:20:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:20:36 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 12.926 | nll_loss 11.941 | ppl 3931.84 | wps 40130.3 | wpb 510.9 | bsz 1 | num_updates 5741 | best_loss 9.157
2022-03-06 17:20:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5741 updates
2022-03-06 17:20:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:20:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:20:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 118 @ 5741 updates, score 12.926) (writing took 2.5442859269678593 seconds)
2022-03-06 17:20:38 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-06 17:20:38 | INFO | train | epoch 118 | loss 3.483 | nll_loss 1.31 | ppl 2.48 | wps 23053.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5741 | lr 0.000417356 | gnorm 1.015 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 15483
2022-03-06 17:20:38 | INFO | fairseq.trainer | begin training epoch 119
2022-03-06 17:20:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:21:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:22:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:22:53 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 12.97 | nll_loss 12.002 | ppl 4100.57 | wps 41342.3 | wpb 510.9 | bsz 1 | num_updates 5789 | best_loss 9.157
2022-03-06 17:22:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5789 updates
2022-03-06 17:22:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:22:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:22:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 119 @ 5789 updates, score 12.97) (writing took 2.3221489498391747 seconds)
2022-03-06 17:22:55 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-06 17:22:55 | INFO | train | epoch 119 | loss 3.461 | nll_loss 1.285 | ppl 2.44 | wps 22724.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5789 | lr 0.000415622 | gnorm 0.987 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 15620
2022-03-06 17:22:55 | INFO | fairseq.trainer | begin training epoch 120
2022-03-06 17:22:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:23:24 | INFO | train_inner | epoch 120:     11 / 49 loss=3.468, nll_loss=1.292, ppl=2.45, wps=22963, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=0.996, loss_scale=8, train_wall=241, gb_free=8.8, wall=15649
2022-03-06 17:25:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:25:08 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 13 | nll_loss 12.039 | ppl 4207.64 | wps 41197.7 | wpb 510.9 | bsz 1 | num_updates 5838 | best_loss 9.157
2022-03-06 17:25:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5838 updates
2022-03-06 17:25:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:25:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:25:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 120 @ 5838 updates, score 13.0) (writing took 2.4917287519201636 seconds)
2022-03-06 17:25:11 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-06 17:25:11 | INFO | train | epoch 120 | loss 3.449 | nll_loss 1.271 | ppl 2.41 | wps 23409.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5838 | lr 0.000413874 | gnorm 1.004 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 15756
2022-03-06 17:25:11 | INFO | fairseq.trainer | begin training epoch 121
2022-03-06 17:25:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:27:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:27:24 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 13.015 | nll_loss 12.06 | ppl 4269.43 | wps 41259.9 | wpb 510.9 | bsz 1 | num_updates 5887 | best_loss 9.157
2022-03-06 17:27:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5887 updates
2022-03-06 17:27:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:27:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:27:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 121 @ 5887 updates, score 13.015) (writing took 2.340011273045093 seconds)
2022-03-06 17:27:26 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-06 17:27:26 | INFO | train | epoch 121 | loss 3.431 | nll_loss 1.25 | ppl 2.38 | wps 23494.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5887 | lr 0.000412148 | gnorm 0.988 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 15891
2022-03-06 17:27:26 | INFO | fairseq.trainer | begin training epoch 122
2022-03-06 17:27:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:28:01 | INFO | train_inner | epoch 122:     13 / 49 loss=3.435, nll_loss=1.255, ppl=2.39, wps=23481.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=0.998, loss_scale=16, train_wall=235, gb_free=8.8, wall=15925
2022-03-06 17:29:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:29:39 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 13.063 | nll_loss 12.113 | ppl 4429.95 | wps 40943.9 | wpb 510.9 | bsz 1 | num_updates 5936 | best_loss 9.157
2022-03-06 17:29:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5936 updates
2022-03-06 17:29:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:29:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:29:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 122 @ 5936 updates, score 13.063) (writing took 2.4551071119494736 seconds)
2022-03-06 17:29:42 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-06 17:29:42 | INFO | train | epoch 122 | loss 3.413 | nll_loss 1.231 | ppl 2.35 | wps 23424.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5936 | lr 0.000410443 | gnorm 0.969 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 16027
2022-03-06 17:29:42 | INFO | fairseq.trainer | begin training epoch 123
2022-03-06 17:29:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:30:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:31:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:31:55 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 12.961 | nll_loss 11.997 | ppl 4087.37 | wps 41592.7 | wpb 510.9 | bsz 1 | num_updates 5984 | best_loss 9.157
2022-03-06 17:31:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5984 updates
2022-03-06 17:31:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:31:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:31:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 123 @ 5984 updates, score 12.961) (writing took 2.486199826002121 seconds)
2022-03-06 17:31:57 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-06 17:31:57 | INFO | train | epoch 123 | loss 3.397 | nll_loss 1.213 | ppl 2.32 | wps 22967.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5984 | lr 0.000408794 | gnorm 0.979 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 16162
2022-03-06 17:31:57 | INFO | fairseq.trainer | begin training epoch 124
2022-03-06 17:31:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:32:40 | INFO | train_inner | epoch 124:     16 / 49 loss=3.399, nll_loss=1.215, ppl=2.32, wps=23245.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=0.962, loss_scale=8, train_wall=238, gb_free=8.8, wall=16204
2022-03-06 17:34:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:34:10 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 13.068 | nll_loss 12.127 | ppl 4472.81 | wps 41920.9 | wpb 510.9 | bsz 1 | num_updates 6033 | best_loss 9.157
2022-03-06 17:34:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6033 updates
2022-03-06 17:34:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:34:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:34:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 124 @ 6033 updates, score 13.068) (writing took 2.375876596197486 seconds)
2022-03-06 17:34:13 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-06 17:34:13 | INFO | train | epoch 124 | loss 3.381 | nll_loss 1.194 | ppl 2.29 | wps 23499.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6033 | lr 0.00040713 | gnorm 0.943 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 16297
2022-03-06 17:34:13 | INFO | fairseq.trainer | begin training epoch 125
2022-03-06 17:34:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:36:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:36:26 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 13.105 | nll_loss 12.176 | ppl 4628.76 | wps 39712 | wpb 510.9 | bsz 1 | num_updates 6082 | best_loss 9.157
2022-03-06 17:36:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6082 updates
2022-03-06 17:36:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:36:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:36:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 125 @ 6082 updates, score 13.105) (writing took 2.4635219001211226 seconds)
2022-03-06 17:36:29 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-06 17:36:29 | INFO | train | epoch 125 | loss 3.366 | nll_loss 1.178 | ppl 2.26 | wps 23365.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6082 | lr 0.000405487 | gnorm 0.932 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 16433
2022-03-06 17:36:29 | INFO | fairseq.trainer | begin training epoch 126
2022-03-06 17:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:37:17 | INFO | train_inner | epoch 126:     18 / 49 loss=3.37, nll_loss=1.182, ppl=2.27, wps=23391.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=0.941, loss_scale=16, train_wall=236, gb_free=8.8, wall=16482
2022-03-06 17:38:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:38:44 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 13.114 | nll_loss 12.184 | ppl 4653.55 | wps 40493.1 | wpb 510.9 | bsz 1 | num_updates 6131 | best_loss 9.157
2022-03-06 17:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6131 updates
2022-03-06 17:38:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:38:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:38:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 126 @ 6131 updates, score 13.114) (writing took 2.4266709848307073 seconds)
2022-03-06 17:38:46 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-06 17:38:46 | INFO | train | epoch 126 | loss 3.351 | nll_loss 1.162 | ppl 2.24 | wps 23063.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6131 | lr 0.000403863 | gnorm 0.927 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 16571
2022-03-06 17:38:47 | INFO | fairseq.trainer | begin training epoch 127
2022-03-06 17:38:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:40:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:41:02 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 12.974 | nll_loss 12.001 | ppl 4097.7 | wps 40047.2 | wpb 510.9 | bsz 1 | num_updates 6180 | best_loss 9.157
2022-03-06 17:41:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6180 updates
2022-03-06 17:41:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:41:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:41:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 127 @ 6180 updates, score 12.974) (writing took 2.5163786690682173 seconds)
2022-03-06 17:41:05 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-06 17:41:05 | INFO | train | epoch 127 | loss 3.341 | nll_loss 1.151 | ppl 2.22 | wps 23019.4 | ups 0.35 | wpb 64858.2 | bsz 126.7 | num_updates 6180 | lr 0.000402259 | gnorm 0.946 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 16709
2022-03-06 17:41:05 | INFO | fairseq.trainer | begin training epoch 128
2022-03-06 17:41:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:41:58 | INFO | train_inner | epoch 128:     20 / 49 loss=3.34, nll_loss=1.149, ppl=2.22, wps=23065.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=0.934, loss_scale=16, train_wall=240, gb_free=8.8, wall=16763
2022-03-06 17:42:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:43:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:43:20 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 12.988 | nll_loss 12.02 | ppl 4153.25 | wps 39753.6 | wpb 510.9 | bsz 1 | num_updates 6228 | best_loss 9.157
2022-03-06 17:43:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6228 updates
2022-03-06 17:43:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:43:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:43:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 128 @ 6228 updates, score 12.988) (writing took 2.4741702028550208 seconds)
2022-03-06 17:43:23 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-06 17:43:23 | INFO | train | epoch 128 | loss 3.325 | nll_loss 1.133 | ppl 2.19 | wps 22538.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 6228 | lr 0.000400706 | gnorm 0.941 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 16847
2022-03-06 17:43:23 | INFO | fairseq.trainer | begin training epoch 129
2022-03-06 17:43:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:45:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:45:38 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 12.984 | nll_loss 12.036 | ppl 4198.19 | wps 40423.9 | wpb 510.9 | bsz 1 | num_updates 6277 | best_loss 9.157
2022-03-06 17:45:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6277 updates
2022-03-06 17:45:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:45:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:45:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 129 @ 6277 updates, score 12.984) (writing took 2.38851201813668 seconds)
2022-03-06 17:45:40 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-06 17:45:40 | INFO | train | epoch 129 | loss 3.309 | nll_loss 1.115 | ppl 2.17 | wps 23081.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6277 | lr 0.000399139 | gnorm 0.911 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 16985
2022-03-06 17:45:40 | INFO | fairseq.trainer | begin training epoch 130
2022-03-06 17:45:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:46:42 | INFO | train_inner | epoch 130:     23 / 49 loss=3.311, nll_loss=1.117, ppl=2.17, wps=22860.6, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=0.917, loss_scale=16, train_wall=242, gb_free=8.8, wall=17047
2022-03-06 17:47:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:47:56 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 13.064 | nll_loss 12.122 | ppl 4458.11 | wps 39585.5 | wpb 510.9 | bsz 1 | num_updates 6326 | best_loss 9.157
2022-03-06 17:47:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6326 updates
2022-03-06 17:47:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:47:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:47:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 130 @ 6326 updates, score 13.064) (writing took 2.396587024908513 seconds)
2022-03-06 17:47:58 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-06 17:47:58 | INFO | train | epoch 130 | loss 3.298 | nll_loss 1.103 | ppl 2.15 | wps 23069.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6326 | lr 0.00039759 | gnorm 0.91 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 17123
2022-03-06 17:47:58 | INFO | fairseq.trainer | begin training epoch 131
2022-03-06 17:47:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:48:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:50:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:50:14 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 13.091 | nll_loss 12.167 | ppl 4599.84 | wps 39896.6 | wpb 510.9 | bsz 1 | num_updates 6374 | best_loss 9.157
2022-03-06 17:50:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6374 updates
2022-03-06 17:50:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:50:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:50:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 131 @ 6374 updates, score 13.091) (writing took 2.5105064096860588 seconds)
2022-03-06 17:50:16 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-06 17:50:16 | INFO | train | epoch 131 | loss 3.285 | nll_loss 1.088 | ppl 2.13 | wps 22544.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 6374 | lr 0.00039609 | gnorm 0.904 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 17261
2022-03-06 17:50:16 | INFO | fairseq.trainer | begin training epoch 132
2022-03-06 17:50:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:51:26 | INFO | train_inner | epoch 132:     26 / 49 loss=3.286, nll_loss=1.089, ppl=2.13, wps=22857.7, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=0.911, loss_scale=16, train_wall=242, gb_free=8.8, wall=17331
2022-03-06 17:52:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:52:31 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 13.121 | nll_loss 12.195 | ppl 4688.9 | wps 40614.8 | wpb 510.9 | bsz 1 | num_updates 6423 | best_loss 9.157
2022-03-06 17:52:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6423 updates
2022-03-06 17:52:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:52:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:52:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 132 @ 6423 updates, score 13.121) (writing took 2.4020032747648656 seconds)
2022-03-06 17:52:34 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-06 17:52:34 | INFO | train | epoch 132 | loss 3.274 | nll_loss 1.076 | ppl 2.11 | wps 23084.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6423 | lr 0.000394576 | gnorm 0.901 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 17399
2022-03-06 17:52:34 | INFO | fairseq.trainer | begin training epoch 133
2022-03-06 17:52:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:54:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:54:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:54:49 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 13.147 | nll_loss 12.228 | ppl 4797.38 | wps 39830.3 | wpb 510.9 | bsz 1 | num_updates 6471 | best_loss 9.157
2022-03-06 17:54:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6471 updates
2022-03-06 17:54:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:54:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:54:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 133 @ 6471 updates, score 13.147) (writing took 2.455502938013524 seconds)
2022-03-06 17:54:52 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-06 17:54:52 | INFO | train | epoch 133 | loss 3.26 | nll_loss 1.062 | ppl 2.09 | wps 22593.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 6471 | lr 0.00039311 | gnorm 0.886 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 17536
2022-03-06 17:54:52 | INFO | fairseq.trainer | begin training epoch 134
2022-03-06 17:54:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:56:09 | INFO | train_inner | epoch 134:     29 / 49 loss=3.261, nll_loss=1.063, ppl=2.09, wps=22885.3, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=0.889, loss_scale=16, train_wall=242, gb_free=8.8, wall=17614
2022-03-06 17:57:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:57:07 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 13.1 | nll_loss 12.186 | ppl 4658.92 | wps 40033.8 | wpb 510.9 | bsz 1 | num_updates 6520 | best_loss 9.157
2022-03-06 17:57:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6520 updates
2022-03-06 17:57:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:57:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:57:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 134 @ 6520 updates, score 13.1) (writing took 2.6028795442543924 seconds)
2022-03-06 17:57:09 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-06 17:57:09 | INFO | train | epoch 134 | loss 3.252 | nll_loss 1.053 | ppl 2.08 | wps 23050.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6520 | lr 0.00039163 | gnorm 0.89 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 17674
2022-03-06 17:57:09 | INFO | fairseq.trainer | begin training epoch 135
2022-03-06 17:57:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:59:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:59:24 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 13.021 | nll_loss 12.071 | ppl 4302.33 | wps 40661.5 | wpb 510.9 | bsz 1 | num_updates 6569 | best_loss 9.157
2022-03-06 17:59:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6569 updates
2022-03-06 17:59:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:59:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:59:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 135 @ 6569 updates, score 13.021) (writing took 2.5464117070659995 seconds)
2022-03-06 17:59:27 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-06 17:59:27 | INFO | train | epoch 135 | loss 3.239 | nll_loss 1.039 | ppl 2.05 | wps 23132 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6569 | lr 0.000390167 | gnorm 0.88 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 17812
2022-03-06 17:59:27 | INFO | fairseq.trainer | begin training epoch 136
2022-03-06 17:59:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:00:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:00:52 | INFO | train_inner | epoch 136:     32 / 49 loss=3.238, nll_loss=1.037, ppl=2.05, wps=22979.1, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.87, loss_scale=16, train_wall=240, gb_free=8.8, wall=17896
2022-03-06 18:01:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:01:40 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 13.186 | nll_loss 12.282 | ppl 4981.27 | wps 41564.9 | wpb 510.9 | bsz 1 | num_updates 6617 | best_loss 9.157
2022-03-06 18:01:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6617 updates
2022-03-06 18:01:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:01:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:01:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 136 @ 6617 updates, score 13.186) (writing took 2.3805169356055558 seconds)
2022-03-06 18:01:43 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-06 18:01:43 | INFO | train | epoch 136 | loss 3.227 | nll_loss 1.025 | ppl 2.04 | wps 22935.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 6617 | lr 0.000388749 | gnorm 0.86 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 17947
2022-03-06 18:01:43 | INFO | fairseq.trainer | begin training epoch 137
2022-03-06 18:01:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:03:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:03:55 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 13.192 | nll_loss 12.278 | ppl 4967.47 | wps 42720.1 | wpb 510.9 | bsz 1 | num_updates 6666 | best_loss 9.157
2022-03-06 18:03:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6666 updates
2022-03-06 18:03:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:03:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:03:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 137 @ 6666 updates, score 13.192) (writing took 2.3897892953827977 seconds)
2022-03-06 18:03:57 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-06 18:03:57 | INFO | train | epoch 137 | loss 3.218 | nll_loss 1.017 | ppl 2.02 | wps 23583.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6666 | lr 0.000387318 | gnorm 0.872 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 18082
2022-03-06 18:03:57 | INFO | fairseq.trainer | begin training epoch 138
2022-03-06 18:03:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:04:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:05:29 | INFO | train_inner | epoch 138:     35 / 49 loss=3.216, nll_loss=1.015, ppl=2.02, wps=23400.4, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.873, loss_scale=8, train_wall=236, gb_free=8.8, wall=18174
2022-03-06 18:06:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:06:09 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 13.154 | nll_loss 12.246 | ppl 4858.22 | wps 41693.5 | wpb 510.9 | bsz 1 | num_updates 6714 | best_loss 9.157
2022-03-06 18:06:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6714 updates
2022-03-06 18:06:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:06:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:06:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 138 @ 6714 updates, score 13.154) (writing took 2.4465213078074157 seconds)
2022-03-06 18:06:12 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-06 18:06:12 | INFO | train | epoch 138 | loss 3.206 | nll_loss 1.003 | ppl 2 | wps 23147.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 6714 | lr 0.000385931 | gnorm 0.864 | loss_scale 8 | train_wall 114 | gb_free 8.8 | wall 18217
2022-03-06 18:06:12 | INFO | fairseq.trainer | begin training epoch 139
2022-03-06 18:06:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:08:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:08:24 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 13.004 | nll_loss 12.061 | ppl 4272.04 | wps 41965.1 | wpb 510.9 | bsz 1 | num_updates 6763 | best_loss 9.157
2022-03-06 18:08:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6763 updates
2022-03-06 18:08:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:08:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:08:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 139 @ 6763 updates, score 13.004) (writing took 2.5146973780356348 seconds)
2022-03-06 18:08:26 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-06 18:08:26 | INFO | train | epoch 139 | loss 3.196 | nll_loss 0.993 | ppl 1.99 | wps 23593.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6763 | lr 0.00038453 | gnorm 0.847 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 18351
2022-03-06 18:08:26 | INFO | fairseq.trainer | begin training epoch 140
2022-03-06 18:08:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:10:04 | INFO | train_inner | epoch 140:     37 / 49 loss=3.195, nll_loss=0.992, ppl=1.99, wps=23578.5, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.862, loss_scale=16, train_wall=234, gb_free=8.8, wall=18449
2022-03-06 18:10:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:10:40 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 13.123 | nll_loss 12.208 | ppl 4732.44 | wps 41196.1 | wpb 510.9 | bsz 1 | num_updates 6812 | best_loss 9.157
2022-03-06 18:10:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6812 updates
2022-03-06 18:10:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:10:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:10:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 140 @ 6812 updates, score 13.123) (writing took 2.3751238752156496 seconds)
2022-03-06 18:10:42 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-06 18:10:42 | INFO | train | epoch 140 | loss 3.188 | nll_loss 0.985 | ppl 1.98 | wps 23448.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6812 | lr 0.000383145 | gnorm 0.879 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 18487
2022-03-06 18:10:42 | INFO | fairseq.trainer | begin training epoch 141
2022-03-06 18:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:12:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:12:55 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 13.124 | nll_loss 12.211 | ppl 4742.32 | wps 40816.5 | wpb 510.9 | bsz 1 | num_updates 6861 | best_loss 9.157
2022-03-06 18:12:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6861 updates
2022-03-06 18:12:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:12:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:12:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 141 @ 6861 updates, score 13.124) (writing took 2.4042057851329446 seconds)
2022-03-06 18:12:57 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-06 18:12:57 | INFO | train | epoch 141 | loss 3.178 | nll_loss 0.974 | ppl 1.96 | wps 23489.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6861 | lr 0.000381774 | gnorm 0.85 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 18622
2022-03-06 18:12:57 | INFO | fairseq.trainer | begin training epoch 142
2022-03-06 18:12:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:14:41 | INFO | train_inner | epoch 142:     39 / 49 loss=3.175, nll_loss=0.972, ppl=1.96, wps=23409.9, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.844, loss_scale=16, train_wall=236, gb_free=8.8, wall=18726
2022-03-06 18:15:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:15:12 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 13.086 | nll_loss 12.159 | ppl 4572.84 | wps 40372.1 | wpb 510.9 | bsz 1 | num_updates 6910 | best_loss 9.157
2022-03-06 18:15:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6910 updates
2022-03-06 18:15:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:15:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:15:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 142 @ 6910 updates, score 13.086) (writing took 2.4373607500456274 seconds)
2022-03-06 18:15:14 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-06 18:15:14 | INFO | train | epoch 142 | loss 3.167 | nll_loss 0.963 | ppl 1.95 | wps 23197 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6910 | lr 0.000380418 | gnorm 0.828 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 18759
2022-03-06 18:15:14 | INFO | fairseq.trainer | begin training epoch 143
2022-03-06 18:15:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:15:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:17:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:17:30 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 13.173 | nll_loss 12.275 | ppl 4954.96 | wps 40025.8 | wpb 510.9 | bsz 1 | num_updates 6958 | best_loss 9.157
2022-03-06 18:17:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6958 updates
2022-03-06 18:17:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:17:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:17:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 143 @ 6958 updates, score 13.173) (writing took 2.383839463815093 seconds)
2022-03-06 18:17:32 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-06 18:17:32 | INFO | train | epoch 143 | loss 3.158 | nll_loss 0.953 | ppl 1.94 | wps 22590.6 | ups 0.35 | wpb 64853.3 | bsz 126.7 | num_updates 6958 | lr 0.000379103 | gnorm 0.837 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 18897
2022-03-06 18:17:32 | INFO | fairseq.trainer | begin training epoch 144
2022-03-06 18:17:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:19:25 | INFO | train_inner | epoch 144:     42 / 49 loss=3.156, nll_loss=0.952, ppl=1.93, wps=22876.3, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.842, loss_scale=16, train_wall=242, gb_free=8.8, wall=19009
2022-03-06 18:19:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:19:48 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 13.114 | nll_loss 12.196 | ppl 4691.23 | wps 40135.6 | wpb 510.9 | bsz 1 | num_updates 7007 | best_loss 9.157
2022-03-06 18:19:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7007 updates
2022-03-06 18:19:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:19:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:19:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 144 @ 7007 updates, score 13.114) (writing took 2.556709805969149 seconds)
2022-03-06 18:19:50 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-06 18:19:50 | INFO | train | epoch 144 | loss 3.15 | nll_loss 0.945 | ppl 1.93 | wps 23031.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7007 | lr 0.000377776 | gnorm 0.847 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 19035
2022-03-06 18:19:50 | INFO | fairseq.trainer | begin training epoch 145
2022-03-06 18:19:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:22:06 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 13.206 | nll_loss 12.32 | ppl 5111.41 | wps 40171.7 | wpb 510.9 | bsz 1 | num_updates 7056 | best_loss 9.157
2022-03-06 18:22:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7056 updates
2022-03-06 18:22:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:22:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:22:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 145 @ 7056 updates, score 13.206) (writing took 2.519236591178924 seconds)
2022-03-06 18:22:08 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-06 18:22:08 | INFO | train | epoch 145 | loss 3.141 | nll_loss 0.936 | ppl 1.91 | wps 23042.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7056 | lr 0.000376462 | gnorm 0.823 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 19173
2022-03-06 18:22:08 | INFO | fairseq.trainer | begin training epoch 146
2022-03-06 18:22:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:22:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:24:08 | INFO | train_inner | epoch 146:     45 / 49 loss=3.138, nll_loss=0.933, ppl=1.91, wps=22871.7, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.822, loss_scale=16, train_wall=242, gb_free=8.8, wall=19293
2022-03-06 18:24:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:24:23 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 13.104 | nll_loss 12.189 | ppl 4670 | wps 39758.9 | wpb 510.9 | bsz 1 | num_updates 7104 | best_loss 9.157
2022-03-06 18:24:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7104 updates
2022-03-06 18:24:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:24:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:24:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 146 @ 7104 updates, score 13.104) (writing took 2.4274731781333685 seconds)
2022-03-06 18:24:26 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-06 18:24:26 | INFO | train | epoch 146 | loss 3.131 | nll_loss 0.925 | ppl 1.9 | wps 22621.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7104 | lr 0.000375188 | gnorm 0.816 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 19310
2022-03-06 18:24:26 | INFO | fairseq.trainer | begin training epoch 147
2022-03-06 18:24:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:26:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:26:41 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 13.176 | nll_loss 12.276 | ppl 4960.59 | wps 39701.6 | wpb 510.9 | bsz 1 | num_updates 7153 | best_loss 9.157
2022-03-06 18:26:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7153 updates
2022-03-06 18:26:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:26:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:26:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 147 @ 7153 updates, score 13.176) (writing took 2.548822484910488 seconds)
2022-03-06 18:26:44 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-06 18:26:44 | INFO | train | epoch 147 | loss 3.123 | nll_loss 0.917 | ppl 1.89 | wps 23031.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7153 | lr 0.0003739 | gnorm 0.796 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 19448
2022-03-06 18:26:44 | INFO | fairseq.trainer | begin training epoch 148
2022-03-06 18:26:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:28:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:28:52 | INFO | train_inner | epoch 148:     48 / 49 loss=3.121, nll_loss=0.916, ppl=1.89, wps=22851.4, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=7200, lr=0.000372678, gnorm=0.813, loss_scale=16, train_wall=242, gb_free=8.8, wall=19577
2022-03-06 18:28:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:28:59 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 13.097 | nll_loss 12.204 | ppl 4718.6 | wps 39932.4 | wpb 510.9 | bsz 1 | num_updates 7201 | best_loss 9.157
2022-03-06 18:28:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7201 updates
2022-03-06 18:28:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:29:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:29:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 148 @ 7201 updates, score 13.097) (writing took 2.5884962207637727 seconds)
2022-03-06 18:29:02 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-06 18:29:02 | INFO | train | epoch 148 | loss 3.118 | nll_loss 0.912 | ppl 1.88 | wps 22554 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7201 | lr 0.000372652 | gnorm 0.83 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 19586
2022-03-06 18:29:02 | INFO | fairseq.trainer | begin training epoch 149
2022-03-06 18:29:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:31:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:31:17 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 13.164 | nll_loss 12.264 | ppl 4917.11 | wps 39997 | wpb 510.9 | bsz 1 | num_updates 7250 | best_loss 9.157
2022-03-06 18:31:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7250 updates
2022-03-06 18:31:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:31:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:31:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 149 @ 7250 updates, score 13.164) (writing took 2.4662531898356974 seconds)
2022-03-06 18:31:20 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-06 18:31:20 | INFO | train | epoch 149 | loss 3.108 | nll_loss 0.902 | ppl 1.87 | wps 23045.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7250 | lr 0.000371391 | gnorm 0.805 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 19724
2022-03-06 18:31:20 | INFO | fairseq.trainer | begin training epoch 150
2022-03-06 18:31:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:33:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:33:35 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 13.104 | nll_loss 12.196 | ppl 4693.02 | wps 41453.2 | wpb 510.9 | bsz 1 | num_updates 7299 | best_loss 9.157
2022-03-06 18:33:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7299 updates
2022-03-06 18:33:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:33:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:33:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 150 @ 7299 updates, score 13.104) (writing took 2.5719200521707535 seconds)
2022-03-06 18:33:37 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-06 18:33:37 | INFO | train | epoch 150 | loss 3.101 | nll_loss 0.894 | ppl 1.86 | wps 23050.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7299 | lr 0.000370142 | gnorm 0.806 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 19862
2022-03-06 18:33:37 | INFO | fairseq.trainer | begin training epoch 151
2022-03-06 18:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:33:40 | INFO | train_inner | epoch 151:      1 / 49 loss=3.104, nll_loss=0.898, ppl=1.86, wps=22406.6, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=7300, lr=0.000370117, gnorm=0.807, loss_scale=16, train_wall=238, gb_free=8.8, wall=19865
2022-03-06 18:34:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:35:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:35:52 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 13.218 | nll_loss 12.34 | ppl 5185.62 | wps 40779.1 | wpb 510.9 | bsz 1 | num_updates 7347 | best_loss 9.157
2022-03-06 18:35:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7347 updates
2022-03-06 18:35:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:35:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:35:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 151 @ 7347 updates, score 13.218) (writing took 2.537446507718414 seconds)
2022-03-06 18:35:55 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-06 18:35:55 | INFO | train | epoch 151 | loss 3.091 | nll_loss 0.884 | ppl 1.85 | wps 22634 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7347 | lr 0.000368931 | gnorm 0.789 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 20000
2022-03-06 18:35:55 | INFO | fairseq.trainer | begin training epoch 152
2022-03-06 18:35:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:37:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:38:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:38:09 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 13.181 | nll_loss 12.296 | ppl 5027.29 | wps 40478.7 | wpb 510.9 | bsz 1 | num_updates 7395 | best_loss 9.157
2022-03-06 18:38:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7395 updates
2022-03-06 18:38:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:38:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:38:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 152 @ 7395 updates, score 13.181) (writing took 2.484062507748604 seconds)
2022-03-06 18:38:12 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-06 18:38:12 | INFO | train | epoch 152 | loss 3.086 | nll_loss 0.879 | ppl 1.84 | wps 22751.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7395 | lr 0.000367732 | gnorm 0.809 | loss_scale 8 | train_wall 116 | gb_free 8.8 | wall 20136
2022-03-06 18:38:12 | INFO | fairseq.trainer | begin training epoch 153
2022-03-06 18:38:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:38:25 | INFO | train_inner | epoch 153:      5 / 49 loss=3.087, nll_loss=0.88, ppl=1.84, wps=22767.6, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=7400, lr=0.000367607, gnorm=0.796, loss_scale=8, train_wall=243, gb_free=8.8, wall=20150
2022-03-06 18:40:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:40:27 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 13.178 | nll_loss 12.281 | ppl 4975.12 | wps 40341.7 | wpb 510.9 | bsz 1 | num_updates 7444 | best_loss 9.157
2022-03-06 18:40:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7444 updates
2022-03-06 18:40:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:40:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:40:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 153 @ 7444 updates, score 13.178) (writing took 2.5207120361737907 seconds)
2022-03-06 18:40:29 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-06 18:40:29 | INFO | train | epoch 153 | loss 3.077 | nll_loss 0.87 | ppl 1.83 | wps 23101.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7444 | lr 0.000366519 | gnorm 0.782 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 20274
2022-03-06 18:40:29 | INFO | fairseq.trainer | begin training epoch 154
2022-03-06 18:40:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:42:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:42:44 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 13.19 | nll_loss 12.317 | ppl 5103.4 | wps 40132.9 | wpb 510.9 | bsz 1 | num_updates 7493 | best_loss 9.157
2022-03-06 18:42:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7493 updates
2022-03-06 18:42:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:42:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:42:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 154 @ 7493 updates, score 13.19) (writing took 2.442891933955252 seconds)
2022-03-06 18:42:47 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-06 18:42:47 | INFO | train | epoch 154 | loss 3.071 | nll_loss 0.865 | ppl 1.82 | wps 23126.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7493 | lr 0.000365319 | gnorm 0.782 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 20411
2022-03-06 18:42:47 | INFO | fairseq.trainer | begin training epoch 155
2022-03-06 18:42:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:43:06 | INFO | train_inner | epoch 155:      7 / 49 loss=3.074, nll_loss=0.867, ppl=1.82, wps=23135.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.783, loss_scale=8, train_wall=239, gb_free=8.8, wall=20430
2022-03-06 18:44:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:45:02 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 13.235 | nll_loss 12.364 | ppl 5270.01 | wps 39603 | wpb 510.9 | bsz 1 | num_updates 7542 | best_loss 9.157
2022-03-06 18:45:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7542 updates
2022-03-06 18:45:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:45:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:45:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 155 @ 7542 updates, score 13.235) (writing took 2.539913556072861 seconds)
2022-03-06 18:45:04 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-06 18:45:04 | INFO | train | epoch 155 | loss 3.064 | nll_loss 0.857 | ppl 1.81 | wps 23103.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7542 | lr 0.00036413 | gnorm 0.766 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 20549
2022-03-06 18:45:04 | INFO | fairseq.trainer | begin training epoch 156
2022-03-06 18:45:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:47:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:47:19 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 13.013 | nll_loss 12.098 | ppl 4384.29 | wps 40113.2 | wpb 510.9 | bsz 1 | num_updates 7591 | best_loss 9.157
2022-03-06 18:47:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7591 updates
2022-03-06 18:47:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:47:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:47:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 156 @ 7591 updates, score 13.013) (writing took 2.4914630739949644 seconds)
2022-03-06 18:47:22 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-06 18:47:22 | INFO | train | epoch 156 | loss 3.056 | nll_loss 0.849 | ppl 1.8 | wps 23128 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7591 | lr 0.000362953 | gnorm 0.784 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 20686
2022-03-06 18:47:22 | INFO | fairseq.trainer | begin training epoch 157
2022-03-06 18:47:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:47:46 | INFO | train_inner | epoch 157:      9 / 49 loss=3.058, nll_loss=0.851, ppl=1.8, wps=23144.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.78, loss_scale=16, train_wall=239, gb_free=8.8, wall=20711
2022-03-06 18:49:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:49:37 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 13.116 | nll_loss 12.231 | ppl 4806.73 | wps 40100.6 | wpb 510.9 | bsz 1 | num_updates 7640 | best_loss 9.157
2022-03-06 18:49:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7640 updates
2022-03-06 18:49:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:49:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:49:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 157 @ 7640 updates, score 13.116) (writing took 2.4986531496979296 seconds)
2022-03-06 18:49:39 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-06 18:49:39 | INFO | train | epoch 157 | loss 3.051 | nll_loss 0.843 | ppl 1.79 | wps 23128.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7640 | lr 0.000361787 | gnorm 0.774 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 20824
2022-03-06 18:49:39 | INFO | fairseq.trainer | begin training epoch 158
2022-03-06 18:49:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:49:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:51:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:51:54 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 13.152 | nll_loss 12.27 | ppl 4937.4 | wps 40355.3 | wpb 510.9 | bsz 1 | num_updates 7688 | best_loss 9.157
2022-03-06 18:51:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7688 updates
2022-03-06 18:51:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:51:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:51:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 158 @ 7688 updates, score 13.152) (writing took 2.5390675170347095 seconds)
2022-03-06 18:51:57 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-06 18:51:57 | INFO | train | epoch 158 | loss 3.041 | nll_loss 0.834 | ppl 1.78 | wps 22643 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7688 | lr 0.000360656 | gnorm 0.755 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 20961
2022-03-06 18:51:57 | INFO | fairseq.trainer | begin training epoch 159
2022-03-06 18:51:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:52:29 | INFO | train_inner | epoch 159:     12 / 49 loss=3.044, nll_loss=0.837, ppl=1.79, wps=22929.6, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.757, loss_scale=16, train_wall=241, gb_free=8.8, wall=20993
2022-03-06 18:54:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:54:12 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 13.156 | nll_loss 12.274 | ppl 4951.08 | wps 40284.7 | wpb 510.9 | bsz 1 | num_updates 7737 | best_loss 9.157
2022-03-06 18:54:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7737 updates
2022-03-06 18:54:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:54:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:54:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 159 @ 7737 updates, score 13.156) (writing took 2.4694480211474 seconds)
2022-03-06 18:54:14 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-06 18:54:14 | INFO | train | epoch 159 | loss 3.037 | nll_loss 0.831 | ppl 1.78 | wps 23096.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7737 | lr 0.000359512 | gnorm 0.759 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 21099
2022-03-06 18:54:14 | INFO | fairseq.trainer | begin training epoch 160
2022-03-06 18:54:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:55:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:56:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:56:29 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 13.139 | nll_loss 12.26 | ppl 4903.41 | wps 39691.3 | wpb 510.9 | bsz 1 | num_updates 7785 | best_loss 9.157
2022-03-06 18:56:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7785 updates
2022-03-06 18:56:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:56:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:56:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 160 @ 7785 updates, score 13.139) (writing took 2.477097758091986 seconds)
2022-03-06 18:56:32 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-06 18:56:32 | INFO | train | epoch 160 | loss 3.03 | nll_loss 0.823 | ppl 1.77 | wps 22635.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7785 | lr 0.000358402 | gnorm 0.752 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 21236
2022-03-06 18:56:32 | INFO | fairseq.trainer | begin training epoch 161
2022-03-06 18:56:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:57:12 | INFO | train_inner | epoch 161:     15 / 49 loss=3.032, nll_loss=0.825, ppl=1.77, wps=22924.4, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.763, loss_scale=16, train_wall=241, gb_free=8.8, wall=21276
2022-03-06 18:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:58:47 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 13.196 | nll_loss 12.327 | ppl 5137.11 | wps 40317.6 | wpb 510.9 | bsz 1 | num_updates 7834 | best_loss 9.157
2022-03-06 18:58:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7834 updates
2022-03-06 18:58:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:58:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:58:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 161 @ 7834 updates, score 13.196) (writing took 2.4728877511806786 seconds)
2022-03-06 18:58:49 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-06 18:58:49 | INFO | train | epoch 161 | loss 3.025 | nll_loss 0.819 | ppl 1.76 | wps 23129.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7834 | lr 0.00035728 | gnorm 0.78 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 21374
2022-03-06 18:58:49 | INFO | fairseq.trainer | begin training epoch 162
2022-03-06 18:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:00:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:01:04 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 13.156 | nll_loss 12.286 | ppl 4992.46 | wps 39921.1 | wpb 510.9 | bsz 1 | num_updates 7883 | best_loss 9.157
2022-03-06 19:01:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7883 updates
2022-03-06 19:01:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:01:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:01:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 162 @ 7883 updates, score 13.156) (writing took 2.361873700749129 seconds)
2022-03-06 19:01:07 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-06 19:01:07 | INFO | train | epoch 162 | loss 3.018 | nll_loss 0.811 | ppl 1.75 | wps 23117.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7883 | lr 0.000356167 | gnorm 0.746 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 21511
2022-03-06 19:01:07 | INFO | fairseq.trainer | begin training epoch 163
2022-03-06 19:01:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:01:52 | INFO | train_inner | epoch 163:     17 / 49 loss=3.019, nll_loss=0.812, ppl=1.76, wps=23143.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.753, loss_scale=32, train_wall=239, gb_free=8.8, wall=21557
2022-03-06 19:02:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:03:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:03:21 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 13.039 | nll_loss 12.142 | ppl 4520.41 | wps 40680.4 | wpb 510.9 | bsz 1 | num_updates 7931 | best_loss 9.157
2022-03-06 19:03:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7931 updates
2022-03-06 19:03:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:03:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:03:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 163 @ 7931 updates, score 13.039) (writing took 2.465042829979211 seconds)
2022-03-06 19:03:24 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-06 19:03:24 | INFO | train | epoch 163 | loss 3.011 | nll_loss 0.805 | ppl 1.75 | wps 22702.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7931 | lr 0.000355088 | gnorm 0.758 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 21648
2022-03-06 19:03:24 | INFO | fairseq.trainer | begin training epoch 164
2022-03-06 19:03:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:05:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:05:36 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 13.15 | nll_loss 12.279 | ppl 4968.2 | wps 42393.5 | wpb 510.9 | bsz 1 | num_updates 7980 | best_loss 9.157
2022-03-06 19:05:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7980 updates
2022-03-06 19:05:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:05:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:05:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 164 @ 7980 updates, score 13.15) (writing took 2.421364885289222 seconds)
2022-03-06 19:05:39 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-06 19:05:39 | INFO | train | epoch 164 | loss 3.006 | nll_loss 0.799 | ppl 1.74 | wps 23505.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7980 | lr 0.000353996 | gnorm 0.739 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 21784
2022-03-06 19:05:39 | INFO | fairseq.trainer | begin training epoch 165
2022-03-06 19:05:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:06:31 | INFO | train_inner | epoch 165:     20 / 49 loss=3.006, nll_loss=0.8, ppl=1.74, wps=23219.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.749, loss_scale=16, train_wall=238, gb_free=8.8, wall=21836
2022-03-06 19:07:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:07:52 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 13.015 | nll_loss 12.124 | ppl 4462.63 | wps 41443 | wpb 510.9 | bsz 1 | num_updates 8029 | best_loss 9.157
2022-03-06 19:07:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8029 updates
2022-03-06 19:07:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:07:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:07:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 165 @ 8029 updates, score 13.015) (writing took 2.3256528000347316 seconds)
2022-03-06 19:07:54 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-06 19:07:54 | INFO | train | epoch 165 | loss 3 | nll_loss 0.793 | ppl 1.73 | wps 23520.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8029 | lr 0.000352914 | gnorm 0.738 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 21919
2022-03-06 19:07:54 | INFO | fairseq.trainer | begin training epoch 166
2022-03-06 19:07:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:09:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:10:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:10:07 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 13.185 | nll_loss 12.317 | ppl 5103.38 | wps 41844.7 | wpb 510.9 | bsz 1 | num_updates 8077 | best_loss 9.157
2022-03-06 19:10:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8077 updates
2022-03-06 19:10:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:10:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:10:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 166 @ 8077 updates, score 13.185) (writing took 2.490264873020351 seconds)
2022-03-06 19:10:09 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-06 19:10:09 | INFO | train | epoch 166 | loss 2.995 | nll_loss 0.789 | ppl 1.73 | wps 23043.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 8077 | lr 0.000351864 | gnorm 0.746 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 22054
2022-03-06 19:10:09 | INFO | fairseq.trainer | begin training epoch 167
2022-03-06 19:10:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:11:09 | INFO | train_inner | epoch 167:     23 / 49 loss=2.995, nll_loss=0.789, ppl=1.73, wps=23332, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.741, loss_scale=16, train_wall=237, gb_free=8.8, wall=22114
2022-03-06 19:12:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:12:22 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 13.195 | nll_loss 12.332 | ppl 5154.24 | wps 42085.6 | wpb 510.9 | bsz 1 | num_updates 8126 | best_loss 9.157
2022-03-06 19:12:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8126 updates
2022-03-06 19:12:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:12:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:12:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 167 @ 8126 updates, score 13.195) (writing took 2.3412286429665983 seconds)
2022-03-06 19:12:24 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-06 19:12:24 | INFO | train | epoch 167 | loss 2.991 | nll_loss 0.785 | ppl 1.72 | wps 23558.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8126 | lr 0.000350802 | gnorm 0.733 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 22189
2022-03-06 19:12:24 | INFO | fairseq.trainer | begin training epoch 168
2022-03-06 19:12:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:14:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:14:37 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 13.138 | nll_loss 12.264 | ppl 4918.08 | wps 40743.9 | wpb 510.9 | bsz 1 | num_updates 8175 | best_loss 9.157
2022-03-06 19:14:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8175 updates
2022-03-06 19:14:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:14:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:14:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 168 @ 8175 updates, score 13.138) (writing took 2.462886055931449 seconds)
2022-03-06 19:14:39 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-06 19:14:39 | INFO | train | epoch 168 | loss 2.985 | nll_loss 0.78 | ppl 1.72 | wps 23510.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8175 | lr 0.000349749 | gnorm 0.727 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 22324
2022-03-06 19:14:39 | INFO | fairseq.trainer | begin training epoch 169
2022-03-06 19:14:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:15:45 | INFO | train_inner | epoch 169:     25 / 49 loss=2.985, nll_loss=0.779, ppl=1.72, wps=23558.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.731, loss_scale=32, train_wall=235, gb_free=8.8, wall=22390
2022-03-06 19:15:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:16:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:16:52 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 13.134 | nll_loss 12.266 | ppl 4925.33 | wps 40134.8 | wpb 510.9 | bsz 1 | num_updates 8223 | best_loss 9.157
2022-03-06 19:16:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8223 updates
2022-03-06 19:16:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:16:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:16:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 169 @ 8223 updates, score 13.134) (writing took 2.3603195319883525 seconds)
2022-03-06 19:16:55 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-06 19:16:55 | INFO | train | epoch 169 | loss 2.979 | nll_loss 0.773 | ppl 1.71 | wps 22956.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 8223 | lr 0.000348726 | gnorm 0.735 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 22459
2022-03-06 19:16:55 | INFO | fairseq.trainer | begin training epoch 170
2022-03-06 19:16:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:19:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:19:10 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 13.125 | nll_loss 12.256 | ppl 4890.31 | wps 40114.5 | wpb 510.9 | bsz 1 | num_updates 8272 | best_loss 9.157
2022-03-06 19:19:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8272 updates
2022-03-06 19:19:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:19:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:19:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 170 @ 8272 updates, score 13.125) (writing took 2.508214959874749 seconds)
2022-03-06 19:19:12 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-06 19:19:12 | INFO | train | epoch 170 | loss 2.975 | nll_loss 0.769 | ppl 1.7 | wps 23069.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8272 | lr 0.000347692 | gnorm 0.729 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 22597
2022-03-06 19:19:12 | INFO | fairseq.trainer | begin training epoch 171
2022-03-06 19:19:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:20:28 | INFO | train_inner | epoch 171:     28 / 49 loss=2.973, nll_loss=0.768, ppl=1.7, wps=22945.2, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.722, loss_scale=16, train_wall=241, gb_free=8.8, wall=22672
2022-03-06 19:21:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:21:28 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 13.157 | nll_loss 12.294 | ppl 5020.66 | wps 40094.7 | wpb 510.9 | bsz 1 | num_updates 8321 | best_loss 9.157
2022-03-06 19:21:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8321 updates
2022-03-06 19:21:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:21:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:21:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 171 @ 8321 updates, score 13.157) (writing took 2.5080193770118058 seconds)
2022-03-06 19:21:30 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-06 19:21:30 | INFO | train | epoch 171 | loss 2.968 | nll_loss 0.763 | ppl 1.7 | wps 23036.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8321 | lr 0.000346667 | gnorm 0.718 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 22735
2022-03-06 19:21:30 | INFO | fairseq.trainer | begin training epoch 172
2022-03-06 19:21:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:23:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:23:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:23:46 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 13.102 | nll_loss 12.233 | ppl 4812.97 | wps 40528.7 | wpb 510.9 | bsz 1 | num_updates 8369 | best_loss 9.157
2022-03-06 19:23:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8369 updates
2022-03-06 19:23:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:23:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:23:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 172 @ 8369 updates, score 13.102) (writing took 2.4340844159014523 seconds)
2022-03-06 19:23:48 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-06 19:23:48 | INFO | train | epoch 172 | loss 2.963 | nll_loss 0.759 | ppl 1.69 | wps 22584.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 8369 | lr 0.000345671 | gnorm 0.708 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 22873
2022-03-06 19:23:48 | INFO | fairseq.trainer | begin training epoch 173
2022-03-06 19:23:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:25:11 | INFO | train_inner | epoch 173:     31 / 49 loss=2.964, nll_loss=0.759, ppl=1.69, wps=22864.6, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.716, loss_scale=16, train_wall=242, gb_free=8.8, wall=22956
2022-03-06 19:25:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:26:04 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 13.222 | nll_loss 12.371 | ppl 5295.47 | wps 39659.2 | wpb 510.9 | bsz 1 | num_updates 8418 | best_loss 9.157
2022-03-06 19:26:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8418 updates
2022-03-06 19:26:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:26:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:26:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 173 @ 8418 updates, score 13.222) (writing took 2.3964550881646574 seconds)
2022-03-06 19:26:06 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-06 19:26:06 | INFO | train | epoch 173 | loss 2.96 | nll_loss 0.756 | ppl 1.69 | wps 23046.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8418 | lr 0.000344664 | gnorm 0.72 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23011
2022-03-06 19:26:06 | INFO | fairseq.trainer | begin training epoch 174
2022-03-06 19:26:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:28:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:28:21 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 13.197 | nll_loss 12.345 | ppl 5201.13 | wps 40299.1 | wpb 510.9 | bsz 1 | num_updates 8467 | best_loss 9.157
2022-03-06 19:28:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8467 updates
2022-03-06 19:28:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:28:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:28:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 174 @ 8467 updates, score 13.197) (writing took 2.524512612260878 seconds)
2022-03-06 19:28:24 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-06 19:28:24 | INFO | train | epoch 174 | loss 2.953 | nll_loss 0.748 | ppl 1.68 | wps 23053.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8467 | lr 0.000343665 | gnorm 0.698 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23149
2022-03-06 19:28:24 | INFO | fairseq.trainer | begin training epoch 175
2022-03-06 19:28:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:29:52 | INFO | train_inner | epoch 175:     33 / 49 loss=2.953, nll_loss=0.749, ppl=1.68, wps=23081.9, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.708, loss_scale=32, train_wall=239, gb_free=8.8, wall=23237
2022-03-06 19:30:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:30:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:30:39 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 13.208 | nll_loss 12.357 | ppl 5246.45 | wps 40058.1 | wpb 510.9 | bsz 1 | num_updates 8515 | best_loss 9.157
2022-03-06 19:30:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8515 updates
2022-03-06 19:30:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:30:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:30:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 175 @ 8515 updates, score 13.208) (writing took 2.4204982789233327 seconds)
2022-03-06 19:30:42 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-06 19:30:42 | INFO | train | epoch 175 | loss 2.949 | nll_loss 0.745 | ppl 1.68 | wps 22607.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 8515 | lr 0.000342695 | gnorm 0.715 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23286
2022-03-06 19:30:42 | INFO | fairseq.trainer | begin training epoch 176
2022-03-06 19:30:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:32:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:32:57 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 13.198 | nll_loss 12.358 | ppl 5247.99 | wps 39616.2 | wpb 510.9 | bsz 1 | num_updates 8564 | best_loss 9.157
2022-03-06 19:32:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8564 updates
2022-03-06 19:32:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:32:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:32:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 176 @ 8564 updates, score 13.198) (writing took 2.4229020113125443 seconds)
2022-03-06 19:32:59 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-06 19:32:59 | INFO | train | epoch 176 | loss 2.946 | nll_loss 0.741 | ppl 1.67 | wps 23062.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8564 | lr 0.000341713 | gnorm 0.715 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23424
2022-03-06 19:32:59 | INFO | fairseq.trainer | begin training epoch 177
2022-03-06 19:32:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:34:36 | INFO | train_inner | epoch 177:     36 / 49 loss=2.945, nll_loss=0.74, ppl=1.67, wps=22887.5, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.71, loss_scale=16, train_wall=242, gb_free=8.8, wall=23521
2022-03-06 19:35:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:35:15 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 13.133 | nll_loss 12.275 | ppl 4954.55 | wps 40638.4 | wpb 510.9 | bsz 1 | num_updates 8613 | best_loss 9.157
2022-03-06 19:35:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8613 updates
2022-03-06 19:35:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:35:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:35:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 177 @ 8613 updates, score 13.133) (writing took 2.5408356469124556 seconds)
2022-03-06 19:35:17 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-06 19:35:17 | INFO | train | epoch 177 | loss 2.941 | nll_loss 0.737 | ppl 1.67 | wps 23075.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8613 | lr 0.00034074 | gnorm 0.708 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23562
2022-03-06 19:35:17 | INFO | fairseq.trainer | begin training epoch 178
2022-03-06 19:35:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:37:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:37:32 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 13.06 | nll_loss 12.191 | ppl 4674.29 | wps 40217.9 | wpb 510.9 | bsz 1 | num_updates 8662 | best_loss 9.157
2022-03-06 19:37:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8662 updates
2022-03-06 19:37:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:37:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:37:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 178 @ 8662 updates, score 13.06) (writing took 2.554405791219324 seconds)
2022-03-06 19:37:35 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-06 19:37:35 | INFO | train | epoch 178 | loss 2.935 | nll_loss 0.731 | ppl 1.66 | wps 23073.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8662 | lr 0.000339775 | gnorm 0.702 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 23700
2022-03-06 19:37:35 | INFO | fairseq.trainer | begin training epoch 179
2022-03-06 19:37:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:38:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:39:19 | INFO | train_inner | epoch 179:     39 / 49 loss=2.934, nll_loss=0.73, ppl=1.66, wps=22912.4, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.703, loss_scale=16, train_wall=241, gb_free=8.8, wall=23804
2022-03-06 19:39:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:39:50 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 13.098 | nll_loss 12.239 | ppl 4833.46 | wps 40016 | wpb 510.9 | bsz 1 | num_updates 8710 | best_loss 9.157
2022-03-06 19:39:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8710 updates
2022-03-06 19:39:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:39:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:39:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 179 @ 8710 updates, score 13.098) (writing took 2.4943267852067947 seconds)
2022-03-06 19:39:52 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-06 19:39:52 | INFO | train | epoch 179 | loss 2.929 | nll_loss 0.725 | ppl 1.65 | wps 22645.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 8710 | lr 0.000338837 | gnorm 0.692 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23837
2022-03-06 19:39:52 | INFO | fairseq.trainer | begin training epoch 180
2022-03-06 19:39:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:42:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:42:05 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 13.147 | nll_loss 12.294 | ppl 5021.55 | wps 42236.6 | wpb 510.9 | bsz 1 | num_updates 8759 | best_loss 9.157
2022-03-06 19:42:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8759 updates
2022-03-06 19:42:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:42:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:42:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 180 @ 8759 updates, score 13.147) (writing took 2.445457756984979 seconds)
2022-03-06 19:42:08 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-06 19:42:08 | INFO | train | epoch 180 | loss 2.925 | nll_loss 0.722 | ppl 1.65 | wps 23510.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8759 | lr 0.000337888 | gnorm 0.679 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 23972
2022-03-06 19:42:08 | INFO | fairseq.trainer | begin training epoch 181
2022-03-06 19:42:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:43:55 | INFO | train_inner | epoch 181:     41 / 49 loss=2.924, nll_loss=0.721, ppl=1.65, wps=23519.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.674, loss_scale=16, train_wall=235, gb_free=8.8, wall=24079
2022-03-06 19:44:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:44:20 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 13.282 | nll_loss 12.449 | ppl 5590.14 | wps 41679.7 | wpb 510.9 | bsz 1 | num_updates 8808 | best_loss 9.157
2022-03-06 19:44:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8808 updates
2022-03-06 19:44:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:44:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:44:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 181 @ 8808 updates, score 13.282) (writing took 2.432383534964174 seconds)
2022-03-06 19:44:22 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-06 19:44:22 | INFO | train | epoch 181 | loss 2.921 | nll_loss 0.718 | ppl 1.65 | wps 23638.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8808 | lr 0.000336947 | gnorm 0.671 | loss_scale 16 | train_wall 114 | gb_free 8.8 | wall 24107
2022-03-06 19:44:22 | INFO | fairseq.trainer | begin training epoch 182
2022-03-06 19:44:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:46:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:46:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:46:34 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 13.114 | nll_loss 12.273 | ppl 4949.91 | wps 41479.7 | wpb 510.9 | bsz 1 | num_updates 8856 | best_loss 9.157
2022-03-06 19:46:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8856 updates
2022-03-06 19:46:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:46:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:46:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 182 @ 8856 updates, score 13.114) (writing took 2.5243523186072707 seconds)
2022-03-06 19:46:37 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-06 19:46:37 | INFO | train | epoch 182 | loss 2.919 | nll_loss 0.716 | ppl 1.64 | wps 23098.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 8856 | lr 0.000336032 | gnorm 0.692 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 24241
2022-03-06 19:46:37 | INFO | fairseq.trainer | begin training epoch 183
2022-03-06 19:46:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:48:32 | INFO | train_inner | epoch 183:     44 / 49 loss=2.917, nll_loss=0.714, ppl=1.64, wps=23377.8, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.682, loss_scale=16, train_wall=236, gb_free=8.8, wall=24357
2022-03-06 19:48:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:48:49 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 13.237 | nll_loss 12.395 | ppl 5384.24 | wps 41184 | wpb 510.9 | bsz 1 | num_updates 8905 | best_loss 9.157
2022-03-06 19:48:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8905 updates
2022-03-06 19:48:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:48:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:48:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 183 @ 8905 updates, score 13.237) (writing took 2.3810512218624353 seconds)
2022-03-06 19:48:52 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-06 19:48:52 | INFO | train | epoch 183 | loss 2.913 | nll_loss 0.71 | ppl 1.64 | wps 23531.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8905 | lr 0.000335107 | gnorm 0.674 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 24377
2022-03-06 19:48:52 | INFO | fairseq.trainer | begin training epoch 184
2022-03-06 19:48:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:50:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:51:05 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 13.18 | nll_loss 12.345 | ppl 5200.76 | wps 41253.2 | wpb 510.9 | bsz 1 | num_updates 8954 | best_loss 9.157
2022-03-06 19:51:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8954 updates
2022-03-06 19:51:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:51:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:51:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 184 @ 8954 updates, score 13.18) (writing took 2.4434507000260055 seconds)
2022-03-06 19:51:07 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-06 19:51:07 | INFO | train | epoch 184 | loss 2.91 | nll_loss 0.708 | ppl 1.63 | wps 23477.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8954 | lr 0.000334188 | gnorm 0.695 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 24512
2022-03-06 19:51:07 | INFO | fairseq.trainer | begin training epoch 185
2022-03-06 19:51:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:52:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:53:11 | INFO | train_inner | epoch 185:     47 / 49 loss=2.909, nll_loss=0.707, ppl=1.63, wps=23299.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.693, loss_scale=16, train_wall=237, gb_free=8.8, wall=24635
2022-03-06 19:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:53:20 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 13.174 | nll_loss 12.329 | ppl 5145.58 | wps 40526.9 | wpb 510.9 | bsz 1 | num_updates 9002 | best_loss 9.157
2022-03-06 19:53:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9002 updates
2022-03-06 19:53:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:53:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:53:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 185 @ 9002 updates, score 13.174) (writing took 2.457123324275017 seconds)
2022-03-06 19:53:22 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-06 19:53:22 | INFO | train | epoch 185 | loss 2.905 | nll_loss 0.703 | ppl 1.63 | wps 22995.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 9002 | lr 0.000333296 | gnorm 0.687 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 24647
2022-03-06 19:53:22 | INFO | fairseq.trainer | begin training epoch 186
2022-03-06 19:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:55:37 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 13.161 | nll_loss 12.32 | ppl 5114.65 | wps 39917.3 | wpb 510.9 | bsz 1 | num_updates 9051 | best_loss 9.157
2022-03-06 19:55:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9051 updates
2022-03-06 19:55:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:55:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:55:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 186 @ 9051 updates, score 13.161) (writing took 2.3666777736507356 seconds)
2022-03-06 19:55:39 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-06 19:55:39 | INFO | train | epoch 186 | loss 2.9 | nll_loss 0.698 | ppl 1.62 | wps 23207.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9051 | lr 0.000332393 | gnorm 0.663 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 24784
2022-03-06 19:55:39 | INFO | fairseq.trainer | begin training epoch 187
2022-03-06 19:55:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:57:49 | INFO | train_inner | epoch 187:     49 / 49 loss=2.898, nll_loss=0.697, ppl=1.62, wps=23150, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=9100, lr=0.000331497, gnorm=0.664, loss_scale=16, train_wall=238, gb_free=8.8, wall=24914
2022-03-06 19:57:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:57:55 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 13.127 | nll_loss 12.274 | ppl 4952.27 | wps 40052.5 | wpb 510.9 | bsz 1 | num_updates 9100 | best_loss 9.157
2022-03-06 19:57:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9100 updates
2022-03-06 19:57:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:57:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:57:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 187 @ 9100 updates, score 13.127) (writing took 2.4530137819238007 seconds)
2022-03-06 19:57:57 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-06 19:57:57 | INFO | train | epoch 187 | loss 2.896 | nll_loss 0.695 | ppl 1.62 | wps 23032.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9100 | lr 0.000331497 | gnorm 0.663 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 24922
2022-03-06 19:57:57 | INFO | fairseq.trainer | begin training epoch 188
2022-03-06 19:57:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:00:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:00:13 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 13.159 | nll_loss 12.315 | ppl 5096.84 | wps 40384.3 | wpb 510.9 | bsz 1 | num_updates 9149 | best_loss 9.157
2022-03-06 20:00:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9149 updates
2022-03-06 20:00:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:00:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:00:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 188 @ 9149 updates, score 13.159) (writing took 2.4552222662605345 seconds)
2022-03-06 20:00:15 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-06 20:00:15 | INFO | train | epoch 188 | loss 2.893 | nll_loss 0.692 | ppl 1.62 | wps 23089.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9149 | lr 0.000330608 | gnorm 0.664 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 25060
2022-03-06 20:00:15 | INFO | fairseq.trainer | begin training epoch 189
2022-03-06 20:00:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:02:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:02:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:02:31 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 13.142 | nll_loss 12.299 | ppl 5040.33 | wps 39475.4 | wpb 510.9 | bsz 1 | num_updates 9197 | best_loss 9.157
2022-03-06 20:02:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9197 updates
2022-03-06 20:02:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:02:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:02:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 189 @ 9197 updates, score 13.142) (writing took 2.479675816837698 seconds)
2022-03-06 20:02:33 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-06 20:02:33 | INFO | train | epoch 189 | loss 2.89 | nll_loss 0.689 | ppl 1.61 | wps 22539.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 9197 | lr 0.000329744 | gnorm 0.671 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 25198
2022-03-06 20:02:33 | INFO | fairseq.trainer | begin training epoch 190
2022-03-06 20:02:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:02:41 | INFO | train_inner | epoch 190:      3 / 49 loss=2.891, nll_loss=0.69, ppl=1.61, wps=22230.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=9200, lr=0.00032969, gnorm=0.667, loss_scale=16, train_wall=242, gb_free=8.8, wall=25206
2022-03-06 20:04:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:04:48 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 13.236 | nll_loss 12.397 | ppl 5393.85 | wps 40197 | wpb 510.9 | bsz 1 | num_updates 9246 | best_loss 9.157
2022-03-06 20:04:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9246 updates
2022-03-06 20:04:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:04:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:04:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 190 @ 9246 updates, score 13.236) (writing took 2.445870067924261 seconds)
2022-03-06 20:04:51 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-06 20:04:51 | INFO | train | epoch 190 | loss 2.886 | nll_loss 0.685 | ppl 1.61 | wps 23098.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9246 | lr 0.000328869 | gnorm 0.658 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 25335
2022-03-06 20:04:51 | INFO | fairseq.trainer | begin training epoch 191
2022-03-06 20:04:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:07:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:07:06 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 13.153 | nll_loss 12.307 | ppl 5065.7 | wps 40050.8 | wpb 510.9 | bsz 1 | num_updates 9295 | best_loss 9.157
2022-03-06 20:07:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9295 updates
2022-03-06 20:07:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:07:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:07:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 191 @ 9295 updates, score 13.153) (writing took 2.394400385674089 seconds)
2022-03-06 20:07:08 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-06 20:07:08 | INFO | train | epoch 191 | loss 2.883 | nll_loss 0.683 | ppl 1.6 | wps 23102.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9295 | lr 0.000328001 | gnorm 0.668 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 25473
2022-03-06 20:07:08 | INFO | fairseq.trainer | begin training epoch 192
2022-03-06 20:07:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:07:22 | INFO | train_inner | epoch 192:      5 / 49 loss=2.884, nll_loss=0.683, ppl=1.61, wps=23125.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.665, loss_scale=16, train_wall=239, gb_free=8.8, wall=25487
2022-03-06 20:09:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:09:24 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 13.199 | nll_loss 12.355 | ppl 5238.24 | wps 40059.3 | wpb 510.9 | bsz 1 | num_updates 9344 | best_loss 9.157
2022-03-06 20:09:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9344 updates
2022-03-06 20:09:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:09:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:09:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 192 @ 9344 updates, score 13.199) (writing took 2.4945047381334007 seconds)
2022-03-06 20:09:26 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-06 20:09:26 | INFO | train | epoch 192 | loss 2.878 | nll_loss 0.677 | ppl 1.6 | wps 23057.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9344 | lr 0.00032714 | gnorm 0.665 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 25611
2022-03-06 20:09:26 | INFO | fairseq.trainer | begin training epoch 193
2022-03-06 20:09:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:10:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:11:41 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 13.163 | nll_loss 12.32 | ppl 5112.15 | wps 40247.5 | wpb 510.9 | bsz 1 | num_updates 9392 | best_loss 9.157
2022-03-06 20:11:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9392 updates
2022-03-06 20:11:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:11:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:11:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 193 @ 9392 updates, score 13.163) (writing took 2.5290653640404344 seconds)
2022-03-06 20:11:44 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-06 20:11:44 | INFO | train | epoch 193 | loss 2.874 | nll_loss 0.674 | ppl 1.6 | wps 22622 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 9392 | lr 0.000326303 | gnorm 0.65 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 25748
2022-03-06 20:11:44 | INFO | fairseq.trainer | begin training epoch 194
2022-03-06 20:11:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:12:05 | INFO | train_inner | epoch 194:      8 / 49 loss=2.875, nll_loss=0.675, ppl=1.6, wps=22886.4, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.655, loss_scale=16, train_wall=241, gb_free=8.8, wall=25770
2022-03-06 20:13:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:13:59 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 13.093 | nll_loss 12.243 | ppl 4847.32 | wps 40096.6 | wpb 510.9 | bsz 1 | num_updates 9441 | best_loss 9.157
2022-03-06 20:13:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9441 updates
2022-03-06 20:13:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:14:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:14:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 194 @ 9441 updates, score 13.093) (writing took 2.435692156199366 seconds)
2022-03-06 20:14:02 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-06 20:14:02 | INFO | train | epoch 194 | loss 2.871 | nll_loss 0.672 | ppl 1.59 | wps 23039.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9441 | lr 0.000325455 | gnorm 0.657 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 25886
2022-03-06 20:14:02 | INFO | fairseq.trainer | begin training epoch 195
2022-03-06 20:14:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:16:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:16:17 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 13.197 | nll_loss 12.368 | ppl 5285.48 | wps 40027.6 | wpb 510.9 | bsz 1 | num_updates 9490 | best_loss 9.157
2022-03-06 20:16:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9490 updates
2022-03-06 20:16:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:16:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:16:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 195 @ 9490 updates, score 13.197) (writing took 2.5536654191091657 seconds)
2022-03-06 20:16:19 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-06 20:16:19 | INFO | train | epoch 195 | loss 2.867 | nll_loss 0.667 | ppl 1.59 | wps 23103.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9490 | lr 0.000324614 | gnorm 0.652 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 26024
2022-03-06 20:16:19 | INFO | fairseq.trainer | begin training epoch 196
2022-03-06 20:16:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:16:46 | INFO | train_inner | epoch 196:     10 / 49 loss=2.868, nll_loss=0.669, ppl=1.59, wps=23111, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.655, loss_scale=32, train_wall=239, gb_free=8.8, wall=26051
2022-03-06 20:18:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:18:33 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 13.177 | nll_loss 12.34 | ppl 5186.12 | wps 41629.1 | wpb 510.9 | bsz 1 | num_updates 9539 | best_loss 9.157
2022-03-06 20:18:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9539 updates
2022-03-06 20:18:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:18:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:18:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 196 @ 9539 updates, score 13.177) (writing took 2.3926612939685583 seconds)
2022-03-06 20:18:36 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-06 20:18:36 | INFO | train | epoch 196 | loss 2.865 | nll_loss 0.666 | ppl 1.59 | wps 23268.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9539 | lr 0.000323779 | gnorm 0.653 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 26161
2022-03-06 20:18:36 | INFO | fairseq.trainer | begin training epoch 197
2022-03-06 20:18:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:20:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:20:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:20:49 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 13.176 | nll_loss 12.34 | ppl 5183.43 | wps 41385 | wpb 510.9 | bsz 1 | num_updates 9587 | best_loss 9.157
2022-03-06 20:20:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9587 updates
2022-03-06 20:20:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:20:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:20:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 197 @ 9587 updates, score 13.176) (writing took 2.401614136993885 seconds)
2022-03-06 20:20:51 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-06 20:20:51 | INFO | train | epoch 197 | loss 2.859 | nll_loss 0.66 | ppl 1.58 | wps 23000.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 9587 | lr 0.000322967 | gnorm 0.648 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 26296
2022-03-06 20:20:51 | INFO | fairseq.trainer | begin training epoch 198
2022-03-06 20:20:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:21:25 | INFO | train_inner | epoch 198:     13 / 49 loss=2.86, nll_loss=0.661, ppl=1.58, wps=23207, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.648, loss_scale=16, train_wall=238, gb_free=8.8, wall=26330
2022-03-06 20:22:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:23:04 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 13.193 | nll_loss 12.365 | ppl 5276.97 | wps 41902.2 | wpb 510.9 | bsz 1 | num_updates 9636 | best_loss 9.157
2022-03-06 20:23:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9636 updates
2022-03-06 20:23:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:23:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:23:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 198 @ 9636 updates, score 13.193) (writing took 2.4670121199451387 seconds)
2022-03-06 20:23:06 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-06 20:23:06 | INFO | train | epoch 198 | loss 2.856 | nll_loss 0.657 | ppl 1.58 | wps 23495.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9636 | lr 0.000322145 | gnorm 0.643 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 26431
2022-03-06 20:23:06 | INFO | fairseq.trainer | begin training epoch 199
2022-03-06 20:23:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:25:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:25:19 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 13.072 | nll_loss 12.233 | ppl 4814.82 | wps 41379 | wpb 510.9 | bsz 1 | num_updates 9685 | best_loss 9.157
2022-03-06 20:25:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9685 updates
2022-03-06 20:25:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:25:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:25:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 199 @ 9685 updates, score 13.072) (writing took 2.419892725069076 seconds)
2022-03-06 20:25:22 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-06 20:25:22 | INFO | train | epoch 199 | loss 2.854 | nll_loss 0.656 | ppl 1.58 | wps 23499 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9685 | lr 0.000321329 | gnorm 0.645 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 26566
2022-03-06 20:25:22 | INFO | fairseq.trainer | begin training epoch 200
2022-03-06 20:25:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:26:01 | INFO | train_inner | epoch 200:     15 / 49 loss=2.854, nll_loss=0.656, ppl=1.58, wps=23540, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.642, loss_scale=32, train_wall=235, gb_free=8.8, wall=26606
2022-03-06 20:26:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:27:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:27:34 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 13.172 | nll_loss 12.347 | ppl 5209.18 | wps 40528 | wpb 510.9 | bsz 1 | num_updates 9733 | best_loss 9.157
2022-03-06 20:27:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9733 updates
2022-03-06 20:27:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:27:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:27:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 200 @ 9733 updates, score 13.172) (writing took 2.417524306103587 seconds)
2022-03-06 20:27:37 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-06 20:27:37 | INFO | train | epoch 200 | loss 2.85 | nll_loss 0.652 | ppl 1.57 | wps 23041.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 9733 | lr 0.000320536 | gnorm 0.645 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 26701
2022-03-06 20:27:37 | INFO | fairseq.trainer | begin training epoch 201
2022-03-06 20:27:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:29:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:29:50 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 13.211 | nll_loss 12.387 | ppl 5357.98 | wps 41765 | wpb 510.9 | bsz 1 | num_updates 9782 | best_loss 9.157
2022-03-06 20:29:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9782 updates
2022-03-06 20:29:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:29:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:29:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 201 @ 9782 updates, score 13.211) (writing took 2.4065666096284986 seconds)
2022-03-06 20:29:52 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-06 20:29:52 | INFO | train | epoch 201 | loss 2.846 | nll_loss 0.649 | ppl 1.57 | wps 23486.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9782 | lr 0.000319732 | gnorm 0.64 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 26837
2022-03-06 20:29:52 | INFO | fairseq.trainer | begin training epoch 202
2022-03-06 20:29:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:30:39 | INFO | train_inner | epoch 202:     18 / 49 loss=2.846, nll_loss=0.649, ppl=1.57, wps=23301.5, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.642, loss_scale=16, train_wall=237, gb_free=8.8, wall=26884
2022-03-06 20:32:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:32:05 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 13.118 | nll_loss 12.275 | ppl 4955.66 | wps 40061.6 | wpb 510.9 | bsz 1 | num_updates 9831 | best_loss 9.157
2022-03-06 20:32:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9831 updates
2022-03-06 20:32:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:32:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:32:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 202 @ 9831 updates, score 13.118) (writing took 2.4874819931574166 seconds)
2022-03-06 20:32:08 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-06 20:32:08 | INFO | train | epoch 202 | loss 2.843 | nll_loss 0.646 | ppl 1.56 | wps 23389.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9831 | lr 0.000318934 | gnorm 0.627 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 26973
2022-03-06 20:32:08 | INFO | fairseq.trainer | begin training epoch 203
2022-03-06 20:32:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:34:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:34:23 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 13.138 | nll_loss 12.296 | ppl 5029.04 | wps 40348.9 | wpb 510.9 | bsz 1 | num_updates 9880 | best_loss 9.157
2022-03-06 20:34:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9880 updates
2022-03-06 20:34:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:34:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:34:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 203 @ 9880 updates, score 13.138) (writing took 2.502976800315082 seconds)
2022-03-06 20:34:26 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-06 20:34:26 | INFO | train | epoch 203 | loss 2.841 | nll_loss 0.644 | ppl 1.56 | wps 23063.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9880 | lr 0.000318142 | gnorm 0.625 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 27110
2022-03-06 20:34:26 | INFO | fairseq.trainer | begin training epoch 204
2022-03-06 20:34:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:35:19 | INFO | train_inner | epoch 204:     20 / 49 loss=2.841, nll_loss=0.644, ppl=1.56, wps=23179.5, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.626, loss_scale=32, train_wall=238, gb_free=8.8, wall=27164
2022-03-06 20:36:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:36:41 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 13.081 | nll_loss 12.241 | ppl 4842.2 | wps 40255.5 | wpb 510.9 | bsz 1 | num_updates 9929 | best_loss 9.157
2022-03-06 20:36:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9929 updates
2022-03-06 20:36:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:36:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:36:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 204 @ 9929 updates, score 13.081) (writing took 2.504759289789945 seconds)
2022-03-06 20:36:44 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-06 20:36:44 | INFO | train | epoch 204 | loss 2.839 | nll_loss 0.643 | ppl 1.56 | wps 23054.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9929 | lr 0.000317356 | gnorm 0.647 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 27248
2022-03-06 20:36:44 | INFO | fairseq.trainer | begin training epoch 205
2022-03-06 20:36:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:38:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:38:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:38:59 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 13.15 | nll_loss 12.319 | ppl 5110.65 | wps 39886.8 | wpb 510.9 | bsz 1 | num_updates 9977 | best_loss 9.157
2022-03-06 20:38:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9977 updates
2022-03-06 20:38:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:39:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:39:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 205 @ 9977 updates, score 13.15) (writing took 2.394371344242245 seconds)
2022-03-06 20:39:01 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-06 20:39:01 | INFO | train | epoch 205 | loss 2.834 | nll_loss 0.638 | ppl 1.56 | wps 22605.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 9977 | lr 0.000316592 | gnorm 0.624 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 27386
2022-03-06 20:39:01 | INFO | fairseq.trainer | begin training epoch 206
2022-03-06 20:39:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:40:03 | INFO | train_inner | epoch 206:     23 / 49 loss=2.835, nll_loss=0.639, ppl=1.56, wps=22872.7, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.633, loss_scale=32, train_wall=242, gb_free=8.8, wall=27448
2022-03-06 20:41:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:41:17 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 13.163 | nll_loss 12.337 | ppl 5175.48 | wps 39992.6 | wpb 510.9 | bsz 1 | num_updates 10026 | best_loss 9.157
2022-03-06 20:41:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10026 updates
2022-03-06 20:41:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:41:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:41:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 206 @ 10026 updates, score 13.163) (writing took 2.5636122338473797 seconds)
2022-03-06 20:41:19 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-06 20:41:19 | INFO | train | epoch 206 | loss 2.832 | nll_loss 0.635 | ppl 1.55 | wps 23019 | ups 0.35 | wpb 64858.2 | bsz 126.7 | num_updates 10026 | lr 0.000315817 | gnorm 0.628 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 27524
2022-03-06 20:41:19 | INFO | fairseq.trainer | begin training epoch 207
2022-03-06 20:41:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:42:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:43:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:43:34 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 13.229 | nll_loss 12.409 | ppl 5440.27 | wps 40183.9 | wpb 510.9 | bsz 1 | num_updates 10074 | best_loss 9.157
2022-03-06 20:43:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10074 updates
2022-03-06 20:43:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:43:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:43:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 207 @ 10074 updates, score 13.229) (writing took 2.467649848200381 seconds)
2022-03-06 20:43:37 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-06 20:43:37 | INFO | train | epoch 207 | loss 2.828 | nll_loss 0.632 | ppl 1.55 | wps 22613.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 10074 | lr 0.000315064 | gnorm 0.622 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 27662
2022-03-06 20:43:37 | INFO | fairseq.trainer | begin training epoch 208
2022-03-06 20:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:44:47 | INFO | train_inner | epoch 208:     26 / 49 loss=2.829, nll_loss=0.633, ppl=1.55, wps=22873.1, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.626, loss_scale=16, train_wall=242, gb_free=8.8, wall=27731
2022-03-06 20:45:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:45:52 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 13.162 | nll_loss 12.336 | ppl 5169.63 | wps 39749.3 | wpb 510.9 | bsz 1 | num_updates 10123 | best_loss 9.157
2022-03-06 20:45:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10123 updates
2022-03-06 20:45:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:45:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:45:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 208 @ 10123 updates, score 13.162) (writing took 2.4531233441084623 seconds)
2022-03-06 20:45:55 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-06 20:45:55 | INFO | train | epoch 208 | loss 2.827 | nll_loss 0.631 | ppl 1.55 | wps 23060.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10123 | lr 0.000314301 | gnorm 0.625 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 27799
2022-03-06 20:45:55 | INFO | fairseq.trainer | begin training epoch 209
2022-03-06 20:45:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:48:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:48:10 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 13.199 | nll_loss 12.371 | ppl 5296.98 | wps 40734.6 | wpb 510.9 | bsz 1 | num_updates 10172 | best_loss 9.157
2022-03-06 20:48:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10172 updates
2022-03-06 20:48:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:48:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:48:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 209 @ 10172 updates, score 13.199) (writing took 2.5248061162419617 seconds)
2022-03-06 20:48:12 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-06 20:48:12 | INFO | train | epoch 209 | loss 2.824 | nll_loss 0.629 | ppl 1.55 | wps 23078.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10172 | lr 0.000313543 | gnorm 0.624 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 27937
2022-03-06 20:48:12 | INFO | fairseq.trainer | begin training epoch 210
2022-03-06 20:48:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:49:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:49:30 | INFO | train_inner | epoch 210:     29 / 49 loss=2.823, nll_loss=0.628, ppl=1.55, wps=22878.6, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.622, loss_scale=16, train_wall=242, gb_free=8.8, wall=28015
2022-03-06 20:50:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:50:28 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 13.224 | nll_loss 12.404 | ppl 5418.86 | wps 40001.1 | wpb 510.9 | bsz 1 | num_updates 10220 | best_loss 9.157
2022-03-06 20:50:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10220 updates
2022-03-06 20:50:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:50:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:50:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 210 @ 10220 updates, score 13.224) (writing took 2.5383876990526915 seconds)
2022-03-06 20:50:30 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-06 20:50:30 | INFO | train | epoch 210 | loss 2.821 | nll_loss 0.626 | ppl 1.54 | wps 22580.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 10220 | lr 0.000312806 | gnorm 0.633 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 28075
2022-03-06 20:50:30 | INFO | fairseq.trainer | begin training epoch 211
2022-03-06 20:50:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:52:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:52:46 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 13.168 | nll_loss 12.337 | ppl 5173.63 | wps 39925.8 | wpb 510.9 | bsz 1 | num_updates 10269 | best_loss 9.157
2022-03-06 20:52:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10269 updates
2022-03-06 20:52:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:52:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:52:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 211 @ 10269 updates, score 13.168) (writing took 2.4517616401426494 seconds)
2022-03-06 20:52:48 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-06 20:52:48 | INFO | train | epoch 211 | loss 2.818 | nll_loss 0.624 | ppl 1.54 | wps 23074.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10269 | lr 0.000312058 | gnorm 0.637 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 28213
2022-03-06 20:52:48 | INFO | fairseq.trainer | begin training epoch 212
2022-03-06 20:52:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:54:11 | INFO | train_inner | epoch 212:     31 / 49 loss=2.819, nll_loss=0.624, ppl=1.54, wps=23101.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.636, loss_scale=16, train_wall=239, gb_free=8.8, wall=28296
2022-03-06 20:54:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:55:03 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 13.187 | nll_loss 12.37 | ppl 5293.36 | wps 39859.8 | wpb 510.9 | bsz 1 | num_updates 10318 | best_loss 9.157
2022-03-06 20:55:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10318 updates
2022-03-06 20:55:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:55:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:55:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 212 @ 10318 updates, score 13.187) (writing took 2.397524616215378 seconds)
2022-03-06 20:55:06 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-06 20:55:06 | INFO | train | epoch 212 | loss 2.815 | nll_loss 0.62 | ppl 1.54 | wps 23080.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10318 | lr 0.000311317 | gnorm 0.62 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 28350
2022-03-06 20:55:06 | INFO | fairseq.trainer | begin training epoch 213
2022-03-06 20:55:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:57:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:57:20 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 13.167 | nll_loss 12.341 | ppl 5188.87 | wps 40236.1 | wpb 510.9 | bsz 1 | num_updates 10367 | best_loss 9.157
2022-03-06 20:57:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10367 updates
2022-03-06 20:57:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:57:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:57:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 213 @ 10367 updates, score 13.167) (writing took 2.3918623733334243 seconds)
2022-03-06 20:57:22 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-06 20:57:22 | INFO | train | epoch 213 | loss 2.812 | nll_loss 0.618 | ppl 1.53 | wps 23278.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10367 | lr 0.00031058 | gnorm 0.62 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 28487
2022-03-06 20:57:22 | INFO | fairseq.trainer | begin training epoch 214
2022-03-06 20:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:58:50 | INFO | train_inner | epoch 214:     33 / 49 loss=2.811, nll_loss=0.617, ppl=1.53, wps=23216, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.619, loss_scale=32, train_wall=238, gb_free=8.8, wall=28575
2022-03-06 20:59:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:59:37 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 13.108 | nll_loss 12.284 | ppl 4985.79 | wps 40584.6 | wpb 510.9 | bsz 1 | num_updates 10416 | best_loss 9.157
2022-03-06 20:59:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10416 updates
2022-03-06 20:59:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:59:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:59:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 214 @ 10416 updates, score 13.108) (writing took 2.452602656558156 seconds)
2022-03-06 20:59:40 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-06 20:59:40 | INFO | train | epoch 214 | loss 2.808 | nll_loss 0.614 | ppl 1.53 | wps 23144.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10416 | lr 0.000309849 | gnorm 0.616 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 28624
2022-03-06 20:59:40 | INFO | fairseq.trainer | begin training epoch 215
2022-03-06 20:59:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:01:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:01:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:01:55 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 13.178 | nll_loss 12.359 | ppl 5252.68 | wps 40433.7 | wpb 510.9 | bsz 1 | num_updates 10464 | best_loss 9.157
2022-03-06 21:01:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10464 updates
2022-03-06 21:01:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:01:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:01:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 215 @ 10464 updates, score 13.178) (writing took 2.4986971942707896 seconds)
2022-03-06 21:01:57 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-06 21:01:57 | INFO | train | epoch 215 | loss 2.806 | nll_loss 0.612 | ppl 1.53 | wps 22642.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 10464 | lr 0.000309137 | gnorm 0.607 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 28762
2022-03-06 21:01:57 | INFO | fairseq.trainer | begin training epoch 216
2022-03-06 21:01:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:03:33 | INFO | train_inner | epoch 216:     36 / 49 loss=2.805, nll_loss=0.612, ppl=1.53, wps=22940.7, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.606, loss_scale=32, train_wall=241, gb_free=8.8, wall=28858
2022-03-06 21:04:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:04:12 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 13.144 | nll_loss 12.312 | ppl 5084.16 | wps 40516.6 | wpb 510.9 | bsz 1 | num_updates 10513 | best_loss 9.157
2022-03-06 21:04:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10513 updates
2022-03-06 21:04:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:04:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:04:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 216 @ 10513 updates, score 13.144) (writing took 2.5238178810104728 seconds)
2022-03-06 21:04:14 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-06 21:04:14 | INFO | train | epoch 216 | loss 2.803 | nll_loss 0.61 | ppl 1.53 | wps 23127.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10513 | lr 0.000308416 | gnorm 0.612 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 28899
2022-03-06 21:04:14 | INFO | fairseq.trainer | begin training epoch 217
2022-03-06 21:04:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:06:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:06:29 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 13.16 | nll_loss 12.347 | ppl 5210.95 | wps 40445.1 | wpb 510.9 | bsz 1 | num_updates 10562 | best_loss 9.157
2022-03-06 21:06:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10562 updates
2022-03-06 21:06:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:06:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:06:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 217 @ 10562 updates, score 13.16) (writing took 2.4823947148397565 seconds)
2022-03-06 21:06:32 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-06 21:06:32 | INFO | train | epoch 217 | loss 2.801 | nll_loss 0.608 | ppl 1.52 | wps 23110.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10562 | lr 0.0003077 | gnorm 0.609 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 29037
2022-03-06 21:06:32 | INFO | fairseq.trainer | begin training epoch 218
2022-03-06 21:06:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:07:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:08:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:08:18 | INFO | train_inner | epoch 218:     40 / 49 loss=2.8, nll_loss=0.607, ppl=1.52, wps=22736.4, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.612, loss_scale=16, train_wall=243, gb_free=8.8, wall=29143
2022-03-06 21:08:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:08:47 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 13.186 | nll_loss 12.367 | ppl 5282.49 | wps 39774.6 | wpb 510.9 | bsz 1 | num_updates 10609 | best_loss 9.157
2022-03-06 21:08:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10609 updates
2022-03-06 21:08:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:08:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:08:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 218 @ 10609 updates, score 13.186) (writing took 2.4353097421117127 seconds)
2022-03-06 21:08:49 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-06 21:08:49 | INFO | train | epoch 218 | loss 2.798 | nll_loss 0.605 | ppl 1.52 | wps 22222.7 | ups 0.34 | wpb 64829.4 | bsz 126.6 | num_updates 10609 | lr 0.000307017 | gnorm 0.612 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 29174
2022-03-06 21:08:49 | INFO | fairseq.trainer | begin training epoch 219
2022-03-06 21:08:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:10:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:11:04 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 13.191 | nll_loss 12.376 | ppl 5314.84 | wps 39745.1 | wpb 510.9 | bsz 1 | num_updates 10658 | best_loss 9.157
2022-03-06 21:11:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10658 updates
2022-03-06 21:11:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:11:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:11:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 219 @ 10658 updates, score 13.191) (writing took 2.4987588860094547 seconds)
2022-03-06 21:11:06 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-06 21:11:06 | INFO | train | epoch 219 | loss 2.795 | nll_loss 0.603 | ppl 1.52 | wps 23126.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10658 | lr 0.000306311 | gnorm 0.596 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 29311
2022-03-06 21:11:06 | INFO | fairseq.trainer | begin training epoch 220
2022-03-06 21:11:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:12:59 | INFO | train_inner | epoch 220:     42 / 49 loss=2.796, nll_loss=0.604, ppl=1.52, wps=23152.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.605, loss_scale=16, train_wall=239, gb_free=8.8, wall=29423
2022-03-06 21:13:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:13:21 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 13.222 | nll_loss 12.404 | ppl 5421.38 | wps 40504.5 | wpb 510.9 | bsz 1 | num_updates 10707 | best_loss 9.157
2022-03-06 21:13:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10707 updates
2022-03-06 21:13:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:13:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:13:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 220 @ 10707 updates, score 13.222) (writing took 2.4439271902665496 seconds)
2022-03-06 21:13:24 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-06 21:13:24 | INFO | train | epoch 220 | loss 2.794 | nll_loss 0.602 | ppl 1.52 | wps 23128.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10707 | lr 0.000305609 | gnorm 0.607 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 29449
2022-03-06 21:13:24 | INFO | fairseq.trainer | begin training epoch 221
2022-03-06 21:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:15:39 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 13.339 | nll_loss 12.535 | ppl 5936.85 | wps 39549.6 | wpb 510.9 | bsz 1 | num_updates 10756 | best_loss 9.157
2022-03-06 21:15:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10756 updates
2022-03-06 21:15:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:15:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:15:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 221 @ 10756 updates, score 13.339) (writing took 2.4068542206659913 seconds)
2022-03-06 21:15:41 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-06 21:15:41 | INFO | train | epoch 221 | loss 2.791 | nll_loss 0.599 | ppl 1.51 | wps 23107.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10756 | lr 0.000304912 | gnorm 0.6 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 29586
2022-03-06 21:15:41 | INFO | fairseq.trainer | begin training epoch 222
2022-03-06 21:15:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:17:39 | INFO | train_inner | epoch 222:     44 / 49 loss=2.79, nll_loss=0.598, ppl=1.51, wps=23153.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.598, loss_scale=32, train_wall=239, gb_free=8.8, wall=29704
2022-03-06 21:17:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:17:56 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 13.161 | nll_loss 12.343 | ppl 5194.24 | wps 40863.3 | wpb 510.9 | bsz 1 | num_updates 10805 | best_loss 9.157
2022-03-06 21:17:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10805 updates
2022-03-06 21:17:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:17:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:17:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 222 @ 10805 updates, score 13.161) (writing took 2.5521817449480295 seconds)
2022-03-06 21:17:59 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-06 21:17:59 | INFO | train | epoch 222 | loss 2.788 | nll_loss 0.596 | ppl 1.51 | wps 23140 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10805 | lr 0.00030422 | gnorm 0.598 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 29724
2022-03-06 21:17:59 | INFO | fairseq.trainer | begin training epoch 223
2022-03-06 21:17:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:19:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:20:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:20:13 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 13.099 | nll_loss 12.288 | ppl 5001.22 | wps 41157.7 | wpb 510.9 | bsz 1 | num_updates 10853 | best_loss 9.157
2022-03-06 21:20:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10853 updates
2022-03-06 21:20:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:20:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:20:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 223 @ 10853 updates, score 13.099) (writing took 2.462998177856207 seconds)
2022-03-06 21:20:16 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-06 21:20:16 | INFO | train | epoch 223 | loss 2.786 | nll_loss 0.594 | ppl 1.51 | wps 22692.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 10853 | lr 0.000303546 | gnorm 0.594 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 29861
2022-03-06 21:20:16 | INFO | fairseq.trainer | begin training epoch 224
2022-03-06 21:20:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:22:20 | INFO | train_inner | epoch 224:     47 / 49 loss=2.787, nll_loss=0.595, ppl=1.51, wps=23095, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=10900, lr=0.000302891, gnorm=0.606, loss_scale=16, train_wall=239, gb_free=8.8, wall=29984
2022-03-06 21:22:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:22:29 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 13.209 | nll_loss 12.396 | ppl 5389.36 | wps 41951.1 | wpb 510.9 | bsz 1 | num_updates 10902 | best_loss 9.157
2022-03-06 21:22:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10902 updates
2022-03-06 21:22:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:22:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:22:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 224 @ 10902 updates, score 13.209) (writing took 2.466746608261019 seconds)
2022-03-06 21:22:31 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-06 21:22:31 | INFO | train | epoch 224 | loss 2.786 | nll_loss 0.596 | ppl 1.51 | wps 23468.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10902 | lr 0.000302863 | gnorm 0.618 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 29996
2022-03-06 21:22:31 | INFO | fairseq.trainer | begin training epoch 225
2022-03-06 21:22:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:24:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:24:43 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 13.252 | nll_loss 12.45 | ppl 5593.91 | wps 42239.3 | wpb 510.9 | bsz 1 | num_updates 10951 | best_loss 9.157
2022-03-06 21:24:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10951 updates
2022-03-06 21:24:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:24:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:24:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 225 @ 10951 updates, score 13.252) (writing took 2.4291707510128617 seconds)
2022-03-06 21:24:46 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-06 21:24:46 | INFO | train | epoch 225 | loss 2.782 | nll_loss 0.591 | ppl 1.51 | wps 23645 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10951 | lr 0.000302185 | gnorm 0.597 | loss_scale 16 | train_wall 114 | gb_free 8.8 | wall 30130
2022-03-06 21:24:46 | INFO | fairseq.trainer | begin training epoch 226
2022-03-06 21:24:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:26:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:26:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:26:58 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 13.146 | nll_loss 12.332 | ppl 5154.67 | wps 41480.5 | wpb 510.9 | bsz 1 | num_updates 10999 | best_loss 9.157
2022-03-06 21:26:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 10999 updates
2022-03-06 21:26:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:27:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:27:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 226 @ 10999 updates, score 13.146) (writing took 2.4216124480590224 seconds)
2022-03-06 21:27:01 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-06 21:27:01 | INFO | train | epoch 226 | loss 2.779 | nll_loss 0.588 | ppl 1.5 | wps 23076.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 10999 | lr 0.000301525 | gnorm 0.589 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 30265
2022-03-06 21:27:01 | INFO | fairseq.trainer | begin training epoch 227
2022-03-06 21:27:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:27:03 | INFO | train_inner | epoch 227:      1 / 49 loss=2.78, nll_loss=0.59, ppl=1.5, wps=22753.2, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=11000, lr=0.000301511, gnorm=0.595, loss_scale=16, train_wall=235, gb_free=8.8, wall=30268
2022-03-06 21:29:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:29:13 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 13.199 | nll_loss 12.391 | ppl 5372.62 | wps 41539.8 | wpb 510.9 | bsz 1 | num_updates 11048 | best_loss 9.157
2022-03-06 21:29:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11048 updates
2022-03-06 21:29:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:29:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:29:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 227 @ 11048 updates, score 13.199) (writing took 2.467187715228647 seconds)
2022-03-06 21:29:16 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-06 21:29:16 | INFO | train | epoch 227 | loss 2.777 | nll_loss 0.587 | ppl 1.5 | wps 23504.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11048 | lr 0.000300856 | gnorm 0.596 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 30401
2022-03-06 21:29:16 | INFO | fairseq.trainer | begin training epoch 228
2022-03-06 21:29:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:31:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:31:29 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 13.262 | nll_loss 12.456 | ppl 5617.38 | wps 41293.5 | wpb 510.9 | bsz 1 | num_updates 11097 | best_loss 9.157
2022-03-06 21:31:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11097 updates
2022-03-06 21:31:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:31:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:31:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 228 @ 11097 updates, score 13.262) (writing took 2.4083431027829647 seconds)
2022-03-06 21:31:31 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-06 21:31:31 | INFO | train | epoch 228 | loss 2.775 | nll_loss 0.585 | ppl 1.5 | wps 23524.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11097 | lr 0.000300191 | gnorm 0.598 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 30536
2022-03-06 21:31:31 | INFO | fairseq.trainer | begin training epoch 229
2022-03-06 21:31:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:31:39 | INFO | train_inner | epoch 229:      3 / 49 loss=2.776, nll_loss=0.586, ppl=1.5, wps=23540.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=11100, lr=0.00030015, gnorm=0.597, loss_scale=16, train_wall=235, gb_free=8.8, wall=30544
2022-03-06 21:33:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:33:44 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 13.138 | nll_loss 12.314 | ppl 5090.55 | wps 41324.5 | wpb 510.9 | bsz 1 | num_updates 11146 | best_loss 9.157
2022-03-06 21:33:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11146 updates
2022-03-06 21:33:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:33:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:33:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 229 @ 11146 updates, score 13.138) (writing took 2.3721018941141665 seconds)
2022-03-06 21:33:46 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-06 21:33:46 | INFO | train | epoch 229 | loss 2.772 | nll_loss 0.582 | ppl 1.5 | wps 23497.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11146 | lr 0.00029953 | gnorm 0.581 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 30671
2022-03-06 21:33:46 | INFO | fairseq.trainer | begin training epoch 230
2022-03-06 21:33:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:34:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:35:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:36:01 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 13.195 | nll_loss 12.394 | ppl 5383.98 | wps 40382 | wpb 510.9 | bsz 1 | num_updates 11194 | best_loss 9.157
2022-03-06 21:36:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11194 updates
2022-03-06 21:36:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:36:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:36:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 230 @ 11194 updates, score 13.195) (writing took 2.502385779283941 seconds)
2022-03-06 21:36:03 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-06 21:36:03 | INFO | train | epoch 230 | loss 2.77 | nll_loss 0.581 | ppl 1.5 | wps 22711.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 11194 | lr 0.000298887 | gnorm 0.592 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 30808
2022-03-06 21:36:03 | INFO | fairseq.trainer | begin training epoch 231
2022-03-06 21:36:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:36:19 | INFO | train_inner | epoch 231:      6 / 49 loss=2.77, nll_loss=0.581, ppl=1.5, wps=23140.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.586, loss_scale=16, train_wall=239, gb_free=8.8, wall=30824
2022-03-06 21:38:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:38:18 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 13.161 | nll_loss 12.35 | ppl 5220.39 | wps 40178 | wpb 510.9 | bsz 1 | num_updates 11243 | best_loss 9.157
2022-03-06 21:38:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11243 updates
2022-03-06 21:38:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:38:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:38:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 231 @ 11243 updates, score 13.161) (writing took 2.484413019847125 seconds)
2022-03-06 21:38:21 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-06 21:38:21 | INFO | train | epoch 231 | loss 2.766 | nll_loss 0.577 | ppl 1.49 | wps 23092.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11243 | lr 0.000298235 | gnorm 0.576 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 30946
2022-03-06 21:38:21 | INFO | fairseq.trainer | begin training epoch 232
2022-03-06 21:38:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:40:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:40:36 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 13.269 | nll_loss 12.473 | ppl 5685.65 | wps 39948.5 | wpb 510.9 | bsz 1 | num_updates 11292 | best_loss 9.157
2022-03-06 21:40:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11292 updates
2022-03-06 21:40:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:40:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:40:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 232 @ 11292 updates, score 13.269) (writing took 2.436968179885298 seconds)
2022-03-06 21:40:38 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-06 21:40:38 | INFO | train | epoch 232 | loss 2.766 | nll_loss 0.577 | ppl 1.49 | wps 23096.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11292 | lr 0.000297587 | gnorm 0.588 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 31083
2022-03-06 21:40:38 | INFO | fairseq.trainer | begin training epoch 233
2022-03-06 21:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:41:00 | INFO | train_inner | epoch 233:      8 / 49 loss=2.765, nll_loss=0.576, ppl=1.49, wps=23107.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.58, loss_scale=32, train_wall=239, gb_free=8.8, wall=31105
2022-03-06 21:42:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:42:54 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 13.181 | nll_loss 12.368 | ppl 5284.94 | wps 40164.2 | wpb 510.9 | bsz 1 | num_updates 11341 | best_loss 9.157
2022-03-06 21:42:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11341 updates
2022-03-06 21:42:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:42:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:42:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 233 @ 11341 updates, score 13.181) (writing took 2.3859225627966225 seconds)
2022-03-06 21:42:56 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-06 21:42:56 | INFO | train | epoch 233 | loss 2.763 | nll_loss 0.575 | ppl 1.49 | wps 23092.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11341 | lr 0.000296944 | gnorm 0.581 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 31221
2022-03-06 21:42:56 | INFO | fairseq.trainer | begin training epoch 234
2022-03-06 21:42:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:45:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:45:11 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 13.221 | nll_loss 12.415 | ppl 5462.19 | wps 39815.6 | wpb 510.9 | bsz 1 | num_updates 11390 | best_loss 9.157
2022-03-06 21:45:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11390 updates
2022-03-06 21:45:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:45:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:45:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 234 @ 11390 updates, score 13.221) (writing took 2.4962720279581845 seconds)
2022-03-06 21:45:14 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-06 21:45:14 | INFO | train | epoch 234 | loss 2.76 | nll_loss 0.572 | ppl 1.49 | wps 23077.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11390 | lr 0.000296304 | gnorm 0.574 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 31359
2022-03-06 21:45:14 | INFO | fairseq.trainer | begin training epoch 235
2022-03-06 21:45:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:45:41 | INFO | train_inner | epoch 235:     10 / 49 loss=2.762, nll_loss=0.573, ppl=1.49, wps=23121.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.578, loss_scale=32, train_wall=239, gb_free=8.8, wall=31385
2022-03-06 21:46:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:47:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:47:29 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 13.153 | nll_loss 12.345 | ppl 5202.68 | wps 40451.2 | wpb 510.9 | bsz 1 | num_updates 11438 | best_loss 9.157
2022-03-06 21:47:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11438 updates
2022-03-06 21:47:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:47:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:47:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 235 @ 11438 updates, score 13.153) (writing took 2.6069043367169797 seconds)
2022-03-06 21:47:32 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-06 21:47:32 | INFO | train | epoch 235 | loss 2.758 | nll_loss 0.57 | ppl 1.48 | wps 22594.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 11438 | lr 0.000295682 | gnorm 0.565 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 31496
2022-03-06 21:47:32 | INFO | fairseq.trainer | begin training epoch 236
2022-03-06 21:47:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:49:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:49:47 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 13.272 | nll_loss 12.468 | ppl 5663.76 | wps 40147.1 | wpb 510.9 | bsz 1 | num_updates 11487 | best_loss 9.157
2022-03-06 21:49:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11487 updates
2022-03-06 21:49:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:49:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:49:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 236 @ 11487 updates, score 13.272) (writing took 2.451695845928043 seconds)
2022-03-06 21:49:49 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-06 21:49:49 | INFO | train | epoch 236 | loss 2.758 | nll_loss 0.57 | ppl 1.48 | wps 23060.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11487 | lr 0.000295051 | gnorm 0.576 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 31634
2022-03-06 21:49:49 | INFO | fairseq.trainer | begin training epoch 237
2022-03-06 21:49:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:50:24 | INFO | train_inner | epoch 237:     13 / 49 loss=2.757, nll_loss=0.57, ppl=1.48, wps=22867.7, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.572, loss_scale=32, train_wall=242, gb_free=8.8, wall=31669
2022-03-06 21:51:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:52:05 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 13.286 | nll_loss 12.493 | ppl 5763.82 | wps 40486.8 | wpb 510.9 | bsz 1 | num_updates 11536 | best_loss 9.157
2022-03-06 21:52:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11536 updates
2022-03-06 21:52:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:52:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:52:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 237 @ 11536 updates, score 13.286) (writing took 2.5501838698983192 seconds)
2022-03-06 21:52:07 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-06 21:52:07 | INFO | train | epoch 237 | loss 2.754 | nll_loss 0.567 | ppl 1.48 | wps 23076 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11536 | lr 0.000294423 | gnorm 0.574 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 31772
2022-03-06 21:52:07 | INFO | fairseq.trainer | begin training epoch 238
2022-03-06 21:52:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:52:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:54:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:54:22 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 13.143 | nll_loss 12.329 | ppl 5145.9 | wps 40219 | wpb 510.9 | bsz 1 | num_updates 11584 | best_loss 9.157
2022-03-06 21:54:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11584 updates
2022-03-06 21:54:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:54:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:54:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 238 @ 11584 updates, score 13.143) (writing took 2.5007700962014496 seconds)
2022-03-06 21:54:25 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-06 21:54:25 | INFO | train | epoch 238 | loss 2.753 | nll_loss 0.566 | ppl 1.48 | wps 22611.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 11584 | lr 0.000293813 | gnorm 0.582 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 31909
2022-03-06 21:54:25 | INFO | fairseq.trainer | begin training epoch 239
2022-03-06 21:54:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:55:08 | INFO | train_inner | epoch 239:     16 / 49 loss=2.753, nll_loss=0.566, ppl=1.48, wps=22903.4, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.577, loss_scale=32, train_wall=241, gb_free=8.8, wall=31952
2022-03-06 21:56:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:56:40 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 13.166 | nll_loss 12.357 | ppl 5247.54 | wps 39631.1 | wpb 510.9 | bsz 1 | num_updates 11633 | best_loss 9.157
2022-03-06 21:56:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11633 updates
2022-03-06 21:56:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:56:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:56:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 239 @ 11633 updates, score 13.166) (writing took 2.3757508359849453 seconds)
2022-03-06 21:56:42 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-06 21:56:42 | INFO | train | epoch 239 | loss 2.752 | nll_loss 0.565 | ppl 1.48 | wps 23118.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11633 | lr 0.000293193 | gnorm 0.589 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 32047
2022-03-06 21:56:42 | INFO | fairseq.trainer | begin training epoch 240
2022-03-06 21:56:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:58:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:58:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:58:57 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 13.182 | nll_loss 12.371 | ppl 5298.97 | wps 41490.8 | wpb 510.9 | bsz 1 | num_updates 11681 | best_loss 9.157
2022-03-06 21:58:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11681 updates
2022-03-06 21:58:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:58:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:58:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 240 @ 11681 updates, score 13.182) (writing took 2.4696363578550518 seconds)
2022-03-06 21:58:59 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-06 21:58:59 | INFO | train | epoch 240 | loss 2.748 | nll_loss 0.562 | ppl 1.48 | wps 22750.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 11681 | lr 0.00029259 | gnorm 0.565 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 32184
2022-03-06 21:58:59 | INFO | fairseq.trainer | begin training epoch 241
2022-03-06 21:58:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:59:49 | INFO | train_inner | epoch 241:     19 / 49 loss=2.749, nll_loss=0.563, ppl=1.48, wps=23048, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.578, loss_scale=32, train_wall=240, gb_free=8.8, wall=32234
2022-03-06 22:00:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:01:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:01:12 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 13.2 | nll_loss 12.397 | ppl 5393.39 | wps 41089.4 | wpb 510.9 | bsz 1 | num_updates 11729 | best_loss 9.157
2022-03-06 22:01:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11729 updates
2022-03-06 22:01:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:01:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:01:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 241 @ 11729 updates, score 13.2) (writing took 2.335205121897161 seconds)
2022-03-06 22:01:14 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-06 22:01:14 | INFO | train | epoch 241 | loss 2.747 | nll_loss 0.561 | ppl 1.48 | wps 23025.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 11729 | lr 0.000291991 | gnorm 0.588 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 32319
2022-03-06 22:01:14 | INFO | fairseq.trainer | begin training epoch 242
2022-03-06 22:01:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:03:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:03:27 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 13.18 | nll_loss 12.374 | ppl 5307.06 | wps 42934.5 | wpb 510.9 | bsz 1 | num_updates 11778 | best_loss 9.157
2022-03-06 22:03:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11778 updates
2022-03-06 22:03:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:03:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:03:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 242 @ 11778 updates, score 13.18) (writing took 2.5040666689164937 seconds)
2022-03-06 22:03:29 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-06 22:03:29 | INFO | train | epoch 242 | loss 2.744 | nll_loss 0.558 | ppl 1.47 | wps 23561.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11778 | lr 0.000291383 | gnorm 0.564 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 32454
2022-03-06 22:03:29 | INFO | fairseq.trainer | begin training epoch 243
2022-03-06 22:03:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:04:26 | INFO | train_inner | epoch 243:     22 / 49 loss=2.744, nll_loss=0.559, ppl=1.47, wps=23386.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.575, loss_scale=16, train_wall=237, gb_free=8.8, wall=32511
2022-03-06 22:05:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:05:41 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 13.106 | nll_loss 12.297 | ppl 5033.4 | wps 41725.4 | wpb 510.9 | bsz 1 | num_updates 11827 | best_loss 9.157
2022-03-06 22:05:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11827 updates
2022-03-06 22:05:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:05:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:05:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 243 @ 11827 updates, score 13.106) (writing took 2.402177487965673 seconds)
2022-03-06 22:05:43 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-06 22:05:43 | INFO | train | epoch 243 | loss 2.742 | nll_loss 0.557 | ppl 1.47 | wps 23660.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11827 | lr 0.000290779 | gnorm 0.571 | loss_scale 16 | train_wall 114 | gb_free 8.8 | wall 32588
2022-03-06 22:05:43 | INFO | fairseq.trainer | begin training epoch 244
2022-03-06 22:05:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:07:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:07:56 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 13.218 | nll_loss 12.415 | ppl 5462.93 | wps 42096 | wpb 510.9 | bsz 1 | num_updates 11876 | best_loss 9.157
2022-03-06 22:07:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11876 updates
2022-03-06 22:07:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:07:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:07:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 244 @ 11876 updates, score 13.218) (writing took 2.512100785970688 seconds)
2022-03-06 22:07:58 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-06 22:07:58 | INFO | train | epoch 244 | loss 2.742 | nll_loss 0.557 | ppl 1.47 | wps 23598.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11876 | lr 0.000290178 | gnorm 0.573 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 32723
2022-03-06 22:07:58 | INFO | fairseq.trainer | begin training epoch 245
2022-03-06 22:07:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:09:01 | INFO | train_inner | epoch 245:     24 / 49 loss=2.741, nll_loss=0.555, ppl=1.47, wps=23631.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.566, loss_scale=32, train_wall=234, gb_free=8.8, wall=32786
2022-03-06 22:10:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:10:10 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 13.166 | nll_loss 12.356 | ppl 5241.92 | wps 41705.1 | wpb 510.9 | bsz 1 | num_updates 11925 | best_loss 9.157
2022-03-06 22:10:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11925 updates
2022-03-06 22:10:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:10:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:10:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 245 @ 11925 updates, score 13.166) (writing took 2.3799583530053496 seconds)
2022-03-06 22:10:13 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-06 22:10:13 | INFO | train | epoch 245 | loss 2.738 | nll_loss 0.553 | ppl 1.47 | wps 23619.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11925 | lr 0.000289581 | gnorm 0.557 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 32857
2022-03-06 22:10:13 | INFO | fairseq.trainer | begin training epoch 246
2022-03-06 22:10:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:12:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:12:25 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 13.228 | nll_loss 12.43 | ppl 5519.91 | wps 40069.4 | wpb 510.9 | bsz 1 | num_updates 11973 | best_loss 9.157
2022-03-06 22:12:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11973 updates
2022-03-06 22:12:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:12:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:12:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 246 @ 11973 updates, score 13.228) (writing took 2.4037287128157914 seconds)
2022-03-06 22:12:28 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-06 22:12:28 | INFO | train | epoch 246 | loss 2.736 | nll_loss 0.552 | ppl 1.47 | wps 23037.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 11973 | lr 0.000289 | gnorm 0.565 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 32992
2022-03-06 22:12:28 | INFO | fairseq.trainer | begin training epoch 247
2022-03-06 22:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:13:40 | INFO | train_inner | epoch 247:     27 / 49 loss=2.737, nll_loss=0.552, ppl=1.47, wps=23258, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.56, loss_scale=32, train_wall=238, gb_free=8.8, wall=33065
2022-03-06 22:14:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:14:42 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 13.175 | nll_loss 12.377 | ppl 5319.67 | wps 41158.2 | wpb 510.9 | bsz 1 | num_updates 12022 | best_loss 9.157
2022-03-06 22:14:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12022 updates
2022-03-06 22:14:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:14:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:14:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 247 @ 12022 updates, score 13.175) (writing took 2.4027435551397502 seconds)
2022-03-06 22:14:45 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-06 22:14:45 | INFO | train | epoch 247 | loss 2.736 | nll_loss 0.551 | ppl 1.47 | wps 23201 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12022 | lr 0.000288411 | gnorm 0.563 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 33129
2022-03-06 22:14:45 | INFO | fairseq.trainer | begin training epoch 248
2022-03-06 22:14:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:16:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:17:00 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 13.212 | nll_loss 12.414 | ppl 5456.49 | wps 39792.2 | wpb 510.9 | bsz 1 | num_updates 12071 | best_loss 9.157
2022-03-06 22:17:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12071 updates
2022-03-06 22:17:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:17:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:17:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 248 @ 12071 updates, score 13.212) (writing took 2.6109124501235783 seconds)
2022-03-06 22:17:02 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-06 22:17:02 | INFO | train | epoch 248 | loss 2.733 | nll_loss 0.549 | ppl 1.46 | wps 23104.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12071 | lr 0.000287825 | gnorm 0.557 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 33267
2022-03-06 22:17:02 | INFO | fairseq.trainer | begin training epoch 249
2022-03-06 22:17:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:18:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:18:22 | INFO | train_inner | epoch 249:     30 / 49 loss=2.733, nll_loss=0.549, ppl=1.46, wps=22985.6, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.565, loss_scale=32, train_wall=240, gb_free=8.8, wall=33347
2022-03-06 22:19:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:19:17 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 13.211 | nll_loss 12.412 | ppl 5448.29 | wps 41018.9 | wpb 510.9 | bsz 1 | num_updates 12119 | best_loss 9.157
2022-03-06 22:19:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12119 updates
2022-03-06 22:19:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:19:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:19:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 249 @ 12119 updates, score 13.211) (writing took 2.5968759530223906 seconds)
2022-03-06 22:19:19 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-06 22:19:19 | INFO | train | epoch 249 | loss 2.731 | nll_loss 0.547 | ppl 1.46 | wps 22718.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 12119 | lr 0.000287254 | gnorm 0.566 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 33404
2022-03-06 22:19:19 | INFO | fairseq.trainer | begin training epoch 250
2022-03-06 22:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:21:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:21:34 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 13.157 | nll_loss 12.352 | ppl 5226.8 | wps 40861.3 | wpb 510.9 | bsz 1 | num_updates 12168 | best_loss 9.157
2022-03-06 22:21:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12168 updates
2022-03-06 22:21:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:21:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:21:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 250 @ 12168 updates, score 13.157) (writing took 2.411930553149432 seconds)
2022-03-06 22:21:36 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-06 22:21:36 | INFO | train | epoch 250 | loss 2.729 | nll_loss 0.545 | ppl 1.46 | wps 23175.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12168 | lr 0.000286675 | gnorm 0.555 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 33541
2022-03-06 22:21:36 | INFO | fairseq.trainer | begin training epoch 251
2022-03-06 22:21:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:23:02 | INFO | train_inner | epoch 251:     32 / 49 loss=2.729, nll_loss=0.545, ppl=1.46, wps=23208, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.559, loss_scale=32, train_wall=238, gb_free=8.8, wall=33626
2022-03-06 22:23:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:23:51 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 13.269 | nll_loss 12.484 | ppl 5727.62 | wps 40588.6 | wpb 510.9 | bsz 1 | num_updates 12217 | best_loss 9.157
2022-03-06 22:23:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12217 updates
2022-03-06 22:23:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:23:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:23:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 251 @ 12217 updates, score 13.269) (writing took 2.3144784183241427 seconds)
2022-03-06 22:23:53 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-06 22:23:53 | INFO | train | epoch 251 | loss 2.728 | nll_loss 0.544 | ppl 1.46 | wps 23233.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12217 | lr 0.0002861 | gnorm 0.559 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 33678
2022-03-06 22:23:53 | INFO | fairseq.trainer | begin training epoch 252
2022-03-06 22:23:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:24:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:26:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:26:08 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 13.264 | nll_loss 12.477 | ppl 5700.04 | wps 40601.9 | wpb 510.9 | bsz 1 | num_updates 12265 | best_loss 9.157
2022-03-06 22:26:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12265 updates
2022-03-06 22:26:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:26:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:26:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 252 @ 12265 updates, score 13.264) (writing took 2.485348756890744 seconds)
2022-03-06 22:26:10 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-06 22:26:10 | INFO | train | epoch 252 | loss 2.726 | nll_loss 0.543 | ppl 1.46 | wps 22696.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 12265 | lr 0.00028554 | gnorm 0.549 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 33815
2022-03-06 22:26:10 | INFO | fairseq.trainer | begin training epoch 253
2022-03-06 22:26:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:27:43 | INFO | train_inner | epoch 253:     35 / 49 loss=2.726, nll_loss=0.543, ppl=1.46, wps=23019.4, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.549, loss_scale=32, train_wall=240, gb_free=8.8, wall=33908
2022-03-06 22:28:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:28:25 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 13.199 | nll_loss 12.405 | ppl 5422.02 | wps 40546.4 | wpb 510.9 | bsz 1 | num_updates 12314 | best_loss 9.157
2022-03-06 22:28:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12314 updates
2022-03-06 22:28:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:28:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:28:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 253 @ 12314 updates, score 13.199) (writing took 2.4652310381643474 seconds)
2022-03-06 22:28:27 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-06 22:28:27 | INFO | train | epoch 253 | loss 2.724 | nll_loss 0.541 | ppl 1.46 | wps 23189.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12314 | lr 0.000284971 | gnorm 0.552 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 33952
2022-03-06 22:28:27 | INFO | fairseq.trainer | begin training epoch 254
2022-03-06 22:28:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:30:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:30:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:30:42 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 13.227 | nll_loss 12.433 | ppl 5529.69 | wps 40749.6 | wpb 510.9 | bsz 1 | num_updates 12362 | best_loss 9.157
2022-03-06 22:30:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12362 updates
2022-03-06 22:30:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:30:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:30:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 254 @ 12362 updates, score 13.227) (writing took 2.321811265312135 seconds)
2022-03-06 22:30:44 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-06 22:30:44 | INFO | train | epoch 254 | loss 2.723 | nll_loss 0.541 | ppl 1.45 | wps 22711.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 12362 | lr 0.000284417 | gnorm 0.556 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 34089
2022-03-06 22:30:44 | INFO | fairseq.trainer | begin training epoch 255
2022-03-06 22:30:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:32:26 | INFO | train_inner | epoch 255:     38 / 49 loss=2.723, nll_loss=0.54, ppl=1.45, wps=22987.3, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.553, loss_scale=32, train_wall=241, gb_free=8.8, wall=34190
2022-03-06 22:32:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:32:59 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 13.196 | nll_loss 12.404 | ppl 5418.06 | wps 41322.4 | wpb 510.9 | bsz 1 | num_updates 12411 | best_loss 9.157
2022-03-06 22:32:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12411 updates
2022-03-06 22:32:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:33:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:33:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 255 @ 12411 updates, score 13.196) (writing took 2.463557526934892 seconds)
2022-03-06 22:33:01 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-06 22:33:01 | INFO | train | epoch 255 | loss 2.721 | nll_loss 0.538 | ppl 1.45 | wps 23203.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12411 | lr 0.000283855 | gnorm 0.55 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 34226
2022-03-06 22:33:01 | INFO | fairseq.trainer | begin training epoch 256
2022-03-06 22:33:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:35:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:35:16 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 13.285 | nll_loss 12.499 | ppl 5788.26 | wps 40458.4 | wpb 510.9 | bsz 1 | num_updates 12460 | best_loss 9.157
2022-03-06 22:35:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12460 updates
2022-03-06 22:35:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:35:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:35:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 256 @ 12460 updates, score 13.285) (writing took 2.3974332520738244 seconds)
2022-03-06 22:35:18 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-06 22:35:18 | INFO | train | epoch 256 | loss 2.719 | nll_loss 0.537 | ppl 1.45 | wps 23257.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12460 | lr 0.000283296 | gnorm 0.555 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 34363
2022-03-06 22:35:18 | INFO | fairseq.trainer | begin training epoch 257
2022-03-06 22:35:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:36:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:37:06 | INFO | train_inner | epoch 257:     41 / 49 loss=2.719, nll_loss=0.537, ppl=1.45, wps=23138.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.552, loss_scale=32, train_wall=239, gb_free=8.8, wall=34471
2022-03-06 22:37:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:37:31 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 13.253 | nll_loss 12.461 | ppl 5638.46 | wps 41916.3 | wpb 510.9 | bsz 1 | num_updates 12508 | best_loss 9.157
2022-03-06 22:37:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12508 updates
2022-03-06 22:37:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:37:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:37:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 257 @ 12508 updates, score 13.253) (writing took 2.497034548316151 seconds)
2022-03-06 22:37:33 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-06 22:37:33 | INFO | train | epoch 257 | loss 2.717 | nll_loss 0.535 | ppl 1.45 | wps 22978.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 12508 | lr 0.000282752 | gnorm 0.548 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 34498
2022-03-06 22:37:33 | INFO | fairseq.trainer | begin training epoch 258
2022-03-06 22:37:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:39:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:39:46 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 13.188 | nll_loss 12.395 | ppl 5385.64 | wps 42095.8 | wpb 510.9 | bsz 1 | num_updates 12557 | best_loss 9.157
2022-03-06 22:39:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12557 updates
2022-03-06 22:39:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:39:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:39:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 258 @ 12557 updates, score 13.188) (writing took 2.4620585050433874 seconds)
2022-03-06 22:39:48 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-06 22:39:48 | INFO | train | epoch 258 | loss 2.716 | nll_loss 0.534 | ppl 1.45 | wps 23613.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12557 | lr 0.0002822 | gnorm 0.549 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 34633
2022-03-06 22:39:48 | INFO | fairseq.trainer | begin training epoch 259
2022-03-06 22:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:41:41 | INFO | train_inner | epoch 259:     43 / 49 loss=2.715, nll_loss=0.534, ppl=1.45, wps=23616.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.553, loss_scale=32, train_wall=234, gb_free=8.8, wall=34745
2022-03-06 22:41:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:42:00 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 13.301 | nll_loss 12.523 | ppl 5885.87 | wps 42320.8 | wpb 510.9 | bsz 1 | num_updates 12606 | best_loss 9.157
2022-03-06 22:42:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12606 updates
2022-03-06 22:42:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:42:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:42:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 259 @ 12606 updates, score 13.301) (writing took 2.3199250400066376 seconds)
2022-03-06 22:42:03 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-06 22:42:03 | INFO | train | epoch 259 | loss 2.714 | nll_loss 0.533 | ppl 1.45 | wps 23630.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12606 | lr 0.000281651 | gnorm 0.555 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 34767
2022-03-06 22:42:03 | INFO | fairseq.trainer | begin training epoch 260
2022-03-06 22:42:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:42:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:44:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:44:15 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 13.327 | nll_loss 12.544 | ppl 5973.9 | wps 42277.1 | wpb 510.9 | bsz 1 | num_updates 12654 | best_loss 9.157
2022-03-06 22:44:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12654 updates
2022-03-06 22:44:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:44:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:44:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 260 @ 12654 updates, score 13.327) (writing took 2.4263628851622343 seconds)
2022-03-06 22:44:17 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-06 22:44:17 | INFO | train | epoch 260 | loss 2.711 | nll_loss 0.53 | ppl 1.44 | wps 23150.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 12654 | lr 0.000281116 | gnorm 0.542 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 34902
2022-03-06 22:44:17 | INFO | fairseq.trainer | begin training epoch 261
2022-03-06 22:44:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:46:17 | INFO | train_inner | epoch 261:     46 / 49 loss=2.711, nll_loss=0.53, ppl=1.44, wps=23434.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=12700, lr=0.000280607, gnorm=0.544, loss_scale=32, train_wall=236, gb_free=8.8, wall=35022
2022-03-06 22:46:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:46:29 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 13.31 | nll_loss 12.523 | ppl 5887.41 | wps 41021.6 | wpb 510.9 | bsz 1 | num_updates 12703 | best_loss 9.157
2022-03-06 22:46:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12703 updates
2022-03-06 22:46:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:46:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:46:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 261 @ 12703 updates, score 13.31) (writing took 2.550834464840591 seconds)
2022-03-06 22:46:32 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-06 22:46:32 | INFO | train | epoch 261 | loss 2.711 | nll_loss 0.53 | ppl 1.44 | wps 23553.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12703 | lr 0.000280574 | gnorm 0.544 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 35037
2022-03-06 22:46:32 | INFO | fairseq.trainer | begin training epoch 262
2022-03-06 22:46:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:48:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:48:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:48:44 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 13.183 | nll_loss 12.387 | ppl 5357.52 | wps 41523.4 | wpb 510.9 | bsz 1 | num_updates 12751 | best_loss 9.157
2022-03-06 22:48:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12751 updates
2022-03-06 22:48:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:48:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:48:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 262 @ 12751 updates, score 13.183) (writing took 2.3404745790176094 seconds)
2022-03-06 22:48:47 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-06 22:48:47 | INFO | train | epoch 262 | loss 2.709 | nll_loss 0.529 | ppl 1.44 | wps 23102.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 12751 | lr 0.000280045 | gnorm 0.539 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 35171
2022-03-06 22:48:47 | INFO | fairseq.trainer | begin training epoch 263
2022-03-06 22:48:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:50:55 | INFO | train_inner | epoch 263:     49 / 49 loss=2.709, nll_loss=0.529, ppl=1.44, wps=23281.2, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=12800, lr=0.000279508, gnorm=0.545, loss_scale=32, train_wall=236, gb_free=8.8, wall=35299
2022-03-06 22:50:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:51:00 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 13.15 | nll_loss 12.351 | ppl 5224.68 | wps 40371 | wpb 510.9 | bsz 1 | num_updates 12800 | best_loss 9.157
2022-03-06 22:51:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12800 updates
2022-03-06 22:51:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:51:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:51:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 263 @ 12800 updates, score 13.15) (writing took 2.40079523390159 seconds)
2022-03-06 22:51:03 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-06 22:51:03 | INFO | train | epoch 263 | loss 2.708 | nll_loss 0.527 | ppl 1.44 | wps 23382.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12800 | lr 0.000279508 | gnorm 0.549 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 35307
2022-03-06 22:51:03 | INFO | fairseq.trainer | begin training epoch 264
2022-03-06 22:51:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:53:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:53:17 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 13.155 | nll_loss 12.354 | ppl 5236.84 | wps 40916.6 | wpb 510.9 | bsz 1 | num_updates 12849 | best_loss 9.157
2022-03-06 22:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12849 updates
2022-03-06 22:53:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:53:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:53:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 264 @ 12849 updates, score 13.155) (writing took 2.5045818709768355 seconds)
2022-03-06 22:53:19 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-06 22:53:19 | INFO | train | epoch 264 | loss 2.706 | nll_loss 0.526 | ppl 1.44 | wps 23208 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12849 | lr 0.000278975 | gnorm 0.54 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 35444
2022-03-06 22:53:19 | INFO | fairseq.trainer | begin training epoch 265
2022-03-06 22:53:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:54:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:54:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:55:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:55:34 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 13.224 | nll_loss 12.44 | ppl 5556.74 | wps 41085.2 | wpb 510.9 | bsz 1 | num_updates 12896 | best_loss 9.157
2022-03-06 22:55:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12896 updates
2022-03-06 22:55:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:55:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:55:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 265 @ 12896 updates, score 13.224) (writing took 2.48934167297557 seconds)
2022-03-06 22:55:37 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-06 22:55:37 | INFO | train | epoch 265 | loss 2.704 | nll_loss 0.524 | ppl 1.44 | wps 22204.3 | ups 0.34 | wpb 64829.4 | bsz 126.6 | num_updates 12896 | lr 0.000278466 | gnorm 0.539 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 35581
2022-03-06 22:55:37 | INFO | fairseq.trainer | begin training epoch 266
2022-03-06 22:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:55:48 | INFO | train_inner | epoch 266:      4 / 49 loss=2.705, nll_loss=0.525, ppl=1.44, wps=22149.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=12900, lr=0.000278423, gnorm=0.54, loss_scale=16, train_wall=243, gb_free=8.8, wall=35592
2022-03-06 22:57:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:57:51 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 13.203 | nll_loss 12.402 | ppl 5412.59 | wps 40239.5 | wpb 510.9 | bsz 1 | num_updates 12945 | best_loss 9.157
2022-03-06 22:57:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12945 updates
2022-03-06 22:57:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:57:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:57:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 266 @ 12945 updates, score 13.203) (writing took 2.5280587002635 seconds)
2022-03-06 22:57:54 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-06 22:57:54 | INFO | train | epoch 266 | loss 2.703 | nll_loss 0.524 | ppl 1.44 | wps 23157.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12945 | lr 0.000277939 | gnorm 0.54 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 35719
2022-03-06 22:57:54 | INFO | fairseq.trainer | begin training epoch 267
2022-03-06 22:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:00:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:00:08 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 13.094 | nll_loss 12.293 | ppl 5019.64 | wps 42513.5 | wpb 510.9 | bsz 1 | num_updates 12994 | best_loss 9.157
2022-03-06 23:00:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12994 updates
2022-03-06 23:00:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:00:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:00:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 267 @ 12994 updates, score 13.094) (writing took 2.3811803897842765 seconds)
2022-03-06 23:00:10 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-06 23:00:10 | INFO | train | epoch 267 | loss 2.702 | nll_loss 0.522 | ppl 1.44 | wps 23352.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12994 | lr 0.000277414 | gnorm 0.536 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 35855
2022-03-06 23:00:10 | INFO | fairseq.trainer | begin training epoch 268
2022-03-06 23:00:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:00:26 | INFO | train_inner | epoch 268:      6 / 49 loss=2.702, nll_loss=0.522, ppl=1.44, wps=23296.4, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=13000, lr=0.00027735, gnorm=0.538, loss_scale=16, train_wall=237, gb_free=8.8, wall=35871
2022-03-06 23:02:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:02:24 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 13.206 | nll_loss 12.418 | ppl 5473.44 | wps 41131 | wpb 510.9 | bsz 1 | num_updates 13043 | best_loss 9.157
2022-03-06 23:02:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13043 updates
2022-03-06 23:02:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:02:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:02:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 268 @ 13043 updates, score 13.206) (writing took 2.4429729459807277 seconds)
2022-03-06 23:02:26 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-06 23:02:26 | INFO | train | epoch 268 | loss 2.7 | nll_loss 0.521 | ppl 1.43 | wps 23310.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13043 | lr 0.000276893 | gnorm 0.538 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 35991
2022-03-06 23:02:26 | INFO | fairseq.trainer | begin training epoch 269
2022-03-06 23:02:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:04:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:04:41 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 13.306 | nll_loss 12.531 | ppl 5916.4 | wps 40892.1 | wpb 510.9 | bsz 1 | num_updates 13092 | best_loss 9.157
2022-03-06 23:04:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13092 updates
2022-03-06 23:04:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:04:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:04:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 269 @ 13092 updates, score 13.306) (writing took 2.423827331047505 seconds)
2022-03-06 23:04:43 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-06 23:04:43 | INFO | train | epoch 269 | loss 2.698 | nll_loss 0.519 | ppl 1.43 | wps 23257.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13092 | lr 0.000276374 | gnorm 0.54 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 36128
2022-03-06 23:04:43 | INFO | fairseq.trainer | begin training epoch 270
2022-03-06 23:04:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:05:04 | INFO | train_inner | epoch 270:      8 / 49 loss=2.699, nll_loss=0.52, ppl=1.43, wps=23303.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.539, loss_scale=32, train_wall=237, gb_free=8.8, wall=36149
2022-03-06 23:06:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:06:58 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 13.137 | nll_loss 12.339 | ppl 5180.96 | wps 39927.4 | wpb 510.9 | bsz 1 | num_updates 13141 | best_loss 9.157
2022-03-06 23:06:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13141 updates
2022-03-06 23:06:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:07:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:07:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 270 @ 13141 updates, score 13.137) (writing took 2.394465561956167 seconds)
2022-03-06 23:07:00 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-06 23:07:00 | INFO | train | epoch 270 | loss 2.696 | nll_loss 0.517 | ppl 1.43 | wps 23175 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13141 | lr 0.000275858 | gnorm 0.542 | loss_scale 64 | train_wall 117 | gb_free 8.8 | wall 36265
2022-03-06 23:07:00 | INFO | fairseq.trainer | begin training epoch 271
2022-03-06 23:07:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:07:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:09:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:09:15 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 13.188 | nll_loss 12.393 | ppl 5380.23 | wps 40542.6 | wpb 510.9 | bsz 1 | num_updates 13189 | best_loss 9.157
2022-03-06 23:09:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13189 updates
2022-03-06 23:09:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:09:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:09:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 271 @ 13189 updates, score 13.188) (writing took 2.5099951759912074 seconds)
2022-03-06 23:09:17 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-06 23:09:17 | INFO | train | epoch 271 | loss 2.694 | nll_loss 0.516 | ppl 1.43 | wps 22701.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 13189 | lr 0.000275356 | gnorm 0.539 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 36402
2022-03-06 23:09:17 | INFO | fairseq.trainer | begin training epoch 272
2022-03-06 23:09:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:09:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:09:49 | INFO | train_inner | epoch 272:     12 / 49 loss=2.694, nll_loss=0.516, ppl=1.43, wps=22768.3, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.541, loss_scale=16, train_wall=243, gb_free=8.8, wall=36434
2022-03-06 23:11:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:11:32 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 13.176 | nll_loss 12.383 | ppl 5340.95 | wps 41519.2 | wpb 510.9 | bsz 1 | num_updates 13237 | best_loss 9.157
2022-03-06 23:11:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13237 updates
2022-03-06 23:11:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:11:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:11:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 272 @ 13237 updates, score 13.176) (writing took 2.3681449848227203 seconds)
2022-03-06 23:11:34 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-06 23:11:34 | INFO | train | epoch 272 | loss 2.694 | nll_loss 0.515 | ppl 1.43 | wps 22741.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 13237 | lr 0.000274856 | gnorm 0.534 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 36539
2022-03-06 23:11:34 | INFO | fairseq.trainer | begin training epoch 273
2022-03-06 23:11:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:13:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:13:48 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 13.172 | nll_loss 12.389 | ppl 5364.17 | wps 40953.8 | wpb 510.9 | bsz 1 | num_updates 13286 | best_loss 9.157
2022-03-06 23:13:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13286 updates
2022-03-06 23:13:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:13:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:13:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 273 @ 13286 updates, score 13.172) (writing took 2.3657274660654366 seconds)
2022-03-06 23:13:51 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-06 23:13:51 | INFO | train | epoch 273 | loss 2.692 | nll_loss 0.514 | ppl 1.43 | wps 23249.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13286 | lr 0.000274349 | gnorm 0.53 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 36676
2022-03-06 23:13:51 | INFO | fairseq.trainer | begin training epoch 274
2022-03-06 23:13:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:14:28 | INFO | train_inner | epoch 274:     14 / 49 loss=2.693, nll_loss=0.515, ppl=1.43, wps=23316.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.53, loss_scale=16, train_wall=237, gb_free=8.8, wall=36712
2022-03-06 23:15:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:16:04 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 13.265 | nll_loss 12.484 | ppl 5729.19 | wps 41144.7 | wpb 510.9 | bsz 1 | num_updates 13335 | best_loss 9.157
2022-03-06 23:16:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13335 updates
2022-03-06 23:16:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:16:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:16:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 274 @ 13335 updates, score 13.265) (writing took 2.3861150736920536 seconds)
2022-03-06 23:16:06 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-06 23:16:06 | INFO | train | epoch 274 | loss 2.691 | nll_loss 0.514 | ppl 1.43 | wps 23480.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13335 | lr 0.000273844 | gnorm 0.534 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 36811
2022-03-06 23:16:06 | INFO | fairseq.trainer | begin training epoch 275
2022-03-06 23:16:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:18:21 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 13.336 | nll_loss 12.563 | ppl 6050.68 | wps 40890.8 | wpb 510.9 | bsz 1 | num_updates 13384 | best_loss 9.157
2022-03-06 23:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13384 updates
2022-03-06 23:18:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:18:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 275 @ 13384 updates, score 13.336) (writing took 2.573176178149879 seconds)
2022-03-06 23:18:23 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-06 23:18:23 | INFO | train | epoch 275 | loss 2.689 | nll_loss 0.512 | ppl 1.43 | wps 23177.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13384 | lr 0.000273342 | gnorm 0.536 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 36948
2022-03-06 23:18:23 | INFO | fairseq.trainer | begin training epoch 276
2022-03-06 23:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:19:06 | INFO | train_inner | epoch 276:     16 / 49 loss=2.69, nll_loss=0.513, ppl=1.43, wps=23313.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.538, loss_scale=32, train_wall=237, gb_free=8.8, wall=36991
2022-03-06 23:20:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:20:38 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 13.185 | nll_loss 12.398 | ppl 5396.62 | wps 40797.6 | wpb 510.9 | bsz 1 | num_updates 13433 | best_loss 9.157
2022-03-06 23:20:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13433 updates
2022-03-06 23:20:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:20:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:20:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 276 @ 13433 updates, score 13.185) (writing took 2.3906588731333613 seconds)
2022-03-06 23:20:40 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-06 23:20:40 | INFO | train | epoch 276 | loss 2.688 | nll_loss 0.51 | ppl 1.42 | wps 23251.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13433 | lr 0.000272843 | gnorm 0.533 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 37085
2022-03-06 23:20:40 | INFO | fairseq.trainer | begin training epoch 277
2022-03-06 23:20:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:20:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:22:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:22:54 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 13.268 | nll_loss 12.49 | ppl 5752.02 | wps 40720 | wpb 510.9 | bsz 1 | num_updates 13481 | best_loss 9.157
2022-03-06 23:22:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13481 updates
2022-03-06 23:22:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:22:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:22:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 277 @ 13481 updates, score 13.268) (writing took 2.4553941329941154 seconds)
2022-03-06 23:22:57 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-06 23:22:57 | INFO | train | epoch 277 | loss 2.686 | nll_loss 0.509 | ppl 1.42 | wps 22754.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 13481 | lr 0.000272357 | gnorm 0.536 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 37222
2022-03-06 23:22:57 | INFO | fairseq.trainer | begin training epoch 278
2022-03-06 23:22:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:23:47 | INFO | train_inner | epoch 278:     19 / 49 loss=2.686, nll_loss=0.509, ppl=1.42, wps=23038.4, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.531, loss_scale=16, train_wall=240, gb_free=8.8, wall=37272
2022-03-06 23:25:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:25:11 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 13.28 | nll_loss 12.507 | ppl 5819.13 | wps 40977 | wpb 510.9 | bsz 1 | num_updates 13530 | best_loss 9.157
2022-03-06 23:25:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13530 updates
2022-03-06 23:25:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:25:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:25:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 278 @ 13530 updates, score 13.28) (writing took 2.3499091370031238 seconds)
2022-03-06 23:25:13 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-06 23:25:13 | INFO | train | epoch 278 | loss 2.686 | nll_loss 0.509 | ppl 1.42 | wps 23249.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13530 | lr 0.000271864 | gnorm 0.534 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 37358
2022-03-06 23:25:13 | INFO | fairseq.trainer | begin training epoch 279
2022-03-06 23:25:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:27:28 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 13.116 | nll_loss 12.32 | ppl 5112.51 | wps 40796 | wpb 510.9 | bsz 1 | num_updates 13579 | best_loss 9.157
2022-03-06 23:27:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13579 updates
2022-03-06 23:27:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:27:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:27:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 279 @ 13579 updates, score 13.116) (writing took 2.410589681006968 seconds)
2022-03-06 23:27:30 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-06 23:27:30 | INFO | train | epoch 279 | loss 2.683 | nll_loss 0.507 | ppl 1.42 | wps 23262.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13579 | lr 0.000271373 | gnorm 0.524 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 37495
2022-03-06 23:27:30 | INFO | fairseq.trainer | begin training epoch 280
2022-03-06 23:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:28:26 | INFO | train_inner | epoch 280:     21 / 49 loss=2.683, nll_loss=0.507, ppl=1.42, wps=23278, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.53, loss_scale=32, train_wall=238, gb_free=8.8, wall=37551
2022-03-06 23:29:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:29:45 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 13.306 | nll_loss 12.531 | ppl 5920.29 | wps 40428.1 | wpb 510.9 | bsz 1 | num_updates 13628 | best_loss 9.157
2022-03-06 23:29:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13628 updates
2022-03-06 23:29:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:29:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:29:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 280 @ 13628 updates, score 13.306) (writing took 2.417990020941943 seconds)
2022-03-06 23:29:47 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-06 23:29:47 | INFO | train | epoch 280 | loss 2.682 | nll_loss 0.507 | ppl 1.42 | wps 23193.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13628 | lr 0.000270884 | gnorm 0.537 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 37632
2022-03-06 23:29:47 | INFO | fairseq.trainer | begin training epoch 281
2022-03-06 23:29:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:31:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:32:02 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 13.161 | nll_loss 12.373 | ppl 5305.82 | wps 40232 | wpb 510.9 | bsz 1 | num_updates 13677 | best_loss 9.157
2022-03-06 23:32:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13677 updates
2022-03-06 23:32:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:32:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:32:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 281 @ 13677 updates, score 13.161) (writing took 2.4215951981022954 seconds)
2022-03-06 23:32:04 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-06 23:32:04 | INFO | train | epoch 281 | loss 2.68 | nll_loss 0.504 | ppl 1.42 | wps 23194.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13677 | lr 0.000270399 | gnorm 0.526 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 37769
2022-03-06 23:32:04 | INFO | fairseq.trainer | begin training epoch 282
2022-03-06 23:32:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:32:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:33:08 | INFO | train_inner | epoch 282:     24 / 49 loss=2.681, nll_loss=0.505, ppl=1.42, wps=23007, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.53, loss_scale=32, train_wall=240, gb_free=8.8, wall=37833
2022-03-06 23:34:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:34:19 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 13.241 | nll_loss 12.46 | ppl 5634.72 | wps 40478.2 | wpb 510.9 | bsz 1 | num_updates 13725 | best_loss 9.157
2022-03-06 23:34:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13725 updates
2022-03-06 23:34:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:34:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:34:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 282 @ 13725 updates, score 13.241) (writing took 2.3938807249069214 seconds)
2022-03-06 23:34:21 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-06 23:34:21 | INFO | train | epoch 282 | loss 2.679 | nll_loss 0.504 | ppl 1.42 | wps 22719.6 | ups 0.35 | wpb 64853.3 | bsz 126.7 | num_updates 13725 | lr 0.000269925 | gnorm 0.527 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 37906
2022-03-06 23:34:21 | INFO | fairseq.trainer | begin training epoch 283
2022-03-06 23:34:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:36:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:36:35 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 13.155 | nll_loss 12.363 | ppl 5269.1 | wps 40593.2 | wpb 510.9 | bsz 1 | num_updates 13774 | best_loss 9.157
2022-03-06 23:36:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13774 updates
2022-03-06 23:36:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:36:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:36:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 283 @ 13774 updates, score 13.155) (writing took 2.4008419080637395 seconds)
2022-03-06 23:36:38 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-06 23:36:38 | INFO | train | epoch 283 | loss 2.678 | nll_loss 0.502 | ppl 1.42 | wps 23250.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13774 | lr 0.000269445 | gnorm 0.523 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 38043
2022-03-06 23:36:38 | INFO | fairseq.trainer | begin training epoch 284
2022-03-06 23:36:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:37:47 | INFO | train_inner | epoch 284:     26 / 49 loss=2.677, nll_loss=0.502, ppl=1.42, wps=23257.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.526, loss_scale=32, train_wall=238, gb_free=8.8, wall=38112
2022-03-06 23:38:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:38:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:38:52 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 13.179 | nll_loss 12.399 | ppl 5401.67 | wps 39627.8 | wpb 510.9 | bsz 1 | num_updates 13822 | best_loss 9.157
2022-03-06 23:38:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13822 updates
2022-03-06 23:38:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:38:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:38:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 284 @ 13822 updates, score 13.179) (writing took 2.5527794947847724 seconds)
2022-03-06 23:38:55 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-06 23:38:55 | INFO | train | epoch 284 | loss 2.675 | nll_loss 0.5 | ppl 1.41 | wps 22748.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 13822 | lr 0.000268977 | gnorm 0.528 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 38179
2022-03-06 23:38:55 | INFO | fairseq.trainer | begin training epoch 285
2022-03-06 23:38:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:41:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:41:08 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 13.248 | nll_loss 12.473 | ppl 5685.01 | wps 42634.4 | wpb 510.9 | bsz 1 | num_updates 13871 | best_loss 9.157
2022-03-06 23:41:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13871 updates
2022-03-06 23:41:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:41:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:41:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 285 @ 13871 updates, score 13.248) (writing took 2.45839740941301 seconds)
2022-03-06 23:41:10 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-06 23:41:10 | INFO | train | epoch 285 | loss 2.674 | nll_loss 0.499 | ppl 1.41 | wps 23417.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13871 | lr 0.000268501 | gnorm 0.518 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 38315
2022-03-06 23:41:10 | INFO | fairseq.trainer | begin training epoch 286
2022-03-06 23:41:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:42:26 | INFO | train_inner | epoch 286:     29 / 49 loss=2.674, nll_loss=0.499, ppl=1.41, wps=23242.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.518, loss_scale=32, train_wall=238, gb_free=8.8, wall=38391
2022-03-06 23:43:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:43:22 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 13.242 | nll_loss 12.458 | ppl 5625.56 | wps 40934.8 | wpb 510.9 | bsz 1 | num_updates 13920 | best_loss 9.157
2022-03-06 23:43:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13920 updates
2022-03-06 23:43:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:43:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:43:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 286 @ 13920 updates, score 13.242) (writing took 2.3766053933650255 seconds)
2022-03-06 23:43:25 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-06 23:43:25 | INFO | train | epoch 286 | loss 2.674 | nll_loss 0.5 | ppl 1.41 | wps 23625.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13920 | lr 0.000268028 | gnorm 0.522 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 38450
2022-03-06 23:43:25 | INFO | fairseq.trainer | begin training epoch 287
2022-03-06 23:43:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:44:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:45:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:45:37 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 13.242 | nll_loss 12.46 | ppl 5634.47 | wps 42016.7 | wpb 510.9 | bsz 1 | num_updates 13968 | best_loss 9.157
2022-03-06 23:45:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13968 updates
2022-03-06 23:45:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:45:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:45:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 287 @ 13968 updates, score 13.242) (writing took 2.338707352988422 seconds)
2022-03-06 23:45:39 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-06 23:45:39 | INFO | train | epoch 287 | loss 2.672 | nll_loss 0.498 | ppl 1.41 | wps 23144.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 13968 | lr 0.000267567 | gnorm 0.526 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 38584
2022-03-06 23:45:39 | INFO | fairseq.trainer | begin training epoch 288
2022-03-06 23:45:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:47:03 | INFO | train_inner | epoch 288:     32 / 49 loss=2.673, nll_loss=0.498, ppl=1.41, wps=23403.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.525, loss_scale=32, train_wall=236, gb_free=8.8, wall=38668
2022-03-06 23:47:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:47:52 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 13.198 | nll_loss 12.418 | ppl 5472.54 | wps 41921.3 | wpb 510.9 | bsz 1 | num_updates 14017 | best_loss 9.157
2022-03-06 23:47:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14017 updates
2022-03-06 23:47:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:47:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:47:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 288 @ 14017 updates, score 13.198) (writing took 2.5196821447461843 seconds)
2022-03-06 23:47:54 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-06 23:47:54 | INFO | train | epoch 288 | loss 2.671 | nll_loss 0.497 | ppl 1.41 | wps 23596.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14017 | lr 0.000267099 | gnorm 0.521 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 38719
2022-03-06 23:47:54 | INFO | fairseq.trainer | begin training epoch 289
2022-03-06 23:47:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:50:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:50:06 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 13.132 | nll_loss 12.346 | ppl 5206.64 | wps 42230.8 | wpb 510.9 | bsz 1 | num_updates 14066 | best_loss 9.157
2022-03-06 23:50:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14066 updates
2022-03-06 23:50:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:50:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:50:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 289 @ 14066 updates, score 13.132) (writing took 2.416729439049959 seconds)
2022-03-06 23:50:09 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-06 23:50:09 | INFO | train | epoch 289 | loss 2.67 | nll_loss 0.496 | ppl 1.41 | wps 23589.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14066 | lr 0.000266633 | gnorm 0.516 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 38854
2022-03-06 23:50:09 | INFO | fairseq.trainer | begin training epoch 290
2022-03-06 23:50:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:50:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:51:40 | INFO | train_inner | epoch 290:     35 / 49 loss=2.669, nll_loss=0.496, ppl=1.41, wps=23402.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.517, loss_scale=32, train_wall=236, gb_free=8.8, wall=38945
2022-03-06 23:52:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:52:21 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 13.252 | nll_loss 12.475 | ppl 5694.91 | wps 42078.5 | wpb 510.9 | bsz 1 | num_updates 14114 | best_loss 9.157
2022-03-06 23:52:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14114 updates
2022-03-06 23:52:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:52:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:52:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 290 @ 14114 updates, score 13.252) (writing took 2.4297585990279913 seconds)
2022-03-06 23:52:23 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-06 23:52:23 | INFO | train | epoch 290 | loss 2.668 | nll_loss 0.494 | ppl 1.41 | wps 23116.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 14114 | lr 0.00026618 | gnorm 0.515 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 38988
2022-03-06 23:52:23 | INFO | fairseq.trainer | begin training epoch 291
2022-03-06 23:52:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:52:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:54:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:54:37 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 13.144 | nll_loss 12.355 | ppl 5240.38 | wps 41061.9 | wpb 510.9 | bsz 1 | num_updates 14162 | best_loss 9.157
2022-03-06 23:54:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14162 updates
2022-03-06 23:54:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:54:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:54:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 291 @ 14162 updates, score 13.144) (writing took 2.463320431765169 seconds)
2022-03-06 23:54:40 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-06 23:54:40 | INFO | train | epoch 291 | loss 2.666 | nll_loss 0.493 | ppl 1.41 | wps 22838.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 14162 | lr 0.000265728 | gnorm 0.512 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 39124
2022-03-06 23:54:40 | INFO | fairseq.trainer | begin training epoch 292
2022-03-06 23:54:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:56:21 | INFO | train_inner | epoch 292:     38 / 49 loss=2.667, nll_loss=0.493, ppl=1.41, wps=23144.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.515, loss_scale=16, train_wall=239, gb_free=8.8, wall=39226
2022-03-06 23:56:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:56:54 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 13.242 | nll_loss 12.463 | ppl 5646.52 | wps 40448.4 | wpb 510.9 | bsz 1 | num_updates 14211 | best_loss 9.157
2022-03-06 23:56:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14211 updates
2022-03-06 23:56:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:56:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:56:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 292 @ 14211 updates, score 13.242) (writing took 2.3594530601985753 seconds)
2022-03-06 23:56:56 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-06 23:56:56 | INFO | train | epoch 292 | loss 2.666 | nll_loss 0.493 | ppl 1.41 | wps 23229.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14211 | lr 0.00026527 | gnorm 0.519 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 39261
2022-03-06 23:56:57 | INFO | fairseq.trainer | begin training epoch 293
2022-03-06 23:56:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:59:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:59:11 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 13.257 | nll_loss 12.485 | ppl 5731.98 | wps 40198 | wpb 510.9 | bsz 1 | num_updates 14260 | best_loss 9.157
2022-03-06 23:59:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14260 updates
2022-03-06 23:59:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:59:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:59:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 293 @ 14260 updates, score 13.257) (writing took 2.5017864569090307 seconds)
2022-03-06 23:59:14 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-06 23:59:14 | INFO | train | epoch 293 | loss 2.666 | nll_loss 0.493 | ppl 1.41 | wps 23184.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14260 | lr 0.000264814 | gnorm 0.524 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 39398
2022-03-06 23:59:14 | INFO | fairseq.trainer | begin training epoch 294
2022-03-06 23:59:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:01:00 | INFO | train_inner | epoch 294:     40 / 49 loss=2.665, nll_loss=0.492, ppl=1.41, wps=23206.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.52, loss_scale=32, train_wall=238, gb_free=8.8, wall=39505
2022-03-07 00:01:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:01:28 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 13.161 | nll_loss 12.377 | ppl 5319.37 | wps 40233.4 | wpb 510.9 | bsz 1 | num_updates 14309 | best_loss 9.157
2022-03-07 00:01:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14309 updates
2022-03-07 00:01:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:01:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:01:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 294 @ 14309 updates, score 13.161) (writing took 2.4726011562161148 seconds)
2022-03-07 00:01:31 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-07 00:01:31 | INFO | train | epoch 294 | loss 2.663 | nll_loss 0.491 | ppl 1.41 | wps 23149.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14309 | lr 0.00026436 | gnorm 0.514 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 39536
2022-03-07 00:01:31 | INFO | fairseq.trainer | begin training epoch 295
2022-03-07 00:01:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:03:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:03:45 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 13.34 | nll_loss 12.575 | ppl 6103.65 | wps 40617 | wpb 510.9 | bsz 1 | num_updates 14358 | best_loss 9.157
2022-03-07 00:03:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14358 updates
2022-03-07 00:03:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:03:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 295 @ 14358 updates, score 13.34) (writing took 2.3483568280935287 seconds)
2022-03-07 00:03:48 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 00:03:48 | INFO | train | epoch 295 | loss 2.663 | nll_loss 0.49 | ppl 1.4 | wps 23235.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14358 | lr 0.000263908 | gnorm 0.52 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 39672
2022-03-07 00:03:48 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 00:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:04:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:05:42 | INFO | train_inner | epoch 296:     43 / 49 loss=2.662, nll_loss=0.49, ppl=1.4, wps=23022.1, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.514, loss_scale=32, train_wall=240, gb_free=8.8, wall=39787
2022-03-07 00:05:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:06:02 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 13.202 | nll_loss 12.415 | ppl 5461.42 | wps 40962.6 | wpb 510.9 | bsz 1 | num_updates 14406 | best_loss 9.157
2022-03-07 00:06:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14406 updates
2022-03-07 00:06:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:06:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:06:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 296 @ 14406 updates, score 13.202) (writing took 2.4571959571912885 seconds)
2022-03-07 00:06:05 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 00:06:05 | INFO | train | epoch 296 | loss 2.661 | nll_loss 0.489 | ppl 1.4 | wps 22737.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 14406 | lr 0.000263468 | gnorm 0.509 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 39809
2022-03-07 00:06:05 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 00:06:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:08:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:08:19 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 13.16 | nll_loss 12.371 | ppl 5296.91 | wps 40358.3 | wpb 510.9 | bsz 1 | num_updates 14455 | best_loss 9.157
2022-03-07 00:08:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14455 updates
2022-03-07 00:08:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:08:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:08:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 297 @ 14455 updates, score 13.16) (writing took 2.3663484528660774 seconds)
2022-03-07 00:08:21 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 00:08:21 | INFO | train | epoch 297 | loss 2.66 | nll_loss 0.488 | ppl 1.4 | wps 23243.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14455 | lr 0.000263021 | gnorm 0.503 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 39946
2022-03-07 00:08:21 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 00:08:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:10:21 | INFO | train_inner | epoch 298:     45 / 49 loss=2.66, nll_loss=0.488, ppl=1.4, wps=23246.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=14500, lr=0.000262613, gnorm=0.51, loss_scale=32, train_wall=238, gb_free=8.8, wall=40066
2022-03-07 00:10:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:10:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:10:36 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 13.219 | nll_loss 12.44 | ppl 5556.44 | wps 40043.3 | wpb 510.9 | bsz 1 | num_updates 14503 | best_loss 9.157
2022-03-07 00:10:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14503 updates
2022-03-07 00:10:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:10:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:10:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 298 @ 14503 updates, score 13.219) (writing took 2.41346587613225 seconds)
2022-03-07 00:10:38 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 00:10:38 | INFO | train | epoch 298 | loss 2.659 | nll_loss 0.487 | ppl 1.4 | wps 22691.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 14503 | lr 0.000262586 | gnorm 0.515 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 40083
2022-03-07 00:10:38 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 00:10:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:12:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:12:53 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 13.16 | nll_loss 12.379 | ppl 5328.35 | wps 40631.7 | wpb 510.9 | bsz 1 | num_updates 14552 | best_loss 9.157
2022-03-07 00:12:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14552 updates
2022-03-07 00:12:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:12:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:12:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 299 @ 14552 updates, score 13.16) (writing took 2.4706546468660235 seconds)
2022-03-07 00:12:55 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 00:12:55 | INFO | train | epoch 299 | loss 2.659 | nll_loss 0.487 | ppl 1.4 | wps 23202.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14552 | lr 0.000262143 | gnorm 0.521 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 40220
2022-03-07 00:12:55 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 00:12:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:15:03 | INFO | train_inner | epoch 300:     48 / 49 loss=2.658, nll_loss=0.486, ppl=1.4, wps=23021.5, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=14600, lr=0.000261712, gnorm=0.513, loss_scale=32, train_wall=240, gb_free=8.8, wall=40348
2022-03-07 00:15:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:15:10 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 13.15 | nll_loss 12.367 | ppl 5281.02 | wps 40449.5 | wpb 510.9 | bsz 1 | num_updates 14601 | best_loss 9.157
2022-03-07 00:15:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14601 updates
2022-03-07 00:15:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:15:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:15:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 300 @ 14601 updates, score 13.15) (writing took 2.376151533331722 seconds)
2022-03-07 00:15:12 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 00:15:12 | INFO | train | epoch 300 | loss 2.656 | nll_loss 0.485 | ppl 1.4 | wps 23247 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14601 | lr 0.000261703 | gnorm 0.505 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 40357
2022-03-07 00:15:12 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 00:15:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:16:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:17:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:17:26 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 13.279 | nll_loss 12.509 | ppl 5828.28 | wps 42155.9 | wpb 510.9 | bsz 1 | num_updates 14649 | best_loss 9.157
2022-03-07 00:17:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14649 updates
2022-03-07 00:17:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:17:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:17:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 301 @ 14649 updates, score 13.279) (writing took 2.3302477058023214 seconds)
2022-03-07 00:17:28 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 00:17:28 | INFO | train | epoch 301 | loss 2.654 | nll_loss 0.483 | ppl 1.4 | wps 22924.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 14649 | lr 0.000261274 | gnorm 0.515 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 40493
2022-03-07 00:17:28 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 00:17:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:19:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:19:40 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 13.23 | nll_loss 12.453 | ppl 5607.47 | wps 40669.7 | wpb 510.9 | bsz 1 | num_updates 14698 | best_loss 9.157
2022-03-07 00:19:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14698 updates
2022-03-07 00:19:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:19:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:19:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 302 @ 14698 updates, score 13.23) (writing took 2.543372836895287 seconds)
2022-03-07 00:19:43 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 00:19:43 | INFO | train | epoch 302 | loss 2.654 | nll_loss 0.483 | ppl 1.4 | wps 23579.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14698 | lr 0.000260838 | gnorm 0.507 | loss_scale 16 | train_wall 114 | gb_free 8.8 | wall 40627
2022-03-07 00:19:43 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 00:19:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:19:48 | INFO | train_inner | epoch 303:      2 / 49 loss=2.654, nll_loss=0.483, ppl=1.4, wps=22643.4, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=14700, lr=0.00026082, gnorm=0.513, loss_scale=16, train_wall=236, gb_free=8.8, wall=40633
2022-03-07 00:21:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:21:55 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 13.274 | nll_loss 12.507 | ppl 5821.08 | wps 41695.3 | wpb 510.9 | bsz 1 | num_updates 14747 | best_loss 9.157
2022-03-07 00:21:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14747 updates
2022-03-07 00:21:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:21:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:21:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 303 @ 14747 updates, score 13.274) (writing took 2.333852023817599 seconds)
2022-03-07 00:21:57 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 00:21:57 | INFO | train | epoch 303 | loss 2.652 | nll_loss 0.481 | ppl 1.4 | wps 23631 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14747 | lr 0.000260404 | gnorm 0.505 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 40762
2022-03-07 00:21:57 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 00:21:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:24:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:24:09 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 13.247 | nll_loss 12.473 | ppl 5684.05 | wps 41983.8 | wpb 510.9 | bsz 1 | num_updates 14796 | best_loss 9.157
2022-03-07 00:24:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14796 updates
2022-03-07 00:24:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:24:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:24:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 304 @ 14796 updates, score 13.247) (writing took 2.35210947599262 seconds)
2022-03-07 00:24:12 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 00:24:12 | INFO | train | epoch 304 | loss 2.651 | nll_loss 0.481 | ppl 1.4 | wps 23617 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14796 | lr 0.000259973 | gnorm 0.499 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 40896
2022-03-07 00:24:12 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 00:24:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:24:22 | INFO | train_inner | epoch 305:      4 / 49 loss=2.652, nll_loss=0.481, ppl=1.4, wps=23648.3, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.503, loss_scale=32, train_wall=234, gb_free=8.8, wall=40907
2022-03-07 00:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:26:24 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 13.235 | nll_loss 12.455 | ppl 5613 | wps 42396.1 | wpb 510.9 | bsz 1 | num_updates 14845 | best_loss 9.157
2022-03-07 00:26:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14845 updates
2022-03-07 00:26:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:26:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:26:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 305 @ 14845 updates, score 13.235) (writing took 2.3526491560041904 seconds)
2022-03-07 00:26:26 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 00:26:26 | INFO | train | epoch 305 | loss 2.651 | nll_loss 0.481 | ppl 1.4 | wps 23664.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14845 | lr 0.000259543 | gnorm 0.514 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 41031
2022-03-07 00:26:26 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 00:26:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:28:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:28:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:28:38 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 13.224 | nll_loss 12.451 | ppl 5599.82 | wps 42005.1 | wpb 510.9 | bsz 1 | num_updates 14893 | best_loss 9.157
2022-03-07 00:28:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14893 updates
2022-03-07 00:28:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:28:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:28:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 306 @ 14893 updates, score 13.224) (writing took 2.4430050468072295 seconds)
2022-03-07 00:28:40 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 00:28:40 | INFO | train | epoch 306 | loss 2.649 | nll_loss 0.479 | ppl 1.39 | wps 23148.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 14893 | lr 0.000259125 | gnorm 0.507 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 41165
2022-03-07 00:28:40 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 00:28:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:28:59 | INFO | train_inner | epoch 307:      7 / 49 loss=2.649, nll_loss=0.479, ppl=1.39, wps=23443.9, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.509, loss_scale=32, train_wall=236, gb_free=8.8, wall=41184
2022-03-07 00:30:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:30:53 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 13.212 | nll_loss 12.434 | ppl 5533.28 | wps 40848.2 | wpb 510.9 | bsz 1 | num_updates 14942 | best_loss 9.157
2022-03-07 00:30:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14942 updates
2022-03-07 00:30:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:30:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:30:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 307 @ 14942 updates, score 13.212) (writing took 2.4100606171414256 seconds)
2022-03-07 00:30:56 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 00:30:56 | INFO | train | epoch 307 | loss 2.648 | nll_loss 0.478 | ppl 1.39 | wps 23498 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14942 | lr 0.0002587 | gnorm 0.502 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 41300
2022-03-07 00:30:56 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 00:30:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:33:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:33:10 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 13.113 | nll_loss 12.321 | ppl 5118.18 | wps 40687.3 | wpb 510.9 | bsz 1 | num_updates 14991 | best_loss 9.157
2022-03-07 00:33:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14991 updates
2022-03-07 00:33:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:33:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:33:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 308 @ 14991 updates, score 13.113) (writing took 2.4054050440900028 seconds)
2022-03-07 00:33:12 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 00:33:12 | INFO | train | epoch 308 | loss 2.648 | nll_loss 0.478 | ppl 1.39 | wps 23236.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14991 | lr 0.000258276 | gnorm 0.508 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 41437
2022-03-07 00:33:12 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 00:33:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:33:37 | INFO | train_inner | epoch 309:      9 / 49 loss=2.648, nll_loss=0.478, ppl=1.39, wps=23375.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.506, loss_scale=32, train_wall=236, gb_free=8.8, wall=41461
2022-03-07 00:34:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:35:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:35:27 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 13.222 | nll_loss 12.448 | ppl 5585.76 | wps 40365.3 | wpb 510.9 | bsz 1 | num_updates 15039 | best_loss 9.157
2022-03-07 00:35:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15039 updates
2022-03-07 00:35:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:35:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:35:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 309 @ 15039 updates, score 13.222) (writing took 2.4691206263378263 seconds)
2022-03-07 00:35:30 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 00:35:30 | INFO | train | epoch 309 | loss 2.645 | nll_loss 0.475 | ppl 1.39 | wps 22697.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 15039 | lr 0.000257864 | gnorm 0.502 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 41574
2022-03-07 00:35:30 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 00:35:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:37:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:37:44 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 13.155 | nll_loss 12.37 | ppl 5292.55 | wps 42139.5 | wpb 510.9 | bsz 1 | num_updates 15088 | best_loss 9.157
2022-03-07 00:37:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15088 updates
2022-03-07 00:37:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:37:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:37:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 310 @ 15088 updates, score 13.155) (writing took 2.4960660841315985 seconds)
2022-03-07 00:37:46 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 00:37:46 | INFO | train | epoch 310 | loss 2.645 | nll_loss 0.475 | ppl 1.39 | wps 23268.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15088 | lr 0.000257445 | gnorm 0.501 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 41711
2022-03-07 00:37:46 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 00:37:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:38:18 | INFO | train_inner | epoch 311:     12 / 49 loss=2.645, nll_loss=0.475, ppl=1.39, wps=23035.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.5, loss_scale=32, train_wall=240, gb_free=8.8, wall=41743
2022-03-07 00:38:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:39:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:40:00 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 13.12 | nll_loss 12.333 | ppl 5159.63 | wps 39728.6 | wpb 510.9 | bsz 1 | num_updates 15136 | best_loss 9.157
2022-03-07 00:40:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15136 updates
2022-03-07 00:40:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:40:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:40:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 311 @ 15136 updates, score 13.12) (writing took 2.5406820559874177 seconds)
2022-03-07 00:40:03 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 00:40:03 | INFO | train | epoch 311 | loss 2.643 | nll_loss 0.474 | ppl 1.39 | wps 22768.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 15136 | lr 0.000257036 | gnorm 0.503 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 41848
2022-03-07 00:40:03 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 00:40:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:42:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:42:17 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 13.132 | nll_loss 12.351 | ppl 5222.73 | wps 40944.3 | wpb 510.9 | bsz 1 | num_updates 15185 | best_loss 9.157
2022-03-07 00:42:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15185 updates
2022-03-07 00:42:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:42:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:42:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 312 @ 15185 updates, score 13.132) (writing took 2.413688640575856 seconds)
2022-03-07 00:42:19 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 00:42:19 | INFO | train | epoch 312 | loss 2.642 | nll_loss 0.472 | ppl 1.39 | wps 23334.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15185 | lr 0.000256621 | gnorm 0.498 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 41984
2022-03-07 00:42:19 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 00:42:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:42:59 | INFO | train_inner | epoch 313:     15 / 49 loss=2.642, nll_loss=0.473, ppl=1.39, wps=23087.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.499, loss_scale=16, train_wall=239, gb_free=8.8, wall=42024
2022-03-07 00:44:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:44:34 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 13.317 | nll_loss 12.555 | ppl 6016.98 | wps 40066.2 | wpb 510.9 | bsz 1 | num_updates 15234 | best_loss 9.157
2022-03-07 00:44:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15234 updates
2022-03-07 00:44:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:44:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:44:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 313 @ 15234 updates, score 13.317) (writing took 2.361830957233906 seconds)
2022-03-07 00:44:36 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 00:44:36 | INFO | train | epoch 313 | loss 2.641 | nll_loss 0.473 | ppl 1.39 | wps 23176.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15234 | lr 0.000256208 | gnorm 0.499 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 42121
2022-03-07 00:44:36 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 00:44:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:46:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:46:51 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 13.231 | nll_loss 12.46 | ppl 5632.76 | wps 40386 | wpb 510.9 | bsz 1 | num_updates 15283 | best_loss 9.157
2022-03-07 00:46:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15283 updates
2022-03-07 00:46:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:46:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:46:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 314 @ 15283 updates, score 13.231) (writing took 2.3197704320773482 seconds)
2022-03-07 00:46:53 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 00:46:53 | INFO | train | epoch 314 | loss 2.64 | nll_loss 0.472 | ppl 1.39 | wps 23180.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15283 | lr 0.000255797 | gnorm 0.498 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 42258
2022-03-07 00:46:53 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 00:46:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:47:39 | INFO | train_inner | epoch 315:     17 / 49 loss=2.641, nll_loss=0.472, ppl=1.39, wps=23194.3, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.499, loss_scale=32, train_wall=239, gb_free=8.8, wall=42304
2022-03-07 00:49:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:49:08 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 13.296 | nll_loss 12.52 | ppl 5874.49 | wps 40551.2 | wpb 510.9 | bsz 1 | num_updates 15332 | best_loss 9.157
2022-03-07 00:49:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15332 updates
2022-03-07 00:49:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:49:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:49:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 315 @ 15332 updates, score 13.296) (writing took 2.3643390689976513 seconds)
2022-03-07 00:49:10 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 00:49:10 | INFO | train | epoch 315 | loss 2.64 | nll_loss 0.471 | ppl 1.39 | wps 23203.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15332 | lr 0.000255388 | gnorm 0.503 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 42395
2022-03-07 00:49:10 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 00:49:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:50:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:51:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:51:25 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 13.143 | nll_loss 12.366 | ppl 5280.15 | wps 40598.9 | wpb 510.9 | bsz 1 | num_updates 15380 | best_loss 9.157
2022-03-07 00:51:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15380 updates
2022-03-07 00:51:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:51:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:51:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 316 @ 15380 updates, score 13.143) (writing took 2.455481301061809 seconds)
2022-03-07 00:51:27 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 00:51:27 | INFO | train | epoch 316 | loss 2.638 | nll_loss 0.469 | ppl 1.38 | wps 22697.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 15380 | lr 0.000254989 | gnorm 0.491 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 42532
2022-03-07 00:51:27 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 00:51:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:52:21 | INFO | train_inner | epoch 317:     20 / 49 loss=2.638, nll_loss=0.47, ppl=1.39, wps=23017, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.499, loss_scale=32, train_wall=240, gb_free=8.8, wall=42585
2022-03-07 00:53:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:53:42 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 13.181 | nll_loss 12.407 | ppl 5430.5 | wps 40743.1 | wpb 510.9 | bsz 1 | num_updates 15429 | best_loss 9.157
2022-03-07 00:53:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15429 updates
2022-03-07 00:53:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:53:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:53:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 317 @ 15429 updates, score 13.181) (writing took 2.4206146937794983 seconds)
2022-03-07 00:53:44 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 00:53:44 | INFO | train | epoch 317 | loss 2.638 | nll_loss 0.47 | ppl 1.38 | wps 23201.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15429 | lr 0.000254584 | gnorm 0.5 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 42669
2022-03-07 00:53:44 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 00:53:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:55:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:55:57 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 13.2 | nll_loss 12.432 | ppl 5525.6 | wps 42034.9 | wpb 510.9 | bsz 1 | num_updates 15478 | best_loss 9.157
2022-03-07 00:55:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15478 updates
2022-03-07 00:55:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:55:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:55:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 318 @ 15478 updates, score 13.2) (writing took 2.459488505963236 seconds)
2022-03-07 00:55:59 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 00:55:59 | INFO | train | epoch 318 | loss 2.636 | nll_loss 0.469 | ppl 1.38 | wps 23548 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15478 | lr 0.000254181 | gnorm 0.487 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 42804
2022-03-07 00:55:59 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 00:55:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:56:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:57:00 | INFO | train_inner | epoch 319:     23 / 49 loss=2.637, nll_loss=0.469, ppl=1.38, wps=23259, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.491, loss_scale=32, train_wall=238, gb_free=8.8, wall=42864
2022-03-07 00:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:58:12 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 13.169 | nll_loss 12.396 | ppl 5389 | wps 42440.4 | wpb 510.9 | bsz 1 | num_updates 15526 | best_loss 9.157
2022-03-07 00:58:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15526 updates
2022-03-07 00:58:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:58:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:58:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 319 @ 15526 updates, score 13.169) (writing took 2.4822620362974703 seconds)
2022-03-07 00:58:14 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 00:58:14 | INFO | train | epoch 319 | loss 2.636 | nll_loss 0.468 | ppl 1.38 | wps 23111.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 15526 | lr 0.000253787 | gnorm 0.494 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 42939
2022-03-07 00:58:14 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 00:58:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:00:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:00:26 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 13.256 | nll_loss 12.487 | ppl 5741.7 | wps 40130.7 | wpb 510.9 | bsz 1 | num_updates 15575 | best_loss 9.157
2022-03-07 01:00:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15575 updates
2022-03-07 01:00:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:00:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:00:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 320 @ 15575 updates, score 13.256) (writing took 2.5558168832212687 seconds)
2022-03-07 01:00:29 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 01:00:29 | INFO | train | epoch 320 | loss 2.634 | nll_loss 0.467 | ppl 1.38 | wps 23545.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15575 | lr 0.000253388 | gnorm 0.488 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 43074
2022-03-07 01:00:29 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 01:00:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:01:34 | INFO | train_inner | epoch 321:     25 / 49 loss=2.635, nll_loss=0.467, ppl=1.38, wps=23605.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.491, loss_scale=32, train_wall=234, gb_free=8.8, wall=43139
2022-03-07 01:02:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:02:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:02:41 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 13.26 | nll_loss 12.493 | ppl 5765.31 | wps 41692.9 | wpb 510.9 | bsz 1 | num_updates 15623 | best_loss 9.157
2022-03-07 01:02:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15623 updates
2022-03-07 01:02:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:02:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:02:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 321 @ 15623 updates, score 13.26) (writing took 2.4353113463148475 seconds)
2022-03-07 01:02:43 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 01:02:43 | INFO | train | epoch 321 | loss 2.634 | nll_loss 0.467 | ppl 1.38 | wps 23144.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 15623 | lr 0.000252998 | gnorm 0.495 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 43208
2022-03-07 01:02:43 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 01:02:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:04:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:04:56 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 13.193 | nll_loss 12.421 | ppl 5483.82 | wps 42319.7 | wpb 510.9 | bsz 1 | num_updates 15672 | best_loss 9.157
2022-03-07 01:04:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15672 updates
2022-03-07 01:04:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:04:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:04:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 322 @ 15672 updates, score 13.193) (writing took 2.5183952851220965 seconds)
2022-03-07 01:04:58 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 01:04:58 | INFO | train | epoch 322 | loss 2.633 | nll_loss 0.466 | ppl 1.38 | wps 23603.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15672 | lr 0.000252603 | gnorm 0.497 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 43343
2022-03-07 01:04:58 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 01:04:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:06:11 | INFO | train_inner | epoch 323:     28 / 49 loss=2.632, nll_loss=0.466, ppl=1.38, wps=23416.9, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.5, loss_scale=32, train_wall=236, gb_free=8.8, wall=43416
2022-03-07 01:07:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:07:10 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 13.274 | nll_loss 12.516 | ppl 5856.42 | wps 41913.1 | wpb 510.9 | bsz 1 | num_updates 15721 | best_loss 9.157
2022-03-07 01:07:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15721 updates
2022-03-07 01:07:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:07:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 323 @ 15721 updates, score 13.274) (writing took 2.3595858397893608 seconds)
2022-03-07 01:07:13 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 01:07:13 | INFO | train | epoch 323 | loss 2.631 | nll_loss 0.465 | ppl 1.38 | wps 23638.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15721 | lr 0.000252209 | gnorm 0.497 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 43477
2022-03-07 01:07:13 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 01:07:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:08:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:09:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:09:26 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 13.212 | nll_loss 12.439 | ppl 5554.09 | wps 40663.6 | wpb 510.9 | bsz 1 | num_updates 15769 | best_loss 9.157
2022-03-07 01:09:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15769 updates
2022-03-07 01:09:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:09:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:09:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 324 @ 15769 updates, score 13.212) (writing took 2.456479921936989 seconds)
2022-03-07 01:09:29 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 01:09:29 | INFO | train | epoch 324 | loss 2.63 | nll_loss 0.463 | ppl 1.38 | wps 22861.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 15769 | lr 0.000251824 | gnorm 0.494 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 43613
2022-03-07 01:09:29 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 01:09:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:10:52 | INFO | train_inner | epoch 325:     31 / 49 loss=2.63, nll_loss=0.464, ppl=1.38, wps=23159.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.488, loss_scale=32, train_wall=239, gb_free=8.8, wall=43696
2022-03-07 01:11:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:11:44 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 13.195 | nll_loss 12.42 | ppl 5480.55 | wps 40139.6 | wpb 510.9 | bsz 1 | num_updates 15818 | best_loss 9.157
2022-03-07 01:11:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15818 updates
2022-03-07 01:11:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:11:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:11:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 325 @ 15818 updates, score 13.195) (writing took 2.4280667738057673 seconds)
2022-03-07 01:11:46 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 01:11:46 | INFO | train | epoch 325 | loss 2.629 | nll_loss 0.463 | ppl 1.38 | wps 23132.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15818 | lr 0.000251434 | gnorm 0.488 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 43751
2022-03-07 01:11:46 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 01:11:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:13:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:14:01 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 13.217 | nll_loss 12.453 | ppl 5606.38 | wps 40567.6 | wpb 510.9 | bsz 1 | num_updates 15867 | best_loss 9.157
2022-03-07 01:14:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15867 updates
2022-03-07 01:14:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:14:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:14:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 326 @ 15867 updates, score 13.217) (writing took 2.367030490655452 seconds)
2022-03-07 01:14:03 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 01:14:03 | INFO | train | epoch 326 | loss 2.629 | nll_loss 0.463 | ppl 1.38 | wps 23191.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15867 | lr 0.000251046 | gnorm 0.486 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 43888
2022-03-07 01:14:03 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 01:14:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:14:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:15:34 | INFO | train_inner | epoch 327:     34 / 49 loss=2.628, nll_loss=0.462, ppl=1.38, wps=22989.6, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.486, loss_scale=32, train_wall=241, gb_free=8.8, wall=43978
2022-03-07 01:16:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:16:18 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 13.213 | nll_loss 12.44 | ppl 5557.05 | wps 40159.9 | wpb 510.9 | bsz 1 | num_updates 15915 | best_loss 9.157
2022-03-07 01:16:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15915 updates
2022-03-07 01:16:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:16:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:16:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 327 @ 15915 updates, score 13.213) (writing took 2.4705355670303106 seconds)
2022-03-07 01:16:20 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 01:16:20 | INFO | train | epoch 327 | loss 2.627 | nll_loss 0.461 | ppl 1.38 | wps 22706.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 15915 | lr 0.000250667 | gnorm 0.49 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 44025
2022-03-07 01:16:20 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 01:16:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:18:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:18:35 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 13.234 | nll_loss 12.462 | ppl 5642.55 | wps 40745.2 | wpb 510.9 | bsz 1 | num_updates 15964 | best_loss 9.157
2022-03-07 01:18:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15964 updates
2022-03-07 01:18:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:18:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:18:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 328 @ 15964 updates, score 13.234) (writing took 2.4483145279809833 seconds)
2022-03-07 01:18:37 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 01:18:37 | INFO | train | epoch 328 | loss 2.627 | nll_loss 0.461 | ppl 1.38 | wps 23191 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15964 | lr 0.000250282 | gnorm 0.484 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 44162
2022-03-07 01:18:37 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 01:18:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:20:13 | INFO | train_inner | epoch 329:     36 / 49 loss=2.627, nll_loss=0.461, ppl=1.38, wps=23204.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.491, loss_scale=32, train_wall=238, gb_free=8.8, wall=44258
2022-03-07 01:20:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:20:52 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 13.282 | nll_loss 12.517 | ppl 5860.01 | wps 39219.1 | wpb 510.9 | bsz 1 | num_updates 16012 | best_loss 9.157
2022-03-07 01:20:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16012 updates
2022-03-07 01:20:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:20:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:20:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 329 @ 16012 updates, score 13.282) (writing took 2.657217498868704 seconds)
2022-03-07 01:20:55 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 01:20:55 | INFO | train | epoch 329 | loss 2.626 | nll_loss 0.46 | ppl 1.38 | wps 22624.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 16012 | lr 0.000249906 | gnorm 0.493 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 44300
2022-03-07 01:20:55 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 01:20:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:23:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:23:09 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 13.187 | nll_loss 12.417 | ppl 5469.91 | wps 40647.4 | wpb 510.9 | bsz 1 | num_updates 16061 | best_loss 9.157
2022-03-07 01:23:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16061 updates
2022-03-07 01:23:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:23:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:23:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 330 @ 16061 updates, score 13.187) (writing took 2.5038741072639823 seconds)
2022-03-07 01:23:12 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 01:23:12 | INFO | train | epoch 330 | loss 2.624 | nll_loss 0.458 | ppl 1.37 | wps 23178.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16061 | lr 0.000249525 | gnorm 0.491 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 44437
2022-03-07 01:23:12 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 01:23:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:24:56 | INFO | train_inner | epoch 331:     39 / 49 loss=2.624, nll_loss=0.459, ppl=1.37, wps=22937, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.487, loss_scale=32, train_wall=241, gb_free=8.8, wall=44541
2022-03-07 01:25:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:25:27 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 13.154 | nll_loss 12.378 | ppl 5323.13 | wps 40985.9 | wpb 510.9 | bsz 1 | num_updates 16110 | best_loss 9.157
2022-03-07 01:25:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16110 updates
2022-03-07 01:25:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:25:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:25:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 331 @ 16110 updates, score 13.154) (writing took 2.4241177807562053 seconds)
2022-03-07 01:25:29 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 01:25:29 | INFO | train | epoch 331 | loss 2.624 | nll_loss 0.458 | ppl 1.37 | wps 23154.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16110 | lr 0.000249145 | gnorm 0.483 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 44574
2022-03-07 01:25:29 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 01:25:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:26:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:27:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:27:44 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 13.173 | nll_loss 12.404 | ppl 5419.03 | wps 40791.4 | wpb 510.9 | bsz 1 | num_updates 16158 | best_loss 9.157
2022-03-07 01:27:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16158 updates
2022-03-07 01:27:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:27:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:27:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 332 @ 16158 updates, score 13.173) (writing took 2.5016276137903333 seconds)
2022-03-07 01:27:46 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 01:27:46 | INFO | train | epoch 332 | loss 2.623 | nll_loss 0.458 | ppl 1.37 | wps 22676.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 16158 | lr 0.000248775 | gnorm 0.493 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 44711
2022-03-07 01:27:46 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 01:27:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:29:38 | INFO | train_inner | epoch 333:     42 / 49 loss=2.623, nll_loss=0.458, ppl=1.37, wps=22987.6, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.49, loss_scale=32, train_wall=241, gb_free=8.8, wall=44823
2022-03-07 01:29:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:30:01 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 13.246 | nll_loss 12.485 | ppl 5733.56 | wps 41496.8 | wpb 510.9 | bsz 1 | num_updates 16207 | best_loss 9.157
2022-03-07 01:30:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16207 updates
2022-03-07 01:30:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:30:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:30:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 333 @ 16207 updates, score 13.246) (writing took 2.464094764087349 seconds)
2022-03-07 01:30:03 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 01:30:03 | INFO | train | epoch 333 | loss 2.622 | nll_loss 0.457 | ppl 1.37 | wps 23218 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16207 | lr 0.000248398 | gnorm 0.488 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 44848
2022-03-07 01:30:03 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 01:30:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:32:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:32:17 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 13.239 | nll_loss 12.471 | ppl 5675.47 | wps 41630.5 | wpb 510.9 | bsz 1 | num_updates 16256 | best_loss 9.157
2022-03-07 01:32:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16256 updates
2022-03-07 01:32:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:32:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:32:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 334 @ 16256 updates, score 13.239) (writing took 2.5284796999767423 seconds)
2022-03-07 01:32:20 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 01:32:20 | INFO | train | epoch 334 | loss 2.62 | nll_loss 0.456 | ppl 1.37 | wps 23298.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16256 | lr 0.000248024 | gnorm 0.481 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 44984
2022-03-07 01:32:20 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 01:32:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:32:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:34:18 | INFO | train_inner | epoch 335:     45 / 49 loss=2.62, nll_loss=0.456, ppl=1.37, wps=23161, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.482, loss_scale=32, train_wall=239, gb_free=8.8, wall=45103
2022-03-07 01:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:34:33 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 13.182 | nll_loss 12.42 | ppl 5478.26 | wps 40806.6 | wpb 510.9 | bsz 1 | num_updates 16304 | best_loss 9.157
2022-03-07 01:34:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16304 updates
2022-03-07 01:34:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:34:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:34:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 335 @ 16304 updates, score 13.182) (writing took 2.4227622277103364 seconds)
2022-03-07 01:34:35 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 01:34:35 | INFO | train | epoch 335 | loss 2.62 | nll_loss 0.455 | ppl 1.37 | wps 22927.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 16304 | lr 0.000247658 | gnorm 0.483 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 45120
2022-03-07 01:34:35 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 01:34:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:36:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:36:50 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 13.196 | nll_loss 12.427 | ppl 5506.98 | wps 40428.6 | wpb 510.9 | bsz 1 | num_updates 16353 | best_loss 9.157
2022-03-07 01:36:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16353 updates
2022-03-07 01:36:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:36:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:36:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 336 @ 16353 updates, score 13.196) (writing took 2.4244668669998646 seconds)
2022-03-07 01:36:52 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 01:36:52 | INFO | train | epoch 336 | loss 2.619 | nll_loss 0.455 | ppl 1.37 | wps 23227 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16353 | lr 0.000247287 | gnorm 0.486 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 45257
2022-03-07 01:36:52 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 01:36:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:38:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:39:00 | INFO | train_inner | epoch 337:     48 / 49 loss=2.619, nll_loss=0.455, ppl=1.37, wps=23042.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=16400, lr=0.000246932, gnorm=0.484, loss_scale=32, train_wall=240, gb_free=8.8, wall=45385
2022-03-07 01:39:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:39:07 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 13.285 | nll_loss 12.522 | ppl 5881.16 | wps 40978.3 | wpb 510.9 | bsz 1 | num_updates 16401 | best_loss 9.157
2022-03-07 01:39:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16401 updates
2022-03-07 01:39:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:39:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:39:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 337 @ 16401 updates, score 13.285) (writing took 2.5573788229376078 seconds)
2022-03-07 01:39:09 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 01:39:09 | INFO | train | epoch 337 | loss 2.618 | nll_loss 0.454 | ppl 1.37 | wps 22740.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 16401 | lr 0.000246925 | gnorm 0.482 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 45394
2022-03-07 01:39:09 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 01:39:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:41:24 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 13.224 | nll_loss 12.456 | ppl 5617.48 | wps 39362.1 | wpb 510.9 | bsz 1 | num_updates 16450 | best_loss 9.157
2022-03-07 01:41:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16450 updates
2022-03-07 01:41:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:41:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:41:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 338 @ 16450 updates, score 13.224) (writing took 2.472931632772088 seconds)
2022-03-07 01:41:26 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 01:41:26 | INFO | train | epoch 338 | loss 2.617 | nll_loss 0.453 | ppl 1.37 | wps 23201.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16450 | lr 0.000246557 | gnorm 0.484 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 45531
2022-03-07 01:41:26 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 01:41:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:43:40 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 13.294 | nll_loss 12.535 | ppl 5934.53 | wps 42093.4 | wpb 510.9 | bsz 1 | num_updates 16499 | best_loss 9.157
2022-03-07 01:43:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16499 updates
2022-03-07 01:43:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:43:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:43:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 339 @ 16499 updates, score 13.294) (writing took 2.4042812450788915 seconds)
2022-03-07 01:43:43 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 01:43:43 | INFO | train | epoch 339 | loss 2.617 | nll_loss 0.453 | ppl 1.37 | wps 23267.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16499 | lr 0.00024619 | gnorm 0.489 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 45667
2022-03-07 01:43:43 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 01:43:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:43:46 | INFO | train_inner | epoch 340:      1 / 49 loss=2.617, nll_loss=0.453, ppl=1.37, wps=22598.9, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=16500, lr=0.000246183, gnorm=0.488, loss_scale=32, train_wall=236, gb_free=8.8, wall=45670
2022-03-07 01:44:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:45:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:45:57 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 13.231 | nll_loss 12.469 | ppl 5667.77 | wps 41409.7 | wpb 510.9 | bsz 1 | num_updates 16547 | best_loss 9.157
2022-03-07 01:45:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16547 updates
2022-03-07 01:45:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:45:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:45:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 340 @ 16547 updates, score 13.231) (writing took 2.50059159565717 seconds)
2022-03-07 01:45:59 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 01:45:59 | INFO | train | epoch 340 | loss 2.615 | nll_loss 0.451 | ppl 1.37 | wps 22793.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 16547 | lr 0.000245833 | gnorm 0.477 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 45804
2022-03-07 01:45:59 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 01:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:48:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:48:13 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 13.207 | nll_loss 12.442 | ppl 5562.84 | wps 40661 | wpb 510.9 | bsz 1 | num_updates 16596 | best_loss 9.157
2022-03-07 01:48:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16596 updates
2022-03-07 01:48:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:48:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:48:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 341 @ 16596 updates, score 13.207) (writing took 2.394584096968174 seconds)
2022-03-07 01:48:16 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 01:48:16 | INFO | train | epoch 341 | loss 2.614 | nll_loss 0.451 | ppl 1.37 | wps 23279.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16596 | lr 0.00024547 | gnorm 0.477 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 45941
2022-03-07 01:48:16 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 01:48:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:48:27 | INFO | train_inner | epoch 342:      4 / 49 loss=2.614, nll_loss=0.451, ppl=1.37, wps=23086.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=16600, lr=0.00024544, gnorm=0.477, loss_scale=32, train_wall=240, gb_free=8.8, wall=45951
2022-03-07 01:50:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:50:30 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 13.247 | nll_loss 12.484 | ppl 5730.55 | wps 40263.6 | wpb 510.9 | bsz 1 | num_updates 16645 | best_loss 9.157
2022-03-07 01:50:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16645 updates
2022-03-07 01:50:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:50:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:50:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 342 @ 16645 updates, score 13.247) (writing took 2.412637540139258 seconds)
2022-03-07 01:50:33 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 01:50:33 | INFO | train | epoch 342 | loss 2.614 | nll_loss 0.451 | ppl 1.37 | wps 23229.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16645 | lr 0.000245108 | gnorm 0.485 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 46077
2022-03-07 01:50:33 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 01:50:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:50:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:52:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:52:47 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 13.299 | nll_loss 12.545 | ppl 5976.74 | wps 40338.5 | wpb 510.9 | bsz 1 | num_updates 16693 | best_loss 9.157
2022-03-07 01:52:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16693 updates
2022-03-07 01:52:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:52:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:52:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 343 @ 16693 updates, score 13.299) (writing took 2.5270735071972013 seconds)
2022-03-07 01:52:50 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 01:52:50 | INFO | train | epoch 343 | loss 2.612 | nll_loss 0.449 | ppl 1.37 | wps 22706.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 16693 | lr 0.000244756 | gnorm 0.476 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 46214
2022-03-07 01:52:50 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 01:52:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:53:08 | INFO | train_inner | epoch 344:      7 / 49 loss=2.613, nll_loss=0.449, ppl=1.37, wps=23015.4, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.48, loss_scale=32, train_wall=240, gb_free=8.8, wall=46233
2022-03-07 01:54:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:55:04 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 13.231 | nll_loss 12.463 | ppl 5646.19 | wps 39942.2 | wpb 510.9 | bsz 1 | num_updates 16742 | best_loss 9.157
2022-03-07 01:55:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16742 updates
2022-03-07 01:55:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:55:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:55:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 344 @ 16742 updates, score 13.231) (writing took 2.40454329084605 seconds)
2022-03-07 01:55:06 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 01:55:06 | INFO | train | epoch 344 | loss 2.612 | nll_loss 0.449 | ppl 1.37 | wps 23263.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16742 | lr 0.000244397 | gnorm 0.48 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 46351
2022-03-07 01:55:06 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 01:55:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:56:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:57:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:57:20 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 13.263 | nll_loss 12.505 | ppl 5811.35 | wps 40245.7 | wpb 510.9 | bsz 1 | num_updates 16790 | best_loss 9.157
2022-03-07 01:57:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16790 updates
2022-03-07 01:57:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:57:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:57:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 345 @ 16790 updates, score 13.263) (writing took 2.4743076926097274 seconds)
2022-03-07 01:57:23 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 01:57:23 | INFO | train | epoch 345 | loss 2.611 | nll_loss 0.448 | ppl 1.36 | wps 22798.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 16790 | lr 0.000244048 | gnorm 0.479 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 46488
2022-03-07 01:57:23 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 01:57:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:57:49 | INFO | train_inner | epoch 346:     10 / 49 loss=2.611, nll_loss=0.448, ppl=1.36, wps=23082.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.48, loss_scale=32, train_wall=239, gb_free=8.8, wall=46514
2022-03-07 01:59:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:59:36 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 13.24 | nll_loss 12.471 | ppl 5678.02 | wps 42023.9 | wpb 510.9 | bsz 1 | num_updates 16839 | best_loss 9.157
2022-03-07 01:59:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16839 updates
2022-03-07 01:59:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:59:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:59:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 346 @ 16839 updates, score 13.24) (writing took 2.384872588329017 seconds)
2022-03-07 01:59:38 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 01:59:38 | INFO | train | epoch 346 | loss 2.611 | nll_loss 0.449 | ppl 1.36 | wps 23500.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16839 | lr 0.000243692 | gnorm 0.481 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 46623
2022-03-07 01:59:38 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 01:59:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:01:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:01:50 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 13.243 | nll_loss 12.488 | ppl 5743.45 | wps 40128 | wpb 510.9 | bsz 1 | num_updates 16888 | best_loss 9.157
2022-03-07 02:01:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16888 updates
2022-03-07 02:01:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:01:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:01:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 347 @ 16888 updates, score 13.243) (writing took 2.548914645332843 seconds)
2022-03-07 02:01:53 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 02:01:53 | INFO | train | epoch 347 | loss 2.609 | nll_loss 0.447 | ppl 1.36 | wps 23606.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16888 | lr 0.000243339 | gnorm 0.472 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 46757
2022-03-07 02:01:53 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 02:01:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:02:24 | INFO | train_inner | epoch 348:     12 / 49 loss=2.61, nll_loss=0.448, ppl=1.36, wps=23618.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.476, loss_scale=32, train_wall=234, gb_free=8.8, wall=46789
2022-03-07 02:02:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:03:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:04:05 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 13.19 | nll_loss 12.424 | ppl 5496.13 | wps 41319.6 | wpb 510.9 | bsz 1 | num_updates 16936 | best_loss 9.157
2022-03-07 02:04:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16936 updates
2022-03-07 02:04:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:04:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:04:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 348 @ 16936 updates, score 13.19) (writing took 2.342731773853302 seconds)
2022-03-07 02:04:07 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 02:04:07 | INFO | train | epoch 348 | loss 2.609 | nll_loss 0.447 | ppl 1.36 | wps 23142.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 16936 | lr 0.000242993 | gnorm 0.484 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 46892
2022-03-07 02:04:07 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 02:04:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:06:19 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 13.294 | nll_loss 12.54 | ppl 5953.68 | wps 41196.7 | wpb 510.9 | bsz 1 | num_updates 16985 | best_loss 9.157
2022-03-07 02:06:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16985 updates
2022-03-07 02:06:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:06:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:06:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 349 @ 16985 updates, score 13.294) (writing took 2.6555261141620576 seconds)
2022-03-07 02:06:22 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 02:06:22 | INFO | train | epoch 349 | loss 2.607 | nll_loss 0.445 | ppl 1.36 | wps 23583.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16985 | lr 0.000242643 | gnorm 0.474 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 47027
2022-03-07 02:06:22 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 02:06:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:07:01 | INFO | train_inner | epoch 350:     15 / 49 loss=2.608, nll_loss=0.445, ppl=1.36, wps=23414.2, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.478, loss_scale=32, train_wall=236, gb_free=8.8, wall=47066
2022-03-07 02:08:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:08:34 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 13.294 | nll_loss 12.54 | ppl 5954.77 | wps 41675.9 | wpb 510.9 | bsz 1 | num_updates 17034 | best_loss 9.157
2022-03-07 02:08:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17034 updates
2022-03-07 02:08:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:08:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:08:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 350 @ 17034 updates, score 13.294) (writing took 2.324134082067758 seconds)
2022-03-07 02:08:36 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 02:08:36 | INFO | train | epoch 350 | loss 2.606 | nll_loss 0.444 | ppl 1.36 | wps 23663.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17034 | lr 0.000242293 | gnorm 0.474 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 47161
2022-03-07 02:08:36 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 02:08:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:08:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:10:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:10:49 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 13.306 | nll_loss 12.551 | ppl 6000.08 | wps 40454.5 | wpb 510.9 | bsz 1 | num_updates 17082 | best_loss 9.157
2022-03-07 02:10:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17082 updates
2022-03-07 02:10:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:10:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:10:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 351 @ 17082 updates, score 13.306) (writing took 2.4010108658112586 seconds)
2022-03-07 02:10:51 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 02:10:51 | INFO | train | epoch 351 | loss 2.607 | nll_loss 0.445 | ppl 1.36 | wps 23079.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 17082 | lr 0.000241953 | gnorm 0.478 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 47296
2022-03-07 02:10:51 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 02:10:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:11:39 | INFO | train_inner | epoch 352:     18 / 49 loss=2.606, nll_loss=0.445, ppl=1.36, wps=23331, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.475, loss_scale=32, train_wall=237, gb_free=8.8, wall=47344
2022-03-07 02:13:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:13:06 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 13.26 | nll_loss 12.504 | ppl 5810 | wps 40147 | wpb 510.9 | bsz 1 | num_updates 17131 | best_loss 9.157
2022-03-07 02:13:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17131 updates
2022-03-07 02:13:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:13:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:13:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 352 @ 17131 updates, score 13.26) (writing took 2.6598566453903913 seconds)
2022-03-07 02:13:09 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 02:13:09 | INFO | train | epoch 352 | loss 2.605 | nll_loss 0.444 | ppl 1.36 | wps 23128.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17131 | lr 0.000241607 | gnorm 0.474 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 47433
2022-03-07 02:13:09 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 02:13:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:14:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:15:23 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 13.303 | nll_loss 12.541 | ppl 5959.11 | wps 39523.8 | wpb 510.9 | bsz 1 | num_updates 17179 | best_loss 9.157
2022-03-07 02:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17179 updates
2022-03-07 02:15:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:15:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:15:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 353 @ 17179 updates, score 13.303) (writing took 2.510129630099982 seconds)
2022-03-07 02:15:26 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 02:15:26 | INFO | train | epoch 353 | loss 2.605 | nll_loss 0.444 | ppl 1.36 | wps 22695 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 17179 | lr 0.000241269 | gnorm 0.478 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 47570
2022-03-07 02:15:26 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 02:15:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:16:21 | INFO | train_inner | epoch 354:     21 / 49 loss=2.605, nll_loss=0.443, ppl=1.36, wps=23000.3, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.477, loss_scale=32, train_wall=240, gb_free=8.8, wall=47626
2022-03-07 02:17:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:17:40 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 13.201 | nll_loss 12.435 | ppl 5537.78 | wps 40183.1 | wpb 510.9 | bsz 1 | num_updates 17228 | best_loss 9.157
2022-03-07 02:17:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17228 updates
2022-03-07 02:17:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:17:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:17:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 354 @ 17228 updates, score 13.201) (writing took 2.4244338939897716 seconds)
2022-03-07 02:17:42 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 02:17:42 | INFO | train | epoch 354 | loss 2.603 | nll_loss 0.442 | ppl 1.36 | wps 23308 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17228 | lr 0.000240925 | gnorm 0.469 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 47707
2022-03-07 02:17:42 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 02:17:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:19:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:19:56 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 13.337 | nll_loss 12.591 | ppl 6169.47 | wps 40760.2 | wpb 510.9 | bsz 1 | num_updates 17277 | best_loss 9.157
2022-03-07 02:19:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17277 updates
2022-03-07 02:19:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:19:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:19:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 355 @ 17277 updates, score 13.337) (writing took 2.431768358219415 seconds)
2022-03-07 02:19:58 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 02:19:58 | INFO | train | epoch 355 | loss 2.603 | nll_loss 0.442 | ppl 1.36 | wps 23313.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17277 | lr 0.000240583 | gnorm 0.471 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 47843
2022-03-07 02:19:58 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 02:19:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:20:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:21:02 | INFO | train_inner | epoch 356:     24 / 49 loss=2.603, nll_loss=0.441, ppl=1.36, wps=23096.4, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.47, loss_scale=32, train_wall=239, gb_free=8.8, wall=47907
2022-03-07 02:22:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:22:13 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 13.222 | nll_loss 12.459 | ppl 5629.58 | wps 39377.5 | wpb 510.9 | bsz 1 | num_updates 17325 | best_loss 9.157
2022-03-07 02:22:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17325 updates
2022-03-07 02:22:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:22:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:22:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 356 @ 17325 updates, score 13.222) (writing took 2.3746297378093004 seconds)
2022-03-07 02:22:15 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 02:22:15 | INFO | train | epoch 356 | loss 2.602 | nll_loss 0.441 | ppl 1.36 | wps 22749.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 17325 | lr 0.00024025 | gnorm 0.475 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 47980
2022-03-07 02:22:15 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 02:22:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:23:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:24:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:24:30 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 13.301 | nll_loss 12.544 | ppl 5970.98 | wps 40359.9 | wpb 510.9 | bsz 1 | num_updates 17373 | best_loss 9.157
2022-03-07 02:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17373 updates
2022-03-07 02:24:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:24:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:24:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 357 @ 17373 updates, score 13.301) (writing took 2.4622166361659765 seconds)
2022-03-07 02:24:32 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 02:24:32 | INFO | train | epoch 357 | loss 2.601 | nll_loss 0.44 | ppl 1.36 | wps 22704.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 17373 | lr 0.000239918 | gnorm 0.47 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 48117
2022-03-07 02:24:32 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 02:24:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:25:44 | INFO | train_inner | epoch 358:     27 / 49 loss=2.601, nll_loss=0.44, ppl=1.36, wps=22998.9, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.472, loss_scale=16, train_wall=240, gb_free=8.8, wall=48189
2022-03-07 02:26:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:26:47 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 13.288 | nll_loss 12.534 | ppl 5930.93 | wps 40337.6 | wpb 510.9 | bsz 1 | num_updates 17422 | best_loss 9.157
2022-03-07 02:26:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17422 updates
2022-03-07 02:26:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:26:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:26:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 358 @ 17422 updates, score 13.288) (writing took 2.3714654268696904 seconds)
2022-03-07 02:26:49 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 02:26:49 | INFO | train | epoch 358 | loss 2.6 | nll_loss 0.44 | ppl 1.36 | wps 23166.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17422 | lr 0.00023958 | gnorm 0.468 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 48254
2022-03-07 02:26:49 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 02:26:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:28:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:29:04 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 13.271 | nll_loss 12.514 | ppl 5848.51 | wps 40798.5 | wpb 510.9 | bsz 1 | num_updates 17471 | best_loss 9.157
2022-03-07 02:29:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17471 updates
2022-03-07 02:29:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:29:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:29:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 359 @ 17471 updates, score 13.271) (writing took 2.420753948856145 seconds)
2022-03-07 02:29:07 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 02:29:07 | INFO | train | epoch 359 | loss 2.6 | nll_loss 0.44 | ppl 1.36 | wps 23176.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17471 | lr 0.000239244 | gnorm 0.473 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 48391
2022-03-07 02:29:07 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 02:29:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:30:24 | INFO | train_inner | epoch 360:     29 / 49 loss=2.6, nll_loss=0.439, ppl=1.36, wps=23201.2, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.47, loss_scale=32, train_wall=238, gb_free=8.8, wall=48469
2022-03-07 02:31:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:31:21 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 13.329 | nll_loss 12.569 | ppl 6076.49 | wps 41098 | wpb 510.9 | bsz 1 | num_updates 17520 | best_loss 9.157
2022-03-07 02:31:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17520 updates
2022-03-07 02:31:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:31:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:31:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 360 @ 17520 updates, score 13.329) (writing took 2.5100924549624324 seconds)
2022-03-07 02:31:23 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 02:31:23 | INFO | train | epoch 360 | loss 2.599 | nll_loss 0.439 | ppl 1.36 | wps 23222.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17520 | lr 0.000238909 | gnorm 0.468 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 48528
2022-03-07 02:31:23 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 02:31:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:33:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:33:38 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 13.27 | nll_loss 12.511 | ppl 5837.22 | wps 40465.7 | wpb 510.9 | bsz 1 | num_updates 17569 | best_loss 9.157
2022-03-07 02:33:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17569 updates
2022-03-07 02:33:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:33:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:33:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 361 @ 17569 updates, score 13.27) (writing took 2.5228368900716305 seconds)
2022-03-07 02:33:40 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 02:33:40 | INFO | train | epoch 361 | loss 2.597 | nll_loss 0.437 | ppl 1.35 | wps 23202.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17569 | lr 0.000238576 | gnorm 0.458 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 48665
2022-03-07 02:33:40 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 02:33:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:35:02 | INFO | train_inner | epoch 362:     31 / 49 loss=2.598, nll_loss=0.438, ppl=1.35, wps=23345.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.465, loss_scale=32, train_wall=237, gb_free=8.8, wall=48746
2022-03-07 02:35:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:35:53 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 13.418 | nll_loss 12.674 | ppl 6535.23 | wps 41585 | wpb 510.9 | bsz 1 | num_updates 17618 | best_loss 9.157
2022-03-07 02:35:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17618 updates
2022-03-07 02:35:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:35:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:35:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 362 @ 17618 updates, score 13.418) (writing took 2.358556180726737 seconds)
2022-03-07 02:35:55 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 02:35:55 | INFO | train | epoch 362 | loss 2.598 | nll_loss 0.438 | ppl 1.35 | wps 23592.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17618 | lr 0.000238244 | gnorm 0.473 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 48800
2022-03-07 02:35:55 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 02:35:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:36:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:38:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:38:07 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 13.335 | nll_loss 12.585 | ppl 6142.61 | wps 42089.5 | wpb 510.9 | bsz 1 | num_updates 17666 | best_loss 9.157
2022-03-07 02:38:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17666 updates
2022-03-07 02:38:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:38:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:38:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 363 @ 17666 updates, score 13.335) (writing took 2.4093298609368503 seconds)
2022-03-07 02:38:10 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 02:38:10 | INFO | train | epoch 363 | loss 2.597 | nll_loss 0.437 | ppl 1.35 | wps 23145.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 17666 | lr 0.00023792 | gnorm 0.47 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 48934
2022-03-07 02:38:10 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 02:38:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:39:39 | INFO | train_inner | epoch 364:     34 / 49 loss=2.597, nll_loss=0.437, ppl=1.35, wps=23422.1, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.469, loss_scale=32, train_wall=236, gb_free=8.8, wall=49023
2022-03-07 02:40:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:40:22 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 13.267 | nll_loss 12.516 | ppl 5857.03 | wps 41874 | wpb 510.9 | bsz 1 | num_updates 17715 | best_loss 9.157
2022-03-07 02:40:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17715 updates
2022-03-07 02:40:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:40:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:40:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 364 @ 17715 updates, score 13.267) (writing took 2.3768625422380865 seconds)
2022-03-07 02:40:24 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 02:40:24 | INFO | train | epoch 364 | loss 2.596 | nll_loss 0.436 | ppl 1.35 | wps 23620.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17715 | lr 0.000237591 | gnorm 0.466 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 49069
2022-03-07 02:40:24 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 02:40:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:41:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:42:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:42:36 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 13.453 | nll_loss 12.713 | ppl 6715.18 | wps 41061.4 | wpb 510.9 | bsz 1 | num_updates 17763 | best_loss 9.157
2022-03-07 02:42:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17763 updates
2022-03-07 02:42:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:42:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:42:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 365 @ 17763 updates, score 13.453) (writing took 2.5517816338688135 seconds)
2022-03-07 02:42:39 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 02:42:39 | INFO | train | epoch 365 | loss 2.596 | nll_loss 0.437 | ppl 1.35 | wps 23063.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 17763 | lr 0.000237269 | gnorm 0.47 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 49204
2022-03-07 02:42:39 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 02:42:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:44:15 | INFO | train_inner | epoch 366:     37 / 49 loss=2.595, nll_loss=0.436, ppl=1.35, wps=23430.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.47, loss_scale=32, train_wall=236, gb_free=8.8, wall=49300
2022-03-07 02:44:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:44:51 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 13.254 | nll_loss 12.496 | ppl 5774.77 | wps 42427.7 | wpb 510.9 | bsz 1 | num_updates 17812 | best_loss 9.157
2022-03-07 02:44:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17812 updates
2022-03-07 02:44:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:44:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:44:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 366 @ 17812 updates, score 13.254) (writing took 2.396362863946706 seconds)
2022-03-07 02:44:53 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 02:44:53 | INFO | train | epoch 366 | loss 2.595 | nll_loss 0.435 | ppl 1.35 | wps 23669.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17812 | lr 0.000236943 | gnorm 0.471 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 49338
2022-03-07 02:44:53 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 02:44:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:47:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:47:05 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 13.317 | nll_loss 12.574 | ppl 6098.1 | wps 41985.1 | wpb 510.9 | bsz 1 | num_updates 17861 | best_loss 9.157
2022-03-07 02:47:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17861 updates
2022-03-07 02:47:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:47:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:47:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 367 @ 17861 updates, score 13.317) (writing took 2.3496611742302775 seconds)
2022-03-07 02:47:08 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 02:47:08 | INFO | train | epoch 367 | loss 2.593 | nll_loss 0.434 | ppl 1.35 | wps 23634.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17861 | lr 0.000236618 | gnorm 0.467 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 49473
2022-03-07 02:47:08 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 02:47:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:47:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:48:54 | INFO | train_inner | epoch 368:     40 / 49 loss=2.593, nll_loss=0.434, ppl=1.35, wps=23331.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.471, loss_scale=32, train_wall=237, gb_free=8.8, wall=49578
2022-03-07 02:49:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:49:22 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 13.235 | nll_loss 12.467 | ppl 5660.35 | wps 40842.5 | wpb 510.9 | bsz 1 | num_updates 17909 | best_loss 9.157
2022-03-07 02:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17909 updates
2022-03-07 02:49:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:49:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:49:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 368 @ 17909 updates, score 13.235) (writing took 2.3804593812674284 seconds)
2022-03-07 02:49:24 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 02:49:24 | INFO | train | epoch 368 | loss 2.593 | nll_loss 0.434 | ppl 1.35 | wps 22857.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 17909 | lr 0.0002363 | gnorm 0.476 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 49609
2022-03-07 02:49:24 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 02:49:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:51:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:51:39 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 13.36 | nll_loss 12.612 | ppl 6260.39 | wps 40988.8 | wpb 510.9 | bsz 1 | num_updates 17958 | best_loss 9.157
2022-03-07 02:51:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17958 updates
2022-03-07 02:51:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:51:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:51:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 369 @ 17958 updates, score 13.36) (writing took 2.5863646459765732 seconds)
2022-03-07 02:51:41 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 02:51:41 | INFO | train | epoch 369 | loss 2.592 | nll_loss 0.433 | ppl 1.35 | wps 23169.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17958 | lr 0.000235978 | gnorm 0.47 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 49746
2022-03-07 02:51:41 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 02:51:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:53:33 | INFO | train_inner | epoch 370:     42 / 49 loss=2.592, nll_loss=0.433, ppl=1.35, wps=23206.5, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.469, loss_scale=32, train_wall=238, gb_free=8.8, wall=49858
2022-03-07 02:53:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:53:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:53:56 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 13.235 | nll_loss 12.478 | ppl 5703.94 | wps 40716.2 | wpb 510.9 | bsz 1 | num_updates 18006 | best_loss 9.157
2022-03-07 02:53:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18006 updates
2022-03-07 02:53:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:53:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:53:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 370 @ 18006 updates, score 13.235) (writing took 2.530107931699604 seconds)
2022-03-07 02:53:58 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 02:53:58 | INFO | train | epoch 370 | loss 2.592 | nll_loss 0.433 | ppl 1.35 | wps 22660 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 18006 | lr 0.000235663 | gnorm 0.464 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 49883
2022-03-07 02:53:58 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 02:53:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:56:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:56:13 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 13.28 | nll_loss 12.525 | ppl 5895.86 | wps 40785 | wpb 510.9 | bsz 1 | num_updates 18055 | best_loss 9.157
2022-03-07 02:56:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18055 updates
2022-03-07 02:56:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:56:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:56:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 371 @ 18055 updates, score 13.28) (writing took 2.433101524133235 seconds)
2022-03-07 02:56:15 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 02:56:15 | INFO | train | epoch 371 | loss 2.591 | nll_loss 0.432 | ppl 1.35 | wps 23218.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18055 | lr 0.000235343 | gnorm 0.469 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 50020
2022-03-07 02:56:15 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 02:56:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:58:15 | INFO | train_inner | epoch 372:     45 / 49 loss=2.591, nll_loss=0.432, ppl=1.35, wps=23009.1, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.469, loss_scale=32, train_wall=240, gb_free=8.8, wall=50140
2022-03-07 02:58:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:58:30 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 13.296 | nll_loss 12.543 | ppl 5968.57 | wps 40558.8 | wpb 510.9 | bsz 1 | num_updates 18104 | best_loss 9.157
2022-03-07 02:58:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18104 updates
2022-03-07 02:58:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:58:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:58:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 372 @ 18104 updates, score 13.296) (writing took 2.547717328183353 seconds)
2022-03-07 02:58:32 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 02:58:32 | INFO | train | epoch 372 | loss 2.59 | nll_loss 0.431 | ppl 1.35 | wps 23199.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18104 | lr 0.000235024 | gnorm 0.47 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 50157
2022-03-07 02:58:32 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 02:58:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:59:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:00:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:00:47 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 13.332 | nll_loss 12.583 | ppl 6134.32 | wps 40802.6 | wpb 510.9 | bsz 1 | num_updates 18152 | best_loss 9.157
2022-03-07 03:00:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18152 updates
2022-03-07 03:00:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:00:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:00:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 373 @ 18152 updates, score 13.332) (writing took 2.405583695974201 seconds)
2022-03-07 03:00:49 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 03:00:49 | INFO | train | epoch 373 | loss 2.588 | nll_loss 0.43 | ppl 1.35 | wps 22749.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 18152 | lr 0.000234713 | gnorm 0.463 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 50294
2022-03-07 03:00:49 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 03:00:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:02:57 | INFO | train_inner | epoch 374:     48 / 49 loss=2.589, nll_loss=0.43, ppl=1.35, wps=23007.4, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=18200, lr=0.000234404, gnorm=0.461, loss_scale=32, train_wall=240, gb_free=8.8, wall=50422
2022-03-07 03:02:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:03:04 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 13.274 | nll_loss 12.518 | ppl 5864.51 | wps 39591.3 | wpb 510.9 | bsz 1 | num_updates 18201 | best_loss 9.157
2022-03-07 03:03:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18201 updates
2022-03-07 03:03:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:03:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:03:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 374 @ 18201 updates, score 13.274) (writing took 2.408894387073815 seconds)
2022-03-07 03:03:06 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 03:03:06 | INFO | train | epoch 374 | loss 2.588 | nll_loss 0.43 | ppl 1.35 | wps 23176.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18201 | lr 0.000234397 | gnorm 0.459 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 50431
2022-03-07 03:03:06 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 03:03:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:05:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:05:21 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 13.285 | nll_loss 12.534 | ppl 5931.77 | wps 40341.6 | wpb 510.9 | bsz 1 | num_updates 18250 | best_loss 9.157
2022-03-07 03:05:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18250 updates
2022-03-07 03:05:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:05:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:05:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 375 @ 18250 updates, score 13.285) (writing took 2.4286997742019594 seconds)
2022-03-07 03:05:24 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 03:05:24 | INFO | train | epoch 375 | loss 2.588 | nll_loss 0.43 | ppl 1.35 | wps 23147.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18250 | lr 0.000234082 | gnorm 0.467 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 50568
2022-03-07 03:05:24 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 03:05:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:05:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:07:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:07:38 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 13.261 | nll_loss 12.507 | ppl 5821.92 | wps 40917.2 | wpb 510.9 | bsz 1 | num_updates 18298 | best_loss 9.157
2022-03-07 03:07:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18298 updates
2022-03-07 03:07:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:07:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:07:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 376 @ 18298 updates, score 13.261) (writing took 2.425847484264523 seconds)
2022-03-07 03:07:41 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 03:07:41 | INFO | train | epoch 376 | loss 2.587 | nll_loss 0.429 | ppl 1.35 | wps 22725.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 18298 | lr 0.000233775 | gnorm 0.462 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 50705
2022-03-07 03:07:41 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 03:07:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:07:46 | INFO | train_inner | epoch 377:      2 / 49 loss=2.587, nll_loss=0.429, ppl=1.35, wps=22332.1, ups=0.35, wpb=64539.7, bsz=126.1, num_updates=18300, lr=0.000233762, gnorm=0.466, loss_scale=32, train_wall=240, gb_free=8.8, wall=50711
2022-03-07 03:09:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:09:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:09:55 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 13.191 | nll_loss 12.433 | ppl 5530.44 | wps 40855.4 | wpb 510.9 | bsz 1 | num_updates 18346 | best_loss 9.157
2022-03-07 03:09:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18346 updates
2022-03-07 03:09:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:09:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:09:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 377 @ 18346 updates, score 13.191) (writing took 2.6822596858255565 seconds)
2022-03-07 03:09:58 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 03:09:58 | INFO | train | epoch 377 | loss 2.586 | nll_loss 0.429 | ppl 1.35 | wps 22697.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 18346 | lr 0.000233469 | gnorm 0.465 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 50842
2022-03-07 03:09:58 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 03:09:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:12:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:12:11 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 13.256 | nll_loss 12.499 | ppl 5788.42 | wps 41802.3 | wpb 510.9 | bsz 1 | num_updates 18395 | best_loss 9.157
2022-03-07 03:12:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18395 updates
2022-03-07 03:12:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:12:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:12:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 378 @ 18395 updates, score 13.256) (writing took 2.323823851067573 seconds)
2022-03-07 03:12:14 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 03:12:14 | INFO | train | epoch 378 | loss 2.586 | nll_loss 0.429 | ppl 1.35 | wps 23357.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18395 | lr 0.000233158 | gnorm 0.46 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 50978
2022-03-07 03:12:14 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 03:12:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:12:27 | INFO | train_inner | epoch 379:      5 / 49 loss=2.586, nll_loss=0.429, ppl=1.35, wps=23083.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=18400, lr=0.000233126, gnorm=0.462, loss_scale=16, train_wall=240, gb_free=8.8, wall=50992
2022-03-07 03:14:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:14:26 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 13.25 | nll_loss 12.495 | ppl 5772.17 | wps 41366.1 | wpb 510.9 | bsz 1 | num_updates 18444 | best_loss 9.157
2022-03-07 03:14:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18444 updates
2022-03-07 03:14:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:14:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:14:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 379 @ 18444 updates, score 13.25) (writing took 2.428123699966818 seconds)
2022-03-07 03:14:28 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 03:14:28 | INFO | train | epoch 379 | loss 2.586 | nll_loss 0.429 | ppl 1.35 | wps 23582.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18444 | lr 0.000232848 | gnorm 0.46 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 51113
2022-03-07 03:14:29 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 03:14:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:16:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:16:41 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 13.21 | nll_loss 12.446 | ppl 5578.86 | wps 42510.3 | wpb 510.9 | bsz 1 | num_updates 18493 | best_loss 9.157
2022-03-07 03:16:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18493 updates
2022-03-07 03:16:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:16:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:16:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 380 @ 18493 updates, score 13.21) (writing took 2.3689035889692605 seconds)
2022-03-07 03:16:43 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 03:16:43 | INFO | train | epoch 380 | loss 2.584 | nll_loss 0.427 | ppl 1.34 | wps 23640.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18493 | lr 0.000232539 | gnorm 0.458 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 51248
2022-03-07 03:16:43 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 03:16:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:17:01 | INFO | train_inner | epoch 381:      7 / 49 loss=2.585, nll_loss=0.427, ppl=1.34, wps=23645.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.46, loss_scale=32, train_wall=234, gb_free=8.8, wall=51266
2022-03-07 03:18:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:18:55 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 13.305 | nll_loss 12.546 | ppl 5979.63 | wps 41406.6 | wpb 510.9 | bsz 1 | num_updates 18542 | best_loss 9.157
2022-03-07 03:18:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18542 updates
2022-03-07 03:18:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:18:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:18:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 381 @ 18542 updates, score 13.305) (writing took 2.3650575731880963 seconds)
2022-03-07 03:18:57 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 03:18:57 | INFO | train | epoch 381 | loss 2.584 | nll_loss 0.427 | ppl 1.34 | wps 23625.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18542 | lr 0.000232232 | gnorm 0.461 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 51382
2022-03-07 03:18:57 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 03:18:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:20:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:21:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:21:10 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 13.276 | nll_loss 12.52 | ppl 5873.22 | wps 42165.3 | wpb 510.9 | bsz 1 | num_updates 18590 | best_loss 9.157
2022-03-07 03:21:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18590 updates
2022-03-07 03:21:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:21:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:21:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 382 @ 18590 updates, score 13.276) (writing took 2.3416780293919146 seconds)
2022-03-07 03:21:12 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 03:21:12 | INFO | train | epoch 382 | loss 2.583 | nll_loss 0.426 | ppl 1.34 | wps 23138.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 18590 | lr 0.000231932 | gnorm 0.462 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 51517
2022-03-07 03:21:12 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 03:21:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:21:38 | INFO | train_inner | epoch 383:     10 / 49 loss=2.584, nll_loss=0.427, ppl=1.34, wps=23427.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.461, loss_scale=32, train_wall=236, gb_free=8.8, wall=51543
2022-03-07 03:23:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:23:24 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 13.276 | nll_loss 12.522 | ppl 5883.63 | wps 40891.6 | wpb 510.9 | bsz 1 | num_updates 18639 | best_loss 9.157
2022-03-07 03:23:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18639 updates
2022-03-07 03:23:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:23:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:23:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 383 @ 18639 updates, score 13.276) (writing took 2.5063979839906096 seconds)
2022-03-07 03:23:27 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 03:23:27 | INFO | train | epoch 383 | loss 2.583 | nll_loss 0.427 | ppl 1.34 | wps 23559.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18639 | lr 0.000231627 | gnorm 0.462 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 51652
2022-03-07 03:23:27 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 03:23:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:25:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:25:40 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 13.22 | nll_loss 12.459 | ppl 5630.98 | wps 40472.4 | wpb 510.9 | bsz 1 | num_updates 18688 | best_loss 9.157
2022-03-07 03:25:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18688 updates
2022-03-07 03:25:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:25:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:25:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 384 @ 18688 updates, score 13.22) (writing took 2.4210735727101564 seconds)
2022-03-07 03:25:42 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 03:25:42 | INFO | train | epoch 384 | loss 2.582 | nll_loss 0.425 | ppl 1.34 | wps 23524.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18688 | lr 0.000231323 | gnorm 0.458 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 51787
2022-03-07 03:25:42 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 03:25:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:26:14 | INFO | train_inner | epoch 385:     12 / 49 loss=2.582, nll_loss=0.425, ppl=1.34, wps=23528, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.46, loss_scale=32, train_wall=235, gb_free=8.8, wall=51819
2022-03-07 03:26:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:27:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:27:57 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 13.281 | nll_loss 12.526 | ppl 5897.85 | wps 40664.3 | wpb 510.9 | bsz 1 | num_updates 18736 | best_loss 9.157
2022-03-07 03:27:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18736 updates
2022-03-07 03:27:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:27:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:27:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 385 @ 18736 updates, score 13.281) (writing took 2.4401521082036197 seconds)
2022-03-07 03:27:59 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 03:27:59 | INFO | train | epoch 385 | loss 2.581 | nll_loss 0.424 | ppl 1.34 | wps 22689.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 18736 | lr 0.000231026 | gnorm 0.454 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 51924
2022-03-07 03:27:59 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 03:27:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:30:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:30:14 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 13.274 | nll_loss 12.518 | ppl 5866.84 | wps 40634.9 | wpb 510.9 | bsz 1 | num_updates 18785 | best_loss 9.157
2022-03-07 03:30:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18785 updates
2022-03-07 03:30:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:30:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:30:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 386 @ 18785 updates, score 13.274) (writing took 2.4135236241854727 seconds)
2022-03-07 03:30:16 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 03:30:16 | INFO | train | epoch 386 | loss 2.58 | nll_loss 0.424 | ppl 1.34 | wps 23185.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18785 | lr 0.000230725 | gnorm 0.457 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 52061
2022-03-07 03:30:16 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 03:30:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:30:56 | INFO | train_inner | epoch 387:     15 / 49 loss=2.58, nll_loss=0.424, ppl=1.34, wps=22979.5, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.454, loss_scale=32, train_wall=241, gb_free=8.8, wall=52101
2022-03-07 03:32:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:32:31 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 13.276 | nll_loss 12.521 | ppl 5877.11 | wps 40629.5 | wpb 510.9 | bsz 1 | num_updates 18834 | best_loss 9.157
2022-03-07 03:32:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18834 updates
2022-03-07 03:32:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:32:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:32:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 387 @ 18834 updates, score 13.276) (writing took 2.509825467597693 seconds)
2022-03-07 03:32:33 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 03:32:33 | INFO | train | epoch 387 | loss 2.579 | nll_loss 0.422 | ppl 1.34 | wps 23150.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18834 | lr 0.000230425 | gnorm 0.452 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 52198
2022-03-07 03:32:33 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 03:32:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:32:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:34:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:34:48 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 13.266 | nll_loss 12.519 | ppl 5868.45 | wps 40087.6 | wpb 510.9 | bsz 1 | num_updates 18882 | best_loss 9.157
2022-03-07 03:34:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18882 updates
2022-03-07 03:34:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:34:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:34:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 388 @ 18882 updates, score 13.266) (writing took 2.515357410069555 seconds)
2022-03-07 03:34:51 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 03:34:51 | INFO | train | epoch 388 | loss 2.579 | nll_loss 0.423 | ppl 1.34 | wps 22675.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 18882 | lr 0.000230131 | gnorm 0.457 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 52335
2022-03-07 03:34:51 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 03:34:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:35:39 | INFO | train_inner | epoch 389:     18 / 49 loss=2.579, nll_loss=0.423, ppl=1.34, wps=22968.5, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.459, loss_scale=32, train_wall=241, gb_free=8.8, wall=52383
2022-03-07 03:37:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:37:05 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 13.334 | nll_loss 12.588 | ppl 6157.48 | wps 40690.6 | wpb 510.9 | bsz 1 | num_updates 18931 | best_loss 9.157
2022-03-07 03:37:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18931 updates
2022-03-07 03:37:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:37:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:37:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 389 @ 18931 updates, score 13.334) (writing took 2.39201526530087 seconds)
2022-03-07 03:37:08 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 03:37:08 | INFO | train | epoch 389 | loss 2.579 | nll_loss 0.423 | ppl 1.34 | wps 23208.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18931 | lr 0.000229833 | gnorm 0.47 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 52472
2022-03-07 03:37:08 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 03:37:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:38:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:39:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:39:22 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 13.187 | nll_loss 12.418 | ppl 5473.85 | wps 40322.3 | wpb 510.9 | bsz 1 | num_updates 18979 | best_loss 9.157
2022-03-07 03:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18979 updates
2022-03-07 03:39:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:39:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:39:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 390 @ 18979 updates, score 13.187) (writing took 2.440797918010503 seconds)
2022-03-07 03:39:25 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 03:39:25 | INFO | train | epoch 390 | loss 2.577 | nll_loss 0.422 | ppl 1.34 | wps 22730.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 18979 | lr 0.000229543 | gnorm 0.456 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 52609
2022-03-07 03:39:25 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 03:39:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:40:21 | INFO | train_inner | epoch 391:     21 / 49 loss=2.578, nll_loss=0.422, ppl=1.34, wps=23010.1, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.46, loss_scale=32, train_wall=240, gb_free=8.8, wall=52665
2022-03-07 03:41:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:41:39 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 13.212 | nll_loss 12.456 | ppl 5619.33 | wps 40564.5 | wpb 510.9 | bsz 1 | num_updates 19028 | best_loss 9.157
2022-03-07 03:41:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19028 updates
2022-03-07 03:41:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:41:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:41:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 391 @ 19028 updates, score 13.212) (writing took 2.3829744081012905 seconds)
2022-03-07 03:41:42 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 03:41:42 | INFO | train | epoch 391 | loss 2.577 | nll_loss 0.422 | ppl 1.34 | wps 23177.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19028 | lr 0.000229247 | gnorm 0.46 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 52746
2022-03-07 03:41:42 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 03:41:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:43:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:43:56 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 13.331 | nll_loss 12.587 | ppl 6150.57 | wps 40051.6 | wpb 510.9 | bsz 1 | num_updates 19077 | best_loss 9.157
2022-03-07 03:43:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19077 updates
2022-03-07 03:43:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:43:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:43:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 392 @ 19077 updates, score 13.331) (writing took 2.4456781637854874 seconds)
2022-03-07 03:43:59 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 03:43:59 | INFO | train | epoch 392 | loss 2.575 | nll_loss 0.42 | ppl 1.34 | wps 23181.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19077 | lr 0.000228952 | gnorm 0.456 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 52884
2022-03-07 03:43:59 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 03:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:44:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:45:03 | INFO | train_inner | epoch 393:     24 / 49 loss=2.576, nll_loss=0.42, ppl=1.34, wps=23012, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.457, loss_scale=32, train_wall=240, gb_free=8.8, wall=52947
2022-03-07 03:46:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:46:13 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 13.31 | nll_loss 12.563 | ppl 6051.13 | wps 40679.3 | wpb 510.9 | bsz 1 | num_updates 19125 | best_loss 9.157
2022-03-07 03:46:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19125 updates
2022-03-07 03:46:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:46:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:46:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 393 @ 19125 updates, score 13.31) (writing took 2.4270315202884376 seconds)
2022-03-07 03:46:15 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 03:46:15 | INFO | train | epoch 393 | loss 2.576 | nll_loss 0.42 | ppl 1.34 | wps 22833.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 19125 | lr 0.000228665 | gnorm 0.458 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 53020
2022-03-07 03:46:15 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 03:46:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:48:29 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 13.306 | nll_loss 12.554 | ppl 6011.65 | wps 41159.2 | wpb 510.9 | bsz 1 | num_updates 19174 | best_loss 9.157
2022-03-07 03:48:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19174 updates
2022-03-07 03:48:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:48:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:48:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 394 @ 19174 updates, score 13.306) (writing took 2.3469942351803184 seconds)
2022-03-07 03:48:31 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 03:48:31 | INFO | train | epoch 394 | loss 2.575 | nll_loss 0.419 | ppl 1.34 | wps 23416 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19174 | lr 0.000228372 | gnorm 0.451 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 53156
2022-03-07 03:48:31 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 03:48:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:49:40 | INFO | train_inner | epoch 395:     26 / 49 loss=2.575, nll_loss=0.42, ppl=1.34, wps=23417.5, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.452, loss_scale=32, train_wall=236, gb_free=8.8, wall=53224
2022-03-07 03:50:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:50:44 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 13.253 | nll_loss 12.498 | ppl 5783.58 | wps 41917.3 | wpb 510.9 | bsz 1 | num_updates 19223 | best_loss 9.157
2022-03-07 03:50:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19223 updates
2022-03-07 03:50:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:50:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:50:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 395 @ 19223 updates, score 13.253) (writing took 2.4130372339859605 seconds)
2022-03-07 03:50:46 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 03:50:46 | INFO | train | epoch 395 | loss 2.574 | nll_loss 0.419 | ppl 1.34 | wps 23481.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19223 | lr 0.000228081 | gnorm 0.451 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 53291
2022-03-07 03:50:46 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 03:50:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:50:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:52:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:52:59 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 13.339 | nll_loss 12.593 | ppl 6178.78 | wps 40634.2 | wpb 510.9 | bsz 1 | num_updates 19271 | best_loss 9.157
2022-03-07 03:52:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19271 updates
2022-03-07 03:52:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:53:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:53:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 396 @ 19271 updates, score 13.339) (writing took 2.345406226348132 seconds)
2022-03-07 03:53:02 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 03:53:02 | INFO | train | epoch 396 | loss 2.573 | nll_loss 0.418 | ppl 1.34 | wps 23002.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 19271 | lr 0.000227797 | gnorm 0.455 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 53426
2022-03-07 03:53:02 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 03:53:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:54:19 | INFO | train_inner | epoch 397:     29 / 49 loss=2.573, nll_loss=0.419, ppl=1.34, wps=23238.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.454, loss_scale=32, train_wall=238, gb_free=8.8, wall=53503
2022-03-07 03:55:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:55:16 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 13.219 | nll_loss 12.462 | ppl 5642.51 | wps 41383.4 | wpb 510.9 | bsz 1 | num_updates 19320 | best_loss 9.157
2022-03-07 03:55:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19320 updates
2022-03-07 03:55:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:55:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:55:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 397 @ 19320 updates, score 13.219) (writing took 2.548372993245721 seconds)
2022-03-07 03:55:18 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 03:55:18 | INFO | train | epoch 397 | loss 2.574 | nll_loss 0.419 | ppl 1.34 | wps 23247.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19320 | lr 0.000227508 | gnorm 0.452 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 53563
2022-03-07 03:55:18 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 03:55:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:56:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:57:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:57:32 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 13.343 | nll_loss 12.607 | ppl 6237.04 | wps 41248.4 | wpb 510.9 | bsz 1 | num_updates 19368 | best_loss 9.157
2022-03-07 03:57:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19368 updates
2022-03-07 03:57:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:57:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:57:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 398 @ 19368 updates, score 13.343) (writing took 2.496640916913748 seconds)
2022-03-07 03:57:34 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-07 03:57:34 | INFO | train | epoch 398 | loss 2.572 | nll_loss 0.417 | ppl 1.34 | wps 22860.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 19368 | lr 0.000227226 | gnorm 0.452 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 53699
2022-03-07 03:57:34 | INFO | fairseq.trainer | begin training epoch 399
2022-03-07 03:57:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:58:59 | INFO | train_inner | epoch 399:     32 / 49 loss=2.573, nll_loss=0.418, ppl=1.34, wps=23147.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.452, loss_scale=32, train_wall=239, gb_free=8.8, wall=53784
2022-03-07 03:59:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:59:48 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 13.276 | nll_loss 12.53 | ppl 5916.21 | wps 40833 | wpb 510.9 | bsz 1 | num_updates 19417 | best_loss 9.157
2022-03-07 03:59:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19417 updates
2022-03-07 03:59:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:59:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:59:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 399 @ 19417 updates, score 13.276) (writing took 2.386696747969836 seconds)
2022-03-07 03:59:50 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-07 03:59:50 | INFO | train | epoch 399 | loss 2.572 | nll_loss 0.418 | ppl 1.34 | wps 23373.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19417 | lr 0.000226939 | gnorm 0.45 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 53835
2022-03-07 03:59:50 | INFO | fairseq.trainer | begin training epoch 400
2022-03-07 03:59:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:01:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:02:05 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 13.315 | nll_loss 12.57 | ppl 6078.59 | wps 40832.1 | wpb 510.9 | bsz 1 | num_updates 19466 | best_loss 9.157
2022-03-07 04:02:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19466 updates
2022-03-07 04:02:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:02:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:02:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 400 @ 19466 updates, score 13.315) (writing took 2.47112994780764 seconds)
2022-03-07 04:02:07 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-07 04:02:07 | INFO | train | epoch 400 | loss 2.57 | nll_loss 0.416 | ppl 1.33 | wps 23221.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19466 | lr 0.000226653 | gnorm 0.452 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 53972
2022-03-07 04:02:07 | INFO | fairseq.trainer | begin training epoch 401
2022-03-07 04:02:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:02:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:03:40 | INFO | train_inner | epoch 401:     35 / 49 loss=2.571, nll_loss=0.416, ppl=1.33, wps=23073.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.45, loss_scale=32, train_wall=240, gb_free=8.8, wall=54065
2022-03-07 04:04:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:04:21 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 13.242 | nll_loss 12.494 | ppl 5769.15 | wps 40839.9 | wpb 510.9 | bsz 1 | num_updates 19514 | best_loss 9.157
2022-03-07 04:04:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19514 updates
2022-03-07 04:04:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:04:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:04:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 401 @ 19514 updates, score 13.242) (writing took 2.3848309400491416 seconds)
2022-03-07 04:04:24 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-07 04:04:24 | INFO | train | epoch 401 | loss 2.57 | nll_loss 0.415 | ppl 1.33 | wps 22792.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 19514 | lr 0.000226374 | gnorm 0.45 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 54109
2022-03-07 04:04:24 | INFO | fairseq.trainer | begin training epoch 402
2022-03-07 04:04:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:06:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:06:38 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 13.337 | nll_loss 12.591 | ppl 6169.41 | wps 40729.1 | wpb 510.9 | bsz 1 | num_updates 19563 | best_loss 9.157
2022-03-07 04:06:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19563 updates
2022-03-07 04:06:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:06:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:06:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 402 @ 19563 updates, score 13.337) (writing took 2.395926265977323 seconds)
2022-03-07 04:06:41 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-07 04:06:41 | INFO | train | epoch 402 | loss 2.571 | nll_loss 0.417 | ppl 1.33 | wps 23227.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19563 | lr 0.00022609 | gnorm 0.447 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 54245
2022-03-07 04:06:41 | INFO | fairseq.trainer | begin training epoch 403
2022-03-07 04:06:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:08:19 | INFO | train_inner | epoch 403:     37 / 49 loss=2.57, nll_loss=0.416, ppl=1.33, wps=23272.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.448, loss_scale=32, train_wall=238, gb_free=8.8, wall=54344
2022-03-07 04:08:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:08:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:08:55 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 13.289 | nll_loss 12.54 | ppl 5957.01 | wps 41011.7 | wpb 510.9 | bsz 1 | num_updates 19611 | best_loss 9.157
2022-03-07 04:08:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19611 updates
2022-03-07 04:08:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:08:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:08:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 403 @ 19611 updates, score 13.289) (writing took 2.4152766899205744 seconds)
2022-03-07 04:08:57 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-07 04:08:57 | INFO | train | epoch 403 | loss 2.57 | nll_loss 0.416 | ppl 1.33 | wps 22768.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 19611 | lr 0.000225814 | gnorm 0.45 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 54382
2022-03-07 04:08:57 | INFO | fairseq.trainer | begin training epoch 404
2022-03-07 04:08:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:11:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:11:12 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 13.29 | nll_loss 12.539 | ppl 5951.38 | wps 40915.2 | wpb 510.9 | bsz 1 | num_updates 19660 | best_loss 9.157
2022-03-07 04:11:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19660 updates
2022-03-07 04:11:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:11:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:11:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 404 @ 19660 updates, score 13.29) (writing took 2.3516061999835074 seconds)
2022-03-07 04:11:14 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-07 04:11:14 | INFO | train | epoch 404 | loss 2.569 | nll_loss 0.415 | ppl 1.33 | wps 23264.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19660 | lr 0.000225532 | gnorm 0.453 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 54519
2022-03-07 04:11:14 | INFO | fairseq.trainer | begin training epoch 405
2022-03-07 04:11:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:13:00 | INFO | train_inner | epoch 405:     40 / 49 loss=2.569, nll_loss=0.415, ppl=1.33, wps=23059, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.453, loss_scale=32, train_wall=240, gb_free=8.8, wall=54625
2022-03-07 04:13:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:13:28 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 13.192 | nll_loss 12.435 | ppl 5536.23 | wps 40806.3 | wpb 510.9 | bsz 1 | num_updates 19709 | best_loss 9.157
2022-03-07 04:13:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19709 updates
2022-03-07 04:13:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:13:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:13:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 405 @ 19709 updates, score 13.192) (writing took 2.461126022040844 seconds)
2022-03-07 04:13:31 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-07 04:13:31 | INFO | train | epoch 405 | loss 2.568 | nll_loss 0.415 | ppl 1.33 | wps 23258.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19709 | lr 0.000225252 | gnorm 0.452 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 54655
2022-03-07 04:13:31 | INFO | fairseq.trainer | begin training epoch 406
2022-03-07 04:13:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:14:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:15:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:15:45 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 13.274 | nll_loss 12.524 | ppl 5887.85 | wps 40603.6 | wpb 510.9 | bsz 1 | num_updates 19757 | best_loss 9.157
2022-03-07 04:15:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19757 updates
2022-03-07 04:15:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:15:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:15:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 406 @ 19757 updates, score 13.274) (writing took 2.5383818987756968 seconds)
2022-03-07 04:15:47 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-07 04:15:47 | INFO | train | epoch 406 | loss 2.567 | nll_loss 0.413 | ppl 1.33 | wps 22752.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 19757 | lr 0.000224978 | gnorm 0.446 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 54792
2022-03-07 04:15:47 | INFO | fairseq.trainer | begin training epoch 407
2022-03-07 04:15:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:17:41 | INFO | train_inner | epoch 407:     43 / 49 loss=2.567, nll_loss=0.414, ppl=1.33, wps=23109.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.444, loss_scale=32, train_wall=239, gb_free=8.8, wall=54906
2022-03-07 04:17:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:18:01 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 13.3 | nll_loss 12.559 | ppl 6036.27 | wps 42089.1 | wpb 510.9 | bsz 1 | num_updates 19806 | best_loss 9.157
2022-03-07 04:18:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19806 updates
2022-03-07 04:18:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:18:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:18:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 407 @ 19806 updates, score 13.3) (writing took 2.3389210691675544 seconds)
2022-03-07 04:18:03 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-07 04:18:03 | INFO | train | epoch 407 | loss 2.567 | nll_loss 0.413 | ppl 1.33 | wps 23440.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19806 | lr 0.000224699 | gnorm 0.444 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 54928
2022-03-07 04:18:03 | INFO | fairseq.trainer | begin training epoch 408
2022-03-07 04:18:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:20:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:20:15 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 13.322 | nll_loss 12.581 | ppl 6126.07 | wps 42171.9 | wpb 510.9 | bsz 1 | num_updates 19855 | best_loss 9.157
2022-03-07 04:20:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19855 updates
2022-03-07 04:20:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:20:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:20:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 408 @ 19855 updates, score 13.322) (writing took 2.3573995563201606 seconds)
2022-03-07 04:20:17 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-07 04:20:17 | INFO | train | epoch 408 | loss 2.568 | nll_loss 0.414 | ppl 1.33 | wps 23637.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19855 | lr 0.000224422 | gnorm 0.455 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 55062
2022-03-07 04:20:17 | INFO | fairseq.trainer | begin training epoch 409
2022-03-07 04:20:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:20:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:22:18 | INFO | train_inner | epoch 409:     46 / 49 loss=2.567, nll_loss=0.414, ppl=1.33, wps=23438.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.452, loss_scale=32, train_wall=236, gb_free=8.8, wall=55182
2022-03-07 04:22:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:22:29 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 13.333 | nll_loss 12.585 | ppl 6145.2 | wps 41853.6 | wpb 510.9 | bsz 1 | num_updates 19903 | best_loss 9.157
2022-03-07 04:22:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19903 updates
2022-03-07 04:22:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:22:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:22:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 409 @ 19903 updates, score 13.333) (writing took 2.3602063138969243 seconds)
2022-03-07 04:22:32 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-07 04:22:32 | INFO | train | epoch 409 | loss 2.566 | nll_loss 0.413 | ppl 1.33 | wps 23145.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 19903 | lr 0.000224151 | gnorm 0.449 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 55197
2022-03-07 04:22:32 | INFO | fairseq.trainer | begin training epoch 410
2022-03-07 04:22:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:24:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:24:44 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 13.347 | nll_loss 12.612 | ppl 6261.79 | wps 41362 | wpb 510.9 | bsz 1 | num_updates 19952 | best_loss 9.157
2022-03-07 04:24:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19952 updates
2022-03-07 04:24:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:24:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:24:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 410 @ 19952 updates, score 13.347) (writing took 2.3741079587489367 seconds)
2022-03-07 04:24:46 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-07 04:24:46 | INFO | train | epoch 410 | loss 2.565 | nll_loss 0.412 | ppl 1.33 | wps 23630.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19952 | lr 0.000223876 | gnorm 0.442 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 55331
2022-03-07 04:24:46 | INFO | fairseq.trainer | begin training epoch 411
2022-03-07 04:24:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:26:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:26:53 | INFO | train_inner | epoch 411:     49 / 49 loss=2.565, nll_loss=0.412, ppl=1.33, wps=23425.2, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=20000, lr=0.000223607, gnorm=0.445, loss_scale=32, train_wall=235, gb_free=8.8, wall=55458
2022-03-07 04:26:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:26:58 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 13.265 | nll_loss 12.515 | ppl 5851.26 | wps 42293.2 | wpb 510.9 | bsz 1 | num_updates 20000 | best_loss 9.157
2022-03-07 04:26:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 20000 updates
2022-03-07 04:26:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:27:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:27:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 411 @ 20000 updates, score 13.265) (writing took 2.5074650570750237 seconds)
2022-03-07 04:27:01 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-07 04:27:01 | INFO | train | epoch 411 | loss 2.564 | nll_loss 0.411 | ppl 1.33 | wps 23114.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 20000 | lr 0.000223607 | gnorm 0.444 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 55466
2022-03-07 04:27:01 | INFO | fairseq.trainer | begin training epoch 412
2022-03-07 04:27:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:29:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:29:13 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 13.317 | nll_loss 12.568 | ppl 6073.42 | wps 40817.9 | wpb 510.9 | bsz 1 | num_updates 20049 | best_loss 9.157
2022-03-07 04:29:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20049 updates
2022-03-07 04:29:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:29:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:29:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 412 @ 20049 updates, score 13.317) (writing took 2.4140165550634265 seconds)
2022-03-07 04:29:16 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-07 04:29:16 | INFO | train | epoch 412 | loss 2.565 | nll_loss 0.412 | ppl 1.33 | wps 23626.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20049 | lr 0.000223333 | gnorm 0.455 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 55600
2022-03-07 04:29:16 | INFO | fairseq.trainer | begin training epoch 413
2022-03-07 04:29:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:31:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:31:30 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 13.391 | nll_loss 12.653 | ppl 6440.53 | wps 40861.3 | wpb 510.9 | bsz 1 | num_updates 20098 | best_loss 9.157
2022-03-07 04:31:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20098 updates
2022-03-07 04:31:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:31:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:31:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 413 @ 20098 updates, score 13.391) (writing took 2.493857651948929 seconds)
2022-03-07 04:31:32 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-07 04:31:32 | INFO | train | epoch 413 | loss 2.563 | nll_loss 0.411 | ppl 1.33 | wps 23200.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20098 | lr 0.000223061 | gnorm 0.447 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 55737
2022-03-07 04:31:32 | INFO | fairseq.trainer | begin training epoch 414
2022-03-07 04:31:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:31:38 | INFO | train_inner | epoch 414:      2 / 49 loss=2.564, nll_loss=0.411, ppl=1.33, wps=22791.7, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=20100, lr=0.00022305, gnorm=0.451, loss_scale=32, train_wall=236, gb_free=8.8, wall=55743
2022-03-07 04:32:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:33:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:33:47 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 13.374 | nll_loss 12.631 | ppl 6344.78 | wps 41245.8 | wpb 510.9 | bsz 1 | num_updates 20146 | best_loss 9.157
2022-03-07 04:33:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20146 updates
2022-03-07 04:33:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:33:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:33:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 414 @ 20146 updates, score 13.374) (writing took 2.5485302759334445 seconds)
2022-03-07 04:33:49 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-07 04:33:49 | INFO | train | epoch 414 | loss 2.563 | nll_loss 0.41 | ppl 1.33 | wps 22753.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 20146 | lr 0.000222795 | gnorm 0.444 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 55874
2022-03-07 04:33:49 | INFO | fairseq.trainer | begin training epoch 415
2022-03-07 04:33:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:35:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:36:04 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 13.304 | nll_loss 12.556 | ppl 6023.5 | wps 40697.5 | wpb 510.9 | bsz 1 | num_updates 20195 | best_loss 9.157
2022-03-07 04:36:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20195 updates
2022-03-07 04:36:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:36:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:36:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 415 @ 20195 updates, score 13.304) (writing took 2.6857511191628873 seconds)
2022-03-07 04:36:07 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-07 04:36:07 | INFO | train | epoch 415 | loss 2.561 | nll_loss 0.409 | ppl 1.33 | wps 23148.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20195 | lr 0.000222525 | gnorm 0.443 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 56011
2022-03-07 04:36:07 | INFO | fairseq.trainer | begin training epoch 416
2022-03-07 04:36:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:36:20 | INFO | train_inner | epoch 416:      5 / 49 loss=2.561, nll_loss=0.409, ppl=1.33, wps=23000.1, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.443, loss_scale=32, train_wall=240, gb_free=8.8, wall=56025
2022-03-07 04:38:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:38:20 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 13.362 | nll_loss 12.616 | ppl 6279.02 | wps 41464.7 | wpb 510.9 | bsz 1 | num_updates 20244 | best_loss 9.157
2022-03-07 04:38:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20244 updates
2022-03-07 04:38:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:38:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:38:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 416 @ 20244 updates, score 13.362) (writing took 2.438702655956149 seconds)
2022-03-07 04:38:22 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-07 04:38:22 | INFO | train | epoch 416 | loss 2.561 | nll_loss 0.409 | ppl 1.33 | wps 23419.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20244 | lr 0.000222255 | gnorm 0.451 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 56147
2022-03-07 04:38:22 | INFO | fairseq.trainer | begin training epoch 417
2022-03-07 04:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:38:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:40:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:40:35 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 13.333 | nll_loss 12.593 | ppl 6176.88 | wps 41275.5 | wpb 510.9 | bsz 1 | num_updates 20292 | best_loss 9.157
2022-03-07 04:40:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20292 updates
2022-03-07 04:40:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:40:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:40:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 417 @ 20292 updates, score 13.333) (writing took 2.5411180569790304 seconds)
2022-03-07 04:40:38 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-07 04:40:38 | INFO | train | epoch 417 | loss 2.562 | nll_loss 0.41 | ppl 1.33 | wps 22948.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 20292 | lr 0.000221992 | gnorm 0.448 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 56283
2022-03-07 04:40:38 | INFO | fairseq.trainer | begin training epoch 418
2022-03-07 04:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:40:59 | INFO | train_inner | epoch 418:      8 / 49 loss=2.561, nll_loss=0.409, ppl=1.33, wps=23240.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.449, loss_scale=32, train_wall=238, gb_free=8.8, wall=56304
2022-03-07 04:42:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:42:51 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 13.281 | nll_loss 12.53 | ppl 5913.77 | wps 41685.8 | wpb 510.9 | bsz 1 | num_updates 20341 | best_loss 9.157
2022-03-07 04:42:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20341 updates
2022-03-07 04:42:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:42:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:42:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 418 @ 20341 updates, score 13.281) (writing took 2.382894725073129 seconds)
2022-03-07 04:42:53 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-07 04:42:53 | INFO | train | epoch 418 | loss 2.561 | nll_loss 0.409 | ppl 1.33 | wps 23451.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20341 | lr 0.000221725 | gnorm 0.453 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 56418
2022-03-07 04:42:53 | INFO | fairseq.trainer | begin training epoch 419
2022-03-07 04:42:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:44:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:45:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:45:06 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 13.274 | nll_loss 12.524 | ppl 5889.35 | wps 42001.1 | wpb 510.9 | bsz 1 | num_updates 20389 | best_loss 9.157
2022-03-07 04:45:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20389 updates
2022-03-07 04:45:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:45:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:45:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 419 @ 20389 updates, score 13.274) (writing took 2.4109441339969635 seconds)
2022-03-07 04:45:09 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-07 04:45:09 | INFO | train | epoch 419 | loss 2.56 | nll_loss 0.408 | ppl 1.33 | wps 22977.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 20389 | lr 0.000221463 | gnorm 0.448 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 56554
2022-03-07 04:45:09 | INFO | fairseq.trainer | begin training epoch 420
2022-03-07 04:45:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:45:38 | INFO | train_inner | epoch 420:     11 / 49 loss=2.56, nll_loss=0.408, ppl=1.33, wps=23255.1, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.451, loss_scale=32, train_wall=238, gb_free=8.8, wall=56583
2022-03-07 04:47:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:47:22 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 13.273 | nll_loss 12.526 | ppl 5896.36 | wps 41721.6 | wpb 510.9 | bsz 1 | num_updates 20438 | best_loss 9.157
2022-03-07 04:47:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20438 updates
2022-03-07 04:47:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:47:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:47:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 420 @ 20438 updates, score 13.273) (writing took 2.637079724110663 seconds)
2022-03-07 04:47:25 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-07 04:47:25 | INFO | train | epoch 420 | loss 2.56 | nll_loss 0.409 | ppl 1.33 | wps 23420.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20438 | lr 0.000221198 | gnorm 0.45 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 56689
2022-03-07 04:47:25 | INFO | fairseq.trainer | begin training epoch 421
2022-03-07 04:47:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:49:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:49:38 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 13.16 | nll_loss 12.398 | ppl 5397.43 | wps 42037 | wpb 510.9 | bsz 1 | num_updates 20487 | best_loss 9.157
2022-03-07 04:49:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20487 updates
2022-03-07 04:49:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:49:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:49:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 421 @ 20487 updates, score 13.16) (writing took 2.4836190519854426 seconds)
2022-03-07 04:49:40 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-07 04:49:40 | INFO | train | epoch 421 | loss 2.558 | nll_loss 0.407 | ppl 1.33 | wps 23453.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20487 | lr 0.000220933 | gnorm 0.447 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 56825
2022-03-07 04:49:40 | INFO | fairseq.trainer | begin training epoch 422
2022-03-07 04:49:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:50:14 | INFO | train_inner | epoch 422:     13 / 49 loss=2.559, nll_loss=0.407, ppl=1.33, wps=23481.3, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.448, loss_scale=32, train_wall=235, gb_free=8.8, wall=56859
2022-03-07 04:50:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:51:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:51:53 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 13.275 | nll_loss 12.527 | ppl 5900.76 | wps 41562.5 | wpb 510.9 | bsz 1 | num_updates 20535 | best_loss 9.157
2022-03-07 04:51:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20535 updates
2022-03-07 04:51:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:51:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:51:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 422 @ 20535 updates, score 13.275) (writing took 2.352376244030893 seconds)
2022-03-07 04:51:55 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-07 04:51:55 | INFO | train | epoch 422 | loss 2.558 | nll_loss 0.406 | ppl 1.32 | wps 23008.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 20535 | lr 0.000220675 | gnorm 0.442 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 56960
2022-03-07 04:51:55 | INFO | fairseq.trainer | begin training epoch 423
2022-03-07 04:51:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:54:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:54:07 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 13.422 | nll_loss 12.689 | ppl 6605.7 | wps 43222.6 | wpb 510.9 | bsz 1 | num_updates 20584 | best_loss 9.157
2022-03-07 04:54:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20584 updates
2022-03-07 04:54:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:54:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:54:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 423 @ 20584 updates, score 13.422) (writing took 2.3002993501722813 seconds)
2022-03-07 04:54:09 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-07 04:54:09 | INFO | train | epoch 423 | loss 2.558 | nll_loss 0.406 | ppl 1.33 | wps 23767.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20584 | lr 0.000220412 | gnorm 0.442 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 57094
2022-03-07 04:54:09 | INFO | fairseq.trainer | begin training epoch 424
2022-03-07 04:54:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:54:51 | INFO | train_inner | epoch 424:     16 / 49 loss=2.557, nll_loss=0.406, ppl=1.32, wps=23453.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.441, loss_scale=32, train_wall=236, gb_free=8.8, wall=57136
2022-03-07 04:56:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:56:20 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 13.217 | nll_loss 12.462 | ppl 5642.5 | wps 42465.2 | wpb 510.9 | bsz 1 | num_updates 20633 | best_loss 9.157
2022-03-07 04:56:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20633 updates
2022-03-07 04:56:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:56:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:56:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 424 @ 20633 updates, score 13.217) (writing took 2.51345467986539 seconds)
2022-03-07 04:56:22 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-07 04:56:22 | INFO | train | epoch 424 | loss 2.558 | nll_loss 0.406 | ppl 1.33 | wps 23851.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20633 | lr 0.00022015 | gnorm 0.442 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 57227
2022-03-07 04:56:22 | INFO | fairseq.trainer | begin training epoch 425
2022-03-07 04:56:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:56:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:58:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:58:33 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 13.373 | nll_loss 12.641 | ppl 6389.08 | wps 43838.8 | wpb 510.9 | bsz 1 | num_updates 20681 | best_loss 9.157
2022-03-07 04:58:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20681 updates
2022-03-07 04:58:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:58:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:58:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 425 @ 20681 updates, score 13.373) (writing took 2.407504502683878 seconds)
2022-03-07 04:58:35 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-07 04:58:35 | INFO | train | epoch 425 | loss 2.557 | nll_loss 0.405 | ppl 1.32 | wps 23472.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 20681 | lr 0.000219894 | gnorm 0.441 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 57360
2022-03-07 04:58:35 | INFO | fairseq.trainer | begin training epoch 426
2022-03-07 04:58:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:59:24 | INFO | train_inner | epoch 426:     19 / 49 loss=2.557, nll_loss=0.406, ppl=1.32, wps=23764.4, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.44, loss_scale=32, train_wall=233, gb_free=8.8, wall=57409
2022-03-07 05:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:00:45 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 13.276 | nll_loss 12.534 | ppl 5930.47 | wps 43814.8 | wpb 510.9 | bsz 1 | num_updates 20730 | best_loss 9.157
2022-03-07 05:00:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20730 updates
2022-03-07 05:00:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:00:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 426 @ 20730 updates, score 13.276) (writing took 2.257860539946705 seconds)
2022-03-07 05:00:47 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-07 05:00:47 | INFO | train | epoch 426 | loss 2.557 | nll_loss 0.406 | ppl 1.32 | wps 23997.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20730 | lr 0.000219634 | gnorm 0.437 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 57492
2022-03-07 05:00:47 | INFO | fairseq.trainer | begin training epoch 427
2022-03-07 05:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:02:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:02:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:02:58 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 13.304 | nll_loss 12.562 | ppl 6047.6 | wps 43382.1 | wpb 510.9 | bsz 1 | num_updates 20778 | best_loss 9.157
2022-03-07 05:02:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20778 updates
2022-03-07 05:02:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:03:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:03:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 427 @ 20778 updates, score 13.304) (writing took 2.358751352876425 seconds)
2022-03-07 05:03:00 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-07 05:03:00 | INFO | train | epoch 427 | loss 2.556 | nll_loss 0.405 | ppl 1.32 | wps 23442.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 20778 | lr 0.000219381 | gnorm 0.438 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 57625
2022-03-07 05:03:00 | INFO | fairseq.trainer | begin training epoch 428
2022-03-07 05:03:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:03:57 | INFO | train_inner | epoch 428:     22 / 49 loss=2.556, nll_loss=0.405, ppl=1.32, wps=23749, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.437, loss_scale=32, train_wall=233, gb_free=8.8, wall=57682
2022-03-07 05:05:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:05:10 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 13.285 | nll_loss 12.548 | ppl 5988.37 | wps 43579.2 | wpb 510.9 | bsz 1 | num_updates 20827 | best_loss 9.157
2022-03-07 05:05:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20827 updates
2022-03-07 05:05:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:05:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:05:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 428 @ 20827 updates, score 13.285) (writing took 2.369923295918852 seconds)
2022-03-07 05:05:13 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-07 05:05:13 | INFO | train | epoch 428 | loss 2.555 | nll_loss 0.404 | ppl 1.32 | wps 23949 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20827 | lr 0.000219122 | gnorm 0.443 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 57758
2022-03-07 05:05:13 | INFO | fairseq.trainer | begin training epoch 429
2022-03-07 05:05:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:07:24 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 13.248 | nll_loss 12.497 | ppl 5779.82 | wps 41361.8 | wpb 510.9 | bsz 1 | num_updates 20876 | best_loss 9.157
2022-03-07 05:07:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20876 updates
2022-03-07 05:07:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:07:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:07:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 429 @ 20876 updates, score 13.248) (writing took 2.3474825411103666 seconds)
2022-03-07 05:07:27 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-07 05:07:27 | INFO | train | epoch 429 | loss 2.554 | nll_loss 0.404 | ppl 1.32 | wps 23722 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20876 | lr 0.000218865 | gnorm 0.442 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 57892
2022-03-07 05:07:27 | INFO | fairseq.trainer | begin training epoch 430
2022-03-07 05:07:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:08:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:08:32 | INFO | train_inner | epoch 430:     25 / 49 loss=2.555, nll_loss=0.404, ppl=1.32, wps=23554.1, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.443, loss_scale=32, train_wall=235, gb_free=8.8, wall=57957
2022-03-07 05:09:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:09:40 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 13.373 | nll_loss 12.631 | ppl 6342.86 | wps 41904.6 | wpb 510.9 | bsz 1 | num_updates 20924 | best_loss 9.157
2022-03-07 05:09:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20924 updates
2022-03-07 05:09:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:09:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:09:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 430 @ 20924 updates, score 13.373) (writing took 2.3941395869478583 seconds)
2022-03-07 05:09:42 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-07 05:09:42 | INFO | train | epoch 430 | loss 2.554 | nll_loss 0.403 | ppl 1.32 | wps 23020.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 20924 | lr 0.000218614 | gnorm 0.439 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58027
2022-03-07 05:09:42 | INFO | fairseq.trainer | begin training epoch 431
2022-03-07 05:09:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:11:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:11:55 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 13.317 | nll_loss 12.572 | ppl 6088.43 | wps 41506.5 | wpb 510.9 | bsz 1 | num_updates 20973 | best_loss 9.157
2022-03-07 05:11:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20973 updates
2022-03-07 05:11:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:11:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:11:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 431 @ 20973 updates, score 13.317) (writing took 2.507187475915998 seconds)
2022-03-07 05:11:58 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-07 05:11:58 | INFO | train | epoch 431 | loss 2.553 | nll_loss 0.402 | ppl 1.32 | wps 23447.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20973 | lr 0.000218358 | gnorm 0.439 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58162
2022-03-07 05:11:58 | INFO | fairseq.trainer | begin training epoch 432
2022-03-07 05:11:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:13:09 | INFO | train_inner | epoch 432:     27 / 49 loss=2.553, nll_loss=0.403, ppl=1.32, wps=23483.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.439, loss_scale=32, train_wall=235, gb_free=8.8, wall=58233
2022-03-07 05:13:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:14:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:14:10 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 13.367 | nll_loss 12.634 | ppl 6358.49 | wps 41785.2 | wpb 510.9 | bsz 1 | num_updates 21021 | best_loss 9.157
2022-03-07 05:14:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21021 updates
2022-03-07 05:14:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:14:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:14:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 432 @ 21021 updates, score 13.367) (writing took 2.424724970012903 seconds)
2022-03-07 05:14:13 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-07 05:14:13 | INFO | train | epoch 432 | loss 2.554 | nll_loss 0.403 | ppl 1.32 | wps 22994.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 21021 | lr 0.000218109 | gnorm 0.439 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58298
2022-03-07 05:14:13 | INFO | fairseq.trainer | begin training epoch 433
2022-03-07 05:14:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:16:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:16:26 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 13.283 | nll_loss 12.547 | ppl 5986.3 | wps 39980.8 | wpb 510.9 | bsz 1 | num_updates 21070 | best_loss 9.157
2022-03-07 05:16:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21070 updates
2022-03-07 05:16:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:16:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:16:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 433 @ 21070 updates, score 13.283) (writing took 2.396925901994109 seconds)
2022-03-07 05:16:28 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-07 05:16:28 | INFO | train | epoch 433 | loss 2.553 | nll_loss 0.402 | ppl 1.32 | wps 23439.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21070 | lr 0.000217855 | gnorm 0.433 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58433
2022-03-07 05:16:28 | INFO | fairseq.trainer | begin training epoch 434
2022-03-07 05:16:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:17:47 | INFO | train_inner | epoch 434:     30 / 49 loss=2.553, nll_loss=0.402, ppl=1.32, wps=23273.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.432, loss_scale=32, train_wall=238, gb_free=8.8, wall=58512
2022-03-07 05:18:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:18:41 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 13.38 | nll_loss 12.643 | ppl 6395.5 | wps 41721.6 | wpb 510.9 | bsz 1 | num_updates 21119 | best_loss 9.157
2022-03-07 05:18:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21119 updates
2022-03-07 05:18:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:18:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:18:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 434 @ 21119 updates, score 13.38) (writing took 2.3585451268590987 seconds)
2022-03-07 05:18:44 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-07 05:18:44 | INFO | train | epoch 434 | loss 2.552 | nll_loss 0.402 | ppl 1.32 | wps 23492.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21119 | lr 0.000217602 | gnorm 0.433 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58569
2022-03-07 05:18:44 | INFO | fairseq.trainer | begin training epoch 435
2022-03-07 05:18:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:19:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:20:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:20:57 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 13.299 | nll_loss 12.559 | ppl 6034.58 | wps 41346.4 | wpb 510.9 | bsz 1 | num_updates 21167 | best_loss 9.157
2022-03-07 05:20:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21167 updates
2022-03-07 05:20:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:20:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:20:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 435 @ 21167 updates, score 13.299) (writing took 2.3548063752241433 seconds)
2022-03-07 05:20:59 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-07 05:20:59 | INFO | train | epoch 435 | loss 2.552 | nll_loss 0.402 | ppl 1.32 | wps 23004.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 21167 | lr 0.000217355 | gnorm 0.444 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58704
2022-03-07 05:20:59 | INFO | fairseq.trainer | begin training epoch 436
2022-03-07 05:20:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:22:26 | INFO | train_inner | epoch 436:     33 / 49 loss=2.552, nll_loss=0.402, ppl=1.32, wps=23296.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.44, loss_scale=32, train_wall=238, gb_free=8.8, wall=58791
2022-03-07 05:23:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:23:12 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 13.356 | nll_loss 12.619 | ppl 6289.32 | wps 41768.3 | wpb 510.9 | bsz 1 | num_updates 21216 | best_loss 9.157
2022-03-07 05:23:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21216 updates
2022-03-07 05:23:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:23:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 436 @ 21216 updates, score 13.356) (writing took 2.490135914180428 seconds)
2022-03-07 05:23:14 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-07 05:23:14 | INFO | train | epoch 436 | loss 2.551 | nll_loss 0.401 | ppl 1.32 | wps 23485.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21216 | lr 0.000217104 | gnorm 0.432 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58839
2022-03-07 05:23:14 | INFO | fairseq.trainer | begin training epoch 437
2022-03-07 05:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:25:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:25:27 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 13.4 | nll_loss 12.664 | ppl 6488.12 | wps 41874.6 | wpb 510.9 | bsz 1 | num_updates 21265 | best_loss 9.157
2022-03-07 05:25:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21265 updates
2022-03-07 05:25:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:25:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:25:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 437 @ 21265 updates, score 13.4) (writing took 2.511832223739475 seconds)
2022-03-07 05:25:30 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-07 05:25:30 | INFO | train | epoch 437 | loss 2.55 | nll_loss 0.401 | ppl 1.32 | wps 23438.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21265 | lr 0.000216854 | gnorm 0.431 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58975
2022-03-07 05:25:30 | INFO | fairseq.trainer | begin training epoch 438
2022-03-07 05:25:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:25:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:27:05 | INFO | train_inner | epoch 438:     36 / 49 loss=2.55, nll_loss=0.401, ppl=1.32, wps=23269.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.433, loss_scale=32, train_wall=238, gb_free=8.8, wall=59069
2022-03-07 05:27:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:27:43 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 13.453 | nll_loss 12.727 | ppl 6778.75 | wps 41236.6 | wpb 510.9 | bsz 1 | num_updates 21313 | best_loss 9.157
2022-03-07 05:27:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21313 updates
2022-03-07 05:27:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:27:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:27:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 438 @ 21313 updates, score 13.453) (writing took 2.458986042998731 seconds)
2022-03-07 05:27:46 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-07 05:27:46 | INFO | train | epoch 438 | loss 2.551 | nll_loss 0.401 | ppl 1.32 | wps 22965.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 21313 | lr 0.00021661 | gnorm 0.437 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 59110
2022-03-07 05:27:46 | INFO | fairseq.trainer | begin training epoch 439
2022-03-07 05:27:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:29:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:29:58 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 13.387 | nll_loss 12.656 | ppl 6452.48 | wps 42042.8 | wpb 510.9 | bsz 1 | num_updates 21362 | best_loss 9.157
2022-03-07 05:29:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21362 updates
2022-03-07 05:29:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:30:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:30:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 439 @ 21362 updates, score 13.387) (writing took 2.4119568299502134 seconds)
2022-03-07 05:30:01 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-07 05:30:01 | INFO | train | epoch 439 | loss 2.549 | nll_loss 0.4 | ppl 1.32 | wps 23494 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21362 | lr 0.000216361 | gnorm 0.437 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 59246
2022-03-07 05:30:01 | INFO | fairseq.trainer | begin training epoch 440
2022-03-07 05:30:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:31:39 | INFO | train_inner | epoch 440:     38 / 49 loss=2.549, nll_loss=0.4, ppl=1.32, wps=23624.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.437, loss_scale=32, train_wall=234, gb_free=8.8, wall=59344
2022-03-07 05:31:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:32:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:32:11 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 13.311 | nll_loss 12.565 | ppl 6060.69 | wps 43241.4 | wpb 510.9 | bsz 1 | num_updates 21410 | best_loss 9.157
2022-03-07 05:32:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21410 updates
2022-03-07 05:32:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:32:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:32:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 440 @ 21410 updates, score 13.311) (writing took 2.2843491239473224 seconds)
2022-03-07 05:32:14 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-07 05:32:14 | INFO | train | epoch 440 | loss 2.549 | nll_loss 0.399 | ppl 1.32 | wps 23417 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 21410 | lr 0.000216118 | gnorm 0.436 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 59378
2022-03-07 05:32:14 | INFO | fairseq.trainer | begin training epoch 441
2022-03-07 05:32:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:34:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:34:24 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 13.371 | nll_loss 12.633 | ppl 6353.96 | wps 43119.8 | wpb 510.9 | bsz 1 | num_updates 21459 | best_loss 9.157
2022-03-07 05:34:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21459 updates
2022-03-07 05:34:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:34:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:34:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 441 @ 21459 updates, score 13.371) (writing took 2.3111396110616624 seconds)
2022-03-07 05:34:26 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-07 05:34:26 | INFO | train | epoch 441 | loss 2.548 | nll_loss 0.399 | ppl 1.32 | wps 23962.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21459 | lr 0.000215871 | gnorm 0.436 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 59511
2022-03-07 05:34:26 | INFO | fairseq.trainer | begin training epoch 442
2022-03-07 05:34:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:36:12 | INFO | train_inner | epoch 442:     41 / 49 loss=2.549, nll_loss=0.399, ppl=1.32, wps=23746.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.436, loss_scale=32, train_wall=233, gb_free=8.8, wall=59617
2022-03-07 05:36:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:36:37 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 13.355 | nll_loss 12.616 | ppl 6279.15 | wps 41914.9 | wpb 510.9 | bsz 1 | num_updates 21508 | best_loss 9.157
2022-03-07 05:36:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21508 updates
2022-03-07 05:36:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:36:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:36:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 442 @ 21508 updates, score 13.355) (writing took 2.362935494631529 seconds)
2022-03-07 05:36:39 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-07 05:36:39 | INFO | train | epoch 442 | loss 2.549 | nll_loss 0.399 | ppl 1.32 | wps 23875.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21508 | lr 0.000215625 | gnorm 0.435 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 59644
2022-03-07 05:36:39 | INFO | fairseq.trainer | begin training epoch 443
2022-03-07 05:36:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:37:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:38:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:38:50 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 13.335 | nll_loss 12.598 | ppl 6200.97 | wps 43631.2 | wpb 510.9 | bsz 1 | num_updates 21556 | best_loss 9.157
2022-03-07 05:38:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21556 updates
2022-03-07 05:38:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:38:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:38:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 443 @ 21556 updates, score 13.335) (writing took 2.398131930269301 seconds)
2022-03-07 05:38:52 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-07 05:38:52 | INFO | train | epoch 443 | loss 2.547 | nll_loss 0.398 | ppl 1.32 | wps 23421.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 21556 | lr 0.000215385 | gnorm 0.43 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 59777
2022-03-07 05:38:52 | INFO | fairseq.trainer | begin training epoch 444
2022-03-07 05:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:40:46 | INFO | train_inner | epoch 444:     44 / 49 loss=2.547, nll_loss=0.398, ppl=1.32, wps=23708.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.43, loss_scale=32, train_wall=233, gb_free=8.8, wall=59891
2022-03-07 05:40:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:41:03 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 13.262 | nll_loss 12.523 | ppl 5886.27 | wps 42662.3 | wpb 510.9 | bsz 1 | num_updates 21605 | best_loss 9.157
2022-03-07 05:41:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21605 updates
2022-03-07 05:41:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:41:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:41:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 444 @ 21605 updates, score 13.262) (writing took 2.3961666636168957 seconds)
2022-03-07 05:41:05 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-07 05:41:05 | INFO | train | epoch 444 | loss 2.547 | nll_loss 0.398 | ppl 1.32 | wps 23908.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21605 | lr 0.000215141 | gnorm 0.429 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 59910
2022-03-07 05:41:05 | INFO | fairseq.trainer | begin training epoch 445
2022-03-07 05:41:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:43:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:43:16 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 13.267 | nll_loss 12.524 | ppl 5888.13 | wps 43587.9 | wpb 510.9 | bsz 1 | num_updates 21654 | best_loss 9.157
2022-03-07 05:43:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21654 updates
2022-03-07 05:43:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:43:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:43:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 445 @ 21654 updates, score 13.267) (writing took 2.3917664908804 seconds)
2022-03-07 05:43:18 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-07 05:43:18 | INFO | train | epoch 445 | loss 2.547 | nll_loss 0.398 | ppl 1.32 | wps 23924 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21654 | lr 0.000214897 | gnorm 0.438 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 60043
2022-03-07 05:43:18 | INFO | fairseq.trainer | begin training epoch 446
2022-03-07 05:43:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:43:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:45:21 | INFO | train_inner | epoch 446:     47 / 49 loss=2.546, nll_loss=0.398, ppl=1.32, wps=23565.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.434, loss_scale=32, train_wall=235, gb_free=8.8, wall=60166
2022-03-07 05:45:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:45:31 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 13.236 | nll_loss 12.485 | ppl 5732.02 | wps 41771.6 | wpb 510.9 | bsz 1 | num_updates 21702 | best_loss 9.157
2022-03-07 05:45:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21702 updates
2022-03-07 05:45:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:45:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:45:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 446 @ 21702 updates, score 13.236) (writing took 2.3065586099401116 seconds)
2022-03-07 05:45:33 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-07 05:45:33 | INFO | train | epoch 446 | loss 2.545 | nll_loss 0.397 | ppl 1.32 | wps 23090.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 21702 | lr 0.00021466 | gnorm 0.431 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 60178
2022-03-07 05:45:33 | INFO | fairseq.trainer | begin training epoch 447
2022-03-07 05:45:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:47:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:47:46 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 13.35 | nll_loss 12.609 | ppl 6247.19 | wps 41355.4 | wpb 510.9 | bsz 1 | num_updates 21751 | best_loss 9.157
2022-03-07 05:47:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21751 updates
2022-03-07 05:47:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:47:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:47:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 447 @ 21751 updates, score 13.35) (writing took 2.4743420090526342 seconds)
2022-03-07 05:47:49 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-07 05:47:49 | INFO | train | epoch 447 | loss 2.546 | nll_loss 0.398 | ppl 1.32 | wps 23416.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21751 | lr 0.000214418 | gnorm 0.431 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 60313
2022-03-07 05:47:49 | INFO | fairseq.trainer | begin training epoch 448
2022-03-07 05:47:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:49:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:49:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:50:02 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 13.345 | nll_loss 12.607 | ppl 6237.79 | wps 41507.9 | wpb 510.9 | bsz 1 | num_updates 21799 | best_loss 9.157
2022-03-07 05:50:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21799 updates
2022-03-07 05:50:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:50:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:50:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 448 @ 21799 updates, score 13.345) (writing took 2.415521053597331 seconds)
2022-03-07 05:50:04 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-07 05:50:04 | INFO | train | epoch 448 | loss 2.545 | nll_loss 0.397 | ppl 1.32 | wps 22956.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 21799 | lr 0.000214181 | gnorm 0.435 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 60449
2022-03-07 05:50:04 | INFO | fairseq.trainer | begin training epoch 449
2022-03-07 05:50:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:50:07 | INFO | train_inner | epoch 449:      1 / 49 loss=2.546, nll_loss=0.397, ppl=1.32, wps=22599.3, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=21800, lr=0.000214176, gnorm=0.434, loss_scale=32, train_wall=237, gb_free=8.8, wall=60452
2022-03-07 05:52:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:52:17 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 13.227 | nll_loss 12.479 | ppl 5709.49 | wps 41636 | wpb 510.9 | bsz 1 | num_updates 21848 | best_loss 9.157
2022-03-07 05:52:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21848 updates
2022-03-07 05:52:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:52:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:52:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 449 @ 21848 updates, score 13.227) (writing took 2.30794784007594 seconds)
2022-03-07 05:52:20 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-07 05:52:20 | INFO | train | epoch 449 | loss 2.545 | nll_loss 0.397 | ppl 1.32 | wps 23462.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21848 | lr 0.000213941 | gnorm 0.439 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 60584
2022-03-07 05:52:20 | INFO | fairseq.trainer | begin training epoch 450
2022-03-07 05:52:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:54:33 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 13.223 | nll_loss 12.473 | ppl 5686.13 | wps 41911.8 | wpb 510.9 | bsz 1 | num_updates 21897 | best_loss 9.157
2022-03-07 05:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21897 updates
2022-03-07 05:54:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 450 @ 21897 updates, score 13.223) (writing took 2.3478799699805677 seconds)
2022-03-07 05:54:35 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-07 05:54:35 | INFO | train | epoch 450 | loss 2.544 | nll_loss 0.396 | ppl 1.32 | wps 23477.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21897 | lr 0.000213702 | gnorm 0.434 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 60720
2022-03-07 05:54:35 | INFO | fairseq.trainer | begin training epoch 451
2022-03-07 05:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:54:43 | INFO | train_inner | epoch 451:      3 / 49 loss=2.544, nll_loss=0.396, ppl=1.32, wps=23501, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=21900, lr=0.000213687, gnorm=0.436, loss_scale=32, train_wall=236, gb_free=8.8, wall=60728
2022-03-07 05:55:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:56:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:56:48 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 13.291 | nll_loss 12.557 | ppl 6028.08 | wps 41820.2 | wpb 510.9 | bsz 1 | num_updates 21945 | best_loss 9.157
2022-03-07 05:56:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21945 updates
2022-03-07 05:56:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:56:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:56:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 451 @ 21945 updates, score 13.291) (writing took 2.5467989360913634 seconds)
2022-03-07 05:56:51 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-07 05:56:51 | INFO | train | epoch 451 | loss 2.543 | nll_loss 0.395 | ppl 1.31 | wps 22965.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 21945 | lr 0.000213468 | gnorm 0.432 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 60855
2022-03-07 05:56:51 | INFO | fairseq.trainer | begin training epoch 452
2022-03-07 05:56:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:58:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:59:04 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 13.366 | nll_loss 12.63 | ppl 6338.51 | wps 41432.5 | wpb 510.9 | bsz 1 | num_updates 21994 | best_loss 9.157
2022-03-07 05:59:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 21994 updates
2022-03-07 05:59:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:59:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:59:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 452 @ 21994 updates, score 13.366) (writing took 2.4091094727627933 seconds)
2022-03-07 05:59:06 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-07 05:59:06 | INFO | train | epoch 452 | loss 2.543 | nll_loss 0.395 | ppl 1.31 | wps 23436.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21994 | lr 0.00021323 | gnorm 0.429 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 60991
2022-03-07 05:59:06 | INFO | fairseq.trainer | begin training epoch 453
2022-03-07 05:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:59:22 | INFO | train_inner | epoch 453:      6 / 49 loss=2.543, nll_loss=0.395, ppl=1.31, wps=23250.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.431, loss_scale=32, train_wall=238, gb_free=8.8, wall=61007
2022-03-07 06:01:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:01:19 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 13.278 | nll_loss 12.543 | ppl 5967.22 | wps 41040.5 | wpb 510.9 | bsz 1 | num_updates 22043 | best_loss 9.157
2022-03-07 06:01:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22043 updates
2022-03-07 06:01:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:01:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:01:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 453 @ 22043 updates, score 13.278) (writing took 2.516741402912885 seconds)
2022-03-07 06:01:22 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-07 06:01:22 | INFO | train | epoch 453 | loss 2.542 | nll_loss 0.394 | ppl 1.31 | wps 23419.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22043 | lr 0.000212993 | gnorm 0.432 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 61127
2022-03-07 06:01:22 | INFO | fairseq.trainer | begin training epoch 454
2022-03-07 06:01:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:01:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:03:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:03:35 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 13.434 | nll_loss 12.707 | ppl 6686.16 | wps 42557.7 | wpb 510.9 | bsz 1 | num_updates 22091 | best_loss 9.157
2022-03-07 06:03:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22091 updates
2022-03-07 06:03:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:03:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:03:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 454 @ 22091 updates, score 13.434) (writing took 2.374203711282462 seconds)
2022-03-07 06:03:37 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-07 06:03:37 | INFO | train | epoch 454 | loss 2.542 | nll_loss 0.395 | ppl 1.31 | wps 22980.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 22091 | lr 0.000212761 | gnorm 0.433 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 61262
2022-03-07 06:03:37 | INFO | fairseq.trainer | begin training epoch 455
2022-03-07 06:03:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:04:01 | INFO | train_inner | epoch 455:      9 / 49 loss=2.542, nll_loss=0.394, ppl=1.31, wps=23250.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.432, loss_scale=32, train_wall=238, gb_free=8.8, wall=61286
2022-03-07 06:05:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:05:50 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 13.393 | nll_loss 12.661 | ppl 6476.29 | wps 41584.3 | wpb 510.9 | bsz 1 | num_updates 22140 | best_loss 9.157
2022-03-07 06:05:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22140 updates
2022-03-07 06:05:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:05:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:05:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 455 @ 22140 updates, score 13.393) (writing took 2.3609115737490356 seconds)
2022-03-07 06:05:53 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-07 06:05:53 | INFO | train | epoch 455 | loss 2.542 | nll_loss 0.394 | ppl 1.31 | wps 23494.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22140 | lr 0.000212526 | gnorm 0.426 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 61397
2022-03-07 06:05:53 | INFO | fairseq.trainer | begin training epoch 456
2022-03-07 06:05:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:07:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:07:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:08:05 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 13.463 | nll_loss 12.74 | ppl 6839.74 | wps 41134.8 | wpb 510.9 | bsz 1 | num_updates 22188 | best_loss 9.157
2022-03-07 06:08:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22188 updates
2022-03-07 06:08:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:08:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:08:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 456 @ 22188 updates, score 13.463) (writing took 2.4938865010626614 seconds)
2022-03-07 06:08:07 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-07 06:08:07 | INFO | train | epoch 456 | loss 2.542 | nll_loss 0.394 | ppl 1.31 | wps 23112.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 22188 | lr 0.000212296 | gnorm 0.438 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 61532
2022-03-07 06:08:07 | INFO | fairseq.trainer | begin training epoch 457
2022-03-07 06:08:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:08:38 | INFO | train_inner | epoch 457:     12 / 49 loss=2.541, nll_loss=0.394, ppl=1.31, wps=23401.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.431, loss_scale=32, train_wall=236, gb_free=8.8, wall=61563
2022-03-07 06:10:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:10:19 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 13.27 | nll_loss 12.534 | ppl 5929.3 | wps 41156.4 | wpb 510.9 | bsz 1 | num_updates 22237 | best_loss 9.157
2022-03-07 06:10:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22237 updates
2022-03-07 06:10:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:10:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:10:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 457 @ 22237 updates, score 13.27) (writing took 2.4929497693665326 seconds)
2022-03-07 06:10:21 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-07 06:10:21 | INFO | train | epoch 457 | loss 2.541 | nll_loss 0.393 | ppl 1.31 | wps 23735.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 22237 | lr 0.000212062 | gnorm 0.429 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 61666
2022-03-07 06:10:21 | INFO | fairseq.trainer | begin training epoch 458
2022-03-07 06:10:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:12:34 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 13.34 | nll_loss 12.606 | ppl 6233.34 | wps 42084.9 | wpb 510.9 | bsz 1 | num_updates 22286 | best_loss 9.157
2022-03-07 06:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22286 updates
2022-03-07 06:12:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:12:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 458 @ 22286 updates, score 13.34) (writing took 2.4729101699776947 seconds)
2022-03-07 06:12:36 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-07 06:12:36 | INFO | train | epoch 458 | loss 2.54 | nll_loss 0.393 | ppl 1.31 | wps 23496.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22286 | lr 0.000211828 | gnorm 0.424 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 61801
2022-03-07 06:12:36 | INFO | fairseq.trainer | begin training epoch 459
2022-03-07 06:12:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:13:13 | INFO | train_inner | epoch 459:     14 / 49 loss=2.541, nll_loss=0.393, ppl=1.31, wps=23596.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22300, lr=0.000211762, gnorm=0.427, loss_scale=32, train_wall=234, gb_free=8.8, wall=61838
2022-03-07 06:13:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:14:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:14:49 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 13.267 | nll_loss 12.524 | ppl 5889.4 | wps 42126.1 | wpb 510.9 | bsz 1 | num_updates 22334 | best_loss 9.157
2022-03-07 06:14:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22334 updates
2022-03-07 06:14:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:14:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:14:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 459 @ 22334 updates, score 13.267) (writing took 2.4276543501764536 seconds)
2022-03-07 06:14:51 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-07 06:14:51 | INFO | train | epoch 459 | loss 2.54 | nll_loss 0.393 | ppl 1.31 | wps 23033.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 22334 | lr 0.000211601 | gnorm 0.429 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 61936
2022-03-07 06:14:52 | INFO | fairseq.trainer | begin training epoch 460
2022-03-07 06:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:16:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:17:04 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 13.405 | nll_loss 12.679 | ppl 6555.81 | wps 41622.8 | wpb 510.9 | bsz 1 | num_updates 22383 | best_loss 9.157
2022-03-07 06:17:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22383 updates
2022-03-07 06:17:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:17:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:17:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 460 @ 22383 updates, score 13.405) (writing took 2.4279096978716552 seconds)
2022-03-07 06:17:07 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-07 06:17:07 | INFO | train | epoch 460 | loss 2.539 | nll_loss 0.392 | ppl 1.31 | wps 23536.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22383 | lr 0.000211369 | gnorm 0.425 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 62071
2022-03-07 06:17:07 | INFO | fairseq.trainer | begin training epoch 461
2022-03-07 06:17:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:17:51 | INFO | train_inner | epoch 461:     17 / 49 loss=2.539, nll_loss=0.392, ppl=1.31, wps=23316.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.426, loss_scale=32, train_wall=237, gb_free=8.8, wall=62116
2022-03-07 06:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:19:20 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 13.376 | nll_loss 12.645 | ppl 6406.11 | wps 41481.4 | wpb 510.9 | bsz 1 | num_updates 22432 | best_loss 9.157
2022-03-07 06:19:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22432 updates
2022-03-07 06:19:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:19:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:19:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 461 @ 22432 updates, score 13.376) (writing took 2.4696389008313417 seconds)
2022-03-07 06:19:22 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-07 06:19:22 | INFO | train | epoch 461 | loss 2.539 | nll_loss 0.392 | ppl 1.31 | wps 23459.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22432 | lr 0.000211138 | gnorm 0.429 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 62207
2022-03-07 06:19:22 | INFO | fairseq.trainer | begin training epoch 462
2022-03-07 06:19:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:19:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:20:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:21:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:21:35 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 13.387 | nll_loss 12.654 | ppl 6445.91 | wps 41862.8 | wpb 510.9 | bsz 1 | num_updates 22479 | best_loss 9.157
2022-03-07 06:21:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22479 updates
2022-03-07 06:21:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:21:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:21:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 462 @ 22479 updates, score 13.387) (writing took 2.4894538847729564 seconds)
2022-03-07 06:21:37 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-07 06:21:37 | INFO | train | epoch 462 | loss 2.538 | nll_loss 0.391 | ppl 1.31 | wps 22543.4 | ups 0.35 | wpb 64829.4 | bsz 126.6 | num_updates 22479 | lr 0.000210917 | gnorm 0.423 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 62342
2022-03-07 06:21:37 | INFO | fairseq.trainer | begin training epoch 463
2022-03-07 06:21:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:22:32 | INFO | train_inner | epoch 463:     21 / 49 loss=2.539, nll_loss=0.392, ppl=1.31, wps=23097.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.426, loss_scale=16, train_wall=240, gb_free=8.8, wall=62397
2022-03-07 06:23:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:23:50 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 13.325 | nll_loss 12.589 | ppl 6161.62 | wps 41366.6 | wpb 510.9 | bsz 1 | num_updates 22528 | best_loss 9.157
2022-03-07 06:23:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22528 updates
2022-03-07 06:23:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:23:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:23:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 463 @ 22528 updates, score 13.325) (writing took 2.430553123354912 seconds)
2022-03-07 06:23:52 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-07 06:23:52 | INFO | train | epoch 463 | loss 2.538 | nll_loss 0.391 | ppl 1.31 | wps 23525.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22528 | lr 0.000210687 | gnorm 0.425 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 62477
2022-03-07 06:23:52 | INFO | fairseq.trainer | begin training epoch 464
2022-03-07 06:23:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:25:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:26:05 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 13.296 | nll_loss 12.554 | ppl 6013.4 | wps 41478.8 | wpb 510.9 | bsz 1 | num_updates 22577 | best_loss 9.157
2022-03-07 06:26:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22577 updates
2022-03-07 06:26:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:26:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:26:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 464 @ 22577 updates, score 13.296) (writing took 2.3551096678711474 seconds)
2022-03-07 06:26:07 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-07 06:26:07 | INFO | train | epoch 464 | loss 2.538 | nll_loss 0.391 | ppl 1.31 | wps 23559.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22577 | lr 0.000210459 | gnorm 0.429 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 62612
2022-03-07 06:26:07 | INFO | fairseq.trainer | begin training epoch 465
2022-03-07 06:26:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:27:08 | INFO | train_inner | epoch 465:     23 / 49 loss=2.537, nll_loss=0.391, ppl=1.31, wps=23550.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.426, loss_scale=32, train_wall=235, gb_free=8.8, wall=62672
2022-03-07 06:28:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:28:20 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 13.352 | nll_loss 12.619 | ppl 6289.46 | wps 41187 | wpb 510.9 | bsz 1 | num_updates 22626 | best_loss 9.157
2022-03-07 06:28:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22626 updates
2022-03-07 06:28:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:28:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:28:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 465 @ 22626 updates, score 13.352) (writing took 2.603587474208325 seconds)
2022-03-07 06:28:23 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-07 06:28:23 | INFO | train | epoch 465 | loss 2.537 | nll_loss 0.391 | ppl 1.31 | wps 23467.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22626 | lr 0.000210231 | gnorm 0.423 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 62747
2022-03-07 06:28:23 | INFO | fairseq.trainer | begin training epoch 466
2022-03-07 06:28:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:30:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:30:35 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 13.337 | nll_loss 12.6 | ppl 6206.4 | wps 41450.3 | wpb 510.9 | bsz 1 | num_updates 22675 | best_loss 9.157
2022-03-07 06:30:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22675 updates
2022-03-07 06:30:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:30:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:30:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 466 @ 22675 updates, score 13.337) (writing took 2.3966038217768073 seconds)
2022-03-07 06:30:38 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-07 06:30:38 | INFO | train | epoch 466 | loss 2.537 | nll_loss 0.391 | ppl 1.31 | wps 23491.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22675 | lr 0.000210003 | gnorm 0.429 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 62883
2022-03-07 06:30:38 | INFO | fairseq.trainer | begin training epoch 467
2022-03-07 06:30:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:31:43 | INFO | train_inner | epoch 467:     25 / 49 loss=2.537, nll_loss=0.39, ppl=1.31, wps=23530.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.426, loss_scale=32, train_wall=235, gb_free=8.8, wall=62948
2022-03-07 06:31:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:32:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:32:50 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 13.283 | nll_loss 12.543 | ppl 5968.67 | wps 42385.6 | wpb 510.9 | bsz 1 | num_updates 22723 | best_loss 9.157
2022-03-07 06:32:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22723 updates
2022-03-07 06:32:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:32:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:32:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 467 @ 22723 updates, score 13.283) (writing took 2.330425802618265 seconds)
2022-03-07 06:32:53 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-07 06:32:53 | INFO | train | epoch 467 | loss 2.536 | nll_loss 0.39 | ppl 1.31 | wps 23076 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 22723 | lr 0.000209781 | gnorm 0.427 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 63017
2022-03-07 06:32:53 | INFO | fairseq.trainer | begin training epoch 468
2022-03-07 06:32:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:34:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:35:04 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 13.333 | nll_loss 12.596 | ppl 6192.93 | wps 43794.9 | wpb 510.9 | bsz 1 | num_updates 22772 | best_loss 9.157
2022-03-07 06:35:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22772 updates
2022-03-07 06:35:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:35:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:35:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 468 @ 22772 updates, score 13.333) (writing took 2.3123334953561425 seconds)
2022-03-07 06:35:07 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-07 06:35:07 | INFO | train | epoch 468 | loss 2.535 | nll_loss 0.389 | ppl 1.31 | wps 23753.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 22772 | lr 0.000209556 | gnorm 0.423 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 63151
2022-03-07 06:35:07 | INFO | fairseq.trainer | begin training epoch 469
2022-03-07 06:35:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:36:19 | INFO | train_inner | epoch 469:     28 / 49 loss=2.536, nll_loss=0.389, ppl=1.31, wps=23543.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.426, loss_scale=32, train_wall=235, gb_free=8.8, wall=63224
2022-03-07 06:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:37:17 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 13.36 | nll_loss 12.622 | ppl 6305.87 | wps 43601.4 | wpb 510.9 | bsz 1 | num_updates 22821 | best_loss 9.157
2022-03-07 06:37:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22821 updates
2022-03-07 06:37:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:37:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:37:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 469 @ 22821 updates, score 13.36) (writing took 2.3655665861442685 seconds)
2022-03-07 06:37:19 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-07 06:37:19 | INFO | train | epoch 469 | loss 2.535 | nll_loss 0.389 | ppl 1.31 | wps 23951 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 22821 | lr 0.000209331 | gnorm 0.426 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 63284
2022-03-07 06:37:19 | INFO | fairseq.trainer | begin training epoch 470
2022-03-07 06:37:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:37:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:39:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:39:30 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 13.246 | nll_loss 12.508 | ppl 5825.88 | wps 42269.4 | wpb 510.9 | bsz 1 | num_updates 22869 | best_loss 9.157
2022-03-07 06:39:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22869 updates
2022-03-07 06:39:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:39:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:39:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 470 @ 22869 updates, score 13.246) (writing took 2.3975996263325214 seconds)
2022-03-07 06:39:32 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-07 06:39:32 | INFO | train | epoch 470 | loss 2.536 | nll_loss 0.39 | ppl 1.31 | wps 23400.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 22869 | lr 0.000209111 | gnorm 0.432 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 63417
2022-03-07 06:39:32 | INFO | fairseq.trainer | begin training epoch 471
2022-03-07 06:39:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:40:52 | INFO | train_inner | epoch 471:     31 / 49 loss=2.535, nll_loss=0.389, ppl=1.31, wps=23732.9, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.428, loss_scale=32, train_wall=233, gb_free=8.8, wall=63497
2022-03-07 06:41:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:41:43 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 13.32 | nll_loss 12.588 | ppl 6155.47 | wps 43650.8 | wpb 510.9 | bsz 1 | num_updates 22918 | best_loss 9.157
2022-03-07 06:41:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22918 updates
2022-03-07 06:41:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:41:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:41:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 471 @ 22918 updates, score 13.32) (writing took 2.477355291135609 seconds)
2022-03-07 06:41:45 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-07 06:41:45 | INFO | train | epoch 471 | loss 2.534 | nll_loss 0.389 | ppl 1.31 | wps 23924 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 22918 | lr 0.000208887 | gnorm 0.423 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 63550
2022-03-07 06:41:45 | INFO | fairseq.trainer | begin training epoch 472
2022-03-07 06:41:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:43:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:43:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:43:55 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 13.301 | nll_loss 12.569 | ppl 6077.65 | wps 43495.2 | wpb 510.9 | bsz 1 | num_updates 22966 | best_loss 9.157
2022-03-07 06:43:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22966 updates
2022-03-07 06:43:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:43:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:43:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 472 @ 22966 updates, score 13.301) (writing took 2.372842743061483 seconds)
2022-03-07 06:43:58 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-07 06:43:58 | INFO | train | epoch 472 | loss 2.533 | nll_loss 0.388 | ppl 1.31 | wps 23467.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 22966 | lr 0.000208669 | gnorm 0.421 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 63682
2022-03-07 06:43:58 | INFO | fairseq.trainer | begin training epoch 473
2022-03-07 06:43:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:45:26 | INFO | train_inner | epoch 473:     34 / 49 loss=2.534, nll_loss=0.388, ppl=1.31, wps=23729.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.425, loss_scale=32, train_wall=233, gb_free=8.8, wall=63770
2022-03-07 06:46:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:46:09 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 13.262 | nll_loss 12.527 | ppl 5900.6 | wps 42464.1 | wpb 510.9 | bsz 1 | num_updates 23015 | best_loss 9.157
2022-03-07 06:46:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23015 updates
2022-03-07 06:46:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:46:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:46:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 473 @ 23015 updates, score 13.262) (writing took 2.4834713097661734 seconds)
2022-03-07 06:46:11 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-07 06:46:11 | INFO | train | epoch 473 | loss 2.534 | nll_loss 0.388 | ppl 1.31 | wps 23820.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23015 | lr 0.000208446 | gnorm 0.432 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 63816
2022-03-07 06:46:11 | INFO | fairseq.trainer | begin training epoch 474
2022-03-07 06:46:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:48:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:48:24 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 13.353 | nll_loss 12.623 | ppl 6308.73 | wps 41146.2 | wpb 510.9 | bsz 1 | num_updates 23064 | best_loss 9.157
2022-03-07 06:48:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23064 updates
2022-03-07 06:48:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:48:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:48:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 474 @ 23064 updates, score 13.353) (writing took 2.5367494551464915 seconds)
2022-03-07 06:48:27 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-07 06:48:27 | INFO | train | epoch 474 | loss 2.533 | nll_loss 0.387 | ppl 1.31 | wps 23462.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23064 | lr 0.000208225 | gnorm 0.424 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 63951
2022-03-07 06:48:27 | INFO | fairseq.trainer | begin training epoch 475
2022-03-07 06:48:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:49:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:50:04 | INFO | train_inner | epoch 475:     37 / 49 loss=2.533, nll_loss=0.387, ppl=1.31, wps=23315.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.422, loss_scale=32, train_wall=237, gb_free=8.8, wall=64049
2022-03-07 06:50:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:50:40 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 13.402 | nll_loss 12.677 | ppl 6548.56 | wps 41941.4 | wpb 510.9 | bsz 1 | num_updates 23112 | best_loss 9.157
2022-03-07 06:50:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23112 updates
2022-03-07 06:50:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:50:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:50:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 475 @ 23112 updates, score 13.402) (writing took 2.511994769796729 seconds)
2022-03-07 06:50:42 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-07 06:50:42 | INFO | train | epoch 475 | loss 2.532 | nll_loss 0.386 | ppl 1.31 | wps 22965 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 23112 | lr 0.000208009 | gnorm 0.418 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 64087
2022-03-07 06:50:42 | INFO | fairseq.trainer | begin training epoch 476
2022-03-07 06:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:52:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:52:55 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 13.315 | nll_loss 12.585 | ppl 6143.25 | wps 41806.6 | wpb 510.9 | bsz 1 | num_updates 23161 | best_loss 9.157
2022-03-07 06:52:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23161 updates
2022-03-07 06:52:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:52:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:52:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 476 @ 23161 updates, score 13.315) (writing took 2.594534482806921 seconds)
2022-03-07 06:52:58 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-07 06:52:58 | INFO | train | epoch 476 | loss 2.533 | nll_loss 0.387 | ppl 1.31 | wps 23410.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23161 | lr 0.000207788 | gnorm 0.426 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 64223
2022-03-07 06:52:58 | INFO | fairseq.trainer | begin training epoch 477
2022-03-07 06:52:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:54:40 | INFO | train_inner | epoch 477:     39 / 49 loss=2.532, nll_loss=0.387, ppl=1.31, wps=23454.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.424, loss_scale=32, train_wall=236, gb_free=8.8, wall=64325
2022-03-07 06:55:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:55:11 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 13.33 | nll_loss 12.594 | ppl 6182.09 | wps 41629.4 | wpb 510.9 | bsz 1 | num_updates 23210 | best_loss 9.157
2022-03-07 06:55:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23210 updates
2022-03-07 06:55:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:55:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:55:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 477 @ 23210 updates, score 13.33) (writing took 2.375310407951474 seconds)
2022-03-07 06:55:13 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-07 06:55:13 | INFO | train | epoch 477 | loss 2.532 | nll_loss 0.387 | ppl 1.31 | wps 23485 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23210 | lr 0.000207569 | gnorm 0.422 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 64358
2022-03-07 06:55:13 | INFO | fairseq.trainer | begin training epoch 478
2022-03-07 06:55:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:55:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:57:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:57:26 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 13.336 | nll_loss 12.598 | ppl 6201.38 | wps 42310.8 | wpb 510.9 | bsz 1 | num_updates 23258 | best_loss 9.157
2022-03-07 06:57:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23258 updates
2022-03-07 06:57:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:57:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:57:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 478 @ 23258 updates, score 13.336) (writing took 2.456892393063754 seconds)
2022-03-07 06:57:28 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-07 06:57:28 | INFO | train | epoch 478 | loss 2.531 | nll_loss 0.386 | ppl 1.31 | wps 23021.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 23258 | lr 0.000207355 | gnorm 0.419 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 64493
2022-03-07 06:57:28 | INFO | fairseq.trainer | begin training epoch 479
2022-03-07 06:57:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:59:19 | INFO | train_inner | epoch 479:     42 / 49 loss=2.531, nll_loss=0.386, ppl=1.31, wps=23292.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.421, loss_scale=32, train_wall=238, gb_free=8.8, wall=64604
2022-03-07 06:59:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:59:42 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 13.431 | nll_loss 12.708 | ppl 6691.77 | wps 41402.8 | wpb 510.9 | bsz 1 | num_updates 23307 | best_loss 9.157
2022-03-07 06:59:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23307 updates
2022-03-07 06:59:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:59:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:59:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 479 @ 23307 updates, score 13.431) (writing took 2.4543046662583947 seconds)
2022-03-07 06:59:44 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-07 06:59:44 | INFO | train | epoch 479 | loss 2.532 | nll_loss 0.386 | ppl 1.31 | wps 23433.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23307 | lr 0.000207137 | gnorm 0.425 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 64629
2022-03-07 06:59:44 | INFO | fairseq.trainer | begin training epoch 480
2022-03-07 06:59:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:01:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:01:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:01:57 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 13.335 | nll_loss 12.602 | ppl 6217.06 | wps 41431.1 | wpb 510.9 | bsz 1 | num_updates 23355 | best_loss 9.157
2022-03-07 07:01:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23355 updates
2022-03-07 07:01:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:01:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:01:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 480 @ 23355 updates, score 13.335) (writing took 2.3684440590441227 seconds)
2022-03-07 07:01:59 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-07 07:01:59 | INFO | train | epoch 480 | loss 2.531 | nll_loss 0.386 | ppl 1.31 | wps 23000.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 23355 | lr 0.000206924 | gnorm 0.424 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 64764
2022-03-07 07:01:59 | INFO | fairseq.trainer | begin training epoch 481
2022-03-07 07:01:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:03:58 | INFO | train_inner | epoch 481:     45 / 49 loss=2.53, nll_loss=0.385, ppl=1.31, wps=23267.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.421, loss_scale=32, train_wall=238, gb_free=8.8, wall=64883
2022-03-07 07:04:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:04:12 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 13.317 | nll_loss 12.582 | ppl 6132.07 | wps 41043.7 | wpb 510.9 | bsz 1 | num_updates 23404 | best_loss 9.157
2022-03-07 07:04:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23404 updates
2022-03-07 07:04:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:04:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:04:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 481 @ 23404 updates, score 13.317) (writing took 2.387021229136735 seconds)
2022-03-07 07:04:15 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-07 07:04:15 | INFO | train | epoch 481 | loss 2.53 | nll_loss 0.385 | ppl 1.31 | wps 23448.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23404 | lr 0.000206707 | gnorm 0.418 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 64900
2022-03-07 07:04:15 | INFO | fairseq.trainer | begin training epoch 482
2022-03-07 07:04:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:06:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:06:28 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 13.318 | nll_loss 12.587 | ppl 6151.11 | wps 41803.8 | wpb 510.9 | bsz 1 | num_updates 23453 | best_loss 9.157
2022-03-07 07:06:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23453 updates
2022-03-07 07:06:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:06:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:06:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 482 @ 23453 updates, score 13.318) (writing took 2.292359048034996 seconds)
2022-03-07 07:06:30 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-07 07:06:30 | INFO | train | epoch 482 | loss 2.529 | nll_loss 0.384 | ppl 1.31 | wps 23480.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23453 | lr 0.000206491 | gnorm 0.422 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 65035
2022-03-07 07:06:30 | INFO | fairseq.trainer | begin training epoch 483
2022-03-07 07:06:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:07:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:08:36 | INFO | train_inner | epoch 483:     48 / 49 loss=2.529, nll_loss=0.384, ppl=1.31, wps=23286.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.422, loss_scale=32, train_wall=238, gb_free=8.8, wall=65161
2022-03-07 07:08:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:08:43 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 13.427 | nll_loss 12.702 | ppl 6664.91 | wps 41761.2 | wpb 510.9 | bsz 1 | num_updates 23501 | best_loss 9.157
2022-03-07 07:08:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23501 updates
2022-03-07 07:08:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:08:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:08:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 483 @ 23501 updates, score 13.427) (writing took 2.407441932708025 seconds)
2022-03-07 07:08:45 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-07 07:08:45 | INFO | train | epoch 483 | loss 2.528 | nll_loss 0.384 | ppl 1.3 | wps 23015.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 23501 | lr 0.00020628 | gnorm 0.42 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 65170
2022-03-07 07:08:45 | INFO | fairseq.trainer | begin training epoch 484
2022-03-07 07:08:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:10:56 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 13.321 | nll_loss 12.593 | ppl 6179.23 | wps 42570.8 | wpb 510.9 | bsz 1 | num_updates 23550 | best_loss 9.157
2022-03-07 07:10:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23550 updates
2022-03-07 07:10:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:10:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:10:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 484 @ 23550 updates, score 13.321) (writing took 2.417599886190146 seconds)
2022-03-07 07:10:59 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-07 07:10:59 | INFO | train | epoch 484 | loss 2.529 | nll_loss 0.384 | ppl 1.31 | wps 23847.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23550 | lr 0.000206065 | gnorm 0.422 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 65303
2022-03-07 07:10:59 | INFO | fairseq.trainer | begin training epoch 485
2022-03-07 07:10:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:13:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:13:09 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 13.345 | nll_loss 12.613 | ppl 6265.7 | wps 43800.4 | wpb 510.9 | bsz 1 | num_updates 23599 | best_loss 9.157
2022-03-07 07:13:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23599 updates
2022-03-07 07:13:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:13:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:13:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 485 @ 23599 updates, score 13.345) (writing took 2.6207782081328332 seconds)
2022-03-07 07:13:12 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-07 07:13:12 | INFO | train | epoch 485 | loss 2.528 | nll_loss 0.384 | ppl 1.31 | wps 23904.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23599 | lr 0.000205851 | gnorm 0.423 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 65436
2022-03-07 07:13:12 | INFO | fairseq.trainer | begin training epoch 486
2022-03-07 07:13:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:13:14 | INFO | train_inner | epoch 486:      1 / 49 loss=2.529, nll_loss=0.384, ppl=1.31, wps=23224.7, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=23600, lr=0.000205847, gnorm=0.424, loss_scale=32, train_wall=230, gb_free=8.8, wall=65439
2022-03-07 07:13:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:15:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:15:22 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 13.499 | nll_loss 12.785 | ppl 7059.9 | wps 43239.3 | wpb 510.9 | bsz 1 | num_updates 23647 | best_loss 9.157
2022-03-07 07:15:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23647 updates
2022-03-07 07:15:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:15:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:15:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 486 @ 23647 updates, score 13.499) (writing took 2.4578793798573315 seconds)
2022-03-07 07:15:25 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-07 07:15:25 | INFO | train | epoch 486 | loss 2.528 | nll_loss 0.384 | ppl 1.3 | wps 23413.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 23647 | lr 0.000205642 | gnorm 0.427 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 65569
2022-03-07 07:15:25 | INFO | fairseq.trainer | begin training epoch 487
2022-03-07 07:15:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:17:35 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 13.327 | nll_loss 12.597 | ppl 6195.77 | wps 43271.2 | wpb 510.9 | bsz 1 | num_updates 23696 | best_loss 9.157
2022-03-07 07:17:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23696 updates
2022-03-07 07:17:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:17:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:17:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 487 @ 23696 updates, score 13.327) (writing took 2.3055956279858947 seconds)
2022-03-07 07:17:37 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-07 07:17:37 | INFO | train | epoch 487 | loss 2.528 | nll_loss 0.384 | ppl 1.3 | wps 23937.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23696 | lr 0.000205429 | gnorm 0.422 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 65702
2022-03-07 07:17:37 | INFO | fairseq.trainer | begin training epoch 488
2022-03-07 07:17:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:17:48 | INFO | train_inner | epoch 488:      4 / 49 loss=2.528, nll_loss=0.384, ppl=1.3, wps=23724.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23700, lr=0.000205412, gnorm=0.425, loss_scale=32, train_wall=233, gb_free=8.8, wall=65713
2022-03-07 07:19:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:19:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:19:48 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 13.184 | nll_loss 12.436 | ppl 5539.73 | wps 41781.6 | wpb 510.9 | bsz 1 | num_updates 23744 | best_loss 9.157
2022-03-07 07:19:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23744 updates
2022-03-07 07:19:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:19:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:19:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 488 @ 23744 updates, score 13.184) (writing took 2.5028288108296692 seconds)
2022-03-07 07:19:51 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-07 07:19:51 | INFO | train | epoch 488 | loss 2.527 | nll_loss 0.383 | ppl 1.3 | wps 23361.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 23744 | lr 0.000205222 | gnorm 0.419 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 65835
2022-03-07 07:19:51 | INFO | fairseq.trainer | begin training epoch 489
2022-03-07 07:19:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:21:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:22:01 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 13.323 | nll_loss 12.588 | ppl 6155.29 | wps 43173.6 | wpb 510.9 | bsz 1 | num_updates 23793 | best_loss 9.157
2022-03-07 07:22:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23793 updates
2022-03-07 07:22:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:22:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:22:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 489 @ 23793 updates, score 13.323) (writing took 2.3677585450932384 seconds)
2022-03-07 07:22:03 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-07 07:22:03 | INFO | train | epoch 489 | loss 2.527 | nll_loss 0.383 | ppl 1.3 | wps 23930.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23793 | lr 0.00020501 | gnorm 0.424 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 65968
2022-03-07 07:22:03 | INFO | fairseq.trainer | begin training epoch 490
2022-03-07 07:22:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:22:22 | INFO | train_inner | epoch 490:      7 / 49 loss=2.527, nll_loss=0.383, ppl=1.3, wps=23697.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.422, loss_scale=32, train_wall=233, gb_free=8.8, wall=65986
2022-03-07 07:23:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:24:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:24:16 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 13.267 | nll_loss 12.534 | ppl 5929.66 | wps 41293.2 | wpb 510.9 | bsz 1 | num_updates 23841 | best_loss 9.157
2022-03-07 07:24:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23841 updates
2022-03-07 07:24:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:24:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:24:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 490 @ 23841 updates, score 13.267) (writing took 2.345427980646491 seconds)
2022-03-07 07:24:18 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-07 07:24:18 | INFO | train | epoch 490 | loss 2.526 | nll_loss 0.383 | ppl 1.3 | wps 23080.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 23841 | lr 0.000204804 | gnorm 0.421 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 66103
2022-03-07 07:24:18 | INFO | fairseq.trainer | begin training epoch 491
2022-03-07 07:24:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:26:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:26:31 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 13.329 | nll_loss 12.593 | ppl 6179.63 | wps 42253.1 | wpb 510.9 | bsz 1 | num_updates 23890 | best_loss 9.157
2022-03-07 07:26:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23890 updates
2022-03-07 07:26:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:26:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:26:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 491 @ 23890 updates, score 13.329) (writing took 2.4368081018328667 seconds)
2022-03-07 07:26:34 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-07 07:26:34 | INFO | train | epoch 491 | loss 2.526 | nll_loss 0.382 | ppl 1.3 | wps 23494 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23890 | lr 0.000204594 | gnorm 0.419 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 66238
2022-03-07 07:26:34 | INFO | fairseq.trainer | begin training epoch 492
2022-03-07 07:26:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:27:00 | INFO | train_inner | epoch 492:     10 / 49 loss=2.526, nll_loss=0.382, ppl=1.3, wps=23311.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.419, loss_scale=16, train_wall=237, gb_free=8.8, wall=66265
2022-03-07 07:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:28:46 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 13.345 | nll_loss 12.609 | ppl 6245.17 | wps 41804.6 | wpb 510.9 | bsz 1 | num_updates 23939 | best_loss 9.157
2022-03-07 07:28:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23939 updates
2022-03-07 07:28:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:28:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:28:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 492 @ 23939 updates, score 13.345) (writing took 2.343859371729195 seconds)
2022-03-07 07:28:49 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-07 07:28:49 | INFO | train | epoch 492 | loss 2.525 | nll_loss 0.381 | ppl 1.3 | wps 23489.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23939 | lr 0.000204384 | gnorm 0.42 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 66374
2022-03-07 07:28:49 | INFO | fairseq.trainer | begin training epoch 493
2022-03-07 07:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:30:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:31:02 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 13.431 | nll_loss 12.711 | ppl 6702.89 | wps 41618.5 | wpb 510.9 | bsz 1 | num_updates 23988 | best_loss 9.157
2022-03-07 07:31:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 23988 updates
2022-03-07 07:31:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:31:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:31:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 493 @ 23988 updates, score 13.431) (writing took 2.391172688920051 seconds)
2022-03-07 07:31:04 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-07 07:31:04 | INFO | train | epoch 493 | loss 2.525 | nll_loss 0.382 | ppl 1.3 | wps 23459.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23988 | lr 0.000204175 | gnorm 0.416 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 66509
2022-03-07 07:31:04 | INFO | fairseq.trainer | begin training epoch 494
2022-03-07 07:31:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:31:36 | INFO | train_inner | epoch 494:     12 / 49 loss=2.525, nll_loss=0.381, ppl=1.3, wps=23493, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.417, loss_scale=32, train_wall=235, gb_free=8.8, wall=66541
2022-03-07 07:33:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:33:17 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 13.264 | nll_loss 12.524 | ppl 5890.3 | wps 41383.1 | wpb 510.9 | bsz 1 | num_updates 24037 | best_loss 9.157
2022-03-07 07:33:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24037 updates
2022-03-07 07:33:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:33:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:33:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 494 @ 24037 updates, score 13.264) (writing took 2.3987481272779405 seconds)
2022-03-07 07:33:20 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-07 07:33:20 | INFO | train | epoch 494 | loss 2.524 | nll_loss 0.381 | ppl 1.3 | wps 23466.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24037 | lr 0.000203967 | gnorm 0.413 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 66644
2022-03-07 07:33:20 | INFO | fairseq.trainer | begin training epoch 495
2022-03-07 07:33:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:35:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:35:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:35:33 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 13.212 | nll_loss 12.472 | ppl 5680.68 | wps 41225.1 | wpb 510.9 | bsz 1 | num_updates 24085 | best_loss 9.157
2022-03-07 07:35:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24085 updates
2022-03-07 07:35:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:35:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:35:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 495 @ 24085 updates, score 13.212) (writing took 2.4643218088895082 seconds)
2022-03-07 07:35:35 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-07 07:35:35 | INFO | train | epoch 495 | loss 2.524 | nll_loss 0.381 | ppl 1.3 | wps 22946.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 24085 | lr 0.000203764 | gnorm 0.424 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 66780
2022-03-07 07:35:35 | INFO | fairseq.trainer | begin training epoch 496
2022-03-07 07:35:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:36:15 | INFO | train_inner | epoch 496:     15 / 49 loss=2.525, nll_loss=0.381, ppl=1.3, wps=23270.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=24100, lr=0.0002037, gnorm=0.419, loss_scale=32, train_wall=238, gb_free=8.8, wall=66819
2022-03-07 07:37:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:37:48 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 13.401 | nll_loss 12.68 | ppl 6562.88 | wps 41707.8 | wpb 510.9 | bsz 1 | num_updates 24134 | best_loss 9.157
2022-03-07 07:37:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24134 updates
2022-03-07 07:37:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:37:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:37:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 496 @ 24134 updates, score 13.401) (writing took 2.3563728402368724 seconds)
2022-03-07 07:37:51 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-07 07:37:51 | INFO | train | epoch 496 | loss 2.523 | nll_loss 0.38 | ppl 1.3 | wps 23479 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24134 | lr 0.000203557 | gnorm 0.417 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 66915
2022-03-07 07:37:51 | INFO | fairseq.trainer | begin training epoch 497
2022-03-07 07:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:39:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:40:04 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 13.331 | nll_loss 12.599 | ppl 6205.33 | wps 40731.3 | wpb 510.9 | bsz 1 | num_updates 24183 | best_loss 9.157
2022-03-07 07:40:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24183 updates
2022-03-07 07:40:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:40:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:40:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 497 @ 24183 updates, score 13.331) (writing took 2.409558671992272 seconds)
2022-03-07 07:40:06 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-07 07:40:06 | INFO | train | epoch 497 | loss 2.524 | nll_loss 0.381 | ppl 1.3 | wps 23446 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24183 | lr 0.00020335 | gnorm 0.422 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 67051
2022-03-07 07:40:06 | INFO | fairseq.trainer | begin training epoch 498
2022-03-07 07:40:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:40:51 | INFO | train_inner | epoch 498:     17 / 49 loss=2.523, nll_loss=0.38, ppl=1.3, wps=23463.1, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.419, loss_scale=32, train_wall=236, gb_free=8.8, wall=67096
2022-03-07 07:41:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:42:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:42:20 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 13.365 | nll_loss 12.64 | ppl 6382.77 | wps 41216.2 | wpb 510.9 | bsz 1 | num_updates 24231 | best_loss 9.157
2022-03-07 07:42:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24231 updates
2022-03-07 07:42:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:42:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:42:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 498 @ 24231 updates, score 13.365) (writing took 2.3606496090069413 seconds)
2022-03-07 07:42:22 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-07 07:42:22 | INFO | train | epoch 498 | loss 2.523 | nll_loss 0.38 | ppl 1.3 | wps 22954.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 24231 | lr 0.000203149 | gnorm 0.417 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 67187
2022-03-07 07:42:22 | INFO | fairseq.trainer | begin training epoch 499
2022-03-07 07:42:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:44:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:44:35 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 13.268 | nll_loss 12.53 | ppl 5912.56 | wps 41525.9 | wpb 510.9 | bsz 1 | num_updates 24280 | best_loss 9.157
2022-03-07 07:44:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24280 updates
2022-03-07 07:44:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:44:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:44:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 499 @ 24280 updates, score 13.268) (writing took 2.3257753090001643 seconds)
2022-03-07 07:44:37 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-07 07:44:37 | INFO | train | epoch 499 | loss 2.522 | nll_loss 0.379 | ppl 1.3 | wps 23522 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24280 | lr 0.000202944 | gnorm 0.416 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 67322
2022-03-07 07:44:37 | INFO | fairseq.trainer | begin training epoch 500
2022-03-07 07:44:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:45:29 | INFO | train_inner | epoch 500:     20 / 49 loss=2.522, nll_loss=0.379, ppl=1.3, wps=23319.9, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.415, loss_scale=32, train_wall=237, gb_free=8.8, wall=67374
2022-03-07 07:46:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:46:48 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 13.346 | nll_loss 12.612 | ppl 6261.07 | wps 43407.6 | wpb 510.9 | bsz 1 | num_updates 24329 | best_loss 9.157
2022-03-07 07:46:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24329 updates
2022-03-07 07:46:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:46:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:46:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 500 @ 24329 updates, score 13.346) (writing took 2.3116631410084665 seconds)
2022-03-07 07:46:51 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-07 07:46:51 | INFO | train | epoch 500 | loss 2.522 | nll_loss 0.379 | ppl 1.3 | wps 23757.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24329 | lr 0.000202739 | gnorm 0.414 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 67456
2022-03-07 07:46:51 | INFO | fairseq.trainer | begin training epoch 501
2022-03-07 07:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:47:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:48:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:49:01 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 13.376 | nll_loss 12.653 | ppl 6440.03 | wps 44021.6 | wpb 510.9 | bsz 1 | num_updates 24377 | best_loss 9.157
2022-03-07 07:49:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24377 updates
2022-03-07 07:49:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:49:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:49:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 501 @ 24377 updates, score 13.376) (writing took 2.3278933581896126 seconds)
2022-03-07 07:49:03 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-07 07:49:03 | INFO | train | epoch 501 | loss 2.522 | nll_loss 0.379 | ppl 1.3 | wps 23458.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 24377 | lr 0.00020254 | gnorm 0.416 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 67588
2022-03-07 07:49:03 | INFO | fairseq.trainer | begin training epoch 502
2022-03-07 07:49:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:50:03 | INFO | train_inner | epoch 502:     23 / 49 loss=2.522, nll_loss=0.379, ppl=1.3, wps=23716, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.419, loss_scale=32, train_wall=234, gb_free=8.8, wall=67648
2022-03-07 07:51:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:51:14 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 13.365 | nll_loss 12.638 | ppl 6372.45 | wps 42803.7 | wpb 510.9 | bsz 1 | num_updates 24426 | best_loss 9.157
2022-03-07 07:51:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24426 updates
2022-03-07 07:51:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:51:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:51:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 502 @ 24426 updates, score 13.365) (writing took 2.4348176359198987 seconds)
2022-03-07 07:51:16 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-07 07:51:16 | INFO | train | epoch 502 | loss 2.522 | nll_loss 0.38 | ppl 1.3 | wps 23911.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24426 | lr 0.000202336 | gnorm 0.417 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 67721
2022-03-07 07:51:16 | INFO | fairseq.trainer | begin training epoch 503
2022-03-07 07:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:53:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:53:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:53:27 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 13.426 | nll_loss 12.704 | ppl 6670.2 | wps 43154.1 | wpb 510.9 | bsz 1 | num_updates 24474 | best_loss 9.157
2022-03-07 07:53:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24474 updates
2022-03-07 07:53:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:53:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:53:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 503 @ 24474 updates, score 13.426) (writing took 2.359957962296903 seconds)
2022-03-07 07:53:29 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-07 07:53:29 | INFO | train | epoch 503 | loss 2.52 | nll_loss 0.378 | ppl 1.3 | wps 23439 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 24474 | lr 0.000202138 | gnorm 0.415 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 67854
2022-03-07 07:53:29 | INFO | fairseq.trainer | begin training epoch 504
2022-03-07 07:53:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:54:36 | INFO | train_inner | epoch 504:     26 / 49 loss=2.521, nll_loss=0.378, ppl=1.3, wps=23731.5, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.413, loss_scale=32, train_wall=233, gb_free=8.8, wall=67921
2022-03-07 07:55:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:55:39 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 13.389 | nll_loss 12.661 | ppl 6476.62 | wps 43203.8 | wpb 510.9 | bsz 1 | num_updates 24523 | best_loss 9.157
2022-03-07 07:55:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24523 updates
2022-03-07 07:55:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:55:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:55:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 504 @ 24523 updates, score 13.389) (writing took 2.399212229065597 seconds)
2022-03-07 07:55:42 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-07 07:55:42 | INFO | train | epoch 504 | loss 2.521 | nll_loss 0.378 | ppl 1.3 | wps 23937 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24523 | lr 0.000201936 | gnorm 0.416 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 67987
2022-03-07 07:55:42 | INFO | fairseq.trainer | begin training epoch 505
2022-03-07 07:55:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:57:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:57:52 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 13.305 | nll_loss 12.57 | ppl 6082.49 | wps 43000.6 | wpb 510.9 | bsz 1 | num_updates 24572 | best_loss 9.157
2022-03-07 07:57:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24572 updates
2022-03-07 07:57:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:57:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:57:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 505 @ 24572 updates, score 13.305) (writing took 2.4232170642353594 seconds)
2022-03-07 07:57:55 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-07 07:57:55 | INFO | train | epoch 505 | loss 2.52 | nll_loss 0.378 | ppl 1.3 | wps 23917.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24572 | lr 0.000201734 | gnorm 0.412 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 68120
2022-03-07 07:57:55 | INFO | fairseq.trainer | begin training epoch 506
2022-03-07 07:57:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:58:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:59:10 | INFO | train_inner | epoch 506:     29 / 49 loss=2.52, nll_loss=0.378, ppl=1.3, wps=23719.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.413, loss_scale=32, train_wall=233, gb_free=8.8, wall=68195
2022-03-07 08:00:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:00:06 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 13.32 | nll_loss 12.586 | ppl 6149.83 | wps 40422.7 | wpb 510.9 | bsz 1 | num_updates 24620 | best_loss 9.157
2022-03-07 08:00:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24620 updates
2022-03-07 08:00:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:00:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:00:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 506 @ 24620 updates, score 13.32) (writing took 2.368087955750525 seconds)
2022-03-07 08:00:08 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-07 08:00:08 | INFO | train | epoch 506 | loss 2.52 | nll_loss 0.377 | ppl 1.3 | wps 23278.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 24620 | lr 0.000201538 | gnorm 0.414 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 68253
2022-03-07 08:00:09 | INFO | fairseq.trainer | begin training epoch 507
2022-03-07 08:00:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:02:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:02:21 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 13.387 | nll_loss 12.662 | ppl 6482.3 | wps 41664.8 | wpb 510.9 | bsz 1 | num_updates 24669 | best_loss 9.157
2022-03-07 08:02:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24669 updates
2022-03-07 08:02:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:02:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:02:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 507 @ 24669 updates, score 13.387) (writing took 2.47022907063365 seconds)
2022-03-07 08:02:24 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-07 08:02:24 | INFO | train | epoch 507 | loss 2.519 | nll_loss 0.377 | ppl 1.3 | wps 23466.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24669 | lr 0.000201337 | gnorm 0.414 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 68389
2022-03-07 08:02:24 | INFO | fairseq.trainer | begin training epoch 508
2022-03-07 08:02:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:03:46 | INFO | train_inner | epoch 508:     31 / 49 loss=2.519, nll_loss=0.377, ppl=1.3, wps=23522.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.413, loss_scale=32, train_wall=235, gb_free=8.8, wall=68470
2022-03-07 08:04:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:04:37 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 13.445 | nll_loss 12.722 | ppl 6756.41 | wps 41344.4 | wpb 510.9 | bsz 1 | num_updates 24718 | best_loss 9.157
2022-03-07 08:04:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24718 updates
2022-03-07 08:04:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:04:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:04:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 508 @ 24718 updates, score 13.445) (writing took 2.331307227257639 seconds)
2022-03-07 08:04:39 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-07 08:04:39 | INFO | train | epoch 508 | loss 2.52 | nll_loss 0.377 | ppl 1.3 | wps 23451.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24718 | lr 0.000201138 | gnorm 0.413 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 68524
2022-03-07 08:04:39 | INFO | fairseq.trainer | begin training epoch 509
2022-03-07 08:04:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:04:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:06:53 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 13.373 | nll_loss 12.643 | ppl 6398.02 | wps 41605.1 | wpb 510.9 | bsz 1 | num_updates 24766 | best_loss 9.157
2022-03-07 08:06:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24766 updates
2022-03-07 08:06:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:06:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:06:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 509 @ 24766 updates, score 13.373) (writing took 2.3562442446127534 seconds)
2022-03-07 08:06:55 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-07 08:06:55 | INFO | train | epoch 509 | loss 2.519 | nll_loss 0.377 | ppl 1.3 | wps 22980.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 24766 | lr 0.000200943 | gnorm 0.412 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 68660
2022-03-07 08:06:55 | INFO | fairseq.trainer | begin training epoch 510
2022-03-07 08:06:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:08:25 | INFO | train_inner | epoch 510:     34 / 49 loss=2.519, nll_loss=0.377, ppl=1.3, wps=23253.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.414, loss_scale=32, train_wall=238, gb_free=8.8, wall=68749
2022-03-07 08:09:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:09:08 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 13.417 | nll_loss 12.696 | ppl 6637.24 | wps 41720.6 | wpb 510.9 | bsz 1 | num_updates 24815 | best_loss 9.157
2022-03-07 08:09:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24815 updates
2022-03-07 08:09:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:09:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:09:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 510 @ 24815 updates, score 13.417) (writing took 2.379405464977026 seconds)
2022-03-07 08:09:10 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-07 08:09:10 | INFO | train | epoch 510 | loss 2.519 | nll_loss 0.377 | ppl 1.3 | wps 23454.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24815 | lr 0.000200744 | gnorm 0.414 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 68795
2022-03-07 08:09:10 | INFO | fairseq.trainer | begin training epoch 511
2022-03-07 08:09:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:11:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:11:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:11:24 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 13.375 | nll_loss 12.648 | ppl 6417.06 | wps 40686.9 | wpb 510.9 | bsz 1 | num_updates 24863 | best_loss 9.157
2022-03-07 08:11:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24863 updates
2022-03-07 08:11:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:11:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:11:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 511 @ 24863 updates, score 13.375) (writing took 2.6802442469634116 seconds)
2022-03-07 08:11:26 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-07 08:11:26 | INFO | train | epoch 511 | loss 2.518 | nll_loss 0.376 | ppl 1.3 | wps 22899.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 24863 | lr 0.00020055 | gnorm 0.412 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 68931
2022-03-07 08:11:26 | INFO | fairseq.trainer | begin training epoch 512
2022-03-07 08:11:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:13:04 | INFO | train_inner | epoch 512:     37 / 49 loss=2.518, nll_loss=0.376, ppl=1.3, wps=23239.6, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.413, loss_scale=32, train_wall=238, gb_free=8.8, wall=69028
2022-03-07 08:13:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:13:39 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 13.258 | nll_loss 12.522 | ppl 5882.78 | wps 41399.8 | wpb 510.9 | bsz 1 | num_updates 24912 | best_loss 9.157
2022-03-07 08:13:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24912 updates
2022-03-07 08:13:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:13:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:13:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 512 @ 24912 updates, score 13.258) (writing took 2.4419952551834285 seconds)
2022-03-07 08:13:42 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-07 08:13:42 | INFO | train | epoch 512 | loss 2.518 | nll_loss 0.376 | ppl 1.3 | wps 23451.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24912 | lr 0.000200353 | gnorm 0.416 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 69067
2022-03-07 08:13:42 | INFO | fairseq.trainer | begin training epoch 513
2022-03-07 08:13:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:15:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:15:55 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 13.315 | nll_loss 12.583 | ppl 6134.07 | wps 41321.3 | wpb 510.9 | bsz 1 | num_updates 24961 | best_loss 9.157
2022-03-07 08:15:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24961 updates
2022-03-07 08:15:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:15:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:15:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 513 @ 24961 updates, score 13.315) (writing took 2.3654406210407615 seconds)
2022-03-07 08:15:57 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-07 08:15:57 | INFO | train | epoch 513 | loss 2.517 | nll_loss 0.375 | ppl 1.3 | wps 23475.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24961 | lr 0.000200156 | gnorm 0.407 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 69202
2022-03-07 08:15:57 | INFO | fairseq.trainer | begin training epoch 514
2022-03-07 08:15:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:17:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:17:43 | INFO | train_inner | epoch 514:     40 / 49 loss=2.517, nll_loss=0.375, ppl=1.3, wps=23262.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.41, loss_scale=32, train_wall=238, gb_free=8.8, wall=69307
2022-03-07 08:18:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:18:10 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 13.447 | nll_loss 12.723 | ppl 6759.08 | wps 41705.5 | wpb 510.9 | bsz 1 | num_updates 25009 | best_loss 9.157
2022-03-07 08:18:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25009 updates
2022-03-07 08:18:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:18:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:18:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 514 @ 25009 updates, score 13.447) (writing took 2.391344149131328 seconds)
2022-03-07 08:18:13 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-07 08:18:13 | INFO | train | epoch 514 | loss 2.517 | nll_loss 0.376 | ppl 1.3 | wps 22993.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 25009 | lr 0.000199964 | gnorm 0.414 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 69337
2022-03-07 08:18:13 | INFO | fairseq.trainer | begin training epoch 515
2022-03-07 08:18:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:20:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:20:25 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 13.341 | nll_loss 12.616 | ppl 6276 | wps 41553.5 | wpb 510.9 | bsz 1 | num_updates 25058 | best_loss 9.157
2022-03-07 08:20:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25058 updates
2022-03-07 08:20:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:20:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:20:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 515 @ 25058 updates, score 13.341) (writing took 2.3426431571133435 seconds)
2022-03-07 08:20:28 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-07 08:20:28 | INFO | train | epoch 515 | loss 2.517 | nll_loss 0.375 | ppl 1.3 | wps 23503.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25058 | lr 0.000199768 | gnorm 0.415 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 69473
2022-03-07 08:20:28 | INFO | fairseq.trainer | begin training epoch 516
2022-03-07 08:20:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:22:18 | INFO | train_inner | epoch 516:     42 / 49 loss=2.517, nll_loss=0.376, ppl=1.3, wps=23537.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.416, loss_scale=32, train_wall=235, gb_free=8.8, wall=69583
2022-03-07 08:22:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:22:41 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 13.35 | nll_loss 12.626 | ppl 6323.19 | wps 40811.2 | wpb 510.9 | bsz 1 | num_updates 25107 | best_loss 9.157
2022-03-07 08:22:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25107 updates
2022-03-07 08:22:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:22:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:22:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 516 @ 25107 updates, score 13.35) (writing took 2.409235854167491 seconds)
2022-03-07 08:22:43 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-07 08:22:43 | INFO | train | epoch 516 | loss 2.516 | nll_loss 0.375 | ppl 1.3 | wps 23473 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25107 | lr 0.000199573 | gnorm 0.415 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 69608
2022-03-07 08:22:43 | INFO | fairseq.trainer | begin training epoch 517
2022-03-07 08:22:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:23:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:24:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:24:54 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 13.371 | nll_loss 12.645 | ppl 6405.56 | wps 43249.3 | wpb 510.9 | bsz 1 | num_updates 25155 | best_loss 9.157
2022-03-07 08:24:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25155 updates
2022-03-07 08:24:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:24:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:24:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 517 @ 25155 updates, score 13.371) (writing took 2.450280569959432 seconds)
2022-03-07 08:24:56 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-07 08:24:56 | INFO | train | epoch 517 | loss 2.516 | nll_loss 0.374 | ppl 1.3 | wps 23417.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25155 | lr 0.000199383 | gnorm 0.414 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 69741
2022-03-07 08:24:56 | INFO | fairseq.trainer | begin training epoch 518
2022-03-07 08:24:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:26:54 | INFO | train_inner | epoch 518:     45 / 49 loss=2.515, nll_loss=0.374, ppl=1.3, wps=23540.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.411, loss_scale=32, train_wall=235, gb_free=8.8, wall=69858
2022-03-07 08:27:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:27:08 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 13.363 | nll_loss 12.636 | ppl 6367.05 | wps 41183.3 | wpb 510.9 | bsz 1 | num_updates 25204 | best_loss 9.157
2022-03-07 08:27:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25204 updates
2022-03-07 08:27:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:27:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:27:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 518 @ 25204 updates, score 13.363) (writing took 2.310711783822626 seconds)
2022-03-07 08:27:11 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-07 08:27:11 | INFO | train | epoch 518 | loss 2.515 | nll_loss 0.374 | ppl 1.3 | wps 23623.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25204 | lr 0.000199189 | gnorm 0.409 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 69875
2022-03-07 08:27:11 | INFO | fairseq.trainer | begin training epoch 519
2022-03-07 08:27:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:28:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:29:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:29:23 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 13.298 | nll_loss 12.573 | ppl 6092.49 | wps 41622.5 | wpb 510.9 | bsz 1 | num_updates 25252 | best_loss 9.157
2022-03-07 08:29:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25252 updates
2022-03-07 08:29:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:29:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:29:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 519 @ 25252 updates, score 13.298) (writing took 2.3649713820777833 seconds)
2022-03-07 08:29:26 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-07 08:29:26 | INFO | train | epoch 519 | loss 2.515 | nll_loss 0.374 | ppl 1.3 | wps 23038.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25252 | lr 0.000199 | gnorm 0.407 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 70010
2022-03-07 08:29:26 | INFO | fairseq.trainer | begin training epoch 520
2022-03-07 08:29:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:31:32 | INFO | train_inner | epoch 520:     48 / 49 loss=2.515, nll_loss=0.374, ppl=1.3, wps=23312.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.409, loss_scale=32, train_wall=237, gb_free=8.8, wall=70137
2022-03-07 08:31:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:31:39 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 13.356 | nll_loss 12.633 | ppl 6353.51 | wps 39896.5 | wpb 510.9 | bsz 1 | num_updates 25301 | best_loss 9.157
2022-03-07 08:31:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25301 updates
2022-03-07 08:31:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:31:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:31:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 520 @ 25301 updates, score 13.356) (writing took 2.3810735982842743 seconds)
2022-03-07 08:31:41 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-07 08:31:41 | INFO | train | epoch 520 | loss 2.514 | nll_loss 0.374 | ppl 1.3 | wps 23455 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25301 | lr 0.000198807 | gnorm 0.409 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 70146
2022-03-07 08:31:41 | INFO | fairseq.trainer | begin training epoch 521
2022-03-07 08:31:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:33:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:33:54 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 13.37 | nll_loss 12.645 | ppl 6404.35 | wps 41855.5 | wpb 510.9 | bsz 1 | num_updates 25350 | best_loss 9.157
2022-03-07 08:33:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25350 updates
2022-03-07 08:33:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:33:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:33:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 521 @ 25350 updates, score 13.37) (writing took 2.424157792236656 seconds)
2022-03-07 08:33:56 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-07 08:33:56 | INFO | train | epoch 521 | loss 2.514 | nll_loss 0.373 | ppl 1.3 | wps 23518.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25350 | lr 0.000198615 | gnorm 0.404 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 70281
2022-03-07 08:33:56 | INFO | fairseq.trainer | begin training epoch 522
2022-03-07 08:33:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:34:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:36:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:36:09 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 13.418 | nll_loss 12.698 | ppl 6642.74 | wps 41517.1 | wpb 510.9 | bsz 1 | num_updates 25398 | best_loss 9.157
2022-03-07 08:36:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25398 updates
2022-03-07 08:36:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:36:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:36:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 522 @ 25398 updates, score 13.418) (writing took 2.311705376021564 seconds)
2022-03-07 08:36:11 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-07 08:36:11 | INFO | train | epoch 522 | loss 2.514 | nll_loss 0.374 | ppl 1.3 | wps 23056.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25398 | lr 0.000198427 | gnorm 0.411 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 70416
2022-03-07 08:36:11 | INFO | fairseq.trainer | begin training epoch 523
2022-03-07 08:36:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:36:17 | INFO | train_inner | epoch 523:      2 / 49 loss=2.514, nll_loss=0.373, ppl=1.3, wps=22670.5, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=25400, lr=0.000198419, gnorm=0.409, loss_scale=32, train_wall=236, gb_free=8.8, wall=70421
2022-03-07 08:38:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:38:24 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 13.317 | nll_loss 12.59 | ppl 6163.38 | wps 41926.2 | wpb 510.9 | bsz 1 | num_updates 25447 | best_loss 9.157
2022-03-07 08:38:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25447 updates
2022-03-07 08:38:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:38:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:38:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 523 @ 25447 updates, score 13.317) (writing took 2.61832661787048 seconds)
2022-03-07 08:38:27 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-07 08:38:27 | INFO | train | epoch 523 | loss 2.514 | nll_loss 0.373 | ppl 1.3 | wps 23496.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25447 | lr 0.000198236 | gnorm 0.414 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 70551
2022-03-07 08:38:27 | INFO | fairseq.trainer | begin training epoch 524
2022-03-07 08:38:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:40:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:40:39 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 13.272 | nll_loss 12.539 | ppl 5952.11 | wps 42106.9 | wpb 510.9 | bsz 1 | num_updates 25496 | best_loss 9.157
2022-03-07 08:40:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25496 updates
2022-03-07 08:40:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:40:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:40:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 524 @ 25496 updates, score 13.272) (writing took 2.3360064798034728 seconds)
2022-03-07 08:40:41 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-07 08:40:41 | INFO | train | epoch 524 | loss 2.513 | nll_loss 0.373 | ppl 1.29 | wps 23637.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25496 | lr 0.000198045 | gnorm 0.408 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 70686
2022-03-07 08:40:41 | INFO | fairseq.trainer | begin training epoch 525
2022-03-07 08:40:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:40:52 | INFO | train_inner | epoch 525:      4 / 49 loss=2.514, nll_loss=0.373, ppl=1.3, wps=23587.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=25500, lr=0.00019803, gnorm=0.411, loss_scale=64, train_wall=234, gb_free=8.8, wall=70696
2022-03-07 08:40:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:42:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:42:53 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 13.395 | nll_loss 12.675 | ppl 6537.54 | wps 42005.5 | wpb 510.9 | bsz 1 | num_updates 25544 | best_loss 9.157
2022-03-07 08:42:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25544 updates
2022-03-07 08:42:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:42:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:42:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 525 @ 25544 updates, score 13.395) (writing took 2.412448779679835 seconds)
2022-03-07 08:42:56 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-07 08:42:56 | INFO | train | epoch 525 | loss 2.513 | nll_loss 0.373 | ppl 1.3 | wps 23101.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25544 | lr 0.000197859 | gnorm 0.405 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 70821
2022-03-07 08:42:56 | INFO | fairseq.trainer | begin training epoch 526
2022-03-07 08:42:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:45:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:45:09 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 13.414 | nll_loss 12.694 | ppl 6624.73 | wps 41255.1 | wpb 510.9 | bsz 1 | num_updates 25593 | best_loss 9.157
2022-03-07 08:45:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25593 updates
2022-03-07 08:45:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:45:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:45:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 526 @ 25593 updates, score 13.414) (writing took 2.4292191858403385 seconds)
2022-03-07 08:45:11 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-07 08:45:11 | INFO | train | epoch 526 | loss 2.512 | nll_loss 0.372 | ppl 1.29 | wps 23496.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25593 | lr 0.000197669 | gnorm 0.412 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 70956
2022-03-07 08:45:11 | INFO | fairseq.trainer | begin training epoch 527
2022-03-07 08:45:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:45:29 | INFO | train_inner | epoch 527:      7 / 49 loss=2.512, nll_loss=0.372, ppl=1.29, wps=23354.4, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.408, loss_scale=32, train_wall=237, gb_free=8.8, wall=70974
2022-03-07 08:46:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:47:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:47:23 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 13.413 | nll_loss 12.695 | ppl 6629.55 | wps 41805.1 | wpb 510.9 | bsz 1 | num_updates 25641 | best_loss 9.157
2022-03-07 08:47:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25641 updates
2022-03-07 08:47:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:47:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:47:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 527 @ 25641 updates, score 13.413) (writing took 2.3694115723483264 seconds)
2022-03-07 08:47:26 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-07 08:47:26 | INFO | train | epoch 527 | loss 2.512 | nll_loss 0.372 | ppl 1.29 | wps 23095.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25641 | lr 0.000197484 | gnorm 0.415 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 71091
2022-03-07 08:47:26 | INFO | fairseq.trainer | begin training epoch 528
2022-03-07 08:47:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:49:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:49:38 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 13.363 | nll_loss 12.637 | ppl 6368.17 | wps 41742.3 | wpb 510.9 | bsz 1 | num_updates 25690 | best_loss 9.157
2022-03-07 08:49:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25690 updates
2022-03-07 08:49:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:49:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:49:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 528 @ 25690 updates, score 13.363) (writing took 2.4469907213933766 seconds)
2022-03-07 08:49:40 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-07 08:49:40 | INFO | train | epoch 528 | loss 2.511 | nll_loss 0.371 | ppl 1.29 | wps 23669.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25690 | lr 0.000197296 | gnorm 0.403 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 71225
2022-03-07 08:49:40 | INFO | fairseq.trainer | begin training epoch 529
2022-03-07 08:49:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:50:06 | INFO | train_inner | epoch 529:     10 / 49 loss=2.512, nll_loss=0.372, ppl=1.29, wps=23422.8, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.409, loss_scale=32, train_wall=236, gb_free=8.8, wall=71251
2022-03-07 08:51:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:51:53 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 13.337 | nll_loss 12.611 | ppl 6257.46 | wps 41497.8 | wpb 510.9 | bsz 1 | num_updates 25739 | best_loss 9.157
2022-03-07 08:51:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25739 updates
2022-03-07 08:51:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:51:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:51:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 529 @ 25739 updates, score 13.337) (writing took 2.4464993593282998 seconds)
2022-03-07 08:51:55 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-07 08:51:55 | INFO | train | epoch 529 | loss 2.511 | nll_loss 0.371 | ppl 1.29 | wps 23554.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25739 | lr 0.000197108 | gnorm 0.411 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 71360
2022-03-07 08:51:55 | INFO | fairseq.trainer | begin training epoch 530
2022-03-07 08:51:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:52:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:54:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:54:06 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 13.374 | nll_loss 12.645 | ppl 6404.53 | wps 43942 | wpb 510.9 | bsz 1 | num_updates 25787 | best_loss 9.157
2022-03-07 08:54:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25787 updates
2022-03-07 08:54:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:54:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:54:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 530 @ 25787 updates, score 13.374) (writing took 2.333976319991052 seconds)
2022-03-07 08:54:08 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-07 08:54:08 | INFO | train | epoch 530 | loss 2.511 | nll_loss 0.371 | ppl 1.29 | wps 23413.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25787 | lr 0.000196924 | gnorm 0.408 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 71493
2022-03-07 08:54:08 | INFO | fairseq.trainer | begin training epoch 531
2022-03-07 08:54:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:54:41 | INFO | train_inner | epoch 531:     13 / 49 loss=2.511, nll_loss=0.371, ppl=1.29, wps=23586.1, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.41, loss_scale=32, train_wall=235, gb_free=8.8, wall=71526
2022-03-07 08:56:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:56:18 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 13.37 | nll_loss 12.645 | ppl 6406.27 | wps 42157.5 | wpb 510.9 | bsz 1 | num_updates 25836 | best_loss 9.157
2022-03-07 08:56:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25836 updates
2022-03-07 08:56:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:56:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:56:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 531 @ 25836 updates, score 13.37) (writing took 2.3526311740279198 seconds)
2022-03-07 08:56:21 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-07 08:56:21 | INFO | train | epoch 531 | loss 2.51 | nll_loss 0.37 | ppl 1.29 | wps 23932 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25836 | lr 0.000196738 | gnorm 0.407 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 71625
2022-03-07 08:56:21 | INFO | fairseq.trainer | begin training epoch 532
2022-03-07 08:56:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:58:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:58:31 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 13.383 | nll_loss 12.654 | ppl 6447.34 | wps 43984.3 | wpb 510.9 | bsz 1 | num_updates 25885 | best_loss 9.157
2022-03-07 08:58:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25885 updates
2022-03-07 08:58:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:58:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:58:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 532 @ 25885 updates, score 13.383) (writing took 2.3107424839399755 seconds)
2022-03-07 08:58:33 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-07 08:58:33 | INFO | train | epoch 532 | loss 2.51 | nll_loss 0.371 | ppl 1.29 | wps 23966.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25885 | lr 0.000196551 | gnorm 0.407 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 71758
2022-03-07 08:58:33 | INFO | fairseq.trainer | begin training epoch 533
2022-03-07 08:58:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:58:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:59:15 | INFO | train_inner | epoch 533:     16 / 49 loss=2.51, nll_loss=0.37, ppl=1.29, wps=23736.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.405, loss_scale=32, train_wall=233, gb_free=8.8, wall=71800
2022-03-07 09:00:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:00:44 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 13.371 | nll_loss 12.643 | ppl 6397.02 | wps 41598.5 | wpb 510.9 | bsz 1 | num_updates 25933 | best_loss 9.157
2022-03-07 09:00:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25933 updates
2022-03-07 09:00:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:00:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 533 @ 25933 updates, score 13.371) (writing took 2.382516672834754 seconds)
2022-03-07 09:00:47 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-07 09:00:47 | INFO | train | epoch 533 | loss 2.51 | nll_loss 0.37 | ppl 1.29 | wps 23343.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25933 | lr 0.000196369 | gnorm 0.408 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 71891
2022-03-07 09:00:47 | INFO | fairseq.trainer | begin training epoch 534
2022-03-07 09:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:02:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:02:58 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 13.485 | nll_loss 12.776 | ppl 7011.75 | wps 41420.7 | wpb 510.9 | bsz 1 | num_updates 25982 | best_loss 9.157
2022-03-07 09:02:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25982 updates
2022-03-07 09:02:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:03:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:03:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 534 @ 25982 updates, score 13.485) (writing took 2.4683508779853582 seconds)
2022-03-07 09:03:01 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-07 09:03:01 | INFO | train | epoch 534 | loss 2.509 | nll_loss 0.37 | ppl 1.29 | wps 23697.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25982 | lr 0.000196184 | gnorm 0.413 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 72026
2022-03-07 09:03:01 | INFO | fairseq.trainer | begin training epoch 535
2022-03-07 09:03:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:03:48 | INFO | train_inner | epoch 535:     18 / 49 loss=2.51, nll_loss=0.37, ppl=1.29, wps=23719.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=26000, lr=0.000196116, gnorm=0.413, loss_scale=32, train_wall=233, gb_free=8.8, wall=72073
2022-03-07 09:04:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:05:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:05:14 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 13.333 | nll_loss 12.61 | ppl 6253.49 | wps 40980.4 | wpb 510.9 | bsz 1 | num_updates 26030 | best_loss 9.157
2022-03-07 09:05:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26030 updates
2022-03-07 09:05:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:05:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:05:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 535 @ 26030 updates, score 13.333) (writing took 2.4423170047812164 seconds)
2022-03-07 09:05:17 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-07 09:05:17 | INFO | train | epoch 535 | loss 2.51 | nll_loss 0.37 | ppl 1.29 | wps 22894 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 26030 | lr 0.000196003 | gnorm 0.411 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 72161
2022-03-07 09:05:17 | INFO | fairseq.trainer | begin training epoch 536
2022-03-07 09:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:07:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:07:30 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 13.361 | nll_loss 12.636 | ppl 6365.43 | wps 41862.5 | wpb 510.9 | bsz 1 | num_updates 26079 | best_loss 9.157
2022-03-07 09:07:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26079 updates
2022-03-07 09:07:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:07:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:07:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 536 @ 26079 updates, score 13.361) (writing took 2.6378267887048423 seconds)
2022-03-07 09:07:33 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-07 09:07:33 | INFO | train | epoch 536 | loss 2.509 | nll_loss 0.369 | ppl 1.29 | wps 23357.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26079 | lr 0.000195819 | gnorm 0.404 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 72298
2022-03-07 09:07:33 | INFO | fairseq.trainer | begin training epoch 537
2022-03-07 09:07:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:08:28 | INFO | train_inner | epoch 537:     21 / 49 loss=2.508, nll_loss=0.369, ppl=1.29, wps=23163.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.404, loss_scale=32, train_wall=239, gb_free=8.8, wall=72353
2022-03-07 09:09:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:09:46 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 13.327 | nll_loss 12.597 | ppl 6194.16 | wps 41464.8 | wpb 510.9 | bsz 1 | num_updates 26128 | best_loss 9.157
2022-03-07 09:09:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26128 updates
2022-03-07 09:09:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:09:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:09:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 537 @ 26128 updates, score 13.327) (writing took 2.3691658251918852 seconds)
2022-03-07 09:09:49 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-07 09:09:49 | INFO | train | epoch 537 | loss 2.508 | nll_loss 0.369 | ppl 1.29 | wps 23408.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26128 | lr 0.000195635 | gnorm 0.403 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 72433
2022-03-07 09:09:49 | INFO | fairseq.trainer | begin training epoch 538
2022-03-07 09:09:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:10:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:11:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:12:02 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 13.324 | nll_loss 12.589 | ppl 6160.02 | wps 41334.6 | wpb 510.9 | bsz 1 | num_updates 26176 | best_loss 9.157
2022-03-07 09:12:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26176 updates
2022-03-07 09:12:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:12:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:12:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 538 @ 26176 updates, score 13.324) (writing took 2.440501324366778 seconds)
2022-03-07 09:12:04 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-07 09:12:04 | INFO | train | epoch 538 | loss 2.508 | nll_loss 0.369 | ppl 1.29 | wps 22900.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 26176 | lr 0.000195456 | gnorm 0.407 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 72569
2022-03-07 09:12:04 | INFO | fairseq.trainer | begin training epoch 539
2022-03-07 09:12:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:13:08 | INFO | train_inner | epoch 539:     24 / 49 loss=2.508, nll_loss=0.369, ppl=1.29, wps=23207.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.408, loss_scale=32, train_wall=239, gb_free=8.8, wall=72633
2022-03-07 09:14:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:14:18 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 13.358 | nll_loss 12.634 | ppl 6357.32 | wps 41778.3 | wpb 510.9 | bsz 1 | num_updates 26225 | best_loss 9.157
2022-03-07 09:14:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26225 updates
2022-03-07 09:14:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:14:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:14:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 539 @ 26225 updates, score 13.358) (writing took 2.5068674329668283 seconds)
2022-03-07 09:14:20 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-07 09:14:20 | INFO | train | epoch 539 | loss 2.508 | nll_loss 0.368 | ppl 1.29 | wps 23396 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26225 | lr 0.000195273 | gnorm 0.41 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 72705
2022-03-07 09:14:20 | INFO | fairseq.trainer | begin training epoch 540
2022-03-07 09:14:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:16:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:16:34 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 13.505 | nll_loss 12.802 | ppl 7141.28 | wps 41203.9 | wpb 510.9 | bsz 1 | num_updates 26274 | best_loss 9.157
2022-03-07 09:16:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26274 updates
2022-03-07 09:16:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:16:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:16:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 540 @ 26274 updates, score 13.505) (writing took 2.384036750998348 seconds)
2022-03-07 09:16:36 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-07 09:16:36 | INFO | train | epoch 540 | loss 2.508 | nll_loss 0.369 | ppl 1.29 | wps 23387.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26274 | lr 0.000195091 | gnorm 0.408 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 72841
2022-03-07 09:16:36 | INFO | fairseq.trainer | begin training epoch 541
2022-03-07 09:16:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:16:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:17:47 | INFO | train_inner | epoch 541:     27 / 49 loss=2.507, nll_loss=0.369, ppl=1.29, wps=23199.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.407, loss_scale=32, train_wall=239, gb_free=8.8, wall=72912
2022-03-07 09:18:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:18:50 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 13.463 | nll_loss 12.75 | ppl 6886.35 | wps 41241.1 | wpb 510.9 | bsz 1 | num_updates 26322 | best_loss 9.157
2022-03-07 09:18:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26322 updates
2022-03-07 09:18:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:18:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:18:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 541 @ 26322 updates, score 13.463) (writing took 2.469949538819492 seconds)
2022-03-07 09:18:52 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-07 09:18:52 | INFO | train | epoch 541 | loss 2.507 | nll_loss 0.368 | ppl 1.29 | wps 22915 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 26322 | lr 0.000194913 | gnorm 0.41 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 72977
2022-03-07 09:18:52 | INFO | fairseq.trainer | begin training epoch 542
2022-03-07 09:18:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:21:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:21:05 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 13.356 | nll_loss 12.634 | ppl 6356.13 | wps 41663.2 | wpb 510.9 | bsz 1 | num_updates 26371 | best_loss 9.157
2022-03-07 09:21:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26371 updates
2022-03-07 09:21:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:21:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:21:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 542 @ 26371 updates, score 13.356) (writing took 2.4036875562742352 seconds)
2022-03-07 09:21:08 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-07 09:21:08 | INFO | train | epoch 542 | loss 2.506 | nll_loss 0.367 | ppl 1.29 | wps 23438.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26371 | lr 0.000194732 | gnorm 0.405 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 73112
2022-03-07 09:21:08 | INFO | fairseq.trainer | begin training epoch 543
2022-03-07 09:21:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:22:24 | INFO | train_inner | epoch 543:     29 / 49 loss=2.507, nll_loss=0.368, ppl=1.29, wps=23431, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.406, loss_scale=32, train_wall=236, gb_free=8.8, wall=73189
2022-03-07 09:22:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:23:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:23:21 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 13.324 | nll_loss 12.596 | ppl 6191.69 | wps 39634.8 | wpb 510.9 | bsz 1 | num_updates 26419 | best_loss 9.157
2022-03-07 09:23:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26419 updates
2022-03-07 09:23:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:23:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:23:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 543 @ 26419 updates, score 13.324) (writing took 2.5656313081271946 seconds)
2022-03-07 09:23:24 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-07 09:23:24 | INFO | train | epoch 543 | loss 2.508 | nll_loss 0.369 | ppl 1.29 | wps 22858.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 26419 | lr 0.000194555 | gnorm 0.407 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 73249
2022-03-07 09:23:24 | INFO | fairseq.trainer | begin training epoch 544
2022-03-07 09:23:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:25:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:25:37 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 13.396 | nll_loss 12.679 | ppl 6556 | wps 41468.8 | wpb 510.9 | bsz 1 | num_updates 26468 | best_loss 9.157
2022-03-07 09:25:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26468 updates
2022-03-07 09:25:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:25:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:25:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 544 @ 26468 updates, score 13.396) (writing took 2.462850413285196 seconds)
2022-03-07 09:25:39 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-07 09:25:39 | INFO | train | epoch 544 | loss 2.507 | nll_loss 0.368 | ppl 1.29 | wps 23439.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26468 | lr 0.000194375 | gnorm 0.415 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 73384
2022-03-07 09:25:39 | INFO | fairseq.trainer | begin training epoch 545
2022-03-07 09:25:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:27:03 | INFO | train_inner | epoch 545:     32 / 49 loss=2.507, nll_loss=0.368, ppl=1.29, wps=23284.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.411, loss_scale=32, train_wall=237, gb_free=8.8, wall=73468
2022-03-07 09:27:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:27:51 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 13.361 | nll_loss 12.636 | ppl 6365.77 | wps 42806.1 | wpb 510.9 | bsz 1 | num_updates 26517 | best_loss 9.157
2022-03-07 09:27:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26517 updates
2022-03-07 09:27:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:27:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:27:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 545 @ 26517 updates, score 13.361) (writing took 2.3946075472049415 seconds)
2022-03-07 09:27:53 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-07 09:27:53 | INFO | train | epoch 545 | loss 2.506 | nll_loss 0.367 | ppl 1.29 | wps 23755.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26517 | lr 0.000194195 | gnorm 0.404 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 73518
2022-03-07 09:27:53 | INFO | fairseq.trainer | begin training epoch 546
2022-03-07 09:27:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:28:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:29:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:30:04 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 13.317 | nll_loss 12.592 | ppl 6172.05 | wps 43239.9 | wpb 510.9 | bsz 1 | num_updates 26565 | best_loss 9.157
2022-03-07 09:30:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26565 updates
2022-03-07 09:30:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:30:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:30:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 546 @ 26565 updates, score 13.317) (writing took 2.3358081337064505 seconds)
2022-03-07 09:30:06 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-07 09:30:06 | INFO | train | epoch 546 | loss 2.505 | nll_loss 0.367 | ppl 1.29 | wps 23379.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 26565 | lr 0.000194019 | gnorm 0.403 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 73651
2022-03-07 09:30:06 | INFO | fairseq.trainer | begin training epoch 547
2022-03-07 09:30:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:31:37 | INFO | train_inner | epoch 547:     35 / 49 loss=2.506, nll_loss=0.367, ppl=1.29, wps=23671, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.405, loss_scale=32, train_wall=234, gb_free=8.8, wall=73742
2022-03-07 09:32:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:32:17 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 13.396 | nll_loss 12.675 | ppl 6541.79 | wps 43079.1 | wpb 510.9 | bsz 1 | num_updates 26614 | best_loss 9.157
2022-03-07 09:32:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26614 updates
2022-03-07 09:32:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:32:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:32:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 547 @ 26614 updates, score 13.396) (writing took 2.3220362020656466 seconds)
2022-03-07 09:32:19 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-07 09:32:19 | INFO | train | epoch 547 | loss 2.506 | nll_loss 0.367 | ppl 1.29 | wps 23884 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26614 | lr 0.000193841 | gnorm 0.407 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 73784
2022-03-07 09:32:19 | INFO | fairseq.trainer | begin training epoch 548
2022-03-07 09:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:34:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:34:30 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 13.382 | nll_loss 12.663 | ppl 6487.62 | wps 42575.6 | wpb 510.9 | bsz 1 | num_updates 26663 | best_loss 9.157
2022-03-07 09:34:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26663 updates
2022-03-07 09:34:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:34:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:34:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 548 @ 26663 updates, score 13.382) (writing took 2.427233678754419 seconds)
2022-03-07 09:34:33 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-07 09:34:33 | INFO | train | epoch 548 | loss 2.504 | nll_loss 0.366 | ppl 1.29 | wps 23839.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26663 | lr 0.000193662 | gnorm 0.406 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 73917
2022-03-07 09:34:33 | INFO | fairseq.trainer | begin training epoch 549
2022-03-07 09:34:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:34:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:36:11 | INFO | train_inner | epoch 549:     38 / 49 loss=2.505, nll_loss=0.366, ppl=1.29, wps=23675.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.406, loss_scale=32, train_wall=234, gb_free=8.8, wall=74016
2022-03-07 09:36:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:36:43 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 13.339 | nll_loss 12.616 | ppl 6277.28 | wps 42706.3 | wpb 510.9 | bsz 1 | num_updates 26711 | best_loss 9.157
2022-03-07 09:36:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26711 updates
2022-03-07 09:36:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:36:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:36:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 549 @ 26711 updates, score 13.339) (writing took 2.460996354930103 seconds)
2022-03-07 09:36:46 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-07 09:36:46 | INFO | train | epoch 549 | loss 2.504 | nll_loss 0.366 | ppl 1.29 | wps 23386.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 26711 | lr 0.000193488 | gnorm 0.406 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 74051
2022-03-07 09:36:46 | INFO | fairseq.trainer | begin training epoch 550
2022-03-07 09:36:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:38:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:38:56 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 13.392 | nll_loss 12.671 | ppl 6521.98 | wps 43210.3 | wpb 510.9 | bsz 1 | num_updates 26760 | best_loss 9.157
2022-03-07 09:38:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26760 updates
2022-03-07 09:38:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:38:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:38:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 550 @ 26760 updates, score 13.392) (writing took 2.271679164841771 seconds)
2022-03-07 09:38:59 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-07 09:38:59 | INFO | train | epoch 550 | loss 2.504 | nll_loss 0.366 | ppl 1.29 | wps 23892.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26760 | lr 0.000193311 | gnorm 0.402 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 74184
2022-03-07 09:38:59 | INFO | fairseq.trainer | begin training epoch 551
2022-03-07 09:38:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:40:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:40:46 | INFO | train_inner | epoch 551:     41 / 49 loss=2.504, nll_loss=0.366, ppl=1.29, wps=23579.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.403, loss_scale=32, train_wall=235, gb_free=8.8, wall=74291
2022-03-07 09:41:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:41:11 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 13.384 | nll_loss 12.666 | ppl 6499.12 | wps 41056.8 | wpb 510.9 | bsz 1 | num_updates 26808 | best_loss 9.157
2022-03-07 09:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26808 updates
2022-03-07 09:41:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:41:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:41:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 551 @ 26808 updates, score 13.384) (writing took 2.3224832778796554 seconds)
2022-03-07 09:41:14 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-07 09:41:14 | INFO | train | epoch 551 | loss 2.504 | nll_loss 0.366 | ppl 1.29 | wps 23087 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 26808 | lr 0.000193138 | gnorm 0.403 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 74318
2022-03-07 09:41:14 | INFO | fairseq.trainer | begin training epoch 552
2022-03-07 09:41:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:43:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:43:27 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 13.409 | nll_loss 12.694 | ppl 6626.69 | wps 39642.7 | wpb 510.9 | bsz 1 | num_updates 26857 | best_loss 9.157
2022-03-07 09:43:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26857 updates
2022-03-07 09:43:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:43:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:43:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 552 @ 26857 updates, score 13.409) (writing took 2.561128207948059 seconds)
2022-03-07 09:43:30 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-07 09:43:30 | INFO | train | epoch 552 | loss 2.504 | nll_loss 0.366 | ppl 1.29 | wps 23352.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26857 | lr 0.000192962 | gnorm 0.406 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 74454
2022-03-07 09:43:30 | INFO | fairseq.trainer | begin training epoch 553
2022-03-07 09:43:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:45:23 | INFO | train_inner | epoch 553:     43 / 49 loss=2.504, nll_loss=0.366, ppl=1.29, wps=23397.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.404, loss_scale=32, train_wall=236, gb_free=8.8, wall=74568
2022-03-07 09:45:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:45:43 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 13.288 | nll_loss 12.557 | ppl 6026.69 | wps 41173 | wpb 510.9 | bsz 1 | num_updates 26906 | best_loss 9.157
2022-03-07 09:45:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26906 updates
2022-03-07 09:45:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:45:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:45:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 553 @ 26906 updates, score 13.288) (writing took 2.3852357869036496 seconds)
2022-03-07 09:45:46 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-07 09:45:46 | INFO | train | epoch 553 | loss 2.503 | nll_loss 0.365 | ppl 1.29 | wps 23367.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26906 | lr 0.000192786 | gnorm 0.403 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 74590
2022-03-07 09:45:46 | INFO | fairseq.trainer | begin training epoch 554
2022-03-07 09:45:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:46:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:47:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:47:59 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 13.356 | nll_loss 12.627 | ppl 6323.99 | wps 40928 | wpb 510.9 | bsz 1 | num_updates 26954 | best_loss 9.157
2022-03-07 09:47:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26954 updates
2022-03-07 09:47:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:48:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:48:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 554 @ 26954 updates, score 13.356) (writing took 2.405633986927569 seconds)
2022-03-07 09:48:02 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-07 09:48:02 | INFO | train | epoch 554 | loss 2.503 | nll_loss 0.365 | ppl 1.29 | wps 22894.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 26954 | lr 0.000192614 | gnorm 0.401 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 74726
2022-03-07 09:48:02 | INFO | fairseq.trainer | begin training epoch 555
2022-03-07 09:48:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:50:03 | INFO | train_inner | epoch 555:     46 / 49 loss=2.503, nll_loss=0.365, ppl=1.29, wps=23209.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.401, loss_scale=32, train_wall=238, gb_free=8.8, wall=74848
2022-03-07 09:50:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:50:15 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 13.452 | nll_loss 12.737 | ppl 6828.35 | wps 41198.7 | wpb 510.9 | bsz 1 | num_updates 27003 | best_loss 9.157
2022-03-07 09:50:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27003 updates
2022-03-07 09:50:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:50:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:50:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 555 @ 27003 updates, score 13.452) (writing took 2.311016164254397 seconds)
2022-03-07 09:50:17 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-07 09:50:17 | INFO | train | epoch 555 | loss 2.503 | nll_loss 0.365 | ppl 1.29 | wps 23446.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27003 | lr 0.000192439 | gnorm 0.4 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 74862
2022-03-07 09:50:17 | INFO | fairseq.trainer | begin training epoch 556
2022-03-07 09:50:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:52:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:52:30 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 13.385 | nll_loss 12.667 | ppl 6504.89 | wps 41724.8 | wpb 510.9 | bsz 1 | num_updates 27052 | best_loss 9.157
2022-03-07 09:52:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27052 updates
2022-03-07 09:52:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:52:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:52:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 556 @ 27052 updates, score 13.385) (writing took 2.3045752751640975 seconds)
2022-03-07 09:52:33 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-07 09:52:33 | INFO | train | epoch 556 | loss 2.502 | nll_loss 0.365 | ppl 1.29 | wps 23461.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27052 | lr 0.000192265 | gnorm 0.405 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 74997
2022-03-07 09:52:33 | INFO | fairseq.trainer | begin training epoch 557
2022-03-07 09:52:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:52:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:54:41 | INFO | train_inner | epoch 557:     49 / 49 loss=2.502, nll_loss=0.364, ppl=1.29, wps=23226.5, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=27100, lr=0.000192095, gnorm=0.404, loss_scale=32, train_wall=237, gb_free=8.8, wall=75126
2022-03-07 09:54:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:54:46 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 13.452 | nll_loss 12.738 | ppl 6833.57 | wps 41198.4 | wpb 510.9 | bsz 1 | num_updates 27100 | best_loss 9.157
2022-03-07 09:54:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27100 updates
2022-03-07 09:54:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:54:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:54:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 557 @ 27100 updates, score 13.452) (writing took 2.4937360952608287 seconds)
2022-03-07 09:54:49 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-07 09:54:49 | INFO | train | epoch 557 | loss 2.501 | nll_loss 0.364 | ppl 1.29 | wps 22878.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 27100 | lr 0.000192095 | gnorm 0.4 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 75133
2022-03-07 09:54:49 | INFO | fairseq.trainer | begin training epoch 558
2022-03-07 09:54:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:56:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:57:02 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 13.33 | nll_loss 12.599 | ppl 6204.77 | wps 41688 | wpb 510.9 | bsz 1 | num_updates 27149 | best_loss 9.157
2022-03-07 09:57:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27149 updates
2022-03-07 09:57:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:57:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:57:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 558 @ 27149 updates, score 13.33) (writing took 2.4353704629465938 seconds)
2022-03-07 09:57:04 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-07 09:57:04 | INFO | train | epoch 558 | loss 2.502 | nll_loss 0.365 | ppl 1.29 | wps 23415.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27149 | lr 0.000191921 | gnorm 0.411 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 75269
2022-03-07 09:57:04 | INFO | fairseq.trainer | begin training epoch 559
2022-03-07 09:57:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:58:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:59:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:59:18 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 13.343 | nll_loss 12.619 | ppl 6291.93 | wps 41402.5 | wpb 510.9 | bsz 1 | num_updates 27197 | best_loss 9.157
2022-03-07 09:59:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27197 updates
2022-03-07 09:59:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:59:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 559 @ 27197 updates, score 13.343) (writing took 2.408592902123928 seconds)
2022-03-07 09:59:20 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-07 09:59:20 | INFO | train | epoch 559 | loss 2.501 | nll_loss 0.363 | ppl 1.29 | wps 22943.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 27197 | lr 0.000191752 | gnorm 0.403 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 75405
2022-03-07 09:59:20 | INFO | fairseq.trainer | begin training epoch 560
2022-03-07 09:59:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:59:28 | INFO | train_inner | epoch 560:      3 / 49 loss=2.501, nll_loss=0.364, ppl=1.29, wps=22583.9, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=27200, lr=0.000191741, gnorm=0.407, loss_scale=32, train_wall=238, gb_free=8.8, wall=75413
2022-03-07 10:01:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:01:33 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 13.416 | nll_loss 12.7 | ppl 6653.78 | wps 40342 | wpb 510.9 | bsz 1 | num_updates 27246 | best_loss 9.157
2022-03-07 10:01:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27246 updates
2022-03-07 10:01:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:01:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:01:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 560 @ 27246 updates, score 13.416) (writing took 2.377549601253122 seconds)
2022-03-07 10:01:36 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-07 10:01:36 | INFO | train | epoch 560 | loss 2.501 | nll_loss 0.363 | ppl 1.29 | wps 23417.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27246 | lr 0.000191579 | gnorm 0.401 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 75541
2022-03-07 10:01:36 | INFO | fairseq.trainer | begin training epoch 561
2022-03-07 10:01:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:03:48 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 13.374 | nll_loss 12.649 | ppl 6422.1 | wps 41558.1 | wpb 510.9 | bsz 1 | num_updates 27295 | best_loss 9.157
2022-03-07 10:03:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27295 updates
2022-03-07 10:03:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:03:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:03:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 561 @ 27295 updates, score 13.374) (writing took 2.379186687991023 seconds)
2022-03-07 10:03:51 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-07 10:03:51 | INFO | train | epoch 561 | loss 2.501 | nll_loss 0.364 | ppl 1.29 | wps 23553.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27295 | lr 0.000191407 | gnorm 0.411 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 75675
2022-03-07 10:03:51 | INFO | fairseq.trainer | begin training epoch 562
2022-03-07 10:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:04:04 | INFO | train_inner | epoch 562:      5 / 49 loss=2.501, nll_loss=0.364, ppl=1.29, wps=23528.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=27300, lr=0.00019139, gnorm=0.406, loss_scale=32, train_wall=235, gb_free=8.8, wall=75689
2022-03-07 10:04:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:05:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:06:01 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 13.541 | nll_loss 12.837 | ppl 7316.28 | wps 42391.1 | wpb 510.9 | bsz 1 | num_updates 27343 | best_loss 9.157
2022-03-07 10:06:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27343 updates
2022-03-07 10:06:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:06:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:06:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 562 @ 27343 updates, score 13.541) (writing took 2.387951265089214 seconds)
2022-03-07 10:06:04 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-07 10:06:04 | INFO | train | epoch 562 | loss 2.5 | nll_loss 0.363 | ppl 1.29 | wps 23384.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 27343 | lr 0.000191239 | gnorm 0.401 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 75809
2022-03-07 10:06:04 | INFO | fairseq.trainer | begin training epoch 563
2022-03-07 10:06:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:08:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:08:14 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 13.425 | nll_loss 12.714 | ppl 6716.68 | wps 43080.5 | wpb 510.9 | bsz 1 | num_updates 27392 | best_loss 9.157
2022-03-07 10:08:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27392 updates
2022-03-07 10:08:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:08:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:08:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 563 @ 27392 updates, score 13.425) (writing took 2.3032375420443714 seconds)
2022-03-07 10:08:17 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-07 10:08:17 | INFO | train | epoch 563 | loss 2.5 | nll_loss 0.363 | ppl 1.29 | wps 23894.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27392 | lr 0.000191068 | gnorm 0.403 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 75942
2022-03-07 10:08:17 | INFO | fairseq.trainer | begin training epoch 564
2022-03-07 10:08:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:08:38 | INFO | train_inner | epoch 564:      8 / 49 loss=2.5, nll_loss=0.363, ppl=1.29, wps=23695.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.401, loss_scale=32, train_wall=234, gb_free=8.8, wall=75962
2022-03-07 10:10:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:10:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:10:28 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 13.508 | nll_loss 12.802 | ppl 7140.79 | wps 42425.4 | wpb 510.9 | bsz 1 | num_updates 27440 | best_loss 9.157
2022-03-07 10:10:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27440 updates
2022-03-07 10:10:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:10:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:10:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 564 @ 27440 updates, score 13.508) (writing took 2.387047137133777 seconds)
2022-03-07 10:10:30 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-07 10:10:30 | INFO | train | epoch 564 | loss 2.5 | nll_loss 0.363 | ppl 1.29 | wps 23369.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 27440 | lr 0.000190901 | gnorm 0.402 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 76075
2022-03-07 10:10:30 | INFO | fairseq.trainer | begin training epoch 565
2022-03-07 10:10:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:12:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:12:41 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 13.471 | nll_loss 12.758 | ppl 6925.4 | wps 42383.7 | wpb 510.9 | bsz 1 | num_updates 27489 | best_loss 9.157
2022-03-07 10:12:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27489 updates
2022-03-07 10:12:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:12:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:12:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 565 @ 27489 updates, score 13.471) (writing took 2.325498443096876 seconds)
2022-03-07 10:12:43 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-07 10:12:43 | INFO | train | epoch 565 | loss 2.499 | nll_loss 0.362 | ppl 1.29 | wps 23847.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27489 | lr 0.000190731 | gnorm 0.406 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 76208
2022-03-07 10:12:43 | INFO | fairseq.trainer | begin training epoch 566
2022-03-07 10:12:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:13:12 | INFO | train_inner | epoch 566:     11 / 49 loss=2.499, nll_loss=0.362, ppl=1.29, wps=23637, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.403, loss_scale=32, train_wall=234, gb_free=8.8, wall=76237
2022-03-07 10:14:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:14:54 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 13.385 | nll_loss 12.67 | ppl 6517.79 | wps 42748.8 | wpb 510.9 | bsz 1 | num_updates 27538 | best_loss 9.157
2022-03-07 10:14:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27538 updates
2022-03-07 10:14:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:14:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:14:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 566 @ 27538 updates, score 13.385) (writing took 2.451161100063473 seconds)
2022-03-07 10:14:57 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-07 10:14:57 | INFO | train | epoch 566 | loss 2.499 | nll_loss 0.362 | ppl 1.29 | wps 23825.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27538 | lr 0.000190561 | gnorm 0.397 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 76341
2022-03-07 10:14:57 | INFO | fairseq.trainer | begin training epoch 567
2022-03-07 10:14:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:16:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:17:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:17:08 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 13.442 | nll_loss 12.727 | ppl 6780.97 | wps 41364.4 | wpb 510.9 | bsz 1 | num_updates 27586 | best_loss 9.157
2022-03-07 10:17:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27586 updates
2022-03-07 10:17:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:17:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:17:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 567 @ 27586 updates, score 13.442) (writing took 2.406930500175804 seconds)
2022-03-07 10:17:10 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-07 10:17:10 | INFO | train | epoch 567 | loss 2.498 | nll_loss 0.362 | ppl 1.29 | wps 23305.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 27586 | lr 0.000190395 | gnorm 0.399 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 76475
2022-03-07 10:17:10 | INFO | fairseq.trainer | begin training epoch 568
2022-03-07 10:17:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:17:47 | INFO | train_inner | epoch 568:     14 / 49 loss=2.499, nll_loss=0.362, ppl=1.29, wps=23569, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.401, loss_scale=32, train_wall=235, gb_free=8.8, wall=76512
2022-03-07 10:19:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:19:23 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 13.412 | nll_loss 12.69 | ppl 6606.11 | wps 41260.4 | wpb 510.9 | bsz 1 | num_updates 27635 | best_loss 9.157
2022-03-07 10:19:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27635 updates
2022-03-07 10:19:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:19:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:19:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 568 @ 27635 updates, score 13.412) (writing took 2.2902523861266673 seconds)
2022-03-07 10:19:26 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-07 10:19:26 | INFO | train | epoch 568 | loss 2.499 | nll_loss 0.362 | ppl 1.29 | wps 23438.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27635 | lr 0.000190226 | gnorm 0.41 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 76611
2022-03-07 10:19:26 | INFO | fairseq.trainer | begin training epoch 569
2022-03-07 10:19:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:21:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:21:39 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 13.485 | nll_loss 12.773 | ppl 6998.91 | wps 41800.1 | wpb 510.9 | bsz 1 | num_updates 27684 | best_loss 9.157
2022-03-07 10:21:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27684 updates
2022-03-07 10:21:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:21:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:21:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 569 @ 27684 updates, score 13.485) (writing took 2.3113368484191597 seconds)
2022-03-07 10:21:41 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-07 10:21:41 | INFO | train | epoch 569 | loss 2.498 | nll_loss 0.361 | ppl 1.28 | wps 23451.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27684 | lr 0.000190058 | gnorm 0.4 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 76746
2022-03-07 10:21:41 | INFO | fairseq.trainer | begin training epoch 570
2022-03-07 10:21:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:22:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:22:26 | INFO | train_inner | epoch 570:     17 / 49 loss=2.498, nll_loss=0.361, ppl=1.28, wps=23243.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.403, loss_scale=32, train_wall=238, gb_free=8.8, wall=76791
2022-03-07 10:23:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:23:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:23:54 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 13.484 | nll_loss 12.771 | ppl 6991.47 | wps 41692.1 | wpb 510.9 | bsz 1 | num_updates 27731 | best_loss 9.157
2022-03-07 10:23:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27731 updates
2022-03-07 10:23:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:23:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:23:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 570 @ 27731 updates, score 13.484) (writing took 2.460860752966255 seconds)
2022-03-07 10:23:57 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-07 10:23:57 | INFO | train | epoch 570 | loss 2.498 | nll_loss 0.362 | ppl 1.28 | wps 22467.9 | ups 0.35 | wpb 64829.4 | bsz 126.6 | num_updates 27731 | lr 0.000189897 | gnorm 0.404 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 76882
2022-03-07 10:23:57 | INFO | fairseq.trainer | begin training epoch 571
2022-03-07 10:23:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:26:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:26:10 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 13.474 | nll_loss 12.762 | ppl 6945.01 | wps 41462.1 | wpb 510.9 | bsz 1 | num_updates 27780 | best_loss 9.157
2022-03-07 10:26:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27780 updates
2022-03-07 10:26:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:26:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:26:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 571 @ 27780 updates, score 13.474) (writing took 2.5008178427815437 seconds)
2022-03-07 10:26:13 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-07 10:26:13 | INFO | train | epoch 571 | loss 2.497 | nll_loss 0.361 | ppl 1.28 | wps 23393 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27780 | lr 0.000189729 | gnorm 0.397 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 77018
2022-03-07 10:26:13 | INFO | fairseq.trainer | begin training epoch 572
2022-03-07 10:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:27:05 | INFO | train_inner | epoch 572:     20 / 49 loss=2.497, nll_loss=0.361, ppl=1.28, wps=23240.5, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.4, loss_scale=16, train_wall=238, gb_free=8.8, wall=77070
2022-03-07 10:28:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:28:26 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 13.396 | nll_loss 12.681 | ppl 6569.05 | wps 41431.2 | wpb 510.9 | bsz 1 | num_updates 27829 | best_loss 9.157
2022-03-07 10:28:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27829 updates
2022-03-07 10:28:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:28:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:28:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 572 @ 27829 updates, score 13.396) (writing took 2.361572208814323 seconds)
2022-03-07 10:28:28 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-07 10:28:28 | INFO | train | epoch 572 | loss 2.497 | nll_loss 0.36 | ppl 1.28 | wps 23432.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27829 | lr 0.000189562 | gnorm 0.402 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 77153
2022-03-07 10:28:28 | INFO | fairseq.trainer | begin training epoch 573
2022-03-07 10:28:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:30:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:30:42 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 13.519 | nll_loss 12.811 | ppl 7184.43 | wps 41651.1 | wpb 510.9 | bsz 1 | num_updates 27878 | best_loss 9.157
2022-03-07 10:30:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27878 updates
2022-03-07 10:30:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:30:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:30:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 573 @ 27878 updates, score 13.519) (writing took 2.3724488937295973 seconds)
2022-03-07 10:30:44 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-07 10:30:44 | INFO | train | epoch 573 | loss 2.497 | nll_loss 0.361 | ppl 1.28 | wps 23435.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27878 | lr 0.000189395 | gnorm 0.396 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 77289
2022-03-07 10:30:44 | INFO | fairseq.trainer | begin training epoch 574
2022-03-07 10:30:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:31:42 | INFO | train_inner | epoch 574:     22 / 49 loss=2.497, nll_loss=0.361, ppl=1.28, wps=23432, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=27900, lr=0.000189321, gnorm=0.401, loss_scale=32, train_wall=236, gb_free=8.8, wall=77347
2022-03-07 10:32:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:32:57 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 13.493 | nll_loss 12.789 | ppl 7078.17 | wps 41477.9 | wpb 510.9 | bsz 1 | num_updates 27927 | best_loss 9.157
2022-03-07 10:32:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27927 updates
2022-03-07 10:32:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:33:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:33:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 574 @ 27927 updates, score 13.493) (writing took 2.360063704662025 seconds)
2022-03-07 10:33:00 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-07 10:33:00 | INFO | train | epoch 574 | loss 2.496 | nll_loss 0.36 | ppl 1.28 | wps 23409.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27927 | lr 0.000189229 | gnorm 0.406 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 77425
2022-03-07 10:33:00 | INFO | fairseq.trainer | begin training epoch 575
2022-03-07 10:33:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:35:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:35:13 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 13.356 | nll_loss 12.636 | ppl 6366.89 | wps 39806.2 | wpb 510.9 | bsz 1 | num_updates 27976 | best_loss 9.157
2022-03-07 10:35:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27976 updates
2022-03-07 10:35:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:35:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:35:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 575 @ 27976 updates, score 13.356) (writing took 2.4901689868420362 seconds)
2022-03-07 10:35:16 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-07 10:35:16 | INFO | train | epoch 575 | loss 2.496 | nll_loss 0.36 | ppl 1.28 | wps 23358.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27976 | lr 0.000189063 | gnorm 0.397 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 77561
2022-03-07 10:35:16 | INFO | fairseq.trainer | begin training epoch 576
2022-03-07 10:35:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:35:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:36:22 | INFO | train_inner | epoch 576:     25 / 49 loss=2.496, nll_loss=0.36, ppl=1.28, wps=23216.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.399, loss_scale=32, train_wall=238, gb_free=8.8, wall=77626
2022-03-07 10:37:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:37:29 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 13.436 | nll_loss 12.719 | ppl 6744.24 | wps 41345.2 | wpb 510.9 | bsz 1 | num_updates 28024 | best_loss 9.157
2022-03-07 10:37:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28024 updates
2022-03-07 10:37:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:37:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:37:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 576 @ 28024 updates, score 13.436) (writing took 2.474678016733378 seconds)
2022-03-07 10:37:32 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-07 10:37:32 | INFO | train | epoch 576 | loss 2.496 | nll_loss 0.36 | ppl 1.28 | wps 22928.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 28024 | lr 0.000188901 | gnorm 0.402 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 77696
2022-03-07 10:37:32 | INFO | fairseq.trainer | begin training epoch 577
2022-03-07 10:37:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:39:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:39:45 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 13.5 | nll_loss 12.791 | ppl 7088.86 | wps 41591.3 | wpb 510.9 | bsz 1 | num_updates 28073 | best_loss 9.157
2022-03-07 10:39:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28073 updates
2022-03-07 10:39:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:39:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:39:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 577 @ 28073 updates, score 13.5) (writing took 2.554558369796723 seconds)
2022-03-07 10:39:47 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-07 10:39:47 | INFO | train | epoch 577 | loss 2.496 | nll_loss 0.36 | ppl 1.28 | wps 23409.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28073 | lr 0.000188736 | gnorm 0.398 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 77832
2022-03-07 10:39:47 | INFO | fairseq.trainer | begin training epoch 578
2022-03-07 10:39:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:40:58 | INFO | train_inner | epoch 578:     27 / 49 loss=2.496, nll_loss=0.36, ppl=1.28, wps=23447.5, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.397, loss_scale=32, train_wall=236, gb_free=8.8, wall=77903
2022-03-07 10:41:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:41:59 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 13.33 | nll_loss 12.608 | ppl 6242.89 | wps 43494.3 | wpb 510.9 | bsz 1 | num_updates 28122 | best_loss 9.157
2022-03-07 10:41:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28122 updates
2022-03-07 10:41:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:42:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:42:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 578 @ 28122 updates, score 13.33) (writing took 2.335584812797606 seconds)
2022-03-07 10:42:02 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-07 10:42:02 | INFO | train | epoch 578 | loss 2.495 | nll_loss 0.359 | ppl 1.28 | wps 23659.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28122 | lr 0.000188572 | gnorm 0.393 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 77966
2022-03-07 10:42:02 | INFO | fairseq.trainer | begin training epoch 579
2022-03-07 10:42:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:42:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:44:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:44:13 | INFO | valid | epoch 579 | valid on 'valid' subset | loss 13.391 | nll_loss 12.672 | ppl 6526.28 | wps 41612.9 | wpb 510.9 | bsz 1 | num_updates 28170 | best_loss 9.157
2022-03-07 10:44:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 28170 updates
2022-03-07 10:44:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:44:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:44:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 579 @ 28170 updates, score 13.391) (writing took 2.439099847804755 seconds)
2022-03-07 10:44:15 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2022-03-07 10:44:15 | INFO | train | epoch 579 | loss 2.495 | nll_loss 0.359 | ppl 1.28 | wps 23279.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 28170 | lr 0.000188411 | gnorm 0.399 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 78100
2022-03-07 10:44:15 | INFO | fairseq.trainer | begin training epoch 580
2022-03-07 10:44:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:45:35 | INFO | train_inner | epoch 580:     30 / 49 loss=2.495, nll_loss=0.359, ppl=1.28, wps=23494, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=28200, lr=0.000188311, gnorm=0.4, loss_scale=32, train_wall=236, gb_free=8.8, wall=78179
2022-03-07 10:46:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:46:29 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 13.407 | nll_loss 12.687 | ppl 6595.42 | wps 41180 | wpb 510.9 | bsz 1 | num_updates 28219 | best_loss 9.157
2022-03-07 10:46:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 28219 updates
2022-03-07 10:46:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:46:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:46:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 580 @ 28219 updates, score 13.407) (writing took 2.5267136162146926 seconds)
2022-03-07 10:46:31 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2022-03-07 10:46:31 | INFO | train | epoch 580 | loss 2.495 | nll_loss 0.36 | ppl 1.28 | wps 23413 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28219 | lr 0.000188247 | gnorm 0.405 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 78236
2022-03-07 10:46:31 | INFO | fairseq.trainer | begin training epoch 581
2022-03-07 10:46:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:47:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:48:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:48:44 | INFO | valid | epoch 581 | valid on 'valid' subset | loss 13.512 | nll_loss 12.8 | ppl 7131.17 | wps 41517.5 | wpb 510.9 | bsz 1 | num_updates 28267 | best_loss 9.157
2022-03-07 10:48:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 581 @ 28267 updates
2022-03-07 10:48:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:48:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:48:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 581 @ 28267 updates, score 13.512) (writing took 2.46181051293388 seconds)
2022-03-07 10:48:47 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)
2022-03-07 10:48:47 | INFO | train | epoch 581 | loss 2.494 | nll_loss 0.359 | ppl 1.28 | wps 22978.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 28267 | lr 0.000188088 | gnorm 0.399 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 78371
2022-03-07 10:48:47 | INFO | fairseq.trainer | begin training epoch 582
2022-03-07 10:48:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:50:14 | INFO | train_inner | epoch 582:     33 / 49 loss=2.494, nll_loss=0.359, ppl=1.28, wps=23251.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=28300, lr=0.000187978, gnorm=0.401, loss_scale=32, train_wall=238, gb_free=8.8, wall=78458
2022-03-07 10:50:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:51:00 | INFO | valid | epoch 582 | valid on 'valid' subset | loss 13.46 | nll_loss 12.749 | ppl 6883.57 | wps 41227.7 | wpb 510.9 | bsz 1 | num_updates 28316 | best_loss 9.157
2022-03-07 10:51:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 582 @ 28316 updates
2022-03-07 10:51:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:51:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:51:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 582 @ 28316 updates, score 13.46) (writing took 2.4873115001246333 seconds)
2022-03-07 10:51:02 | INFO | fairseq_cli.train | end of epoch 582 (average epoch stats below)
2022-03-07 10:51:02 | INFO | train | epoch 582 | loss 2.494 | nll_loss 0.358 | ppl 1.28 | wps 23457.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28316 | lr 0.000187925 | gnorm 0.399 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 78507
2022-03-07 10:51:02 | INFO | fairseq.trainer | begin training epoch 583
2022-03-07 10:51:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:53:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:53:15 | INFO | valid | epoch 583 | valid on 'valid' subset | loss 13.431 | nll_loss 12.722 | ppl 6753.94 | wps 41559.8 | wpb 510.9 | bsz 1 | num_updates 28365 | best_loss 9.157
2022-03-07 10:53:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 583 @ 28365 updates
2022-03-07 10:53:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:53:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 583 @ 28365 updates, score 13.431) (writing took 2.4286619052290916 seconds)
2022-03-07 10:53:17 | INFO | fairseq_cli.train | end of epoch 583 (average epoch stats below)
2022-03-07 10:53:17 | INFO | train | epoch 583 | loss 2.494 | nll_loss 0.358 | ppl 1.28 | wps 23467.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28365 | lr 0.000187762 | gnorm 0.4 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 78642
2022-03-07 10:53:17 | INFO | fairseq.trainer | begin training epoch 584
2022-03-07 10:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:53:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:54:52 | INFO | train_inner | epoch 584:     36 / 49 loss=2.494, nll_loss=0.358, ppl=1.28, wps=23278.8, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=28400, lr=0.000187647, gnorm=0.399, loss_scale=32, train_wall=238, gb_free=8.8, wall=78737
2022-03-07 10:55:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:55:31 | INFO | valid | epoch 584 | valid on 'valid' subset | loss 13.451 | nll_loss 12.739 | ppl 6835.91 | wps 40243.5 | wpb 510.9 | bsz 1 | num_updates 28413 | best_loss 9.157
2022-03-07 10:55:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 584 @ 28413 updates
2022-03-07 10:55:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:55:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:55:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 584 @ 28413 updates, score 13.451) (writing took 2.3543920922093093 seconds)
2022-03-07 10:55:33 | INFO | fairseq_cli.train | end of epoch 584 (average epoch stats below)
2022-03-07 10:55:33 | INFO | train | epoch 584 | loss 2.494 | nll_loss 0.358 | ppl 1.28 | wps 22979.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 28413 | lr 0.000187604 | gnorm 0.401 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 78778
2022-03-07 10:55:33 | INFO | fairseq.trainer | begin training epoch 585
2022-03-07 10:55:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:57:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:57:46 | INFO | valid | epoch 585 | valid on 'valid' subset | loss 13.438 | nll_loss 12.724 | ppl 6765.57 | wps 41761.1 | wpb 510.9 | bsz 1 | num_updates 28462 | best_loss 9.157
2022-03-07 10:57:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 585 @ 28462 updates
2022-03-07 10:57:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:57:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:57:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 585 @ 28462 updates, score 13.438) (writing took 2.512295475229621 seconds)
2022-03-07 10:57:49 | INFO | fairseq_cli.train | end of epoch 585 (average epoch stats below)
2022-03-07 10:57:49 | INFO | train | epoch 585 | loss 2.492 | nll_loss 0.357 | ppl 1.28 | wps 23437.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28462 | lr 0.000187442 | gnorm 0.393 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 78913
2022-03-07 10:57:49 | INFO | fairseq.trainer | begin training epoch 586
2022-03-07 10:57:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:59:29 | INFO | train_inner | epoch 586:     38 / 49 loss=2.493, nll_loss=0.358, ppl=1.28, wps=23458.4, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=28500, lr=0.000187317, gnorm=0.395, loss_scale=32, train_wall=236, gb_free=8.8, wall=79013
2022-03-07 10:59:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:59:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:00:02 | INFO | valid | epoch 586 | valid on 'valid' subset | loss 13.45 | nll_loss 12.745 | ppl 6864.13 | wps 41696.9 | wpb 510.9 | bsz 1 | num_updates 28510 | best_loss 9.157
2022-03-07 11:00:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 586 @ 28510 updates
2022-03-07 11:00:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:00:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:00:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 586 @ 28510 updates, score 13.45) (writing took 2.5042630746029317 seconds)
2022-03-07 11:00:04 | INFO | fairseq_cli.train | end of epoch 586 (average epoch stats below)
2022-03-07 11:00:04 | INFO | train | epoch 586 | loss 2.493 | nll_loss 0.358 | ppl 1.28 | wps 22943.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 28510 | lr 0.000187284 | gnorm 0.397 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 79049
2022-03-07 11:00:04 | INFO | fairseq.trainer | begin training epoch 587
2022-03-07 11:00:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:02:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:02:17 | INFO | valid | epoch 587 | valid on 'valid' subset | loss 13.482 | nll_loss 12.774 | ppl 7005.81 | wps 41412.5 | wpb 510.9 | bsz 1 | num_updates 28559 | best_loss 9.157
2022-03-07 11:02:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 587 @ 28559 updates
2022-03-07 11:02:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:02:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:02:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 587 @ 28559 updates, score 13.482) (writing took 2.40746729914099 seconds)
2022-03-07 11:02:20 | INFO | fairseq_cli.train | end of epoch 587 (average epoch stats below)
2022-03-07 11:02:20 | INFO | train | epoch 587 | loss 2.493 | nll_loss 0.358 | ppl 1.28 | wps 23449.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28559 | lr 0.000187124 | gnorm 0.396 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 79184
2022-03-07 11:02:20 | INFO | fairseq.trainer | begin training epoch 588
2022-03-07 11:02:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:04:08 | INFO | train_inner | epoch 588:     41 / 49 loss=2.493, nll_loss=0.358, ppl=1.28, wps=23259.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=28600, lr=0.000186989, gnorm=0.399, loss_scale=32, train_wall=238, gb_free=8.8, wall=79292
2022-03-07 11:04:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:04:33 | INFO | valid | epoch 588 | valid on 'valid' subset | loss 13.342 | nll_loss 12.621 | ppl 6298.98 | wps 41615.9 | wpb 510.9 | bsz 1 | num_updates 28608 | best_loss 9.157
2022-03-07 11:04:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 588 @ 28608 updates
2022-03-07 11:04:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:04:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:04:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 588 @ 28608 updates, score 13.342) (writing took 2.4095482011325657 seconds)
2022-03-07 11:04:35 | INFO | fairseq_cli.train | end of epoch 588 (average epoch stats below)
2022-03-07 11:04:35 | INFO | train | epoch 588 | loss 2.493 | nll_loss 0.358 | ppl 1.28 | wps 23495.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28608 | lr 0.000186963 | gnorm 0.401 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 79320
2022-03-07 11:04:35 | INFO | fairseq.trainer | begin training epoch 589
2022-03-07 11:04:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:05:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:06:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:06:48 | INFO | valid | epoch 589 | valid on 'valid' subset | loss 13.417 | nll_loss 12.706 | ppl 6680.4 | wps 41214.6 | wpb 510.9 | bsz 1 | num_updates 28656 | best_loss 9.157
2022-03-07 11:06:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 589 @ 28656 updates
2022-03-07 11:06:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:06:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:06:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 589 @ 28656 updates, score 13.417) (writing took 2.4455721508711576 seconds)
2022-03-07 11:06:50 | INFO | fairseq_cli.train | end of epoch 589 (average epoch stats below)
2022-03-07 11:06:50 | INFO | train | epoch 589 | loss 2.492 | nll_loss 0.357 | ppl 1.28 | wps 23043.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 28656 | lr 0.000186807 | gnorm 0.398 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 79455
2022-03-07 11:06:50 | INFO | fairseq.trainer | begin training epoch 590
2022-03-07 11:06:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:08:45 | INFO | train_inner | epoch 590:     44 / 49 loss=2.492, nll_loss=0.357, ppl=1.28, wps=23362.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=28700, lr=0.000186663, gnorm=0.398, loss_scale=32, train_wall=237, gb_free=8.8, wall=79570
2022-03-07 11:08:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:09:02 | INFO | valid | epoch 590 | valid on 'valid' subset | loss 13.395 | nll_loss 12.681 | ppl 6566.17 | wps 42351.7 | wpb 510.9 | bsz 1 | num_updates 28705 | best_loss 9.157
2022-03-07 11:09:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 590 @ 28705 updates
2022-03-07 11:09:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:09:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:09:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 590 @ 28705 updates, score 13.395) (writing took 2.3133032810874283 seconds)
2022-03-07 11:09:04 | INFO | fairseq_cli.train | end of epoch 590 (average epoch stats below)
2022-03-07 11:09:04 | INFO | train | epoch 590 | loss 2.491 | nll_loss 0.357 | ppl 1.28 | wps 23645.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28705 | lr 0.000186647 | gnorm 0.399 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 79589
2022-03-07 11:09:04 | INFO | fairseq.trainer | begin training epoch 591
2022-03-07 11:09:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:11:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:11:15 | INFO | valid | epoch 591 | valid on 'valid' subset | loss 13.415 | nll_loss 12.701 | ppl 6658.84 | wps 43352.1 | wpb 510.9 | bsz 1 | num_updates 28754 | best_loss 9.157
2022-03-07 11:11:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 591 @ 28754 updates
2022-03-07 11:11:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:11:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:11:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 591 @ 28754 updates, score 13.415) (writing took 2.3600084260106087 seconds)
2022-03-07 11:11:17 | INFO | fairseq_cli.train | end of epoch 591 (average epoch stats below)
2022-03-07 11:11:17 | INFO | train | epoch 591 | loss 2.491 | nll_loss 0.356 | ppl 1.28 | wps 23932.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 28754 | lr 0.000186488 | gnorm 0.396 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 79722
2022-03-07 11:11:17 | INFO | fairseq.trainer | begin training epoch 592
2022-03-07 11:11:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:11:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:13:19 | INFO | train_inner | epoch 592:     47 / 49 loss=2.491, nll_loss=0.357, ppl=1.28, wps=23731, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=28800, lr=0.000186339, gnorm=0.398, loss_scale=32, train_wall=233, gb_free=8.8, wall=79843
2022-03-07 11:13:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:13:28 | INFO | valid | epoch 592 | valid on 'valid' subset | loss 13.305 | nll_loss 12.579 | ppl 6119.77 | wps 43409.9 | wpb 510.9 | bsz 1 | num_updates 28802 | best_loss 9.157
2022-03-07 11:13:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 592 @ 28802 updates
2022-03-07 11:13:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:13:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:13:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 592 @ 28802 updates, score 13.305) (writing took 2.3435027771629393 seconds)
2022-03-07 11:13:30 | INFO | fairseq_cli.train | end of epoch 592 (average epoch stats below)
2022-03-07 11:13:30 | INFO | train | epoch 592 | loss 2.491 | nll_loss 0.357 | ppl 1.28 | wps 23450.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 28802 | lr 0.000186333 | gnorm 0.4 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 79855
2022-03-07 11:13:30 | INFO | fairseq.trainer | begin training epoch 593
2022-03-07 11:13:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:15:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:15:40 | INFO | valid | epoch 593 | valid on 'valid' subset | loss 13.472 | nll_loss 12.765 | ppl 6958.63 | wps 43573.6 | wpb 510.9 | bsz 1 | num_updates 28851 | best_loss 9.157
2022-03-07 11:15:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 593 @ 28851 updates
2022-03-07 11:15:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:15:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:15:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 593 @ 28851 updates, score 13.472) (writing took 2.4398071146570146 seconds)
2022-03-07 11:15:43 | INFO | fairseq_cli.train | end of epoch 593 (average epoch stats below)
2022-03-07 11:15:43 | INFO | train | epoch 593 | loss 2.49 | nll_loss 0.356 | ppl 1.28 | wps 23906.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 28851 | lr 0.000186174 | gnorm 0.392 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 79988
2022-03-07 11:15:43 | INFO | fairseq.trainer | begin training epoch 594
2022-03-07 11:15:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:17:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:17:54 | INFO | valid | epoch 594 | valid on 'valid' subset | loss 13.397 | nll_loss 12.672 | ppl 6524.49 | wps 42806.1 | wpb 510.9 | bsz 1 | num_updates 28899 | best_loss 9.157
2022-03-07 11:17:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 594 @ 28899 updates
2022-03-07 11:17:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:17:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:17:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 594 @ 28899 updates, score 13.397) (writing took 2.3339160862378776 seconds)
2022-03-07 11:17:56 | INFO | fairseq_cli.train | end of epoch 594 (average epoch stats below)
2022-03-07 11:17:56 | INFO | train | epoch 594 | loss 2.491 | nll_loss 0.357 | ppl 1.28 | wps 23402.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 28899 | lr 0.00018602 | gnorm 0.397 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 80121
2022-03-07 11:17:56 | INFO | fairseq.trainer | begin training epoch 595
2022-03-07 11:17:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:17:59 | INFO | train_inner | epoch 595:      1 / 49 loss=2.491, nll_loss=0.356, ppl=1.28, wps=23059.5, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=28900, lr=0.000186016, gnorm=0.395, loss_scale=32, train_wall=232, gb_free=8.8, wall=80123
2022-03-07 11:20:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:20:07 | INFO | valid | epoch 595 | valid on 'valid' subset | loss 13.418 | nll_loss 12.708 | ppl 6690.88 | wps 41405.9 | wpb 510.9 | bsz 1 | num_updates 28948 | best_loss 9.157
2022-03-07 11:20:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 595 @ 28948 updates
2022-03-07 11:20:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:20:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:20:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 595 @ 28948 updates, score 13.418) (writing took 2.48389465874061 seconds)
2022-03-07 11:20:10 | INFO | fairseq_cli.train | end of epoch 595 (average epoch stats below)
2022-03-07 11:20:10 | INFO | train | epoch 595 | loss 2.491 | nll_loss 0.356 | ppl 1.28 | wps 23751.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 28948 | lr 0.000185862 | gnorm 0.398 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 80254
2022-03-07 11:20:10 | INFO | fairseq.trainer | begin training epoch 596
2022-03-07 11:20:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:22:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:22:23 | INFO | valid | epoch 596 | valid on 'valid' subset | loss 13.371 | nll_loss 12.654 | ppl 6444.63 | wps 41536.6 | wpb 510.9 | bsz 1 | num_updates 28997 | best_loss 9.157
2022-03-07 11:22:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 596 @ 28997 updates
2022-03-07 11:22:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:22:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:22:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 596 @ 28997 updates, score 13.371) (writing took 2.4509441019035876 seconds)
2022-03-07 11:22:25 | INFO | fairseq_cli.train | end of epoch 596 (average epoch stats below)
2022-03-07 11:22:25 | INFO | train | epoch 596 | loss 2.49 | nll_loss 0.356 | ppl 1.28 | wps 23485.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28997 | lr 0.000185705 | gnorm 0.396 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 80390
2022-03-07 11:22:25 | INFO | fairseq.trainer | begin training epoch 597
2022-03-07 11:22:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:22:33 | INFO | train_inner | epoch 597:      3 / 49 loss=2.49, nll_loss=0.356, ppl=1.28, wps=23640.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=29000, lr=0.000185695, gnorm=0.397, loss_scale=32, train_wall=234, gb_free=8.8, wall=80398
2022-03-07 11:23:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:24:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:24:38 | INFO | valid | epoch 597 | valid on 'valid' subset | loss 13.611 | nll_loss 12.916 | ppl 7726.75 | wps 41663.4 | wpb 510.9 | bsz 1 | num_updates 29045 | best_loss 9.157
2022-03-07 11:24:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 597 @ 29045 updates
2022-03-07 11:24:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:24:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:24:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 597 @ 29045 updates, score 13.611) (writing took 2.388991020154208 seconds)
2022-03-07 11:24:40 | INFO | fairseq_cli.train | end of epoch 597 (average epoch stats below)
2022-03-07 11:24:40 | INFO | train | epoch 597 | loss 2.49 | nll_loss 0.355 | ppl 1.28 | wps 23009.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 29045 | lr 0.000185551 | gnorm 0.398 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 80525
2022-03-07 11:24:40 | INFO | fairseq.trainer | begin training epoch 598
2022-03-07 11:24:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:26:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:26:53 | INFO | valid | epoch 598 | valid on 'valid' subset | loss 13.409 | nll_loss 12.698 | ppl 6645.48 | wps 39862.8 | wpb 510.9 | bsz 1 | num_updates 29094 | best_loss 9.157
2022-03-07 11:26:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 598 @ 29094 updates
2022-03-07 11:26:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:26:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:26:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 598 @ 29094 updates, score 13.409) (writing took 2.555752294138074 seconds)
2022-03-07 11:26:56 | INFO | fairseq_cli.train | end of epoch 598 (average epoch stats below)
2022-03-07 11:26:56 | INFO | train | epoch 598 | loss 2.49 | nll_loss 0.355 | ppl 1.28 | wps 23407.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29094 | lr 0.000185395 | gnorm 0.398 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 80661
2022-03-07 11:26:56 | INFO | fairseq.trainer | begin training epoch 599
2022-03-07 11:26:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:27:12 | INFO | train_inner | epoch 599:      6 / 49 loss=2.489, nll_loss=0.355, ppl=1.28, wps=23256.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=29100, lr=0.000185376, gnorm=0.397, loss_scale=32, train_wall=238, gb_free=8.8, wall=80677
2022-03-07 11:29:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:29:09 | INFO | valid | epoch 599 | valid on 'valid' subset | loss 13.535 | nll_loss 12.832 | ppl 7292.17 | wps 41536.9 | wpb 510.9 | bsz 1 | num_updates 29143 | best_loss 9.157
2022-03-07 11:29:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 599 @ 29143 updates
2022-03-07 11:29:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:29:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:29:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 599 @ 29143 updates, score 13.535) (writing took 2.3892566482536495 seconds)
2022-03-07 11:29:11 | INFO | fairseq_cli.train | end of epoch 599 (average epoch stats below)
2022-03-07 11:29:11 | INFO | train | epoch 599 | loss 2.489 | nll_loss 0.355 | ppl 1.28 | wps 23484.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29143 | lr 0.000185239 | gnorm 0.394 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 80796
2022-03-07 11:29:11 | INFO | fairseq.trainer | begin training epoch 600
2022-03-07 11:29:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:29:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:31:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:31:24 | INFO | valid | epoch 600 | valid on 'valid' subset | loss 13.382 | nll_loss 12.668 | ppl 6505.87 | wps 41531.1 | wpb 510.9 | bsz 1 | num_updates 29191 | best_loss 9.157
2022-03-07 11:31:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 600 @ 29191 updates
2022-03-07 11:31:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:31:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:31:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 600 @ 29191 updates, score 13.382) (writing took 2.3668171097524464 seconds)
2022-03-07 11:31:27 | INFO | fairseq_cli.train | end of epoch 600 (average epoch stats below)
2022-03-07 11:31:27 | INFO | train | epoch 600 | loss 2.489 | nll_loss 0.355 | ppl 1.28 | wps 22972.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 29191 | lr 0.000185087 | gnorm 0.39 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 80932
2022-03-07 11:31:27 | INFO | fairseq.trainer | begin training epoch 601
2022-03-07 11:31:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:31:51 | INFO | train_inner | epoch 601:      9 / 49 loss=2.489, nll_loss=0.355, ppl=1.28, wps=23288, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=29200, lr=0.000185058, gnorm=0.392, loss_scale=32, train_wall=238, gb_free=8.8, wall=80955
2022-03-07 11:33:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:33:40 | INFO | valid | epoch 601 | valid on 'valid' subset | loss 13.353 | nll_loss 12.63 | ppl 6338.58 | wps 41608.7 | wpb 510.9 | bsz 1 | num_updates 29240 | best_loss 9.157
2022-03-07 11:33:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 601 @ 29240 updates
2022-03-07 11:33:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:33:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:33:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 601 @ 29240 updates, score 13.353) (writing took 2.339392122812569 seconds)
2022-03-07 11:33:42 | INFO | fairseq_cli.train | end of epoch 601 (average epoch stats below)
2022-03-07 11:33:42 | INFO | train | epoch 601 | loss 2.489 | nll_loss 0.355 | ppl 1.28 | wps 23455.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29240 | lr 0.000184932 | gnorm 0.391 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 81067
2022-03-07 11:33:42 | INFO | fairseq.trainer | begin training epoch 602
2022-03-07 11:33:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:35:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:35:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:35:55 | INFO | valid | epoch 602 | valid on 'valid' subset | loss 13.443 | nll_loss 12.737 | ppl 6824.88 | wps 41729.6 | wpb 510.9 | bsz 1 | num_updates 29288 | best_loss 9.157
2022-03-07 11:35:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 602 @ 29288 updates
2022-03-07 11:35:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:35:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:35:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 602 @ 29288 updates, score 13.443) (writing took 2.3435811661183834 seconds)
2022-03-07 11:35:58 | INFO | fairseq_cli.train | end of epoch 602 (average epoch stats below)
2022-03-07 11:35:58 | INFO | train | epoch 602 | loss 2.488 | nll_loss 0.354 | ppl 1.28 | wps 23011.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 29288 | lr 0.00018478 | gnorm 0.396 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 81202
2022-03-07 11:35:58 | INFO | fairseq.trainer | begin training epoch 603
2022-03-07 11:35:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:36:29 | INFO | train_inner | epoch 603:     12 / 49 loss=2.488, nll_loss=0.354, ppl=1.28, wps=23270.4, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=29300, lr=0.000184742, gnorm=0.393, loss_scale=32, train_wall=238, gb_free=8.8, wall=81234
2022-03-07 11:38:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:38:11 | INFO | valid | epoch 603 | valid on 'valid' subset | loss 13.466 | nll_loss 12.756 | ppl 6918.18 | wps 41559.6 | wpb 510.9 | bsz 1 | num_updates 29337 | best_loss 9.157
2022-03-07 11:38:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 603 @ 29337 updates
2022-03-07 11:38:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:38:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:38:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 603 @ 29337 updates, score 13.466) (writing took 2.7040062369778752 seconds)
2022-03-07 11:38:13 | INFO | fairseq_cli.train | end of epoch 603 (average epoch stats below)
2022-03-07 11:38:13 | INFO | train | epoch 603 | loss 2.488 | nll_loss 0.355 | ppl 1.28 | wps 23406.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29337 | lr 0.000184626 | gnorm 0.391 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 81338
2022-03-07 11:38:13 | INFO | fairseq.trainer | begin training epoch 604
2022-03-07 11:38:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:40:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:40:26 | INFO | valid | epoch 604 | valid on 'valid' subset | loss 13.465 | nll_loss 12.761 | ppl 6939.57 | wps 41738.3 | wpb 510.9 | bsz 1 | num_updates 29386 | best_loss 9.157
2022-03-07 11:40:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 604 @ 29386 updates
2022-03-07 11:40:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:40:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:40:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 604 @ 29386 updates, score 13.465) (writing took 2.496187230106443 seconds)
2022-03-07 11:40:29 | INFO | fairseq_cli.train | end of epoch 604 (average epoch stats below)
2022-03-07 11:40:29 | INFO | train | epoch 604 | loss 2.488 | nll_loss 0.354 | ppl 1.28 | wps 23489.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29386 | lr 0.000184472 | gnorm 0.391 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 81473
2022-03-07 11:40:29 | INFO | fairseq.trainer | begin training epoch 605
2022-03-07 11:40:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:41:05 | INFO | train_inner | epoch 605:     14 / 49 loss=2.488, nll_loss=0.354, ppl=1.28, wps=23497.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=29400, lr=0.000184428, gnorm=0.391, loss_scale=32, train_wall=235, gb_free=8.8, wall=81510
2022-03-07 11:41:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:42:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:42:41 | INFO | valid | epoch 605 | valid on 'valid' subset | loss 13.502 | nll_loss 12.795 | ppl 7108.86 | wps 41564.3 | wpb 510.9 | bsz 1 | num_updates 29434 | best_loss 9.157
2022-03-07 11:42:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 605 @ 29434 updates
2022-03-07 11:42:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:42:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:42:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 605 @ 29434 updates, score 13.502) (writing took 2.3731360849924386 seconds)
2022-03-07 11:42:44 | INFO | fairseq_cli.train | end of epoch 605 (average epoch stats below)
2022-03-07 11:42:44 | INFO | train | epoch 605 | loss 2.487 | nll_loss 0.354 | ppl 1.28 | wps 23046.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29434 | lr 0.000184321 | gnorm 0.39 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 81608
2022-03-07 11:42:44 | INFO | fairseq.trainer | begin training epoch 606
2022-03-07 11:42:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:44:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:44:55 | INFO | valid | epoch 606 | valid on 'valid' subset | loss 13.422 | nll_loss 12.71 | ppl 6701.96 | wps 43153.4 | wpb 510.9 | bsz 1 | num_updates 29483 | best_loss 9.157
2022-03-07 11:44:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 606 @ 29483 updates
2022-03-07 11:44:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:44:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:44:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 606 @ 29483 updates, score 13.422) (writing took 2.4969161758199334 seconds)
2022-03-07 11:44:57 | INFO | fairseq_cli.train | end of epoch 606 (average epoch stats below)
2022-03-07 11:44:57 | INFO | train | epoch 606 | loss 2.487 | nll_loss 0.354 | ppl 1.28 | wps 23834.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29483 | lr 0.000184168 | gnorm 0.393 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 81742
2022-03-07 11:44:57 | INFO | fairseq.trainer | begin training epoch 607
2022-03-07 11:44:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:45:41 | INFO | train_inner | epoch 607:     17 / 49 loss=2.487, nll_loss=0.354, ppl=1.28, wps=23525.4, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=29500, lr=0.000184115, gnorm=0.393, loss_scale=32, train_wall=235, gb_free=8.8, wall=81786
2022-03-07 11:47:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:47:08 | INFO | valid | epoch 607 | valid on 'valid' subset | loss 13.37 | nll_loss 12.656 | ppl 6455.41 | wps 41974.7 | wpb 510.9 | bsz 1 | num_updates 29532 | best_loss 9.157
2022-03-07 11:47:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 607 @ 29532 updates
2022-03-07 11:47:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:47:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:47:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 607 @ 29532 updates, score 13.37) (writing took 2.406501562334597 seconds)
2022-03-07 11:47:10 | INFO | fairseq_cli.train | end of epoch 607 (average epoch stats below)
2022-03-07 11:47:10 | INFO | train | epoch 607 | loss 2.487 | nll_loss 0.354 | ppl 1.28 | wps 23894 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29532 | lr 0.000184015 | gnorm 0.395 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 81875
2022-03-07 11:47:10 | INFO | fairseq.trainer | begin training epoch 608
2022-03-07 11:47:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:47:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:49:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:49:20 | INFO | valid | epoch 608 | valid on 'valid' subset | loss 13.434 | nll_loss 12.719 | ppl 6741.97 | wps 43002.5 | wpb 510.9 | bsz 1 | num_updates 29580 | best_loss 9.157
2022-03-07 11:49:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 608 @ 29580 updates
2022-03-07 11:49:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:49:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:49:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 608 @ 29580 updates, score 13.434) (writing took 2.459698564838618 seconds)
2022-03-07 11:49:23 | INFO | fairseq_cli.train | end of epoch 608 (average epoch stats below)
2022-03-07 11:49:23 | INFO | train | epoch 608 | loss 2.487 | nll_loss 0.353 | ppl 1.28 | wps 23426.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29580 | lr 0.000183866 | gnorm 0.395 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 82008
2022-03-07 11:49:23 | INFO | fairseq.trainer | begin training epoch 609
2022-03-07 11:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:50:15 | INFO | train_inner | epoch 609:     20 / 49 loss=2.487, nll_loss=0.353, ppl=1.28, wps=23736.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=29600, lr=0.000183804, gnorm=0.393, loss_scale=32, train_wall=233, gb_free=8.8, wall=82059
2022-03-07 11:51:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:51:33 | INFO | valid | epoch 609 | valid on 'valid' subset | loss 13.464 | nll_loss 12.757 | ppl 6922.95 | wps 43203 | wpb 510.9 | bsz 1 | num_updates 29629 | best_loss 9.157
2022-03-07 11:51:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 609 @ 29629 updates
2022-03-07 11:51:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:51:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:51:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 609 @ 29629 updates, score 13.464) (writing took 2.4355389871634543 seconds)
2022-03-07 11:51:36 | INFO | fairseq_cli.train | end of epoch 609 (average epoch stats below)
2022-03-07 11:51:36 | INFO | train | epoch 609 | loss 2.486 | nll_loss 0.353 | ppl 1.28 | wps 23960.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29629 | lr 0.000183714 | gnorm 0.395 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 82140
2022-03-07 11:51:36 | INFO | fairseq.trainer | begin training epoch 610
2022-03-07 11:51:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:53:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:53:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:53:46 | INFO | valid | epoch 610 | valid on 'valid' subset | loss 13.461 | nll_loss 12.748 | ppl 6877.75 | wps 43579.4 | wpb 510.9 | bsz 1 | num_updates 29677 | best_loss 9.157
2022-03-07 11:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 610 @ 29677 updates
2022-03-07 11:53:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:53:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 610 @ 29677 updates, score 13.461) (writing took 2.3238678057678044 seconds)
2022-03-07 11:53:48 | INFO | fairseq_cli.train | end of epoch 610 (average epoch stats below)
2022-03-07 11:53:48 | INFO | train | epoch 610 | loss 2.487 | nll_loss 0.354 | ppl 1.28 | wps 23475.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29677 | lr 0.000183565 | gnorm 0.392 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 82273
2022-03-07 11:53:48 | INFO | fairseq.trainer | begin training epoch 611
2022-03-07 11:53:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:54:48 | INFO | train_inner | epoch 611:     23 / 49 loss=2.486, nll_loss=0.353, ppl=1.28, wps=23741.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=29700, lr=0.000183494, gnorm=0.394, loss_scale=32, train_wall=233, gb_free=8.8, wall=82333
2022-03-07 11:55:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:55:59 | INFO | valid | epoch 611 | valid on 'valid' subset | loss 13.365 | nll_loss 12.65 | ppl 6428.39 | wps 42680.8 | wpb 510.9 | bsz 1 | num_updates 29726 | best_loss 9.157
2022-03-07 11:55:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 611 @ 29726 updates
2022-03-07 11:55:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:56:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:56:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 611 @ 29726 updates, score 13.365) (writing took 2.334545305930078 seconds)
2022-03-07 11:56:01 | INFO | fairseq_cli.train | end of epoch 611 (average epoch stats below)
2022-03-07 11:56:01 | INFO | train | epoch 611 | loss 2.486 | nll_loss 0.353 | ppl 1.28 | wps 23941.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29726 | lr 0.000183414 | gnorm 0.392 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 82406
2022-03-07 11:56:01 | INFO | fairseq.trainer | begin training epoch 612
2022-03-07 11:56:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:58:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:58:13 | INFO | valid | epoch 612 | valid on 'valid' subset | loss 13.427 | nll_loss 12.713 | ppl 6715.48 | wps 41400.7 | wpb 510.9 | bsz 1 | num_updates 29775 | best_loss 9.157
2022-03-07 11:58:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 612 @ 29775 updates
2022-03-07 11:58:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:58:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:58:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 612 @ 29775 updates, score 13.427) (writing took 2.5116302561946213 seconds)
2022-03-07 11:58:16 | INFO | fairseq_cli.train | end of epoch 612 (average epoch stats below)
2022-03-07 11:58:16 | INFO | train | epoch 612 | loss 2.486 | nll_loss 0.353 | ppl 1.28 | wps 23552.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29775 | lr 0.000183263 | gnorm 0.39 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 82541
2022-03-07 11:58:16 | INFO | fairseq.trainer | begin training epoch 613
2022-03-07 11:58:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:59:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:59:25 | INFO | train_inner | epoch 613:     26 / 49 loss=2.486, nll_loss=0.353, ppl=1.28, wps=23423.1, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=29800, lr=0.000183186, gnorm=0.39, loss_scale=32, train_wall=236, gb_free=8.8, wall=82609
2022-03-07 12:00:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:00:30 | INFO | valid | epoch 613 | valid on 'valid' subset | loss 13.481 | nll_loss 12.77 | ppl 6985.54 | wps 40266.8 | wpb 510.9 | bsz 1 | num_updates 29823 | best_loss 9.157
2022-03-07 12:00:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 613 @ 29823 updates
2022-03-07 12:00:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:00:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:00:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 613 @ 29823 updates, score 13.481) (writing took 2.441498029977083 seconds)
2022-03-07 12:00:33 | INFO | fairseq_cli.train | end of epoch 613 (average epoch stats below)
2022-03-07 12:00:33 | INFO | train | epoch 613 | loss 2.485 | nll_loss 0.352 | ppl 1.28 | wps 22767.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 29823 | lr 0.000183115 | gnorm 0.391 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 82677
2022-03-07 12:00:33 | INFO | fairseq.trainer | begin training epoch 614
2022-03-07 12:00:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:02:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:02:47 | INFO | valid | epoch 614 | valid on 'valid' subset | loss 13.361 | nll_loss 12.645 | ppl 6403.35 | wps 40440.1 | wpb 510.9 | bsz 1 | num_updates 29872 | best_loss 9.157
2022-03-07 12:02:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 614 @ 29872 updates
2022-03-07 12:02:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:02:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:02:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 614 @ 29872 updates, score 13.361) (writing took 2.3442306513898075 seconds)
2022-03-07 12:02:49 | INFO | fairseq_cli.train | end of epoch 614 (average epoch stats below)
2022-03-07 12:02:49 | INFO | train | epoch 614 | loss 2.485 | nll_loss 0.352 | ppl 1.28 | wps 23250.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29872 | lr 0.000182965 | gnorm 0.39 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 82814
2022-03-07 12:02:49 | INFO | fairseq.trainer | begin training epoch 615
2022-03-07 12:02:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:04:04 | INFO | train_inner | epoch 615:     28 / 49 loss=2.485, nll_loss=0.352, ppl=1.28, wps=23255.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=29900, lr=0.000182879, gnorm=0.389, loss_scale=32, train_wall=238, gb_free=8.8, wall=82888
2022-03-07 12:04:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:05:04 | INFO | valid | epoch 615 | valid on 'valid' subset | loss 13.451 | nll_loss 12.738 | ppl 6832.43 | wps 40581.3 | wpb 510.9 | bsz 1 | num_updates 29921 | best_loss 9.157
2022-03-07 12:05:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 615 @ 29921 updates
2022-03-07 12:05:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:05:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:05:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 615 @ 29921 updates, score 13.451) (writing took 2.3255427088588476 seconds)
2022-03-07 12:05:06 | INFO | fairseq_cli.train | end of epoch 615 (average epoch stats below)
2022-03-07 12:05:06 | INFO | train | epoch 615 | loss 2.485 | nll_loss 0.352 | ppl 1.28 | wps 23266 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29921 | lr 0.000182815 | gnorm 0.388 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 82951
2022-03-07 12:05:06 | INFO | fairseq.trainer | begin training epoch 616
2022-03-07 12:05:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:05:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:07:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:07:20 | INFO | valid | epoch 616 | valid on 'valid' subset | loss 13.405 | nll_loss 12.688 | ppl 6601.14 | wps 39813.3 | wpb 510.9 | bsz 1 | num_updates 29969 | best_loss 9.157
2022-03-07 12:07:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 616 @ 29969 updates
2022-03-07 12:07:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:07:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:07:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 616 @ 29969 updates, score 13.405) (writing took 3.0334841050207615 seconds)
2022-03-07 12:07:23 | INFO | fairseq_cli.train | end of epoch 616 (average epoch stats below)
2022-03-07 12:07:23 | INFO | train | epoch 616 | loss 2.484 | nll_loss 0.352 | ppl 1.28 | wps 22682.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 29969 | lr 0.000182669 | gnorm 0.39 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 83088
2022-03-07 12:07:23 | INFO | fairseq.trainer | begin training epoch 617
2022-03-07 12:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:08:46 | INFO | train_inner | epoch 617:     31 / 49 loss=2.484, nll_loss=0.352, ppl=1.28, wps=23014.6, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=30000, lr=0.000182574, gnorm=0.388, loss_scale=32, train_wall=240, gb_free=8.8, wall=83170
2022-03-07 12:09:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:09:38 | INFO | valid | epoch 617 | valid on 'valid' subset | loss 13.335 | nll_loss 12.613 | ppl 6264.66 | wps 41682.6 | wpb 510.9 | bsz 1 | num_updates 30018 | best_loss 9.157
2022-03-07 12:09:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 617 @ 30018 updates
2022-03-07 12:09:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:09:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:09:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 617 @ 30018 updates, score 13.335) (writing took 2.5115610091015697 seconds)
2022-03-07 12:09:40 | INFO | fairseq_cli.train | end of epoch 617 (average epoch stats below)
2022-03-07 12:09:40 | INFO | train | epoch 617 | loss 2.484 | nll_loss 0.352 | ppl 1.28 | wps 23184.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30018 | lr 0.000182519 | gnorm 0.388 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 83225
2022-03-07 12:09:40 | INFO | fairseq.trainer | begin training epoch 618
2022-03-07 12:09:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:11:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:11:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:11:55 | INFO | valid | epoch 618 | valid on 'valid' subset | loss 13.532 | nll_loss 12.831 | ppl 7288.47 | wps 40347 | wpb 510.9 | bsz 1 | num_updates 30066 | best_loss 9.157
2022-03-07 12:11:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 618 @ 30066 updates
2022-03-07 12:11:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:11:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:11:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 618 @ 30066 updates, score 13.532) (writing took 2.3604777371510863 seconds)
2022-03-07 12:11:57 | INFO | fairseq_cli.train | end of epoch 618 (average epoch stats below)
2022-03-07 12:11:57 | INFO | train | epoch 618 | loss 2.484 | nll_loss 0.351 | ppl 1.28 | wps 22764.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 30066 | lr 0.000182374 | gnorm 0.393 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 83362
2022-03-07 12:11:57 | INFO | fairseq.trainer | begin training epoch 619
2022-03-07 12:11:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:13:27 | INFO | train_inner | epoch 619:     34 / 49 loss=2.484, nll_loss=0.351, ppl=1.28, wps=23016.1, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=30100, lr=0.000182271, gnorm=0.392, loss_scale=32, train_wall=241, gb_free=8.8, wall=83452
2022-03-07 12:14:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:14:11 | INFO | valid | epoch 619 | valid on 'valid' subset | loss 13.393 | nll_loss 12.676 | ppl 6545.32 | wps 40132.1 | wpb 510.9 | bsz 1 | num_updates 30115 | best_loss 9.157
2022-03-07 12:14:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 619 @ 30115 updates
2022-03-07 12:14:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:14:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:14:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 619 @ 30115 updates, score 13.393) (writing took 2.4804906114004552 seconds)
2022-03-07 12:14:14 | INFO | fairseq_cli.train | end of epoch 619 (average epoch stats below)
2022-03-07 12:14:14 | INFO | train | epoch 619 | loss 2.483 | nll_loss 0.351 | ppl 1.28 | wps 23193.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30115 | lr 0.000182225 | gnorm 0.391 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 83499
2022-03-07 12:14:14 | INFO | fairseq.trainer | begin training epoch 620
2022-03-07 12:14:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:16:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:16:28 | INFO | valid | epoch 620 | valid on 'valid' subset | loss 13.379 | nll_loss 12.665 | ppl 6495 | wps 40809.9 | wpb 510.9 | bsz 1 | num_updates 30164 | best_loss 9.157
2022-03-07 12:16:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 620 @ 30164 updates
2022-03-07 12:16:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:16:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:16:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 620 @ 30164 updates, score 13.379) (writing took 2.504792792722583 seconds)
2022-03-07 12:16:31 | INFO | fairseq_cli.train | end of epoch 620 (average epoch stats below)
2022-03-07 12:16:31 | INFO | train | epoch 620 | loss 2.483 | nll_loss 0.351 | ppl 1.28 | wps 23237.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30164 | lr 0.000182077 | gnorm 0.39 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 83635
2022-03-07 12:16:31 | INFO | fairseq.trainer | begin training epoch 621
2022-03-07 12:16:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:17:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:18:09 | INFO | train_inner | epoch 621:     37 / 49 loss=2.483, nll_loss=0.351, ppl=1.28, wps=23045.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=30200, lr=0.000181969, gnorm=0.39, loss_scale=32, train_wall=240, gb_free=8.8, wall=83734
2022-03-07 12:18:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:18:45 | INFO | valid | epoch 621 | valid on 'valid' subset | loss 13.424 | nll_loss 12.713 | ppl 6714.07 | wps 39268 | wpb 510.9 | bsz 1 | num_updates 30212 | best_loss 9.157
2022-03-07 12:18:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 621 @ 30212 updates
2022-03-07 12:18:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:18:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:18:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 621 @ 30212 updates, score 13.424) (writing took 2.645054521970451 seconds)
2022-03-07 12:18:48 | INFO | fairseq_cli.train | end of epoch 621 (average epoch stats below)
2022-03-07 12:18:48 | INFO | train | epoch 621 | loss 2.483 | nll_loss 0.35 | ppl 1.27 | wps 22710.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 30212 | lr 0.000181932 | gnorm 0.39 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 83772
2022-03-07 12:18:48 | INFO | fairseq.trainer | begin training epoch 622
2022-03-07 12:18:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:20:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:21:00 | INFO | valid | epoch 622 | valid on 'valid' subset | loss 13.445 | nll_loss 12.735 | ppl 6818.92 | wps 42306.8 | wpb 510.9 | bsz 1 | num_updates 30261 | best_loss 9.157
2022-03-07 12:21:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 622 @ 30261 updates
2022-03-07 12:21:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:21:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:21:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 622 @ 30261 updates, score 13.445) (writing took 2.3711507841944695 seconds)
2022-03-07 12:21:03 | INFO | fairseq_cli.train | end of epoch 622 (average epoch stats below)
2022-03-07 12:21:03 | INFO | train | epoch 622 | loss 2.483 | nll_loss 0.35 | ppl 1.27 | wps 23522.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30261 | lr 0.000181785 | gnorm 0.386 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 83908
2022-03-07 12:21:03 | INFO | fairseq.trainer | begin training epoch 623
2022-03-07 12:21:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:22:45 | INFO | train_inner | epoch 623:     39 / 49 loss=2.483, nll_loss=0.35, ppl=1.27, wps=23530.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=30300, lr=0.000181668, gnorm=0.389, loss_scale=32, train_wall=235, gb_free=8.8, wall=84009
2022-03-07 12:23:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:23:15 | INFO | valid | epoch 623 | valid on 'valid' subset | loss 13.366 | nll_loss 12.654 | ppl 6447.17 | wps 42374.3 | wpb 510.9 | bsz 1 | num_updates 30310 | best_loss 9.157
2022-03-07 12:23:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 623 @ 30310 updates
2022-03-07 12:23:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:23:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:23:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 623 @ 30310 updates, score 13.366) (writing took 2.41501295985654 seconds)
2022-03-07 12:23:17 | INFO | fairseq_cli.train | end of epoch 623 (average epoch stats below)
2022-03-07 12:23:17 | INFO | train | epoch 623 | loss 2.483 | nll_loss 0.35 | ppl 1.27 | wps 23681.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 30310 | lr 0.000181638 | gnorm 0.391 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 84042
2022-03-07 12:23:17 | INFO | fairseq.trainer | begin training epoch 624
2022-03-07 12:23:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:23:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:25:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:25:29 | INFO | valid | epoch 624 | valid on 'valid' subset | loss 13.5 | nll_loss 12.797 | ppl 7116.3 | wps 41710.1 | wpb 510.9 | bsz 1 | num_updates 30358 | best_loss 9.157
2022-03-07 12:25:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 624 @ 30358 updates
2022-03-07 12:25:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:25:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:25:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 624 @ 30358 updates, score 13.5) (writing took 2.380079953931272 seconds)
2022-03-07 12:25:31 | INFO | fairseq_cli.train | end of epoch 624 (average epoch stats below)
2022-03-07 12:25:31 | INFO | train | epoch 624 | loss 2.483 | nll_loss 0.35 | ppl 1.27 | wps 23196.2 | ups 0.36 | wpb 64853.3 | bsz 126.7 | num_updates 30358 | lr 0.000181494 | gnorm 0.392 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 84176
2022-03-07 12:25:31 | INFO | fairseq.trainer | begin training epoch 625
2022-03-07 12:25:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:27:21 | INFO | train_inner | epoch 625:     42 / 49 loss=2.482, nll_loss=0.35, ppl=1.27, wps=23499.9, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=30400, lr=0.000181369, gnorm=0.392, loss_scale=32, train_wall=235, gb_free=8.8, wall=84285
2022-03-07 12:27:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:27:43 | INFO | valid | epoch 625 | valid on 'valid' subset | loss 13.465 | nll_loss 12.757 | ppl 6920.84 | wps 41884.3 | wpb 510.9 | bsz 1 | num_updates 30407 | best_loss 9.157
2022-03-07 12:27:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 625 @ 30407 updates
2022-03-07 12:27:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:27:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:27:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 625 @ 30407 updates, score 13.465) (writing took 2.4211895298212767 seconds)
2022-03-07 12:27:45 | INFO | fairseq_cli.train | end of epoch 625 (average epoch stats below)
2022-03-07 12:27:45 | INFO | train | epoch 625 | loss 2.482 | nll_loss 0.35 | ppl 1.27 | wps 23711.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 30407 | lr 0.000181348 | gnorm 0.392 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 84310
2022-03-07 12:27:45 | INFO | fairseq.trainer | begin training epoch 626
2022-03-07 12:27:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:29:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:29:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:29:57 | INFO | valid | epoch 626 | valid on 'valid' subset | loss 13.375 | nll_loss 12.661 | ppl 6476.24 | wps 42500.1 | wpb 510.9 | bsz 1 | num_updates 30455 | best_loss 9.157
2022-03-07 12:29:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 626 @ 30455 updates
2022-03-07 12:29:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:30:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:30:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 626 @ 30455 updates, score 13.375) (writing took 2.518000451847911 seconds)
2022-03-07 12:30:00 | INFO | fairseq_cli.train | end of epoch 626 (average epoch stats below)
2022-03-07 12:30:00 | INFO | train | epoch 626 | loss 2.482 | nll_loss 0.349 | ppl 1.27 | wps 23171.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 30455 | lr 0.000181205 | gnorm 0.383 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 84444
2022-03-07 12:30:00 | INFO | fairseq.trainer | begin training epoch 627
2022-03-07 12:30:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:31:57 | INFO | train_inner | epoch 627:     45 / 49 loss=2.482, nll_loss=0.35, ppl=1.27, wps=23484.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=30500, lr=0.000181071, gnorm=0.385, loss_scale=32, train_wall=236, gb_free=8.8, wall=84562
2022-03-07 12:32:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:32:11 | INFO | valid | epoch 627 | valid on 'valid' subset | loss 13.393 | nll_loss 12.673 | ppl 6532.07 | wps 42465.9 | wpb 510.9 | bsz 1 | num_updates 30504 | best_loss 9.157
2022-03-07 12:32:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 627 @ 30504 updates
2022-03-07 12:32:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:32:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:32:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 627 @ 30504 updates, score 13.393) (writing took 2.31588531518355 seconds)
2022-03-07 12:32:14 | INFO | fairseq_cli.train | end of epoch 627 (average epoch stats below)
2022-03-07 12:32:14 | INFO | train | epoch 627 | loss 2.482 | nll_loss 0.35 | ppl 1.27 | wps 23726.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 30504 | lr 0.00018106 | gnorm 0.386 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 84578
2022-03-07 12:32:14 | INFO | fairseq.trainer | begin training epoch 628
2022-03-07 12:32:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:34:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:34:26 | INFO | valid | epoch 628 | valid on 'valid' subset | loss 13.407 | nll_loss 12.688 | ppl 6598.92 | wps 40438.4 | wpb 510.9 | bsz 1 | num_updates 30553 | best_loss 9.157
2022-03-07 12:34:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 628 @ 30553 updates
2022-03-07 12:34:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:34:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:34:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 628 @ 30553 updates, score 13.407) (writing took 2.347897371277213 seconds)
2022-03-07 12:34:28 | INFO | fairseq_cli.train | end of epoch 628 (average epoch stats below)
2022-03-07 12:34:28 | INFO | train | epoch 628 | loss 2.482 | nll_loss 0.35 | ppl 1.27 | wps 23589 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30553 | lr 0.000180914 | gnorm 0.389 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 84713
2022-03-07 12:34:28 | INFO | fairseq.trainer | begin training epoch 629
2022-03-07 12:34:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:35:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:36:36 | INFO | train_inner | epoch 629:     48 / 49 loss=2.482, nll_loss=0.35, ppl=1.27, wps=23260.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=30600, lr=0.000180775, gnorm=0.387, loss_scale=32, train_wall=238, gb_free=8.8, wall=84841
2022-03-07 12:36:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:36:43 | INFO | valid | epoch 629 | valid on 'valid' subset | loss 13.451 | nll_loss 12.745 | ppl 6863.94 | wps 40280.8 | wpb 510.9 | bsz 1 | num_updates 30601 | best_loss 9.157
2022-03-07 12:36:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 629 @ 30601 updates
2022-03-07 12:36:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:36:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:36:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 629 @ 30601 updates, score 13.451) (writing took 2.3692984441295266 seconds)
2022-03-07 12:36:45 | INFO | fairseq_cli.train | end of epoch 629 (average epoch stats below)
2022-03-07 12:36:45 | INFO | train | epoch 629 | loss 2.481 | nll_loss 0.349 | ppl 1.27 | wps 22764.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 30601 | lr 0.000180772 | gnorm 0.385 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 84850
2022-03-07 12:36:45 | INFO | fairseq.trainer | begin training epoch 630
2022-03-07 12:36:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:38:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:39:00 | INFO | valid | epoch 630 | valid on 'valid' subset | loss 13.46 | nll_loss 12.754 | ppl 6908.44 | wps 40038.1 | wpb 510.9 | bsz 1 | num_updates 30650 | best_loss 9.157
2022-03-07 12:39:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 630 @ 30650 updates
2022-03-07 12:39:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:39:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:39:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 630 @ 30650 updates, score 13.46) (writing took 2.520754544995725 seconds)
2022-03-07 12:39:02 | INFO | fairseq_cli.train | end of epoch 630 (average epoch stats below)
2022-03-07 12:39:02 | INFO | train | epoch 630 | loss 2.481 | nll_loss 0.35 | ppl 1.27 | wps 23173.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30650 | lr 0.000180628 | gnorm 0.387 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 84987
2022-03-07 12:39:02 | INFO | fairseq.trainer | begin training epoch 631
2022-03-07 12:39:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:41:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:41:17 | INFO | valid | epoch 631 | valid on 'valid' subset | loss 13.437 | nll_loss 12.721 | ppl 6752.18 | wps 40348.7 | wpb 510.9 | bsz 1 | num_updates 30699 | best_loss 9.157
2022-03-07 12:41:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 631 @ 30699 updates
2022-03-07 12:41:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:41:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:41:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 631 @ 30699 updates, score 13.437) (writing took 2.608808921650052 seconds)
2022-03-07 12:41:19 | INFO | fairseq_cli.train | end of epoch 631 (average epoch stats below)
2022-03-07 12:41:19 | INFO | train | epoch 631 | loss 2.481 | nll_loss 0.35 | ppl 1.27 | wps 23183.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30699 | lr 0.000180484 | gnorm 0.393 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 85124
2022-03-07 12:41:19 | INFO | fairseq.trainer | begin training epoch 632
2022-03-07 12:41:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:41:22 | INFO | train_inner | epoch 632:      1 / 49 loss=2.481, nll_loss=0.349, ppl=1.27, wps=22550.3, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=30700, lr=0.000180481, gnorm=0.391, loss_scale=32, train_wall=237, gb_free=8.8, wall=85127
2022-03-07 12:41:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:43:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:43:33 | INFO | valid | epoch 632 | valid on 'valid' subset | loss 13.49 | nll_loss 12.786 | ppl 7063.1 | wps 41622.3 | wpb 510.9 | bsz 1 | num_updates 30747 | best_loss 9.157
2022-03-07 12:43:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 632 @ 30747 updates
2022-03-07 12:43:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:43:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:43:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 632 @ 30747 updates, score 13.49) (writing took 2.4450507387518883 seconds)
2022-03-07 12:43:35 | INFO | fairseq_cli.train | end of epoch 632 (average epoch stats below)
2022-03-07 12:43:35 | INFO | train | epoch 632 | loss 2.48 | nll_loss 0.349 | ppl 1.27 | wps 22928.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 30747 | lr 0.000180343 | gnorm 0.393 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 85260
2022-03-07 12:43:35 | INFO | fairseq.trainer | begin training epoch 633
2022-03-07 12:43:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:45:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:45:48 | INFO | valid | epoch 633 | valid on 'valid' subset | loss 13.41 | nll_loss 12.698 | ppl 6643.38 | wps 41864 | wpb 510.9 | bsz 1 | num_updates 30796 | best_loss 9.157
2022-03-07 12:45:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 633 @ 30796 updates
2022-03-07 12:45:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:45:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:45:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 633 @ 30796 updates, score 13.41) (writing took 2.461739539168775 seconds)
2022-03-07 12:45:50 | INFO | fairseq_cli.train | end of epoch 633 (average epoch stats below)
2022-03-07 12:45:50 | INFO | train | epoch 633 | loss 2.48 | nll_loss 0.348 | ppl 1.27 | wps 23464 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30796 | lr 0.000180199 | gnorm 0.388 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 85395
2022-03-07 12:45:50 | INFO | fairseq.trainer | begin training epoch 634
2022-03-07 12:45:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:46:01 | INFO | train_inner | epoch 634:      4 / 49 loss=2.48, nll_loss=0.349, ppl=1.27, wps=23252.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=30800, lr=0.000180187, gnorm=0.39, loss_scale=32, train_wall=238, gb_free=8.8, wall=85406
2022-03-07 12:47:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:47:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:48:03 | INFO | valid | epoch 634 | valid on 'valid' subset | loss 13.479 | nll_loss 12.772 | ppl 6994.87 | wps 41602 | wpb 510.9 | bsz 1 | num_updates 30844 | best_loss 9.157
2022-03-07 12:48:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 634 @ 30844 updates
2022-03-07 12:48:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:48:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:48:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 634 @ 30844 updates, score 13.479) (writing took 2.379004032816738 seconds)
2022-03-07 12:48:06 | INFO | fairseq_cli.train | end of epoch 634 (average epoch stats below)
2022-03-07 12:48:06 | INFO | train | epoch 634 | loss 2.48 | nll_loss 0.349 | ppl 1.27 | wps 22995 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 30844 | lr 0.000180059 | gnorm 0.389 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 85531
2022-03-07 12:48:06 | INFO | fairseq.trainer | begin training epoch 635
2022-03-07 12:48:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:50:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:50:19 | INFO | valid | epoch 635 | valid on 'valid' subset | loss 13.331 | nll_loss 12.608 | ppl 6241.91 | wps 40990.6 | wpb 510.9 | bsz 1 | num_updates 30893 | best_loss 9.157
2022-03-07 12:50:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 635 @ 30893 updates
2022-03-07 12:50:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:50:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:50:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 635 @ 30893 updates, score 13.331) (writing took 2.492562847211957 seconds)
2022-03-07 12:50:22 | INFO | fairseq_cli.train | end of epoch 635 (average epoch stats below)
2022-03-07 12:50:22 | INFO | train | epoch 635 | loss 2.48 | nll_loss 0.348 | ppl 1.27 | wps 23386.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30893 | lr 0.000179916 | gnorm 0.39 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 85666
2022-03-07 12:50:22 | INFO | fairseq.trainer | begin training epoch 636
2022-03-07 12:50:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:50:40 | INFO | train_inner | epoch 636:      7 / 49 loss=2.48, nll_loss=0.348, ppl=1.27, wps=23235.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=30900, lr=0.000179896, gnorm=0.389, loss_scale=32, train_wall=238, gb_free=8.8, wall=85685
2022-03-07 12:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:52:35 | INFO | valid | epoch 636 | valid on 'valid' subset | loss 13.409 | nll_loss 12.7 | ppl 6654.24 | wps 41512.6 | wpb 510.9 | bsz 1 | num_updates 30942 | best_loss 9.157
2022-03-07 12:52:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 636 @ 30942 updates
2022-03-07 12:52:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:52:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:52:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 636 @ 30942 updates, score 13.409) (writing took 2.479770698118955 seconds)
2022-03-07 12:52:38 | INFO | fairseq_cli.train | end of epoch 636 (average epoch stats below)
2022-03-07 12:52:38 | INFO | train | epoch 636 | loss 2.48 | nll_loss 0.348 | ppl 1.27 | wps 23388.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30942 | lr 0.000179774 | gnorm 0.388 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 85802
2022-03-07 12:52:38 | INFO | fairseq.trainer | begin training epoch 637
2022-03-07 12:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:53:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:54:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:54:50 | INFO | valid | epoch 637 | valid on 'valid' subset | loss 13.392 | nll_loss 12.675 | ppl 6541.02 | wps 41155.1 | wpb 510.9 | bsz 1 | num_updates 30990 | best_loss 9.157
2022-03-07 12:54:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 637 @ 30990 updates
2022-03-07 12:54:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:54:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:54:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 637 @ 30990 updates, score 13.392) (writing took 2.480041936971247 seconds)
2022-03-07 12:54:53 | INFO | fairseq_cli.train | end of epoch 637 (average epoch stats below)
2022-03-07 12:54:53 | INFO | train | epoch 637 | loss 2.479 | nll_loss 0.348 | ppl 1.27 | wps 23004.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 30990 | lr 0.000179634 | gnorm 0.389 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 85938
2022-03-07 12:54:53 | INFO | fairseq.trainer | begin training epoch 638
2022-03-07 12:54:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:55:19 | INFO | train_inner | epoch 638:     10 / 49 loss=2.479, nll_loss=0.348, ppl=1.27, wps=23258.6, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=31000, lr=0.000179605, gnorm=0.388, loss_scale=32, train_wall=238, gb_free=8.8, wall=85964
2022-03-07 12:57:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:57:06 | INFO | valid | epoch 638 | valid on 'valid' subset | loss 13.506 | nll_loss 12.809 | ppl 7175.31 | wps 41729.9 | wpb 510.9 | bsz 1 | num_updates 31039 | best_loss 9.157
2022-03-07 12:57:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 638 @ 31039 updates
2022-03-07 12:57:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:57:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:57:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 638 @ 31039 updates, score 13.506) (writing took 2.551128906197846 seconds)
2022-03-07 12:57:08 | INFO | fairseq_cli.train | end of epoch 638 (average epoch stats below)
2022-03-07 12:57:08 | INFO | train | epoch 638 | loss 2.479 | nll_loss 0.348 | ppl 1.27 | wps 23489 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31039 | lr 0.000179492 | gnorm 0.384 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 86073
2022-03-07 12:57:08 | INFO | fairseq.trainer | begin training epoch 639
2022-03-07 12:57:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:59:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:59:19 | INFO | valid | epoch 639 | valid on 'valid' subset | loss 13.447 | nll_loss 12.738 | ppl 6831.09 | wps 40712.1 | wpb 510.9 | bsz 1 | num_updates 31088 | best_loss 9.157
2022-03-07 12:59:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 639 @ 31088 updates
2022-03-07 12:59:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:59:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:59:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 639 @ 31088 updates, score 13.447) (writing took 2.3748998548835516 seconds)
2022-03-07 12:59:21 | INFO | fairseq_cli.train | end of epoch 639 (average epoch stats below)
2022-03-07 12:59:21 | INFO | train | epoch 639 | loss 2.478 | nll_loss 0.348 | ppl 1.27 | wps 23835.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 31088 | lr 0.000179351 | gnorm 0.389 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 86206
2022-03-07 12:59:21 | INFO | fairseq.trainer | begin training epoch 640
2022-03-07 12:59:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:59:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:59:55 | INFO | train_inner | epoch 640:     13 / 49 loss=2.479, nll_loss=0.348, ppl=1.27, wps=23504.8, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=31100, lr=0.000179316, gnorm=0.387, loss_scale=32, train_wall=235, gb_free=8.8, wall=86240
2022-03-07 13:01:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:01:33 | INFO | valid | epoch 640 | valid on 'valid' subset | loss 13.422 | nll_loss 12.712 | ppl 6711.72 | wps 41649.7 | wpb 510.9 | bsz 1 | num_updates 31136 | best_loss 9.157
2022-03-07 13:01:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 640 @ 31136 updates
2022-03-07 13:01:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:01:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:01:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 640 @ 31136 updates, score 13.422) (writing took 2.5215779482387006 seconds)
2022-03-07 13:01:35 | INFO | fairseq_cli.train | end of epoch 640 (average epoch stats below)
2022-03-07 13:01:35 | INFO | train | epoch 640 | loss 2.478 | nll_loss 0.347 | ppl 1.27 | wps 23226.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 31136 | lr 0.000179213 | gnorm 0.391 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 86340
2022-03-07 13:01:35 | INFO | fairseq.trainer | begin training epoch 641
2022-03-07 13:01:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:03:48 | INFO | valid | epoch 641 | valid on 'valid' subset | loss 13.519 | nll_loss 12.818 | ppl 7222.7 | wps 41487.4 | wpb 510.9 | bsz 1 | num_updates 31185 | best_loss 9.157
2022-03-07 13:03:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 641 @ 31185 updates
2022-03-07 13:03:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:03:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:03:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 641 @ 31185 updates, score 13.519) (writing took 2.3818543129600585 seconds)
2022-03-07 13:03:51 | INFO | fairseq_cli.train | end of epoch 641 (average epoch stats below)
2022-03-07 13:03:51 | INFO | train | epoch 641 | loss 2.478 | nll_loss 0.347 | ppl 1.27 | wps 23504.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31185 | lr 0.000179072 | gnorm 0.387 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 86475
2022-03-07 13:03:51 | INFO | fairseq.trainer | begin training epoch 642
2022-03-07 13:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:04:30 | INFO | train_inner | epoch 642:     15 / 49 loss=2.478, nll_loss=0.347, ppl=1.27, wps=23573.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=31200, lr=0.000179029, gnorm=0.39, loss_scale=32, train_wall=235, gb_free=8.8, wall=86515
2022-03-07 13:05:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:05:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:06:04 | INFO | valid | epoch 642 | valid on 'valid' subset | loss 13.521 | nll_loss 12.82 | ppl 7231.34 | wps 41288.3 | wpb 510.9 | bsz 1 | num_updates 31233 | best_loss 9.157
2022-03-07 13:06:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 642 @ 31233 updates
2022-03-07 13:06:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:06:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:06:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 642 @ 31233 updates, score 13.521) (writing took 2.4438662379980087 seconds)
2022-03-07 13:06:06 | INFO | fairseq_cli.train | end of epoch 642 (average epoch stats below)
2022-03-07 13:06:06 | INFO | train | epoch 642 | loss 2.479 | nll_loss 0.348 | ppl 1.27 | wps 22997.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 31233 | lr 0.000178934 | gnorm 0.389 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 86611
2022-03-07 13:06:06 | INFO | fairseq.trainer | begin training epoch 643
2022-03-07 13:06:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:08:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:08:19 | INFO | valid | epoch 643 | valid on 'valid' subset | loss 13.483 | nll_loss 12.781 | ppl 7039.8 | wps 41660.3 | wpb 510.9 | bsz 1 | num_updates 31282 | best_loss 9.157
2022-03-07 13:08:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 643 @ 31282 updates
2022-03-07 13:08:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:08:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:08:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 643 @ 31282 updates, score 13.483) (writing took 2.3622945812530816 seconds)
2022-03-07 13:08:21 | INFO | fairseq_cli.train | end of epoch 643 (average epoch stats below)
2022-03-07 13:08:21 | INFO | train | epoch 643 | loss 2.478 | nll_loss 0.347 | ppl 1.27 | wps 23528.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31282 | lr 0.000178794 | gnorm 0.386 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 86746
2022-03-07 13:08:21 | INFO | fairseq.trainer | begin training epoch 644
2022-03-07 13:08:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:09:09 | INFO | train_inner | epoch 644:     18 / 49 loss=2.478, nll_loss=0.347, ppl=1.27, wps=23311, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=31300, lr=0.000178743, gnorm=0.387, loss_scale=32, train_wall=237, gb_free=8.8, wall=86793
2022-03-07 13:10:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:10:34 | INFO | valid | epoch 644 | valid on 'valid' subset | loss 13.439 | nll_loss 12.725 | ppl 6772.49 | wps 42269.4 | wpb 510.9 | bsz 1 | num_updates 31331 | best_loss 9.157
2022-03-07 13:10:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 644 @ 31331 updates
2022-03-07 13:10:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:10:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:10:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 644 @ 31331 updates, score 13.439) (writing took 2.5305809159763157 seconds)
2022-03-07 13:10:37 | INFO | fairseq_cli.train | end of epoch 644 (average epoch stats below)
2022-03-07 13:10:37 | INFO | train | epoch 644 | loss 2.477 | nll_loss 0.346 | ppl 1.27 | wps 23470.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31331 | lr 0.000178654 | gnorm 0.383 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 86881
2022-03-07 13:10:37 | INFO | fairseq.trainer | begin training epoch 645
2022-03-07 13:10:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:12:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:12:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:12:49 | INFO | valid | epoch 645 | valid on 'valid' subset | loss 13.393 | nll_loss 12.677 | ppl 6547.57 | wps 41888.1 | wpb 510.9 | bsz 1 | num_updates 31379 | best_loss 9.157
2022-03-07 13:12:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 645 @ 31379 updates
2022-03-07 13:12:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:12:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:12:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 645 @ 31379 updates, score 13.393) (writing took 2.3668970689177513 seconds)
2022-03-07 13:12:51 | INFO | fairseq_cli.train | end of epoch 645 (average epoch stats below)
2022-03-07 13:12:51 | INFO | train | epoch 645 | loss 2.477 | nll_loss 0.346 | ppl 1.27 | wps 23077.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 31379 | lr 0.000178517 | gnorm 0.385 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 87016
2022-03-07 13:12:51 | INFO | fairseq.trainer | begin training epoch 646
2022-03-07 13:12:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:13:47 | INFO | train_inner | epoch 646:     21 / 49 loss=2.477, nll_loss=0.347, ppl=1.27, wps=23334.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=31400, lr=0.000178458, gnorm=0.383, loss_scale=32, train_wall=237, gb_free=8.8, wall=87071
2022-03-07 13:14:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:15:04 | INFO | valid | epoch 646 | valid on 'valid' subset | loss 13.449 | nll_loss 12.743 | ppl 6855.18 | wps 41579.3 | wpb 510.9 | bsz 1 | num_updates 31428 | best_loss 9.157
2022-03-07 13:15:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 646 @ 31428 updates
2022-03-07 13:15:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:15:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:15:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 646 @ 31428 updates, score 13.449) (writing took 2.3505443362519145 seconds)
2022-03-07 13:15:06 | INFO | fairseq_cli.train | end of epoch 646 (average epoch stats below)
2022-03-07 13:15:06 | INFO | train | epoch 646 | loss 2.477 | nll_loss 0.347 | ppl 1.27 | wps 23530.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31428 | lr 0.000178378 | gnorm 0.385 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 87151
2022-03-07 13:15:06 | INFO | fairseq.trainer | begin training epoch 647
2022-03-07 13:15:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:17:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:17:19 | INFO | valid | epoch 647 | valid on 'valid' subset | loss 13.563 | nll_loss 12.867 | ppl 7471.76 | wps 41708.6 | wpb 510.9 | bsz 1 | num_updates 31477 | best_loss 9.157
2022-03-07 13:17:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 647 @ 31477 updates
2022-03-07 13:17:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:17:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:17:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 647 @ 31477 updates, score 13.563) (writing took 2.4191078948788345 seconds)
2022-03-07 13:17:22 | INFO | fairseq_cli.train | end of epoch 647 (average epoch stats below)
2022-03-07 13:17:22 | INFO | train | epoch 647 | loss 2.477 | nll_loss 0.346 | ppl 1.27 | wps 23521 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31477 | lr 0.000178239 | gnorm 0.381 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 87286
2022-03-07 13:17:22 | INFO | fairseq.trainer | begin training epoch 648
2022-03-07 13:17:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:18:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:18:25 | INFO | train_inner | epoch 648:     24 / 49 loss=2.477, nll_loss=0.346, ppl=1.27, wps=23318.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=31500, lr=0.000178174, gnorm=0.382, loss_scale=32, train_wall=237, gb_free=8.8, wall=87350
2022-03-07 13:19:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:19:34 | INFO | valid | epoch 648 | valid on 'valid' subset | loss 13.315 | nll_loss 12.598 | ppl 6199.29 | wps 41367.6 | wpb 510.9 | bsz 1 | num_updates 31525 | best_loss 9.157
2022-03-07 13:19:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 648 @ 31525 updates
2022-03-07 13:19:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:19:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:19:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 648 @ 31525 updates, score 13.315) (writing took 2.55715773627162 seconds)
2022-03-07 13:19:37 | INFO | fairseq_cli.train | end of epoch 648 (average epoch stats below)
2022-03-07 13:19:37 | INFO | train | epoch 648 | loss 2.477 | nll_loss 0.346 | ppl 1.27 | wps 23008 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 31525 | lr 0.000178103 | gnorm 0.384 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 87422
2022-03-07 13:19:37 | INFO | fairseq.trainer | begin training epoch 649
2022-03-07 13:19:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:21:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:21:49 | INFO | valid | epoch 649 | valid on 'valid' subset | loss 13.439 | nll_loss 12.732 | ppl 6802.72 | wps 41778.8 | wpb 510.9 | bsz 1 | num_updates 31574 | best_loss 9.157
2022-03-07 13:21:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 649 @ 31574 updates
2022-03-07 13:21:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:21:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:21:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 649 @ 31574 updates, score 13.439) (writing took 2.411343842279166 seconds)
2022-03-07 13:21:52 | INFO | fairseq_cli.train | end of epoch 649 (average epoch stats below)
2022-03-07 13:21:52 | INFO | train | epoch 649 | loss 2.477 | nll_loss 0.346 | ppl 1.27 | wps 23536.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31574 | lr 0.000177965 | gnorm 0.385 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 87557
2022-03-07 13:21:52 | INFO | fairseq.trainer | begin training epoch 650
2022-03-07 13:21:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:23:00 | INFO | train_inner | epoch 650:     26 / 49 loss=2.477, nll_loss=0.346, ppl=1.27, wps=23571.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=31600, lr=0.000177892, gnorm=0.384, loss_scale=32, train_wall=234, gb_free=8.8, wall=87625
2022-03-07 13:23:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:24:04 | INFO | valid | epoch 650 | valid on 'valid' subset | loss 13.481 | nll_loss 12.773 | ppl 7001.05 | wps 41731.8 | wpb 510.9 | bsz 1 | num_updates 31623 | best_loss 9.157
2022-03-07 13:24:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 650 @ 31623 updates
2022-03-07 13:24:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:24:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:24:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 650 @ 31623 updates, score 13.481) (writing took 2.3394580599851906 seconds)
2022-03-07 13:24:07 | INFO | fairseq_cli.train | end of epoch 650 (average epoch stats below)
2022-03-07 13:24:07 | INFO | train | epoch 650 | loss 2.476 | nll_loss 0.346 | ppl 1.27 | wps 23602.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31623 | lr 0.000177827 | gnorm 0.384 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 87691
2022-03-07 13:24:07 | INFO | fairseq.trainer | begin training epoch 651
2022-03-07 13:24:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:24:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:26:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:26:18 | INFO | valid | epoch 651 | valid on 'valid' subset | loss 13.377 | nll_loss 12.662 | ppl 6482.16 | wps 42921 | wpb 510.9 | bsz 1 | num_updates 31671 | best_loss 9.157
2022-03-07 13:26:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 651 @ 31671 updates
2022-03-07 13:26:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:26:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:26:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 651 @ 31671 updates, score 13.377) (writing took 2.433659364003688 seconds)
2022-03-07 13:26:21 | INFO | fairseq_cli.train | end of epoch 651 (average epoch stats below)
2022-03-07 13:26:21 | INFO | train | epoch 651 | loss 2.476 | nll_loss 0.345 | ppl 1.27 | wps 23215 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 31671 | lr 0.000177693 | gnorm 0.379 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 87825
2022-03-07 13:26:21 | INFO | fairseq.trainer | begin training epoch 652
2022-03-07 13:26:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:27:36 | INFO | train_inner | epoch 652:     29 / 49 loss=2.476, nll_loss=0.345, ppl=1.27, wps=23517.3, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=31700, lr=0.000177611, gnorm=0.384, loss_scale=32, train_wall=235, gb_free=8.8, wall=87901
2022-03-07 13:28:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:28:31 | INFO | valid | epoch 652 | valid on 'valid' subset | loss 13.5 | nll_loss 12.793 | ppl 7095.67 | wps 42729.9 | wpb 510.9 | bsz 1 | num_updates 31720 | best_loss 9.157
2022-03-07 13:28:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 652 @ 31720 updates
2022-03-07 13:28:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:28:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:28:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 652 @ 31720 updates, score 13.5) (writing took 2.3952061431482434 seconds)
2022-03-07 13:28:34 | INFO | fairseq_cli.train | end of epoch 652 (average epoch stats below)
2022-03-07 13:28:34 | INFO | train | epoch 652 | loss 2.475 | nll_loss 0.345 | ppl 1.27 | wps 23889.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 31720 | lr 0.000177555 | gnorm 0.384 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 87958
2022-03-07 13:28:34 | INFO | fairseq.trainer | begin training epoch 653
2022-03-07 13:28:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:29:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:30:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:30:44 | INFO | valid | epoch 653 | valid on 'valid' subset | loss 13.428 | nll_loss 12.715 | ppl 6725.26 | wps 42611.3 | wpb 510.9 | bsz 1 | num_updates 31768 | best_loss 9.157
2022-03-07 13:30:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 653 @ 31768 updates
2022-03-07 13:30:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:30:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 653 @ 31768 updates, score 13.428) (writing took 2.5008231112733483 seconds)
2022-03-07 13:30:47 | INFO | fairseq_cli.train | end of epoch 653 (average epoch stats below)
2022-03-07 13:30:47 | INFO | train | epoch 653 | loss 2.476 | nll_loss 0.346 | ppl 1.27 | wps 23419.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 31768 | lr 0.000177421 | gnorm 0.384 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 88091
2022-03-07 13:30:47 | INFO | fairseq.trainer | begin training epoch 654
2022-03-07 13:30:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:32:09 | INFO | train_inner | epoch 654:     32 / 49 loss=2.476, nll_loss=0.346, ppl=1.27, wps=23731.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=31800, lr=0.000177332, gnorm=0.387, loss_scale=32, train_wall=233, gb_free=8.8, wall=88174
2022-03-07 13:32:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:32:57 | INFO | valid | epoch 654 | valid on 'valid' subset | loss 13.406 | nll_loss 12.694 | ppl 6625.12 | wps 43127.9 | wpb 510.9 | bsz 1 | num_updates 31817 | best_loss 9.157
2022-03-07 13:32:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 654 @ 31817 updates
2022-03-07 13:32:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:32:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:32:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 654 @ 31817 updates, score 13.406) (writing took 2.3970890161581337 seconds)
2022-03-07 13:32:59 | INFO | fairseq_cli.train | end of epoch 654 (average epoch stats below)
2022-03-07 13:32:59 | INFO | train | epoch 654 | loss 2.475 | nll_loss 0.345 | ppl 1.27 | wps 23914.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 31817 | lr 0.000177284 | gnorm 0.391 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 88224
2022-03-07 13:32:59 | INFO | fairseq.trainer | begin training epoch 655
2022-03-07 13:32:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:35:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:35:10 | INFO | valid | epoch 655 | valid on 'valid' subset | loss 13.411 | nll_loss 12.701 | ppl 6656.64 | wps 42601.4 | wpb 510.9 | bsz 1 | num_updates 31866 | best_loss 9.157
2022-03-07 13:35:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 655 @ 31866 updates
2022-03-07 13:35:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:35:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:35:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 655 @ 31866 updates, score 13.411) (writing took 2.353761376813054 seconds)
2022-03-07 13:35:12 | INFO | fairseq_cli.train | end of epoch 655 (average epoch stats below)
2022-03-07 13:35:12 | INFO | train | epoch 655 | loss 2.475 | nll_loss 0.345 | ppl 1.27 | wps 23889.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 31866 | lr 0.000177148 | gnorm 0.38 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 88357
2022-03-07 13:35:12 | INFO | fairseq.trainer | begin training epoch 656
2022-03-07 13:35:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:35:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:36:44 | INFO | train_inner | epoch 656:     35 / 49 loss=2.475, nll_loss=0.345, ppl=1.27, wps=23613.4, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=31900, lr=0.000177054, gnorm=0.381, loss_scale=32, train_wall=234, gb_free=8.8, wall=88449
2022-03-07 13:37:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:37:25 | INFO | valid | epoch 656 | valid on 'valid' subset | loss 13.433 | nll_loss 12.727 | ppl 6777.63 | wps 41924 | wpb 510.9 | bsz 1 | num_updates 31914 | best_loss 9.157
2022-03-07 13:37:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 656 @ 31914 updates
2022-03-07 13:37:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:37:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:37:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 656 @ 31914 updates, score 13.433) (writing took 2.416666739154607 seconds)
2022-03-07 13:37:27 | INFO | fairseq_cli.train | end of epoch 656 (average epoch stats below)
2022-03-07 13:37:27 | INFO | train | epoch 656 | loss 2.474 | nll_loss 0.344 | ppl 1.27 | wps 23110.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 31914 | lr 0.000177015 | gnorm 0.383 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 88492
2022-03-07 13:37:27 | INFO | fairseq.trainer | begin training epoch 657
2022-03-07 13:37:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:39:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:39:40 | INFO | valid | epoch 657 | valid on 'valid' subset | loss 13.457 | nll_loss 12.751 | ppl 6892.19 | wps 41222.3 | wpb 510.9 | bsz 1 | num_updates 31963 | best_loss 9.157
2022-03-07 13:39:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 657 @ 31963 updates
2022-03-07 13:39:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:39:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:39:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 657 @ 31963 updates, score 13.457) (writing took 2.4554015258327127 seconds)
2022-03-07 13:39:43 | INFO | fairseq_cli.train | end of epoch 657 (average epoch stats below)
2022-03-07 13:39:43 | INFO | train | epoch 657 | loss 2.475 | nll_loss 0.345 | ppl 1.27 | wps 23434.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31963 | lr 0.000176879 | gnorm 0.381 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 88627
2022-03-07 13:39:43 | INFO | fairseq.trainer | begin training epoch 658
2022-03-07 13:39:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:41:20 | INFO | train_inner | epoch 658:     37 / 49 loss=2.474, nll_loss=0.345, ppl=1.27, wps=23478.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=32000, lr=0.000176777, gnorm=0.384, loss_scale=32, train_wall=236, gb_free=8.8, wall=88725
2022-03-07 13:41:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:41:56 | INFO | valid | epoch 658 | valid on 'valid' subset | loss 13.42 | nll_loss 12.71 | ppl 6701.22 | wps 41136.6 | wpb 510.9 | bsz 1 | num_updates 32012 | best_loss 9.157
2022-03-07 13:41:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 658 @ 32012 updates
2022-03-07 13:41:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:41:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:41:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 658 @ 32012 updates, score 13.42) (writing took 2.3967359410598874 seconds)
2022-03-07 13:41:58 | INFO | fairseq_cli.train | end of epoch 658 (average epoch stats below)
2022-03-07 13:41:58 | INFO | train | epoch 658 | loss 2.474 | nll_loss 0.344 | ppl 1.27 | wps 23435 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32012 | lr 0.000176744 | gnorm 0.385 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 88763
2022-03-07 13:41:58 | INFO | fairseq.trainer | begin training epoch 659
2022-03-07 13:41:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:42:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:44:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:44:11 | INFO | valid | epoch 659 | valid on 'valid' subset | loss 13.516 | nll_loss 12.815 | ppl 7205.66 | wps 41978.1 | wpb 510.9 | bsz 1 | num_updates 32060 | best_loss 9.157
2022-03-07 13:44:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 659 @ 32060 updates
2022-03-07 13:44:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:44:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:44:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 659 @ 32060 updates, score 13.516) (writing took 2.488536010030657 seconds)
2022-03-07 13:44:14 | INFO | fairseq_cli.train | end of epoch 659 (average epoch stats below)
2022-03-07 13:44:14 | INFO | train | epoch 659 | loss 2.474 | nll_loss 0.344 | ppl 1.27 | wps 23027.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 32060 | lr 0.000176611 | gnorm 0.381 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 88898
2022-03-07 13:44:14 | INFO | fairseq.trainer | begin training epoch 660
2022-03-07 13:44:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:45:59 | INFO | train_inner | epoch 660:     40 / 49 loss=2.474, nll_loss=0.344, ppl=1.27, wps=23301.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=32100, lr=0.000176501, gnorm=0.38, loss_scale=32, train_wall=237, gb_free=8.8, wall=89003
2022-03-07 13:46:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:46:26 | INFO | valid | epoch 660 | valid on 'valid' subset | loss 13.419 | nll_loss 12.713 | ppl 6712.22 | wps 41739 | wpb 510.9 | bsz 1 | num_updates 32109 | best_loss 9.157
2022-03-07 13:46:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 660 @ 32109 updates
2022-03-07 13:46:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:46:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:46:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 660 @ 32109 updates, score 13.419) (writing took 2.477508878801018 seconds)
2022-03-07 13:46:29 | INFO | fairseq_cli.train | end of epoch 660 (average epoch stats below)
2022-03-07 13:46:29 | INFO | train | epoch 660 | loss 2.474 | nll_loss 0.344 | ppl 1.27 | wps 23495.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32109 | lr 0.000176476 | gnorm 0.38 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 89034
2022-03-07 13:46:29 | INFO | fairseq.trainer | begin training epoch 661
2022-03-07 13:46:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:48:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:48:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:48:42 | INFO | valid | epoch 661 | valid on 'valid' subset | loss 13.525 | nll_loss 12.826 | ppl 7259.31 | wps 41638.8 | wpb 510.9 | bsz 1 | num_updates 32157 | best_loss 9.157
2022-03-07 13:48:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 661 @ 32157 updates
2022-03-07 13:48:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:48:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:48:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 661 @ 32157 updates, score 13.525) (writing took 2.3993710088543594 seconds)
2022-03-07 13:48:44 | INFO | fairseq_cli.train | end of epoch 661 (average epoch stats below)
2022-03-07 13:48:44 | INFO | train | epoch 661 | loss 2.473 | nll_loss 0.343 | ppl 1.27 | wps 22971.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 32157 | lr 0.000176345 | gnorm 0.381 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 89169
2022-03-07 13:48:44 | INFO | fairseq.trainer | begin training epoch 662
2022-03-07 13:48:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:50:38 | INFO | train_inner | epoch 662:     43 / 49 loss=2.473, nll_loss=0.344, ppl=1.27, wps=23260.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=32200, lr=0.000176227, gnorm=0.383, loss_scale=32, train_wall=238, gb_free=8.8, wall=89282
2022-03-07 13:50:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:50:58 | INFO | valid | epoch 662 | valid on 'valid' subset | loss 13.386 | nll_loss 12.674 | ppl 6532.99 | wps 39919.3 | wpb 510.9 | bsz 1 | num_updates 32206 | best_loss 9.157
2022-03-07 13:50:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 662 @ 32206 updates
2022-03-07 13:50:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:51:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:51:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 662 @ 32206 updates, score 13.386) (writing took 2.5059777782298625 seconds)
2022-03-07 13:51:00 | INFO | fairseq_cli.train | end of epoch 662 (average epoch stats below)
2022-03-07 13:51:00 | INFO | train | epoch 662 | loss 2.474 | nll_loss 0.344 | ppl 1.27 | wps 23405.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32206 | lr 0.00017621 | gnorm 0.386 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 89305
2022-03-07 13:51:00 | INFO | fairseq.trainer | begin training epoch 663
2022-03-07 13:51:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:53:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:53:13 | INFO | valid | epoch 663 | valid on 'valid' subset | loss 13.491 | nll_loss 12.789 | ppl 7075.53 | wps 41254 | wpb 510.9 | bsz 1 | num_updates 32255 | best_loss 9.157
2022-03-07 13:53:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 663 @ 32255 updates
2022-03-07 13:53:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:53:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:53:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 663 @ 32255 updates, score 13.491) (writing took 2.409926568157971 seconds)
2022-03-07 13:53:15 | INFO | fairseq_cli.train | end of epoch 663 (average epoch stats below)
2022-03-07 13:53:15 | INFO | train | epoch 663 | loss 2.474 | nll_loss 0.344 | ppl 1.27 | wps 23489.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32255 | lr 0.000176077 | gnorm 0.383 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 89440
2022-03-07 13:53:15 | INFO | fairseq.trainer | begin training epoch 664
2022-03-07 13:53:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:54:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:55:16 | INFO | train_inner | epoch 664:     46 / 49 loss=2.473, nll_loss=0.344, ppl=1.27, wps=23272.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=32300, lr=0.000175954, gnorm=0.385, loss_scale=32, train_wall=237, gb_free=8.8, wall=89561
2022-03-07 13:55:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:55:28 | INFO | valid | epoch 664 | valid on 'valid' subset | loss 13.61 | nll_loss 12.916 | ppl 7729.8 | wps 41631.8 | wpb 510.9 | bsz 1 | num_updates 32303 | best_loss 9.157
2022-03-07 13:55:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 664 @ 32303 updates
2022-03-07 13:55:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:55:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:55:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 664 @ 32303 updates, score 13.61) (writing took 2.4920492148958147 seconds)
2022-03-07 13:55:31 | INFO | fairseq_cli.train | end of epoch 664 (average epoch stats below)
2022-03-07 13:55:31 | INFO | train | epoch 664 | loss 2.473 | nll_loss 0.344 | ppl 1.27 | wps 23000 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 32303 | lr 0.000175946 | gnorm 0.386 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 89575
2022-03-07 13:55:31 | INFO | fairseq.trainer | begin training epoch 665
2022-03-07 13:55:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:57:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:57:44 | INFO | valid | epoch 665 | valid on 'valid' subset | loss 13.55 | nll_loss 12.857 | ppl 7418.36 | wps 41081.3 | wpb 510.9 | bsz 1 | num_updates 32352 | best_loss 9.157
2022-03-07 13:57:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 665 @ 32352 updates
2022-03-07 13:57:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:57:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:57:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 665 @ 32352 updates, score 13.55) (writing took 2.39349761698395 seconds)
2022-03-07 13:57:46 | INFO | fairseq_cli.train | end of epoch 665 (average epoch stats below)
2022-03-07 13:57:46 | INFO | train | epoch 665 | loss 2.472 | nll_loss 0.343 | ppl 1.27 | wps 23500.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32352 | lr 0.000175812 | gnorm 0.385 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 89711
2022-03-07 13:57:46 | INFO | fairseq.trainer | begin training epoch 666
2022-03-07 13:57:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:59:51 | INFO | train_inner | epoch 666:     48 / 49 loss=2.472, nll_loss=0.343, ppl=1.27, wps=23582.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=32400, lr=0.000175682, gnorm=0.385, loss_scale=32, train_wall=234, gb_free=8.8, wall=89836
2022-03-07 13:59:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:59:58 | INFO | valid | epoch 666 | valid on 'valid' subset | loss 13.487 | nll_loss 12.788 | ppl 7073.47 | wps 42397 | wpb 510.9 | bsz 1 | num_updates 32401 | best_loss 9.157
2022-03-07 13:59:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 666 @ 32401 updates
2022-03-07 13:59:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:00:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:00:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 666 @ 32401 updates, score 13.487) (writing took 2.425523435231298 seconds)
2022-03-07 14:00:00 | INFO | fairseq_cli.train | end of epoch 666 (average epoch stats below)
2022-03-07 14:00:00 | INFO | train | epoch 666 | loss 2.472 | nll_loss 0.343 | ppl 1.27 | wps 23644.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32401 | lr 0.000175679 | gnorm 0.384 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 89845
2022-03-07 14:00:00 | INFO | fairseq.trainer | begin training epoch 667
2022-03-07 14:00:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:00:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:02:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:02:11 | INFO | valid | epoch 667 | valid on 'valid' subset | loss 13.464 | nll_loss 12.758 | ppl 6928.07 | wps 42845 | wpb 510.9 | bsz 1 | num_updates 32449 | best_loss 9.157
2022-03-07 14:02:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 667 @ 32449 updates
2022-03-07 14:02:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:02:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:02:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 667 @ 32449 updates, score 13.464) (writing took 2.4965535062365234 seconds)
2022-03-07 14:02:13 | INFO | fairseq_cli.train | end of epoch 667 (average epoch stats below)
2022-03-07 14:02:13 | INFO | train | epoch 667 | loss 2.472 | nll_loss 0.343 | ppl 1.27 | wps 23415.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 32449 | lr 0.000175549 | gnorm 0.382 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 89978
2022-03-07 14:02:13 | INFO | fairseq.trainer | begin training epoch 668
2022-03-07 14:02:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:04:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:04:24 | INFO | valid | epoch 668 | valid on 'valid' subset | loss 13.491 | nll_loss 12.79 | ppl 7081.14 | wps 42326.5 | wpb 510.9 | bsz 1 | num_updates 32498 | best_loss 9.157
2022-03-07 14:04:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 668 @ 32498 updates
2022-03-07 14:04:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:04:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:04:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 668 @ 32498 updates, score 13.491) (writing took 2.4166626622900367 seconds)
2022-03-07 14:04:26 | INFO | fairseq_cli.train | end of epoch 668 (average epoch stats below)
2022-03-07 14:04:26 | INFO | train | epoch 668 | loss 2.472 | nll_loss 0.343 | ppl 1.27 | wps 23922.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 32498 | lr 0.000175417 | gnorm 0.382 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 90111
2022-03-07 14:04:26 | INFO | fairseq.trainer | begin training epoch 669
2022-03-07 14:04:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:04:31 | INFO | train_inner | epoch 669:      2 / 49 loss=2.472, nll_loss=0.343, ppl=1.27, wps=23054.3, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=32500, lr=0.000175412, gnorm=0.383, loss_scale=32, train_wall=232, gb_free=8.8, wall=90116
2022-03-07 14:06:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:06:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:06:37 | INFO | valid | epoch 669 | valid on 'valid' subset | loss 13.481 | nll_loss 12.78 | ppl 7034.81 | wps 42451.3 | wpb 510.9 | bsz 1 | num_updates 32546 | best_loss 9.157
2022-03-07 14:06:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 669 @ 32546 updates
2022-03-07 14:06:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:06:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:06:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 669 @ 32546 updates, score 13.481) (writing took 2.3769641192629933 seconds)
2022-03-07 14:06:39 | INFO | fairseq_cli.train | end of epoch 669 (average epoch stats below)
2022-03-07 14:06:39 | INFO | train | epoch 669 | loss 2.471 | nll_loss 0.342 | ppl 1.27 | wps 23438.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 32546 | lr 0.000175288 | gnorm 0.379 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 90244
2022-03-07 14:06:39 | INFO | fairseq.trainer | begin training epoch 670
2022-03-07 14:06:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:08:49 | INFO | valid | epoch 670 | valid on 'valid' subset | loss 13.532 | nll_loss 12.837 | ppl 7317.21 | wps 42917.1 | wpb 510.9 | bsz 1 | num_updates 32595 | best_loss 9.157
2022-03-07 14:08:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 670 @ 32595 updates
2022-03-07 14:08:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:08:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:08:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 670 @ 32595 updates, score 13.532) (writing took 2.385268404148519 seconds)
2022-03-07 14:08:52 | INFO | fairseq_cli.train | end of epoch 670 (average epoch stats below)
2022-03-07 14:08:52 | INFO | train | epoch 670 | loss 2.471 | nll_loss 0.342 | ppl 1.27 | wps 23960.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 32595 | lr 0.000175156 | gnorm 0.379 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 90376
2022-03-07 14:08:52 | INFO | fairseq.trainer | begin training epoch 671
2022-03-07 14:08:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:09:05 | INFO | train_inner | epoch 671:      5 / 49 loss=2.471, nll_loss=0.342, ppl=1.27, wps=23747.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=32600, lr=0.000175142, gnorm=0.379, loss_scale=32, train_wall=233, gb_free=8.8, wall=90389
2022-03-07 14:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:11:02 | INFO | valid | epoch 671 | valid on 'valid' subset | loss 13.444 | nll_loss 12.737 | ppl 6828.7 | wps 40627.4 | wpb 510.9 | bsz 1 | num_updates 32644 | best_loss 9.157
2022-03-07 14:11:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 671 @ 32644 updates
2022-03-07 14:11:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:11:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:11:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 671 @ 32644 updates, score 13.444) (writing took 2.3869445407763124 seconds)
2022-03-07 14:11:05 | INFO | fairseq_cli.train | end of epoch 671 (average epoch stats below)
2022-03-07 14:11:05 | INFO | train | epoch 671 | loss 2.471 | nll_loss 0.342 | ppl 1.27 | wps 23853.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 32644 | lr 0.000175024 | gnorm 0.384 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 90510
2022-03-07 14:11:05 | INFO | fairseq.trainer | begin training epoch 672
2022-03-07 14:11:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:12:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:13:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:13:16 | INFO | valid | epoch 672 | valid on 'valid' subset | loss 13.591 | nll_loss 12.897 | ppl 7628.61 | wps 41218.3 | wpb 510.9 | bsz 1 | num_updates 32692 | best_loss 9.157
2022-03-07 14:13:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 672 @ 32692 updates
2022-03-07 14:13:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:13:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:13:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 672 @ 32692 updates, score 13.591) (writing took 2.3790488317608833 seconds)
2022-03-07 14:13:18 | INFO | fairseq_cli.train | end of epoch 672 (average epoch stats below)
2022-03-07 14:13:18 | INFO | train | epoch 672 | loss 2.471 | nll_loss 0.343 | ppl 1.27 | wps 23364.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 32692 | lr 0.000174896 | gnorm 0.384 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 90643
2022-03-07 14:13:18 | INFO | fairseq.trainer | begin training epoch 673
2022-03-07 14:13:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:13:39 | INFO | train_inner | epoch 673:      8 / 49 loss=2.471, nll_loss=0.342, ppl=1.27, wps=23624.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=32700, lr=0.000174874, gnorm=0.384, loss_scale=32, train_wall=234, gb_free=8.8, wall=90664
2022-03-07 14:15:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:15:31 | INFO | valid | epoch 673 | valid on 'valid' subset | loss 13.412 | nll_loss 12.701 | ppl 6656.29 | wps 41322.5 | wpb 510.9 | bsz 1 | num_updates 32741 | best_loss 9.157
2022-03-07 14:15:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 673 @ 32741 updates
2022-03-07 14:15:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:15:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:15:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 673 @ 32741 updates, score 13.412) (writing took 2.374494519084692 seconds)
2022-03-07 14:15:33 | INFO | fairseq_cli.train | end of epoch 673 (average epoch stats below)
2022-03-07 14:15:33 | INFO | train | epoch 673 | loss 2.472 | nll_loss 0.343 | ppl 1.27 | wps 23471.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32741 | lr 0.000174765 | gnorm 0.388 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 90778
2022-03-07 14:15:33 | INFO | fairseq.trainer | begin training epoch 674
2022-03-07 14:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:17:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:17:46 | INFO | valid | epoch 674 | valid on 'valid' subset | loss 13.522 | nll_loss 12.827 | ppl 7264.86 | wps 41904.8 | wpb 510.9 | bsz 1 | num_updates 32790 | best_loss 9.157
2022-03-07 14:17:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 674 @ 32790 updates
2022-03-07 14:17:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:17:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:17:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 674 @ 32790 updates, score 13.522) (writing took 2.450206310953945 seconds)
2022-03-07 14:17:49 | INFO | fairseq_cli.train | end of epoch 674 (average epoch stats below)
2022-03-07 14:17:49 | INFO | train | epoch 674 | loss 2.47 | nll_loss 0.341 | ppl 1.27 | wps 23504.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32790 | lr 0.000174634 | gnorm 0.379 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 90913
2022-03-07 14:17:49 | INFO | fairseq.trainer | begin training epoch 675
2022-03-07 14:17:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:18:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:18:17 | INFO | train_inner | epoch 675:     11 / 49 loss=2.471, nll_loss=0.342, ppl=1.27, wps=23307.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=32800, lr=0.000174608, gnorm=0.382, loss_scale=32, train_wall=237, gb_free=8.8, wall=90942
2022-03-07 14:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:20:01 | INFO | valid | epoch 675 | valid on 'valid' subset | loss 13.564 | nll_loss 12.867 | ppl 7471.84 | wps 41977.3 | wpb 510.9 | bsz 1 | num_updates 32838 | best_loss 9.157
2022-03-07 14:20:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 675 @ 32838 updates
2022-03-07 14:20:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:20:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:20:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 675 @ 32838 updates, score 13.564) (writing took 2.4693161118775606 seconds)
2022-03-07 14:20:04 | INFO | fairseq_cli.train | end of epoch 675 (average epoch stats below)
2022-03-07 14:20:04 | INFO | train | epoch 675 | loss 2.47 | nll_loss 0.341 | ppl 1.27 | wps 23043.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 32838 | lr 0.000174507 | gnorm 0.378 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 91048
2022-03-07 14:20:04 | INFO | fairseq.trainer | begin training epoch 676
2022-03-07 14:20:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:22:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:22:17 | INFO | valid | epoch 676 | valid on 'valid' subset | loss 13.498 | nll_loss 12.795 | ppl 7106.02 | wps 41260.9 | wpb 510.9 | bsz 1 | num_updates 32887 | best_loss 9.157
2022-03-07 14:22:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 676 @ 32887 updates
2022-03-07 14:22:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:22:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:22:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 676 @ 32887 updates, score 13.498) (writing took 2.581044795922935 seconds)
2022-03-07 14:22:19 | INFO | fairseq_cli.train | end of epoch 676 (average epoch stats below)
2022-03-07 14:22:19 | INFO | train | epoch 676 | loss 2.47 | nll_loss 0.341 | ppl 1.27 | wps 23434.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32887 | lr 0.000174376 | gnorm 0.383 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 91184
2022-03-07 14:22:19 | INFO | fairseq.trainer | begin training epoch 677
2022-03-07 14:22:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:22:53 | INFO | train_inner | epoch 677:     13 / 49 loss=2.47, nll_loss=0.341, ppl=1.27, wps=23503.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=32900, lr=0.000174342, gnorm=0.382, loss_scale=32, train_wall=235, gb_free=8.8, wall=91218
2022-03-07 14:24:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:24:32 | INFO | valid | epoch 677 | valid on 'valid' subset | loss 13.515 | nll_loss 12.813 | ppl 7196.21 | wps 40989.1 | wpb 510.9 | bsz 1 | num_updates 32936 | best_loss 9.157
2022-03-07 14:24:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 677 @ 32936 updates
2022-03-07 14:24:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:24:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:24:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 677 @ 32936 updates, score 13.515) (writing took 2.4010697919875383 seconds)
2022-03-07 14:24:35 | INFO | fairseq_cli.train | end of epoch 677 (average epoch stats below)
2022-03-07 14:24:35 | INFO | train | epoch 677 | loss 2.47 | nll_loss 0.341 | ppl 1.27 | wps 23477 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32936 | lr 0.000174247 | gnorm 0.384 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 91319
2022-03-07 14:24:35 | INFO | fairseq.trainer | begin training epoch 678
2022-03-07 14:24:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:24:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:26:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:26:48 | INFO | valid | epoch 678 | valid on 'valid' subset | loss 13.447 | nll_loss 12.74 | ppl 6842.31 | wps 41682.5 | wpb 510.9 | bsz 1 | num_updates 32984 | best_loss 9.157
2022-03-07 14:26:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 678 @ 32984 updates
2022-03-07 14:26:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:26:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:26:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 678 @ 32984 updates, score 13.447) (writing took 2.4970044516958296 seconds)
2022-03-07 14:26:50 | INFO | fairseq_cli.train | end of epoch 678 (average epoch stats below)
2022-03-07 14:26:50 | INFO | train | epoch 678 | loss 2.47 | nll_loss 0.341 | ppl 1.27 | wps 22976.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 32984 | lr 0.00017412 | gnorm 0.384 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 91455
2022-03-07 14:26:50 | INFO | fairseq.trainer | begin training epoch 679
2022-03-07 14:26:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:27:32 | INFO | train_inner | epoch 679:     16 / 49 loss=2.47, nll_loss=0.341, ppl=1.27, wps=23284.7, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=33000, lr=0.000174078, gnorm=0.383, loss_scale=32, train_wall=237, gb_free=8.8, wall=91497
2022-03-07 14:28:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:29:03 | INFO | valid | epoch 679 | valid on 'valid' subset | loss 13.415 | nll_loss 12.703 | ppl 6666.95 | wps 41340.1 | wpb 510.9 | bsz 1 | num_updates 33033 | best_loss 9.157
2022-03-07 14:29:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 679 @ 33033 updates
2022-03-07 14:29:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:29:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:29:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 679 @ 33033 updates, score 13.415) (writing took 2.3692175769247115 seconds)
2022-03-07 14:29:05 | INFO | fairseq_cli.train | end of epoch 679 (average epoch stats below)
2022-03-07 14:29:05 | INFO | train | epoch 679 | loss 2.47 | nll_loss 0.341 | ppl 1.27 | wps 23498.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33033 | lr 0.000173991 | gnorm 0.38 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 91590
2022-03-07 14:29:05 | INFO | fairseq.trainer | begin training epoch 680
2022-03-07 14:29:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:30:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:31:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:31:18 | INFO | valid | epoch 680 | valid on 'valid' subset | loss 13.518 | nll_loss 12.821 | ppl 7238.16 | wps 41110.4 | wpb 510.9 | bsz 1 | num_updates 33081 | best_loss 9.157
2022-03-07 14:31:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 680 @ 33081 updates
2022-03-07 14:31:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:31:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:31:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 680 @ 33081 updates, score 13.518) (writing took 2.4833152508363128 seconds)
2022-03-07 14:31:21 | INFO | fairseq_cli.train | end of epoch 680 (average epoch stats below)
2022-03-07 14:31:21 | INFO | train | epoch 680 | loss 2.469 | nll_loss 0.34 | ppl 1.27 | wps 22991.4 | ups 0.35 | wpb 64853.3 | bsz 126.7 | num_updates 33081 | lr 0.000173864 | gnorm 0.38 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 91726
2022-03-07 14:31:21 | INFO | fairseq.trainer | begin training epoch 681
2022-03-07 14:31:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:32:11 | INFO | train_inner | epoch 681:     19 / 49 loss=2.469, nll_loss=0.341, ppl=1.27, wps=23260.8, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=33100, lr=0.000173814, gnorm=0.379, loss_scale=32, train_wall=238, gb_free=8.8, wall=91776
2022-03-07 14:33:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:33:34 | INFO | valid | epoch 681 | valid on 'valid' subset | loss 13.465 | nll_loss 12.761 | ppl 6939.29 | wps 40998.6 | wpb 510.9 | bsz 1 | num_updates 33130 | best_loss 9.157
2022-03-07 14:33:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 681 @ 33130 updates
2022-03-07 14:33:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:33:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:33:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 681 @ 33130 updates, score 13.465) (writing took 2.376196968834847 seconds)
2022-03-07 14:33:36 | INFO | fairseq_cli.train | end of epoch 681 (average epoch stats below)
2022-03-07 14:33:36 | INFO | train | epoch 681 | loss 2.469 | nll_loss 0.341 | ppl 1.27 | wps 23445.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33130 | lr 0.000173736 | gnorm 0.382 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 91861
2022-03-07 14:33:36 | INFO | fairseq.trainer | begin training epoch 682
2022-03-07 14:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:35:49 | INFO | valid | epoch 682 | valid on 'valid' subset | loss 13.533 | nll_loss 12.837 | ppl 7317.38 | wps 41758.4 | wpb 510.9 | bsz 1 | num_updates 33179 | best_loss 9.157
2022-03-07 14:35:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 682 @ 33179 updates
2022-03-07 14:35:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:35:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:35:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 682 @ 33179 updates, score 13.533) (writing took 2.3243288449011743 seconds)
2022-03-07 14:35:51 | INFO | fairseq_cli.train | end of epoch 682 (average epoch stats below)
2022-03-07 14:35:51 | INFO | train | epoch 682 | loss 2.469 | nll_loss 0.341 | ppl 1.27 | wps 23510.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33179 | lr 0.000173607 | gnorm 0.384 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 91996
2022-03-07 14:35:51 | INFO | fairseq.trainer | begin training epoch 683
2022-03-07 14:35:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:36:46 | INFO | train_inner | epoch 683:     21 / 49 loss=2.469, nll_loss=0.34, ppl=1.27, wps=23585.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=33200, lr=0.000173553, gnorm=0.382, loss_scale=64, train_wall=235, gb_free=8.8, wall=92051
2022-03-07 14:36:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:37:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:38:02 | INFO | valid | epoch 683 | valid on 'valid' subset | loss 13.398 | nll_loss 12.684 | ppl 6580.54 | wps 42937.4 | wpb 510.9 | bsz 1 | num_updates 33227 | best_loss 9.157
2022-03-07 14:38:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 683 @ 33227 updates
2022-03-07 14:38:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:38:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:38:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 683 @ 33227 updates, score 13.398) (writing took 2.2769916760735214 seconds)
2022-03-07 14:38:05 | INFO | fairseq_cli.train | end of epoch 683 (average epoch stats below)
2022-03-07 14:38:05 | INFO | train | epoch 683 | loss 2.468 | nll_loss 0.34 | ppl 1.27 | wps 23363.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 33227 | lr 0.000173482 | gnorm 0.375 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 92129
2022-03-07 14:38:05 | INFO | fairseq.trainer | begin training epoch 684
2022-03-07 14:38:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:40:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:40:15 | INFO | valid | epoch 684 | valid on 'valid' subset | loss 13.456 | nll_loss 12.752 | ppl 6898.53 | wps 43436.2 | wpb 510.9 | bsz 1 | num_updates 33276 | best_loss 9.157
2022-03-07 14:40:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 684 @ 33276 updates
2022-03-07 14:40:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:40:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:40:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 684 @ 33276 updates, score 13.456) (writing took 2.4300480191595852 seconds)
2022-03-07 14:40:18 | INFO | fairseq_cli.train | end of epoch 684 (average epoch stats below)
2022-03-07 14:40:18 | INFO | train | epoch 684 | loss 2.468 | nll_loss 0.34 | ppl 1.27 | wps 23902.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 33276 | lr 0.000173354 | gnorm 0.381 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 92262
2022-03-07 14:40:18 | INFO | fairseq.trainer | begin training epoch 685
2022-03-07 14:40:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:41:20 | INFO | train_inner | epoch 685:     24 / 49 loss=2.468, nll_loss=0.34, ppl=1.27, wps=23691.6, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=33300, lr=0.000173292, gnorm=0.379, loss_scale=32, train_wall=234, gb_free=8.8, wall=92325
2022-03-07 14:42:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:42:28 | INFO | valid | epoch 685 | valid on 'valid' subset | loss 13.462 | nll_loss 12.753 | ppl 6903.73 | wps 42856 | wpb 510.9 | bsz 1 | num_updates 33325 | best_loss 9.157
2022-03-07 14:42:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 685 @ 33325 updates
2022-03-07 14:42:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:42:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:42:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 685 @ 33325 updates, score 13.462) (writing took 2.446120081935078 seconds)
2022-03-07 14:42:31 | INFO | fairseq_cli.train | end of epoch 685 (average epoch stats below)
2022-03-07 14:42:31 | INFO | train | epoch 685 | loss 2.468 | nll_loss 0.34 | ppl 1.27 | wps 23892.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 33325 | lr 0.000173227 | gnorm 0.38 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 92395
2022-03-07 14:42:31 | INFO | fairseq.trainer | begin training epoch 686
2022-03-07 14:42:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:42:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:44:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:44:41 | INFO | valid | epoch 686 | valid on 'valid' subset | loss 13.449 | nll_loss 12.745 | ppl 6865.08 | wps 43002.8 | wpb 510.9 | bsz 1 | num_updates 33373 | best_loss 9.157
2022-03-07 14:44:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 686 @ 33373 updates
2022-03-07 14:44:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:44:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:44:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 686 @ 33373 updates, score 13.449) (writing took 2.376288121100515 seconds)
2022-03-07 14:44:43 | INFO | fairseq_cli.train | end of epoch 686 (average epoch stats below)
2022-03-07 14:44:43 | INFO | train | epoch 686 | loss 2.468 | nll_loss 0.34 | ppl 1.27 | wps 23444.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 33373 | lr 0.000173102 | gnorm 0.384 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 92528
2022-03-07 14:44:43 | INFO | fairseq.trainer | begin training epoch 687
2022-03-07 14:44:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:45:53 | INFO | train_inner | epoch 687:     27 / 49 loss=2.468, nll_loss=0.34, ppl=1.27, wps=23740, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=33400, lr=0.000173032, gnorm=0.382, loss_scale=32, train_wall=233, gb_free=8.8, wall=92598
2022-03-07 14:46:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:46:54 | INFO | valid | epoch 687 | valid on 'valid' subset | loss 13.497 | nll_loss 12.797 | ppl 7117.83 | wps 43831.6 | wpb 510.9 | bsz 1 | num_updates 33422 | best_loss 9.157
2022-03-07 14:46:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 687 @ 33422 updates
2022-03-07 14:46:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:46:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:46:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 687 @ 33422 updates, score 13.497) (writing took 2.4595224922522902 seconds)
2022-03-07 14:46:56 | INFO | fairseq_cli.train | end of epoch 687 (average epoch stats below)
2022-03-07 14:46:56 | INFO | train | epoch 687 | loss 2.468 | nll_loss 0.34 | ppl 1.27 | wps 23935.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 33422 | lr 0.000172975 | gnorm 0.378 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 92661
2022-03-07 14:46:56 | INFO | fairseq.trainer | begin training epoch 688
2022-03-07 14:46:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:48:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:49:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:49:07 | INFO | valid | epoch 688 | valid on 'valid' subset | loss 13.512 | nll_loss 12.813 | ppl 7197.96 | wps 43039 | wpb 510.9 | bsz 1 | num_updates 33470 | best_loss 9.157
2022-03-07 14:49:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 688 @ 33470 updates
2022-03-07 14:49:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:49:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:49:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 688 @ 33470 updates, score 13.512) (writing took 2.371364865452051 seconds)
2022-03-07 14:49:09 | INFO | fairseq_cli.train | end of epoch 688 (average epoch stats below)
2022-03-07 14:49:09 | INFO | train | epoch 688 | loss 2.468 | nll_loss 0.34 | ppl 1.27 | wps 23430.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 33470 | lr 0.000172851 | gnorm 0.384 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 92794
2022-03-07 14:49:09 | INFO | fairseq.trainer | begin training epoch 689
2022-03-07 14:49:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:50:27 | INFO | train_inner | epoch 689:     30 / 49 loss=2.468, nll_loss=0.34, ppl=1.27, wps=23655.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=33500, lr=0.000172774, gnorm=0.381, loss_scale=32, train_wall=234, gb_free=8.8, wall=92872
2022-03-07 14:51:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:51:21 | INFO | valid | epoch 689 | valid on 'valid' subset | loss 13.549 | nll_loss 12.852 | ppl 7394.76 | wps 41862.6 | wpb 510.9 | bsz 1 | num_updates 33519 | best_loss 9.157
2022-03-07 14:51:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 689 @ 33519 updates
2022-03-07 14:51:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:51:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:51:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 689 @ 33519 updates, score 13.549) (writing took 2.5387866753153503 seconds)
2022-03-07 14:51:24 | INFO | fairseq_cli.train | end of epoch 689 (average epoch stats below)
2022-03-07 14:51:24 | INFO | train | epoch 689 | loss 2.467 | nll_loss 0.339 | ppl 1.27 | wps 23600.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33519 | lr 0.000172725 | gnorm 0.375 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 92928
2022-03-07 14:51:24 | INFO | fairseq.trainer | begin training epoch 690
2022-03-07 14:51:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:53:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:53:37 | INFO | valid | epoch 690 | valid on 'valid' subset | loss 13.527 | nll_loss 12.823 | ppl 7246.97 | wps 41103.2 | wpb 510.9 | bsz 1 | num_updates 33568 | best_loss 9.157
2022-03-07 14:53:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 690 @ 33568 updates
2022-03-07 14:53:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:53:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:53:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 690 @ 33568 updates, score 13.527) (writing took 2.397013919893652 seconds)
2022-03-07 14:53:39 | INFO | fairseq_cli.train | end of epoch 690 (average epoch stats below)
2022-03-07 14:53:39 | INFO | train | epoch 690 | loss 2.467 | nll_loss 0.339 | ppl 1.26 | wps 23445.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33568 | lr 0.000172599 | gnorm 0.383 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 93064
2022-03-07 14:53:39 | INFO | fairseq.trainer | begin training epoch 691
2022-03-07 14:53:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:54:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:55:06 | INFO | train_inner | epoch 691:     33 / 49 loss=2.467, nll_loss=0.339, ppl=1.27, wps=23267.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=33600, lr=0.000172516, gnorm=0.38, loss_scale=32, train_wall=238, gb_free=8.8, wall=93151
2022-03-07 14:55:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:55:52 | INFO | valid | epoch 691 | valid on 'valid' subset | loss 13.532 | nll_loss 12.834 | ppl 7300.36 | wps 41772.7 | wpb 510.9 | bsz 1 | num_updates 33616 | best_loss 9.157
2022-03-07 14:55:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 691 @ 33616 updates
2022-03-07 14:55:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:55:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:55:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 691 @ 33616 updates, score 13.532) (writing took 2.4178419383242726 seconds)
2022-03-07 14:55:55 | INFO | fairseq_cli.train | end of epoch 691 (average epoch stats below)
2022-03-07 14:55:55 | INFO | train | epoch 691 | loss 2.467 | nll_loss 0.339 | ppl 1.27 | wps 22967.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 33616 | lr 0.000172475 | gnorm 0.378 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 93200
2022-03-07 14:55:55 | INFO | fairseq.trainer | begin training epoch 692
2022-03-07 14:55:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:58:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:58:08 | INFO | valid | epoch 692 | valid on 'valid' subset | loss 13.501 | nll_loss 12.797 | ppl 7118.31 | wps 41599.8 | wpb 510.9 | bsz 1 | num_updates 33665 | best_loss 9.157
2022-03-07 14:58:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 692 @ 33665 updates
2022-03-07 14:58:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:58:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:58:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 692 @ 33665 updates, score 13.501) (writing took 2.415967032313347 seconds)
2022-03-07 14:58:10 | INFO | fairseq_cli.train | end of epoch 692 (average epoch stats below)
2022-03-07 14:58:10 | INFO | train | epoch 692 | loss 2.467 | nll_loss 0.339 | ppl 1.26 | wps 23451.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33665 | lr 0.00017235 | gnorm 0.379 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 93335
2022-03-07 14:58:10 | INFO | fairseq.trainer | begin training epoch 693
2022-03-07 14:58:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:59:42 | INFO | train_inner | epoch 693:     35 / 49 loss=2.467, nll_loss=0.339, ppl=1.27, wps=23489.8, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=33700, lr=0.00017226, gnorm=0.379, loss_scale=32, train_wall=235, gb_free=8.8, wall=93427
2022-03-07 15:00:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:00:23 | INFO | valid | epoch 693 | valid on 'valid' subset | loss 13.48 | nll_loss 12.778 | ppl 7021.64 | wps 42386.7 | wpb 510.9 | bsz 1 | num_updates 33714 | best_loss 9.157
2022-03-07 15:00:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 693 @ 33714 updates
2022-03-07 15:00:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:00:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:00:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 693 @ 33714 updates, score 13.48) (writing took 2.632222367916256 seconds)
2022-03-07 15:00:25 | INFO | fairseq_cli.train | end of epoch 693 (average epoch stats below)
2022-03-07 15:00:25 | INFO | train | epoch 693 | loss 2.467 | nll_loss 0.339 | ppl 1.26 | wps 23543 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33714 | lr 0.000172224 | gnorm 0.38 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 93470
2022-03-07 15:00:25 | INFO | fairseq.trainer | begin training epoch 694
2022-03-07 15:00:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:00:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:02:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:02:38 | INFO | valid | epoch 694 | valid on 'valid' subset | loss 13.408 | nll_loss 12.697 | ppl 6638.06 | wps 40109.6 | wpb 510.9 | bsz 1 | num_updates 33762 | best_loss 9.157
2022-03-07 15:02:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 694 @ 33762 updates
2022-03-07 15:02:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:02:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:02:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 694 @ 33762 updates, score 13.408) (writing took 2.599849989172071 seconds)
2022-03-07 15:02:41 | INFO | fairseq_cli.train | end of epoch 694 (average epoch stats below)
2022-03-07 15:02:41 | INFO | train | epoch 694 | loss 2.467 | nll_loss 0.339 | ppl 1.27 | wps 22946.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 33762 | lr 0.000172102 | gnorm 0.379 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 93606
2022-03-07 15:02:41 | INFO | fairseq.trainer | begin training epoch 695
2022-03-07 15:02:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:04:21 | INFO | train_inner | epoch 695:     38 / 49 loss=2.466, nll_loss=0.339, ppl=1.26, wps=23304.9, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=33800, lr=0.000172005, gnorm=0.378, loss_scale=32, train_wall=237, gb_free=8.8, wall=93705
2022-03-07 15:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:04:54 | INFO | valid | epoch 695 | valid on 'valid' subset | loss 13.456 | nll_loss 12.752 | ppl 6897.42 | wps 41879.8 | wpb 510.9 | bsz 1 | num_updates 33811 | best_loss 9.157
2022-03-07 15:04:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 695 @ 33811 updates
2022-03-07 15:04:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:04:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:04:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 695 @ 33811 updates, score 13.456) (writing took 2.4939488121308386 seconds)
2022-03-07 15:04:57 | INFO | fairseq_cli.train | end of epoch 695 (average epoch stats below)
2022-03-07 15:04:57 | INFO | train | epoch 695 | loss 2.466 | nll_loss 0.339 | ppl 1.26 | wps 23435.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33811 | lr 0.000171977 | gnorm 0.377 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 93741
2022-03-07 15:04:57 | INFO | fairseq.trainer | begin training epoch 696
2022-03-07 15:04:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:06:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:07:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:07:09 | INFO | valid | epoch 696 | valid on 'valid' subset | loss 13.532 | nll_loss 12.837 | ppl 7317.41 | wps 41577.5 | wpb 510.9 | bsz 1 | num_updates 33859 | best_loss 9.157
2022-03-07 15:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 696 @ 33859 updates
2022-03-07 15:07:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 696 @ 33859 updates, score 13.532) (writing took 2.3348140199668705 seconds)
2022-03-07 15:07:12 | INFO | fairseq_cli.train | end of epoch 696 (average epoch stats below)
2022-03-07 15:07:12 | INFO | train | epoch 696 | loss 2.465 | nll_loss 0.338 | ppl 1.26 | wps 23038.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 33859 | lr 0.000171855 | gnorm 0.377 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 93876
2022-03-07 15:07:12 | INFO | fairseq.trainer | begin training epoch 697
2022-03-07 15:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:09:00 | INFO | train_inner | epoch 697:     41 / 49 loss=2.465, nll_loss=0.338, ppl=1.26, wps=23278.9, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=33900, lr=0.000171751, gnorm=0.38, loss_scale=32, train_wall=238, gb_free=8.8, wall=93984
2022-03-07 15:09:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:09:25 | INFO | valid | epoch 697 | valid on 'valid' subset | loss 13.486 | nll_loss 12.785 | ppl 7056.5 | wps 41029.4 | wpb 510.9 | bsz 1 | num_updates 33908 | best_loss 9.157
2022-03-07 15:09:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 697 @ 33908 updates
2022-03-07 15:09:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:09:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:09:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 697 @ 33908 updates, score 13.486) (writing took 2.361509284004569 seconds)
2022-03-07 15:09:27 | INFO | fairseq_cli.train | end of epoch 697 (average epoch stats below)
2022-03-07 15:09:27 | INFO | train | epoch 697 | loss 2.465 | nll_loss 0.338 | ppl 1.26 | wps 23480.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33908 | lr 0.000171731 | gnorm 0.383 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 94012
2022-03-07 15:09:27 | INFO | fairseq.trainer | begin training epoch 698
2022-03-07 15:09:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:11:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:11:40 | INFO | valid | epoch 698 | valid on 'valid' subset | loss 13.401 | nll_loss 12.689 | ppl 6601.38 | wps 41583.1 | wpb 510.9 | bsz 1 | num_updates 33957 | best_loss 9.157
2022-03-07 15:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 698 @ 33957 updates
2022-03-07 15:11:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:11:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:11:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 698 @ 33957 updates, score 13.401) (writing took 2.3531683520413935 seconds)
2022-03-07 15:11:42 | INFO | fairseq_cli.train | end of epoch 698 (average epoch stats below)
2022-03-07 15:11:42 | INFO | train | epoch 698 | loss 2.465 | nll_loss 0.338 | ppl 1.26 | wps 23535 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33957 | lr 0.000171607 | gnorm 0.377 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 94147
2022-03-07 15:11:42 | INFO | fairseq.trainer | begin training epoch 699
2022-03-07 15:11:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:12:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:13:37 | INFO | train_inner | epoch 699:     44 / 49 loss=2.465, nll_loss=0.337, ppl=1.26, wps=23340.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=34000, lr=0.000171499, gnorm=0.375, loss_scale=32, train_wall=237, gb_free=8.8, wall=94262
2022-03-07 15:13:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:13:54 | INFO | valid | epoch 699 | valid on 'valid' subset | loss 13.456 | nll_loss 12.749 | ppl 6883.88 | wps 43437.1 | wpb 510.9 | bsz 1 | num_updates 34005 | best_loss 9.157
2022-03-07 15:13:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 699 @ 34005 updates
2022-03-07 15:13:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:13:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:13:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 699 @ 34005 updates, score 13.456) (writing took 2.513175843283534 seconds)
2022-03-07 15:13:57 | INFO | fairseq_cli.train | end of epoch 699 (average epoch stats below)
2022-03-07 15:13:57 | INFO | train | epoch 699 | loss 2.464 | nll_loss 0.337 | ppl 1.26 | wps 23098.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 34005 | lr 0.000171486 | gnorm 0.373 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 94282
2022-03-07 15:13:57 | INFO | fairseq.trainer | begin training epoch 700
2022-03-07 15:13:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:16:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:16:07 | INFO | valid | epoch 700 | valid on 'valid' subset | loss 13.475 | nll_loss 12.767 | ppl 6971.59 | wps 43189.8 | wpb 510.9 | bsz 1 | num_updates 34054 | best_loss 9.157
2022-03-07 15:16:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 700 @ 34054 updates
2022-03-07 15:16:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:16:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:16:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 700 @ 34054 updates, score 13.475) (writing took 2.4012674810364842 seconds)
2022-03-07 15:16:10 | INFO | fairseq_cli.train | end of epoch 700 (average epoch stats below)
2022-03-07 15:16:10 | INFO | train | epoch 700 | loss 2.465 | nll_loss 0.338 | ppl 1.26 | wps 23934.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 34054 | lr 0.000171363 | gnorm 0.384 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 94414
2022-03-07 15:16:10 | INFO | fairseq.trainer | begin training epoch 701
2022-03-07 15:16:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:18:09 | INFO | train_inner | epoch 701:     46 / 49 loss=2.465, nll_loss=0.338, ppl=1.26, wps=23875.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=34100, lr=0.000171247, gnorm=0.381, loss_scale=32, train_wall=232, gb_free=8.8, wall=94534
2022-03-07 15:18:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:18:21 | INFO | valid | epoch 701 | valid on 'valid' subset | loss 13.525 | nll_loss 12.823 | ppl 7244.89 | wps 41528.3 | wpb 510.9 | bsz 1 | num_updates 34103 | best_loss 9.157
2022-03-07 15:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 701 @ 34103 updates
2022-03-07 15:18:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:18:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 701 @ 34103 updates, score 13.525) (writing took 2.412852340377867 seconds)
2022-03-07 15:18:24 | INFO | fairseq_cli.train | end of epoch 701 (average epoch stats below)
2022-03-07 15:18:24 | INFO | train | epoch 701 | loss 2.465 | nll_loss 0.338 | ppl 1.26 | wps 23721.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 34103 | lr 0.000171239 | gnorm 0.378 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 94548
2022-03-07 15:18:24 | INFO | fairseq.trainer | begin training epoch 702
2022-03-07 15:18:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:18:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:20:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:20:36 | INFO | valid | epoch 702 | valid on 'valid' subset | loss 13.579 | nll_loss 12.885 | ppl 7562.98 | wps 41742.3 | wpb 510.9 | bsz 1 | num_updates 34151 | best_loss 9.157
2022-03-07 15:20:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 702 @ 34151 updates
2022-03-07 15:20:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:20:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:20:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 702 @ 34151 updates, score 13.579) (writing took 2.43693422479555 seconds)
2022-03-07 15:20:39 | INFO | fairseq_cli.train | end of epoch 702 (average epoch stats below)
2022-03-07 15:20:39 | INFO | train | epoch 702 | loss 2.464 | nll_loss 0.337 | ppl 1.26 | wps 23015.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 34151 | lr 0.000171119 | gnorm 0.38 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 94684
2022-03-07 15:20:39 | INFO | fairseq.trainer | begin training epoch 703
2022-03-07 15:20:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:22:46 | INFO | train_inner | epoch 703:     49 / 49 loss=2.464, nll_loss=0.337, ppl=1.26, wps=23300.8, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=34200, lr=0.000170996, gnorm=0.38, loss_scale=32, train_wall=236, gb_free=8.8, wall=94811
2022-03-07 15:22:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:22:52 | INFO | valid | epoch 703 | valid on 'valid' subset | loss 13.495 | nll_loss 12.795 | ppl 7108 | wps 40858.6 | wpb 510.9 | bsz 1 | num_updates 34200 | best_loss 9.157
2022-03-07 15:22:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 703 @ 34200 updates
2022-03-07 15:22:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:22:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:22:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 703 @ 34200 updates, score 13.495) (writing took 2.4903594171628356 seconds)
2022-03-07 15:22:54 | INFO | fairseq_cli.train | end of epoch 703 (average epoch stats below)
2022-03-07 15:22:54 | INFO | train | epoch 703 | loss 2.464 | nll_loss 0.337 | ppl 1.26 | wps 23485.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34200 | lr 0.000170996 | gnorm 0.378 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 94819
2022-03-07 15:22:54 | INFO | fairseq.trainer | begin training epoch 704
2022-03-07 15:22:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:24:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:25:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:25:07 | INFO | valid | epoch 704 | valid on 'valid' subset | loss 13.571 | nll_loss 12.875 | ppl 7510.58 | wps 42042.1 | wpb 510.9 | bsz 1 | num_updates 34248 | best_loss 9.157
2022-03-07 15:25:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 704 @ 34248 updates
2022-03-07 15:25:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:25:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:25:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 704 @ 34248 updates, score 13.571) (writing took 2.430888241622597 seconds)
2022-03-07 15:25:09 | INFO | fairseq_cli.train | end of epoch 704 (average epoch stats below)
2022-03-07 15:25:09 | INFO | train | epoch 704 | loss 2.464 | nll_loss 0.337 | ppl 1.26 | wps 23053.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 34248 | lr 0.000170877 | gnorm 0.38 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 94954
2022-03-07 15:25:09 | INFO | fairseq.trainer | begin training epoch 705
2022-03-07 15:25:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:27:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:27:22 | INFO | valid | epoch 705 | valid on 'valid' subset | loss 13.454 | nll_loss 12.747 | ppl 6875.29 | wps 41726.4 | wpb 510.9 | bsz 1 | num_updates 34297 | best_loss 9.157
2022-03-07 15:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 705 @ 34297 updates
2022-03-07 15:27:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:27:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:27:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 705 @ 34297 updates, score 13.454) (writing took 2.365306464023888 seconds)
2022-03-07 15:27:24 | INFO | fairseq_cli.train | end of epoch 705 (average epoch stats below)
2022-03-07 15:27:24 | INFO | train | epoch 705 | loss 2.464 | nll_loss 0.337 | ppl 1.26 | wps 23538.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34297 | lr 0.000170754 | gnorm 0.377 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 95089
2022-03-07 15:27:24 | INFO | fairseq.trainer | begin training epoch 706
2022-03-07 15:27:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:27:32 | INFO | train_inner | epoch 706:      3 / 49 loss=2.464, nll_loss=0.337, ppl=1.26, wps=22691.6, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=34300, lr=0.000170747, gnorm=0.378, loss_scale=32, train_wall=237, gb_free=8.8, wall=95097
2022-03-07 15:29:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:29:37 | INFO | valid | epoch 706 | valid on 'valid' subset | loss 13.442 | nll_loss 12.738 | ppl 6831.09 | wps 41668.6 | wpb 510.9 | bsz 1 | num_updates 34346 | best_loss 9.157
2022-03-07 15:29:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 706 @ 34346 updates
2022-03-07 15:29:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:29:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:29:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 706 @ 34346 updates, score 13.442) (writing took 2.3096674252301455 seconds)
2022-03-07 15:29:39 | INFO | fairseq_cli.train | end of epoch 706 (average epoch stats below)
2022-03-07 15:29:39 | INFO | train | epoch 706 | loss 2.464 | nll_loss 0.337 | ppl 1.26 | wps 23554.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34346 | lr 0.000170633 | gnorm 0.378 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 95224
2022-03-07 15:29:39 | INFO | fairseq.trainer | begin training epoch 707
2022-03-07 15:29:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:31:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:31:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:31:52 | INFO | valid | epoch 707 | valid on 'valid' subset | loss 13.522 | nll_loss 12.827 | ppl 7267.17 | wps 42230.3 | wpb 510.9 | bsz 1 | num_updates 34394 | best_loss 9.157
2022-03-07 15:31:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 707 @ 34394 updates
2022-03-07 15:31:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:31:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:31:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 707 @ 34394 updates, score 13.522) (writing took 2.3422799999825656 seconds)
2022-03-07 15:31:54 | INFO | fairseq_cli.train | end of epoch 707 (average epoch stats below)
2022-03-07 15:31:54 | INFO | train | epoch 707 | loss 2.464 | nll_loss 0.337 | ppl 1.26 | wps 23080.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 34394 | lr 0.000170513 | gnorm 0.377 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 95359
2022-03-07 15:31:54 | INFO | fairseq.trainer | begin training epoch 708
2022-03-07 15:31:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:32:10 | INFO | train_inner | epoch 708:      6 / 49 loss=2.464, nll_loss=0.337, ppl=1.26, wps=23356.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=34400, lr=0.000170499, gnorm=0.377, loss_scale=32, train_wall=237, gb_free=8.8, wall=95375
2022-03-07 15:34:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:34:07 | INFO | valid | epoch 708 | valid on 'valid' subset | loss 13.539 | nll_loss 12.843 | ppl 7347.4 | wps 41971.6 | wpb 510.9 | bsz 1 | num_updates 34443 | best_loss 9.157
2022-03-07 15:34:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 708 @ 34443 updates
2022-03-07 15:34:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:34:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:34:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 708 @ 34443 updates, score 13.539) (writing took 2.511197709944099 seconds)
2022-03-07 15:34:09 | INFO | fairseq_cli.train | end of epoch 708 (average epoch stats below)
2022-03-07 15:34:09 | INFO | train | epoch 708 | loss 2.463 | nll_loss 0.336 | ppl 1.26 | wps 23496.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34443 | lr 0.000170392 | gnorm 0.372 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 95494
2022-03-07 15:34:09 | INFO | fairseq.trainer | begin training epoch 709
2022-03-07 15:34:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:36:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:36:22 | INFO | valid | epoch 709 | valid on 'valid' subset | loss 13.492 | nll_loss 12.794 | ppl 7099.93 | wps 41737.6 | wpb 510.9 | bsz 1 | num_updates 34492 | best_loss 9.157
2022-03-07 15:36:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 709 @ 34492 updates
2022-03-07 15:36:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:36:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:36:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 709 @ 34492 updates, score 13.492) (writing took 2.4096530321985483 seconds)
2022-03-07 15:36:24 | INFO | fairseq_cli.train | end of epoch 709 (average epoch stats below)
2022-03-07 15:36:24 | INFO | train | epoch 709 | loss 2.463 | nll_loss 0.336 | ppl 1.26 | wps 23559.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34492 | lr 0.000170271 | gnorm 0.38 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 95629
2022-03-07 15:36:24 | INFO | fairseq.trainer | begin training epoch 710
2022-03-07 15:36:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:36:45 | INFO | train_inner | epoch 710:      8 / 49 loss=2.463, nll_loss=0.337, ppl=1.26, wps=23566.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=34500, lr=0.000170251, gnorm=0.377, loss_scale=32, train_wall=235, gb_free=8.8, wall=95650
2022-03-07 15:37:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:38:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:38:37 | INFO | valid | epoch 710 | valid on 'valid' subset | loss 13.515 | nll_loss 12.816 | ppl 7213.5 | wps 41575.2 | wpb 510.9 | bsz 1 | num_updates 34540 | best_loss 9.157
2022-03-07 15:38:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 710 @ 34540 updates
2022-03-07 15:38:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:38:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:38:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 710 @ 34540 updates, score 13.515) (writing took 2.440317157190293 seconds)
2022-03-07 15:38:39 | INFO | fairseq_cli.train | end of epoch 710 (average epoch stats below)
2022-03-07 15:38:39 | INFO | train | epoch 710 | loss 2.463 | nll_loss 0.336 | ppl 1.26 | wps 23064.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 34540 | lr 0.000170153 | gnorm 0.375 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 95764
2022-03-07 15:38:39 | INFO | fairseq.trainer | begin training epoch 711
2022-03-07 15:38:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:40:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:40:51 | INFO | valid | epoch 711 | valid on 'valid' subset | loss 13.462 | nll_loss 12.757 | ppl 6923.41 | wps 43795.5 | wpb 510.9 | bsz 1 | num_updates 34589 | best_loss 9.157
2022-03-07 15:40:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 711 @ 34589 updates
2022-03-07 15:40:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:40:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:40:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 711 @ 34589 updates, score 13.462) (writing took 2.4830126399174333 seconds)
2022-03-07 15:40:54 | INFO | fairseq_cli.train | end of epoch 711 (average epoch stats below)
2022-03-07 15:40:54 | INFO | train | epoch 711 | loss 2.462 | nll_loss 0.336 | ppl 1.26 | wps 23574.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34589 | lr 0.000170032 | gnorm 0.375 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 95899
2022-03-07 15:40:54 | INFO | fairseq.trainer | begin training epoch 712
2022-03-07 15:40:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:41:23 | INFO | train_inner | epoch 712:     11 / 49 loss=2.462, nll_loss=0.336, ppl=1.26, wps=23351, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=34600, lr=0.000170005, gnorm=0.374, loss_scale=32, train_wall=237, gb_free=8.8, wall=95928
2022-03-07 15:43:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:43:05 | INFO | valid | epoch 712 | valid on 'valid' subset | loss 13.506 | nll_loss 12.805 | ppl 7155.64 | wps 43159.4 | wpb 510.9 | bsz 1 | num_updates 34638 | best_loss 9.157
2022-03-07 15:43:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 712 @ 34638 updates
2022-03-07 15:43:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:43:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:43:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 712 @ 34638 updates, score 13.506) (writing took 2.4964193287305534 seconds)
2022-03-07 15:43:08 | INFO | fairseq_cli.train | end of epoch 712 (average epoch stats below)
2022-03-07 15:43:08 | INFO | train | epoch 712 | loss 2.462 | nll_loss 0.336 | ppl 1.26 | wps 23721.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 34638 | lr 0.000169912 | gnorm 0.38 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 96033
2022-03-07 15:43:08 | INFO | fairseq.trainer | begin training epoch 713
2022-03-07 15:43:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:43:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:45:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:45:18 | INFO | valid | epoch 713 | valid on 'valid' subset | loss 13.49 | nll_loss 12.792 | ppl 7092.7 | wps 43194.3 | wpb 510.9 | bsz 1 | num_updates 34686 | best_loss 9.157
2022-03-07 15:45:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 713 @ 34686 updates
2022-03-07 15:45:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:45:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:45:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 713 @ 34686 updates, score 13.49) (writing took 2.38006142526865 seconds)
2022-03-07 15:45:21 | INFO | fairseq_cli.train | end of epoch 713 (average epoch stats below)
2022-03-07 15:45:21 | INFO | train | epoch 713 | loss 2.462 | nll_loss 0.336 | ppl 1.26 | wps 23418.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 34686 | lr 0.000169794 | gnorm 0.381 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 96165
2022-03-07 15:45:21 | INFO | fairseq.trainer | begin training epoch 714
2022-03-07 15:45:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:45:57 | INFO | train_inner | epoch 714:     14 / 49 loss=2.462, nll_loss=0.336, ppl=1.26, wps=23677.1, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=34700, lr=0.00016976, gnorm=0.379, loss_scale=32, train_wall=234, gb_free=8.8, wall=96202
2022-03-07 15:47:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:47:31 | INFO | valid | epoch 714 | valid on 'valid' subset | loss 13.49 | nll_loss 12.789 | ppl 7078.1 | wps 42966.6 | wpb 510.9 | bsz 1 | num_updates 34735 | best_loss 9.157
2022-03-07 15:47:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 714 @ 34735 updates
2022-03-07 15:47:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:47:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:47:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 714 @ 34735 updates, score 13.49) (writing took 2.4452884159982204 seconds)
2022-03-07 15:47:34 | INFO | fairseq_cli.train | end of epoch 714 (average epoch stats below)
2022-03-07 15:47:34 | INFO | train | epoch 714 | loss 2.462 | nll_loss 0.336 | ppl 1.26 | wps 23927.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 34735 | lr 0.000169674 | gnorm 0.378 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 96298
2022-03-07 15:47:34 | INFO | fairseq.trainer | begin training epoch 715
2022-03-07 15:47:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:49:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:49:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:49:44 | INFO | valid | epoch 715 | valid on 'valid' subset | loss 13.533 | nll_loss 12.842 | ppl 7340.53 | wps 43607.7 | wpb 510.9 | bsz 1 | num_updates 34783 | best_loss 9.157
2022-03-07 15:49:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 715 @ 34783 updates
2022-03-07 15:49:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:49:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:49:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 715 @ 34783 updates, score 13.533) (writing took 2.3876948300749063 seconds)
2022-03-07 15:49:46 | INFO | fairseq_cli.train | end of epoch 715 (average epoch stats below)
2022-03-07 15:49:46 | INFO | train | epoch 715 | loss 2.462 | nll_loss 0.335 | ppl 1.26 | wps 23472.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 34783 | lr 0.000169557 | gnorm 0.381 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 96431
2022-03-07 15:49:46 | INFO | fairseq.trainer | begin training epoch 716
2022-03-07 15:49:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:50:30 | INFO | train_inner | epoch 716:     17 / 49 loss=2.462, nll_loss=0.336, ppl=1.26, wps=23747.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=34800, lr=0.000169516, gnorm=0.38, loss_scale=32, train_wall=233, gb_free=8.8, wall=96475
2022-03-07 15:51:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:51:56 | INFO | valid | epoch 716 | valid on 'valid' subset | loss 13.514 | nll_loss 12.816 | ppl 7213.16 | wps 43738 | wpb 510.9 | bsz 1 | num_updates 34832 | best_loss 9.157
2022-03-07 15:51:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 716 @ 34832 updates
2022-03-07 15:51:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:51:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:51:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 716 @ 34832 updates, score 13.514) (writing took 2.325025002937764 seconds)
2022-03-07 15:51:59 | INFO | fairseq_cli.train | end of epoch 716 (average epoch stats below)
2022-03-07 15:51:59 | INFO | train | epoch 716 | loss 2.461 | nll_loss 0.335 | ppl 1.26 | wps 23984.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 34832 | lr 0.000169438 | gnorm 0.375 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 96563
2022-03-07 15:51:59 | INFO | fairseq.trainer | begin training epoch 717
2022-03-07 15:51:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:54:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:54:11 | INFO | valid | epoch 717 | valid on 'valid' subset | loss 13.495 | nll_loss 12.797 | ppl 7117.36 | wps 41646.8 | wpb 510.9 | bsz 1 | num_updates 34881 | best_loss 9.157
2022-03-07 15:54:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 717 @ 34881 updates
2022-03-07 15:54:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:54:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:54:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 717 @ 34881 updates, score 13.495) (writing took 2.5151661173440516 seconds)
2022-03-07 15:54:14 | INFO | fairseq_cli.train | end of epoch 717 (average epoch stats below)
2022-03-07 15:54:14 | INFO | train | epoch 717 | loss 2.461 | nll_loss 0.335 | ppl 1.26 | wps 23485.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34881 | lr 0.000169319 | gnorm 0.376 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 96699
2022-03-07 15:54:14 | INFO | fairseq.trainer | begin training epoch 718
2022-03-07 15:54:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:54:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:55:07 | INFO | train_inner | epoch 718:     20 / 49 loss=2.461, nll_loss=0.335, ppl=1.26, wps=23453, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=34900, lr=0.000169273, gnorm=0.376, loss_scale=32, train_wall=236, gb_free=8.8, wall=96751
2022-03-07 15:56:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:56:27 | INFO | valid | epoch 718 | valid on 'valid' subset | loss 13.481 | nll_loss 12.782 | ppl 7042.19 | wps 41752.8 | wpb 510.9 | bsz 1 | num_updates 34929 | best_loss 9.157
2022-03-07 15:56:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 718 @ 34929 updates
2022-03-07 15:56:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:56:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:56:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 718 @ 34929 updates, score 13.481) (writing took 2.429276803974062 seconds)
2022-03-07 15:56:29 | INFO | fairseq_cli.train | end of epoch 718 (average epoch stats below)
2022-03-07 15:56:29 | INFO | train | epoch 718 | loss 2.461 | nll_loss 0.335 | ppl 1.26 | wps 22997.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 34929 | lr 0.000169203 | gnorm 0.378 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 96834
2022-03-07 15:56:29 | INFO | fairseq.trainer | begin training epoch 719
2022-03-07 15:56:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:58:42 | INFO | valid | epoch 719 | valid on 'valid' subset | loss 13.556 | nll_loss 12.865 | ppl 7461.54 | wps 41676.1 | wpb 510.9 | bsz 1 | num_updates 34978 | best_loss 9.157
2022-03-07 15:58:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 719 @ 34978 updates
2022-03-07 15:58:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:58:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:58:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 719 @ 34978 updates, score 13.556) (writing took 2.413686783052981 seconds)
2022-03-07 15:58:45 | INFO | fairseq_cli.train | end of epoch 719 (average epoch stats below)
2022-03-07 15:58:45 | INFO | train | epoch 719 | loss 2.46 | nll_loss 0.335 | ppl 1.26 | wps 23475.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34978 | lr 0.000169084 | gnorm 0.373 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 96969
2022-03-07 15:58:45 | INFO | fairseq.trainer | begin training epoch 720
2022-03-07 15:58:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:59:43 | INFO | train_inner | epoch 720:     22 / 49 loss=2.461, nll_loss=0.334, ppl=1.26, wps=23495.4, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=35000, lr=0.000169031, gnorm=0.373, loss_scale=32, train_wall=235, gb_free=8.8, wall=97028
2022-03-07 16:00:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:00:58 | INFO | valid | epoch 720 | valid on 'valid' subset | loss 13.565 | nll_loss 12.872 | ppl 7498.34 | wps 41960.2 | wpb 510.9 | bsz 1 | num_updates 35027 | best_loss 9.157
2022-03-07 16:00:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 720 @ 35027 updates
2022-03-07 16:00:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:01:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:01:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 720 @ 35027 updates, score 13.565) (writing took 2.6024014870636165 seconds)
2022-03-07 16:01:00 | INFO | fairseq_cli.train | end of epoch 720 (average epoch stats below)
2022-03-07 16:01:00 | INFO | train | epoch 720 | loss 2.46 | nll_loss 0.334 | ppl 1.26 | wps 23425.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35027 | lr 0.000168966 | gnorm 0.375 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 97105
2022-03-07 16:01:00 | INFO | fairseq.trainer | begin training epoch 721
2022-03-07 16:01:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:01:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:03:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:03:13 | INFO | valid | epoch 721 | valid on 'valid' subset | loss 13.524 | nll_loss 12.829 | ppl 7274.04 | wps 41869.4 | wpb 510.9 | bsz 1 | num_updates 35075 | best_loss 9.157
2022-03-07 16:03:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 721 @ 35075 updates
2022-03-07 16:03:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:03:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:03:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 721 @ 35075 updates, score 13.524) (writing took 2.3915137429721653 seconds)
2022-03-07 16:03:16 | INFO | fairseq_cli.train | end of epoch 721 (average epoch stats below)
2022-03-07 16:03:16 | INFO | train | epoch 721 | loss 2.46 | nll_loss 0.335 | ppl 1.26 | wps 23013.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 35075 | lr 0.00016885 | gnorm 0.375 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 97240
2022-03-07 16:03:16 | INFO | fairseq.trainer | begin training epoch 722
2022-03-07 16:03:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:04:22 | INFO | train_inner | epoch 722:     25 / 49 loss=2.46, nll_loss=0.334, ppl=1.26, wps=23266.8, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=35100, lr=0.00016879, gnorm=0.375, loss_scale=32, train_wall=238, gb_free=8.8, wall=97306
2022-03-07 16:05:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:05:29 | INFO | valid | epoch 722 | valid on 'valid' subset | loss 13.466 | nll_loss 12.766 | ppl 6966.54 | wps 41263.8 | wpb 510.9 | bsz 1 | num_updates 35124 | best_loss 9.157
2022-03-07 16:05:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 722 @ 35124 updates
2022-03-07 16:05:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:05:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:05:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 722 @ 35124 updates, score 13.466) (writing took 2.4417548230849206 seconds)
2022-03-07 16:05:31 | INFO | fairseq_cli.train | end of epoch 722 (average epoch stats below)
2022-03-07 16:05:31 | INFO | train | epoch 722 | loss 2.46 | nll_loss 0.334 | ppl 1.26 | wps 23435.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35124 | lr 0.000168732 | gnorm 0.372 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 97376
2022-03-07 16:05:31 | INFO | fairseq.trainer | begin training epoch 723
2022-03-07 16:05:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:06:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:07:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:07:44 | INFO | valid | epoch 723 | valid on 'valid' subset | loss 13.455 | nll_loss 12.76 | ppl 6936.95 | wps 42210.1 | wpb 510.9 | bsz 1 | num_updates 35172 | best_loss 9.157
2022-03-07 16:07:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 723 @ 35172 updates
2022-03-07 16:07:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:07:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:07:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 723 @ 35172 updates, score 13.455) (writing took 2.4755949452519417 seconds)
2022-03-07 16:07:47 | INFO | fairseq_cli.train | end of epoch 723 (average epoch stats below)
2022-03-07 16:07:47 | INFO | train | epoch 723 | loss 2.46 | nll_loss 0.334 | ppl 1.26 | wps 22997.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 35172 | lr 0.000168617 | gnorm 0.377 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 97511
2022-03-07 16:07:47 | INFO | fairseq.trainer | begin training epoch 724
2022-03-07 16:07:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:09:00 | INFO | train_inner | epoch 724:     28 / 49 loss=2.46, nll_loss=0.334, ppl=1.26, wps=23283.9, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=35200, lr=0.00016855, gnorm=0.374, loss_scale=32, train_wall=238, gb_free=8.8, wall=97585
2022-03-07 16:09:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:09:59 | INFO | valid | epoch 724 | valid on 'valid' subset | loss 13.518 | nll_loss 12.818 | ppl 7220.34 | wps 41281.9 | wpb 510.9 | bsz 1 | num_updates 35221 | best_loss 9.157
2022-03-07 16:09:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 724 @ 35221 updates
2022-03-07 16:09:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:10:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:10:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 724 @ 35221 updates, score 13.518) (writing took 2.372411211952567 seconds)
2022-03-07 16:10:02 | INFO | fairseq_cli.train | end of epoch 724 (average epoch stats below)
2022-03-07 16:10:02 | INFO | train | epoch 724 | loss 2.46 | nll_loss 0.334 | ppl 1.26 | wps 23494.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35221 | lr 0.0001685 | gnorm 0.374 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 97647
2022-03-07 16:10:02 | INFO | fairseq.trainer | begin training epoch 725
2022-03-07 16:10:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:12:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:12:15 | INFO | valid | epoch 725 | valid on 'valid' subset | loss 13.5 | nll_loss 12.799 | ppl 7125.03 | wps 41910.6 | wpb 510.9 | bsz 1 | num_updates 35270 | best_loss 9.157
2022-03-07 16:12:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 725 @ 35270 updates
2022-03-07 16:12:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:12:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:12:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 725 @ 35270 updates, score 13.5) (writing took 2.343717819545418 seconds)
2022-03-07 16:12:17 | INFO | fairseq_cli.train | end of epoch 725 (average epoch stats below)
2022-03-07 16:12:17 | INFO | train | epoch 725 | loss 2.46 | nll_loss 0.334 | ppl 1.26 | wps 23489.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35270 | lr 0.000168383 | gnorm 0.375 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 97782
2022-03-07 16:12:17 | INFO | fairseq.trainer | begin training epoch 726
2022-03-07 16:12:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:13:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:13:39 | INFO | train_inner | epoch 726:     31 / 49 loss=2.46, nll_loss=0.334, ppl=1.26, wps=23289.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=35300, lr=0.000168311, gnorm=0.375, loss_scale=32, train_wall=238, gb_free=8.8, wall=97863
2022-03-07 16:14:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:14:30 | INFO | valid | epoch 726 | valid on 'valid' subset | loss 13.5 | nll_loss 12.801 | ppl 7138.86 | wps 40589 | wpb 510.9 | bsz 1 | num_updates 35318 | best_loss 9.157
2022-03-07 16:14:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 726 @ 35318 updates
2022-03-07 16:14:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:14:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:14:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 726 @ 35318 updates, score 13.5) (writing took 2.5238645947538316 seconds)
2022-03-07 16:14:33 | INFO | fairseq_cli.train | end of epoch 726 (average epoch stats below)
2022-03-07 16:14:33 | INFO | train | epoch 726 | loss 2.46 | nll_loss 0.334 | ppl 1.26 | wps 22951.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 35318 | lr 0.000168268 | gnorm 0.372 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 97917
2022-03-07 16:14:33 | INFO | fairseq.trainer | begin training epoch 727
2022-03-07 16:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:16:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:16:44 | INFO | valid | epoch 727 | valid on 'valid' subset | loss 13.41 | nll_loss 12.703 | ppl 6669.02 | wps 42900.2 | wpb 510.9 | bsz 1 | num_updates 35367 | best_loss 9.157
2022-03-07 16:16:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 727 @ 35367 updates
2022-03-07 16:16:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:16:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:16:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 727 @ 35367 updates, score 13.41) (writing took 2.3749628020450473 seconds)
2022-03-07 16:16:47 | INFO | fairseq_cli.train | end of epoch 727 (average epoch stats below)
2022-03-07 16:16:47 | INFO | train | epoch 727 | loss 2.46 | nll_loss 0.334 | ppl 1.26 | wps 23718.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35367 | lr 0.000168152 | gnorm 0.377 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 98051
2022-03-07 16:16:47 | INFO | fairseq.trainer | begin training epoch 728
2022-03-07 16:16:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:18:12 | INFO | train_inner | epoch 728:     33 / 49 loss=2.459, nll_loss=0.334, ppl=1.26, wps=23727.3, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=35400, lr=0.000168073, gnorm=0.374, loss_scale=32, train_wall=233, gb_free=8.8, wall=98137
2022-03-07 16:18:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:18:57 | INFO | valid | epoch 728 | valid on 'valid' subset | loss 13.579 | nll_loss 12.892 | ppl 7602.09 | wps 43680.5 | wpb 510.9 | bsz 1 | num_updates 35416 | best_loss 9.157
2022-03-07 16:18:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 728 @ 35416 updates
2022-03-07 16:18:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:19:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:19:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 728 @ 35416 updates, score 13.579) (writing took 2.3779330058023334 seconds)
2022-03-07 16:19:00 | INFO | fairseq_cli.train | end of epoch 728 (average epoch stats below)
2022-03-07 16:19:00 | INFO | train | epoch 728 | loss 2.459 | nll_loss 0.334 | ppl 1.26 | wps 23902.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35416 | lr 0.000168035 | gnorm 0.373 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 98184
2022-03-07 16:19:00 | INFO | fairseq.trainer | begin training epoch 729
2022-03-07 16:19:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:19:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:21:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:21:09 | INFO | valid | epoch 729 | valid on 'valid' subset | loss 13.51 | nll_loss 12.809 | ppl 7176.49 | wps 48288.9 | wpb 510.9 | bsz 1 | num_updates 35464 | best_loss 9.157
2022-03-07 16:21:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 729 @ 35464 updates
2022-03-07 16:21:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:21:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:21:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 729 @ 35464 updates, score 13.51) (writing took 2.244318882934749 seconds)
2022-03-07 16:21:11 | INFO | fairseq_cli.train | end of epoch 729 (average epoch stats below)
2022-03-07 16:21:11 | INFO | train | epoch 729 | loss 2.459 | nll_loss 0.334 | ppl 1.26 | wps 23683.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 35464 | lr 0.000167921 | gnorm 0.375 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 98316
2022-03-07 16:21:11 | INFO | fairseq.trainer | begin training epoch 730
2022-03-07 16:21:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:22:39 | INFO | train_inner | epoch 730:     36 / 49 loss=2.459, nll_loss=0.334, ppl=1.26, wps=24268.9, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=35500, lr=0.000167836, gnorm=0.374, loss_scale=32, train_wall=228, gb_free=8.8, wall=98404
2022-03-07 16:23:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:23:15 | INFO | valid | epoch 730 | valid on 'valid' subset | loss 13.456 | nll_loss 12.759 | ppl 6931.26 | wps 48088.9 | wpb 510.9 | bsz 1 | num_updates 35513 | best_loss 9.157
2022-03-07 16:23:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 730 @ 35513 updates
2022-03-07 16:23:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:23:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:23:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 730 @ 35513 updates, score 13.456) (writing took 2.3627370269969106 seconds)
2022-03-07 16:23:17 | INFO | fairseq_cli.train | end of epoch 730 (average epoch stats below)
2022-03-07 16:23:17 | INFO | train | epoch 730 | loss 2.459 | nll_loss 0.333 | ppl 1.26 | wps 25245.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35513 | lr 0.000167806 | gnorm 0.374 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 98442
2022-03-07 16:23:17 | INFO | fairseq.trainer | begin training epoch 731
2022-03-07 16:23:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:25:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:25:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:25:21 | INFO | valid | epoch 731 | valid on 'valid' subset | loss 13.434 | nll_loss 12.731 | ppl 6796.63 | wps 47518.6 | wpb 510.9 | bsz 1 | num_updates 35561 | best_loss 9.157
2022-03-07 16:25:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 731 @ 35561 updates
2022-03-07 16:25:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:25:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:25:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 731 @ 35561 updates, score 13.434) (writing took 2.3763707792386413 seconds)
2022-03-07 16:25:23 | INFO | fairseq_cli.train | end of epoch 731 (average epoch stats below)
2022-03-07 16:25:23 | INFO | train | epoch 731 | loss 2.459 | nll_loss 0.334 | ppl 1.26 | wps 24699.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35561 | lr 0.000167692 | gnorm 0.377 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 98568
2022-03-07 16:25:23 | INFO | fairseq.trainer | begin training epoch 732
2022-03-07 16:25:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:26:59 | INFO | train_inner | epoch 732:     39 / 49 loss=2.459, nll_loss=0.334, ppl=1.26, wps=25007.3, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=35600, lr=0.0001676, gnorm=0.376, loss_scale=32, train_wall=221, gb_free=8.8, wall=98664
2022-03-07 16:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:27:27 | INFO | valid | epoch 732 | valid on 'valid' subset | loss 13.571 | nll_loss 12.884 | ppl 7559.39 | wps 48261.2 | wpb 510.9 | bsz 1 | num_updates 35610 | best_loss 9.157
2022-03-07 16:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 732 @ 35610 updates
2022-03-07 16:27:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:27:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:27:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 732 @ 35610 updates, score 13.571) (writing took 2.278690811712295 seconds)
2022-03-07 16:27:29 | INFO | fairseq_cli.train | end of epoch 732 (average epoch stats below)
2022-03-07 16:27:29 | INFO | train | epoch 732 | loss 2.458 | nll_loss 0.333 | ppl 1.26 | wps 25237.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35610 | lr 0.000167577 | gnorm 0.372 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 98694
2022-03-07 16:27:29 | INFO | fairseq.trainer | begin training epoch 733
2022-03-07 16:27:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:29:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:29:32 | INFO | valid | epoch 733 | valid on 'valid' subset | loss 13.584 | nll_loss 12.897 | ppl 7626.8 | wps 47853.2 | wpb 510.9 | bsz 1 | num_updates 35659 | best_loss 9.157
2022-03-07 16:29:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 733 @ 35659 updates
2022-03-07 16:29:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:29:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:29:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 733 @ 35659 updates, score 13.584) (writing took 2.254501875024289 seconds)
2022-03-07 16:29:35 | INFO | fairseq_cli.train | end of epoch 733 (average epoch stats below)
2022-03-07 16:29:35 | INFO | train | epoch 733 | loss 2.458 | nll_loss 0.333 | ppl 1.26 | wps 25278.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35659 | lr 0.000167462 | gnorm 0.369 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 98819
2022-03-07 16:29:35 | INFO | fairseq.trainer | begin training epoch 734
2022-03-07 16:29:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:30:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:31:18 | INFO | train_inner | epoch 734:     42 / 49 loss=2.458, nll_loss=0.333, ppl=1.26, wps=25069.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=35700, lr=0.000167365, gnorm=0.373, loss_scale=32, train_wall=221, gb_free=8.8, wall=98922
2022-03-07 16:31:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:31:38 | INFO | valid | epoch 734 | valid on 'valid' subset | loss 13.415 | nll_loss 12.708 | ppl 6689.5 | wps 48358.9 | wpb 510.9 | bsz 1 | num_updates 35707 | best_loss 9.157
2022-03-07 16:31:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 734 @ 35707 updates
2022-03-07 16:31:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:31:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:31:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 734 @ 35707 updates, score 13.415) (writing took 2.2990802130661905 seconds)
2022-03-07 16:31:40 | INFO | fairseq_cli.train | end of epoch 734 (average epoch stats below)
2022-03-07 16:31:40 | INFO | train | epoch 734 | loss 2.458 | nll_loss 0.333 | ppl 1.26 | wps 24748.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35707 | lr 0.000167349 | gnorm 0.378 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 98945
2022-03-07 16:31:40 | INFO | fairseq.trainer | begin training epoch 735
2022-03-07 16:31:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:33:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:33:44 | INFO | valid | epoch 735 | valid on 'valid' subset | loss 13.417 | nll_loss 12.709 | ppl 6693.4 | wps 48072.2 | wpb 510.9 | bsz 1 | num_updates 35756 | best_loss 9.157
2022-03-07 16:33:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 735 @ 35756 updates
2022-03-07 16:33:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:33:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:33:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 735 @ 35756 updates, score 13.417) (writing took 2.3606820977292955 seconds)
2022-03-07 16:33:46 | INFO | fairseq_cli.train | end of epoch 735 (average epoch stats below)
2022-03-07 16:33:46 | INFO | train | epoch 735 | loss 2.459 | nll_loss 0.334 | ppl 1.26 | wps 25206 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35756 | lr 0.000167234 | gnorm 0.38 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 99071
2022-03-07 16:33:46 | INFO | fairseq.trainer | begin training epoch 736
2022-03-07 16:33:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:35:34 | INFO | train_inner | epoch 736:     44 / 49 loss=2.458, nll_loss=0.333, ppl=1.26, wps=25263.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=35800, lr=0.000167132, gnorm=0.376, loss_scale=32, train_wall=219, gb_free=8.8, wall=99179
2022-03-07 16:35:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:35:50 | INFO | valid | epoch 736 | valid on 'valid' subset | loss 13.482 | nll_loss 12.78 | ppl 7033 | wps 48616.1 | wpb 510.9 | bsz 1 | num_updates 35805 | best_loss 9.157
2022-03-07 16:35:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 736 @ 35805 updates
2022-03-07 16:35:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:35:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:35:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 736 @ 35805 updates, score 13.482) (writing took 2.2709607440046966 seconds)
2022-03-07 16:35:52 | INFO | fairseq_cli.train | end of epoch 736 (average epoch stats below)
2022-03-07 16:35:52 | INFO | train | epoch 736 | loss 2.457 | nll_loss 0.333 | ppl 1.26 | wps 25272.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35805 | lr 0.00016712 | gnorm 0.37 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 99197
2022-03-07 16:35:52 | INFO | fairseq.trainer | begin training epoch 737
2022-03-07 16:35:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:36:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:37:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:37:56 | INFO | valid | epoch 737 | valid on 'valid' subset | loss 13.559 | nll_loss 12.864 | ppl 7453.93 | wps 48331.2 | wpb 510.9 | bsz 1 | num_updates 35853 | best_loss 9.157
2022-03-07 16:37:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 737 @ 35853 updates
2022-03-07 16:37:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:37:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:37:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 737 @ 35853 updates, score 13.559) (writing took 2.2656575622968376 seconds)
2022-03-07 16:37:58 | INFO | fairseq_cli.train | end of epoch 737 (average epoch stats below)
2022-03-07 16:37:58 | INFO | train | epoch 737 | loss 2.457 | nll_loss 0.333 | ppl 1.26 | wps 24744 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35853 | lr 0.000167008 | gnorm 0.367 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 99323
2022-03-07 16:37:58 | INFO | fairseq.trainer | begin training epoch 738
2022-03-07 16:37:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:39:53 | INFO | train_inner | epoch 738:     47 / 49 loss=2.457, nll_loss=0.332, ppl=1.26, wps=25052.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=35900, lr=0.000166899, gnorm=0.37, loss_scale=32, train_wall=221, gb_free=8.8, wall=99438
2022-03-07 16:39:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:40:02 | INFO | valid | epoch 738 | valid on 'valid' subset | loss 13.475 | nll_loss 12.776 | ppl 7012.17 | wps 48152.4 | wpb 510.9 | bsz 1 | num_updates 35902 | best_loss 9.157
2022-03-07 16:40:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 738 @ 35902 updates
2022-03-07 16:40:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:40:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:40:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 738 @ 35902 updates, score 13.475) (writing took 2.2751048831269145 seconds)
2022-03-07 16:40:04 | INFO | fairseq_cli.train | end of epoch 738 (average epoch stats below)
2022-03-07 16:40:04 | INFO | train | epoch 738 | loss 2.457 | nll_loss 0.332 | ppl 1.26 | wps 25252.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35902 | lr 0.000166894 | gnorm 0.374 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 99449
2022-03-07 16:40:04 | INFO | fairseq.trainer | begin training epoch 739
2022-03-07 16:40:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:42:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:42:08 | INFO | valid | epoch 739 | valid on 'valid' subset | loss 13.523 | nll_loss 12.83 | ppl 7279.82 | wps 47716.8 | wpb 510.9 | bsz 1 | num_updates 35951 | best_loss 9.157
2022-03-07 16:42:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 739 @ 35951 updates
2022-03-07 16:42:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:42:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:42:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 739 @ 35951 updates, score 13.523) (writing took 2.338219911791384 seconds)
2022-03-07 16:42:10 | INFO | fairseq_cli.train | end of epoch 739 (average epoch stats below)
2022-03-07 16:42:10 | INFO | train | epoch 739 | loss 2.457 | nll_loss 0.333 | ppl 1.26 | wps 25215.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35951 | lr 0.00016678 | gnorm 0.379 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 99575
2022-03-07 16:42:10 | INFO | fairseq.trainer | begin training epoch 740
2022-03-07 16:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:42:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:44:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:44:14 | INFO | valid | epoch 740 | valid on 'valid' subset | loss 13.577 | nll_loss 12.887 | ppl 7576.95 | wps 48069.6 | wpb 510.9 | bsz 1 | num_updates 35999 | best_loss 9.157
2022-03-07 16:44:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 740 @ 35999 updates
2022-03-07 16:44:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:44:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:44:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 740 @ 35999 updates, score 13.577) (writing took 2.2525191353634 seconds)
2022-03-07 16:44:16 | INFO | fairseq_cli.train | end of epoch 740 (average epoch stats below)
2022-03-07 16:44:16 | INFO | train | epoch 740 | loss 2.457 | nll_loss 0.332 | ppl 1.26 | wps 24729.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35999 | lr 0.000166669 | gnorm 0.369 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 99701
2022-03-07 16:44:16 | INFO | fairseq.trainer | begin training epoch 741
2022-03-07 16:44:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:44:18 | INFO | train_inner | epoch 741:      1 / 49 loss=2.457, nll_loss=0.332, ppl=1.26, wps=24358.4, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=36000, lr=0.000166667, gnorm=0.375, loss_scale=32, train_wall=220, gb_free=8.8, wall=99703
2022-03-07 16:46:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:46:19 | INFO | valid | epoch 741 | valid on 'valid' subset | loss 13.538 | nll_loss 12.846 | ppl 7363.72 | wps 46827.3 | wpb 510.9 | bsz 1 | num_updates 36048 | best_loss 9.157
2022-03-07 16:46:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 741 @ 36048 updates
2022-03-07 16:46:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:46:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:46:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 741 @ 36048 updates, score 13.538) (writing took 2.2780103688128293 seconds)
2022-03-07 16:46:22 | INFO | fairseq_cli.train | end of epoch 741 (average epoch stats below)
2022-03-07 16:46:22 | INFO | train | epoch 741 | loss 2.456 | nll_loss 0.331 | ppl 1.26 | wps 25220.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36048 | lr 0.000166556 | gnorm 0.374 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 99827
2022-03-07 16:46:22 | INFO | fairseq.trainer | begin training epoch 742
2022-03-07 16:46:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:47:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:48:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:48:25 | INFO | valid | epoch 742 | valid on 'valid' subset | loss 13.398 | nll_loss 12.692 | ppl 6616.07 | wps 47843.7 | wpb 510.9 | bsz 1 | num_updates 36096 | best_loss 9.157
2022-03-07 16:48:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 742 @ 36096 updates
2022-03-07 16:48:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:48:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:48:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 742 @ 36096 updates, score 13.398) (writing took 2.3283410742878914 seconds)
2022-03-07 16:48:28 | INFO | fairseq_cli.train | end of epoch 742 (average epoch stats below)
2022-03-07 16:48:28 | INFO | train | epoch 742 | loss 2.456 | nll_loss 0.332 | ppl 1.26 | wps 24716.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36096 | lr 0.000166445 | gnorm 0.37 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 99952
2022-03-07 16:48:28 | INFO | fairseq.trainer | begin training epoch 743
2022-03-07 16:48:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:48:38 | INFO | train_inner | epoch 743:      4 / 49 loss=2.456, nll_loss=0.331, ppl=1.26, wps=25006.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36100, lr=0.000166436, gnorm=0.372, loss_scale=32, train_wall=221, gb_free=8.8, wall=99962
2022-03-07 16:50:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:50:31 | INFO | valid | epoch 743 | valid on 'valid' subset | loss 13.461 | nll_loss 12.758 | ppl 6925.57 | wps 46416 | wpb 510.9 | bsz 1 | num_updates 36145 | best_loss 9.157
2022-03-07 16:50:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 743 @ 36145 updates
2022-03-07 16:50:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:50:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:50:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 743 @ 36145 updates, score 13.461) (writing took 2.3592559010721743 seconds)
2022-03-07 16:50:34 | INFO | fairseq_cli.train | end of epoch 743 (average epoch stats below)
2022-03-07 16:50:34 | INFO | train | epoch 743 | loss 2.456 | nll_loss 0.332 | ppl 1.26 | wps 25195 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36145 | lr 0.000166332 | gnorm 0.37 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 100079
2022-03-07 16:50:34 | INFO | fairseq.trainer | begin training epoch 744
2022-03-07 16:50:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:52:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:52:37 | INFO | valid | epoch 744 | valid on 'valid' subset | loss 13.511 | nll_loss 12.814 | ppl 7203.21 | wps 48602.9 | wpb 510.9 | bsz 1 | num_updates 36194 | best_loss 9.157
2022-03-07 16:52:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 744 @ 36194 updates
2022-03-07 16:52:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:52:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:52:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 744 @ 36194 updates, score 13.511) (writing took 2.2752884891815484 seconds)
2022-03-07 16:52:40 | INFO | fairseq_cli.train | end of epoch 744 (average epoch stats below)
2022-03-07 16:52:40 | INFO | train | epoch 744 | loss 2.456 | nll_loss 0.331 | ppl 1.26 | wps 25269.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36194 | lr 0.000166219 | gnorm 0.376 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 100204
2022-03-07 16:52:40 | INFO | fairseq.trainer | begin training epoch 745
2022-03-07 16:52:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:52:54 | INFO | train_inner | epoch 745:      6 / 49 loss=2.456, nll_loss=0.332, ppl=1.26, wps=25276.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36200, lr=0.000166206, gnorm=0.373, loss_scale=32, train_wall=219, gb_free=8.8, wall=100219
2022-03-07 16:53:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:54:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:54:43 | INFO | valid | epoch 745 | valid on 'valid' subset | loss 13.529 | nll_loss 12.832 | ppl 7291.49 | wps 48351.3 | wpb 510.9 | bsz 1 | num_updates 36242 | best_loss 9.157
2022-03-07 16:54:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 745 @ 36242 updates
2022-03-07 16:54:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:54:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:54:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 745 @ 36242 updates, score 13.529) (writing took 2.2625656141899526 seconds)
2022-03-07 16:54:45 | INFO | fairseq_cli.train | end of epoch 745 (average epoch stats below)
2022-03-07 16:54:45 | INFO | train | epoch 745 | loss 2.456 | nll_loss 0.331 | ppl 1.26 | wps 24746.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36242 | lr 0.000166109 | gnorm 0.369 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 100330
2022-03-07 16:54:45 | INFO | fairseq.trainer | begin training epoch 746
2022-03-07 16:54:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:56:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:56:49 | INFO | valid | epoch 746 | valid on 'valid' subset | loss 13.46 | nll_loss 12.757 | ppl 6921.76 | wps 48134.5 | wpb 510.9 | bsz 1 | num_updates 36291 | best_loss 9.157
2022-03-07 16:56:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 746 @ 36291 updates
2022-03-07 16:56:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:56:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:56:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 746 @ 36291 updates, score 13.46) (writing took 2.2708910857327282 seconds)
2022-03-07 16:56:51 | INFO | fairseq_cli.train | end of epoch 746 (average epoch stats below)
2022-03-07 16:56:51 | INFO | train | epoch 746 | loss 2.456 | nll_loss 0.332 | ppl 1.26 | wps 25247.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36291 | lr 0.000165997 | gnorm 0.373 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 100456
2022-03-07 16:56:51 | INFO | fairseq.trainer | begin training epoch 747
2022-03-07 16:56:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:57:14 | INFO | train_inner | epoch 747:      9 / 49 loss=2.456, nll_loss=0.331, ppl=1.26, wps=25034, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36300, lr=0.000165977, gnorm=0.371, loss_scale=32, train_wall=221, gb_free=8.8, wall=100478
2022-03-07 16:58:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:58:55 | INFO | valid | epoch 747 | valid on 'valid' subset | loss 13.581 | nll_loss 12.892 | ppl 7603.05 | wps 48258.1 | wpb 510.9 | bsz 1 | num_updates 36340 | best_loss 9.157
2022-03-07 16:58:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 747 @ 36340 updates
2022-03-07 16:58:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:58:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:58:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 747 @ 36340 updates, score 13.581) (writing took 2.3567999163642526 seconds)
2022-03-07 16:58:57 | INFO | fairseq_cli.train | end of epoch 747 (average epoch stats below)
2022-03-07 16:58:57 | INFO | train | epoch 747 | loss 2.455 | nll_loss 0.331 | ppl 1.26 | wps 25212.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36340 | lr 0.000165885 | gnorm 0.369 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 100582
2022-03-07 16:58:57 | INFO | fairseq.trainer | begin training epoch 748
2022-03-07 16:58:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:59:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:00:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:01:01 | INFO | valid | epoch 748 | valid on 'valid' subset | loss 13.498 | nll_loss 12.802 | ppl 7143.13 | wps 48155.8 | wpb 510.9 | bsz 1 | num_updates 36388 | best_loss 9.157
2022-03-07 17:01:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 748 @ 36388 updates
2022-03-07 17:01:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:01:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:01:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 748 @ 36388 updates, score 13.498) (writing took 2.2593049788847566 seconds)
2022-03-07 17:01:03 | INFO | fairseq_cli.train | end of epoch 748 (average epoch stats below)
2022-03-07 17:01:03 | INFO | train | epoch 748 | loss 2.456 | nll_loss 0.331 | ppl 1.26 | wps 24749.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36388 | lr 0.000165776 | gnorm 0.374 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 100708
2022-03-07 17:01:03 | INFO | fairseq.trainer | begin training epoch 749
2022-03-07 17:01:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:01:33 | INFO | train_inner | epoch 749:     12 / 49 loss=2.455, nll_loss=0.331, ppl=1.26, wps=25037.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36400, lr=0.000165748, gnorm=0.372, loss_scale=32, train_wall=221, gb_free=8.8, wall=100737
2022-03-07 17:03:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:03:07 | INFO | valid | epoch 749 | valid on 'valid' subset | loss 13.514 | nll_loss 12.822 | ppl 7239.55 | wps 48345.9 | wpb 510.9 | bsz 1 | num_updates 36437 | best_loss 9.157
2022-03-07 17:03:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 749 @ 36437 updates
2022-03-07 17:03:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:03:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:03:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 749 @ 36437 updates, score 13.514) (writing took 2.3298329571262 seconds)
2022-03-07 17:03:09 | INFO | fairseq_cli.train | end of epoch 749 (average epoch stats below)
2022-03-07 17:03:09 | INFO | train | epoch 749 | loss 2.455 | nll_loss 0.331 | ppl 1.26 | wps 25233.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36437 | lr 0.000165664 | gnorm 0.372 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 100834
2022-03-07 17:03:09 | INFO | fairseq.trainer | begin training epoch 750
2022-03-07 17:03:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:04:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:05:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:05:12 | INFO | valid | epoch 750 | valid on 'valid' subset | loss 13.516 | nll_loss 12.823 | ppl 7243.65 | wps 47892.7 | wpb 510.9 | bsz 1 | num_updates 36485 | best_loss 9.157
2022-03-07 17:05:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 750 @ 36485 updates
2022-03-07 17:05:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:05:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:05:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 750 @ 36485 updates, score 13.516) (writing took 2.3188047520816326 seconds)
2022-03-07 17:05:15 | INFO | fairseq_cli.train | end of epoch 750 (average epoch stats below)
2022-03-07 17:05:15 | INFO | train | epoch 750 | loss 2.454 | nll_loss 0.33 | ppl 1.26 | wps 24747.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36485 | lr 0.000165555 | gnorm 0.365 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 100960
2022-03-07 17:05:15 | INFO | fairseq.trainer | begin training epoch 751
2022-03-07 17:05:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:05:52 | INFO | train_inner | epoch 751:     15 / 49 loss=2.455, nll_loss=0.331, ppl=1.26, wps=25029.5, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=36500, lr=0.000165521, gnorm=0.367, loss_scale=32, train_wall=221, gb_free=8.8, wall=100997
2022-03-07 17:07:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:07:18 | INFO | valid | epoch 751 | valid on 'valid' subset | loss 13.447 | nll_loss 12.74 | ppl 6840.29 | wps 47605.6 | wpb 510.9 | bsz 1 | num_updates 36534 | best_loss 9.157
2022-03-07 17:07:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 751 @ 36534 updates
2022-03-07 17:07:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:07:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:07:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 751 @ 36534 updates, score 13.447) (writing took 2.341742335818708 seconds)
2022-03-07 17:07:21 | INFO | fairseq_cli.train | end of epoch 751 (average epoch stats below)
2022-03-07 17:07:21 | INFO | train | epoch 751 | loss 2.455 | nll_loss 0.331 | ppl 1.26 | wps 25235.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36534 | lr 0.000165444 | gnorm 0.37 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 101085
2022-03-07 17:07:21 | INFO | fairseq.trainer | begin training epoch 752
2022-03-07 17:07:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:09:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:09:24 | INFO | valid | epoch 752 | valid on 'valid' subset | loss 13.462 | nll_loss 12.761 | ppl 6939.95 | wps 48242.1 | wpb 510.9 | bsz 1 | num_updates 36583 | best_loss 9.157
2022-03-07 17:09:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 752 @ 36583 updates
2022-03-07 17:09:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:09:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:09:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 752 @ 36583 updates, score 13.462) (writing took 2.2708064592443407 seconds)
2022-03-07 17:09:26 | INFO | fairseq_cli.train | end of epoch 752 (average epoch stats below)
2022-03-07 17:09:26 | INFO | train | epoch 752 | loss 2.455 | nll_loss 0.331 | ppl 1.26 | wps 25302.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36583 | lr 0.000165333 | gnorm 0.372 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 101211
2022-03-07 17:09:26 | INFO | fairseq.trainer | begin training epoch 753
2022-03-07 17:09:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:10:08 | INFO | train_inner | epoch 753:     17 / 49 loss=2.455, nll_loss=0.331, ppl=1.26, wps=25327.9, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=36600, lr=0.000165295, gnorm=0.372, loss_scale=32, train_wall=218, gb_free=8.8, wall=101253
2022-03-07 17:10:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:11:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:11:30 | INFO | valid | epoch 753 | valid on 'valid' subset | loss 13.507 | nll_loss 12.807 | ppl 7168.72 | wps 47873.4 | wpb 510.9 | bsz 1 | num_updates 36631 | best_loss 9.157
2022-03-07 17:11:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 753 @ 36631 updates
2022-03-07 17:11:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:11:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:11:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 753 @ 36631 updates, score 13.507) (writing took 2.2600314719602466 seconds)
2022-03-07 17:11:32 | INFO | fairseq_cli.train | end of epoch 753 (average epoch stats below)
2022-03-07 17:11:32 | INFO | train | epoch 753 | loss 2.455 | nll_loss 0.331 | ppl 1.26 | wps 24750.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36631 | lr 0.000165225 | gnorm 0.373 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 101337
2022-03-07 17:11:32 | INFO | fairseq.trainer | begin training epoch 754
2022-03-07 17:11:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:13:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:13:36 | INFO | valid | epoch 754 | valid on 'valid' subset | loss 13.517 | nll_loss 12.818 | ppl 7219.16 | wps 47887.5 | wpb 510.9 | bsz 1 | num_updates 36680 | best_loss 9.157
2022-03-07 17:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 754 @ 36680 updates
2022-03-07 17:13:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:13:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:13:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 754 @ 36680 updates, score 13.517) (writing took 2.3413398400880396 seconds)
2022-03-07 17:13:38 | INFO | fairseq_cli.train | end of epoch 754 (average epoch stats below)
2022-03-07 17:13:38 | INFO | train | epoch 754 | loss 2.454 | nll_loss 0.33 | ppl 1.26 | wps 25246.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36680 | lr 0.000165115 | gnorm 0.37 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 101463
2022-03-07 17:13:38 | INFO | fairseq.trainer | begin training epoch 755
2022-03-07 17:13:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:14:27 | INFO | train_inner | epoch 755:     20 / 49 loss=2.454, nll_loss=0.33, ppl=1.26, wps=25032.2, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=36700, lr=0.00016507, gnorm=0.37, loss_scale=32, train_wall=221, gb_free=8.8, wall=101512
2022-03-07 17:15:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:15:41 | INFO | valid | epoch 755 | valid on 'valid' subset | loss 13.525 | nll_loss 12.833 | ppl 7298.62 | wps 48288.1 | wpb 510.9 | bsz 1 | num_updates 36729 | best_loss 9.157
2022-03-07 17:15:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 755 @ 36729 updates
2022-03-07 17:15:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:15:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:15:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 755 @ 36729 updates, score 13.525) (writing took 2.3217225573025644 seconds)
2022-03-07 17:15:44 | INFO | fairseq_cli.train | end of epoch 755 (average epoch stats below)
2022-03-07 17:15:44 | INFO | train | epoch 755 | loss 2.454 | nll_loss 0.33 | ppl 1.26 | wps 25257.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36729 | lr 0.000165004 | gnorm 0.367 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 101589
2022-03-07 17:15:44 | INFO | fairseq.trainer | begin training epoch 756
2022-03-07 17:15:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:16:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:17:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:17:47 | INFO | valid | epoch 756 | valid on 'valid' subset | loss 13.582 | nll_loss 12.894 | ppl 7610.82 | wps 48198.4 | wpb 510.9 | bsz 1 | num_updates 36777 | best_loss 9.157
2022-03-07 17:17:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 756 @ 36777 updates
2022-03-07 17:17:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:17:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:17:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 756 @ 36777 updates, score 13.582) (writing took 2.245923701208085 seconds)
2022-03-07 17:17:49 | INFO | fairseq_cli.train | end of epoch 756 (average epoch stats below)
2022-03-07 17:17:49 | INFO | train | epoch 756 | loss 2.454 | nll_loss 0.33 | ppl 1.26 | wps 24782.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36777 | lr 0.000164897 | gnorm 0.37 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 101714
2022-03-07 17:17:49 | INFO | fairseq.trainer | begin training epoch 757
2022-03-07 17:17:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:18:46 | INFO | train_inner | epoch 757:     23 / 49 loss=2.454, nll_loss=0.33, ppl=1.26, wps=25066.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36800, lr=0.000164845, gnorm=0.37, loss_scale=32, train_wall=221, gb_free=8.8, wall=101771
2022-03-07 17:19:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:19:53 | INFO | valid | epoch 757 | valid on 'valid' subset | loss 13.496 | nll_loss 12.799 | ppl 7124.52 | wps 48327.5 | wpb 510.9 | bsz 1 | num_updates 36826 | best_loss 9.157
2022-03-07 17:19:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 757 @ 36826 updates
2022-03-07 17:19:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:19:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:19:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 757 @ 36826 updates, score 13.496) (writing took 2.2530472609214485 seconds)
2022-03-07 17:19:55 | INFO | fairseq_cli.train | end of epoch 757 (average epoch stats below)
2022-03-07 17:19:55 | INFO | train | epoch 757 | loss 2.454 | nll_loss 0.33 | ppl 1.26 | wps 25290.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36826 | lr 0.000164787 | gnorm 0.371 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 101840
2022-03-07 17:19:55 | INFO | fairseq.trainer | begin training epoch 758
2022-03-07 17:19:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:21:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:21:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:21:59 | INFO | valid | epoch 758 | valid on 'valid' subset | loss 13.521 | nll_loss 12.826 | ppl 7259.54 | wps 45897.5 | wpb 510.9 | bsz 1 | num_updates 36874 | best_loss 9.157
2022-03-07 17:21:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 758 @ 36874 updates
2022-03-07 17:21:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:22:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:22:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 758 @ 36874 updates, score 13.521) (writing took 2.2923341379500926 seconds)
2022-03-07 17:22:01 | INFO | fairseq_cli.train | end of epoch 758 (average epoch stats below)
2022-03-07 17:22:01 | INFO | train | epoch 758 | loss 2.453 | nll_loss 0.329 | ppl 1.26 | wps 24690.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36874 | lr 0.00016468 | gnorm 0.368 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 101966
2022-03-07 17:22:01 | INFO | fairseq.trainer | begin training epoch 759
2022-03-07 17:22:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:23:05 | INFO | train_inner | epoch 759:     26 / 49 loss=2.453, nll_loss=0.33, ppl=1.26, wps=25052.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36900, lr=0.000164622, gnorm=0.368, loss_scale=32, train_wall=221, gb_free=8.8, wall=102030
2022-03-07 17:24:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:24:05 | INFO | valid | epoch 759 | valid on 'valid' subset | loss 13.58 | nll_loss 12.893 | ppl 7603.79 | wps 48234.6 | wpb 510.9 | bsz 1 | num_updates 36923 | best_loss 9.157
2022-03-07 17:24:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 759 @ 36923 updates
2022-03-07 17:24:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:24:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:24:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 759 @ 36923 updates, score 13.58) (writing took 2.349599429871887 seconds)
2022-03-07 17:24:07 | INFO | fairseq_cli.train | end of epoch 759 (average epoch stats below)
2022-03-07 17:24:07 | INFO | train | epoch 759 | loss 2.453 | nll_loss 0.329 | ppl 1.26 | wps 25266.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36923 | lr 0.00016457 | gnorm 0.364 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 102092
2022-03-07 17:24:07 | INFO | fairseq.trainer | begin training epoch 760
2022-03-07 17:24:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:26:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:26:11 | INFO | valid | epoch 760 | valid on 'valid' subset | loss 13.43 | nll_loss 12.725 | ppl 6770.03 | wps 47177.2 | wpb 510.9 | bsz 1 | num_updates 36972 | best_loss 9.157
2022-03-07 17:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 760 @ 36972 updates
2022-03-07 17:26:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:26:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:26:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 760 @ 36972 updates, score 13.43) (writing took 2.2912799110636115 seconds)
2022-03-07 17:26:13 | INFO | fairseq_cli.train | end of epoch 760 (average epoch stats below)
2022-03-07 17:26:13 | INFO | train | epoch 760 | loss 2.453 | nll_loss 0.33 | ppl 1.26 | wps 25168.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36972 | lr 0.000164461 | gnorm 0.368 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 102218
2022-03-07 17:26:13 | INFO | fairseq.trainer | begin training epoch 761
2022-03-07 17:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:27:22 | INFO | train_inner | epoch 761:     28 / 49 loss=2.453, nll_loss=0.329, ppl=1.26, wps=25193.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37000, lr=0.000164399, gnorm=0.368, loss_scale=64, train_wall=219, gb_free=8.8, wall=102287
2022-03-07 17:27:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:28:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:28:17 | INFO | valid | epoch 761 | valid on 'valid' subset | loss 13.51 | nll_loss 12.815 | ppl 7205.57 | wps 48075.3 | wpb 510.9 | bsz 1 | num_updates 37020 | best_loss 9.157
2022-03-07 17:28:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 761 @ 37020 updates
2022-03-07 17:28:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:28:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:28:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 761 @ 37020 updates, score 13.51) (writing took 2.253793063107878 seconds)
2022-03-07 17:28:19 | INFO | fairseq_cli.train | end of epoch 761 (average epoch stats below)
2022-03-07 17:28:19 | INFO | train | epoch 761 | loss 2.453 | nll_loss 0.33 | ppl 1.26 | wps 24687.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37020 | lr 0.000164355 | gnorm 0.373 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 102344
2022-03-07 17:28:19 | INFO | fairseq.trainer | begin training epoch 762
2022-03-07 17:28:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:30:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:30:23 | INFO | valid | epoch 762 | valid on 'valid' subset | loss 13.507 | nll_loss 12.806 | ppl 7159.04 | wps 45624.7 | wpb 510.9 | bsz 1 | num_updates 37069 | best_loss 9.157
2022-03-07 17:30:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 762 @ 37069 updates
2022-03-07 17:30:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:30:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:30:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 762 @ 37069 updates, score 13.507) (writing took 2.413683900143951 seconds)
2022-03-07 17:30:25 | INFO | fairseq_cli.train | end of epoch 762 (average epoch stats below)
2022-03-07 17:30:25 | INFO | train | epoch 762 | loss 2.453 | nll_loss 0.329 | ppl 1.26 | wps 25189.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37069 | lr 0.000164246 | gnorm 0.372 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 102470
2022-03-07 17:30:25 | INFO | fairseq.trainer | begin training epoch 763
2022-03-07 17:30:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:31:41 | INFO | train_inner | epoch 763:     31 / 49 loss=2.453, nll_loss=0.33, ppl=1.26, wps=25046.2, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=37100, lr=0.000164177, gnorm=0.371, loss_scale=32, train_wall=221, gb_free=8.8, wall=102546
2022-03-07 17:32:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:32:29 | INFO | valid | epoch 763 | valid on 'valid' subset | loss 13.536 | nll_loss 12.839 | ppl 7328.28 | wps 48012 | wpb 510.9 | bsz 1 | num_updates 37118 | best_loss 9.157
2022-03-07 17:32:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 763 @ 37118 updates
2022-03-07 17:32:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:32:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:32:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 763 @ 37118 updates, score 13.536) (writing took 2.398284003138542 seconds)
2022-03-07 17:32:31 | INFO | fairseq_cli.train | end of epoch 763 (average epoch stats below)
2022-03-07 17:32:31 | INFO | train | epoch 763 | loss 2.453 | nll_loss 0.329 | ppl 1.26 | wps 25241.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37118 | lr 0.000164137 | gnorm 0.372 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 102596
2022-03-07 17:32:31 | INFO | fairseq.trainer | begin training epoch 764
2022-03-07 17:32:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:33:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:34:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:34:35 | INFO | valid | epoch 764 | valid on 'valid' subset | loss 13.524 | nll_loss 12.829 | ppl 7276.96 | wps 48088.1 | wpb 510.9 | bsz 1 | num_updates 37166 | best_loss 9.157
2022-03-07 17:34:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 764 @ 37166 updates
2022-03-07 17:34:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:34:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:34:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 764 @ 37166 updates, score 13.524) (writing took 2.269525504205376 seconds)
2022-03-07 17:34:37 | INFO | fairseq_cli.train | end of epoch 764 (average epoch stats below)
2022-03-07 17:34:37 | INFO | train | epoch 764 | loss 2.453 | nll_loss 0.329 | ppl 1.26 | wps 24748.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37166 | lr 0.000164031 | gnorm 0.369 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 102722
2022-03-07 17:34:37 | INFO | fairseq.trainer | begin training epoch 765
2022-03-07 17:34:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:36:00 | INFO | train_inner | epoch 765:     34 / 49 loss=2.452, nll_loss=0.329, ppl=1.26, wps=25035.7, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=37200, lr=0.000163956, gnorm=0.369, loss_scale=32, train_wall=221, gb_free=8.8, wall=102805
2022-03-07 17:36:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:36:41 | INFO | valid | epoch 765 | valid on 'valid' subset | loss 13.507 | nll_loss 12.817 | ppl 7213.66 | wps 48121.2 | wpb 510.9 | bsz 1 | num_updates 37215 | best_loss 9.157
2022-03-07 17:36:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 765 @ 37215 updates
2022-03-07 17:36:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:36:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:36:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 765 @ 37215 updates, score 13.507) (writing took 2.2528581200167537 seconds)
2022-03-07 17:36:43 | INFO | fairseq_cli.train | end of epoch 765 (average epoch stats below)
2022-03-07 17:36:43 | INFO | train | epoch 765 | loss 2.452 | nll_loss 0.329 | ppl 1.26 | wps 25278.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37215 | lr 0.000163923 | gnorm 0.366 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 102848
2022-03-07 17:36:43 | INFO | fairseq.trainer | begin training epoch 766
2022-03-07 17:36:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:38:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:38:47 | INFO | valid | epoch 766 | valid on 'valid' subset | loss 13.502 | nll_loss 12.804 | ppl 7152.52 | wps 46740.6 | wpb 510.9 | bsz 1 | num_updates 37264 | best_loss 9.157
2022-03-07 17:38:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 766 @ 37264 updates
2022-03-07 17:38:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:38:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:38:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 766 @ 37264 updates, score 13.502) (writing took 2.463965249247849 seconds)
2022-03-07 17:38:49 | INFO | fairseq_cli.train | end of epoch 766 (average epoch stats below)
2022-03-07 17:38:49 | INFO | train | epoch 766 | loss 2.452 | nll_loss 0.329 | ppl 1.26 | wps 25179 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37264 | lr 0.000163816 | gnorm 0.368 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 102974
2022-03-07 17:38:49 | INFO | fairseq.trainer | begin training epoch 767
2022-03-07 17:38:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:38:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:40:20 | INFO | train_inner | epoch 767:     37 / 49 loss=2.452, nll_loss=0.329, ppl=1.26, wps=25035.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37300, lr=0.000163737, gnorm=0.369, loss_scale=32, train_wall=221, gb_free=8.8, wall=103064
2022-03-07 17:40:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:40:52 | INFO | valid | epoch 767 | valid on 'valid' subset | loss 13.604 | nll_loss 12.923 | ppl 7767.48 | wps 48360.6 | wpb 510.9 | bsz 1 | num_updates 37312 | best_loss 9.157
2022-03-07 17:40:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 767 @ 37312 updates
2022-03-07 17:40:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:40:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:40:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 767 @ 37312 updates, score 13.604) (writing took 2.3489915211685 seconds)
2022-03-07 17:40:55 | INFO | fairseq_cli.train | end of epoch 767 (average epoch stats below)
2022-03-07 17:40:55 | INFO | train | epoch 767 | loss 2.451 | nll_loss 0.328 | ppl 1.26 | wps 24762.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37312 | lr 0.00016371 | gnorm 0.37 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 103099
2022-03-07 17:40:55 | INFO | fairseq.trainer | begin training epoch 768
2022-03-07 17:40:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:42:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:42:58 | INFO | valid | epoch 768 | valid on 'valid' subset | loss 13.48 | nll_loss 12.782 | ppl 7042.84 | wps 48012.4 | wpb 510.9 | bsz 1 | num_updates 37361 | best_loss 9.157
2022-03-07 17:42:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 768 @ 37361 updates
2022-03-07 17:42:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:43:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:43:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 768 @ 37361 updates, score 13.48) (writing took 2.275708752684295 seconds)
2022-03-07 17:43:00 | INFO | fairseq_cli.train | end of epoch 768 (average epoch stats below)
2022-03-07 17:43:00 | INFO | train | epoch 768 | loss 2.452 | nll_loss 0.329 | ppl 1.26 | wps 25268.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37361 | lr 0.000163603 | gnorm 0.37 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 103225
2022-03-07 17:43:00 | INFO | fairseq.trainer | begin training epoch 769
2022-03-07 17:43:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:44:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:44:39 | INFO | train_inner | epoch 769:     40 / 49 loss=2.452, nll_loss=0.329, ppl=1.26, wps=25040.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37400, lr=0.000163517, gnorm=0.373, loss_scale=32, train_wall=221, gb_free=8.8, wall=103323
2022-03-07 17:44:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:45:04 | INFO | valid | epoch 769 | valid on 'valid' subset | loss 13.525 | nll_loss 12.831 | ppl 7288.61 | wps 48265 | wpb 510.9 | bsz 1 | num_updates 37409 | best_loss 9.157
2022-03-07 17:45:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 769 @ 37409 updates
2022-03-07 17:45:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:45:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:45:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 769 @ 37409 updates, score 13.525) (writing took 2.271660631056875 seconds)
2022-03-07 17:45:06 | INFO | fairseq_cli.train | end of epoch 769 (average epoch stats below)
2022-03-07 17:45:06 | INFO | train | epoch 769 | loss 2.452 | nll_loss 0.329 | ppl 1.26 | wps 24755.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37409 | lr 0.000163498 | gnorm 0.373 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 103351
2022-03-07 17:45:06 | INFO | fairseq.trainer | begin training epoch 770
2022-03-07 17:45:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:47:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:47:10 | INFO | valid | epoch 770 | valid on 'valid' subset | loss 13.522 | nll_loss 12.828 | ppl 7273.46 | wps 47986.7 | wpb 510.9 | bsz 1 | num_updates 37458 | best_loss 9.157
2022-03-07 17:47:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 770 @ 37458 updates
2022-03-07 17:47:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:47:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:47:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 770 @ 37458 updates, score 13.522) (writing took 2.3969023688696325 seconds)
2022-03-07 17:47:12 | INFO | fairseq_cli.train | end of epoch 770 (average epoch stats below)
2022-03-07 17:47:12 | INFO | train | epoch 770 | loss 2.451 | nll_loss 0.328 | ppl 1.26 | wps 25199.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37458 | lr 0.000163391 | gnorm 0.367 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 103477
2022-03-07 17:47:12 | INFO | fairseq.trainer | begin training epoch 771
2022-03-07 17:47:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:48:55 | INFO | train_inner | epoch 771:     42 / 49 loss=2.451, nll_loss=0.328, ppl=1.26, wps=25284.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37500, lr=0.000163299, gnorm=0.365, loss_scale=32, train_wall=219, gb_free=8.8, wall=103580
2022-03-07 17:49:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:49:16 | INFO | valid | epoch 771 | valid on 'valid' subset | loss 13.62 | nll_loss 12.933 | ppl 7821.78 | wps 47932.2 | wpb 510.9 | bsz 1 | num_updates 37507 | best_loss 9.157
2022-03-07 17:49:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 771 @ 37507 updates
2022-03-07 17:49:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:49:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:49:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 771 @ 37507 updates, score 13.62) (writing took 2.3129092920571566 seconds)
2022-03-07 17:49:18 | INFO | fairseq_cli.train | end of epoch 771 (average epoch stats below)
2022-03-07 17:49:18 | INFO | train | epoch 771 | loss 2.451 | nll_loss 0.328 | ppl 1.26 | wps 25291.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37507 | lr 0.000163284 | gnorm 0.364 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 103603
2022-03-07 17:49:18 | INFO | fairseq.trainer | begin training epoch 772
2022-03-07 17:49:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:51:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:51:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:51:22 | INFO | valid | epoch 772 | valid on 'valid' subset | loss 13.585 | nll_loss 12.893 | ppl 7604.45 | wps 45336.3 | wpb 510.9 | bsz 1 | num_updates 37555 | best_loss 9.157
2022-03-07 17:51:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 772 @ 37555 updates
2022-03-07 17:51:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:51:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:51:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 772 @ 37555 updates, score 13.585) (writing took 3.1317397858947515 seconds)
2022-03-07 17:51:25 | INFO | fairseq_cli.train | end of epoch 772 (average epoch stats below)
2022-03-07 17:51:25 | INFO | train | epoch 772 | loss 2.451 | nll_loss 0.328 | ppl 1.25 | wps 24430.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37555 | lr 0.00016318 | gnorm 0.367 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103730
2022-03-07 17:51:25 | INFO | fairseq.trainer | begin training epoch 773
2022-03-07 17:51:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:53:17 | INFO | train_inner | epoch 773:     45 / 49 loss=2.451, nll_loss=0.328, ppl=1.25, wps=24749.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=37600, lr=0.000163082, gnorm=0.367, loss_scale=32, train_wall=223, gb_free=8.8, wall=103842
2022-03-07 17:53:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:53:31 | INFO | valid | epoch 773 | valid on 'valid' subset | loss 13.579 | nll_loss 12.892 | ppl 7603.62 | wps 46741.3 | wpb 510.9 | bsz 1 | num_updates 37604 | best_loss 9.157
2022-03-07 17:53:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 773 @ 37604 updates
2022-03-07 17:53:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:53:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:53:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 773 @ 37604 updates, score 13.579) (writing took 2.2673459318466485 seconds)
2022-03-07 17:53:33 | INFO | fairseq_cli.train | end of epoch 773 (average epoch stats below)
2022-03-07 17:53:33 | INFO | train | epoch 773 | loss 2.451 | nll_loss 0.328 | ppl 1.25 | wps 24904.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37604 | lr 0.000163073 | gnorm 0.368 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 103858
2022-03-07 17:53:33 | INFO | fairseq.trainer | begin training epoch 774
2022-03-07 17:53:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:55:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:55:38 | INFO | valid | epoch 774 | valid on 'valid' subset | loss 13.526 | nll_loss 12.834 | ppl 7300.23 | wps 47402.2 | wpb 510.9 | bsz 1 | num_updates 37653 | best_loss 9.157
2022-03-07 17:55:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 774 @ 37653 updates
2022-03-07 17:55:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:55:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:55:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 774 @ 37653 updates, score 13.526) (writing took 2.4300238569267094 seconds)
2022-03-07 17:55:41 | INFO | fairseq_cli.train | end of epoch 774 (average epoch stats below)
2022-03-07 17:55:41 | INFO | train | epoch 774 | loss 2.45 | nll_loss 0.327 | ppl 1.25 | wps 24919 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37653 | lr 0.000162967 | gnorm 0.367 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103985
2022-03-07 17:55:41 | INFO | fairseq.trainer | begin training epoch 775
2022-03-07 17:55:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:56:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:57:38 | INFO | train_inner | epoch 775:     48 / 49 loss=2.451, nll_loss=0.328, ppl=1.26, wps=24875.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=37700, lr=0.000162866, gnorm=0.367, loss_scale=32, train_wall=222, gb_free=8.8, wall=104103
2022-03-07 17:57:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:57:44 | INFO | valid | epoch 775 | valid on 'valid' subset | loss 13.554 | nll_loss 12.864 | ppl 7457.14 | wps 48163 | wpb 510.9 | bsz 1 | num_updates 37701 | best_loss 9.157
2022-03-07 17:57:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 775 @ 37701 updates
2022-03-07 17:57:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:57:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:57:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 775 @ 37701 updates, score 13.554) (writing took 2.350521930027753 seconds)
2022-03-07 17:57:46 | INFO | fairseq_cli.train | end of epoch 775 (average epoch stats below)
2022-03-07 17:57:46 | INFO | train | epoch 775 | loss 2.451 | nll_loss 0.328 | ppl 1.26 | wps 24756.6 | ups 0.38 | wpb 64853.3 | bsz 126.7 | num_updates 37701 | lr 0.000162863 | gnorm 0.366 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 104111
2022-03-07 17:57:46 | INFO | fairseq.trainer | begin training epoch 776
2022-03-07 17:57:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:59:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:59:50 | INFO | valid | epoch 776 | valid on 'valid' subset | loss 13.503 | nll_loss 12.804 | ppl 7151.66 | wps 47683.2 | wpb 510.9 | bsz 1 | num_updates 37750 | best_loss 9.157
2022-03-07 17:59:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 776 @ 37750 updates
2022-03-07 17:59:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:59:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:59:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 776 @ 37750 updates, score 13.503) (writing took 2.289232957176864 seconds)
2022-03-07 17:59:52 | INFO | fairseq_cli.train | end of epoch 776 (average epoch stats below)
2022-03-07 17:59:52 | INFO | train | epoch 776 | loss 2.451 | nll_loss 0.328 | ppl 1.25 | wps 25273.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37750 | lr 0.000162758 | gnorm 0.371 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 104237
2022-03-07 17:59:52 | INFO | fairseq.trainer | begin training epoch 777
2022-03-07 17:59:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:01:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:01:55 | INFO | valid | epoch 777 | valid on 'valid' subset | loss 13.56 | nll_loss 12.871 | ppl 7492.76 | wps 48187.8 | wpb 510.9 | bsz 1 | num_updates 37799 | best_loss 9.157
2022-03-07 18:01:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 777 @ 37799 updates
2022-03-07 18:01:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:01:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:01:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 777 @ 37799 updates, score 13.56) (writing took 2.2923236610367894 seconds)
2022-03-07 18:01:58 | INFO | fairseq_cli.train | end of epoch 777 (average epoch stats below)
2022-03-07 18:01:58 | INFO | train | epoch 777 | loss 2.451 | nll_loss 0.328 | ppl 1.26 | wps 25278.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37799 | lr 0.000162652 | gnorm 0.37 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 104363
2022-03-07 18:01:58 | INFO | fairseq.trainer | begin training epoch 778
2022-03-07 18:01:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:02:00 | INFO | train_inner | epoch 778:      1 / 49 loss=2.451, nll_loss=0.328, ppl=1.26, wps=24617.6, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=37800, lr=0.00016265, gnorm=0.372, loss_scale=32, train_wall=217, gb_free=8.8, wall=104365
2022-03-07 18:02:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:03:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:04:01 | INFO | valid | epoch 778 | valid on 'valid' subset | loss 13.484 | nll_loss 12.785 | ppl 7057.17 | wps 47561.3 | wpb 510.9 | bsz 1 | num_updates 37847 | best_loss 9.157
2022-03-07 18:04:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 778 @ 37847 updates
2022-03-07 18:04:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:04:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:04:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 778 @ 37847 updates, score 13.484) (writing took 2.476038364227861 seconds)
2022-03-07 18:04:04 | INFO | fairseq_cli.train | end of epoch 778 (average epoch stats below)
2022-03-07 18:04:04 | INFO | train | epoch 778 | loss 2.45 | nll_loss 0.327 | ppl 1.25 | wps 24685.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37847 | lr 0.000162549 | gnorm 0.366 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 104489
2022-03-07 18:04:04 | INFO | fairseq.trainer | begin training epoch 779
2022-03-07 18:04:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:06:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:06:07 | INFO | valid | epoch 779 | valid on 'valid' subset | loss 13.547 | nll_loss 12.857 | ppl 7417.18 | wps 48007.6 | wpb 510.9 | bsz 1 | num_updates 37896 | best_loss 9.157
2022-03-07 18:06:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 779 @ 37896 updates
2022-03-07 18:06:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:06:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:06:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 779 @ 37896 updates, score 13.547) (writing took 2.282202100381255 seconds)
2022-03-07 18:06:10 | INFO | fairseq_cli.train | end of epoch 779 (average epoch stats below)
2022-03-07 18:06:10 | INFO | train | epoch 779 | loss 2.45 | nll_loss 0.328 | ppl 1.26 | wps 25273.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37896 | lr 0.000162444 | gnorm 0.368 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 104614
2022-03-07 18:06:10 | INFO | fairseq.trainer | begin training epoch 780
2022-03-07 18:06:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:06:19 | INFO | train_inner | epoch 780:      4 / 49 loss=2.45, nll_loss=0.328, ppl=1.25, wps=25030.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37900, lr=0.000162435, gnorm=0.367, loss_scale=32, train_wall=221, gb_free=8.8, wall=104624
2022-03-07 18:08:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:08:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:08:13 | INFO | valid | epoch 780 | valid on 'valid' subset | loss 13.496 | nll_loss 12.797 | ppl 7117.42 | wps 47909.2 | wpb 510.9 | bsz 1 | num_updates 37944 | best_loss 9.157
2022-03-07 18:08:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 780 @ 37944 updates
2022-03-07 18:08:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:08:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:08:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 780 @ 37944 updates, score 13.496) (writing took 2.2665435569360852 seconds)
2022-03-07 18:08:15 | INFO | fairseq_cli.train | end of epoch 780 (average epoch stats below)
2022-03-07 18:08:15 | INFO | train | epoch 780 | loss 2.45 | nll_loss 0.327 | ppl 1.25 | wps 24754.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37944 | lr 0.000162341 | gnorm 0.369 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 104740
2022-03-07 18:08:15 | INFO | fairseq.trainer | begin training epoch 781
2022-03-07 18:08:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:10:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:10:19 | INFO | valid | epoch 781 | valid on 'valid' subset | loss 13.469 | nll_loss 12.769 | ppl 6979.22 | wps 48001.1 | wpb 510.9 | bsz 1 | num_updates 37993 | best_loss 9.157
2022-03-07 18:10:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 781 @ 37993 updates
2022-03-07 18:10:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:10:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:10:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 781 @ 37993 updates, score 13.469) (writing took 2.3007786301895976 seconds)
2022-03-07 18:10:21 | INFO | fairseq_cli.train | end of epoch 781 (average epoch stats below)
2022-03-07 18:10:21 | INFO | train | epoch 781 | loss 2.449 | nll_loss 0.327 | ppl 1.25 | wps 25245.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37993 | lr 0.000162236 | gnorm 0.37 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 104866
2022-03-07 18:10:21 | INFO | fairseq.trainer | begin training epoch 782
2022-03-07 18:10:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:10:39 | INFO | train_inner | epoch 782:      7 / 49 loss=2.449, nll_loss=0.327, ppl=1.25, wps=25031.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=38000, lr=0.000162221, gnorm=0.369, loss_scale=32, train_wall=221, gb_free=8.8, wall=104883
2022-03-07 18:12:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:12:25 | INFO | valid | epoch 782 | valid on 'valid' subset | loss 13.517 | nll_loss 12.82 | ppl 7232.81 | wps 47536 | wpb 510.9 | bsz 1 | num_updates 38042 | best_loss 9.157
2022-03-07 18:12:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 782 @ 38042 updates
2022-03-07 18:12:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:12:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:12:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 782 @ 38042 updates, score 13.517) (writing took 2.3916369383223355 seconds)
2022-03-07 18:12:28 | INFO | fairseq_cli.train | end of epoch 782 (average epoch stats below)
2022-03-07 18:12:28 | INFO | train | epoch 782 | loss 2.449 | nll_loss 0.327 | ppl 1.25 | wps 25127.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38042 | lr 0.000162132 | gnorm 0.365 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 104992
2022-03-07 18:12:28 | INFO | fairseq.trainer | begin training epoch 783
2022-03-07 18:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:13:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:14:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:14:32 | INFO | valid | epoch 783 | valid on 'valid' subset | loss 13.523 | nll_loss 12.831 | ppl 7285.27 | wps 45863.8 | wpb 510.9 | bsz 1 | num_updates 38090 | best_loss 9.157
2022-03-07 18:14:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 783 @ 38090 updates
2022-03-07 18:14:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:14:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:14:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 783 @ 38090 updates, score 13.523) (writing took 2.3041163966991007 seconds)
2022-03-07 18:14:34 | INFO | fairseq_cli.train | end of epoch 783 (average epoch stats below)
2022-03-07 18:14:34 | INFO | train | epoch 783 | loss 2.449 | nll_loss 0.326 | ppl 1.25 | wps 24664.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38090 | lr 0.00016203 | gnorm 0.359 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 105119
2022-03-07 18:14:34 | INFO | fairseq.trainer | begin training epoch 784
2022-03-07 18:14:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:14:59 | INFO | train_inner | epoch 784:     10 / 49 loss=2.449, nll_loss=0.326, ppl=1.25, wps=24963.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38100, lr=0.000162008, gnorm=0.363, loss_scale=32, train_wall=221, gb_free=8.8, wall=105143
2022-03-07 18:16:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:16:37 | INFO | valid | epoch 784 | valid on 'valid' subset | loss 13.446 | nll_loss 12.75 | ppl 6888.32 | wps 47882.8 | wpb 510.9 | bsz 1 | num_updates 38139 | best_loss 9.157
2022-03-07 18:16:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 784 @ 38139 updates
2022-03-07 18:16:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:16:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:16:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 784 @ 38139 updates, score 13.446) (writing took 2.2460856060497463 seconds)
2022-03-07 18:16:40 | INFO | fairseq_cli.train | end of epoch 784 (average epoch stats below)
2022-03-07 18:16:40 | INFO | train | epoch 784 | loss 2.449 | nll_loss 0.327 | ppl 1.25 | wps 25258.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38139 | lr 0.000161926 | gnorm 0.37 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 105244
2022-03-07 18:16:40 | INFO | fairseq.trainer | begin training epoch 785
2022-03-07 18:16:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:18:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:18:43 | INFO | valid | epoch 785 | valid on 'valid' subset | loss 13.584 | nll_loss 12.897 | ppl 7628.95 | wps 47189.2 | wpb 510.9 | bsz 1 | num_updates 38188 | best_loss 9.157
2022-03-07 18:18:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 785 @ 38188 updates
2022-03-07 18:18:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:18:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:18:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 785 @ 38188 updates, score 13.584) (writing took 2.288487207144499 seconds)
2022-03-07 18:18:46 | INFO | fairseq_cli.train | end of epoch 785 (average epoch stats below)
2022-03-07 18:18:46 | INFO | train | epoch 785 | loss 2.449 | nll_loss 0.327 | ppl 1.25 | wps 25241.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38188 | lr 0.000161822 | gnorm 0.367 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 105370
2022-03-07 18:18:46 | INFO | fairseq.trainer | begin training epoch 786
2022-03-07 18:18:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:19:16 | INFO | train_inner | epoch 786:     12 / 49 loss=2.449, nll_loss=0.327, ppl=1.25, wps=25226.6, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=38200, lr=0.000161796, gnorm=0.369, loss_scale=64, train_wall=219, gb_free=8.8, wall=105400
2022-03-07 18:19:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:20:51 | INFO | valid | epoch 786 | valid on 'valid' subset | loss 13.518 | nll_loss 12.828 | ppl 7271.42 | wps 46023.6 | wpb 510.9 | bsz 1 | num_updates 38236 | best_loss 9.157
2022-03-07 18:20:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 786 @ 38236 updates
2022-03-07 18:20:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:20:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:20:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 786 @ 38236 updates, score 13.518) (writing took 2.3550962232984602 seconds)
2022-03-07 18:20:54 | INFO | fairseq_cli.train | end of epoch 786 (average epoch stats below)
2022-03-07 18:20:54 | INFO | train | epoch 786 | loss 2.449 | nll_loss 0.326 | ppl 1.25 | wps 24292 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 38236 | lr 0.00016172 | gnorm 0.368 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 105498
2022-03-07 18:20:54 | INFO | fairseq.trainer | begin training epoch 787
2022-03-07 18:20:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:22:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:22:59 | INFO | valid | epoch 787 | valid on 'valid' subset | loss 13.576 | nll_loss 12.887 | ppl 7577.18 | wps 48162.7 | wpb 510.9 | bsz 1 | num_updates 38285 | best_loss 9.157
2022-03-07 18:22:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 787 @ 38285 updates
2022-03-07 18:22:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:23:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:23:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 787 @ 38285 updates, score 13.576) (writing took 2.274101353250444 seconds)
2022-03-07 18:23:01 | INFO | fairseq_cli.train | end of epoch 787 (average epoch stats below)
2022-03-07 18:23:01 | INFO | train | epoch 787 | loss 2.448 | nll_loss 0.326 | ppl 1.25 | wps 24963.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38285 | lr 0.000161616 | gnorm 0.363 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 105626
2022-03-07 18:23:01 | INFO | fairseq.trainer | begin training epoch 788
2022-03-07 18:23:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:23:38 | INFO | train_inner | epoch 788:     15 / 49 loss=2.449, nll_loss=0.327, ppl=1.25, wps=24742.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=38300, lr=0.000161585, gnorm=0.365, loss_scale=32, train_wall=224, gb_free=8.8, wall=105663
2022-03-07 18:25:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:25:04 | INFO | valid | epoch 788 | valid on 'valid' subset | loss 13.586 | nll_loss 12.896 | ppl 7620.32 | wps 48282.4 | wpb 510.9 | bsz 1 | num_updates 38334 | best_loss 9.157
2022-03-07 18:25:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 788 @ 38334 updates
2022-03-07 18:25:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:25:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:25:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 788 @ 38334 updates, score 13.586) (writing took 2.286973414942622 seconds)
2022-03-07 18:25:07 | INFO | fairseq_cli.train | end of epoch 788 (average epoch stats below)
2022-03-07 18:25:07 | INFO | train | epoch 788 | loss 2.448 | nll_loss 0.326 | ppl 1.25 | wps 25275.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38334 | lr 0.000161513 | gnorm 0.364 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 105752
2022-03-07 18:25:07 | INFO | fairseq.trainer | begin training epoch 789
2022-03-07 18:25:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:25:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:27:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:27:10 | INFO | valid | epoch 789 | valid on 'valid' subset | loss 13.582 | nll_loss 12.899 | ppl 7636.19 | wps 48258 | wpb 510.9 | bsz 1 | num_updates 38382 | best_loss 9.157
2022-03-07 18:27:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 789 @ 38382 updates
2022-03-07 18:27:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:27:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:27:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 789 @ 38382 updates, score 13.582) (writing took 2.221918282099068 seconds)
2022-03-07 18:27:13 | INFO | fairseq_cli.train | end of epoch 789 (average epoch stats below)
2022-03-07 18:27:13 | INFO | train | epoch 789 | loss 2.448 | nll_loss 0.326 | ppl 1.25 | wps 24753.5 | ups 0.38 | wpb 64853.3 | bsz 126.7 | num_updates 38382 | lr 0.000161412 | gnorm 0.372 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 105877
2022-03-07 18:27:13 | INFO | fairseq.trainer | begin training epoch 790
2022-03-07 18:27:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:27:57 | INFO | train_inner | epoch 790:     18 / 49 loss=2.448, nll_loss=0.326, ppl=1.25, wps=25050.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=38400, lr=0.000161374, gnorm=0.367, loss_scale=32, train_wall=221, gb_free=8.8, wall=105922
2022-03-07 18:29:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:29:16 | INFO | valid | epoch 790 | valid on 'valid' subset | loss 13.494 | nll_loss 12.798 | ppl 7123.79 | wps 47502.6 | wpb 510.9 | bsz 1 | num_updates 38431 | best_loss 9.157
2022-03-07 18:29:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 790 @ 38431 updates
2022-03-07 18:29:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:29:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:29:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 790 @ 38431 updates, score 13.494) (writing took 2.3652267111465335 seconds)
2022-03-07 18:29:18 | INFO | fairseq_cli.train | end of epoch 790 (average epoch stats below)
2022-03-07 18:29:18 | INFO | train | epoch 790 | loss 2.448 | nll_loss 0.326 | ppl 1.25 | wps 25232.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38431 | lr 0.000161309 | gnorm 0.364 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 106003
2022-03-07 18:29:19 | INFO | fairseq.trainer | begin training epoch 791
2022-03-07 18:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:30:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:31:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:31:22 | INFO | valid | epoch 791 | valid on 'valid' subset | loss 13.499 | nll_loss 12.808 | ppl 7171.32 | wps 48082.8 | wpb 510.9 | bsz 1 | num_updates 38479 | best_loss 9.157
2022-03-07 18:31:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 791 @ 38479 updates
2022-03-07 18:31:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:31:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:31:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 791 @ 38479 updates, score 13.499) (writing took 2.3029315010644495 seconds)
2022-03-07 18:31:25 | INFO | fairseq_cli.train | end of epoch 791 (average epoch stats below)
2022-03-07 18:31:25 | INFO | train | epoch 791 | loss 2.448 | nll_loss 0.326 | ppl 1.25 | wps 24694.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38479 | lr 0.000161209 | gnorm 0.364 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 106129
2022-03-07 18:31:25 | INFO | fairseq.trainer | begin training epoch 792
2022-03-07 18:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:32:16 | INFO | train_inner | epoch 792:     21 / 49 loss=2.448, nll_loss=0.326, ppl=1.25, wps=25031.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=38500, lr=0.000161165, gnorm=0.365, loss_scale=32, train_wall=221, gb_free=8.8, wall=106181
2022-03-07 18:33:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:33:28 | INFO | valid | epoch 792 | valid on 'valid' subset | loss 13.598 | nll_loss 12.908 | ppl 7687.5 | wps 47615.3 | wpb 510.9 | bsz 1 | num_updates 38528 | best_loss 9.157
2022-03-07 18:33:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 792 @ 38528 updates
2022-03-07 18:33:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:33:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:33:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 792 @ 38528 updates, score 13.598) (writing took 2.2414360460825264 seconds)
2022-03-07 18:33:30 | INFO | fairseq_cli.train | end of epoch 792 (average epoch stats below)
2022-03-07 18:33:30 | INFO | train | epoch 792 | loss 2.448 | nll_loss 0.326 | ppl 1.25 | wps 25252.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38528 | lr 0.000161106 | gnorm 0.364 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 106255
2022-03-07 18:33:30 | INFO | fairseq.trainer | begin training epoch 793
2022-03-07 18:33:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:35:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:35:34 | INFO | valid | epoch 793 | valid on 'valid' subset | loss 13.532 | nll_loss 12.842 | ppl 7341.1 | wps 48269.6 | wpb 510.9 | bsz 1 | num_updates 38577 | best_loss 9.157
2022-03-07 18:35:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 793 @ 38577 updates
2022-03-07 18:35:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:35:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:35:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 793 @ 38577 updates, score 13.532) (writing took 2.2759404140524566 seconds)
2022-03-07 18:35:36 | INFO | fairseq_cli.train | end of epoch 793 (average epoch stats below)
2022-03-07 18:35:36 | INFO | train | epoch 793 | loss 2.448 | nll_loss 0.326 | ppl 1.25 | wps 25316.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38577 | lr 0.000161004 | gnorm 0.361 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 106381
2022-03-07 18:35:36 | INFO | fairseq.trainer | begin training epoch 794
2022-03-07 18:35:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:36:33 | INFO | train_inner | epoch 794:     23 / 49 loss=2.448, nll_loss=0.326, ppl=1.25, wps=25289.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=38600, lr=0.000160956, gnorm=0.363, loss_scale=64, train_wall=219, gb_free=8.8, wall=106437
2022-03-07 18:36:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:37:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:37:40 | INFO | valid | epoch 794 | valid on 'valid' subset | loss 13.606 | nll_loss 12.92 | ppl 7750.16 | wps 47684.1 | wpb 510.9 | bsz 1 | num_updates 38625 | best_loss 9.157
2022-03-07 18:37:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 794 @ 38625 updates
2022-03-07 18:37:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:37:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:37:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 794 @ 38625 updates, score 13.606) (writing took 2.3539371551014483 seconds)
2022-03-07 18:37:42 | INFO | fairseq_cli.train | end of epoch 794 (average epoch stats below)
2022-03-07 18:37:42 | INFO | train | epoch 794 | loss 2.448 | nll_loss 0.326 | ppl 1.25 | wps 24695.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38625 | lr 0.000160904 | gnorm 0.368 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 106507
2022-03-07 18:37:42 | INFO | fairseq.trainer | begin training epoch 795
2022-03-07 18:37:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:39:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:39:46 | INFO | valid | epoch 795 | valid on 'valid' subset | loss 13.597 | nll_loss 12.913 | ppl 7711.62 | wps 48191.2 | wpb 510.9 | bsz 1 | num_updates 38674 | best_loss 9.157
2022-03-07 18:39:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 795 @ 38674 updates
2022-03-07 18:39:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:39:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:39:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 795 @ 38674 updates, score 13.597) (writing took 2.256499858107418 seconds)
2022-03-07 18:39:48 | INFO | fairseq_cli.train | end of epoch 795 (average epoch stats below)
2022-03-07 18:39:48 | INFO | train | epoch 795 | loss 2.447 | nll_loss 0.325 | ppl 1.25 | wps 25238.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38674 | lr 0.000160802 | gnorm 0.369 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 106633
2022-03-07 18:39:48 | INFO | fairseq.trainer | begin training epoch 796
2022-03-07 18:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:40:52 | INFO | train_inner | epoch 796:     26 / 49 loss=2.447, nll_loss=0.325, ppl=1.25, wps=25033.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=38700, lr=0.000160748, gnorm=0.367, loss_scale=32, train_wall=221, gb_free=8.8, wall=106696
2022-03-07 18:41:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:41:51 | INFO | valid | epoch 796 | valid on 'valid' subset | loss 13.595 | nll_loss 12.907 | ppl 7682.67 | wps 48287.7 | wpb 510.9 | bsz 1 | num_updates 38723 | best_loss 9.157
2022-03-07 18:41:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 796 @ 38723 updates
2022-03-07 18:41:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:41:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:41:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 796 @ 38723 updates, score 13.595) (writing took 2.280246810056269 seconds)
2022-03-07 18:41:54 | INFO | fairseq_cli.train | end of epoch 796 (average epoch stats below)
2022-03-07 18:41:54 | INFO | train | epoch 796 | loss 2.447 | nll_loss 0.325 | ppl 1.25 | wps 25280.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38723 | lr 0.0001607 | gnorm 0.364 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 106758
2022-03-07 18:41:54 | INFO | fairseq.trainer | begin training epoch 797
2022-03-07 18:41:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:42:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:43:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:43:57 | INFO | valid | epoch 797 | valid on 'valid' subset | loss 13.447 | nll_loss 12.745 | ppl 6866.05 | wps 48349.2 | wpb 510.9 | bsz 1 | num_updates 38771 | best_loss 9.157
2022-03-07 18:43:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 797 @ 38771 updates
2022-03-07 18:43:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:44:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:44:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 797 @ 38771 updates, score 13.447) (writing took 4.19447534577921 seconds)
2022-03-07 18:44:01 | INFO | fairseq_cli.train | end of epoch 797 (average epoch stats below)
2022-03-07 18:44:01 | INFO | train | epoch 797 | loss 2.447 | nll_loss 0.325 | ppl 1.25 | wps 24423.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38771 | lr 0.0001606 | gnorm 0.37 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 106886
2022-03-07 18:44:01 | INFO | fairseq.trainer | begin training epoch 798
2022-03-07 18:44:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:45:12 | INFO | train_inner | epoch 798:     29 / 49 loss=2.447, nll_loss=0.326, ppl=1.25, wps=24889.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=38800, lr=0.00016054, gnorm=0.369, loss_scale=32, train_wall=221, gb_free=8.8, wall=106957
2022-03-07 18:46:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:46:05 | INFO | valid | epoch 798 | valid on 'valid' subset | loss 13.463 | nll_loss 12.768 | ppl 6972.7 | wps 48183.9 | wpb 510.9 | bsz 1 | num_updates 38820 | best_loss 9.157
2022-03-07 18:46:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 798 @ 38820 updates
2022-03-07 18:46:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:46:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:46:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 798 @ 38820 updates, score 13.463) (writing took 2.3240758855827153 seconds)
2022-03-07 18:46:07 | INFO | fairseq_cli.train | end of epoch 798 (average epoch stats below)
2022-03-07 18:46:07 | INFO | train | epoch 798 | loss 2.447 | nll_loss 0.326 | ppl 1.25 | wps 25220.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38820 | lr 0.000160499 | gnorm 0.367 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 107012
2022-03-07 18:46:07 | INFO | fairseq.trainer | begin training epoch 799
2022-03-07 18:46:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:47:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:48:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:48:10 | INFO | valid | epoch 799 | valid on 'valid' subset | loss 13.546 | nll_loss 12.854 | ppl 7404.11 | wps 48152.4 | wpb 510.9 | bsz 1 | num_updates 38868 | best_loss 9.157
2022-03-07 18:48:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 799 @ 38868 updates
2022-03-07 18:48:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:48:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:48:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 799 @ 38868 updates, score 13.546) (writing took 5.875628989189863 seconds)
2022-03-07 18:48:16 | INFO | fairseq_cli.train | end of epoch 799 (average epoch stats below)
2022-03-07 18:48:16 | INFO | train | epoch 799 | loss 2.447 | nll_loss 0.325 | ppl 1.25 | wps 24066.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 38868 | lr 0.0001604 | gnorm 0.366 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 107141
2022-03-07 18:48:16 | INFO | fairseq.trainer | begin training epoch 800
2022-03-07 18:48:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:49:35 | INFO | train_inner | epoch 800:     32 / 49 loss=2.447, nll_loss=0.325, ppl=1.25, wps=24704.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38900, lr=0.000160334, gnorm=0.366, loss_scale=32, train_wall=221, gb_free=8.8, wall=107220
2022-03-07 18:50:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:50:20 | INFO | valid | epoch 800 | valid on 'valid' subset | loss 13.487 | nll_loss 12.792 | ppl 7089.82 | wps 47902.5 | wpb 510.9 | bsz 1 | num_updates 38917 | best_loss 9.157
2022-03-07 18:50:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 800 @ 38917 updates
2022-03-07 18:50:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:50:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:50:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 800 @ 38917 updates, score 13.487) (writing took 2.2485851608216763 seconds)
2022-03-07 18:50:22 | INFO | fairseq_cli.train | end of epoch 800 (average epoch stats below)
2022-03-07 18:50:22 | INFO | train | epoch 800 | loss 2.447 | nll_loss 0.325 | ppl 1.25 | wps 25273.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38917 | lr 0.000160299 | gnorm 0.368 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 107267
2022-03-07 18:50:22 | INFO | fairseq.trainer | begin training epoch 801
2022-03-07 18:50:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:52:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:52:26 | INFO | valid | epoch 801 | valid on 'valid' subset | loss 13.464 | nll_loss 12.769 | ppl 6979.97 | wps 45753.7 | wpb 510.9 | bsz 1 | num_updates 38966 | best_loss 9.157
2022-03-07 18:52:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 801 @ 38966 updates
2022-03-07 18:52:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:52:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:52:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 801 @ 38966 updates, score 13.464) (writing took 2.4706443729810417 seconds)
2022-03-07 18:52:28 | INFO | fairseq_cli.train | end of epoch 801 (average epoch stats below)
2022-03-07 18:52:28 | INFO | train | epoch 801 | loss 2.447 | nll_loss 0.325 | ppl 1.25 | wps 25163.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38966 | lr 0.000160198 | gnorm 0.37 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 107393
2022-03-07 18:52:28 | INFO | fairseq.trainer | begin training epoch 802
2022-03-07 18:52:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:53:52 | INFO | train_inner | epoch 802:     34 / 49 loss=2.446, nll_loss=0.325, ppl=1.25, wps=25255.9, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=39000, lr=0.000160128, gnorm=0.369, loss_scale=64, train_wall=219, gb_free=8.8, wall=107476
2022-03-07 18:54:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:54:32 | INFO | valid | epoch 802 | valid on 'valid' subset | loss 13.513 | nll_loss 12.82 | ppl 7229.18 | wps 47758.1 | wpb 510.9 | bsz 1 | num_updates 39014 | best_loss 9.157
2022-03-07 18:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 802 @ 39014 updates
2022-03-07 18:54:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:54:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:54:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 802 @ 39014 updates, score 13.513) (writing took 2.322692926041782 seconds)
2022-03-07 18:54:34 | INFO | fairseq_cli.train | end of epoch 802 (average epoch stats below)
2022-03-07 18:54:34 | INFO | train | epoch 802 | loss 2.446 | nll_loss 0.324 | ppl 1.25 | wps 24727.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39014 | lr 0.000160099 | gnorm 0.365 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 107519
2022-03-07 18:54:34 | INFO | fairseq.trainer | begin training epoch 803
2022-03-07 18:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:56:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:56:38 | INFO | valid | epoch 803 | valid on 'valid' subset | loss 13.534 | nll_loss 12.841 | ppl 7336.8 | wps 47939.3 | wpb 510.9 | bsz 1 | num_updates 39063 | best_loss 9.157
2022-03-07 18:56:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 803 @ 39063 updates
2022-03-07 18:56:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:56:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:56:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 803 @ 39063 updates, score 13.534) (writing took 2.2618346828967333 seconds)
2022-03-07 18:56:40 | INFO | fairseq_cli.train | end of epoch 803 (average epoch stats below)
2022-03-07 18:56:40 | INFO | train | epoch 803 | loss 2.445 | nll_loss 0.324 | ppl 1.25 | wps 25276.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39063 | lr 0.000159999 | gnorm 0.367 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 107645
2022-03-07 18:56:40 | INFO | fairseq.trainer | begin training epoch 804
2022-03-07 18:56:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:58:11 | INFO | train_inner | epoch 804:     37 / 49 loss=2.445, nll_loss=0.324, ppl=1.25, wps=25045.9, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=39100, lr=0.000159923, gnorm=0.363, loss_scale=32, train_wall=221, gb_free=8.8, wall=107736
2022-03-07 18:58:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:58:44 | INFO | valid | epoch 804 | valid on 'valid' subset | loss 13.529 | nll_loss 12.836 | ppl 7311.23 | wps 48241.6 | wpb 510.9 | bsz 1 | num_updates 39112 | best_loss 9.157
2022-03-07 18:58:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 804 @ 39112 updates
2022-03-07 18:58:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:58:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:58:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 804 @ 39112 updates, score 13.529) (writing took 2.263823816087097 seconds)
2022-03-07 18:58:46 | INFO | fairseq_cli.train | end of epoch 804 (average epoch stats below)
2022-03-07 18:58:46 | INFO | train | epoch 804 | loss 2.445 | nll_loss 0.324 | ppl 1.25 | wps 25266.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39112 | lr 0.000159899 | gnorm 0.36 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 107771
2022-03-07 18:58:46 | INFO | fairseq.trainer | begin training epoch 805
2022-03-07 18:58:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:00:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:00:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:00:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:00:51 | INFO | valid | epoch 805 | valid on 'valid' subset | loss 13.551 | nll_loss 12.858 | ppl 7425.38 | wps 45255.4 | wpb 510.9 | bsz 1 | num_updates 39159 | best_loss 9.157
2022-03-07 19:00:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 805 @ 39159 updates
2022-03-07 19:00:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:00:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:00:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 805 @ 39159 updates, score 13.551) (writing took 2.4680410800501704 seconds)
2022-03-07 19:00:53 | INFO | fairseq_cli.train | end of epoch 805 (average epoch stats below)
2022-03-07 19:00:53 | INFO | train | epoch 805 | loss 2.446 | nll_loss 0.324 | ppl 1.25 | wps 23946.1 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 39159 | lr 0.000159803 | gnorm 0.368 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 107898
2022-03-07 19:00:53 | INFO | fairseq.trainer | begin training epoch 806
2022-03-07 19:00:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:02:35 | INFO | train_inner | epoch 806:     41 / 49 loss=2.446, nll_loss=0.324, ppl=1.25, wps=24540.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=39200, lr=0.000159719, gnorm=0.366, loss_scale=16, train_wall=225, gb_free=8.8, wall=108000
2022-03-07 19:02:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:02:58 | INFO | valid | epoch 806 | valid on 'valid' subset | loss 13.525 | nll_loss 12.829 | ppl 7278.87 | wps 46568.6 | wpb 510.9 | bsz 1 | num_updates 39208 | best_loss 9.157
2022-03-07 19:02:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 806 @ 39208 updates
2022-03-07 19:02:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:03:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:03:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 806 @ 39208 updates, score 13.525) (writing took 2.311517715919763 seconds)
2022-03-07 19:03:01 | INFO | fairseq_cli.train | end of epoch 806 (average epoch stats below)
2022-03-07 19:03:01 | INFO | train | epoch 806 | loss 2.446 | nll_loss 0.324 | ppl 1.25 | wps 24882.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39208 | lr 0.000159703 | gnorm 0.364 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 108026
2022-03-07 19:03:01 | INFO | fairseq.trainer | begin training epoch 807
2022-03-07 19:03:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:05:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:05:06 | INFO | valid | epoch 807 | valid on 'valid' subset | loss 13.529 | nll_loss 12.842 | ppl 7340.6 | wps 46697.4 | wpb 510.9 | bsz 1 | num_updates 39257 | best_loss 9.157
2022-03-07 19:05:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 807 @ 39257 updates
2022-03-07 19:05:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:05:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:05:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 807 @ 39257 updates, score 13.529) (writing took 2.3014471121132374 seconds)
2022-03-07 19:05:08 | INFO | fairseq_cli.train | end of epoch 807 (average epoch stats below)
2022-03-07 19:05:08 | INFO | train | epoch 807 | loss 2.446 | nll_loss 0.324 | ppl 1.25 | wps 24941 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39257 | lr 0.000159603 | gnorm 0.367 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 108153
2022-03-07 19:05:08 | INFO | fairseq.trainer | begin training epoch 808
2022-03-07 19:05:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:06:55 | INFO | train_inner | epoch 808:     43 / 49 loss=2.445, nll_loss=0.324, ppl=1.25, wps=24951.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39300, lr=0.000159516, gnorm=0.363, loss_scale=32, train_wall=221, gb_free=8.8, wall=108260
2022-03-07 19:07:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:07:13 | INFO | valid | epoch 808 | valid on 'valid' subset | loss 13.621 | nll_loss 12.938 | ppl 7848.23 | wps 46983 | wpb 510.9 | bsz 1 | num_updates 39306 | best_loss 9.157
2022-03-07 19:07:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 808 @ 39306 updates
2022-03-07 19:07:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:07:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:07:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 808 @ 39306 updates, score 13.621) (writing took 2.340636002831161 seconds)
2022-03-07 19:07:16 | INFO | fairseq_cli.train | end of epoch 808 (average epoch stats below)
2022-03-07 19:07:16 | INFO | train | epoch 808 | loss 2.445 | nll_loss 0.324 | ppl 1.25 | wps 24914.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39306 | lr 0.000159504 | gnorm 0.359 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108280
2022-03-07 19:07:16 | INFO | fairseq.trainer | begin training epoch 809
2022-03-07 19:07:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:09:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:09:21 | INFO | valid | epoch 809 | valid on 'valid' subset | loss 13.581 | nll_loss 12.895 | ppl 7616.46 | wps 43442.9 | wpb 510.9 | bsz 1 | num_updates 39355 | best_loss 9.157
2022-03-07 19:09:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 809 @ 39355 updates
2022-03-07 19:09:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:09:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:09:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 809 @ 39355 updates, score 13.581) (writing took 2.3858085121028125 seconds)
2022-03-07 19:09:24 | INFO | fairseq_cli.train | end of epoch 809 (average epoch stats below)
2022-03-07 19:09:24 | INFO | train | epoch 809 | loss 2.445 | nll_loss 0.324 | ppl 1.25 | wps 24833.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39355 | lr 0.000159404 | gnorm 0.363 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108408
2022-03-07 19:09:24 | INFO | fairseq.trainer | begin training epoch 810
2022-03-07 19:09:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:11:15 | INFO | train_inner | epoch 810:     45 / 49 loss=2.445, nll_loss=0.324, ppl=1.25, wps=24916, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=39400, lr=0.000159313, gnorm=0.362, loss_scale=32, train_wall=221, gb_free=8.8, wall=108520
2022-03-07 19:11:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:11:29 | INFO | valid | epoch 810 | valid on 'valid' subset | loss 13.507 | nll_loss 12.81 | ppl 7181.04 | wps 46719.8 | wpb 510.9 | bsz 1 | num_updates 39404 | best_loss 9.157
2022-03-07 19:11:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 810 @ 39404 updates
2022-03-07 19:11:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:11:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:11:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 810 @ 39404 updates, score 13.507) (writing took 2.3405525516718626 seconds)
2022-03-07 19:11:31 | INFO | fairseq_cli.train | end of epoch 810 (average epoch stats below)
2022-03-07 19:11:31 | INFO | train | epoch 810 | loss 2.444 | nll_loss 0.323 | ppl 1.25 | wps 24927.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39404 | lr 0.000159305 | gnorm 0.362 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 108536
2022-03-07 19:11:31 | INFO | fairseq.trainer | begin training epoch 811
2022-03-07 19:11:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:11:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:13:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:13:37 | INFO | valid | epoch 811 | valid on 'valid' subset | loss 13.59 | nll_loss 12.908 | ppl 7684.2 | wps 46829.7 | wpb 510.9 | bsz 1 | num_updates 39452 | best_loss 9.157
2022-03-07 19:13:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 811 @ 39452 updates
2022-03-07 19:13:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:13:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 811 @ 39452 updates, score 13.59) (writing took 2.3243855317123234 seconds)
2022-03-07 19:13:39 | INFO | fairseq_cli.train | end of epoch 811 (average epoch stats below)
2022-03-07 19:13:39 | INFO | train | epoch 811 | loss 2.445 | nll_loss 0.324 | ppl 1.25 | wps 24388.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39452 | lr 0.000159208 | gnorm 0.367 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 108664
2022-03-07 19:13:39 | INFO | fairseq.trainer | begin training epoch 812
2022-03-07 19:13:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:15:38 | INFO | train_inner | epoch 812:     48 / 49 loss=2.445, nll_loss=0.324, ppl=1.25, wps=24706.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=39500, lr=0.000159111, gnorm=0.366, loss_scale=32, train_wall=224, gb_free=8.8, wall=108783
2022-03-07 19:15:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:15:44 | INFO | valid | epoch 812 | valid on 'valid' subset | loss 13.535 | nll_loss 12.85 | ppl 7381.62 | wps 47391.1 | wpb 510.9 | bsz 1 | num_updates 39501 | best_loss 9.157
2022-03-07 19:15:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 812 @ 39501 updates
2022-03-07 19:15:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:15:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:15:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 812 @ 39501 updates, score 13.535) (writing took 2.2417194498702884 seconds)
2022-03-07 19:15:46 | INFO | fairseq_cli.train | end of epoch 812 (average epoch stats below)
2022-03-07 19:15:46 | INFO | train | epoch 812 | loss 2.445 | nll_loss 0.324 | ppl 1.25 | wps 24958.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39501 | lr 0.000159109 | gnorm 0.365 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108791
2022-03-07 19:15:46 | INFO | fairseq.trainer | begin training epoch 813
2022-03-07 19:15:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:17:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:17:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:17:52 | INFO | valid | epoch 813 | valid on 'valid' subset | loss 13.535 | nll_loss 12.838 | ppl 7322.81 | wps 44698.4 | wpb 510.9 | bsz 1 | num_updates 39549 | best_loss 9.157
2022-03-07 19:17:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 813 @ 39549 updates
2022-03-07 19:17:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:17:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:17:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 813 @ 39549 updates, score 13.535) (writing took 2.272400078829378 seconds)
2022-03-07 19:17:54 | INFO | fairseq_cli.train | end of epoch 813 (average epoch stats below)
2022-03-07 19:17:54 | INFO | train | epoch 813 | loss 2.444 | nll_loss 0.324 | ppl 1.25 | wps 24351.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39549 | lr 0.000159013 | gnorm 0.362 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 108919
2022-03-07 19:17:54 | INFO | fairseq.trainer | begin training epoch 814
2022-03-07 19:17:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:19:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:20:00 | INFO | valid | epoch 814 | valid on 'valid' subset | loss 13.493 | nll_loss 12.801 | ppl 7136.88 | wps 46572.3 | wpb 510.9 | bsz 1 | num_updates 39598 | best_loss 9.157
2022-03-07 19:20:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 814 @ 39598 updates
2022-03-07 19:20:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:20:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:20:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 814 @ 39598 updates, score 13.493) (writing took 2.342387367039919 seconds)
2022-03-07 19:20:02 | INFO | fairseq_cli.train | end of epoch 814 (average epoch stats below)
2022-03-07 19:20:02 | INFO | train | epoch 814 | loss 2.444 | nll_loss 0.323 | ppl 1.25 | wps 24818.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39598 | lr 0.000158914 | gnorm 0.36 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 109047
2022-03-07 19:20:02 | INFO | fairseq.trainer | begin training epoch 815
2022-03-07 19:20:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:20:07 | INFO | train_inner | epoch 815:      2 / 49 loss=2.444, nll_loss=0.323, ppl=1.25, wps=23988.7, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=39600, lr=0.00015891, gnorm=0.363, loss_scale=32, train_wall=223, gb_free=8.8, wall=109052
2022-03-07 19:22:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:22:07 | INFO | valid | epoch 815 | valid on 'valid' subset | loss 13.524 | nll_loss 12.829 | ppl 7278.37 | wps 46679.7 | wpb 510.9 | bsz 1 | num_updates 39647 | best_loss 9.157
2022-03-07 19:22:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 815 @ 39647 updates
2022-03-07 19:22:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:22:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:22:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 815 @ 39647 updates, score 13.524) (writing took 2.3140505449846387 seconds)
2022-03-07 19:22:10 | INFO | fairseq_cli.train | end of epoch 815 (average epoch stats below)
2022-03-07 19:22:10 | INFO | train | epoch 815 | loss 2.444 | nll_loss 0.323 | ppl 1.25 | wps 24892 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39647 | lr 0.000158816 | gnorm 0.366 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 109174
2022-03-07 19:22:10 | INFO | fairseq.trainer | begin training epoch 816
2022-03-07 19:22:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:23:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:24:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:24:15 | INFO | valid | epoch 816 | valid on 'valid' subset | loss 13.583 | nll_loss 12.895 | ppl 7619.42 | wps 46944.1 | wpb 510.9 | bsz 1 | num_updates 39695 | best_loss 9.157
2022-03-07 19:24:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 816 @ 39695 updates
2022-03-07 19:24:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:24:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:24:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 816 @ 39695 updates, score 13.583) (writing took 2.2470896071754396 seconds)
2022-03-07 19:24:17 | INFO | fairseq_cli.train | end of epoch 816 (average epoch stats below)
2022-03-07 19:24:17 | INFO | train | epoch 816 | loss 2.444 | nll_loss 0.323 | ppl 1.25 | wps 24389.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39695 | lr 0.00015872 | gnorm 0.367 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 109302
2022-03-07 19:24:17 | INFO | fairseq.trainer | begin training epoch 817
2022-03-07 19:24:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:24:30 | INFO | train_inner | epoch 817:      5 / 49 loss=2.444, nll_loss=0.323, ppl=1.25, wps=24692.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39700, lr=0.00015871, gnorm=0.366, loss_scale=32, train_wall=224, gb_free=8.8, wall=109315
2022-03-07 19:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:26:23 | INFO | valid | epoch 817 | valid on 'valid' subset | loss 13.572 | nll_loss 12.884 | ppl 7557.38 | wps 45260.4 | wpb 510.9 | bsz 1 | num_updates 39744 | best_loss 9.157
2022-03-07 19:26:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 817 @ 39744 updates
2022-03-07 19:26:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:26:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:26:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 817 @ 39744 updates, score 13.572) (writing took 2.3069874169304967 seconds)
2022-03-07 19:26:25 | INFO | fairseq_cli.train | end of epoch 817 (average epoch stats below)
2022-03-07 19:26:25 | INFO | train | epoch 817 | loss 2.444 | nll_loss 0.323 | ppl 1.25 | wps 24898.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39744 | lr 0.000158622 | gnorm 0.36 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109430
2022-03-07 19:26:25 | INFO | fairseq.trainer | begin training epoch 818
2022-03-07 19:26:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:28:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:28:30 | INFO | valid | epoch 818 | valid on 'valid' subset | loss 13.5 | nll_loss 12.806 | ppl 7159.93 | wps 46209.4 | wpb 510.9 | bsz 1 | num_updates 39793 | best_loss 9.157
2022-03-07 19:28:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 818 @ 39793 updates
2022-03-07 19:28:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:28:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:28:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 818 @ 39793 updates, score 13.5) (writing took 2.3614261341281235 seconds)
2022-03-07 19:28:33 | INFO | fairseq_cli.train | end of epoch 818 (average epoch stats below)
2022-03-07 19:28:33 | INFO | train | epoch 818 | loss 2.443 | nll_loss 0.322 | ppl 1.25 | wps 24909.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39793 | lr 0.000158525 | gnorm 0.365 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109557
2022-03-07 19:28:33 | INFO | fairseq.trainer | begin training epoch 819
2022-03-07 19:28:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:28:50 | INFO | train_inner | epoch 819:      7 / 49 loss=2.443, nll_loss=0.322, ppl=1.25, wps=24933.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39800, lr=0.000158511, gnorm=0.362, loss_scale=64, train_wall=221, gb_free=8.8, wall=109575
2022-03-07 19:28:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:30:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:30:38 | INFO | valid | epoch 819 | valid on 'valid' subset | loss 13.518 | nll_loss 12.825 | ppl 7256.3 | wps 46418.6 | wpb 510.9 | bsz 1 | num_updates 39841 | best_loss 9.157
2022-03-07 19:30:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 819 @ 39841 updates
2022-03-07 19:30:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:30:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:30:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 819 @ 39841 updates, score 13.518) (writing took 2.275970604736358 seconds)
2022-03-07 19:30:40 | INFO | fairseq_cli.train | end of epoch 819 (average epoch stats below)
2022-03-07 19:30:40 | INFO | train | epoch 819 | loss 2.443 | nll_loss 0.323 | ppl 1.25 | wps 24379.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39841 | lr 0.000158429 | gnorm 0.364 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 109685
2022-03-07 19:30:40 | INFO | fairseq.trainer | begin training epoch 820
2022-03-07 19:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:32:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:32:45 | INFO | valid | epoch 820 | valid on 'valid' subset | loss 13.605 | nll_loss 12.925 | ppl 7777.86 | wps 47012.6 | wpb 510.9 | bsz 1 | num_updates 39890 | best_loss 9.157
2022-03-07 19:32:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 820 @ 39890 updates
2022-03-07 19:32:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:32:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:32:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 820 @ 39890 updates, score 13.605) (writing took 2.296222848352045 seconds)
2022-03-07 19:32:48 | INFO | fairseq_cli.train | end of epoch 820 (average epoch stats below)
2022-03-07 19:32:48 | INFO | train | epoch 820 | loss 2.444 | nll_loss 0.323 | ppl 1.25 | wps 24951.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39890 | lr 0.000158332 | gnorm 0.361 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109812
2022-03-07 19:32:48 | INFO | fairseq.trainer | begin training epoch 821
2022-03-07 19:32:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:33:13 | INFO | train_inner | epoch 821:     10 / 49 loss=2.443, nll_loss=0.323, ppl=1.25, wps=24709.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39900, lr=0.000158312, gnorm=0.363, loss_scale=32, train_wall=224, gb_free=8.8, wall=109837
2022-03-07 19:34:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:34:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:34:53 | INFO | valid | epoch 821 | valid on 'valid' subset | loss 13.543 | nll_loss 12.853 | ppl 7397.78 | wps 45864.3 | wpb 510.9 | bsz 1 | num_updates 39938 | best_loss 9.157
2022-03-07 19:34:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 821 @ 39938 updates
2022-03-07 19:34:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:34:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 821 @ 39938 updates, score 13.543) (writing took 2.2790926271118224 seconds)
2022-03-07 19:34:55 | INFO | fairseq_cli.train | end of epoch 821 (average epoch stats below)
2022-03-07 19:34:55 | INFO | train | epoch 821 | loss 2.443 | nll_loss 0.322 | ppl 1.25 | wps 24420 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39938 | lr 0.000158237 | gnorm 0.363 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109940
2022-03-07 19:34:55 | INFO | fairseq.trainer | begin training epoch 822
2022-03-07 19:34:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:36:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:37:01 | INFO | valid | epoch 822 | valid on 'valid' subset | loss 13.621 | nll_loss 12.942 | ppl 7868.84 | wps 46757 | wpb 510.9 | bsz 1 | num_updates 39987 | best_loss 9.157
2022-03-07 19:37:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 822 @ 39987 updates
2022-03-07 19:37:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:37:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:37:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 822 @ 39987 updates, score 13.621) (writing took 2.3567865821532905 seconds)
2022-03-07 19:37:03 | INFO | fairseq_cli.train | end of epoch 822 (average epoch stats below)
2022-03-07 19:37:03 | INFO | train | epoch 822 | loss 2.443 | nll_loss 0.322 | ppl 1.25 | wps 24858.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39987 | lr 0.00015814 | gnorm 0.363 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 110068
2022-03-07 19:37:03 | INFO | fairseq.trainer | begin training epoch 823
2022-03-07 19:37:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:37:35 | INFO | train_inner | epoch 823:     13 / 49 loss=2.443, nll_loss=0.322, ppl=1.25, wps=24691.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40000, lr=0.000158114, gnorm=0.362, loss_scale=32, train_wall=224, gb_free=8.8, wall=110100
2022-03-07 19:39:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:39:08 | INFO | valid | epoch 823 | valid on 'valid' subset | loss 13.482 | nll_loss 12.791 | ppl 7085.7 | wps 46614.5 | wpb 510.9 | bsz 1 | num_updates 40036 | best_loss 9.157
2022-03-07 19:39:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 823 @ 40036 updates
2022-03-07 19:39:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:39:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:39:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 823 @ 40036 updates, score 13.482) (writing took 2.3128728438168764 seconds)
2022-03-07 19:39:10 | INFO | fairseq_cli.train | end of epoch 823 (average epoch stats below)
2022-03-07 19:39:10 | INFO | train | epoch 823 | loss 2.443 | nll_loss 0.322 | ppl 1.25 | wps 24924.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40036 | lr 0.000158043 | gnorm 0.364 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 110195
2022-03-07 19:39:10 | INFO | fairseq.trainer | begin training epoch 824
2022-03-07 19:39:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:40:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:41:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:41:16 | INFO | valid | epoch 824 | valid on 'valid' subset | loss 13.449 | nll_loss 12.747 | ppl 6872.85 | wps 46793.1 | wpb 510.9 | bsz 1 | num_updates 40084 | best_loss 9.157
2022-03-07 19:41:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 824 @ 40084 updates
2022-03-07 19:41:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:41:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:41:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 824 @ 40084 updates, score 13.449) (writing took 2.298163398168981 seconds)
2022-03-07 19:41:18 | INFO | fairseq_cli.train | end of epoch 824 (average epoch stats below)
2022-03-07 19:41:18 | INFO | train | epoch 824 | loss 2.442 | nll_loss 0.322 | ppl 1.25 | wps 24413.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40084 | lr 0.000157948 | gnorm 0.366 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 110323
2022-03-07 19:41:18 | INFO | fairseq.trainer | begin training epoch 825
2022-03-07 19:41:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:41:58 | INFO | train_inner | epoch 825:     16 / 49 loss=2.442, nll_loss=0.322, ppl=1.25, wps=24721.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=40100, lr=0.000157917, gnorm=0.366, loss_scale=32, train_wall=224, gb_free=8.8, wall=110362
2022-03-07 19:43:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:43:22 | INFO | valid | epoch 825 | valid on 'valid' subset | loss 13.577 | nll_loss 12.891 | ppl 7596.03 | wps 48186.6 | wpb 510.9 | bsz 1 | num_updates 40133 | best_loss 9.157
2022-03-07 19:43:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 825 @ 40133 updates
2022-03-07 19:43:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:43:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:43:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 825 @ 40133 updates, score 13.577) (writing took 2.278693091124296 seconds)
2022-03-07 19:43:24 | INFO | fairseq_cli.train | end of epoch 825 (average epoch stats below)
2022-03-07 19:43:24 | INFO | train | epoch 825 | loss 2.442 | nll_loss 0.322 | ppl 1.25 | wps 25206 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40133 | lr 0.000157852 | gnorm 0.362 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 110449
2022-03-07 19:43:24 | INFO | fairseq.trainer | begin training epoch 826
2022-03-07 19:43:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:45:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:45:28 | INFO | valid | epoch 826 | valid on 'valid' subset | loss 13.492 | nll_loss 12.798 | ppl 7119.81 | wps 47886.3 | wpb 510.9 | bsz 1 | num_updates 40182 | best_loss 9.157
2022-03-07 19:45:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 826 @ 40182 updates
2022-03-07 19:45:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:45:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:45:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 826 @ 40182 updates, score 13.492) (writing took 2.352415544912219 seconds)
2022-03-07 19:45:30 | INFO | fairseq_cli.train | end of epoch 826 (average epoch stats below)
2022-03-07 19:45:30 | INFO | train | epoch 826 | loss 2.442 | nll_loss 0.322 | ppl 1.25 | wps 25223.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40182 | lr 0.000157755 | gnorm 0.359 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 110575
2022-03-07 19:45:30 | INFO | fairseq.trainer | begin training epoch 827
2022-03-07 19:45:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:45:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:46:17 | INFO | train_inner | epoch 827:     19 / 49 loss=2.442, nll_loss=0.322, ppl=1.25, wps=25061, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=40200, lr=0.00015772, gnorm=0.359, loss_scale=32, train_wall=221, gb_free=8.8, wall=110621
2022-03-07 19:47:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:47:34 | INFO | valid | epoch 827 | valid on 'valid' subset | loss 13.489 | nll_loss 12.793 | ppl 7096.35 | wps 46562.9 | wpb 510.9 | bsz 1 | num_updates 40230 | best_loss 9.157
2022-03-07 19:47:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 827 @ 40230 updates
2022-03-07 19:47:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:47:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:47:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 827 @ 40230 updates, score 13.489) (writing took 2.2724709399044514 seconds)
2022-03-07 19:47:37 | INFO | fairseq_cli.train | end of epoch 827 (average epoch stats below)
2022-03-07 19:47:37 | INFO | train | epoch 827 | loss 2.442 | nll_loss 0.322 | ppl 1.25 | wps 24596.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40230 | lr 0.000157661 | gnorm 0.36 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 110701
2022-03-07 19:47:37 | INFO | fairseq.trainer | begin training epoch 828
2022-03-07 19:47:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:49:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:49:42 | INFO | valid | epoch 828 | valid on 'valid' subset | loss 13.594 | nll_loss 12.91 | ppl 7698.29 | wps 46788.1 | wpb 510.9 | bsz 1 | num_updates 40279 | best_loss 9.157
2022-03-07 19:49:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 828 @ 40279 updates
2022-03-07 19:49:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:49:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:49:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 828 @ 40279 updates, score 13.594) (writing took 2.3123470512218773 seconds)
2022-03-07 19:49:44 | INFO | fairseq_cli.train | end of epoch 828 (average epoch stats below)
2022-03-07 19:49:44 | INFO | train | epoch 828 | loss 2.442 | nll_loss 0.322 | ppl 1.25 | wps 24919.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40279 | lr 0.000157565 | gnorm 0.36 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 110829
2022-03-07 19:49:44 | INFO | fairseq.trainer | begin training epoch 829
2022-03-07 19:49:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:50:36 | INFO | train_inner | epoch 829:     21 / 49 loss=2.442, nll_loss=0.322, ppl=1.25, wps=24961.3, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=40300, lr=0.000157524, gnorm=0.362, loss_scale=32, train_wall=221, gb_free=8.8, wall=110881
2022-03-07 19:51:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:51:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:51:49 | INFO | valid | epoch 829 | valid on 'valid' subset | loss 13.512 | nll_loss 12.819 | ppl 7228.6 | wps 46772.9 | wpb 510.9 | bsz 1 | num_updates 40327 | best_loss 9.157
2022-03-07 19:51:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 829 @ 40327 updates
2022-03-07 19:51:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:51:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:51:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 829 @ 40327 updates, score 13.512) (writing took 2.326411572750658 seconds)
2022-03-07 19:51:52 | INFO | fairseq_cli.train | end of epoch 829 (average epoch stats below)
2022-03-07 19:51:52 | INFO | train | epoch 829 | loss 2.442 | nll_loss 0.321 | ppl 1.25 | wps 24417.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40327 | lr 0.000157472 | gnorm 0.364 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 110956
2022-03-07 19:51:52 | INFO | fairseq.trainer | begin training epoch 830
2022-03-07 19:51:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:53:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:53:57 | INFO | valid | epoch 830 | valid on 'valid' subset | loss 13.636 | nll_loss 12.96 | ppl 7970.1 | wps 46816.5 | wpb 510.9 | bsz 1 | num_updates 40376 | best_loss 9.157
2022-03-07 19:53:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 830 @ 40376 updates
2022-03-07 19:53:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:53:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:53:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 830 @ 40376 updates, score 13.636) (writing took 2.3895470588468015 seconds)
2022-03-07 19:53:59 | INFO | fairseq_cli.train | end of epoch 830 (average epoch stats below)
2022-03-07 19:53:59 | INFO | train | epoch 830 | loss 2.442 | nll_loss 0.322 | ppl 1.25 | wps 24875.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40376 | lr 0.000157376 | gnorm 0.363 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 111084
2022-03-07 19:53:59 | INFO | fairseq.trainer | begin training epoch 831
2022-03-07 19:53:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:54:59 | INFO | train_inner | epoch 831:     24 / 49 loss=2.442, nll_loss=0.322, ppl=1.25, wps=24706.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40400, lr=0.000157329, gnorm=0.362, loss_scale=32, train_wall=224, gb_free=8.8, wall=111144
2022-03-07 19:56:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:56:05 | INFO | valid | epoch 831 | valid on 'valid' subset | loss 13.573 | nll_loss 12.892 | ppl 7602.19 | wps 46706.1 | wpb 510.9 | bsz 1 | num_updates 40425 | best_loss 9.157
2022-03-07 19:56:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 831 @ 40425 updates
2022-03-07 19:56:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:56:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:56:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 831 @ 40425 updates, score 13.573) (writing took 2.3064030441455543 seconds)
2022-03-07 19:56:07 | INFO | fairseq_cli.train | end of epoch 831 (average epoch stats below)
2022-03-07 19:56:07 | INFO | train | epoch 831 | loss 2.442 | nll_loss 0.321 | ppl 1.25 | wps 24913.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40425 | lr 0.000157281 | gnorm 0.362 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 111212
2022-03-07 19:56:07 | INFO | fairseq.trainer | begin training epoch 832
2022-03-07 19:56:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:57:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:58:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:58:12 | INFO | valid | epoch 832 | valid on 'valid' subset | loss 13.54 | nll_loss 12.854 | ppl 7403.57 | wps 47073.5 | wpb 510.9 | bsz 1 | num_updates 40473 | best_loss 9.157
2022-03-07 19:58:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 832 @ 40473 updates
2022-03-07 19:58:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:58:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:58:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 832 @ 40473 updates, score 13.54) (writing took 2.2551325052045286 seconds)
2022-03-07 19:58:14 | INFO | fairseq_cli.train | end of epoch 832 (average epoch stats below)
2022-03-07 19:58:14 | INFO | train | epoch 832 | loss 2.442 | nll_loss 0.322 | ppl 1.25 | wps 24406.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40473 | lr 0.000157187 | gnorm 0.364 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 111339
2022-03-07 19:58:14 | INFO | fairseq.trainer | begin training epoch 833
2022-03-07 19:58:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:59:22 | INFO | train_inner | epoch 833:     27 / 49 loss=2.441, nll_loss=0.321, ppl=1.25, wps=24700.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40500, lr=0.000157135, gnorm=0.361, loss_scale=32, train_wall=224, gb_free=8.8, wall=111406
2022-03-07 20:00:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:00:19 | INFO | valid | epoch 833 | valid on 'valid' subset | loss 13.629 | nll_loss 12.951 | ppl 7916.42 | wps 46824 | wpb 510.9 | bsz 1 | num_updates 40522 | best_loss 9.157
2022-03-07 20:00:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 833 @ 40522 updates
2022-03-07 20:00:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:00:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:00:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 833 @ 40522 updates, score 13.629) (writing took 2.32563313934952 seconds)
2022-03-07 20:00:22 | INFO | fairseq_cli.train | end of epoch 833 (average epoch stats below)
2022-03-07 20:00:22 | INFO | train | epoch 833 | loss 2.442 | nll_loss 0.322 | ppl 1.25 | wps 24943.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40522 | lr 0.000157092 | gnorm 0.361 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 111467
2022-03-07 20:00:22 | INFO | fairseq.trainer | begin training epoch 834
2022-03-07 20:00:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:02:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:02:27 | INFO | valid | epoch 834 | valid on 'valid' subset | loss 13.569 | nll_loss 12.881 | ppl 7542.39 | wps 46367.6 | wpb 510.9 | bsz 1 | num_updates 40571 | best_loss 9.157
2022-03-07 20:02:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 834 @ 40571 updates
2022-03-07 20:02:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:02:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:02:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 834 @ 40571 updates, score 13.569) (writing took 2.35589069314301 seconds)
2022-03-07 20:02:30 | INFO | fairseq_cli.train | end of epoch 834 (average epoch stats below)
2022-03-07 20:02:30 | INFO | train | epoch 834 | loss 2.441 | nll_loss 0.322 | ppl 1.25 | wps 24850.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40571 | lr 0.000156997 | gnorm 0.362 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 111594
2022-03-07 20:02:30 | INFO | fairseq.trainer | begin training epoch 835
2022-03-07 20:02:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:03:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:03:44 | INFO | train_inner | epoch 835:     30 / 49 loss=2.441, nll_loss=0.322, ppl=1.25, wps=24704.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=40600, lr=0.000156941, gnorm=0.362, loss_scale=32, train_wall=224, gb_free=8.8, wall=111669
2022-03-07 20:04:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:04:35 | INFO | valid | epoch 835 | valid on 'valid' subset | loss 13.588 | nll_loss 12.903 | ppl 7658.36 | wps 46250 | wpb 510.9 | bsz 1 | num_updates 40619 | best_loss 9.157
2022-03-07 20:04:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 835 @ 40619 updates
2022-03-07 20:04:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:04:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:04:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 835 @ 40619 updates, score 13.588) (writing took 2.2813508710823953 seconds)
2022-03-07 20:04:37 | INFO | fairseq_cli.train | end of epoch 835 (average epoch stats below)
2022-03-07 20:04:37 | INFO | train | epoch 835 | loss 2.441 | nll_loss 0.321 | ppl 1.25 | wps 24386.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40619 | lr 0.000156904 | gnorm 0.36 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 111722
2022-03-07 20:04:37 | INFO | fairseq.trainer | begin training epoch 836
2022-03-07 20:04:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:06:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:06:42 | INFO | valid | epoch 836 | valid on 'valid' subset | loss 13.566 | nll_loss 12.879 | ppl 7532.27 | wps 47019 | wpb 510.9 | bsz 1 | num_updates 40668 | best_loss 9.157
2022-03-07 20:06:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 836 @ 40668 updates
2022-03-07 20:06:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:06:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:06:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 836 @ 40668 updates, score 13.566) (writing took 2.2579945726320148 seconds)
2022-03-07 20:06:45 | INFO | fairseq_cli.train | end of epoch 836 (average epoch stats below)
2022-03-07 20:06:45 | INFO | train | epoch 836 | loss 2.441 | nll_loss 0.321 | ppl 1.25 | wps 24936.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40668 | lr 0.00015681 | gnorm 0.362 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 111849
2022-03-07 20:06:45 | INFO | fairseq.trainer | begin training epoch 837
2022-03-07 20:06:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:08:04 | INFO | train_inner | epoch 837:     32 / 49 loss=2.441, nll_loss=0.321, ppl=1.25, wps=24935.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=40700, lr=0.000156748, gnorm=0.36, loss_scale=32, train_wall=222, gb_free=8.8, wall=111929
2022-03-07 20:08:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:08:50 | INFO | valid | epoch 837 | valid on 'valid' subset | loss 13.528 | nll_loss 12.834 | ppl 7303.23 | wps 46535.4 | wpb 510.9 | bsz 1 | num_updates 40717 | best_loss 9.157
2022-03-07 20:08:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 837 @ 40717 updates
2022-03-07 20:08:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:08:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:08:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 837 @ 40717 updates, score 13.528) (writing took 2.2878110338933766 seconds)
2022-03-07 20:08:52 | INFO | fairseq_cli.train | end of epoch 837 (average epoch stats below)
2022-03-07 20:08:52 | INFO | train | epoch 837 | loss 2.441 | nll_loss 0.321 | ppl 1.25 | wps 24933 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40717 | lr 0.000156716 | gnorm 0.36 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 111977
2022-03-07 20:08:52 | INFO | fairseq.trainer | begin training epoch 838
2022-03-07 20:08:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:08:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:10:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:10:58 | INFO | valid | epoch 838 | valid on 'valid' subset | loss 13.632 | nll_loss 12.952 | ppl 7923.22 | wps 46494.4 | wpb 510.9 | bsz 1 | num_updates 40765 | best_loss 9.157
2022-03-07 20:10:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 838 @ 40765 updates
2022-03-07 20:10:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:11:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:11:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 838 @ 40765 updates, score 13.632) (writing took 2.364713930990547 seconds)
2022-03-07 20:11:00 | INFO | fairseq_cli.train | end of epoch 838 (average epoch stats below)
2022-03-07 20:11:00 | INFO | train | epoch 838 | loss 2.44 | nll_loss 0.321 | ppl 1.25 | wps 24320.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40765 | lr 0.000156623 | gnorm 0.36 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 112105
2022-03-07 20:11:00 | INFO | fairseq.trainer | begin training epoch 839
2022-03-07 20:11:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:12:27 | INFO | train_inner | epoch 839:     35 / 49 loss=2.44, nll_loss=0.321, ppl=1.25, wps=24687.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40800, lr=0.000156556, gnorm=0.361, loss_scale=32, train_wall=224, gb_free=8.8, wall=112192
2022-03-07 20:13:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:13:05 | INFO | valid | epoch 839 | valid on 'valid' subset | loss 13.567 | nll_loss 12.88 | ppl 7536.45 | wps 46189 | wpb 510.9 | bsz 1 | num_updates 40814 | best_loss 9.157
2022-03-07 20:13:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 839 @ 40814 updates
2022-03-07 20:13:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:13:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:13:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 839 @ 40814 updates, score 13.567) (writing took 2.2591510489583015 seconds)
2022-03-07 20:13:08 | INFO | fairseq_cli.train | end of epoch 839 (average epoch stats below)
2022-03-07 20:13:08 | INFO | train | epoch 839 | loss 2.44 | nll_loss 0.321 | ppl 1.25 | wps 24928.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40814 | lr 0.000156529 | gnorm 0.36 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 112232
2022-03-07 20:13:08 | INFO | fairseq.trainer | begin training epoch 840
2022-03-07 20:13:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:14:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:15:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:15:13 | INFO | valid | epoch 840 | valid on 'valid' subset | loss 13.598 | nll_loss 12.919 | ppl 7742.21 | wps 47071.8 | wpb 510.9 | bsz 1 | num_updates 40862 | best_loss 9.157
2022-03-07 20:15:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 840 @ 40862 updates
2022-03-07 20:15:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:15:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:15:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 840 @ 40862 updates, score 13.598) (writing took 2.2931784549728036 seconds)
2022-03-07 20:15:15 | INFO | fairseq_cli.train | end of epoch 840 (average epoch stats below)
2022-03-07 20:15:15 | INFO | train | epoch 840 | loss 2.44 | nll_loss 0.321 | ppl 1.25 | wps 24374.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40862 | lr 0.000156437 | gnorm 0.361 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 112360
2022-03-07 20:15:15 | INFO | fairseq.trainer | begin training epoch 841
2022-03-07 20:15:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:16:50 | INFO | train_inner | epoch 841:     38 / 49 loss=2.44, nll_loss=0.321, ppl=1.25, wps=24689, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40900, lr=0.000156365, gnorm=0.36, loss_scale=32, train_wall=224, gb_free=8.8, wall=112455
2022-03-07 20:17:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:17:21 | INFO | valid | epoch 841 | valid on 'valid' subset | loss 13.646 | nll_loss 12.965 | ppl 7997.38 | wps 46883 | wpb 510.9 | bsz 1 | num_updates 40911 | best_loss 9.157
2022-03-07 20:17:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 841 @ 40911 updates
2022-03-07 20:17:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:17:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:17:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 841 @ 40911 updates, score 13.646) (writing took 2.2342437990009785 seconds)
2022-03-07 20:17:23 | INFO | fairseq_cli.train | end of epoch 841 (average epoch stats below)
2022-03-07 20:17:23 | INFO | train | epoch 841 | loss 2.44 | nll_loss 0.321 | ppl 1.25 | wps 24945.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40911 | lr 0.000156344 | gnorm 0.36 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 112488
2022-03-07 20:17:23 | INFO | fairseq.trainer | begin training epoch 842
2022-03-07 20:17:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:19:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:19:28 | INFO | valid | epoch 842 | valid on 'valid' subset | loss 13.555 | nll_loss 12.867 | ppl 7470.65 | wps 46465.4 | wpb 510.9 | bsz 1 | num_updates 40960 | best_loss 9.157
2022-03-07 20:19:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 842 @ 40960 updates
2022-03-07 20:19:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:19:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:19:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 842 @ 40960 updates, score 13.555) (writing took 2.3727370142005384 seconds)
2022-03-07 20:19:30 | INFO | fairseq_cli.train | end of epoch 842 (average epoch stats below)
2022-03-07 20:19:30 | INFO | train | epoch 842 | loss 2.44 | nll_loss 0.32 | ppl 1.25 | wps 24890.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40960 | lr 0.00015625 | gnorm 0.363 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 112615
2022-03-07 20:19:30 | INFO | fairseq.trainer | begin training epoch 843
2022-03-07 20:19:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:20:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:21:12 | INFO | train_inner | epoch 843:     41 / 49 loss=2.44, nll_loss=0.32, ppl=1.25, wps=24717.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41000, lr=0.000156174, gnorm=0.363, loss_scale=32, train_wall=224, gb_free=8.8, wall=112717
2022-03-07 20:21:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:21:36 | INFO | valid | epoch 843 | valid on 'valid' subset | loss 13.483 | nll_loss 12.788 | ppl 7071.08 | wps 46846.7 | wpb 510.9 | bsz 1 | num_updates 41008 | best_loss 9.157
2022-03-07 20:21:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 843 @ 41008 updates
2022-03-07 20:21:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:21:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:21:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 843 @ 41008 updates, score 13.483) (writing took 2.3396331649273634 seconds)
2022-03-07 20:21:38 | INFO | fairseq_cli.train | end of epoch 843 (average epoch stats below)
2022-03-07 20:21:38 | INFO | train | epoch 843 | loss 2.44 | nll_loss 0.32 | ppl 1.25 | wps 24388 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41008 | lr 0.000156159 | gnorm 0.364 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 112743
2022-03-07 20:21:38 | INFO | fairseq.trainer | begin training epoch 844
2022-03-07 20:21:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:23:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:23:42 | INFO | valid | epoch 844 | valid on 'valid' subset | loss 13.518 | nll_loss 12.83 | ppl 7280.23 | wps 48325.4 | wpb 510.9 | bsz 1 | num_updates 41057 | best_loss 9.157
2022-03-07 20:23:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 844 @ 41057 updates
2022-03-07 20:23:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:23:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:23:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 844 @ 41057 updates, score 13.518) (writing took 4.412443985231221 seconds)
2022-03-07 20:23:47 | INFO | fairseq_cli.train | end of epoch 844 (average epoch stats below)
2022-03-07 20:23:47 | INFO | train | epoch 844 | loss 2.44 | nll_loss 0.32 | ppl 1.25 | wps 24701.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41057 | lr 0.000156065 | gnorm 0.362 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 112871
2022-03-07 20:23:47 | INFO | fairseq.trainer | begin training epoch 845
2022-03-07 20:23:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:25:32 | INFO | train_inner | epoch 845:     43 / 49 loss=2.44, nll_loss=0.32, ppl=1.25, wps=24949.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41100, lr=0.000155984, gnorm=0.36, loss_scale=32, train_wall=220, gb_free=8.8, wall=112977
2022-03-07 20:25:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:25:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:25:50 | INFO | valid | epoch 845 | valid on 'valid' subset | loss 13.627 | nll_loss 12.951 | ppl 7918.88 | wps 48260.9 | wpb 510.9 | bsz 1 | num_updates 41105 | best_loss 9.157
2022-03-07 20:25:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 845 @ 41105 updates
2022-03-07 20:25:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:25:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:25:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 845 @ 41105 updates, score 13.627) (writing took 2.2597581250593066 seconds)
2022-03-07 20:25:53 | INFO | fairseq_cli.train | end of epoch 845 (average epoch stats below)
2022-03-07 20:25:53 | INFO | train | epoch 845 | loss 2.44 | nll_loss 0.32 | ppl 1.25 | wps 24733.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41105 | lr 0.000155974 | gnorm 0.358 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 112997
2022-03-07 20:25:53 | INFO | fairseq.trainer | begin training epoch 846
2022-03-07 20:25:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:27:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:27:56 | INFO | valid | epoch 846 | valid on 'valid' subset | loss 13.616 | nll_loss 12.939 | ppl 7851.41 | wps 47884.6 | wpb 510.9 | bsz 1 | num_updates 41154 | best_loss 9.157
2022-03-07 20:27:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 846 @ 41154 updates
2022-03-07 20:27:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:27:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:27:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 846 @ 41154 updates, score 13.616) (writing took 2.3540000948123634 seconds)
2022-03-07 20:27:59 | INFO | fairseq_cli.train | end of epoch 846 (average epoch stats below)
2022-03-07 20:27:59 | INFO | train | epoch 846 | loss 2.439 | nll_loss 0.32 | ppl 1.25 | wps 25227.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41154 | lr 0.000155881 | gnorm 0.36 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 113123
2022-03-07 20:27:59 | INFO | fairseq.trainer | begin training epoch 847
2022-03-07 20:27:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:29:51 | INFO | train_inner | epoch 847:     46 / 49 loss=2.439, nll_loss=0.32, ppl=1.25, wps=25048.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41200, lr=0.000155794, gnorm=0.36, loss_scale=32, train_wall=221, gb_free=8.8, wall=113236
2022-03-07 20:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:30:02 | INFO | valid | epoch 847 | valid on 'valid' subset | loss 13.519 | nll_loss 12.827 | ppl 7264.86 | wps 48178 | wpb 510.9 | bsz 1 | num_updates 41203 | best_loss 9.157
2022-03-07 20:30:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 847 @ 41203 updates
2022-03-07 20:30:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:30:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:30:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 847 @ 41203 updates, score 13.519) (writing took 2.2599263340234756 seconds)
2022-03-07 20:30:04 | INFO | fairseq_cli.train | end of epoch 847 (average epoch stats below)
2022-03-07 20:30:04 | INFO | train | epoch 847 | loss 2.439 | nll_loss 0.32 | ppl 1.25 | wps 25280.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41203 | lr 0.000155789 | gnorm 0.36 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 113249
2022-03-07 20:30:04 | INFO | fairseq.trainer | begin training epoch 848
2022-03-07 20:30:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:31:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:32:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:32:09 | INFO | valid | epoch 848 | valid on 'valid' subset | loss 13.519 | nll_loss 12.828 | ppl 7271.35 | wps 45129.7 | wpb 510.9 | bsz 1 | num_updates 41251 | best_loss 9.157
2022-03-07 20:32:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 848 @ 41251 updates
2022-03-07 20:32:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:32:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:32:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 848 @ 41251 updates, score 13.519) (writing took 2.2454911628738046 seconds)
2022-03-07 20:32:11 | INFO | fairseq_cli.train | end of epoch 848 (average epoch stats below)
2022-03-07 20:32:11 | INFO | train | epoch 848 | loss 2.439 | nll_loss 0.32 | ppl 1.25 | wps 24598 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41251 | lr 0.000155698 | gnorm 0.361 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 113376
2022-03-07 20:32:11 | INFO | fairseq.trainer | begin training epoch 849
2022-03-07 20:32:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:34:11 | INFO | train_inner | epoch 849:     49 / 49 loss=2.439, nll_loss=0.32, ppl=1.25, wps=24818, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=41300, lr=0.000155606, gnorm=0.363, loss_scale=32, train_wall=222, gb_free=8.8, wall=113496
2022-03-07 20:34:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:34:16 | INFO | valid | epoch 849 | valid on 'valid' subset | loss 13.504 | nll_loss 12.811 | ppl 7185.54 | wps 46919.6 | wpb 510.9 | bsz 1 | num_updates 41300 | best_loss 9.157
2022-03-07 20:34:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 849 @ 41300 updates
2022-03-07 20:34:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:34:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:34:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 849 @ 41300 updates, score 13.504) (writing took 2.2752510020509362 seconds)
2022-03-07 20:34:18 | INFO | fairseq_cli.train | end of epoch 849 (average epoch stats below)
2022-03-07 20:34:18 | INFO | train | epoch 849 | loss 2.439 | nll_loss 0.32 | ppl 1.25 | wps 24911.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41300 | lr 0.000155606 | gnorm 0.362 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 113503
2022-03-07 20:34:18 | INFO | fairseq.trainer | begin training epoch 850
2022-03-07 20:34:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:36:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:36:24 | INFO | valid | epoch 850 | valid on 'valid' subset | loss 13.661 | nll_loss 12.986 | ppl 8111.09 | wps 47822.4 | wpb 510.9 | bsz 1 | num_updates 41349 | best_loss 9.157
2022-03-07 20:36:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 850 @ 41349 updates
2022-03-07 20:36:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:36:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:36:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 850 @ 41349 updates, score 13.661) (writing took 2.346748686861247 seconds)
2022-03-07 20:36:26 | INFO | fairseq_cli.train | end of epoch 850 (average epoch stats below)
2022-03-07 20:36:26 | INFO | train | epoch 850 | loss 2.439 | nll_loss 0.319 | ppl 1.25 | wps 24909.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41349 | lr 0.000155513 | gnorm 0.359 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 113631
2022-03-07 20:36:26 | INFO | fairseq.trainer | begin training epoch 851
2022-03-07 20:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:37:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:38:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:38:29 | INFO | valid | epoch 851 | valid on 'valid' subset | loss 13.579 | nll_loss 12.897 | ppl 7625.32 | wps 47862.8 | wpb 510.9 | bsz 1 | num_updates 41397 | best_loss 9.157
2022-03-07 20:38:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 851 @ 41397 updates
2022-03-07 20:38:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:38:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:38:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 851 @ 41397 updates, score 13.579) (writing took 2.3170140911825 seconds)
2022-03-07 20:38:32 | INFO | fairseq_cli.train | end of epoch 851 (average epoch stats below)
2022-03-07 20:38:32 | INFO | train | epoch 851 | loss 2.439 | nll_loss 0.319 | ppl 1.25 | wps 24733.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41397 | lr 0.000155423 | gnorm 0.359 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 113757
2022-03-07 20:38:32 | INFO | fairseq.trainer | begin training epoch 852
2022-03-07 20:38:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:38:39 | INFO | train_inner | epoch 852:      3 / 49 loss=2.439, nll_loss=0.319, ppl=1.25, wps=24219.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=41400, lr=0.000155417, gnorm=0.359, loss_scale=32, train_wall=222, gb_free=8.8, wall=113764
2022-03-07 20:40:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:40:35 | INFO | valid | epoch 852 | valid on 'valid' subset | loss 13.578 | nll_loss 12.895 | ppl 7616.29 | wps 48101.4 | wpb 510.9 | bsz 1 | num_updates 41446 | best_loss 9.157
2022-03-07 20:40:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 852 @ 41446 updates
2022-03-07 20:40:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:40:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:40:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 852 @ 41446 updates, score 13.578) (writing took 2.2470410177484155 seconds)
2022-03-07 20:40:38 | INFO | fairseq_cli.train | end of epoch 852 (average epoch stats below)
2022-03-07 20:40:38 | INFO | train | epoch 852 | loss 2.438 | nll_loss 0.319 | ppl 1.25 | wps 25267.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41446 | lr 0.000155331 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 113882
2022-03-07 20:40:38 | INFO | fairseq.trainer | begin training epoch 853
2022-03-07 20:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:42:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:42:41 | INFO | valid | epoch 853 | valid on 'valid' subset | loss 13.574 | nll_loss 12.885 | ppl 7564.71 | wps 48245.1 | wpb 510.9 | bsz 1 | num_updates 41495 | best_loss 9.157
2022-03-07 20:42:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 853 @ 41495 updates
2022-03-07 20:42:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:42:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:42:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 853 @ 41495 updates, score 13.574) (writing took 2.3189204279333353 seconds)
2022-03-07 20:42:44 | INFO | fairseq_cli.train | end of epoch 853 (average epoch stats below)
2022-03-07 20:42:44 | INFO | train | epoch 853 | loss 2.439 | nll_loss 0.32 | ppl 1.25 | wps 25215.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41495 | lr 0.000155239 | gnorm 0.361 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 114008
2022-03-07 20:42:44 | INFO | fairseq.trainer | begin training epoch 854
2022-03-07 20:42:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:42:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:42:59 | INFO | train_inner | epoch 854:      6 / 49 loss=2.438, nll_loss=0.319, ppl=1.25, wps=25010.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41500, lr=0.00015523, gnorm=0.359, loss_scale=32, train_wall=221, gb_free=8.8, wall=114023
2022-03-07 20:44:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:44:48 | INFO | valid | epoch 854 | valid on 'valid' subset | loss 13.554 | nll_loss 12.869 | ppl 7479.22 | wps 47868.1 | wpb 510.9 | bsz 1 | num_updates 41543 | best_loss 9.157
2022-03-07 20:44:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 854 @ 41543 updates
2022-03-07 20:44:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:44:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:44:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 854 @ 41543 updates, score 13.554) (writing took 2.3555089537985623 seconds)
2022-03-07 20:44:50 | INFO | fairseq_cli.train | end of epoch 854 (average epoch stats below)
2022-03-07 20:44:50 | INFO | train | epoch 854 | loss 2.438 | nll_loss 0.319 | ppl 1.25 | wps 24604.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41543 | lr 0.00015515 | gnorm 0.361 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 114135
2022-03-07 20:44:50 | INFO | fairseq.trainer | begin training epoch 855
2022-03-07 20:44:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:46:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:46:54 | INFO | valid | epoch 855 | valid on 'valid' subset | loss 13.563 | nll_loss 12.873 | ppl 7504.04 | wps 48198 | wpb 510.9 | bsz 1 | num_updates 41592 | best_loss 9.157
2022-03-07 20:46:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 855 @ 41592 updates
2022-03-07 20:46:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:46:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:46:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 855 @ 41592 updates, score 13.563) (writing took 2.255861250218004 seconds)
2022-03-07 20:46:56 | INFO | fairseq_cli.train | end of epoch 855 (average epoch stats below)
2022-03-07 20:46:56 | INFO | train | epoch 855 | loss 2.438 | nll_loss 0.319 | ppl 1.25 | wps 25293.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41592 | lr 0.000155058 | gnorm 0.355 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 114261
2022-03-07 20:46:56 | INFO | fairseq.trainer | begin training epoch 856
2022-03-07 20:46:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:47:15 | INFO | train_inner | epoch 856:      8 / 49 loss=2.438, nll_loss=0.319, ppl=1.25, wps=25258.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41600, lr=0.000155043, gnorm=0.358, loss_scale=32, train_wall=219, gb_free=8.8, wall=114280
2022-03-07 20:48:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:48:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:48:59 | INFO | valid | epoch 856 | valid on 'valid' subset | loss 13.51 | nll_loss 12.819 | ppl 7226.41 | wps 48359 | wpb 510.9 | bsz 1 | num_updates 41640 | best_loss 9.157
2022-03-07 20:48:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 856 @ 41640 updates
2022-03-07 20:48:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:49:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:49:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 856 @ 41640 updates, score 13.51) (writing took 2.271598809864372 seconds)
2022-03-07 20:49:02 | INFO | fairseq_cli.train | end of epoch 856 (average epoch stats below)
2022-03-07 20:49:02 | INFO | train | epoch 856 | loss 2.437 | nll_loss 0.318 | ppl 1.25 | wps 24741.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41640 | lr 0.000154969 | gnorm 0.361 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 114386
2022-03-07 20:49:02 | INFO | fairseq.trainer | begin training epoch 857
2022-03-07 20:49:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:51:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:51:07 | INFO | valid | epoch 857 | valid on 'valid' subset | loss 13.546 | nll_loss 12.859 | ppl 7428.21 | wps 46722.4 | wpb 510.9 | bsz 1 | num_updates 41689 | best_loss 9.157
2022-03-07 20:51:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 857 @ 41689 updates
2022-03-07 20:51:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:51:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:51:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 857 @ 41689 updates, score 13.546) (writing took 2.280354415997863 seconds)
2022-03-07 20:51:09 | INFO | fairseq_cli.train | end of epoch 857 (average epoch stats below)
2022-03-07 20:51:09 | INFO | train | epoch 857 | loss 2.437 | nll_loss 0.319 | ppl 1.25 | wps 24935.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41689 | lr 0.000154878 | gnorm 0.36 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 114514
2022-03-07 20:51:09 | INFO | fairseq.trainer | begin training epoch 858
2022-03-07 20:51:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:51:37 | INFO | train_inner | epoch 858:     11 / 49 loss=2.437, nll_loss=0.318, ppl=1.25, wps=24832.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41700, lr=0.000154857, gnorm=0.361, loss_scale=32, train_wall=223, gb_free=8.8, wall=114541
2022-03-07 20:53:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:53:14 | INFO | valid | epoch 858 | valid on 'valid' subset | loss 13.604 | nll_loss 12.919 | ppl 7742.51 | wps 46343.3 | wpb 510.9 | bsz 1 | num_updates 41738 | best_loss 9.157
2022-03-07 20:53:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 858 @ 41738 updates
2022-03-07 20:53:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:53:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 858 @ 41738 updates, score 13.604) (writing took 2.404311804100871 seconds)
2022-03-07 20:53:17 | INFO | fairseq_cli.train | end of epoch 858 (average epoch stats below)
2022-03-07 20:53:17 | INFO | train | epoch 858 | loss 2.438 | nll_loss 0.319 | ppl 1.25 | wps 24874.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41738 | lr 0.000154787 | gnorm 0.368 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 114642
2022-03-07 20:53:17 | INFO | fairseq.trainer | begin training epoch 859
2022-03-07 20:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:54:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:55:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:55:22 | INFO | valid | epoch 859 | valid on 'valid' subset | loss 13.565 | nll_loss 12.883 | ppl 7552.6 | wps 46634 | wpb 510.9 | bsz 1 | num_updates 41786 | best_loss 9.157
2022-03-07 20:55:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 859 @ 41786 updates
2022-03-07 20:55:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:55:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:55:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 859 @ 41786 updates, score 13.565) (writing took 2.3184005971997976 seconds)
2022-03-07 20:55:24 | INFO | fairseq_cli.train | end of epoch 859 (average epoch stats below)
2022-03-07 20:55:24 | INFO | train | epoch 859 | loss 2.437 | nll_loss 0.318 | ppl 1.25 | wps 24431.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41786 | lr 0.000154698 | gnorm 0.359 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 114769
2022-03-07 20:55:24 | INFO | fairseq.trainer | begin training epoch 860
2022-03-07 20:55:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:55:59 | INFO | train_inner | epoch 860:     14 / 49 loss=2.437, nll_loss=0.318, ppl=1.25, wps=24727.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41800, lr=0.000154672, gnorm=0.362, loss_scale=32, train_wall=223, gb_free=8.8, wall=114804
2022-03-07 20:57:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:57:30 | INFO | valid | epoch 860 | valid on 'valid' subset | loss 13.542 | nll_loss 12.854 | ppl 7401.91 | wps 46802.6 | wpb 510.9 | bsz 1 | num_updates 41835 | best_loss 9.157
2022-03-07 20:57:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 860 @ 41835 updates
2022-03-07 20:57:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:57:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:57:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 860 @ 41835 updates, score 13.542) (writing took 2.280776767991483 seconds)
2022-03-07 20:57:32 | INFO | fairseq_cli.train | end of epoch 860 (average epoch stats below)
2022-03-07 20:57:32 | INFO | train | epoch 860 | loss 2.437 | nll_loss 0.319 | ppl 1.25 | wps 24890.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41835 | lr 0.000154607 | gnorm 0.361 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 114897
2022-03-07 20:57:32 | INFO | fairseq.trainer | begin training epoch 861
2022-03-07 20:57:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:59:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:59:37 | INFO | valid | epoch 861 | valid on 'valid' subset | loss 13.555 | nll_loss 12.867 | ppl 7470.19 | wps 46769.3 | wpb 510.9 | bsz 1 | num_updates 41884 | best_loss 9.157
2022-03-07 20:59:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 861 @ 41884 updates
2022-03-07 20:59:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:59:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:59:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 861 @ 41884 updates, score 13.555) (writing took 2.2741414830088615 seconds)
2022-03-07 20:59:39 | INFO | fairseq_cli.train | end of epoch 861 (average epoch stats below)
2022-03-07 20:59:39 | INFO | train | epoch 861 | loss 2.437 | nll_loss 0.319 | ppl 1.25 | wps 24937.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41884 | lr 0.000154517 | gnorm 0.359 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 115024
2022-03-07 20:59:39 | INFO | fairseq.trainer | begin training epoch 862
2022-03-07 20:59:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:59:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:00:22 | INFO | train_inner | epoch 862:     17 / 49 loss=2.437, nll_loss=0.319, ppl=1.25, wps=24693, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41900, lr=0.000154487, gnorm=0.359, loss_scale=32, train_wall=224, gb_free=8.8, wall=115066
2022-03-07 21:01:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:01:45 | INFO | valid | epoch 862 | valid on 'valid' subset | loss 13.555 | nll_loss 12.87 | ppl 7486.4 | wps 46292.4 | wpb 510.9 | bsz 1 | num_updates 41932 | best_loss 9.157
2022-03-07 21:01:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 862 @ 41932 updates
2022-03-07 21:01:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:01:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:01:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 862 @ 41932 updates, score 13.555) (writing took 2.4445674321614206 seconds)
2022-03-07 21:01:47 | INFO | fairseq_cli.train | end of epoch 862 (average epoch stats below)
2022-03-07 21:01:47 | INFO | train | epoch 862 | loss 2.437 | nll_loss 0.318 | ppl 1.25 | wps 24352 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41932 | lr 0.000154428 | gnorm 0.354 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 115152
2022-03-07 21:01:47 | INFO | fairseq.trainer | begin training epoch 863
2022-03-07 21:01:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:03:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:03:52 | INFO | valid | epoch 863 | valid on 'valid' subset | loss 13.587 | nll_loss 12.901 | ppl 7649.38 | wps 46364.5 | wpb 510.9 | bsz 1 | num_updates 41981 | best_loss 9.157
2022-03-07 21:03:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 863 @ 41981 updates
2022-03-07 21:03:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:03:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:03:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 863 @ 41981 updates, score 13.587) (writing took 2.3432582141831517 seconds)
2022-03-07 21:03:55 | INFO | fairseq_cli.train | end of epoch 863 (average epoch stats below)
2022-03-07 21:03:55 | INFO | train | epoch 863 | loss 2.437 | nll_loss 0.319 | ppl 1.25 | wps 24908.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41981 | lr 0.000154338 | gnorm 0.366 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 115279
2022-03-07 21:03:55 | INFO | fairseq.trainer | begin training epoch 864
2022-03-07 21:03:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:04:42 | INFO | train_inner | epoch 864:     19 / 49 loss=2.437, nll_loss=0.318, ppl=1.25, wps=24936.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42000, lr=0.000154303, gnorm=0.36, loss_scale=32, train_wall=221, gb_free=8.8, wall=115327
2022-03-07 21:05:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:05:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:06:00 | INFO | valid | epoch 864 | valid on 'valid' subset | loss 13.619 | nll_loss 12.941 | ppl 7862.57 | wps 46570.9 | wpb 510.9 | bsz 1 | num_updates 42029 | best_loss 9.157
2022-03-07 21:06:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 864 @ 42029 updates
2022-03-07 21:06:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:06:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:06:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 864 @ 42029 updates, score 13.619) (writing took 2.2395863560959697 seconds)
2022-03-07 21:06:02 | INFO | fairseq_cli.train | end of epoch 864 (average epoch stats below)
2022-03-07 21:06:02 | INFO | train | epoch 864 | loss 2.437 | nll_loss 0.318 | ppl 1.25 | wps 24434.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42029 | lr 0.00015425 | gnorm 0.359 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 115407
2022-03-07 21:06:02 | INFO | fairseq.trainer | begin training epoch 865
2022-03-07 21:06:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:08:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:08:07 | INFO | valid | epoch 865 | valid on 'valid' subset | loss 13.593 | nll_loss 12.915 | ppl 7721.13 | wps 46926.8 | wpb 510.9 | bsz 1 | num_updates 42078 | best_loss 9.157
2022-03-07 21:08:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 865 @ 42078 updates
2022-03-07 21:08:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:08:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:08:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 865 @ 42078 updates, score 13.593) (writing took 2.3265501959249377 seconds)
2022-03-07 21:08:09 | INFO | fairseq_cli.train | end of epoch 865 (average epoch stats below)
2022-03-07 21:08:09 | INFO | train | epoch 865 | loss 2.437 | nll_loss 0.318 | ppl 1.25 | wps 24954.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42078 | lr 0.00015416 | gnorm 0.357 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 115534
2022-03-07 21:08:09 | INFO | fairseq.trainer | begin training epoch 866
2022-03-07 21:08:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:09:04 | INFO | train_inner | epoch 866:     22 / 49 loss=2.437, nll_loss=0.319, ppl=1.25, wps=24723.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42100, lr=0.00015412, gnorm=0.361, loss_scale=32, train_wall=224, gb_free=8.8, wall=115589
2022-03-07 21:10:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:10:15 | INFO | valid | epoch 866 | valid on 'valid' subset | loss 13.558 | nll_loss 12.875 | ppl 7511.5 | wps 47513.4 | wpb 510.9 | bsz 1 | num_updates 42127 | best_loss 9.157
2022-03-07 21:10:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 866 @ 42127 updates
2022-03-07 21:10:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:10:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:10:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 866 @ 42127 updates, score 13.558) (writing took 2.4063057149760425 seconds)
2022-03-07 21:10:17 | INFO | fairseq_cli.train | end of epoch 866 (average epoch stats below)
2022-03-07 21:10:17 | INFO | train | epoch 866 | loss 2.437 | nll_loss 0.319 | ppl 1.25 | wps 24932.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42127 | lr 0.000154071 | gnorm 0.367 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 115662
2022-03-07 21:10:17 | INFO | fairseq.trainer | begin training epoch 867
2022-03-07 21:10:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:11:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:12:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:12:22 | INFO | valid | epoch 867 | valid on 'valid' subset | loss 13.504 | nll_loss 12.808 | ppl 7169.81 | wps 46550.7 | wpb 510.9 | bsz 1 | num_updates 42175 | best_loss 9.157
2022-03-07 21:12:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 867 @ 42175 updates
2022-03-07 21:12:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:12:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:12:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 867 @ 42175 updates, score 13.504) (writing took 2.317747472319752 seconds)
2022-03-07 21:12:24 | INFO | fairseq_cli.train | end of epoch 867 (average epoch stats below)
2022-03-07 21:12:24 | INFO | train | epoch 867 | loss 2.436 | nll_loss 0.318 | ppl 1.25 | wps 24451.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42175 | lr 0.000153983 | gnorm 0.361 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 115789
2022-03-07 21:12:24 | INFO | fairseq.trainer | begin training epoch 868
2022-03-07 21:12:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:13:26 | INFO | train_inner | epoch 868:     25 / 49 loss=2.436, nll_loss=0.318, ppl=1.25, wps=24762.3, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=42200, lr=0.000153937, gnorm=0.362, loss_scale=32, train_wall=223, gb_free=8.8, wall=115851
2022-03-07 21:14:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:14:29 | INFO | valid | epoch 868 | valid on 'valid' subset | loss 13.613 | nll_loss 12.933 | ppl 7821.1 | wps 46469.6 | wpb 510.9 | bsz 1 | num_updates 42224 | best_loss 9.157
2022-03-07 21:14:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 868 @ 42224 updates
2022-03-07 21:14:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:14:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:14:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 868 @ 42224 updates, score 13.613) (writing took 2.29010755289346 seconds)
2022-03-07 21:14:32 | INFO | fairseq_cli.train | end of epoch 868 (average epoch stats below)
2022-03-07 21:14:32 | INFO | train | epoch 868 | loss 2.437 | nll_loss 0.318 | ppl 1.25 | wps 24931.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42224 | lr 0.000153894 | gnorm 0.361 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 115916
2022-03-07 21:14:32 | INFO | fairseq.trainer | begin training epoch 869
2022-03-07 21:14:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:16:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:16:37 | INFO | valid | epoch 869 | valid on 'valid' subset | loss 13.562 | nll_loss 12.881 | ppl 7543.72 | wps 47817.5 | wpb 510.9 | bsz 1 | num_updates 42273 | best_loss 9.157
2022-03-07 21:16:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 869 @ 42273 updates
2022-03-07 21:16:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:16:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:16:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 869 @ 42273 updates, score 13.562) (writing took 2.3332695099525154 seconds)
2022-03-07 21:16:39 | INFO | fairseq_cli.train | end of epoch 869 (average epoch stats below)
2022-03-07 21:16:39 | INFO | train | epoch 869 | loss 2.436 | nll_loss 0.317 | ppl 1.25 | wps 24869.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42273 | lr 0.000153804 | gnorm 0.361 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 116044
2022-03-07 21:16:39 | INFO | fairseq.trainer | begin training epoch 870
2022-03-07 21:16:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:17:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:17:49 | INFO | train_inner | epoch 870:     28 / 49 loss=2.436, nll_loss=0.317, ppl=1.25, wps=24673.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=42300, lr=0.000153755, gnorm=0.36, loss_scale=32, train_wall=224, gb_free=8.8, wall=116114
2022-03-07 21:18:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:18:45 | INFO | valid | epoch 870 | valid on 'valid' subset | loss 13.576 | nll_loss 12.89 | ppl 7591.3 | wps 46263.4 | wpb 510.9 | bsz 1 | num_updates 42321 | best_loss 9.157
2022-03-07 21:18:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 870 @ 42321 updates
2022-03-07 21:18:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:18:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:18:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 870 @ 42321 updates, score 13.576) (writing took 2.373233078047633 seconds)
2022-03-07 21:18:47 | INFO | fairseq_cli.train | end of epoch 870 (average epoch stats below)
2022-03-07 21:18:47 | INFO | train | epoch 870 | loss 2.436 | nll_loss 0.317 | ppl 1.25 | wps 24365.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42321 | lr 0.000153717 | gnorm 0.36 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 116172
2022-03-07 21:18:47 | INFO | fairseq.trainer | begin training epoch 871
2022-03-07 21:18:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:20:52 | INFO | valid | epoch 871 | valid on 'valid' subset | loss 13.583 | nll_loss 12.901 | ppl 7651.32 | wps 46486.5 | wpb 510.9 | bsz 1 | num_updates 42370 | best_loss 9.157
2022-03-07 21:20:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 871 @ 42370 updates
2022-03-07 21:20:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:20:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:20:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 871 @ 42370 updates, score 13.583) (writing took 2.3209189558401704 seconds)
2022-03-07 21:20:55 | INFO | fairseq_cli.train | end of epoch 871 (average epoch stats below)
2022-03-07 21:20:55 | INFO | train | epoch 871 | loss 2.436 | nll_loss 0.317 | ppl 1.25 | wps 24960.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42370 | lr 0.000153628 | gnorm 0.357 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 116299
2022-03-07 21:20:55 | INFO | fairseq.trainer | begin training epoch 872
2022-03-07 21:20:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:22:09 | INFO | train_inner | epoch 872:     30 / 49 loss=2.436, nll_loss=0.317, ppl=1.25, wps=24958.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=42400, lr=0.000153574, gnorm=0.361, loss_scale=32, train_wall=221, gb_free=8.8, wall=116374
2022-03-07 21:22:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:23:00 | INFO | valid | epoch 872 | valid on 'valid' subset | loss 13.575 | nll_loss 12.889 | ppl 7586.55 | wps 46670.1 | wpb 510.9 | bsz 1 | num_updates 42419 | best_loss 9.157
2022-03-07 21:23:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 872 @ 42419 updates
2022-03-07 21:23:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:23:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:23:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 872 @ 42419 updates, score 13.575) (writing took 2.282083918340504 seconds)
2022-03-07 21:23:02 | INFO | fairseq_cli.train | end of epoch 872 (average epoch stats below)
2022-03-07 21:23:02 | INFO | train | epoch 872 | loss 2.436 | nll_loss 0.317 | ppl 1.25 | wps 24948.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42419 | lr 0.000153539 | gnorm 0.361 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 116427
2022-03-07 21:23:02 | INFO | fairseq.trainer | begin training epoch 873
2022-03-07 21:23:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:23:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:25:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:25:06 | INFO | valid | epoch 873 | valid on 'valid' subset | loss 13.623 | nll_loss 12.939 | ppl 7855.08 | wps 48382.4 | wpb 510.9 | bsz 1 | num_updates 42467 | best_loss 9.157
2022-03-07 21:25:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 873 @ 42467 updates
2022-03-07 21:25:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:25:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:25:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 873 @ 42467 updates, score 13.623) (writing took 2.2446993589401245 seconds)
2022-03-07 21:25:08 | INFO | fairseq_cli.train | end of epoch 873 (average epoch stats below)
2022-03-07 21:25:08 | INFO | train | epoch 873 | loss 2.435 | nll_loss 0.317 | ppl 1.25 | wps 24618.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42467 | lr 0.000153453 | gnorm 0.353 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 116553
2022-03-07 21:25:08 | INFO | fairseq.trainer | begin training epoch 874
2022-03-07 21:25:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:26:30 | INFO | train_inner | epoch 874:     33 / 49 loss=2.435, nll_loss=0.317, ppl=1.25, wps=24869.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42500, lr=0.000153393, gnorm=0.354, loss_scale=32, train_wall=222, gb_free=8.8, wall=116635
2022-03-07 21:27:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:27:13 | INFO | valid | epoch 874 | valid on 'valid' subset | loss 13.644 | nll_loss 12.964 | ppl 7988.94 | wps 47257 | wpb 510.9 | bsz 1 | num_updates 42516 | best_loss 9.157
2022-03-07 21:27:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 874 @ 42516 updates
2022-03-07 21:27:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:27:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:27:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 874 @ 42516 updates, score 13.644) (writing took 2.4113375316374004 seconds)
2022-03-07 21:27:15 | INFO | fairseq_cli.train | end of epoch 874 (average epoch stats below)
2022-03-07 21:27:15 | INFO | train | epoch 874 | loss 2.435 | nll_loss 0.317 | ppl 1.25 | wps 25011.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42516 | lr 0.000153364 | gnorm 0.355 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 116680
2022-03-07 21:27:15 | INFO | fairseq.trainer | begin training epoch 875
2022-03-07 21:27:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:29:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:29:20 | INFO | valid | epoch 875 | valid on 'valid' subset | loss 13.583 | nll_loss 12.897 | ppl 7628.83 | wps 47109.6 | wpb 510.9 | bsz 1 | num_updates 42565 | best_loss 9.157
2022-03-07 21:29:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 875 @ 42565 updates
2022-03-07 21:29:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:29:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:29:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 875 @ 42565 updates, score 13.583) (writing took 2.2483997740782797 seconds)
2022-03-07 21:29:22 | INFO | fairseq_cli.train | end of epoch 875 (average epoch stats below)
2022-03-07 21:29:22 | INFO | train | epoch 875 | loss 2.435 | nll_loss 0.316 | ppl 1.25 | wps 25054.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42565 | lr 0.000153276 | gnorm 0.358 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 116807
2022-03-07 21:29:22 | INFO | fairseq.trainer | begin training epoch 876
2022-03-07 21:29:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:29:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:30:51 | INFO | train_inner | epoch 876:     36 / 49 loss=2.435, nll_loss=0.317, ppl=1.25, wps=24810.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=42600, lr=0.000153213, gnorm=0.358, loss_scale=32, train_wall=223, gb_free=8.8, wall=116896
2022-03-07 21:31:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:31:27 | INFO | valid | epoch 876 | valid on 'valid' subset | loss 13.585 | nll_loss 12.899 | ppl 7637.65 | wps 47598.5 | wpb 510.9 | bsz 1 | num_updates 42613 | best_loss 9.157
2022-03-07 21:31:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 876 @ 42613 updates
2022-03-07 21:31:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:31:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:31:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 876 @ 42613 updates, score 13.585) (writing took 2.2649516072124243 seconds)
2022-03-07 21:31:29 | INFO | fairseq_cli.train | end of epoch 876 (average epoch stats below)
2022-03-07 21:31:29 | INFO | train | epoch 876 | loss 2.435 | nll_loss 0.317 | ppl 1.25 | wps 24519.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42613 | lr 0.000153189 | gnorm 0.359 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 116934
2022-03-07 21:31:29 | INFO | fairseq.trainer | begin training epoch 877
2022-03-07 21:31:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:33:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:33:34 | INFO | valid | epoch 877 | valid on 'valid' subset | loss 13.55 | nll_loss 12.863 | ppl 7452.4 | wps 47241.4 | wpb 510.9 | bsz 1 | num_updates 42662 | best_loss 9.157
2022-03-07 21:33:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 877 @ 42662 updates
2022-03-07 21:33:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:33:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:33:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 877 @ 42662 updates, score 13.55) (writing took 2.279499089345336 seconds)
2022-03-07 21:33:36 | INFO | fairseq_cli.train | end of epoch 877 (average epoch stats below)
2022-03-07 21:33:36 | INFO | train | epoch 877 | loss 2.435 | nll_loss 0.317 | ppl 1.25 | wps 25046 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42662 | lr 0.000153101 | gnorm 0.357 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 117061
2022-03-07 21:33:36 | INFO | fairseq.trainer | begin training epoch 878
2022-03-07 21:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:35:10 | INFO | train_inner | epoch 878:     38 / 49 loss=2.435, nll_loss=0.317, ppl=1.25, wps=25066, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=42700, lr=0.000153033, gnorm=0.361, loss_scale=64, train_wall=221, gb_free=8.8, wall=117155
2022-03-07 21:35:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:35:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:35:41 | INFO | valid | epoch 878 | valid on 'valid' subset | loss 13.656 | nll_loss 12.973 | ppl 8038.14 | wps 47077.7 | wpb 510.9 | bsz 1 | num_updates 42710 | best_loss 9.157
2022-03-07 21:35:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 878 @ 42710 updates
2022-03-07 21:35:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:35:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:35:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 878 @ 42710 updates, score 13.656) (writing took 2.4531611637212336 seconds)
2022-03-07 21:35:43 | INFO | fairseq_cli.train | end of epoch 878 (average epoch stats below)
2022-03-07 21:35:43 | INFO | train | epoch 878 | loss 2.435 | nll_loss 0.317 | ppl 1.25 | wps 24440.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42710 | lr 0.000153015 | gnorm 0.365 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 117188
2022-03-07 21:35:43 | INFO | fairseq.trainer | begin training epoch 879
2022-03-07 21:35:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:37:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:37:49 | INFO | valid | epoch 879 | valid on 'valid' subset | loss 13.736 | nll_loss 13.066 | ppl 8572.58 | wps 46530.2 | wpb 510.9 | bsz 1 | num_updates 42759 | best_loss 9.157
2022-03-07 21:37:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 879 @ 42759 updates
2022-03-07 21:37:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:37:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:37:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 879 @ 42759 updates, score 13.736) (writing took 2.286037715151906 seconds)
2022-03-07 21:37:51 | INFO | fairseq_cli.train | end of epoch 879 (average epoch stats below)
2022-03-07 21:37:51 | INFO | train | epoch 879 | loss 2.435 | nll_loss 0.317 | ppl 1.25 | wps 24927.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42759 | lr 0.000152928 | gnorm 0.357 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 117316
2022-03-07 21:37:51 | INFO | fairseq.trainer | begin training epoch 880
2022-03-07 21:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:39:32 | INFO | train_inner | epoch 880:     41 / 49 loss=2.435, nll_loss=0.317, ppl=1.25, wps=24820.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42800, lr=0.000152854, gnorm=0.36, loss_scale=32, train_wall=223, gb_free=8.8, wall=117416
2022-03-07 21:39:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:39:54 | INFO | valid | epoch 880 | valid on 'valid' subset | loss 13.593 | nll_loss 12.912 | ppl 7707.07 | wps 48319.6 | wpb 510.9 | bsz 1 | num_updates 42808 | best_loss 9.157
2022-03-07 21:39:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 880 @ 42808 updates
2022-03-07 21:39:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:39:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:39:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 880 @ 42808 updates, score 13.593) (writing took 2.305301807820797 seconds)
2022-03-07 21:39:57 | INFO | fairseq_cli.train | end of epoch 880 (average epoch stats below)
2022-03-07 21:39:57 | INFO | train | epoch 880 | loss 2.434 | nll_loss 0.316 | ppl 1.25 | wps 25249.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42808 | lr 0.00015284 | gnorm 0.359 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 117442
2022-03-07 21:39:57 | INFO | fairseq.trainer | begin training epoch 881
2022-03-07 21:39:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:41:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:41:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:42:00 | INFO | valid | epoch 881 | valid on 'valid' subset | loss 13.525 | nll_loss 12.837 | ppl 7315.5 | wps 48076.6 | wpb 510.9 | bsz 1 | num_updates 42856 | best_loss 9.157
2022-03-07 21:42:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 881 @ 42856 updates
2022-03-07 21:42:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:42:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:42:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 881 @ 42856 updates, score 13.525) (writing took 2.2986779240891337 seconds)
2022-03-07 21:42:02 | INFO | fairseq_cli.train | end of epoch 881 (average epoch stats below)
2022-03-07 21:42:02 | INFO | train | epoch 881 | loss 2.434 | nll_loss 0.316 | ppl 1.25 | wps 24766.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42856 | lr 0.000152755 | gnorm 0.355 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 117567
2022-03-07 21:42:02 | INFO | fairseq.trainer | begin training epoch 882
2022-03-07 21:42:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:43:51 | INFO | train_inner | epoch 882:     44 / 49 loss=2.434, nll_loss=0.316, ppl=1.25, wps=25048.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=42900, lr=0.000152676, gnorm=0.354, loss_scale=32, train_wall=221, gb_free=8.8, wall=117675
2022-03-07 21:44:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:44:06 | INFO | valid | epoch 882 | valid on 'valid' subset | loss 13.65 | nll_loss 12.973 | ppl 8040.77 | wps 47450.9 | wpb 510.9 | bsz 1 | num_updates 42905 | best_loss 9.157
2022-03-07 21:44:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 882 @ 42905 updates
2022-03-07 21:44:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:44:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:44:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 882 @ 42905 updates, score 13.65) (writing took 2.3809980279766023 seconds)
2022-03-07 21:44:09 | INFO | fairseq_cli.train | end of epoch 882 (average epoch stats below)
2022-03-07 21:44:09 | INFO | train | epoch 882 | loss 2.434 | nll_loss 0.316 | ppl 1.24 | wps 25181.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42905 | lr 0.000152667 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 117693
2022-03-07 21:44:09 | INFO | fairseq.trainer | begin training epoch 883
2022-03-07 21:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:46:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:46:12 | INFO | valid | epoch 883 | valid on 'valid' subset | loss 13.612 | nll_loss 12.93 | ppl 7804.28 | wps 47548.9 | wpb 510.9 | bsz 1 | num_updates 42954 | best_loss 9.157
2022-03-07 21:46:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 883 @ 42954 updates
2022-03-07 21:46:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:46:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:46:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 883 @ 42954 updates, score 13.612) (writing took 2.264927907846868 seconds)
2022-03-07 21:46:14 | INFO | fairseq_cli.train | end of epoch 883 (average epoch stats below)
2022-03-07 21:46:14 | INFO | train | epoch 883 | loss 2.434 | nll_loss 0.316 | ppl 1.25 | wps 25285.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42954 | lr 0.00015258 | gnorm 0.352 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 117819
2022-03-07 21:46:14 | INFO | fairseq.trainer | begin training epoch 884
2022-03-07 21:46:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:47:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:48:09 | INFO | train_inner | epoch 884:     47 / 49 loss=2.434, nll_loss=0.317, ppl=1.25, wps=25069.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43000, lr=0.000152499, gnorm=0.354, loss_scale=32, train_wall=221, gb_free=8.8, wall=117934
2022-03-07 21:48:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:48:18 | INFO | valid | epoch 884 | valid on 'valid' subset | loss 13.532 | nll_loss 12.843 | ppl 7349.06 | wps 47430 | wpb 510.9 | bsz 1 | num_updates 43002 | best_loss 9.157
2022-03-07 21:48:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 884 @ 43002 updates
2022-03-07 21:48:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:48:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:48:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 884 @ 43002 updates, score 13.532) (writing took 2.289322779979557 seconds)
2022-03-07 21:48:20 | INFO | fairseq_cli.train | end of epoch 884 (average epoch stats below)
2022-03-07 21:48:20 | INFO | train | epoch 884 | loss 2.434 | nll_loss 0.317 | ppl 1.25 | wps 24783.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43002 | lr 0.000152495 | gnorm 0.357 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 117945
2022-03-07 21:48:20 | INFO | fairseq.trainer | begin training epoch 885
2022-03-07 21:48:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:50:24 | INFO | valid | epoch 885 | valid on 'valid' subset | loss 13.632 | nll_loss 12.96 | ppl 7969.67 | wps 47343.8 | wpb 510.9 | bsz 1 | num_updates 43051 | best_loss 9.157
2022-03-07 21:50:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 885 @ 43051 updates
2022-03-07 21:50:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:50:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:50:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 885 @ 43051 updates, score 13.632) (writing took 2.273843549657613 seconds)
2022-03-07 21:50:26 | INFO | fairseq_cli.train | end of epoch 885 (average epoch stats below)
2022-03-07 21:50:26 | INFO | train | epoch 885 | loss 2.434 | nll_loss 0.317 | ppl 1.25 | wps 25242.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43051 | lr 0.000152408 | gnorm 0.357 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 118071
2022-03-07 21:50:26 | INFO | fairseq.trainer | begin training epoch 886
2022-03-07 21:50:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:52:25 | INFO | train_inner | epoch 886:     49 / 49 loss=2.434, nll_loss=0.316, ppl=1.25, wps=25261.2, ups=0.39, wpb=64544.1, bsz=126.1, num_updates=43100, lr=0.000152322, gnorm=0.357, loss_scale=64, train_wall=218, gb_free=8.8, wall=118190
2022-03-07 21:52:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:52:30 | INFO | valid | epoch 886 | valid on 'valid' subset | loss 13.631 | nll_loss 12.95 | ppl 7913.2 | wps 46928.1 | wpb 510.9 | bsz 1 | num_updates 43100 | best_loss 9.157
2022-03-07 21:52:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 886 @ 43100 updates
2022-03-07 21:52:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:52:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:52:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 886 @ 43100 updates, score 13.631) (writing took 2.360838009044528 seconds)
2022-03-07 21:52:32 | INFO | fairseq_cli.train | end of epoch 886 (average epoch stats below)
2022-03-07 21:52:32 | INFO | train | epoch 886 | loss 2.433 | nll_loss 0.316 | ppl 1.24 | wps 25210.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43100 | lr 0.000152322 | gnorm 0.354 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 118197
2022-03-07 21:52:32 | INFO | fairseq.trainer | begin training epoch 887
2022-03-07 21:52:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:52:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:54:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:54:37 | INFO | valid | epoch 887 | valid on 'valid' subset | loss 13.527 | nll_loss 12.841 | ppl 7338.66 | wps 45685.5 | wpb 510.9 | bsz 1 | num_updates 43148 | best_loss 9.157
2022-03-07 21:54:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 887 @ 43148 updates
2022-03-07 21:54:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:54:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:54:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 887 @ 43148 updates, score 13.527) (writing took 2.3470613644458354 seconds)
2022-03-07 21:54:40 | INFO | fairseq_cli.train | end of epoch 887 (average epoch stats below)
2022-03-07 21:54:40 | INFO | train | epoch 887 | loss 2.433 | nll_loss 0.315 | ppl 1.24 | wps 24384.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43148 | lr 0.000152237 | gnorm 0.355 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 118324
2022-03-07 21:54:40 | INFO | fairseq.trainer | begin training epoch 888
2022-03-07 21:54:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:56:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:56:45 | INFO | valid | epoch 888 | valid on 'valid' subset | loss 13.585 | nll_loss 12.902 | ppl 7652.37 | wps 46076 | wpb 510.9 | bsz 1 | num_updates 43197 | best_loss 9.157
2022-03-07 21:56:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 888 @ 43197 updates
2022-03-07 21:56:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:56:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:56:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 888 @ 43197 updates, score 13.585) (writing took 2.3202243531122804 seconds)
2022-03-07 21:56:47 | INFO | fairseq_cli.train | end of epoch 888 (average epoch stats below)
2022-03-07 21:56:47 | INFO | train | epoch 888 | loss 2.434 | nll_loss 0.316 | ppl 1.24 | wps 24886 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43197 | lr 0.00015215 | gnorm 0.357 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 118452
2022-03-07 21:56:47 | INFO | fairseq.trainer | begin training epoch 889
2022-03-07 21:56:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:56:55 | INFO | train_inner | epoch 889:      3 / 49 loss=2.433, nll_loss=0.316, ppl=1.24, wps=24030.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=43200, lr=0.000152145, gnorm=0.356, loss_scale=32, train_wall=224, gb_free=8.8, wall=118460
2022-03-07 21:58:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:58:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:58:51 | INFO | valid | epoch 889 | valid on 'valid' subset | loss 13.667 | nll_loss 12.995 | ppl 8164.14 | wps 48011.5 | wpb 510.9 | bsz 1 | num_updates 43245 | best_loss 9.157
2022-03-07 21:58:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 889 @ 43245 updates
2022-03-07 21:58:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:58:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:58:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 889 @ 43245 updates, score 13.667) (writing took 2.305455878842622 seconds)
2022-03-07 21:58:54 | INFO | fairseq_cli.train | end of epoch 889 (average epoch stats below)
2022-03-07 21:58:54 | INFO | train | epoch 889 | loss 2.433 | nll_loss 0.315 | ppl 1.24 | wps 24639.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43245 | lr 0.000152066 | gnorm 0.358 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 118578
2022-03-07 21:58:54 | INFO | fairseq.trainer | begin training epoch 890
2022-03-07 21:58:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:00:58 | INFO | valid | epoch 890 | valid on 'valid' subset | loss 13.587 | nll_loss 12.899 | ppl 7639.72 | wps 47792.2 | wpb 510.9 | bsz 1 | num_updates 43294 | best_loss 9.157
2022-03-07 22:00:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 890 @ 43294 updates
2022-03-07 22:00:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:01:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:01:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 890 @ 43294 updates, score 13.587) (writing took 2.346072170883417 seconds)
2022-03-07 22:01:00 | INFO | fairseq_cli.train | end of epoch 890 (average epoch stats below)
2022-03-07 22:01:00 | INFO | train | epoch 890 | loss 2.434 | nll_loss 0.316 | ppl 1.25 | wps 25167 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43294 | lr 0.00015198 | gnorm 0.358 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 118705
2022-03-07 22:01:00 | INFO | fairseq.trainer | begin training epoch 891
2022-03-07 22:01:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:01:15 | INFO | train_inner | epoch 891:      6 / 49 loss=2.433, nll_loss=0.315, ppl=1.24, wps=24967.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=43300, lr=0.000151969, gnorm=0.358, loss_scale=32, train_wall=221, gb_free=8.8, wall=118719
2022-03-07 22:02:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:03:03 | INFO | valid | epoch 891 | valid on 'valid' subset | loss 13.623 | nll_loss 12.943 | ppl 7875.24 | wps 48161.4 | wpb 510.9 | bsz 1 | num_updates 43343 | best_loss 9.157
2022-03-07 22:03:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 891 @ 43343 updates
2022-03-07 22:03:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:03:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:03:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 891 @ 43343 updates, score 13.623) (writing took 2.2774116420187056 seconds)
2022-03-07 22:03:06 | INFO | fairseq_cli.train | end of epoch 891 (average epoch stats below)
2022-03-07 22:03:06 | INFO | train | epoch 891 | loss 2.433 | nll_loss 0.316 | ppl 1.24 | wps 25242 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43343 | lr 0.000151894 | gnorm 0.359 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 118831
2022-03-07 22:03:06 | INFO | fairseq.trainer | begin training epoch 892
2022-03-07 22:03:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:04:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:05:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:05:10 | INFO | valid | epoch 892 | valid on 'valid' subset | loss 13.57 | nll_loss 12.883 | ppl 7553.28 | wps 48274.9 | wpb 510.9 | bsz 1 | num_updates 43391 | best_loss 9.157
2022-03-07 22:05:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 892 @ 43391 updates
2022-03-07 22:05:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:05:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:05:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 892 @ 43391 updates, score 13.57) (writing took 2.2691826410591602 seconds)
2022-03-07 22:05:12 | INFO | fairseq_cli.train | end of epoch 892 (average epoch stats below)
2022-03-07 22:05:12 | INFO | train | epoch 892 | loss 2.433 | nll_loss 0.316 | ppl 1.24 | wps 24678.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43391 | lr 0.00015181 | gnorm 0.358 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 118957
2022-03-07 22:05:12 | INFO | fairseq.trainer | begin training epoch 893
2022-03-07 22:05:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:05:34 | INFO | train_inner | epoch 893:      9 / 49 loss=2.433, nll_loss=0.316, ppl=1.24, wps=25001.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43400, lr=0.000151794, gnorm=0.358, loss_scale=32, train_wall=221, gb_free=8.8, wall=118979
2022-03-07 22:07:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:07:16 | INFO | valid | epoch 893 | valid on 'valid' subset | loss 13.613 | nll_loss 12.935 | ppl 7830.5 | wps 48164.4 | wpb 510.9 | bsz 1 | num_updates 43440 | best_loss 9.157
2022-03-07 22:07:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 893 @ 43440 updates
2022-03-07 22:07:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:07:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:07:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 893 @ 43440 updates, score 13.613) (writing took 2.3141939393244684 seconds)
2022-03-07 22:07:18 | INFO | fairseq_cli.train | end of epoch 893 (average epoch stats below)
2022-03-07 22:07:18 | INFO | train | epoch 893 | loss 2.433 | nll_loss 0.315 | ppl 1.24 | wps 25194.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43440 | lr 0.000151724 | gnorm 0.36 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 119083
2022-03-07 22:07:18 | INFO | fairseq.trainer | begin training epoch 894
2022-03-07 22:07:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:09:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:09:23 | INFO | valid | epoch 894 | valid on 'valid' subset | loss 13.675 | nll_loss 13.008 | ppl 8236.61 | wps 46305.3 | wpb 510.9 | bsz 1 | num_updates 43489 | best_loss 9.157
2022-03-07 22:09:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 894 @ 43489 updates
2022-03-07 22:09:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:09:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:09:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 894 @ 43489 updates, score 13.675) (writing took 2.4000998251140118 seconds)
2022-03-07 22:09:25 | INFO | fairseq_cli.train | end of epoch 894 (average epoch stats below)
2022-03-07 22:09:25 | INFO | train | epoch 894 | loss 2.433 | nll_loss 0.315 | ppl 1.24 | wps 24954.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43489 | lr 0.000151639 | gnorm 0.355 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 119210
2022-03-07 22:09:25 | INFO | fairseq.trainer | begin training epoch 895
2022-03-07 22:09:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:09:53 | INFO | train_inner | epoch 895:     11 / 49 loss=2.432, nll_loss=0.315, ppl=1.24, wps=25075.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43500, lr=0.00015162, gnorm=0.356, loss_scale=32, train_wall=220, gb_free=8.8, wall=119238
2022-03-07 22:11:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:11:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:11:31 | INFO | valid | epoch 895 | valid on 'valid' subset | loss 13.599 | nll_loss 12.92 | ppl 7748.26 | wps 46564.5 | wpb 510.9 | bsz 1 | num_updates 43537 | best_loss 9.157
2022-03-07 22:11:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 895 @ 43537 updates
2022-03-07 22:11:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:11:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:11:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 895 @ 43537 updates, score 13.599) (writing took 2.327265866100788 seconds)
2022-03-07 22:11:33 | INFO | fairseq_cli.train | end of epoch 895 (average epoch stats below)
2022-03-07 22:11:33 | INFO | train | epoch 895 | loss 2.432 | nll_loss 0.315 | ppl 1.24 | wps 24359.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43537 | lr 0.000151555 | gnorm 0.353 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 119338
2022-03-07 22:11:33 | INFO | fairseq.trainer | begin training epoch 896
2022-03-07 22:11:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:13:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:13:38 | INFO | valid | epoch 896 | valid on 'valid' subset | loss 13.587 | nll_loss 12.906 | ppl 7677.58 | wps 48227.7 | wpb 510.9 | bsz 1 | num_updates 43586 | best_loss 9.157
2022-03-07 22:13:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 896 @ 43586 updates
2022-03-07 22:13:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:13:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:13:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 896 @ 43586 updates, score 13.587) (writing took 2.2382788276299834 seconds)
2022-03-07 22:13:40 | INFO | fairseq_cli.train | end of epoch 896 (average epoch stats below)
2022-03-07 22:13:40 | INFO | train | epoch 896 | loss 2.433 | nll_loss 0.316 | ppl 1.24 | wps 25083.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43586 | lr 0.00015147 | gnorm 0.359 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 119465
2022-03-07 22:13:40 | INFO | fairseq.trainer | begin training epoch 897
2022-03-07 22:13:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:14:14 | INFO | train_inner | epoch 897:     14 / 49 loss=2.432, nll_loss=0.315, ppl=1.24, wps=24806, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=43600, lr=0.000151446, gnorm=0.357, loss_scale=32, train_wall=223, gb_free=8.8, wall=119499
2022-03-07 22:15:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:15:43 | INFO | valid | epoch 897 | valid on 'valid' subset | loss 13.7 | nll_loss 13.03 | ppl 8363.02 | wps 48212.3 | wpb 510.9 | bsz 1 | num_updates 43635 | best_loss 9.157
2022-03-07 22:15:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 897 @ 43635 updates
2022-03-07 22:15:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:15:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:15:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 897 @ 43635 updates, score 13.7) (writing took 2.2804989088326693 seconds)
2022-03-07 22:15:46 | INFO | fairseq_cli.train | end of epoch 897 (average epoch stats below)
2022-03-07 22:15:46 | INFO | train | epoch 897 | loss 2.431 | nll_loss 0.314 | ppl 1.24 | wps 25267.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43635 | lr 0.000151385 | gnorm 0.353 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 119590
2022-03-07 22:15:46 | INFO | fairseq.trainer | begin training epoch 898
2022-03-07 22:15:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:16:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:17:49 | INFO | valid | epoch 898 | valid on 'valid' subset | loss 13.579 | nll_loss 12.898 | ppl 7633.79 | wps 48522.4 | wpb 510.9 | bsz 1 | num_updates 43683 | best_loss 9.157
2022-03-07 22:17:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 898 @ 43683 updates
2022-03-07 22:17:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:17:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:17:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 898 @ 43683 updates, score 13.579) (writing took 2.3368310891091824 seconds)
2022-03-07 22:17:52 | INFO | fairseq_cli.train | end of epoch 898 (average epoch stats below)
2022-03-07 22:17:52 | INFO | train | epoch 898 | loss 2.432 | nll_loss 0.315 | ppl 1.24 | wps 24695.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43683 | lr 0.000151302 | gnorm 0.355 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 119716
2022-03-07 22:17:52 | INFO | fairseq.trainer | begin training epoch 899
2022-03-07 22:17:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:18:33 | INFO | train_inner | epoch 899:     17 / 49 loss=2.432, nll_loss=0.315, ppl=1.24, wps=25044.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43700, lr=0.000151272, gnorm=0.354, loss_scale=32, train_wall=221, gb_free=8.8, wall=119758
2022-03-07 22:19:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:19:55 | INFO | valid | epoch 899 | valid on 'valid' subset | loss 13.58 | nll_loss 12.892 | ppl 7602.85 | wps 48148.9 | wpb 510.9 | bsz 1 | num_updates 43732 | best_loss 9.157
2022-03-07 22:19:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 899 @ 43732 updates
2022-03-07 22:19:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:19:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:19:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 899 @ 43732 updates, score 13.58) (writing took 2.2808332671411335 seconds)
2022-03-07 22:19:57 | INFO | fairseq_cli.train | end of epoch 899 (average epoch stats below)
2022-03-07 22:19:57 | INFO | train | epoch 899 | loss 2.432 | nll_loss 0.315 | ppl 1.24 | wps 25275.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43732 | lr 0.000151217 | gnorm 0.358 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 119842
2022-03-07 22:19:57 | INFO | fairseq.trainer | begin training epoch 900
2022-03-07 22:19:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:21:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:22:01 | INFO | valid | epoch 900 | valid on 'valid' subset | loss 13.669 | nll_loss 12.994 | ppl 8155.6 | wps 48274.8 | wpb 510.9 | bsz 1 | num_updates 43781 | best_loss 9.157
2022-03-07 22:22:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 900 @ 43781 updates
2022-03-07 22:22:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:22:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:22:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 900 @ 43781 updates, score 13.669) (writing took 2.241610301658511 seconds)
2022-03-07 22:22:03 | INFO | fairseq_cli.train | end of epoch 900 (average epoch stats below)
2022-03-07 22:22:03 | INFO | train | epoch 900 | loss 2.432 | nll_loss 0.315 | ppl 1.24 | wps 25220.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43781 | lr 0.000151132 | gnorm 0.359 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 119968
2022-03-07 22:22:03 | INFO | fairseq.trainer | begin training epoch 901
2022-03-07 22:22:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:22:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:22:53 | INFO | train_inner | epoch 901:     20 / 49 loss=2.432, nll_loss=0.315, ppl=1.24, wps=25015.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43800, lr=0.000151099, gnorm=0.359, loss_scale=32, train_wall=221, gb_free=8.8, wall=120017
2022-03-07 22:24:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:24:07 | INFO | valid | epoch 901 | valid on 'valid' subset | loss 13.599 | nll_loss 12.919 | ppl 7742.88 | wps 45345.6 | wpb 510.9 | bsz 1 | num_updates 43829 | best_loss 9.157
2022-03-07 22:24:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 901 @ 43829 updates
2022-03-07 22:24:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:24:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:24:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 901 @ 43829 updates, score 13.599) (writing took 2.386722248978913 seconds)
2022-03-07 22:24:10 | INFO | fairseq_cli.train | end of epoch 901 (average epoch stats below)
2022-03-07 22:24:10 | INFO | train | epoch 901 | loss 2.432 | nll_loss 0.315 | ppl 1.24 | wps 24648.7 | ups 0.38 | wpb 64853.3 | bsz 126.7 | num_updates 43829 | lr 0.000151049 | gnorm 0.36 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120094
2022-03-07 22:24:10 | INFO | fairseq.trainer | begin training epoch 902
2022-03-07 22:24:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:26:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:26:13 | INFO | valid | epoch 902 | valid on 'valid' subset | loss 13.538 | nll_loss 12.851 | ppl 7385.75 | wps 48007.1 | wpb 510.9 | bsz 1 | num_updates 43878 | best_loss 9.157
2022-03-07 22:26:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 902 @ 43878 updates
2022-03-07 22:26:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:26:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:26:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 902 @ 43878 updates, score 13.538) (writing took 2.3078597960993648 seconds)
2022-03-07 22:26:16 | INFO | fairseq_cli.train | end of epoch 902 (average epoch stats below)
2022-03-07 22:26:16 | INFO | train | epoch 902 | loss 2.432 | nll_loss 0.315 | ppl 1.24 | wps 25217 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43878 | lr 0.000150965 | gnorm 0.353 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120220
2022-03-07 22:26:16 | INFO | fairseq.trainer | begin training epoch 903
2022-03-07 22:26:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:27:10 | INFO | train_inner | epoch 903:     22 / 49 loss=2.432, nll_loss=0.315, ppl=1.24, wps=25242.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43900, lr=0.000150927, gnorm=0.357, loss_scale=32, train_wall=219, gb_free=8.8, wall=120274
2022-03-07 22:28:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:28:19 | INFO | valid | epoch 903 | valid on 'valid' subset | loss 13.642 | nll_loss 12.966 | ppl 8003.04 | wps 47601.5 | wpb 510.9 | bsz 1 | num_updates 43927 | best_loss 9.157
2022-03-07 22:28:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 903 @ 43927 updates
2022-03-07 22:28:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:28:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:28:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 903 @ 43927 updates, score 13.642) (writing took 2.304380788002163 seconds)
2022-03-07 22:28:22 | INFO | fairseq_cli.train | end of epoch 903 (average epoch stats below)
2022-03-07 22:28:22 | INFO | train | epoch 903 | loss 2.431 | nll_loss 0.315 | ppl 1.24 | wps 25244.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43927 | lr 0.000150881 | gnorm 0.357 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 120346
2022-03-07 22:28:22 | INFO | fairseq.trainer | begin training epoch 904
2022-03-07 22:28:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:28:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:30:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:30:25 | INFO | valid | epoch 904 | valid on 'valid' subset | loss 13.729 | nll_loss 13.053 | ppl 8498.67 | wps 48099.7 | wpb 510.9 | bsz 1 | num_updates 43975 | best_loss 9.157
2022-03-07 22:30:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 904 @ 43975 updates
2022-03-07 22:30:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:30:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:30:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 904 @ 43975 updates, score 13.729) (writing took 2.2519094818271697 seconds)
2022-03-07 22:30:27 | INFO | fairseq_cli.train | end of epoch 904 (average epoch stats below)
2022-03-07 22:30:27 | INFO | train | epoch 904 | loss 2.431 | nll_loss 0.314 | ppl 1.24 | wps 24738.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43975 | lr 0.000150799 | gnorm 0.357 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120472
2022-03-07 22:30:27 | INFO | fairseq.trainer | begin training epoch 905
2022-03-07 22:30:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:31:29 | INFO | train_inner | epoch 905:     25 / 49 loss=2.431, nll_loss=0.314, ppl=1.24, wps=25022.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44000, lr=0.000150756, gnorm=0.355, loss_scale=32, train_wall=221, gb_free=8.8, wall=120534
2022-03-07 22:32:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:32:31 | INFO | valid | epoch 905 | valid on 'valid' subset | loss 13.649 | nll_loss 12.974 | ppl 8044.82 | wps 47291.9 | wpb 510.9 | bsz 1 | num_updates 44024 | best_loss 9.157
2022-03-07 22:32:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 905 @ 44024 updates
2022-03-07 22:32:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:32:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:32:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 905 @ 44024 updates, score 13.649) (writing took 2.3873943402431905 seconds)
2022-03-07 22:32:34 | INFO | fairseq_cli.train | end of epoch 905 (average epoch stats below)
2022-03-07 22:32:34 | INFO | train | epoch 905 | loss 2.43 | nll_loss 0.314 | ppl 1.24 | wps 25190 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44024 | lr 0.000150715 | gnorm 0.353 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120598
2022-03-07 22:32:34 | INFO | fairseq.trainer | begin training epoch 906
2022-03-07 22:32:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:34:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:34:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:34:37 | INFO | valid | epoch 906 | valid on 'valid' subset | loss 13.765 | nll_loss 13.101 | ppl 8785.13 | wps 47813.9 | wpb 510.9 | bsz 1 | num_updates 44072 | best_loss 9.157
2022-03-07 22:34:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 906 @ 44072 updates
2022-03-07 22:34:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:34:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:34:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 906 @ 44072 updates, score 13.765) (writing took 2.254740981850773 seconds)
2022-03-07 22:34:39 | INFO | fairseq_cli.train | end of epoch 906 (average epoch stats below)
2022-03-07 22:34:39 | INFO | train | epoch 906 | loss 2.431 | nll_loss 0.314 | ppl 1.24 | wps 24732.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44072 | lr 0.000150632 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120724
2022-03-07 22:34:39 | INFO | fairseq.trainer | begin training epoch 907
2022-03-07 22:34:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:35:48 | INFO | train_inner | epoch 907:     28 / 49 loss=2.431, nll_loss=0.314, ppl=1.24, wps=25020.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44100, lr=0.000150585, gnorm=0.354, loss_scale=32, train_wall=221, gb_free=8.8, wall=120793
2022-03-07 22:36:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:36:43 | INFO | valid | epoch 907 | valid on 'valid' subset | loss 13.624 | nll_loss 12.945 | ppl 7884.72 | wps 47875.9 | wpb 510.9 | bsz 1 | num_updates 44121 | best_loss 9.157
2022-03-07 22:36:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 907 @ 44121 updates
2022-03-07 22:36:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:36:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:36:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 907 @ 44121 updates, score 13.624) (writing took 2.298678649123758 seconds)
2022-03-07 22:36:45 | INFO | fairseq_cli.train | end of epoch 907 (average epoch stats below)
2022-03-07 22:36:45 | INFO | train | epoch 907 | loss 2.431 | nll_loss 0.314 | ppl 1.24 | wps 25246.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44121 | lr 0.000150549 | gnorm 0.355 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120850
2022-03-07 22:36:45 | INFO | fairseq.trainer | begin training epoch 908
2022-03-07 22:36:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:38:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:38:49 | INFO | valid | epoch 908 | valid on 'valid' subset | loss 13.588 | nll_loss 12.906 | ppl 7673.76 | wps 48258.9 | wpb 510.9 | bsz 1 | num_updates 44170 | best_loss 9.157
2022-03-07 22:38:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 908 @ 44170 updates
2022-03-07 22:38:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:38:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:38:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 908 @ 44170 updates, score 13.588) (writing took 2.2789915706962347 seconds)
2022-03-07 22:38:51 | INFO | fairseq_cli.train | end of epoch 908 (average epoch stats below)
2022-03-07 22:38:51 | INFO | train | epoch 908 | loss 2.431 | nll_loss 0.314 | ppl 1.24 | wps 25213.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44170 | lr 0.000150465 | gnorm 0.355 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120976
2022-03-07 22:38:51 | INFO | fairseq.trainer | begin training epoch 909
2022-03-07 22:38:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:40:05 | INFO | train_inner | epoch 909:     30 / 49 loss=2.431, nll_loss=0.314, ppl=1.24, wps=25261.6, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=44200, lr=0.000150414, gnorm=0.355, loss_scale=64, train_wall=219, gb_free=8.8, wall=121050
2022-03-07 22:40:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:40:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:40:55 | INFO | valid | epoch 909 | valid on 'valid' subset | loss 13.651 | nll_loss 12.975 | ppl 8050.59 | wps 47685.9 | wpb 510.9 | bsz 1 | num_updates 44218 | best_loss 9.157
2022-03-07 22:40:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 909 @ 44218 updates
2022-03-07 22:40:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:40:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:40:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 909 @ 44218 updates, score 13.651) (writing took 2.3550173160620034 seconds)
2022-03-07 22:40:57 | INFO | fairseq_cli.train | end of epoch 909 (average epoch stats below)
2022-03-07 22:40:57 | INFO | train | epoch 909 | loss 2.431 | nll_loss 0.314 | ppl 1.24 | wps 24692.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44218 | lr 0.000150384 | gnorm 0.354 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 121102
2022-03-07 22:40:57 | INFO | fairseq.trainer | begin training epoch 910
2022-03-07 22:40:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:42:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:43:01 | INFO | valid | epoch 910 | valid on 'valid' subset | loss 13.515 | nll_loss 12.832 | ppl 7290.67 | wps 48029.6 | wpb 510.9 | bsz 1 | num_updates 44267 | best_loss 9.157
2022-03-07 22:43:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 910 @ 44267 updates
2022-03-07 22:43:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:43:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:43:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 910 @ 44267 updates, score 13.515) (writing took 2.2756490278989077 seconds)
2022-03-07 22:43:03 | INFO | fairseq_cli.train | end of epoch 910 (average epoch stats below)
2022-03-07 22:43:03 | INFO | train | epoch 910 | loss 2.43 | nll_loss 0.313 | ppl 1.24 | wps 25222.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44267 | lr 0.0001503 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 121228
2022-03-07 22:43:03 | INFO | fairseq.trainer | begin training epoch 911
2022-03-07 22:43:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:44:25 | INFO | train_inner | epoch 911:     33 / 49 loss=2.43, nll_loss=0.314, ppl=1.24, wps=24991.7, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=44300, lr=0.000150244, gnorm=0.356, loss_scale=32, train_wall=221, gb_free=8.8, wall=121309
2022-03-07 22:45:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:45:07 | INFO | valid | epoch 911 | valid on 'valid' subset | loss 13.608 | nll_loss 12.927 | ppl 7787.99 | wps 47820.6 | wpb 510.9 | bsz 1 | num_updates 44316 | best_loss 9.157
2022-03-07 22:45:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 911 @ 44316 updates
2022-03-07 22:45:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:45:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:45:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 911 @ 44316 updates, score 13.608) (writing took 2.2599325887858868 seconds)
2022-03-07 22:45:09 | INFO | fairseq_cli.train | end of epoch 911 (average epoch stats below)
2022-03-07 22:45:09 | INFO | train | epoch 911 | loss 2.43 | nll_loss 0.314 | ppl 1.24 | wps 25235.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44316 | lr 0.000150217 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 121354
2022-03-07 22:45:09 | INFO | fairseq.trainer | begin training epoch 912
2022-03-07 22:45:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:46:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:47:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:47:13 | INFO | valid | epoch 912 | valid on 'valid' subset | loss 13.682 | nll_loss 13.01 | ppl 8247.42 | wps 48251.3 | wpb 510.9 | bsz 1 | num_updates 44364 | best_loss 9.157
2022-03-07 22:47:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 912 @ 44364 updates
2022-03-07 22:47:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:47:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 912 @ 44364 updates, score 13.682) (writing took 2.2735334197059274 seconds)
2022-03-07 22:47:15 | INFO | fairseq_cli.train | end of epoch 912 (average epoch stats below)
2022-03-07 22:47:15 | INFO | train | epoch 912 | loss 2.431 | nll_loss 0.314 | ppl 1.24 | wps 24747.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44364 | lr 0.000150136 | gnorm 0.354 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 121480
2022-03-07 22:47:15 | INFO | fairseq.trainer | begin training epoch 913
2022-03-07 22:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:48:44 | INFO | train_inner | epoch 913:     36 / 49 loss=2.43, nll_loss=0.314, ppl=1.24, wps=25050.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44400, lr=0.000150075, gnorm=0.355, loss_scale=32, train_wall=221, gb_free=8.8, wall=121568
2022-03-07 22:49:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:49:19 | INFO | valid | epoch 913 | valid on 'valid' subset | loss 13.607 | nll_loss 12.93 | ppl 7802.39 | wps 47522.2 | wpb 510.9 | bsz 1 | num_updates 44413 | best_loss 9.157
2022-03-07 22:49:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 913 @ 44413 updates
2022-03-07 22:49:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:49:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:49:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 913 @ 44413 updates, score 13.607) (writing took 2.4385538729839027 seconds)
2022-03-07 22:49:21 | INFO | fairseq_cli.train | end of epoch 913 (average epoch stats below)
2022-03-07 22:49:21 | INFO | train | epoch 913 | loss 2.43 | nll_loss 0.314 | ppl 1.24 | wps 25184.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44413 | lr 0.000150053 | gnorm 0.357 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 121606
2022-03-07 22:49:21 | INFO | fairseq.trainer | begin training epoch 914
2022-03-07 22:49:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:51:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:51:25 | INFO | valid | epoch 914 | valid on 'valid' subset | loss 13.643 | nll_loss 12.964 | ppl 7989.18 | wps 48021.4 | wpb 510.9 | bsz 1 | num_updates 44462 | best_loss 9.157
2022-03-07 22:51:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 914 @ 44462 updates
2022-03-07 22:51:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:51:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:51:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 914 @ 44462 updates, score 13.643) (writing took 2.2631977288983762 seconds)
2022-03-07 22:51:27 | INFO | fairseq_cli.train | end of epoch 914 (average epoch stats below)
2022-03-07 22:51:27 | INFO | train | epoch 914 | loss 2.43 | nll_loss 0.314 | ppl 1.24 | wps 25218.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44462 | lr 0.00014997 | gnorm 0.359 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 121732
2022-03-07 22:51:27 | INFO | fairseq.trainer | begin training epoch 915
2022-03-07 22:51:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:52:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:53:03 | INFO | train_inner | epoch 915:     39 / 49 loss=2.43, nll_loss=0.314, ppl=1.24, wps=24994.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44500, lr=0.000149906, gnorm=0.358, loss_scale=32, train_wall=221, gb_free=8.8, wall=121828
2022-03-07 22:53:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:53:31 | INFO | valid | epoch 915 | valid on 'valid' subset | loss 13.523 | nll_loss 12.831 | ppl 7288.36 | wps 48244.1 | wpb 510.9 | bsz 1 | num_updates 44510 | best_loss 9.157
2022-03-07 22:53:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 915 @ 44510 updates
2022-03-07 22:53:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:53:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:53:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 915 @ 44510 updates, score 13.523) (writing took 2.2627690071240067 seconds)
2022-03-07 22:53:33 | INFO | fairseq_cli.train | end of epoch 915 (average epoch stats below)
2022-03-07 22:53:33 | INFO | train | epoch 915 | loss 2.43 | nll_loss 0.313 | ppl 1.24 | wps 24723.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44510 | lr 0.000149889 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 121858
2022-03-07 22:53:33 | INFO | fairseq.trainer | begin training epoch 916
2022-03-07 22:53:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:55:37 | INFO | valid | epoch 916 | valid on 'valid' subset | loss 13.771 | nll_loss 13.108 | ppl 8826.26 | wps 47992.8 | wpb 510.9 | bsz 1 | num_updates 44559 | best_loss 9.157
2022-03-07 22:55:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 916 @ 44559 updates
2022-03-07 22:55:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:55:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:55:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 916 @ 44559 updates, score 13.771) (writing took 2.2692089341580868 seconds)
2022-03-07 22:55:39 | INFO | fairseq_cli.train | end of epoch 916 (average epoch stats below)
2022-03-07 22:55:39 | INFO | train | epoch 916 | loss 2.429 | nll_loss 0.313 | ppl 1.24 | wps 25221.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44559 | lr 0.000149807 | gnorm 0.353 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 121984
2022-03-07 22:55:39 | INFO | fairseq.trainer | begin training epoch 917
2022-03-07 22:55:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:57:20 | INFO | train_inner | epoch 917:     41 / 49 loss=2.43, nll_loss=0.313, ppl=1.24, wps=25259.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44600, lr=0.000149738, gnorm=0.355, loss_scale=32, train_wall=219, gb_free=8.8, wall=122085
2022-03-07 22:57:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:57:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:57:43 | INFO | valid | epoch 917 | valid on 'valid' subset | loss 13.576 | nll_loss 12.893 | ppl 7608.02 | wps 48013.7 | wpb 510.9 | bsz 1 | num_updates 44607 | best_loss 9.157
2022-03-07 22:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 917 @ 44607 updates
2022-03-07 22:57:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:57:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:57:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 917 @ 44607 updates, score 13.576) (writing took 2.389849442988634 seconds)
2022-03-07 22:57:45 | INFO | fairseq_cli.train | end of epoch 917 (average epoch stats below)
2022-03-07 22:57:45 | INFO | train | epoch 917 | loss 2.43 | nll_loss 0.313 | ppl 1.24 | wps 24657.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44607 | lr 0.000149726 | gnorm 0.358 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 122110
2022-03-07 22:57:46 | INFO | fairseq.trainer | begin training epoch 918
2022-03-07 22:57:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:59:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:59:49 | INFO | valid | epoch 918 | valid on 'valid' subset | loss 13.648 | nll_loss 12.973 | ppl 8041.77 | wps 48110 | wpb 510.9 | bsz 1 | num_updates 44656 | best_loss 9.157
2022-03-07 22:59:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 918 @ 44656 updates
2022-03-07 22:59:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:59:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:59:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 918 @ 44656 updates, score 13.648) (writing took 2.2843560348264873 seconds)
2022-03-07 22:59:51 | INFO | fairseq_cli.train | end of epoch 918 (average epoch stats below)
2022-03-07 22:59:51 | INFO | train | epoch 918 | loss 2.429 | nll_loss 0.313 | ppl 1.24 | wps 25281.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44656 | lr 0.000149644 | gnorm 0.352 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 122236
2022-03-07 22:59:51 | INFO | fairseq.trainer | begin training epoch 919
2022-03-07 22:59:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:01:39 | INFO | train_inner | epoch 919:     44 / 49 loss=2.43, nll_loss=0.313, ppl=1.24, wps=25012.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44700, lr=0.000149571, gnorm=0.355, loss_scale=32, train_wall=221, gb_free=8.8, wall=122344
2022-03-07 23:01:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:01:55 | INFO | valid | epoch 919 | valid on 'valid' subset | loss 13.679 | nll_loss 13.002 | ppl 8205.06 | wps 48271.9 | wpb 510.9 | bsz 1 | num_updates 44705 | best_loss 9.157
2022-03-07 23:01:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 919 @ 44705 updates
2022-03-07 23:01:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:01:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:01:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 919 @ 44705 updates, score 13.679) (writing took 2.2398043829016387 seconds)
2022-03-07 23:01:57 | INFO | fairseq_cli.train | end of epoch 919 (average epoch stats below)
2022-03-07 23:01:57 | INFO | train | epoch 919 | loss 2.43 | nll_loss 0.313 | ppl 1.24 | wps 25244.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44705 | lr 0.000149562 | gnorm 0.357 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 122362
2022-03-07 23:01:57 | INFO | fairseq.trainer | begin training epoch 920
2022-03-07 23:01:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:03:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:03:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:04:01 | INFO | valid | epoch 920 | valid on 'valid' subset | loss 13.681 | nll_loss 13.009 | ppl 8241.03 | wps 48380.7 | wpb 510.9 | bsz 1 | num_updates 44753 | best_loss 9.157
2022-03-07 23:04:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 920 @ 44753 updates
2022-03-07 23:04:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:04:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:04:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 920 @ 44753 updates, score 13.681) (writing took 2.2557196388952434 seconds)
2022-03-07 23:04:03 | INFO | fairseq_cli.train | end of epoch 920 (average epoch stats below)
2022-03-07 23:04:03 | INFO | train | epoch 920 | loss 2.429 | nll_loss 0.313 | ppl 1.24 | wps 24694.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44753 | lr 0.000149482 | gnorm 0.357 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 122488
2022-03-07 23:04:03 | INFO | fairseq.trainer | begin training epoch 921
2022-03-07 23:04:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:05:59 | INFO | train_inner | epoch 921:     47 / 49 loss=2.429, nll_loss=0.313, ppl=1.24, wps=24989.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44800, lr=0.000149404, gnorm=0.354, loss_scale=32, train_wall=221, gb_free=8.8, wall=122604
2022-03-07 23:06:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:06:07 | INFO | valid | epoch 921 | valid on 'valid' subset | loss 13.601 | nll_loss 12.924 | ppl 7771.48 | wps 47955.3 | wpb 510.9 | bsz 1 | num_updates 44802 | best_loss 9.157
2022-03-07 23:06:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 921 @ 44802 updates
2022-03-07 23:06:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:06:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:06:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 921 @ 44802 updates, score 13.601) (writing took 2.383804631885141 seconds)
2022-03-07 23:06:10 | INFO | fairseq_cli.train | end of epoch 921 (average epoch stats below)
2022-03-07 23:06:10 | INFO | train | epoch 921 | loss 2.429 | nll_loss 0.313 | ppl 1.24 | wps 25142.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44802 | lr 0.0001494 | gnorm 0.351 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 122614
2022-03-07 23:06:10 | INFO | fairseq.trainer | begin training epoch 922
2022-03-07 23:06:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:08:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:08:13 | INFO | valid | epoch 922 | valid on 'valid' subset | loss 13.595 | nll_loss 12.913 | ppl 7712.26 | wps 48559.7 | wpb 510.9 | bsz 1 | num_updates 44851 | best_loss 9.157
2022-03-07 23:08:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 922 @ 44851 updates
2022-03-07 23:08:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:08:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:08:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 922 @ 44851 updates, score 13.595) (writing took 2.259273267816752 seconds)
2022-03-07 23:08:15 | INFO | fairseq_cli.train | end of epoch 922 (average epoch stats below)
2022-03-07 23:08:15 | INFO | train | epoch 922 | loss 2.429 | nll_loss 0.313 | ppl 1.24 | wps 25281 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44851 | lr 0.000149319 | gnorm 0.352 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 122740
2022-03-07 23:08:15 | INFO | fairseq.trainer | begin training epoch 923
2022-03-07 23:08:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:08:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:10:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:10:19 | INFO | valid | epoch 923 | valid on 'valid' subset | loss 13.642 | nll_loss 12.968 | ppl 8012.17 | wps 47033.5 | wpb 510.9 | bsz 1 | num_updates 44899 | best_loss 9.157
2022-03-07 23:10:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 923 @ 44899 updates
2022-03-07 23:10:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:10:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:10:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 923 @ 44899 updates, score 13.642) (writing took 2.2632481162436306 seconds)
2022-03-07 23:10:21 | INFO | fairseq_cli.train | end of epoch 923 (average epoch stats below)
2022-03-07 23:10:21 | INFO | train | epoch 923 | loss 2.429 | nll_loss 0.312 | ppl 1.24 | wps 24725.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44899 | lr 0.000149239 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 122866
2022-03-07 23:10:21 | INFO | fairseq.trainer | begin training epoch 924
2022-03-07 23:10:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:10:24 | INFO | train_inner | epoch 924:      1 / 49 loss=2.429, nll_loss=0.312, ppl=1.24, wps=24372.3, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=44900, lr=0.000149237, gnorm=0.355, loss_scale=32, train_wall=220, gb_free=8.8, wall=122868
2022-03-07 23:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:12:25 | INFO | valid | epoch 924 | valid on 'valid' subset | loss 13.69 | nll_loss 13.021 | ppl 8311.29 | wps 48104.6 | wpb 510.9 | bsz 1 | num_updates 44948 | best_loss 9.157
2022-03-07 23:12:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 924 @ 44948 updates
2022-03-07 23:12:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:12:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:12:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 924 @ 44948 updates, score 13.69) (writing took 2.2625600690953434 seconds)
2022-03-07 23:12:27 | INFO | fairseq_cli.train | end of epoch 924 (average epoch stats below)
2022-03-07 23:12:27 | INFO | train | epoch 924 | loss 2.428 | nll_loss 0.312 | ppl 1.24 | wps 25256.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44948 | lr 0.000149157 | gnorm 0.349 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 122992
2022-03-07 23:12:27 | INFO | fairseq.trainer | begin training epoch 925
2022-03-07 23:12:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:14:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:14:31 | INFO | valid | epoch 925 | valid on 'valid' subset | loss 13.622 | nll_loss 12.947 | ppl 7896.77 | wps 47853.2 | wpb 510.9 | bsz 1 | num_updates 44997 | best_loss 9.157
2022-03-07 23:14:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 925 @ 44997 updates
2022-03-07 23:14:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:14:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:14:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 925 @ 44997 updates, score 13.622) (writing took 2.3818224552087486 seconds)
2022-03-07 23:14:33 | INFO | fairseq_cli.train | end of epoch 925 (average epoch stats below)
2022-03-07 23:14:33 | INFO | train | epoch 925 | loss 2.428 | nll_loss 0.313 | ppl 1.24 | wps 25211.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44997 | lr 0.000149076 | gnorm 0.355 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 123118
2022-03-07 23:14:33 | INFO | fairseq.trainer | begin training epoch 926
2022-03-07 23:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:14:40 | INFO | train_inner | epoch 926:      3 / 49 loss=2.428, nll_loss=0.312, ppl=1.24, wps=25264.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=45000, lr=0.000149071, gnorm=0.352, loss_scale=64, train_wall=219, gb_free=8.8, wall=123125
2022-03-07 23:14:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:16:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:16:37 | INFO | valid | epoch 926 | valid on 'valid' subset | loss 13.648 | nll_loss 12.972 | ppl 8034.93 | wps 47857.1 | wpb 510.9 | bsz 1 | num_updates 45045 | best_loss 9.157
2022-03-07 23:16:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 926 @ 45045 updates
2022-03-07 23:16:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:16:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:16:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 926 @ 45045 updates, score 13.648) (writing took 2.239005539100617 seconds)
2022-03-07 23:16:39 | INFO | fairseq_cli.train | end of epoch 926 (average epoch stats below)
2022-03-07 23:16:39 | INFO | train | epoch 926 | loss 2.428 | nll_loss 0.312 | ppl 1.24 | wps 24743.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45045 | lr 0.000148997 | gnorm 0.349 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123244
2022-03-07 23:16:39 | INFO | fairseq.trainer | begin training epoch 927
2022-03-07 23:16:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:18:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:18:42 | INFO | valid | epoch 927 | valid on 'valid' subset | loss 13.715 | nll_loss 13.052 | ppl 8489.84 | wps 48188.1 | wpb 510.9 | bsz 1 | num_updates 45094 | best_loss 9.157
2022-03-07 23:18:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 927 @ 45094 updates
2022-03-07 23:18:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:18:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:18:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 927 @ 45094 updates, score 13.715) (writing took 2.261425853241235 seconds)
2022-03-07 23:18:45 | INFO | fairseq_cli.train | end of epoch 927 (average epoch stats below)
2022-03-07 23:18:45 | INFO | train | epoch 927 | loss 2.428 | nll_loss 0.312 | ppl 1.24 | wps 25237.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45094 | lr 0.000148916 | gnorm 0.353 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123369
2022-03-07 23:18:45 | INFO | fairseq.trainer | begin training epoch 928
2022-03-07 23:18:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:18:59 | INFO | train_inner | epoch 928:      6 / 49 loss=2.428, nll_loss=0.312, ppl=1.24, wps=25045.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=45100, lr=0.000148906, gnorm=0.351, loss_scale=32, train_wall=221, gb_free=8.8, wall=123384
2022-03-07 23:20:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:20:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:20:48 | INFO | valid | epoch 928 | valid on 'valid' subset | loss 13.601 | nll_loss 12.918 | ppl 7741.13 | wps 48324.7 | wpb 510.9 | bsz 1 | num_updates 45142 | best_loss 9.157
2022-03-07 23:20:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 928 @ 45142 updates
2022-03-07 23:20:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:20:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:20:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 928 @ 45142 updates, score 13.601) (writing took 2.2845007618889213 seconds)
2022-03-07 23:20:50 | INFO | fairseq_cli.train | end of epoch 928 (average epoch stats below)
2022-03-07 23:20:50 | INFO | train | epoch 928 | loss 2.428 | nll_loss 0.312 | ppl 1.24 | wps 24760.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45142 | lr 0.000148837 | gnorm 0.358 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123495
2022-03-07 23:20:50 | INFO | fairseq.trainer | begin training epoch 929
2022-03-07 23:20:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:22:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:22:54 | INFO | valid | epoch 929 | valid on 'valid' subset | loss 13.67 | nll_loss 12.996 | ppl 8170.72 | wps 47945.2 | wpb 510.9 | bsz 1 | num_updates 45191 | best_loss 9.157
2022-03-07 23:22:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 929 @ 45191 updates
2022-03-07 23:22:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:22:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:22:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 929 @ 45191 updates, score 13.67) (writing took 2.332669991068542 seconds)
2022-03-07 23:22:56 | INFO | fairseq_cli.train | end of epoch 929 (average epoch stats below)
2022-03-07 23:22:56 | INFO | train | epoch 929 | loss 2.428 | nll_loss 0.312 | ppl 1.24 | wps 25217.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45191 | lr 0.000148756 | gnorm 0.352 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123621
2022-03-07 23:22:56 | INFO | fairseq.trainer | begin training epoch 930
2022-03-07 23:22:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:23:19 | INFO | train_inner | epoch 930:      9 / 49 loss=2.428, nll_loss=0.312, ppl=1.24, wps=25033.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=45200, lr=0.000148741, gnorm=0.355, loss_scale=32, train_wall=221, gb_free=8.8, wall=123643
2022-03-07 23:24:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:25:00 | INFO | valid | epoch 930 | valid on 'valid' subset | loss 13.716 | nll_loss 13.047 | ppl 8464.59 | wps 48070 | wpb 510.9 | bsz 1 | num_updates 45240 | best_loss 9.157
2022-03-07 23:25:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 930 @ 45240 updates
2022-03-07 23:25:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:25:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:25:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 930 @ 45240 updates, score 13.716) (writing took 2.2821932598017156 seconds)
2022-03-07 23:25:02 | INFO | fairseq_cli.train | end of epoch 930 (average epoch stats below)
2022-03-07 23:25:02 | INFO | train | epoch 930 | loss 2.428 | nll_loss 0.312 | ppl 1.24 | wps 25275.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45240 | lr 0.000148675 | gnorm 0.351 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123747
2022-03-07 23:25:02 | INFO | fairseq.trainer | begin training epoch 931
2022-03-07 23:25:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:25:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:27:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:27:06 | INFO | valid | epoch 931 | valid on 'valid' subset | loss 13.641 | nll_loss 12.966 | ppl 8001.49 | wps 48499.9 | wpb 510.9 | bsz 1 | num_updates 45288 | best_loss 9.157
2022-03-07 23:27:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 931 @ 45288 updates
2022-03-07 23:27:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:27:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:27:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 931 @ 45288 updates, score 13.641) (writing took 2.283805711194873 seconds)
2022-03-07 23:27:08 | INFO | fairseq_cli.train | end of epoch 931 (average epoch stats below)
2022-03-07 23:27:08 | INFO | train | epoch 931 | loss 2.427 | nll_loss 0.312 | ppl 1.24 | wps 24748.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45288 | lr 0.000148596 | gnorm 0.353 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123873
2022-03-07 23:27:08 | INFO | fairseq.trainer | begin training epoch 932
2022-03-07 23:27:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:27:38 | INFO | train_inner | epoch 932:     12 / 49 loss=2.428, nll_loss=0.312, ppl=1.24, wps=25055.3, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=45300, lr=0.000148577, gnorm=0.351, loss_scale=32, train_wall=221, gb_free=8.8, wall=123902
2022-03-07 23:29:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:29:11 | INFO | valid | epoch 932 | valid on 'valid' subset | loss 13.586 | nll_loss 12.907 | ppl 7682.1 | wps 48363.5 | wpb 510.9 | bsz 1 | num_updates 45337 | best_loss 9.157
2022-03-07 23:29:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 932 @ 45337 updates
2022-03-07 23:29:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:29:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:29:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 932 @ 45337 updates, score 13.586) (writing took 2.3043617880903184 seconds)
2022-03-07 23:29:14 | INFO | fairseq_cli.train | end of epoch 932 (average epoch stats below)
2022-03-07 23:29:14 | INFO | train | epoch 932 | loss 2.427 | nll_loss 0.312 | ppl 1.24 | wps 25284.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45337 | lr 0.000148516 | gnorm 0.353 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123998
2022-03-07 23:29:14 | INFO | fairseq.trainer | begin training epoch 933
2022-03-07 23:29:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:31:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:31:17 | INFO | valid | epoch 933 | valid on 'valid' subset | loss 13.577 | nll_loss 12.894 | ppl 7610.43 | wps 47664.1 | wpb 510.9 | bsz 1 | num_updates 45386 | best_loss 9.157
2022-03-07 23:31:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 933 @ 45386 updates
2022-03-07 23:31:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:31:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:31:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 933 @ 45386 updates, score 13.577) (writing took 2.3091396782547235 seconds)
2022-03-07 23:31:20 | INFO | fairseq_cli.train | end of epoch 933 (average epoch stats below)
2022-03-07 23:31:20 | INFO | train | epoch 933 | loss 2.428 | nll_loss 0.312 | ppl 1.24 | wps 25206 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45386 | lr 0.000148436 | gnorm 0.357 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 124124
2022-03-07 23:31:20 | INFO | fairseq.trainer | begin training epoch 934
2022-03-07 23:31:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:31:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:31:57 | INFO | train_inner | epoch 934:     15 / 49 loss=2.428, nll_loss=0.312, ppl=1.24, wps=25038.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=45400, lr=0.000148413, gnorm=0.356, loss_scale=32, train_wall=221, gb_free=8.8, wall=124161
2022-03-07 23:33:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:33:23 | INFO | valid | epoch 934 | valid on 'valid' subset | loss 13.671 | nll_loss 12.999 | ppl 8184.94 | wps 47836.6 | wpb 510.9 | bsz 1 | num_updates 45434 | best_loss 9.157
2022-03-07 23:33:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 934 @ 45434 updates
2022-03-07 23:33:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:33:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:33:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 934 @ 45434 updates, score 13.671) (writing took 2.312548876274377 seconds)
2022-03-07 23:33:26 | INFO | fairseq_cli.train | end of epoch 934 (average epoch stats below)
2022-03-07 23:33:26 | INFO | train | epoch 934 | loss 2.427 | nll_loss 0.312 | ppl 1.24 | wps 24710.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45434 | lr 0.000148358 | gnorm 0.354 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 124250
2022-03-07 23:33:26 | INFO | fairseq.trainer | begin training epoch 935
2022-03-07 23:33:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:35:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:35:29 | INFO | valid | epoch 935 | valid on 'valid' subset | loss 13.681 | nll_loss 13.013 | ppl 8264.5 | wps 47834 | wpb 510.9 | bsz 1 | num_updates 45483 | best_loss 9.157
2022-03-07 23:35:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 935 @ 45483 updates
2022-03-07 23:35:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:35:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:35:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 935 @ 45483 updates, score 13.681) (writing took 2.289417773950845 seconds)
2022-03-07 23:35:32 | INFO | fairseq_cli.train | end of epoch 935 (average epoch stats below)
2022-03-07 23:35:32 | INFO | train | epoch 935 | loss 2.427 | nll_loss 0.311 | ppl 1.24 | wps 25242.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45483 | lr 0.000148278 | gnorm 0.351 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 124376
2022-03-07 23:35:32 | INFO | fairseq.trainer | begin training epoch 936
2022-03-07 23:35:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:36:13 | INFO | train_inner | epoch 936:     17 / 49 loss=2.427, nll_loss=0.311, ppl=1.24, wps=25259.2, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=45500, lr=0.00014825, gnorm=0.352, loss_scale=32, train_wall=219, gb_free=8.8, wall=124418
2022-03-07 23:37:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:37:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:37:35 | INFO | valid | epoch 936 | valid on 'valid' subset | loss 13.642 | nll_loss 12.97 | ppl 8025.23 | wps 48269.8 | wpb 510.9 | bsz 1 | num_updates 45531 | best_loss 9.157
2022-03-07 23:37:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 936 @ 45531 updates
2022-03-07 23:37:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:37:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:37:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 936 @ 45531 updates, score 13.642) (writing took 2.2930192621424794 seconds)
2022-03-07 23:37:38 | INFO | fairseq_cli.train | end of epoch 936 (average epoch stats below)
2022-03-07 23:37:38 | INFO | train | epoch 936 | loss 2.427 | nll_loss 0.311 | ppl 1.24 | wps 24706.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45531 | lr 0.000148199 | gnorm 0.35 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 124502
2022-03-07 23:37:38 | INFO | fairseq.trainer | begin training epoch 937
2022-03-07 23:37:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:39:41 | INFO | valid | epoch 937 | valid on 'valid' subset | loss 13.746 | nll_loss 13.081 | ppl 8666.34 | wps 48326.6 | wpb 510.9 | bsz 1 | num_updates 45580 | best_loss 9.157
2022-03-07 23:39:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 937 @ 45580 updates
2022-03-07 23:39:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:39:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:39:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 937 @ 45580 updates, score 13.746) (writing took 2.3539857589639723 seconds)
2022-03-07 23:39:44 | INFO | fairseq_cli.train | end of epoch 937 (average epoch stats below)
2022-03-07 23:39:44 | INFO | train | epoch 937 | loss 2.427 | nll_loss 0.312 | ppl 1.24 | wps 25176.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45580 | lr 0.00014812 | gnorm 0.354 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 124629
2022-03-07 23:39:44 | INFO | fairseq.trainer | begin training epoch 938
2022-03-07 23:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:40:33 | INFO | train_inner | epoch 938:     20 / 49 loss=2.427, nll_loss=0.312, ppl=1.24, wps=25003.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=45600, lr=0.000148087, gnorm=0.352, loss_scale=32, train_wall=221, gb_free=8.8, wall=124678
2022-03-07 23:41:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:41:47 | INFO | valid | epoch 938 | valid on 'valid' subset | loss 13.661 | nll_loss 12.984 | ppl 8103.79 | wps 48186.1 | wpb 510.9 | bsz 1 | num_updates 45629 | best_loss 9.157
2022-03-07 23:41:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 938 @ 45629 updates
2022-03-07 23:41:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:41:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:41:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 938 @ 45629 updates, score 13.661) (writing took 2.246940800920129 seconds)
2022-03-07 23:41:50 | INFO | fairseq_cli.train | end of epoch 938 (average epoch stats below)
2022-03-07 23:41:50 | INFO | train | epoch 938 | loss 2.428 | nll_loss 0.312 | ppl 1.24 | wps 25249.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45629 | lr 0.00014804 | gnorm 0.352 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 124754
2022-03-07 23:41:50 | INFO | fairseq.trainer | begin training epoch 939
2022-03-07 23:41:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:42:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:43:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:43:54 | INFO | valid | epoch 939 | valid on 'valid' subset | loss 13.597 | nll_loss 12.915 | ppl 7723.86 | wps 47743.5 | wpb 510.9 | bsz 1 | num_updates 45677 | best_loss 9.157
2022-03-07 23:43:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 939 @ 45677 updates
2022-03-07 23:43:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:43:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:43:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 939 @ 45677 updates, score 13.597) (writing took 2.2200484862551093 seconds)
2022-03-07 23:43:56 | INFO | fairseq_cli.train | end of epoch 939 (average epoch stats below)
2022-03-07 23:43:56 | INFO | train | epoch 939 | loss 2.427 | nll_loss 0.311 | ppl 1.24 | wps 24595.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45677 | lr 0.000147962 | gnorm 0.35 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 124881
2022-03-07 23:43:56 | INFO | fairseq.trainer | begin training epoch 940
2022-03-07 23:43:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:44:53 | INFO | train_inner | epoch 940:     23 / 49 loss=2.427, nll_loss=0.312, ppl=1.24, wps=24916.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=45700, lr=0.000147925, gnorm=0.35, loss_scale=32, train_wall=222, gb_free=8.8, wall=124938
2022-03-07 23:45:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:46:00 | INFO | valid | epoch 940 | valid on 'valid' subset | loss 13.644 | nll_loss 12.963 | ppl 7982.22 | wps 47637.3 | wpb 510.9 | bsz 1 | num_updates 45726 | best_loss 9.157
2022-03-07 23:46:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 940 @ 45726 updates
2022-03-07 23:46:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:46:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:46:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 940 @ 45726 updates, score 13.644) (writing took 2.369396154768765 seconds)
2022-03-07 23:46:03 | INFO | fairseq_cli.train | end of epoch 940 (average epoch stats below)
2022-03-07 23:46:03 | INFO | train | epoch 940 | loss 2.427 | nll_loss 0.311 | ppl 1.24 | wps 25104.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45726 | lr 0.000147883 | gnorm 0.352 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 125008
2022-03-07 23:46:03 | INFO | fairseq.trainer | begin training epoch 941
2022-03-07 23:46:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:48:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:48:07 | INFO | valid | epoch 941 | valid on 'valid' subset | loss 13.587 | nll_loss 12.906 | ppl 7675.57 | wps 48171.5 | wpb 510.9 | bsz 1 | num_updates 45775 | best_loss 9.157
2022-03-07 23:48:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 941 @ 45775 updates
2022-03-07 23:48:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:48:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:48:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 941 @ 45775 updates, score 13.587) (writing took 2.3390158051624894 seconds)
2022-03-07 23:48:09 | INFO | fairseq_cli.train | end of epoch 941 (average epoch stats below)
2022-03-07 23:48:09 | INFO | train | epoch 941 | loss 2.427 | nll_loss 0.311 | ppl 1.24 | wps 25211.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45775 | lr 0.000147804 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 125134
2022-03-07 23:48:09 | INFO | fairseq.trainer | begin training epoch 942
2022-03-07 23:48:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:49:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:49:13 | INFO | train_inner | epoch 942:     26 / 49 loss=2.427, nll_loss=0.312, ppl=1.24, wps=25019, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=45800, lr=0.000147764, gnorm=0.357, loss_scale=32, train_wall=221, gb_free=8.8, wall=125197
2022-03-07 23:50:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:50:12 | INFO | valid | epoch 942 | valid on 'valid' subset | loss 13.681 | nll_loss 13.013 | ppl 8265.42 | wps 48200 | wpb 510.9 | bsz 1 | num_updates 45823 | best_loss 9.157
2022-03-07 23:50:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 942 @ 45823 updates
2022-03-07 23:50:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:50:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:50:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 942 @ 45823 updates, score 13.681) (writing took 2.2872137539088726 seconds)
2022-03-07 23:50:15 | INFO | fairseq_cli.train | end of epoch 942 (average epoch stats below)
2022-03-07 23:50:15 | INFO | train | epoch 942 | loss 2.427 | nll_loss 0.312 | ppl 1.24 | wps 24732.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45823 | lr 0.000147726 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 125259
2022-03-07 23:50:15 | INFO | fairseq.trainer | begin training epoch 943
2022-03-07 23:50:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:52:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:52:18 | INFO | valid | epoch 943 | valid on 'valid' subset | loss 13.632 | nll_loss 12.952 | ppl 7921.9 | wps 47451.9 | wpb 510.9 | bsz 1 | num_updates 45872 | best_loss 9.157
2022-03-07 23:52:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 943 @ 45872 updates
2022-03-07 23:52:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:52:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:52:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 943 @ 45872 updates, score 13.632) (writing took 2.2667460618540645 seconds)
2022-03-07 23:52:21 | INFO | fairseq_cli.train | end of epoch 943 (average epoch stats below)
2022-03-07 23:52:21 | INFO | train | epoch 943 | loss 2.426 | nll_loss 0.311 | ppl 1.24 | wps 25226.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45872 | lr 0.000147648 | gnorm 0.349 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 125385
2022-03-07 23:52:21 | INFO | fairseq.trainer | begin training epoch 944
2022-03-07 23:52:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:53:29 | INFO | train_inner | epoch 944:     28 / 49 loss=2.427, nll_loss=0.311, ppl=1.24, wps=25257.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=45900, lr=0.000147602, gnorm=0.352, loss_scale=32, train_wall=219, gb_free=8.8, wall=125454
2022-03-07 23:54:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:54:24 | INFO | valid | epoch 944 | valid on 'valid' subset | loss 13.707 | nll_loss 13.036 | ppl 8400.22 | wps 46770.7 | wpb 510.9 | bsz 1 | num_updates 45921 | best_loss 9.157
2022-03-07 23:54:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 944 @ 45921 updates
2022-03-07 23:54:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:54:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:54:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 944 @ 45921 updates, score 13.707) (writing took 2.282650132663548 seconds)
2022-03-07 23:54:27 | INFO | fairseq_cli.train | end of epoch 944 (average epoch stats below)
2022-03-07 23:54:27 | INFO | train | epoch 944 | loss 2.426 | nll_loss 0.311 | ppl 1.24 | wps 25258.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45921 | lr 0.000147569 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 125511
2022-03-07 23:54:27 | INFO | fairseq.trainer | begin training epoch 945
2022-03-07 23:54:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:55:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:56:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:56:30 | INFO | valid | epoch 945 | valid on 'valid' subset | loss 13.623 | nll_loss 12.944 | ppl 7882.03 | wps 46732.7 | wpb 510.9 | bsz 1 | num_updates 45969 | best_loss 9.157
2022-03-07 23:56:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 945 @ 45969 updates
2022-03-07 23:56:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:56:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:56:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 945 @ 45969 updates, score 13.623) (writing took 2.3337685470469296 seconds)
2022-03-07 23:56:33 | INFO | fairseq_cli.train | end of epoch 945 (average epoch stats below)
2022-03-07 23:56:33 | INFO | train | epoch 945 | loss 2.426 | nll_loss 0.311 | ppl 1.24 | wps 24699.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45969 | lr 0.000147492 | gnorm 0.352 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 125637
2022-03-07 23:56:33 | INFO | fairseq.trainer | begin training epoch 946
2022-03-07 23:56:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:57:48 | INFO | train_inner | epoch 946:     31 / 49 loss=2.426, nll_loss=0.311, ppl=1.24, wps=25038.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46000, lr=0.000147442, gnorm=0.354, loss_scale=32, train_wall=221, gb_free=8.8, wall=125713
2022-03-07 23:58:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:58:36 | INFO | valid | epoch 946 | valid on 'valid' subset | loss 13.733 | nll_loss 13.067 | ppl 8584.38 | wps 48146.6 | wpb 510.9 | bsz 1 | num_updates 46018 | best_loss 9.157
2022-03-07 23:58:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 946 @ 46018 updates
2022-03-07 23:58:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:58:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:58:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 946 @ 46018 updates, score 13.733) (writing took 2.2884442936629057 seconds)
2022-03-07 23:58:38 | INFO | fairseq_cli.train | end of epoch 946 (average epoch stats below)
2022-03-07 23:58:38 | INFO | train | epoch 946 | loss 2.426 | nll_loss 0.311 | ppl 1.24 | wps 25282.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46018 | lr 0.000147413 | gnorm 0.357 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 125763
2022-03-07 23:58:38 | INFO | fairseq.trainer | begin training epoch 947
2022-03-07 23:58:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:00:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:00:42 | INFO | valid | epoch 947 | valid on 'valid' subset | loss 13.64 | nll_loss 12.97 | ppl 8021.39 | wps 48253.2 | wpb 510.9 | bsz 1 | num_updates 46067 | best_loss 9.157
2022-03-08 00:00:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 947 @ 46067 updates
2022-03-08 00:00:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:00:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:00:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 947 @ 46067 updates, score 13.64) (writing took 2.249587152618915 seconds)
2022-03-08 00:00:44 | INFO | fairseq_cli.train | end of epoch 947 (average epoch stats below)
2022-03-08 00:00:44 | INFO | train | epoch 947 | loss 2.426 | nll_loss 0.311 | ppl 1.24 | wps 25263.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46067 | lr 0.000147335 | gnorm 0.356 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 125889
2022-03-08 00:00:44 | INFO | fairseq.trainer | begin training epoch 948
2022-03-08 00:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:00:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:02:08 | INFO | train_inner | epoch 948:     34 / 49 loss=2.426, nll_loss=0.311, ppl=1.24, wps=25039.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46100, lr=0.000147282, gnorm=0.354, loss_scale=32, train_wall=221, gb_free=8.8, wall=125972
2022-03-08 00:02:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:02:48 | INFO | valid | epoch 948 | valid on 'valid' subset | loss 13.682 | nll_loss 13.011 | ppl 8254.75 | wps 46470.7 | wpb 510.9 | bsz 1 | num_updates 46115 | best_loss 9.157
2022-03-08 00:02:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 948 @ 46115 updates
2022-03-08 00:02:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:02:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:02:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 948 @ 46115 updates, score 13.682) (writing took 2.3619008027017117 seconds)
2022-03-08 00:02:50 | INFO | fairseq_cli.train | end of epoch 948 (average epoch stats below)
2022-03-08 00:02:50 | INFO | train | epoch 948 | loss 2.425 | nll_loss 0.31 | ppl 1.24 | wps 24656.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46115 | lr 0.000147258 | gnorm 0.35 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 126015
2022-03-08 00:02:50 | INFO | fairseq.trainer | begin training epoch 949
2022-03-08 00:02:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:04:54 | INFO | valid | epoch 949 | valid on 'valid' subset | loss 13.618 | nll_loss 12.94 | ppl 7858.68 | wps 48157 | wpb 510.9 | bsz 1 | num_updates 46164 | best_loss 9.157
2022-03-08 00:04:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 949 @ 46164 updates
2022-03-08 00:04:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:04:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:04:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 949 @ 46164 updates, score 13.618) (writing took 2.3210517480038106 seconds)
2022-03-08 00:04:56 | INFO | fairseq_cli.train | end of epoch 949 (average epoch stats below)
2022-03-08 00:04:56 | INFO | train | epoch 949 | loss 2.425 | nll_loss 0.311 | ppl 1.24 | wps 25281.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46164 | lr 0.00014718 | gnorm 0.349 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 126141
2022-03-08 00:04:56 | INFO | fairseq.trainer | begin training epoch 950
2022-03-08 00:04:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:06:25 | INFO | train_inner | epoch 950:     36 / 49 loss=2.426, nll_loss=0.311, ppl=1.24, wps=25240.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46200, lr=0.000147122, gnorm=0.349, loss_scale=64, train_wall=219, gb_free=8.8, wall=126229
2022-03-08 00:06:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:06:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:07:00 | INFO | valid | epoch 950 | valid on 'valid' subset | loss 13.638 | nll_loss 12.964 | ppl 7988.04 | wps 48186.1 | wpb 510.9 | bsz 1 | num_updates 46212 | best_loss 9.157
2022-03-08 00:07:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 950 @ 46212 updates
2022-03-08 00:07:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:07:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:07:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 950 @ 46212 updates, score 13.638) (writing took 2.24824081081897 seconds)
2022-03-08 00:07:02 | INFO | fairseq_cli.train | end of epoch 950 (average epoch stats below)
2022-03-08 00:07:02 | INFO | train | epoch 950 | loss 2.426 | nll_loss 0.311 | ppl 1.24 | wps 24705 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46212 | lr 0.000147103 | gnorm 0.351 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 126267
2022-03-08 00:07:02 | INFO | fairseq.trainer | begin training epoch 951
2022-03-08 00:07:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:09:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:09:06 | INFO | valid | epoch 951 | valid on 'valid' subset | loss 13.64 | nll_loss 12.962 | ppl 7977.3 | wps 48160 | wpb 510.9 | bsz 1 | num_updates 46261 | best_loss 9.157
2022-03-08 00:09:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 951 @ 46261 updates
2022-03-08 00:09:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:09:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:09:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 951 @ 46261 updates, score 13.64) (writing took 2.2833732636645436 seconds)
2022-03-08 00:09:08 | INFO | fairseq_cli.train | end of epoch 951 (average epoch stats below)
2022-03-08 00:09:08 | INFO | train | epoch 951 | loss 2.426 | nll_loss 0.311 | ppl 1.24 | wps 25236.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46261 | lr 0.000147025 | gnorm 0.358 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 126393
2022-03-08 00:09:08 | INFO | fairseq.trainer | begin training epoch 952
2022-03-08 00:09:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:10:44 | INFO | train_inner | epoch 952:     39 / 49 loss=2.426, nll_loss=0.311, ppl=1.24, wps=25039.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46300, lr=0.000146964, gnorm=0.353, loss_scale=32, train_wall=221, gb_free=8.8, wall=126488
2022-03-08 00:11:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:11:12 | INFO | valid | epoch 952 | valid on 'valid' subset | loss 13.681 | nll_loss 13.011 | ppl 8252.54 | wps 46196.1 | wpb 510.9 | bsz 1 | num_updates 46310 | best_loss 9.157
2022-03-08 00:11:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 952 @ 46310 updates
2022-03-08 00:11:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:11:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:11:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 952 @ 46310 updates, score 13.681) (writing took 2.2832846702076495 seconds)
2022-03-08 00:11:14 | INFO | fairseq_cli.train | end of epoch 952 (average epoch stats below)
2022-03-08 00:11:14 | INFO | train | epoch 952 | loss 2.425 | nll_loss 0.31 | ppl 1.24 | wps 25217.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46310 | lr 0.000146948 | gnorm 0.347 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 126519
2022-03-08 00:11:14 | INFO | fairseq.trainer | begin training epoch 953
2022-03-08 00:11:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:13:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:13:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:13:17 | INFO | valid | epoch 953 | valid on 'valid' subset | loss 13.704 | nll_loss 13.034 | ppl 8388.2 | wps 48136.6 | wpb 510.9 | bsz 1 | num_updates 46358 | best_loss 9.157
2022-03-08 00:13:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 953 @ 46358 updates
2022-03-08 00:13:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:13:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:13:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 953 @ 46358 updates, score 13.704) (writing took 2.3362382599152625 seconds)
2022-03-08 00:13:20 | INFO | fairseq_cli.train | end of epoch 953 (average epoch stats below)
2022-03-08 00:13:20 | INFO | train | epoch 953 | loss 2.425 | nll_loss 0.311 | ppl 1.24 | wps 24737.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46358 | lr 0.000146872 | gnorm 0.351 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 126644
2022-03-08 00:13:20 | INFO | fairseq.trainer | begin training epoch 954
2022-03-08 00:13:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:15:03 | INFO | train_inner | epoch 954:     42 / 49 loss=2.425, nll_loss=0.31, ppl=1.24, wps=25035.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46400, lr=0.000146805, gnorm=0.35, loss_scale=32, train_wall=221, gb_free=8.8, wall=126748
2022-03-08 00:15:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:15:23 | INFO | valid | epoch 954 | valid on 'valid' subset | loss 13.59 | nll_loss 12.908 | ppl 7687.87 | wps 48108.3 | wpb 510.9 | bsz 1 | num_updates 46407 | best_loss 9.157
2022-03-08 00:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 954 @ 46407 updates
2022-03-08 00:15:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:15:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:15:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 954 @ 46407 updates, score 13.59) (writing took 2.294600514229387 seconds)
2022-03-08 00:15:26 | INFO | fairseq_cli.train | end of epoch 954 (average epoch stats below)
2022-03-08 00:15:26 | INFO | train | epoch 954 | loss 2.425 | nll_loss 0.31 | ppl 1.24 | wps 25264.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46407 | lr 0.000146794 | gnorm 0.35 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 126770
2022-03-08 00:15:26 | INFO | fairseq.trainer | begin training epoch 955
2022-03-08 00:15:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:17:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:17:29 | INFO | valid | epoch 955 | valid on 'valid' subset | loss 13.672 | nll_loss 13.001 | ppl 8198.83 | wps 47777.9 | wpb 510.9 | bsz 1 | num_updates 46456 | best_loss 9.157
2022-03-08 00:17:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 955 @ 46456 updates
2022-03-08 00:17:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:17:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:17:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 955 @ 46456 updates, score 13.672) (writing took 2.263469143770635 seconds)
2022-03-08 00:17:31 | INFO | fairseq_cli.train | end of epoch 955 (average epoch stats below)
2022-03-08 00:17:31 | INFO | train | epoch 955 | loss 2.425 | nll_loss 0.31 | ppl 1.24 | wps 25238 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46456 | lr 0.000146717 | gnorm 0.349 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 126896
2022-03-08 00:17:31 | INFO | fairseq.trainer | begin training epoch 956
2022-03-08 00:17:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:18:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:19:22 | INFO | train_inner | epoch 956:     45 / 49 loss=2.425, nll_loss=0.31, ppl=1.24, wps=25034.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46500, lr=0.000146647, gnorm=0.35, loss_scale=32, train_wall=221, gb_free=8.8, wall=127007
2022-03-08 00:19:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:19:35 | INFO | valid | epoch 956 | valid on 'valid' subset | loss 13.668 | nll_loss 12.997 | ppl 8172.71 | wps 45259.8 | wpb 510.9 | bsz 1 | num_updates 46504 | best_loss 9.157
2022-03-08 00:19:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 956 @ 46504 updates
2022-03-08 00:19:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:19:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:19:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 956 @ 46504 updates, score 13.668) (writing took 2.3977439058944583 seconds)
2022-03-08 00:19:38 | INFO | fairseq_cli.train | end of epoch 956 (average epoch stats below)
2022-03-08 00:19:38 | INFO | train | epoch 956 | loss 2.424 | nll_loss 0.31 | ppl 1.24 | wps 24641.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46504 | lr 0.000146641 | gnorm 0.35 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127023
2022-03-08 00:19:38 | INFO | fairseq.trainer | begin training epoch 957
2022-03-08 00:19:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:21:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:21:42 | INFO | valid | epoch 957 | valid on 'valid' subset | loss 13.651 | nll_loss 12.979 | ppl 8072.57 | wps 48132.5 | wpb 510.9 | bsz 1 | num_updates 46553 | best_loss 9.157
2022-03-08 00:21:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 957 @ 46553 updates
2022-03-08 00:21:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:21:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:21:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 957 @ 46553 updates, score 13.651) (writing took 2.3207263578660786 seconds)
2022-03-08 00:21:44 | INFO | fairseq_cli.train | end of epoch 957 (average epoch stats below)
2022-03-08 00:21:44 | INFO | train | epoch 957 | loss 2.425 | nll_loss 0.31 | ppl 1.24 | wps 25195.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46553 | lr 0.000146564 | gnorm 0.35 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127149
2022-03-08 00:21:44 | INFO | fairseq.trainer | begin training epoch 958
2022-03-08 00:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:23:39 | INFO | train_inner | epoch 958:     47 / 49 loss=2.425, nll_loss=0.31, ppl=1.24, wps=25215, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46600, lr=0.00014649, gnorm=0.349, loss_scale=32, train_wall=219, gb_free=8.8, wall=127264
2022-03-08 00:23:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:23:47 | INFO | valid | epoch 958 | valid on 'valid' subset | loss 13.606 | nll_loss 12.929 | ppl 7799.21 | wps 48072.1 | wpb 510.9 | bsz 1 | num_updates 46602 | best_loss 9.157
2022-03-08 00:23:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 958 @ 46602 updates
2022-03-08 00:23:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:23:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:23:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 958 @ 46602 updates, score 13.606) (writing took 2.2608789382502437 seconds)
2022-03-08 00:23:50 | INFO | fairseq_cli.train | end of epoch 958 (average epoch stats below)
2022-03-08 00:23:50 | INFO | train | epoch 958 | loss 2.424 | nll_loss 0.309 | ppl 1.24 | wps 25268 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46602 | lr 0.000146487 | gnorm 0.348 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127274
2022-03-08 00:23:50 | INFO | fairseq.trainer | begin training epoch 959
2022-03-08 00:23:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:24:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:25:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:25:53 | INFO | valid | epoch 959 | valid on 'valid' subset | loss 13.615 | nll_loss 12.938 | ppl 7848.16 | wps 48267.1 | wpb 510.9 | bsz 1 | num_updates 46650 | best_loss 9.157
2022-03-08 00:25:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 959 @ 46650 updates
2022-03-08 00:25:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:25:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:25:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 959 @ 46650 updates, score 13.615) (writing took 2.286394632887095 seconds)
2022-03-08 00:25:55 | INFO | fairseq_cli.train | end of epoch 959 (average epoch stats below)
2022-03-08 00:25:55 | INFO | train | epoch 959 | loss 2.424 | nll_loss 0.31 | ppl 1.24 | wps 24746.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46650 | lr 0.000146411 | gnorm 0.348 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127400
2022-03-08 00:25:55 | INFO | fairseq.trainer | begin training epoch 960
2022-03-08 00:25:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:27:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:27:59 | INFO | valid | epoch 960 | valid on 'valid' subset | loss 13.692 | nll_loss 13.021 | ppl 8312.03 | wps 45713.1 | wpb 510.9 | bsz 1 | num_updates 46699 | best_loss 9.157
2022-03-08 00:27:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 960 @ 46699 updates
2022-03-08 00:27:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:28:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:28:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 960 @ 46699 updates, score 13.692) (writing took 2.4286511647515 seconds)
2022-03-08 00:28:02 | INFO | fairseq_cli.train | end of epoch 960 (average epoch stats below)
2022-03-08 00:28:02 | INFO | train | epoch 960 | loss 2.425 | nll_loss 0.31 | ppl 1.24 | wps 25142.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46699 | lr 0.000146334 | gnorm 0.352 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127527
2022-03-08 00:28:02 | INFO | fairseq.trainer | begin training epoch 961
2022-03-08 00:28:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:28:04 | INFO | train_inner | epoch 961:      1 / 49 loss=2.425, nll_loss=0.31, ppl=1.24, wps=24331, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=46700, lr=0.000146333, gnorm=0.351, loss_scale=32, train_wall=220, gb_free=8.8, wall=127529
2022-03-08 00:30:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:30:06 | INFO | valid | epoch 961 | valid on 'valid' subset | loss 13.602 | nll_loss 12.922 | ppl 7758.79 | wps 48109.4 | wpb 510.9 | bsz 1 | num_updates 46748 | best_loss 9.157
2022-03-08 00:30:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 961 @ 46748 updates
2022-03-08 00:30:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:30:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:30:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 961 @ 46748 updates, score 13.602) (writing took 2.339350138325244 seconds)
2022-03-08 00:30:08 | INFO | fairseq_cli.train | end of epoch 961 (average epoch stats below)
2022-03-08 00:30:08 | INFO | train | epoch 961 | loss 2.424 | nll_loss 0.309 | ppl 1.24 | wps 25219.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46748 | lr 0.000146258 | gnorm 0.347 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 127653
2022-03-08 00:30:08 | INFO | fairseq.trainer | begin training epoch 962
2022-03-08 00:30:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:30:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:32:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:32:12 | INFO | valid | epoch 962 | valid on 'valid' subset | loss 13.686 | nll_loss 13.019 | ppl 8299.85 | wps 48181.3 | wpb 510.9 | bsz 1 | num_updates 46796 | best_loss 9.157
2022-03-08 00:32:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 962 @ 46796 updates
2022-03-08 00:32:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:32:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:32:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 962 @ 46796 updates, score 13.686) (writing took 2.2868568268604577 seconds)
2022-03-08 00:32:14 | INFO | fairseq_cli.train | end of epoch 962 (average epoch stats below)
2022-03-08 00:32:14 | INFO | train | epoch 962 | loss 2.424 | nll_loss 0.31 | ppl 1.24 | wps 24706.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46796 | lr 0.000146183 | gnorm 0.354 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127779
2022-03-08 00:32:14 | INFO | fairseq.trainer | begin training epoch 963
2022-03-08 00:32:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:32:24 | INFO | train_inner | epoch 963:      4 / 49 loss=2.424, nll_loss=0.309, ppl=1.24, wps=25008.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46800, lr=0.000146176, gnorm=0.35, loss_scale=32, train_wall=221, gb_free=8.8, wall=127789
2022-03-08 00:34:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:34:18 | INFO | valid | epoch 963 | valid on 'valid' subset | loss 13.542 | nll_loss 12.861 | ppl 7437.73 | wps 47927.8 | wpb 510.9 | bsz 1 | num_updates 46845 | best_loss 9.157
2022-03-08 00:34:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 963 @ 46845 updates
2022-03-08 00:34:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:34:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:34:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 963 @ 46845 updates, score 13.542) (writing took 2.2710275687277317 seconds)
2022-03-08 00:34:20 | INFO | fairseq_cli.train | end of epoch 963 (average epoch stats below)
2022-03-08 00:34:20 | INFO | train | epoch 963 | loss 2.424 | nll_loss 0.31 | ppl 1.24 | wps 25236.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46845 | lr 0.000146106 | gnorm 0.353 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127905
2022-03-08 00:34:20 | INFO | fairseq.trainer | begin training epoch 964
2022-03-08 00:34:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:35:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:36:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:36:24 | INFO | valid | epoch 964 | valid on 'valid' subset | loss 13.704 | nll_loss 13.04 | ppl 8425.22 | wps 46277 | wpb 510.9 | bsz 1 | num_updates 46893 | best_loss 9.157
2022-03-08 00:36:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 964 @ 46893 updates
2022-03-08 00:36:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:36:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:36:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 964 @ 46893 updates, score 13.704) (writing took 4.049759939778596 seconds)
2022-03-08 00:36:28 | INFO | fairseq_cli.train | end of epoch 964 (average epoch stats below)
2022-03-08 00:36:28 | INFO | train | epoch 964 | loss 2.424 | nll_loss 0.31 | ppl 1.24 | wps 24327 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46893 | lr 0.000146031 | gnorm 0.354 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 128032
2022-03-08 00:36:28 | INFO | fairseq.trainer | begin training epoch 965
2022-03-08 00:36:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:36:45 | INFO | train_inner | epoch 965:      7 / 49 loss=2.424, nll_loss=0.31, ppl=1.24, wps=24839.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=46900, lr=0.00014602, gnorm=0.353, loss_scale=32, train_wall=221, gb_free=8.8, wall=128050
2022-03-08 00:38:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:38:31 | INFO | valid | epoch 965 | valid on 'valid' subset | loss 13.661 | nll_loss 12.989 | ppl 8128.29 | wps 48163.5 | wpb 510.9 | bsz 1 | num_updates 46942 | best_loss 9.157
2022-03-08 00:38:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 965 @ 46942 updates
2022-03-08 00:38:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:38:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:38:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 965 @ 46942 updates, score 13.661) (writing took 2.346555904019624 seconds)
2022-03-08 00:38:34 | INFO | fairseq_cli.train | end of epoch 965 (average epoch stats below)
2022-03-08 00:38:34 | INFO | train | epoch 965 | loss 2.424 | nll_loss 0.309 | ppl 1.24 | wps 25201.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46942 | lr 0.000145955 | gnorm 0.346 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 128159
2022-03-08 00:38:34 | INFO | fairseq.trainer | begin training epoch 966
2022-03-08 00:38:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:40:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:40:38 | INFO | valid | epoch 966 | valid on 'valid' subset | loss 13.701 | nll_loss 13.035 | ppl 8394.96 | wps 47944.6 | wpb 510.9 | bsz 1 | num_updates 46991 | best_loss 9.157
2022-03-08 00:40:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 966 @ 46991 updates
2022-03-08 00:40:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:40:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:40:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 966 @ 46991 updates, score 13.701) (writing took 2.2902695583179593 seconds)
2022-03-08 00:40:40 | INFO | fairseq_cli.train | end of epoch 966 (average epoch stats below)
2022-03-08 00:40:40 | INFO | train | epoch 966 | loss 2.424 | nll_loss 0.309 | ppl 1.24 | wps 25186.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46991 | lr 0.000145879 | gnorm 0.352 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 128285
2022-03-08 00:40:40 | INFO | fairseq.trainer | begin training epoch 967
2022-03-08 00:40:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:41:02 | INFO | train_inner | epoch 967:      9 / 49 loss=2.424, nll_loss=0.309, ppl=1.24, wps=25231.1, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=47000, lr=0.000145865, gnorm=0.349, loss_scale=32, train_wall=219, gb_free=8.8, wall=128307
2022-03-08 00:41:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:42:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:42:44 | INFO | valid | epoch 967 | valid on 'valid' subset | loss 13.634 | nll_loss 12.958 | ppl 7955.14 | wps 48212.8 | wpb 510.9 | bsz 1 | num_updates 47039 | best_loss 9.157
2022-03-08 00:42:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 967 @ 47039 updates
2022-03-08 00:42:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:42:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:42:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 967 @ 47039 updates, score 13.634) (writing took 2.258461542893201 seconds)
2022-03-08 00:42:46 | INFO | fairseq_cli.train | end of epoch 967 (average epoch stats below)
2022-03-08 00:42:46 | INFO | train | epoch 967 | loss 2.423 | nll_loss 0.309 | ppl 1.24 | wps 24681.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47039 | lr 0.000145805 | gnorm 0.347 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 128411
2022-03-08 00:42:46 | INFO | fairseq.trainer | begin training epoch 968
2022-03-08 00:42:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:44:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:44:51 | INFO | valid | epoch 968 | valid on 'valid' subset | loss 13.564 | nll_loss 12.884 | ppl 7557.62 | wps 45930.1 | wpb 510.9 | bsz 1 | num_updates 47088 | best_loss 9.157
2022-03-08 00:44:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 968 @ 47088 updates
2022-03-08 00:44:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:44:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:44:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 968 @ 47088 updates, score 13.564) (writing took 2.4577659922651947 seconds)
2022-03-08 00:44:54 | INFO | fairseq_cli.train | end of epoch 968 (average epoch stats below)
2022-03-08 00:44:54 | INFO | train | epoch 968 | loss 2.423 | nll_loss 0.309 | ppl 1.24 | wps 24931.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47088 | lr 0.000145729 | gnorm 0.351 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 128538
2022-03-08 00:44:54 | INFO | fairseq.trainer | begin training epoch 969
2022-03-08 00:44:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:45:24 | INFO | train_inner | epoch 969:     12 / 49 loss=2.423, nll_loss=0.309, ppl=1.24, wps=24815.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=47100, lr=0.00014571, gnorm=0.349, loss_scale=32, train_wall=223, gb_free=8.8, wall=128568
2022-03-08 00:46:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:46:58 | INFO | valid | epoch 969 | valid on 'valid' subset | loss 13.599 | nll_loss 12.918 | ppl 7741.65 | wps 48114.4 | wpb 510.9 | bsz 1 | num_updates 47137 | best_loss 9.157
2022-03-08 00:46:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 969 @ 47137 updates
2022-03-08 00:46:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:47:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:47:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 969 @ 47137 updates, score 13.599) (writing took 2.2795199691317976 seconds)
2022-03-08 00:47:00 | INFO | fairseq_cli.train | end of epoch 969 (average epoch stats below)
2022-03-08 00:47:00 | INFO | train | epoch 969 | loss 2.424 | nll_loss 0.309 | ppl 1.24 | wps 25115.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47137 | lr 0.000145653 | gnorm 0.353 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 128665
2022-03-08 00:47:00 | INFO | fairseq.trainer | begin training epoch 970
2022-03-08 00:47:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:47:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:49:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:49:05 | INFO | valid | epoch 970 | valid on 'valid' subset | loss 13.584 | nll_loss 12.903 | ppl 7659.06 | wps 46336.1 | wpb 510.9 | bsz 1 | num_updates 47185 | best_loss 9.157
2022-03-08 00:49:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 970 @ 47185 updates
2022-03-08 00:49:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:49:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:49:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 970 @ 47185 updates, score 13.584) (writing took 2.291687859222293 seconds)
2022-03-08 00:49:07 | INFO | fairseq_cli.train | end of epoch 970 (average epoch stats below)
2022-03-08 00:49:07 | INFO | train | epoch 970 | loss 2.423 | nll_loss 0.309 | ppl 1.24 | wps 24563.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47185 | lr 0.000145579 | gnorm 0.35 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 128792
2022-03-08 00:49:07 | INFO | fairseq.trainer | begin training epoch 971
2022-03-08 00:49:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:49:44 | INFO | train_inner | epoch 971:     15 / 49 loss=2.423, nll_loss=0.309, ppl=1.24, wps=24893.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=47200, lr=0.000145556, gnorm=0.351, loss_scale=32, train_wall=222, gb_free=8.8, wall=128829
2022-03-08 00:51:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:51:11 | INFO | valid | epoch 971 | valid on 'valid' subset | loss 13.677 | nll_loss 13.006 | ppl 8227.41 | wps 47469 | wpb 510.9 | bsz 1 | num_updates 47234 | best_loss 9.157
2022-03-08 00:51:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 971 @ 47234 updates
2022-03-08 00:51:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:51:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:51:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 971 @ 47234 updates, score 13.677) (writing took 2.6896126568317413 seconds)
2022-03-08 00:51:14 | INFO | fairseq_cli.train | end of epoch 971 (average epoch stats below)
2022-03-08 00:51:14 | INFO | train | epoch 971 | loss 2.423 | nll_loss 0.309 | ppl 1.24 | wps 25015.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47234 | lr 0.000145503 | gnorm 0.354 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 128919
2022-03-08 00:51:14 | INFO | fairseq.trainer | begin training epoch 972
2022-03-08 00:51:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:52:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:53:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:53:19 | INFO | valid | epoch 972 | valid on 'valid' subset | loss 13.606 | nll_loss 12.926 | ppl 7782 | wps 46725.5 | wpb 510.9 | bsz 1 | num_updates 47282 | best_loss 9.157
2022-03-08 00:53:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 972 @ 47282 updates
2022-03-08 00:53:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:53:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:53:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 972 @ 47282 updates, score 13.606) (writing took 2.471161815803498 seconds)
2022-03-08 00:53:21 | INFO | fairseq_cli.train | end of epoch 972 (average epoch stats below)
2022-03-08 00:53:21 | INFO | train | epoch 972 | loss 2.423 | nll_loss 0.309 | ppl 1.24 | wps 24410 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47282 | lr 0.000145429 | gnorm 0.349 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 129046
2022-03-08 00:53:21 | INFO | fairseq.trainer | begin training epoch 973
2022-03-08 00:53:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:54:06 | INFO | train_inner | epoch 973:     18 / 49 loss=2.423, nll_loss=0.309, ppl=1.24, wps=24799.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=47300, lr=0.000145402, gnorm=0.35, loss_scale=32, train_wall=223, gb_free=8.8, wall=129090
2022-03-08 00:55:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:55:25 | INFO | valid | epoch 973 | valid on 'valid' subset | loss 13.7 | nll_loss 13.031 | ppl 8371.51 | wps 47609.5 | wpb 510.9 | bsz 1 | num_updates 47331 | best_loss 9.157
2022-03-08 00:55:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 973 @ 47331 updates
2022-03-08 00:55:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:55:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:55:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 973 @ 47331 updates, score 13.7) (writing took 2.3141074180603027 seconds)
2022-03-08 00:55:27 | INFO | fairseq_cli.train | end of epoch 973 (average epoch stats below)
2022-03-08 00:55:27 | INFO | train | epoch 973 | loss 2.423 | nll_loss 0.309 | ppl 1.24 | wps 25206.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47331 | lr 0.000145354 | gnorm 0.349 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 129172
2022-03-08 00:55:27 | INFO | fairseq.trainer | begin training epoch 974
2022-03-08 00:55:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:57:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:57:31 | INFO | valid | epoch 974 | valid on 'valid' subset | loss 13.655 | nll_loss 12.978 | ppl 8067.06 | wps 48026.5 | wpb 510.9 | bsz 1 | num_updates 47380 | best_loss 9.157
2022-03-08 00:57:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 974 @ 47380 updates
2022-03-08 00:57:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:57:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:57:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 974 @ 47380 updates, score 13.655) (writing took 2.296990525908768 seconds)
2022-03-08 00:57:33 | INFO | fairseq_cli.train | end of epoch 974 (average epoch stats below)
2022-03-08 00:57:33 | INFO | train | epoch 974 | loss 2.423 | nll_loss 0.309 | ppl 1.24 | wps 25229.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47380 | lr 0.000145279 | gnorm 0.349 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 129298
2022-03-08 00:57:33 | INFO | fairseq.trainer | begin training epoch 975
2022-03-08 00:57:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:58:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:58:25 | INFO | train_inner | epoch 975:     21 / 49 loss=2.423, nll_loss=0.309, ppl=1.24, wps=25015.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=47400, lr=0.000145248, gnorm=0.35, loss_scale=32, train_wall=221, gb_free=8.8, wall=129350
2022-03-08 00:59:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:59:37 | INFO | valid | epoch 975 | valid on 'valid' subset | loss 13.695 | nll_loss 13.022 | ppl 8320.65 | wps 48192.8 | wpb 510.9 | bsz 1 | num_updates 47428 | best_loss 9.157
2022-03-08 00:59:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 975 @ 47428 updates
2022-03-08 00:59:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:59:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:59:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 975 @ 47428 updates, score 13.695) (writing took 2.245310055091977 seconds)
2022-03-08 00:59:39 | INFO | fairseq_cli.train | end of epoch 975 (average epoch stats below)
2022-03-08 00:59:39 | INFO | train | epoch 975 | loss 2.422 | nll_loss 0.308 | ppl 1.24 | wps 24742.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47428 | lr 0.000145205 | gnorm 0.348 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 129424
2022-03-08 00:59:39 | INFO | fairseq.trainer | begin training epoch 976
2022-03-08 00:59:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:01:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:01:43 | INFO | valid | epoch 976 | valid on 'valid' subset | loss 13.733 | nll_loss 13.072 | ppl 8608.52 | wps 47540.6 | wpb 510.9 | bsz 1 | num_updates 47477 | best_loss 9.157
2022-03-08 01:01:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 976 @ 47477 updates
2022-03-08 01:01:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:01:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:01:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 976 @ 47477 updates, score 13.733) (writing took 2.3883350817486644 seconds)
2022-03-08 01:01:46 | INFO | fairseq_cli.train | end of epoch 976 (average epoch stats below)
2022-03-08 01:01:46 | INFO | train | epoch 976 | loss 2.422 | nll_loss 0.308 | ppl 1.24 | wps 25169.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47477 | lr 0.00014513 | gnorm 0.35 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 129550
2022-03-08 01:01:46 | INFO | fairseq.trainer | begin training epoch 977
2022-03-08 01:01:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:02:42 | INFO | train_inner | epoch 977:     23 / 49 loss=2.422, nll_loss=0.308, ppl=1.24, wps=25253.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=47500, lr=0.000145095, gnorm=0.349, loss_scale=32, train_wall=219, gb_free=8.8, wall=129607
2022-03-08 01:03:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:03:49 | INFO | valid | epoch 977 | valid on 'valid' subset | loss 13.679 | nll_loss 13.009 | ppl 8243.47 | wps 48168.2 | wpb 510.9 | bsz 1 | num_updates 47526 | best_loss 9.157
2022-03-08 01:03:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 977 @ 47526 updates
2022-03-08 01:03:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:03:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:03:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 977 @ 47526 updates, score 13.679) (writing took 2.258596254978329 seconds)
2022-03-08 01:03:51 | INFO | fairseq_cli.train | end of epoch 977 (average epoch stats below)
2022-03-08 01:03:51 | INFO | train | epoch 977 | loss 2.422 | nll_loss 0.308 | ppl 1.24 | wps 25246.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47526 | lr 0.000145056 | gnorm 0.352 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 129676
2022-03-08 01:03:51 | INFO | fairseq.trainer | begin training epoch 978
2022-03-08 01:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:04:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:05:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:05:55 | INFO | valid | epoch 978 | valid on 'valid' subset | loss 13.636 | nll_loss 12.961 | ppl 7974.79 | wps 48000.5 | wpb 510.9 | bsz 1 | num_updates 47574 | best_loss 9.157
2022-03-08 01:05:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 978 @ 47574 updates
2022-03-08 01:05:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:05:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:05:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 978 @ 47574 updates, score 13.636) (writing took 2.2300984249450266 seconds)
2022-03-08 01:05:57 | INFO | fairseq_cli.train | end of epoch 978 (average epoch stats below)
2022-03-08 01:05:57 | INFO | train | epoch 978 | loss 2.422 | nll_loss 0.308 | ppl 1.24 | wps 24718.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47574 | lr 0.000144982 | gnorm 0.351 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 129802
2022-03-08 01:05:57 | INFO | fairseq.trainer | begin training epoch 979
2022-03-08 01:05:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:07:01 | INFO | train_inner | epoch 979:     26 / 49 loss=2.422, nll_loss=0.308, ppl=1.24, wps=25022.1, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=47600, lr=0.000144943, gnorm=0.348, loss_scale=32, train_wall=221, gb_free=8.8, wall=129866
2022-03-08 01:07:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:08:01 | INFO | valid | epoch 979 | valid on 'valid' subset | loss 13.653 | nll_loss 12.981 | ppl 8085.17 | wps 48364.9 | wpb 510.9 | bsz 1 | num_updates 47623 | best_loss 9.157
2022-03-08 01:08:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 979 @ 47623 updates
2022-03-08 01:08:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:08:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:08:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 979 @ 47623 updates, score 13.653) (writing took 2.268028472084552 seconds)
2022-03-08 01:08:03 | INFO | fairseq_cli.train | end of epoch 979 (average epoch stats below)
2022-03-08 01:08:03 | INFO | train | epoch 979 | loss 2.422 | nll_loss 0.308 | ppl 1.24 | wps 25262.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47623 | lr 0.000144908 | gnorm 0.346 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 129928
2022-03-08 01:08:03 | INFO | fairseq.trainer | begin training epoch 980
2022-03-08 01:08:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:10:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:10:07 | INFO | valid | epoch 980 | valid on 'valid' subset | loss 13.601 | nll_loss 12.922 | ppl 7762.32 | wps 47670.1 | wpb 510.9 | bsz 1 | num_updates 47672 | best_loss 9.157
2022-03-08 01:10:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 980 @ 47672 updates
2022-03-08 01:10:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:10:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:10:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 980 @ 47672 updates, score 13.601) (writing took 2.4427980668842793 seconds)
2022-03-08 01:10:09 | INFO | fairseq_cli.train | end of epoch 980 (average epoch stats below)
2022-03-08 01:10:09 | INFO | train | epoch 980 | loss 2.422 | nll_loss 0.308 | ppl 1.24 | wps 25162.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47672 | lr 0.000144833 | gnorm 0.349 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 130054
2022-03-08 01:10:09 | INFO | fairseq.trainer | begin training epoch 981
2022-03-08 01:10:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:10:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:11:21 | INFO | train_inner | epoch 981:     29 / 49 loss=2.422, nll_loss=0.308, ppl=1.24, wps=24999.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=47700, lr=0.000144791, gnorm=0.349, loss_scale=32, train_wall=221, gb_free=8.8, wall=130125
2022-03-08 01:12:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:12:13 | INFO | valid | epoch 981 | valid on 'valid' subset | loss 13.775 | nll_loss 13.112 | ppl 8852.58 | wps 48179.2 | wpb 510.9 | bsz 1 | num_updates 47720 | best_loss 9.157
2022-03-08 01:12:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 981 @ 47720 updates
2022-03-08 01:12:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:12:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:12:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 981 @ 47720 updates, score 13.775) (writing took 2.2669982193037868 seconds)
2022-03-08 01:12:15 | INFO | fairseq_cli.train | end of epoch 981 (average epoch stats below)
2022-03-08 01:12:15 | INFO | train | epoch 981 | loss 2.422 | nll_loss 0.308 | ppl 1.24 | wps 24704.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47720 | lr 0.00014476 | gnorm 0.348 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 130180
2022-03-08 01:12:15 | INFO | fairseq.trainer | begin training epoch 982
2022-03-08 01:12:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:14:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:14:19 | INFO | valid | epoch 982 | valid on 'valid' subset | loss 13.549 | nll_loss 12.866 | ppl 7464.31 | wps 47495.9 | wpb 510.9 | bsz 1 | num_updates 47769 | best_loss 9.157
2022-03-08 01:14:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 982 @ 47769 updates
2022-03-08 01:14:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:14:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:14:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 982 @ 47769 updates, score 13.549) (writing took 2.309006413910538 seconds)
2022-03-08 01:14:21 | INFO | fairseq_cli.train | end of epoch 982 (average epoch stats below)
2022-03-08 01:14:21 | INFO | train | epoch 982 | loss 2.422 | nll_loss 0.308 | ppl 1.24 | wps 25212.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47769 | lr 0.000144686 | gnorm 0.35 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 130306
2022-03-08 01:14:21 | INFO | fairseq.trainer | begin training epoch 983
2022-03-08 01:14:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:15:38 | INFO | train_inner | epoch 983:     31 / 49 loss=2.422, nll_loss=0.308, ppl=1.24, wps=25186.6, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=47800, lr=0.000144639, gnorm=0.349, loss_scale=32, train_wall=220, gb_free=8.8, wall=130383
2022-03-08 01:15:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:16:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:16:26 | INFO | valid | epoch 983 | valid on 'valid' subset | loss 13.65 | nll_loss 12.972 | ppl 8033.91 | wps 47062.8 | wpb 510.9 | bsz 1 | num_updates 47817 | best_loss 9.157
2022-03-08 01:16:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 983 @ 47817 updates
2022-03-08 01:16:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:16:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:16:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 983 @ 47817 updates, score 13.65) (writing took 2.262957870028913 seconds)
2022-03-08 01:16:29 | INFO | fairseq_cli.train | end of epoch 983 (average epoch stats below)
2022-03-08 01:16:29 | INFO | train | epoch 983 | loss 2.422 | nll_loss 0.308 | ppl 1.24 | wps 24499.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47817 | lr 0.000144614 | gnorm 0.349 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 130433
2022-03-08 01:16:29 | INFO | fairseq.trainer | begin training epoch 984
2022-03-08 01:16:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:16:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:18:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:18:34 | INFO | valid | epoch 984 | valid on 'valid' subset | loss 13.646 | nll_loss 12.974 | ppl 8046.08 | wps 45967.7 | wpb 510.9 | bsz 1 | num_updates 47865 | best_loss 9.157
2022-03-08 01:18:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 984 @ 47865 updates
2022-03-08 01:18:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:18:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:18:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 984 @ 47865 updates, score 13.646) (writing took 2.397351431194693 seconds)
2022-03-08 01:18:37 | INFO | fairseq_cli.train | end of epoch 984 (average epoch stats below)
2022-03-08 01:18:37 | INFO | train | epoch 984 | loss 2.421 | nll_loss 0.307 | ppl 1.24 | wps 24308.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 47865 | lr 0.000144541 | gnorm 0.348 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 130561
2022-03-08 01:18:37 | INFO | fairseq.trainer | begin training epoch 985
2022-03-08 01:18:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:20:03 | INFO | train_inner | epoch 985:     35 / 49 loss=2.421, nll_loss=0.308, ppl=1.24, wps=24454.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=47900, lr=0.000144488, gnorm=0.347, loss_scale=16, train_wall=226, gb_free=8.8, wall=130648
2022-03-08 01:20:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:20:42 | INFO | valid | epoch 985 | valid on 'valid' subset | loss 13.653 | nll_loss 12.979 | ppl 8074.42 | wps 46660.7 | wpb 510.9 | bsz 1 | num_updates 47914 | best_loss 9.157
2022-03-08 01:20:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 985 @ 47914 updates
2022-03-08 01:20:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:20:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:20:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 985 @ 47914 updates, score 13.653) (writing took 2.3027684278786182 seconds)
2022-03-08 01:20:44 | INFO | fairseq_cli.train | end of epoch 985 (average epoch stats below)
2022-03-08 01:20:44 | INFO | train | epoch 985 | loss 2.422 | nll_loss 0.308 | ppl 1.24 | wps 24914.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47914 | lr 0.000144467 | gnorm 0.348 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 130689
2022-03-08 01:20:44 | INFO | fairseq.trainer | begin training epoch 986
2022-03-08 01:20:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:22:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:22:49 | INFO | valid | epoch 986 | valid on 'valid' subset | loss 13.662 | nll_loss 12.992 | ppl 8144.34 | wps 45614.6 | wpb 510.9 | bsz 1 | num_updates 47963 | best_loss 9.157
2022-03-08 01:22:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 986 @ 47963 updates
2022-03-08 01:22:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:22:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:22:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 986 @ 47963 updates, score 13.662) (writing took 2.278489268850535 seconds)
2022-03-08 01:22:52 | INFO | fairseq_cli.train | end of epoch 986 (average epoch stats below)
2022-03-08 01:22:52 | INFO | train | epoch 986 | loss 2.422 | nll_loss 0.308 | ppl 1.24 | wps 24915.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47963 | lr 0.000144393 | gnorm 0.348 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 130816
2022-03-08 01:22:52 | INFO | fairseq.trainer | begin training epoch 987
2022-03-08 01:22:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:24:24 | INFO | train_inner | epoch 987:     37 / 49 loss=2.422, nll_loss=0.308, ppl=1.24, wps=24937.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=48000, lr=0.000144338, gnorm=0.348, loss_scale=32, train_wall=222, gb_free=8.8, wall=130908
2022-03-08 01:24:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:24:57 | INFO | valid | epoch 987 | valid on 'valid' subset | loss 13.734 | nll_loss 13.071 | ppl 8602.42 | wps 47127 | wpb 510.9 | bsz 1 | num_updates 48012 | best_loss 9.157
2022-03-08 01:24:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 987 @ 48012 updates
2022-03-08 01:24:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:24:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:24:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 987 @ 48012 updates, score 13.734) (writing took 2.266368019860238 seconds)
2022-03-08 01:24:59 | INFO | fairseq_cli.train | end of epoch 987 (average epoch stats below)
2022-03-08 01:24:59 | INFO | train | epoch 987 | loss 2.421 | nll_loss 0.307 | ppl 1.24 | wps 24939.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48012 | lr 0.00014432 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 130944
2022-03-08 01:24:59 | INFO | fairseq.trainer | begin training epoch 988
2022-03-08 01:24:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:27:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:27:05 | INFO | valid | epoch 988 | valid on 'valid' subset | loss 13.617 | nll_loss 12.933 | ppl 7822.44 | wps 46025.4 | wpb 510.9 | bsz 1 | num_updates 48061 | best_loss 9.157
2022-03-08 01:27:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 988 @ 48061 updates
2022-03-08 01:27:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:27:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:27:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 988 @ 48061 updates, score 13.617) (writing took 2.426973804831505 seconds)
2022-03-08 01:27:07 | INFO | fairseq_cli.train | end of epoch 988 (average epoch stats below)
2022-03-08 01:27:07 | INFO | train | epoch 988 | loss 2.422 | nll_loss 0.308 | ppl 1.24 | wps 24853 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48061 | lr 0.000144246 | gnorm 0.348 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 131072
2022-03-08 01:27:07 | INFO | fairseq.trainer | begin training epoch 989
2022-03-08 01:27:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:27:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:28:46 | INFO | train_inner | epoch 989:     40 / 49 loss=2.421, nll_loss=0.308, ppl=1.24, wps=24702.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=48100, lr=0.000144187, gnorm=0.348, loss_scale=32, train_wall=224, gb_free=8.8, wall=131171
2022-03-08 01:29:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:29:12 | INFO | valid | epoch 989 | valid on 'valid' subset | loss 13.762 | nll_loss 13.105 | ppl 8810.28 | wps 46470.2 | wpb 510.9 | bsz 1 | num_updates 48109 | best_loss 9.157
2022-03-08 01:29:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 989 @ 48109 updates
2022-03-08 01:29:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:29:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:29:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 989 @ 48109 updates, score 13.762) (writing took 2.3230559630319476 seconds)
2022-03-08 01:29:14 | INFO | fairseq_cli.train | end of epoch 989 (average epoch stats below)
2022-03-08 01:29:14 | INFO | train | epoch 989 | loss 2.421 | nll_loss 0.307 | ppl 1.24 | wps 24422.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48109 | lr 0.000144174 | gnorm 0.347 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 131199
2022-03-08 01:29:14 | INFO | fairseq.trainer | begin training epoch 990
2022-03-08 01:29:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:31:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:31:20 | INFO | valid | epoch 990 | valid on 'valid' subset | loss 13.64 | nll_loss 12.965 | ppl 7996.98 | wps 45911.8 | wpb 510.9 | bsz 1 | num_updates 48158 | best_loss 9.157
2022-03-08 01:31:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 990 @ 48158 updates
2022-03-08 01:31:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:31:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:31:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 990 @ 48158 updates, score 13.64) (writing took 2.288212303072214 seconds)
2022-03-08 01:31:22 | INFO | fairseq_cli.train | end of epoch 990 (average epoch stats below)
2022-03-08 01:31:22 | INFO | train | epoch 990 | loss 2.421 | nll_loss 0.307 | ppl 1.24 | wps 24890.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48158 | lr 0.000144101 | gnorm 0.35 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 131327
2022-03-08 01:31:22 | INFO | fairseq.trainer | begin training epoch 991
2022-03-08 01:31:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:33:06 | INFO | train_inner | epoch 991:     42 / 49 loss=2.421, nll_loss=0.307, ppl=1.24, wps=24928.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=48200, lr=0.000144038, gnorm=0.349, loss_scale=32, train_wall=222, gb_free=8.8, wall=131431
2022-03-08 01:33:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:33:27 | INFO | valid | epoch 991 | valid on 'valid' subset | loss 13.646 | nll_loss 12.97 | ppl 8025.67 | wps 46841.1 | wpb 510.9 | bsz 1 | num_updates 48207 | best_loss 9.157
2022-03-08 01:33:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 991 @ 48207 updates
2022-03-08 01:33:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:33:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:33:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 991 @ 48207 updates, score 13.646) (writing took 2.2900522900745273 seconds)
2022-03-08 01:33:30 | INFO | fairseq_cli.train | end of epoch 991 (average epoch stats below)
2022-03-08 01:33:30 | INFO | train | epoch 991 | loss 2.421 | nll_loss 0.307 | ppl 1.24 | wps 24920.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48207 | lr 0.000144027 | gnorm 0.349 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 131454
2022-03-08 01:33:30 | INFO | fairseq.trainer | begin training epoch 992
2022-03-08 01:33:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:33:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:35:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:35:35 | INFO | valid | epoch 992 | valid on 'valid' subset | loss 13.659 | nll_loss 12.985 | ppl 8108.99 | wps 45159.3 | wpb 510.9 | bsz 1 | num_updates 48255 | best_loss 9.157
2022-03-08 01:35:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 992 @ 48255 updates
2022-03-08 01:35:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:35:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:35:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 992 @ 48255 updates, score 13.659) (writing took 2.3923954628407955 seconds)
2022-03-08 01:35:38 | INFO | fairseq_cli.train | end of epoch 992 (average epoch stats below)
2022-03-08 01:35:38 | INFO | train | epoch 992 | loss 2.421 | nll_loss 0.307 | ppl 1.24 | wps 24322.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48255 | lr 0.000143956 | gnorm 0.346 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 131582
2022-03-08 01:35:38 | INFO | fairseq.trainer | begin training epoch 993
2022-03-08 01:35:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:37:29 | INFO | train_inner | epoch 993:     45 / 49 loss=2.421, nll_loss=0.307, ppl=1.24, wps=24673.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=48300, lr=0.000143889, gnorm=0.347, loss_scale=32, train_wall=224, gb_free=8.8, wall=131694
2022-03-08 01:37:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:37:43 | INFO | valid | epoch 993 | valid on 'valid' subset | loss 13.68 | nll_loss 13.013 | ppl 8263.62 | wps 46524.1 | wpb 510.9 | bsz 1 | num_updates 48304 | best_loss 9.157
2022-03-08 01:37:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 993 @ 48304 updates
2022-03-08 01:37:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:37:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:37:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 993 @ 48304 updates, score 13.68) (writing took 2.3155036228708923 seconds)
2022-03-08 01:37:45 | INFO | fairseq_cli.train | end of epoch 993 (average epoch stats below)
2022-03-08 01:37:45 | INFO | train | epoch 993 | loss 2.42 | nll_loss 0.307 | ppl 1.24 | wps 24915.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48304 | lr 0.000143883 | gnorm 0.346 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 131710
2022-03-08 01:37:45 | INFO | fairseq.trainer | begin training epoch 994
2022-03-08 01:37:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:39:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:39:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:39:50 | INFO | valid | epoch 994 | valid on 'valid' subset | loss 13.742 | nll_loss 13.078 | ppl 8649.12 | wps 46722.7 | wpb 510.9 | bsz 1 | num_updates 48352 | best_loss 9.157
2022-03-08 01:39:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 994 @ 48352 updates
2022-03-08 01:39:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:39:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:39:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 994 @ 48352 updates, score 13.742) (writing took 2.3330480358563364 seconds)
2022-03-08 01:39:53 | INFO | fairseq_cli.train | end of epoch 994 (average epoch stats below)
2022-03-08 01:39:53 | INFO | train | epoch 994 | loss 2.42 | nll_loss 0.307 | ppl 1.24 | wps 24396.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48352 | lr 0.000143811 | gnorm 0.348 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 131837
2022-03-08 01:39:53 | INFO | fairseq.trainer | begin training epoch 995
2022-03-08 01:39:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:41:52 | INFO | train_inner | epoch 995:     48 / 49 loss=2.42, nll_loss=0.307, ppl=1.24, wps=24697.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=48400, lr=0.00014374, gnorm=0.35, loss_scale=32, train_wall=224, gb_free=8.8, wall=131957
2022-03-08 01:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:41:58 | INFO | valid | epoch 995 | valid on 'valid' subset | loss 13.647 | nll_loss 12.978 | ppl 8067.3 | wps 47072.5 | wpb 510.9 | bsz 1 | num_updates 48401 | best_loss 9.157
2022-03-08 01:41:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 995 @ 48401 updates
2022-03-08 01:41:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:42:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:42:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 995 @ 48401 updates, score 13.647) (writing took 2.268236549105495 seconds)
2022-03-08 01:42:00 | INFO | fairseq_cli.train | end of epoch 995 (average epoch stats below)
2022-03-08 01:42:00 | INFO | train | epoch 995 | loss 2.42 | nll_loss 0.307 | ppl 1.24 | wps 24917.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48401 | lr 0.000143738 | gnorm 0.353 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 131965
2022-03-08 01:42:00 | INFO | fairseq.trainer | begin training epoch 996
2022-03-08 01:42:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:44:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:44:06 | INFO | valid | epoch 996 | valid on 'valid' subset | loss 13.602 | nll_loss 12.926 | ppl 7783.1 | wps 45904.1 | wpb 510.9 | bsz 1 | num_updates 48450 | best_loss 9.157
2022-03-08 01:44:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 996 @ 48450 updates
2022-03-08 01:44:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:44:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:44:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 996 @ 48450 updates, score 13.602) (writing took 2.395769838243723 seconds)
2022-03-08 01:44:08 | INFO | fairseq_cli.train | end of epoch 996 (average epoch stats below)
2022-03-08 01:44:08 | INFO | train | epoch 996 | loss 2.42 | nll_loss 0.307 | ppl 1.24 | wps 24880.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48450 | lr 0.000143666 | gnorm 0.35 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 132093
2022-03-08 01:44:08 | INFO | fairseq.trainer | begin training epoch 997
2022-03-08 01:44:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:44:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:46:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:46:13 | INFO | valid | epoch 997 | valid on 'valid' subset | loss 13.656 | nll_loss 12.979 | ppl 8071.99 | wps 46748.1 | wpb 510.9 | bsz 1 | num_updates 48498 | best_loss 9.157
2022-03-08 01:46:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 997 @ 48498 updates
2022-03-08 01:46:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:46:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:46:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 997 @ 48498 updates, score 13.656) (writing took 3.8922100248746574 seconds)
2022-03-08 01:46:17 | INFO | fairseq_cli.train | end of epoch 997 (average epoch stats below)
2022-03-08 01:46:17 | INFO | train | epoch 997 | loss 2.42 | nll_loss 0.307 | ppl 1.24 | wps 24098.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 48498 | lr 0.000143595 | gnorm 0.345 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 132222
2022-03-08 01:46:17 | INFO | fairseq.trainer | begin training epoch 998
2022-03-08 01:46:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:46:22 | INFO | train_inner | epoch 998:      2 / 49 loss=2.42, nll_loss=0.307, ppl=1.24, wps=23890.2, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=48500, lr=0.000143592, gnorm=0.349, loss_scale=32, train_wall=223, gb_free=8.8, wall=132227
2022-03-08 01:48:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:48:23 | INFO | valid | epoch 998 | valid on 'valid' subset | loss 13.662 | nll_loss 12.99 | ppl 8133.43 | wps 45355.9 | wpb 510.9 | bsz 1 | num_updates 48547 | best_loss 9.157
2022-03-08 01:48:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 998 @ 48547 updates
2022-03-08 01:48:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:48:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:48:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 998 @ 48547 updates, score 13.662) (writing took 2.262949918396771 seconds)
2022-03-08 01:48:25 | INFO | fairseq_cli.train | end of epoch 998 (average epoch stats below)
2022-03-08 01:48:25 | INFO | train | epoch 998 | loss 2.42 | nll_loss 0.307 | ppl 1.24 | wps 24861.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48547 | lr 0.000143522 | gnorm 0.351 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 132350
2022-03-08 01:48:25 | INFO | fairseq.trainer | begin training epoch 999
2022-03-08 01:48:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:50:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:50:30 | INFO | valid | epoch 999 | valid on 'valid' subset | loss 13.694 | nll_loss 13.021 | ppl 8310.95 | wps 47115.1 | wpb 510.9 | bsz 1 | num_updates 48596 | best_loss 9.157
2022-03-08 01:50:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 999 @ 48596 updates
2022-03-08 01:50:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:50:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:50:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 999 @ 48596 updates, score 13.694) (writing took 2.268770234659314 seconds)
2022-03-08 01:50:33 | INFO | fairseq_cli.train | end of epoch 999 (average epoch stats below)
2022-03-08 01:50:33 | INFO | train | epoch 999 | loss 2.42 | nll_loss 0.307 | ppl 1.24 | wps 24895.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48596 | lr 0.00014345 | gnorm 0.345 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 132477
2022-03-08 01:50:33 | INFO | fairseq.trainer | begin training epoch 1000
2022-03-08 01:50:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:50:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:50:45 | INFO | train_inner | epoch 1000:      5 / 49 loss=2.42, nll_loss=0.307, ppl=1.24, wps=24666.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=48600, lr=0.000143444, gnorm=0.348, loss_scale=32, train_wall=224, gb_free=8.8, wall=132490
2022-03-08 01:52:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:52:38 | INFO | valid | epoch 1000 | valid on 'valid' subset | loss 13.665 | nll_loss 12.993 | ppl 8154.21 | wps 46385.9 | wpb 510.9 | bsz 1 | num_updates 48644 | best_loss 9.157
2022-03-08 01:52:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1000 @ 48644 updates
2022-03-08 01:52:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:52:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:52:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1000 @ 48644 updates, score 13.665) (writing took 2.404631483834237 seconds)
2022-03-08 01:52:41 | INFO | fairseq_cli.train | end of epoch 1000 (average epoch stats below)
2022-03-08 01:52:41 | INFO | train | epoch 1000 | loss 2.42 | nll_loss 0.307 | ppl 1.24 | wps 24303.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 48644 | lr 0.000143379 | gnorm 0.346 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 132605
2022-03-08 01:52:41 | INFO | fairseq.trainer | begin training epoch 1001
2022-03-08 01:52:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:54:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:54:46 | INFO | valid | epoch 1001 | valid on 'valid' subset | loss 13.757 | nll_loss 13.097 | ppl 8764.64 | wps 46788.7 | wpb 510.9 | bsz 1 | num_updates 48693 | best_loss 9.157
2022-03-08 01:54:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1001 @ 48693 updates
2022-03-08 01:54:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:54:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:54:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1001 @ 48693 updates, score 13.757) (writing took 2.2878348608501256 seconds)
2022-03-08 01:54:48 | INFO | fairseq_cli.train | end of epoch 1001 (average epoch stats below)
2022-03-08 01:54:48 | INFO | train | epoch 1001 | loss 2.42 | nll_loss 0.307 | ppl 1.24 | wps 24902.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48693 | lr 0.000143307 | gnorm 0.347 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 132733
2022-03-08 01:54:48 | INFO | fairseq.trainer | begin training epoch 1002
2022-03-08 01:54:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:55:06 | INFO | train_inner | epoch 1002:      7 / 49 loss=2.42, nll_loss=0.307, ppl=1.24, wps=24893, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=48700, lr=0.000143296, gnorm=0.347, loss_scale=32, train_wall=222, gb_free=8.8, wall=132751
2022-03-08 01:56:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:56:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:56:54 | INFO | valid | epoch 1002 | valid on 'valid' subset | loss 13.698 | nll_loss 13.032 | ppl 8373 | wps 46240.8 | wpb 510.9 | bsz 1 | num_updates 48741 | best_loss 9.157
2022-03-08 01:56:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1002 @ 48741 updates
2022-03-08 01:56:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:56:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:56:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1002 @ 48741 updates, score 13.698) (writing took 2.249376075807959 seconds)
2022-03-08 01:56:56 | INFO | fairseq_cli.train | end of epoch 1002 (average epoch stats below)
2022-03-08 01:56:56 | INFO | train | epoch 1002 | loss 2.42 | nll_loss 0.307 | ppl 1.24 | wps 24370.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48741 | lr 0.000143236 | gnorm 0.348 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 132861
2022-03-08 01:56:56 | INFO | fairseq.trainer | begin training epoch 1003
2022-03-08 01:56:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:58:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:59:01 | INFO | valid | epoch 1003 | valid on 'valid' subset | loss 13.712 | nll_loss 13.048 | ppl 8471.58 | wps 47109.7 | wpb 510.9 | bsz 1 | num_updates 48790 | best_loss 9.157
2022-03-08 01:59:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1003 @ 48790 updates
2022-03-08 01:59:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:59:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:59:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1003 @ 48790 updates, score 13.712) (writing took 2.2628891486674547 seconds)
2022-03-08 01:59:04 | INFO | fairseq_cli.train | end of epoch 1003 (average epoch stats below)
2022-03-08 01:59:04 | INFO | train | epoch 1003 | loss 2.42 | nll_loss 0.307 | ppl 1.24 | wps 24932.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48790 | lr 0.000143164 | gnorm 0.353 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 132988
2022-03-08 01:59:04 | INFO | fairseq.trainer | begin training epoch 1004
2022-03-08 01:59:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:59:29 | INFO | train_inner | epoch 1004:     10 / 49 loss=2.42, nll_loss=0.307, ppl=1.24, wps=24690.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=48800, lr=0.00014315, gnorm=0.35, loss_scale=32, train_wall=224, gb_free=8.8, wall=133013
2022-03-08 02:01:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:01:09 | INFO | valid | epoch 1004 | valid on 'valid' subset | loss 13.706 | nll_loss 13.03 | ppl 8362.27 | wps 46042.7 | wpb 510.9 | bsz 1 | num_updates 48839 | best_loss 9.157
2022-03-08 02:01:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1004 @ 48839 updates
2022-03-08 02:01:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:01:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:01:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1004 @ 48839 updates, score 13.706) (writing took 2.4003912089392543 seconds)
2022-03-08 02:01:11 | INFO | fairseq_cli.train | end of epoch 1004 (average epoch stats below)
2022-03-08 02:01:11 | INFO | train | epoch 1004 | loss 2.42 | nll_loss 0.307 | ppl 1.24 | wps 24886.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48839 | lr 0.000143092 | gnorm 0.348 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 133116
2022-03-08 02:01:11 | INFO | fairseq.trainer | begin training epoch 1005
2022-03-08 02:01:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:01:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:03:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:03:16 | INFO | valid | epoch 1005 | valid on 'valid' subset | loss 13.744 | nll_loss 13.08 | ppl 8659.3 | wps 46267.8 | wpb 510.9 | bsz 1 | num_updates 48887 | best_loss 9.157
2022-03-08 02:03:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1005 @ 48887 updates
2022-03-08 02:03:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:03:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:03:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1005 @ 48887 updates, score 13.744) (writing took 2.2812181967310607 seconds)
2022-03-08 02:03:19 | INFO | fairseq_cli.train | end of epoch 1005 (average epoch stats below)
2022-03-08 02:03:19 | INFO | train | epoch 1005 | loss 2.419 | nll_loss 0.306 | ppl 1.24 | wps 24408.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48887 | lr 0.000143022 | gnorm 0.344 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 133243
2022-03-08 02:03:19 | INFO | fairseq.trainer | begin training epoch 1006
2022-03-08 02:03:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:03:51 | INFO | train_inner | epoch 1006:     13 / 49 loss=2.419, nll_loss=0.306, ppl=1.24, wps=24710.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=48900, lr=0.000143003, gnorm=0.346, loss_scale=16, train_wall=224, gb_free=8.8, wall=133276
2022-03-08 02:05:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:05:24 | INFO | valid | epoch 1006 | valid on 'valid' subset | loss 13.716 | nll_loss 13.049 | ppl 8475.88 | wps 45930.7 | wpb 510.9 | bsz 1 | num_updates 48936 | best_loss 9.157
2022-03-08 02:05:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1006 @ 48936 updates
2022-03-08 02:05:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:05:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:05:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1006 @ 48936 updates, score 13.716) (writing took 2.293221163097769 seconds)
2022-03-08 02:05:26 | INFO | fairseq_cli.train | end of epoch 1006 (average epoch stats below)
2022-03-08 02:05:26 | INFO | train | epoch 1006 | loss 2.419 | nll_loss 0.306 | ppl 1.24 | wps 24907.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48936 | lr 0.000142951 | gnorm 0.343 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 133371
2022-03-08 02:05:26 | INFO | fairseq.trainer | begin training epoch 1007
2022-03-08 02:05:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:07:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:07:32 | INFO | valid | epoch 1007 | valid on 'valid' subset | loss 13.72 | nll_loss 13.055 | ppl 8510.44 | wps 46620.2 | wpb 510.9 | bsz 1 | num_updates 48985 | best_loss 9.157
2022-03-08 02:07:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1007 @ 48985 updates
2022-03-08 02:07:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:07:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:07:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1007 @ 48985 updates, score 13.72) (writing took 2.272096750792116 seconds)
2022-03-08 02:07:34 | INFO | fairseq_cli.train | end of epoch 1007 (average epoch stats below)
2022-03-08 02:07:34 | INFO | train | epoch 1007 | loss 2.419 | nll_loss 0.306 | ppl 1.24 | wps 24930.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48985 | lr 0.000142879 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 133499
2022-03-08 02:07:34 | INFO | fairseq.trainer | begin training epoch 1008
2022-03-08 02:07:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:08:11 | INFO | train_inner | epoch 1008:     15 / 49 loss=2.419, nll_loss=0.306, ppl=1.24, wps=24935.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=49000, lr=0.000142857, gnorm=0.347, loss_scale=32, train_wall=222, gb_free=8.8, wall=133536
2022-03-08 02:09:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:09:39 | INFO | valid | epoch 1008 | valid on 'valid' subset | loss 13.642 | nll_loss 12.965 | ppl 7995.53 | wps 44558.1 | wpb 510.9 | bsz 1 | num_updates 49034 | best_loss 9.157
2022-03-08 02:09:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1008 @ 49034 updates
2022-03-08 02:09:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:09:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:09:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1008 @ 49034 updates, score 13.642) (writing took 2.3961671660654247 seconds)
2022-03-08 02:09:42 | INFO | fairseq_cli.train | end of epoch 1008 (average epoch stats below)
2022-03-08 02:09:42 | INFO | train | epoch 1008 | loss 2.419 | nll_loss 0.306 | ppl 1.24 | wps 24825.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49034 | lr 0.000142808 | gnorm 0.348 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 133627
2022-03-08 02:09:42 | INFO | fairseq.trainer | begin training epoch 1009
2022-03-08 02:09:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:11:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:11:47 | INFO | valid | epoch 1009 | valid on 'valid' subset | loss 13.646 | nll_loss 12.972 | ppl 8034.95 | wps 46675.4 | wpb 510.9 | bsz 1 | num_updates 49083 | best_loss 9.157
2022-03-08 02:11:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1009 @ 49083 updates
2022-03-08 02:11:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:11:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:11:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1009 @ 49083 updates, score 13.646) (writing took 2.3037102851085365 seconds)
2022-03-08 02:11:50 | INFO | fairseq_cli.train | end of epoch 1009 (average epoch stats below)
2022-03-08 02:11:50 | INFO | train | epoch 1009 | loss 2.419 | nll_loss 0.306 | ppl 1.24 | wps 24890.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49083 | lr 0.000142736 | gnorm 0.354 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 133754
2022-03-08 02:11:50 | INFO | fairseq.trainer | begin training epoch 1010
2022-03-08 02:11:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:12:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:12:34 | INFO | train_inner | epoch 1010:     18 / 49 loss=2.419, nll_loss=0.306, ppl=1.24, wps=24668.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=49100, lr=0.000142712, gnorm=0.35, loss_scale=32, train_wall=224, gb_free=8.8, wall=133799
2022-03-08 02:13:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:13:55 | INFO | valid | epoch 1010 | valid on 'valid' subset | loss 13.673 | nll_loss 13.002 | ppl 8203.83 | wps 46542 | wpb 510.9 | bsz 1 | num_updates 49131 | best_loss 9.157
2022-03-08 02:13:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1010 @ 49131 updates
2022-03-08 02:13:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:13:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:13:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1010 @ 49131 updates, score 13.673) (writing took 2.3102398100309074 seconds)
2022-03-08 02:13:57 | INFO | fairseq_cli.train | end of epoch 1010 (average epoch stats below)
2022-03-08 02:13:57 | INFO | train | epoch 1010 | loss 2.419 | nll_loss 0.306 | ppl 1.24 | wps 24396.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49131 | lr 0.000142667 | gnorm 0.344 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 133882
2022-03-08 02:13:57 | INFO | fairseq.trainer | begin training epoch 1011
2022-03-08 02:13:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:15:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:16:02 | INFO | valid | epoch 1011 | valid on 'valid' subset | loss 13.708 | nll_loss 13.038 | ppl 8410.91 | wps 46711.7 | wpb 510.9 | bsz 1 | num_updates 49180 | best_loss 9.157
2022-03-08 02:16:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1011 @ 49180 updates
2022-03-08 02:16:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:16:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:16:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1011 @ 49180 updates, score 13.708) (writing took 2.2733664731495082 seconds)
2022-03-08 02:16:04 | INFO | fairseq_cli.train | end of epoch 1011 (average epoch stats below)
2022-03-08 02:16:04 | INFO | train | epoch 1011 | loss 2.419 | nll_loss 0.306 | ppl 1.24 | wps 24952.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49180 | lr 0.000142595 | gnorm 0.347 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 134009
2022-03-08 02:16:04 | INFO | fairseq.trainer | begin training epoch 1012
2022-03-08 02:16:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:16:54 | INFO | train_inner | epoch 1012:     20 / 49 loss=2.419, nll_loss=0.306, ppl=1.24, wps=24937.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=49200, lr=0.000142566, gnorm=0.346, loss_scale=32, train_wall=222, gb_free=8.8, wall=134059
2022-03-08 02:18:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:18:10 | INFO | valid | epoch 1012 | valid on 'valid' subset | loss 13.684 | nll_loss 13.015 | ppl 8279.71 | wps 45882.1 | wpb 510.9 | bsz 1 | num_updates 49229 | best_loss 9.157
2022-03-08 02:18:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1012 @ 49229 updates
2022-03-08 02:18:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:18:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:18:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1012 @ 49229 updates, score 13.684) (writing took 2.4114080481231213 seconds)
2022-03-08 02:18:12 | INFO | fairseq_cli.train | end of epoch 1012 (average epoch stats below)
2022-03-08 02:18:12 | INFO | train | epoch 1012 | loss 2.419 | nll_loss 0.306 | ppl 1.24 | wps 24850.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49229 | lr 0.000142524 | gnorm 0.349 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 134137
2022-03-08 02:18:12 | INFO | fairseq.trainer | begin training epoch 1013
2022-03-08 02:18:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:18:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:20:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:20:18 | INFO | valid | epoch 1013 | valid on 'valid' subset | loss 13.579 | nll_loss 12.895 | ppl 7619.12 | wps 46072.5 | wpb 510.9 | bsz 1 | num_updates 49277 | best_loss 9.157
2022-03-08 02:20:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1013 @ 49277 updates
2022-03-08 02:20:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:20:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:20:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1013 @ 49277 updates, score 13.579) (writing took 2.270618482027203 seconds)
2022-03-08 02:20:20 | INFO | fairseq_cli.train | end of epoch 1013 (average epoch stats below)
2022-03-08 02:20:20 | INFO | train | epoch 1013 | loss 2.418 | nll_loss 0.306 | ppl 1.24 | wps 24372.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49277 | lr 0.000142455 | gnorm 0.346 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 134265
2022-03-08 02:20:20 | INFO | fairseq.trainer | begin training epoch 1014
2022-03-08 02:20:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:21:17 | INFO | train_inner | epoch 1014:     23 / 49 loss=2.418, nll_loss=0.306, ppl=1.24, wps=24686.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=49300, lr=0.000142422, gnorm=0.347, loss_scale=32, train_wall=224, gb_free=8.8, wall=134322
2022-03-08 02:22:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:22:26 | INFO | valid | epoch 1014 | valid on 'valid' subset | loss 13.616 | nll_loss 12.94 | ppl 7855.78 | wps 45796.5 | wpb 510.9 | bsz 1 | num_updates 49326 | best_loss 9.157
2022-03-08 02:22:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1014 @ 49326 updates
2022-03-08 02:22:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:22:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:22:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1014 @ 49326 updates, score 13.616) (writing took 2.309686774853617 seconds)
2022-03-08 02:22:28 | INFO | fairseq_cli.train | end of epoch 1014 (average epoch stats below)
2022-03-08 02:22:28 | INFO | train | epoch 1014 | loss 2.418 | nll_loss 0.306 | ppl 1.24 | wps 24872.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49326 | lr 0.000142384 | gnorm 0.346 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 134393
2022-03-08 02:22:28 | INFO | fairseq.trainer | begin training epoch 1015
2022-03-08 02:22:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:24:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:24:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:24:33 | INFO | valid | epoch 1015 | valid on 'valid' subset | loss 13.613 | nll_loss 12.934 | ppl 7823.63 | wps 46908.3 | wpb 510.9 | bsz 1 | num_updates 49374 | best_loss 9.157
2022-03-08 02:24:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1015 @ 49374 updates
2022-03-08 02:24:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:24:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:24:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1015 @ 49374 updates, score 13.613) (writing took 2.26456805318594 seconds)
2022-03-08 02:24:35 | INFO | fairseq_cli.train | end of epoch 1015 (average epoch stats below)
2022-03-08 02:24:35 | INFO | train | epoch 1015 | loss 2.418 | nll_loss 0.306 | ppl 1.24 | wps 24429.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49374 | lr 0.000142315 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 134520
2022-03-08 02:24:35 | INFO | fairseq.trainer | begin training epoch 1016
2022-03-08 02:24:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:25:40 | INFO | train_inner | epoch 1016:     26 / 49 loss=2.418, nll_loss=0.306, ppl=1.24, wps=24680.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=49400, lr=0.000142278, gnorm=0.346, loss_scale=32, train_wall=224, gb_free=8.8, wall=134585
2022-03-08 02:26:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:26:41 | INFO | valid | epoch 1016 | valid on 'valid' subset | loss 13.573 | nll_loss 12.896 | ppl 7624.03 | wps 46082.3 | wpb 510.9 | bsz 1 | num_updates 49423 | best_loss 9.157
2022-03-08 02:26:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1016 @ 49423 updates
2022-03-08 02:26:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:26:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:26:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1016 @ 49423 updates, score 13.573) (writing took 2.367650575004518 seconds)
2022-03-08 02:26:43 | INFO | fairseq_cli.train | end of epoch 1016 (average epoch stats below)
2022-03-08 02:26:43 | INFO | train | epoch 1016 | loss 2.418 | nll_loss 0.305 | ppl 1.24 | wps 24846.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49423 | lr 0.000142244 | gnorm 0.347 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 134648
2022-03-08 02:26:43 | INFO | fairseq.trainer | begin training epoch 1017
2022-03-08 02:26:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:28:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:28:48 | INFO | valid | epoch 1017 | valid on 'valid' subset | loss 13.644 | nll_loss 12.97 | ppl 8020.68 | wps 46857.8 | wpb 510.9 | bsz 1 | num_updates 49472 | best_loss 9.157
2022-03-08 02:28:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1017 @ 49472 updates
2022-03-08 02:28:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:28:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:28:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1017 @ 49472 updates, score 13.644) (writing took 2.318774826359004 seconds)
2022-03-08 02:28:51 | INFO | fairseq_cli.train | end of epoch 1017 (average epoch stats below)
2022-03-08 02:28:51 | INFO | train | epoch 1017 | loss 2.418 | nll_loss 0.306 | ppl 1.24 | wps 24893 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49472 | lr 0.000142174 | gnorm 0.347 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 134776
2022-03-08 02:28:51 | INFO | fairseq.trainer | begin training epoch 1018
2022-03-08 02:28:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:29:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:30:03 | INFO | train_inner | epoch 1018:     29 / 49 loss=2.418, nll_loss=0.306, ppl=1.24, wps=24664.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=49500, lr=0.000142134, gnorm=0.348, loss_scale=32, train_wall=224, gb_free=8.8, wall=134848
2022-03-08 02:30:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:30:56 | INFO | valid | epoch 1018 | valid on 'valid' subset | loss 13.655 | nll_loss 12.982 | ppl 8090.12 | wps 46358.8 | wpb 510.9 | bsz 1 | num_updates 49520 | best_loss 9.157
2022-03-08 02:30:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1018 @ 49520 updates
2022-03-08 02:30:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:30:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:30:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1018 @ 49520 updates, score 13.655) (writing took 2.2339362180791795 seconds)
2022-03-08 02:30:58 | INFO | fairseq_cli.train | end of epoch 1018 (average epoch stats below)
2022-03-08 02:30:58 | INFO | train | epoch 1018 | loss 2.417 | nll_loss 0.305 | ppl 1.24 | wps 24396.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49520 | lr 0.000142105 | gnorm 0.347 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 134903
2022-03-08 02:30:58 | INFO | fairseq.trainer | begin training epoch 1019
2022-03-08 02:30:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:32:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:33:04 | INFO | valid | epoch 1019 | valid on 'valid' subset | loss 13.736 | nll_loss 13.075 | ppl 8627.59 | wps 46983.5 | wpb 510.9 | bsz 1 | num_updates 49569 | best_loss 9.157
2022-03-08 02:33:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1019 @ 49569 updates
2022-03-08 02:33:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:33:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:33:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1019 @ 49569 updates, score 13.736) (writing took 2.29609831282869 seconds)
2022-03-08 02:33:06 | INFO | fairseq_cli.train | end of epoch 1019 (average epoch stats below)
2022-03-08 02:33:06 | INFO | train | epoch 1019 | loss 2.418 | nll_loss 0.305 | ppl 1.24 | wps 24935 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49569 | lr 0.000142035 | gnorm 0.347 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 135031
2022-03-08 02:33:06 | INFO | fairseq.trainer | begin training epoch 1020
2022-03-08 02:33:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:34:23 | INFO | train_inner | epoch 1020:     31 / 49 loss=2.417, nll_loss=0.305, ppl=1.24, wps=24936.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=49600, lr=0.00014199, gnorm=0.345, loss_scale=32, train_wall=222, gb_free=8.8, wall=135108
2022-03-08 02:35:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:35:11 | INFO | valid | epoch 1020 | valid on 'valid' subset | loss 13.763 | nll_loss 13.103 | ppl 8796.99 | wps 46191.6 | wpb 510.9 | bsz 1 | num_updates 49618 | best_loss 9.157
2022-03-08 02:35:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1020 @ 49618 updates
2022-03-08 02:35:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:35:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:35:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1020 @ 49618 updates, score 13.763) (writing took 2.402343783993274 seconds)
2022-03-08 02:35:14 | INFO | fairseq_cli.train | end of epoch 1020 (average epoch stats below)
2022-03-08 02:35:14 | INFO | train | epoch 1020 | loss 2.418 | nll_loss 0.305 | ppl 1.24 | wps 24821.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49618 | lr 0.000141965 | gnorm 0.343 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 135159
2022-03-08 02:35:14 | INFO | fairseq.trainer | begin training epoch 1021
2022-03-08 02:35:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:35:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:37:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:37:20 | INFO | valid | epoch 1021 | valid on 'valid' subset | loss 13.694 | nll_loss 13.024 | ppl 8329.58 | wps 46310.4 | wpb 510.9 | bsz 1 | num_updates 49666 | best_loss 9.157
2022-03-08 02:37:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1021 @ 49666 updates
2022-03-08 02:37:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:37:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:37:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1021 @ 49666 updates, score 13.694) (writing took 2.2869573081843555 seconds)
2022-03-08 02:37:22 | INFO | fairseq_cli.train | end of epoch 1021 (average epoch stats below)
2022-03-08 02:37:22 | INFO | train | epoch 1021 | loss 2.417 | nll_loss 0.305 | ppl 1.24 | wps 24329.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49666 | lr 0.000141896 | gnorm 0.348 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 135287
2022-03-08 02:37:22 | INFO | fairseq.trainer | begin training epoch 1022
2022-03-08 02:37:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:38:46 | INFO | train_inner | epoch 1022:     34 / 49 loss=2.417, nll_loss=0.305, ppl=1.24, wps=24642.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=49700, lr=0.000141848, gnorm=0.347, loss_scale=32, train_wall=224, gb_free=8.8, wall=135371
2022-03-08 02:39:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:39:27 | INFO | valid | epoch 1022 | valid on 'valid' subset | loss 13.684 | nll_loss 13.017 | ppl 8290.02 | wps 46156.7 | wpb 510.9 | bsz 1 | num_updates 49715 | best_loss 9.157
2022-03-08 02:39:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1022 @ 49715 updates
2022-03-08 02:39:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:39:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:39:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1022 @ 49715 updates, score 13.684) (writing took 2.2949886550195515 seconds)
2022-03-08 02:39:30 | INFO | fairseq_cli.train | end of epoch 1022 (average epoch stats below)
2022-03-08 02:39:30 | INFO | train | epoch 1022 | loss 2.417 | nll_loss 0.305 | ppl 1.24 | wps 24883.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49715 | lr 0.000141826 | gnorm 0.346 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 135414
2022-03-08 02:39:30 | INFO | fairseq.trainer | begin training epoch 1023
2022-03-08 02:39:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:41:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:41:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:41:35 | INFO | valid | epoch 1023 | valid on 'valid' subset | loss 13.613 | nll_loss 12.939 | ppl 7851.86 | wps 46844.2 | wpb 510.9 | bsz 1 | num_updates 49763 | best_loss 9.157
2022-03-08 02:41:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1023 @ 49763 updates
2022-03-08 02:41:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:41:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:41:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1023 @ 49763 updates, score 13.613) (writing took 2.261964620091021 seconds)
2022-03-08 02:41:37 | INFO | fairseq_cli.train | end of epoch 1023 (average epoch stats below)
2022-03-08 02:41:37 | INFO | train | epoch 1023 | loss 2.417 | nll_loss 0.305 | ppl 1.24 | wps 24405.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49763 | lr 0.000141758 | gnorm 0.35 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 135542
2022-03-08 02:41:37 | INFO | fairseq.trainer | begin training epoch 1024
2022-03-08 02:41:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:43:09 | INFO | train_inner | epoch 1024:     37 / 49 loss=2.418, nll_loss=0.305, ppl=1.24, wps=24700.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=49800, lr=0.000141705, gnorm=0.349, loss_scale=32, train_wall=224, gb_free=8.8, wall=135634
2022-03-08 02:43:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:43:43 | INFO | valid | epoch 1024 | valid on 'valid' subset | loss 13.586 | nll_loss 12.904 | ppl 7665.61 | wps 45729.3 | wpb 510.9 | bsz 1 | num_updates 49812 | best_loss 9.157
2022-03-08 02:43:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1024 @ 49812 updates
2022-03-08 02:43:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:43:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:43:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1024 @ 49812 updates, score 13.586) (writing took 2.34979738201946 seconds)
2022-03-08 02:43:45 | INFO | fairseq_cli.train | end of epoch 1024 (average epoch stats below)
2022-03-08 02:43:45 | INFO | train | epoch 1024 | loss 2.417 | nll_loss 0.305 | ppl 1.24 | wps 24861.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49812 | lr 0.000141688 | gnorm 0.348 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 135670
2022-03-08 02:43:45 | INFO | fairseq.trainer | begin training epoch 1025
2022-03-08 02:43:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:45:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:45:50 | INFO | valid | epoch 1025 | valid on 'valid' subset | loss 13.685 | nll_loss 13.012 | ppl 8260.51 | wps 46887.2 | wpb 510.9 | bsz 1 | num_updates 49861 | best_loss 9.157
2022-03-08 02:45:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1025 @ 49861 updates
2022-03-08 02:45:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:45:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:45:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1025 @ 49861 updates, score 13.685) (writing took 2.3070785449817777 seconds)
2022-03-08 02:45:52 | INFO | fairseq_cli.train | end of epoch 1025 (average epoch stats below)
2022-03-08 02:45:52 | INFO | train | epoch 1025 | loss 2.417 | nll_loss 0.305 | ppl 1.24 | wps 24973.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49861 | lr 0.000141618 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 135797
2022-03-08 02:45:52 | INFO | fairseq.trainer | begin training epoch 1026
2022-03-08 02:45:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:47:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:47:31 | INFO | train_inner | epoch 1026:     40 / 49 loss=2.417, nll_loss=0.305, ppl=1.24, wps=24725.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=49900, lr=0.000141563, gnorm=0.349, loss_scale=32, train_wall=224, gb_free=8.8, wall=135896
2022-03-08 02:47:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:47:57 | INFO | valid | epoch 1026 | valid on 'valid' subset | loss 13.774 | nll_loss 13.112 | ppl 8853.41 | wps 46551.6 | wpb 510.9 | bsz 1 | num_updates 49909 | best_loss 9.157
2022-03-08 02:47:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1026 @ 49909 updates
2022-03-08 02:47:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:47:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:47:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1026 @ 49909 updates, score 13.774) (writing took 2.2855259561911225 seconds)
2022-03-08 02:47:59 | INFO | fairseq_cli.train | end of epoch 1026 (average epoch stats below)
2022-03-08 02:47:59 | INFO | train | epoch 1026 | loss 2.417 | nll_loss 0.305 | ppl 1.24 | wps 24442.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49909 | lr 0.00014155 | gnorm 0.349 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 135924
2022-03-08 02:48:00 | INFO | fairseq.trainer | begin training epoch 1027
2022-03-08 02:48:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:50:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:50:04 | INFO | valid | epoch 1027 | valid on 'valid' subset | loss 13.656 | nll_loss 12.985 | ppl 8107.31 | wps 47238.8 | wpb 510.9 | bsz 1 | num_updates 49958 | best_loss 9.157
2022-03-08 02:50:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1027 @ 49958 updates
2022-03-08 02:50:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:50:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:50:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1027 @ 49958 updates, score 13.656) (writing took 2.228880657814443 seconds)
2022-03-08 02:50:07 | INFO | fairseq_cli.train | end of epoch 1027 (average epoch stats below)
2022-03-08 02:50:07 | INFO | train | epoch 1027 | loss 2.416 | nll_loss 0.304 | ppl 1.23 | wps 24992.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49958 | lr 0.000141481 | gnorm 0.343 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 136051
2022-03-08 02:50:07 | INFO | fairseq.trainer | begin training epoch 1028
2022-03-08 02:50:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:51:51 | INFO | train_inner | epoch 1028:     42 / 49 loss=2.417, nll_loss=0.305, ppl=1.24, wps=25006.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=50000, lr=0.000141421, gnorm=0.345, loss_scale=32, train_wall=221, gb_free=8.8, wall=136156
2022-03-08 02:51:51 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2022-03-08 02:51:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:51:56 | INFO | valid | epoch 1028 | valid on 'valid' subset | loss 13.6 | nll_loss 12.92 | ppl 7752.07 | wps 47382.3 | wpb 510.9 | bsz 1 | num_updates 50000 | best_loss 9.157
2022-03-08 02:51:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1028 @ 50000 updates
2022-03-08 02:51:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:51:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:51:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 1028 @ 50000 updates, score 13.6) (writing took 2.2736501307226717 seconds)
2022-03-08 02:51:58 | INFO | fairseq_cli.train | end of epoch 1028 (average epoch stats below)
2022-03-08 02:51:58 | INFO | train | epoch 1028 | loss 2.417 | nll_loss 0.305 | ppl 1.24 | wps 24763 | ups 0.38 | wpb 65525.5 | bsz 128 | num_updates 50000 | lr 0.000141421 | gnorm 0.345 | loss_scale 32 | train_wall 94 | gb_free 8.8 | wall 136163
2022-03-08 02:51:58 | INFO | fairseq_cli.train | done training in 136162.4 seconds
