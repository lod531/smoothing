Sender: LSF System <lsfadmin@eu-g3-056>
Subject: Job 210652880: <iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1> was submitted from host <eu-login-27> by user <andriusb> in cluster <euler> at Wed Mar 23 18:53:44 2022
Job was executed on host(s) <eu-g3-056>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 18:54:08 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 18:54:08 2022
Terminated at Wed Mar 23 23:51:43 2022
Results reported at Wed Mar 23 23:51:43 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion kneser_ney_smoothing --kneser-d 0.08 --kneser-n 2 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --no-last-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   17826.11 sec.
    Max Memory :                                 5079 MB
    Average Memory :                             4394.23 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14921.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   17855 sec.
    Turnaround time :                            17879 sec.

The output (if any) follows:

2022-03-23 18:54:16 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='kneser_ney_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, kneser_d=0.08, kneser_n=2, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'kneser_ney_smoothing', 'kneser_d': 0.08, 'kneser_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 18:54:16 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 18:54:16 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 18:54:16 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 18:54:16 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 18:54:16 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1159/160239 [00:00<00:13, 11589.54it/s]  2%|▏         | 2513/160239 [00:00<00:12, 12731.82it/s]  2%|▏         | 3899/160239 [00:00<00:11, 13239.69it/s]  3%|▎         | 5223/160239 [00:00<00:12, 12903.60it/s]  4%|▍         | 6530/160239 [00:00<00:11, 12960.47it/s]  5%|▍         | 7827/160239 [00:00<00:11, 12758.10it/s]  6%|▌         | 9104/160239 [00:00<00:11, 12628.56it/s]  7%|▋         | 10430/160239 [00:00<00:11, 12823.76it/s]  7%|▋         | 11715/160239 [00:00<00:11, 12830.80it/s]  8%|▊         | 12999/160239 [00:01<00:11, 12803.99it/s]  9%|▉         | 14280/160239 [00:01<00:11, 12626.44it/s] 10%|▉         | 15544/160239 [00:01<00:11, 12549.14it/s] 10%|█         | 16800/160239 [00:01<00:11, 12348.39it/s] 11%|█▏        | 18059/160239 [00:01<00:11, 12419.04it/s] 12%|█▏        | 19318/160239 [00:01<00:11, 12466.85it/s] 13%|█▎        | 20732/160239 [00:01<00:10, 12964.43it/s] 14%|█▎        | 22030/160239 [00:01<00:11, 12449.05it/s] 15%|█▍        | 23294/160239 [00:01<00:10, 12500.27it/s] 15%|█▌        | 24573/160239 [00:01<00:10, 12585.05it/s] 16%|█▌        | 25852/160239 [00:02<00:10, 12641.31it/s] 17%|█▋        | 27119/160239 [00:02<00:10, 12499.97it/s] 18%|█▊        | 28473/160239 [00:02<00:10, 12806.16it/s] 19%|█▊        | 29756/160239 [00:02<00:10, 12588.73it/s] 19%|█▉        | 31017/160239 [00:02<00:10, 12548.85it/s] 20%|██        | 32370/160239 [00:02<00:09, 12837.36it/s] 21%|██        | 33656/160239 [00:02<00:10, 12569.87it/s] 22%|██▏       | 34915/160239 [00:02<00:10, 12362.85it/s] 23%|██▎       | 36218/160239 [00:02<00:09, 12556.42it/s] 23%|██▎       | 37476/160239 [00:02<00:09, 12416.23it/s] 24%|██▍       | 38765/160239 [00:03<00:09, 12553.21it/s] 25%|██▍       | 40022/160239 [00:03<00:09, 12542.23it/s] 26%|██▌       | 41352/160239 [00:03<00:09, 12762.60it/s] 27%|██▋       | 42630/160239 [00:03<00:09, 12340.78it/s] 27%|██▋       | 43868/160239 [00:03<00:09, 12350.46it/s] 28%|██▊       | 45106/160239 [00:03<00:09, 12239.31it/s] 29%|██▉       | 46414/160239 [00:03<00:09, 12484.86it/s] 30%|██▉       | 47763/160239 [00:03<00:08, 12780.29it/s] 31%|███       | 49043/160239 [00:03<00:08, 12600.14it/s] 31%|███▏      | 50305/160239 [00:03<00:08, 12498.69it/s] 32%|███▏      | 51619/160239 [00:04<00:08, 12686.12it/s] 33%|███▎      | 52914/160239 [00:04<00:08, 12763.11it/s] 34%|███▍      | 54192/160239 [00:04<00:08, 12687.31it/s] 35%|███▍      | 55462/160239 [00:04<00:08, 12568.36it/s] 35%|███▌      | 56824/160239 [00:04<00:08, 12876.51it/s] 36%|███▋      | 58189/160239 [00:04<00:07, 13105.87it/s] 37%|███▋      | 59501/160239 [00:04<00:07, 13053.18it/s] 38%|███▊      | 60807/160239 [00:04<00:07, 12981.90it/s] 39%|███▉      | 62106/160239 [00:04<00:07, 12571.20it/s] 40%|███▉      | 63460/160239 [00:05<00:07, 12852.21it/s] 41%|████      | 64900/160239 [00:05<00:07, 13304.66it/s] 41%|████▏     | 66234/160239 [00:05<00:07, 13312.74it/s] 42%|████▏     | 67568/160239 [00:05<00:07, 12872.82it/s] 43%|████▎     | 68860/160239 [00:05<00:07, 12674.11it/s] 44%|████▍     | 70164/160239 [00:05<00:07, 12773.95it/s] 45%|████▍     | 71459/160239 [00:05<00:06, 12817.43it/s] 45%|████▌     | 72743/160239 [00:05<00:06, 12712.15it/s] 46%|████▌     | 74016/160239 [00:05<00:06, 12645.57it/s] 47%|████▋     | 75282/160239 [00:05<00:06, 12487.91it/s] 48%|████▊     | 76558/160239 [00:06<00:06, 12565.96it/s] 49%|████▊     | 77937/160239 [00:06<00:06, 12926.95it/s] 49%|████▉     | 79249/160239 [00:06<00:06, 12982.96it/s] 50%|█████     | 80647/160239 [00:06<00:05, 13277.29it/s] 51%|█████     | 81976/160239 [00:06<00:05, 13204.71it/s] 52%|█████▏    | 83298/160239 [00:06<00:05, 13147.61it/s] 53%|█████▎    | 84618/160239 [00:06<00:05, 13160.08it/s] 54%|█████▎    | 85977/160239 [00:06<00:05, 13286.11it/s] 55%|█████▍    | 87346/160239 [00:06<00:05, 13405.02it/s] 55%|█████▌    | 88687/160239 [00:06<00:05, 13206.65it/s] 56%|█████▌    | 90030/160239 [00:07<00:05, 13270.29it/s] 57%|█████▋    | 91358/160239 [00:07<00:05, 13103.90it/s] 58%|█████▊    | 92670/160239 [00:07<00:05, 13021.60it/s] 59%|█████▊    | 93973/160239 [00:07<00:05, 12573.18it/s] 59%|█████▉    | 95284/160239 [00:07<00:05, 12726.51it/s] 60%|██████    | 96622/160239 [00:07<00:04, 12915.84it/s] 61%|██████    | 97916/160239 [00:07<00:04, 12906.50it/s] 62%|██████▏   | 99249/160239 [00:07<00:04, 13030.13it/s] 63%|██████▎   | 100562/160239 [00:07<00:04, 13056.48it/s] 64%|██████▎   | 101869/160239 [00:07<00:04, 12965.43it/s] 64%|██████▍   | 103167/160239 [00:08<00:04, 12748.97it/s] 65%|██████▌   | 104444/160239 [00:08<00:04, 12733.29it/s] 66%|██████▌   | 105751/160239 [00:08<00:04, 12830.94it/s] 67%|██████▋   | 107035/160239 [00:08<00:04, 12737.63it/s] 68%|██████▊   | 108310/160239 [00:08<00:04, 12381.72it/s] 68%|██████▊   | 109569/160239 [00:08<00:04, 12441.15it/s] 69%|██████▉   | 110815/160239 [00:08<00:03, 12445.88it/s] 70%|██████▉   | 112149/160239 [00:08<00:03, 12707.74it/s] 71%|███████   | 113431/160239 [00:08<00:03, 12740.03it/s] 72%|███████▏  | 114720/160239 [00:08<00:03, 12782.98it/s] 72%|███████▏  | 116010/160239 [00:09<00:03, 12816.70it/s] 73%|███████▎  | 117293/160239 [00:09<00:03, 12632.34it/s] 74%|███████▍  | 118590/160239 [00:09<00:03, 12731.51it/s] 75%|███████▍  | 119937/160239 [00:09<00:03, 12949.30it/s] 76%|███████▌  | 121233/160239 [00:09<00:03, 12863.04it/s] 77%|███████▋  | 122636/160239 [00:09<00:02, 13209.49it/s] 77%|███████▋  | 123958/160239 [00:09<00:02, 12917.13it/s] 78%|███████▊  | 125252/160239 [00:09<00:02, 12553.53it/s] 79%|███████▉  | 126552/160239 [00:09<00:02, 12681.45it/s] 80%|███████▉  | 127881/160239 [00:10<00:02, 12859.32it/s] 81%|████████  | 129170/160239 [00:10<00:02, 12804.27it/s] 81%|████████▏ | 130452/160239 [00:10<00:02, 12419.53it/s] 82%|████████▏ | 131739/160239 [00:10<00:02, 12547.76it/s] 83%|████████▎ | 132997/160239 [00:10<00:02, 12470.52it/s] 84%|████████▍ | 134246/160239 [00:10<00:02, 12337.06it/s] 85%|████████▍ | 135545/160239 [00:10<00:01, 12527.87it/s] 85%|████████▌ | 136838/160239 [00:10<00:01, 12645.99it/s] 86%|████████▌ | 138140/160239 [00:10<00:01, 12756.72it/s] 87%|████████▋ | 139472/160239 [00:10<00:01, 12923.28it/s] 88%|████████▊ | 140854/160239 [00:11<00:01, 13188.70it/s] 89%|████████▊ | 142174/160239 [00:11<00:01, 12930.54it/s] 90%|████████▉ | 143469/160239 [00:11<00:01, 12874.72it/s] 90%|█████████ | 144758/160239 [00:11<00:01, 12790.23it/s] 91%|█████████ | 146038/160239 [00:11<00:01, 12555.66it/s] 92%|█████████▏| 147296/160239 [00:11<00:01, 12559.29it/s] 93%|█████████▎| 148553/160239 [00:11<00:00, 12303.87it/s] 93%|█████████▎| 149804/160239 [00:11<00:00, 12363.21it/s] 94%|█████████▍| 151078/160239 [00:11<00:00, 12473.18it/s] 95%|█████████▌| 152356/160239 [00:11<00:00, 12562.14it/s] 96%|█████████▌| 153630/160239 [00:12<00:00, 12613.80it/s] 97%|█████████▋| 154928/160239 [00:12<00:00, 12721.27it/s] 98%|█████████▊| 156243/160239 [00:12<00:00, 12847.43it/s] 98%|█████████▊| 157529/160239 [00:12<00:00, 12659.28it/s] 99%|█████████▉| 158796/160239 [00:12<00:00, 12114.54it/s]100%|█████████▉| 160111/160239 [00:12<00:00, 12409.74it/s]100%|██████████| 160239/160239 [00:12<00:00, 12720.70it/s]
  0%|          | 0/6629 [00:00<?, ?it/s]  0%|          | 30/6629 [00:00<00:22, 293.51it/s]  1%|          | 60/6629 [00:00<00:22, 292.74it/s]  1%|▏         | 90/6629 [00:00<00:22, 292.98it/s]  2%|▏         | 120/6629 [00:00<00:22, 294.09it/s]  2%|▏         | 150/6629 [00:00<00:22, 292.67it/s]  3%|▎         | 180/6629 [00:00<00:22, 292.81it/s]  3%|▎         | 210/6629 [00:00<00:21, 292.21it/s]  4%|▎         | 240/6629 [00:00<00:21, 291.64it/s]  4%|▍         | 270/6629 [00:00<00:21, 291.03it/s]  5%|▍         | 300/6629 [00:01<00:21, 290.37it/s]  5%|▍         | 330/6629 [00:01<00:21, 290.13it/s]  5%|▌         | 360/6629 [00:01<00:21, 289.30it/s]  6%|▌         | 390/6629 [00:01<00:21, 289.63it/s]  6%|▋         | 419/6629 [00:01<00:21, 289.48it/s]  7%|▋         | 448/6629 [00:01<00:21, 289.30it/s]  7%|▋         | 477/6629 [00:01<00:21, 289.29it/s]  8%|▊         | 506/6629 [00:01<00:21, 289.00it/s]  8%|▊         | 535/6629 [00:01<00:21, 289.28it/s]  9%|▊         | 564/6629 [00:01<00:20, 289.40it/s]  9%|▉         | 594/6629 [00:02<00:20, 289.97it/s]  9%|▉         | 624/6629 [00:02<00:20, 290.40it/s] 10%|▉         | 654/6629 [00:02<00:20, 289.39it/s] 10%|█         | 683/6629 [00:02<00:20, 289.19it/s] 11%|█         | 712/6629 [00:02<00:20, 288.60it/s] 11%|█         | 741/6629 [00:02<00:20, 286.95it/s] 12%|█▏        | 771/6629 [00:02<00:20, 288.12it/s] 12%|█▏        | 800/6629 [00:02<00:20, 288.23it/s] 13%|█▎        | 829/6629 [00:02<00:20, 287.50it/s] 13%|█▎        | 858/6629 [00:02<00:20, 287.51it/s] 13%|█▎        | 887/6629 [00:03<00:19, 287.74it/s] 14%|█▍        | 917/6629 [00:03<00:19, 288.48it/s] 14%|█▍        | 946/6629 [00:03<00:19, 288.44it/s] 15%|█▍        | 975/6629 [00:03<00:19, 287.84it/s] 15%|█▌        | 1004/6629 [00:03<00:19, 287.92it/s] 16%|█▌        | 1034/6629 [00:03<00:19, 289.40it/s] 16%|█▌        | 1065/6629 [00:03<00:19, 292.69it/s] 17%|█▋        | 1096/6629 [00:03<00:18, 296.22it/s] 17%|█▋        | 1127/6629 [00:03<00:18, 298.95it/s] 17%|█▋        | 1158/6629 [00:03<00:18, 299.92it/s] 18%|█▊        | 1189/6629 [00:04<00:18, 300.80it/s] 18%|█▊        | 1220/6629 [00:04<00:17, 301.57it/s] 19%|█▉        | 1251/6629 [00:04<00:17, 303.14it/s] 19%|█▉        | 1282/6629 [00:04<00:17, 303.46it/s] 20%|█▉        | 1313/6629 [00:04<00:17, 301.57it/s] 20%|██        | 1344/6629 [00:04<00:17, 302.74it/s] 21%|██        | 1375/6629 [00:04<00:17, 302.77it/s] 21%|██        | 1406/6629 [00:04<00:17, 303.49it/s] 22%|██▏       | 1437/6629 [00:04<00:17, 303.22it/s] 22%|██▏       | 1468/6629 [00:05<00:17, 301.60it/s] 23%|██▎       | 1499/6629 [00:05<00:16, 302.78it/s] 23%|██▎       | 1530/6629 [00:05<00:16, 303.54it/s] 24%|██▎       | 1561/6629 [00:05<00:16, 304.68it/s] 24%|██▍       | 1592/6629 [00:05<00:16, 305.16it/s] 24%|██▍       | 1623/6629 [00:05<00:16, 305.69it/s] 25%|██▍       | 1654/6629 [00:05<00:16, 305.65it/s] 25%|██▌       | 1685/6629 [00:05<00:16, 306.23it/s] 26%|██▌       | 1716/6629 [00:05<00:16, 305.16it/s] 26%|██▋       | 1747/6629 [00:05<00:15, 305.22it/s] 27%|██▋       | 1778/6629 [00:06<00:15, 305.14it/s] 27%|██▋       | 1809/6629 [00:06<00:15, 305.89it/s] 28%|██▊       | 1840/6629 [00:06<00:15, 306.37it/s] 28%|██▊       | 1872/6629 [00:06<00:15, 307.64it/s] 29%|██▊       | 1903/6629 [00:06<00:15, 307.78it/s] 29%|██▉       | 1934/6629 [00:06<00:15, 307.14it/s] 30%|██▉       | 1965/6629 [00:06<00:15, 307.21it/s] 30%|███       | 1996/6629 [00:06<00:15, 305.71it/s] 31%|███       | 2027/6629 [00:06<00:15, 306.18it/s] 31%|███       | 2058/6629 [00:06<00:14, 306.28it/s] 32%|███▏      | 2089/6629 [00:07<00:14, 306.08it/s] 32%|███▏      | 2120/6629 [00:07<00:14, 305.83it/s] 32%|███▏      | 2151/6629 [00:07<00:14, 305.95it/s] 33%|███▎      | 2182/6629 [00:07<00:14, 306.68it/s] 33%|███▎      | 2213/6629 [00:07<00:14, 306.40it/s] 34%|███▍      | 2244/6629 [00:07<00:14, 305.48it/s] 34%|███▍      | 2275/6629 [00:07<00:14, 305.70it/s] 35%|███▍      | 2306/6629 [00:07<00:14, 305.79it/s] 35%|███▌      | 2337/6629 [00:07<00:14, 304.66it/s] 36%|███▌      | 2368/6629 [00:07<00:13, 306.02it/s] 36%|███▌      | 2399/6629 [00:08<00:13, 306.23it/s] 37%|███▋      | 2430/6629 [00:08<00:13, 307.04it/s] 37%|███▋      | 2461/6629 [00:08<00:13, 307.00it/s] 38%|███▊      | 2492/6629 [00:08<00:13, 307.81it/s] 38%|███▊      | 2523/6629 [00:08<00:13, 307.93it/s] 39%|███▊      | 2554/6629 [00:08<00:13, 307.69it/s] 39%|███▉      | 2585/6629 [00:08<00:13, 307.62it/s] 39%|███▉      | 2616/6629 [00:08<00:13, 307.25it/s] 40%|███▉      | 2647/6629 [00:08<00:12, 306.42it/s] 40%|████      | 2678/6629 [00:08<00:12, 306.97it/s] 41%|████      | 2709/6629 [00:09<00:12, 306.62it/s] 41%|████▏     | 2740/6629 [00:09<00:12, 305.48it/s] 42%|████▏     | 2771/6629 [00:09<00:12, 306.11it/s] 42%|████▏     | 2802/6629 [00:09<00:12, 306.56it/s] 43%|████▎     | 2833/6629 [00:09<00:12, 306.63it/s] 43%|████▎     | 2864/6629 [00:09<00:12, 306.18it/s] 44%|████▎     | 2895/6629 [00:09<00:12, 303.65it/s] 44%|████▍     | 2926/6629 [00:09<00:12, 304.47it/s] 45%|████▍     | 2957/6629 [00:09<00:12, 304.49it/s] 45%|████▌     | 2989/6629 [00:09<00:11, 306.50it/s] 46%|████▌     | 3020/6629 [00:10<00:11, 306.03it/s] 46%|████▌     | 3051/6629 [00:10<00:11, 306.44it/s] 46%|████▋     | 3082/6629 [00:10<00:11, 305.52it/s] 47%|████▋     | 3113/6629 [00:10<00:11, 306.21it/s] 47%|████▋     | 3144/6629 [00:10<00:11, 307.09it/s] 48%|████▊     | 3175/6629 [00:10<00:11, 306.38it/s] 48%|████▊     | 3206/6629 [00:10<00:11, 307.17it/s] 49%|████▉     | 3237/6629 [00:10<00:11, 307.26it/s] 49%|████▉     | 3268/6629 [00:10<00:10, 307.76it/s] 50%|████▉     | 3299/6629 [00:10<00:10, 308.06it/s] 50%|█████     | 3330/6629 [00:11<00:10, 308.45it/s] 51%|█████     | 3361/6629 [00:11<00:10, 308.58it/s] 51%|█████     | 3392/6629 [00:11<00:10, 307.75it/s] 52%|█████▏    | 3423/6629 [00:11<00:10, 307.82it/s] 52%|█████▏    | 3454/6629 [00:11<00:10, 307.98it/s] 53%|█████▎    | 3486/6629 [00:11<00:10, 308.64it/s] 53%|█████▎    | 3517/6629 [00:11<00:10, 308.19it/s] 54%|█████▎    | 3548/6629 [00:11<00:10, 308.07it/s] 54%|█████▍    | 3579/6629 [00:11<00:09, 307.02it/s] 54%|█████▍    | 3610/6629 [00:11<00:09, 306.66it/s] 55%|█████▍    | 3641/6629 [00:12<00:09, 306.57it/s] 55%|█████▌    | 3672/6629 [00:12<00:09, 306.76it/s] 56%|█████▌    | 3703/6629 [00:12<00:09, 306.63it/s] 56%|█████▋    | 3734/6629 [00:12<00:09, 306.37it/s] 57%|█████▋    | 3765/6629 [00:12<00:09, 306.33it/s] 57%|█████▋    | 3796/6629 [00:12<00:09, 306.00it/s] 58%|█████▊    | 3827/6629 [00:12<00:09, 305.22it/s] 58%|█████▊    | 3858/6629 [00:12<00:09, 306.29it/s] 59%|█████▊    | 3889/6629 [00:12<00:08, 307.08it/s] 59%|█████▉    | 3920/6629 [00:13<00:08, 307.13it/s] 60%|█████▉    | 3951/6629 [00:13<00:08, 306.56it/s] 60%|██████    | 3983/6629 [00:13<00:08, 307.73it/s] 61%|██████    | 4014/6629 [00:13<00:08, 307.79it/s] 61%|██████    | 4045/6629 [00:13<00:08, 307.05it/s] 61%|██████▏   | 4076/6629 [00:13<00:08, 307.19it/s] 62%|██████▏   | 4107/6629 [00:13<00:08, 306.80it/s] 62%|██████▏   | 4138/6629 [00:13<00:08, 306.75it/s] 63%|██████▎   | 4169/6629 [00:13<00:08, 306.90it/s] 63%|██████▎   | 4200/6629 [00:13<00:07, 307.26it/s] 64%|██████▍   | 4231/6629 [00:14<00:07, 307.01it/s] 64%|██████▍   | 4262/6629 [00:14<00:07, 307.54it/s] 65%|██████▍   | 4293/6629 [00:14<00:07, 307.36it/s] 65%|██████▌   | 4324/6629 [00:14<00:07, 307.20it/s] 66%|██████▌   | 4355/6629 [00:14<00:07, 306.57it/s] 66%|██████▌   | 4386/6629 [00:14<00:07, 307.37it/s] 67%|██████▋   | 4417/6629 [00:14<00:07, 307.28it/s] 67%|██████▋   | 4448/6629 [00:14<00:07, 306.74it/s] 68%|██████▊   | 4479/6629 [00:14<00:07, 304.88it/s] 68%|██████▊   | 4510/6629 [00:14<00:06, 305.50it/s] 69%|██████▊   | 4541/6629 [00:15<00:06, 305.31it/s] 69%|██████▉   | 4572/6629 [00:15<00:06, 306.13it/s] 69%|██████▉   | 4603/6629 [00:15<00:06, 306.68it/s] 70%|██████▉   | 4634/6629 [00:15<00:06, 307.52it/s] 70%|███████   | 4665/6629 [00:15<00:06, 306.83it/s] 71%|███████   | 4696/6629 [00:15<00:06, 306.83it/s] 71%|███████▏  | 4727/6629 [00:15<00:06, 306.36it/s] 72%|███████▏  | 4758/6629 [00:15<00:06, 307.12it/s] 72%|███████▏  | 4790/6629 [00:15<00:05, 306.87it/s] 73%|███████▎  | 4821/6629 [00:15<00:05, 305.87it/s] 73%|███████▎  | 4852/6629 [00:16<00:05, 305.75it/s] 74%|███████▎  | 4883/6629 [00:16<00:05, 306.70it/s] 74%|███████▍  | 4914/6629 [00:16<00:05, 306.86it/s] 75%|███████▍  | 4945/6629 [00:16<00:05, 307.25it/s] 75%|███████▌  | 4976/6629 [00:16<00:05, 306.48it/s] 76%|███████▌  | 5007/6629 [00:16<00:05, 307.17it/s] 76%|███████▌  | 5038/6629 [00:16<00:05, 307.47it/s] 76%|███████▋  | 5069/6629 [00:16<00:05, 306.10it/s] 77%|███████▋  | 5100/6629 [00:16<00:04, 306.83it/s] 77%|███████▋  | 5131/6629 [00:16<00:04, 306.97it/s] 78%|███████▊  | 5162/6629 [00:17<00:04, 306.76it/s] 78%|███████▊  | 5193/6629 [00:17<00:04, 306.47it/s] 79%|███████▉  | 5224/6629 [00:17<00:04, 306.56it/s] 79%|███████▉  | 5255/6629 [00:17<00:04, 307.08it/s] 80%|███████▉  | 5286/6629 [00:17<00:04, 306.20it/s] 80%|████████  | 5317/6629 [00:17<00:04, 306.84it/s] 81%|████████  | 5348/6629 [00:17<00:04, 306.50it/s] 81%|████████  | 5379/6629 [00:17<00:04, 306.33it/s] 82%|████████▏ | 5410/6629 [00:17<00:03, 306.44it/s] 82%|████████▏ | 5442/6629 [00:17<00:03, 307.67it/s] 83%|████████▎ | 5473/6629 [00:18<00:03, 306.74it/s] 83%|████████▎ | 5504/6629 [00:18<00:03, 306.88it/s] 83%|████████▎ | 5535/6629 [00:18<00:03, 306.75it/s] 84%|████████▍ | 5566/6629 [00:18<00:03, 306.70it/s] 84%|████████▍ | 5597/6629 [00:18<00:03, 306.27it/s] 85%|████████▍ | 5628/6629 [00:18<00:03, 306.23it/s] 85%|████████▌ | 5659/6629 [00:18<00:03, 306.22it/s] 86%|████████▌ | 5690/6629 [00:18<00:03, 305.95it/s] 86%|████████▋ | 5721/6629 [00:18<00:02, 305.17it/s] 87%|████████▋ | 5752/6629 [00:18<00:02, 304.68it/s] 87%|████████▋ | 5783/6629 [00:19<00:02, 304.87it/s] 88%|████████▊ | 5814/6629 [00:19<00:02, 304.59it/s] 88%|████████▊ | 5845/6629 [00:19<00:02, 305.59it/s] 89%|████████▊ | 5876/6629 [00:19<00:02, 306.50it/s] 89%|████████▉ | 5907/6629 [00:19<00:02, 307.26it/s] 90%|████████▉ | 5938/6629 [00:19<00:02, 306.35it/s] 90%|█████████ | 5969/6629 [00:19<00:02, 305.08it/s] 91%|█████████ | 6000/6629 [00:19<00:02, 303.69it/s] 91%|█████████ | 6031/6629 [00:19<00:01, 301.27it/s] 91%|█████████▏| 6062/6629 [00:19<00:01, 302.60it/s] 92%|█████████▏| 6093/6629 [00:20<00:01, 302.87it/s] 92%|█████████▏| 6124/6629 [00:20<00:01, 304.14it/s] 93%|█████████▎| 6155/6629 [00:20<00:01, 304.13it/s] 93%|█████████▎| 6186/6629 [00:20<00:01, 304.00it/s] 94%|█████████▍| 6217/6629 [00:20<00:01, 303.85it/s] 94%|█████████▍| 6248/6629 [00:20<00:01, 304.37it/s] 95%|█████████▍| 6279/6629 [00:20<00:01, 305.50it/s] 95%|█████████▌| 6310/6629 [00:20<00:01, 306.09it/s] 96%|█████████▌| 6341/6629 [00:20<00:00, 306.71it/s] 96%|█████████▌| 6372/6629 [00:21<00:00, 307.36it/s] 97%|█████████▋| 6403/6629 [00:21<00:00, 307.03it/s] 97%|█████████▋| 6434/6629 [00:21<00:00, 305.94it/s] 98%|█████████▊| 6465/6629 [00:21<00:00, 304.86it/s] 98%|█████████▊| 6496/6629 [00:21<00:00, 305.46it/s] 98%|█████████▊| 6527/6629 [00:21<00:00, 305.83it/s] 99%|█████████▉| 6558/6629 [00:21<00:00, 305.95it/s] 99%|█████████▉| 6589/6629 [00:21<00:00, 301.34it/s]100%|█████████▉| 6620/6629 [00:21<00:00, 300.25it/s]100%|██████████| 6629/6629 [00:21<00:00, 303.29it/s]AVERAGE DENSITY :0.0
2022-03-23 18:55:08 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 18:55:08 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 18:55:08 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 18:55:08 | INFO | fairseq_cli.train | criterion: KneserNeySmoothingCriterion
2022-03-23 18:55:08 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 18:55:08 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 18:55:08 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 18:55:08 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 18:55:08 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 18:55:08 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 18:55:08 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 18:55:08 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 18:55:08 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 18:55:08 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 18:55:08 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 18:55:08 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_last.pt
2022-03-23 18:55:08 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_last.pt
2022-03-23 18:55:08 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 18:55:08 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 18:55:08 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 18:55:08 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 18:55:09 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 18:55:09 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 18:55:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 18:55:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 18:55:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 18:55:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 19:00:04 | INFO | train_inner | epoch 001:    104 / 157 loss=11.412, ppl=2724.36, wps=8854.9, ups=0.35, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=3.606, loss_scale=8, train_wall=294, gb_free=13.5, wall=295
2022-03-23 19:00:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 19:02:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/criterions/kneser_ney_smoothing.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  vals = torch.tensor(kl_stuff[hash("val")], device=torch.device("cuda"), dtype=torch.float16)
2022-03-23 19:02:34 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 19:02:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:02:39 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,.....
2022-03-23 19:02:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:02:44 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 19:02:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:02:49 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:02:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:02:56 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:02:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:03:04 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:03:04 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:03:11 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:03:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:03:19 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:03:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:03:27 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:03:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:03:30 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:03:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:03:30 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.669 | ppl 814.07 | bleu 0.01 | wps 2933.8 | wpb 17862.2 | bsz 728.3 | num_updates 152
2022-03-23 19:03:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 152 updates
2022-03-23 19:03:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 19:03:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 19:03:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 1 @ 152 updates, score 0.01) (writing took 0.8345245830714703 seconds)
2022-03-23 19:03:31 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 19:03:31 | INFO | train | epoch 001 | loss 10.958 | ppl 1988.85 | wps 7774.1 | ups 0.31 | wpb 25120.6 | bsz 980.6 | num_updates 152 | lr 1.9e-05 | gnorm 2.855 | loss_scale 4 | train_wall 440 | gb_free 22.4 | wall 502
2022-03-23 19:03:31 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 19:03:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:05:47 | INFO | train_inner | epoch 002:     48 / 157 loss=9.791, ppl=886.2, wps=7407.8, ups=0.29, wpb=25437.5, bsz=1087.6, num_updates=200, lr=2.5e-05, gnorm=1.42, loss_scale=4, train_wall=281, gb_free=13.7, wall=639
2022-03-23 19:10:24 | INFO | train_inner | epoch 002:    148 / 157 loss=9.078, ppl=540.56, wps=9028.4, ups=0.36, wpb=24962.3, bsz=943, num_updates=300, lr=3.75e-05, gnorm=1.527, loss_scale=4, train_wall=276, gb_free=20, wall=915
2022-03-23 19:10:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:10:51 | INFO | fairseq.tasks.translation | example hypothesis: we we we we we we.
2022-03-23 19:10:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:10:57 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the.
2022-03-23 19:10:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:11:04 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 19:11:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:11:10 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:11:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:11:18 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:11:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:11:26 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:11:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:11:33 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:11:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:11:41 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:11:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:11:50 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, "" "" "" "" "" "" "" "" ""
2022-03-23 19:11:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:11:53 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:11:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:11:53 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.675 | ppl 408.66 | bleu 0.01 | wps 2662.7 | wpb 17862.2 | bsz 728.3 | num_updates 309 | best_bleu 0.01
2022-03-23 19:11:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 309 updates
2022-03-23 19:11:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 19:11:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 19:11:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 2 @ 309 updates, score 0.01) (writing took 0.8295647413469851 seconds)
2022-03-23 19:11:54 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 19:11:54 | INFO | train | epoch 002 | loss 9.187 | ppl 582.87 | wps 7853.2 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 309 | lr 3.8625e-05 | gnorm 1.486 | loss_scale 4 | train_wall 435 | gb_free 13.5 | wall 1005
2022-03-23 19:11:54 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 19:11:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:16:05 | INFO | train_inner | epoch 003:     91 / 157 loss=8.713, ppl=419.71, wps=7277.6, ups=0.29, wpb=24808.2, bsz=976.5, num_updates=400, lr=5e-05, gnorm=1.439, loss_scale=4, train_wall=273, gb_free=12.9, wall=1256
2022-03-23 19:19:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:19:14 | INFO | fairseq.tasks.translation | example hypothesis: we the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:19:14 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:19:20 | INFO | fairseq.tasks.translation | example hypothesis: is is the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:19:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:19:26 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 19:19:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:19:32 | INFO | fairseq.tasks.translation | example hypothesis: it's's a, and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and it
2022-03-23 19:19:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:19:40 | INFO | fairseq.tasks.translation | example hypothesis: we we that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that.
2022-03-23 19:19:40 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:19:47 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:19:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:19:55 | INFO | fairseq.tasks.translation | example hypothesis: 's the the the the the the the, and the the the the the the the the, and and and the the the the the the the the the the the the the the the the the the the the the, and and and and and and the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:19:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:20:03 | INFO | fairseq.tasks.translation | example hypothesis: we we we the the the, and the the the the the the the the the the the the the the the the the the the the the the the the the the the the, and and and and and and and and and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:20:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:20:12 | INFO | fairseq.tasks.translation | example hypothesis: 's's, "" "" "" "" "" "" "" ""
2022-03-23 19:20:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:20:14 | INFO | fairseq.tasks.translation | example hypothesis: we we we a a a a a a a a, and the the the the the the the the the the, and the the the the the, and the the the the the the the the the the the the the the the, and the the the the the the the the the the the the, and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the, and and and and the the the the the the the the the the the the the the the the the the the the the the the, and that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that,
2022-03-23 19:20:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:20:14 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.445 | ppl 348.58 | bleu 0.04 | wps 2694.7 | wpb 17862.2 | bsz 728.3 | num_updates 466 | best_bleu 0.04
2022-03-23 19:20:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 466 updates
2022-03-23 19:20:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 19:20:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 19:20:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 3 @ 466 updates, score 0.04) (writing took 0.8758609918877482 seconds)
2022-03-23 19:20:15 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 19:20:15 | INFO | train | epoch 003 | loss 8.625 | ppl 394.85 | wps 7869.8 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 466 | lr 5.825e-05 | gnorm 1.577 | loss_scale 4 | train_wall 434 | gb_free 13.2 | wall 1507
2022-03-23 19:20:16 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 19:20:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:21:51 | INFO | train_inner | epoch 004:     34 / 157 loss=8.464, ppl=353.17, wps=7342.2, ups=0.29, wpb=25464, bsz=1090.9, num_updates=500, lr=6.25e-05, gnorm=1.526, loss_scale=4, train_wall=279, gb_free=13, wall=1603
2022-03-23 19:26:29 | INFO | train_inner | epoch 004:    134 / 157 loss=8.215, ppl=297.1, wps=9083.9, ups=0.36, wpb=25227.2, bsz=1021.3, num_updates=600, lr=7.5e-05, gnorm=1.581, loss_scale=4, train_wall=277, gb_free=13.8, wall=1881
2022-03-23 19:27:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:27:35 | INFO | fairseq.tasks.translation | example hypothesis: we're the world in the world.
2022-03-23 19:27:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:27:41 | INFO | fairseq.tasks.translation | example hypothesis: the world is the world is the world.
2022-03-23 19:27:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:27:47 | INFO | fairseq.tasks.translation | example hypothesis: we're're the world of the world of the world.
2022-03-23 19:27:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:27:52 | INFO | fairseq.tasks.translation | example hypothesis: , it's a way, and it's a way, and it's a way.
2022-03-23 19:27:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:27:59 | INFO | fairseq.tasks.translation | example hypothesis: it's not not not not not not not not not not not not not not not not not not.
2022-03-23 19:27:59 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:28:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world, and the world is the world of the world, and the world, and the world, and the world of the world of the world.
2022-03-23 19:28:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:28:13 | INFO | fairseq.tasks.translation | example hypothesis: it's not not not not not, but you can can can can can can can can can can can can can can can can can can can can can can can can can be be be be be be be be be be the world, but but but but it.
2022-03-23 19:28:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:28:21 | INFO | fairseq.tasks.translation | example hypothesis: we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see of the way, and we're the way of the world of the way of the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 19:28:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:28:29 | INFO | fairseq.tasks.translation | example hypothesis: "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 19:28:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:28:32 | INFO | fairseq.tasks.translation | example hypothesis: , we have to have the world, which we have to can can can can can can can can can can can can can can can can can can can can can can can can be be be be be be be be be the world, which which which which is the world of the world, and it's the world, which which is the world, which we're the world of the world, which we're're be be be be be be be be be the world of the world, which which is the world, which we're're the world, and we're be be be be be be be be be be be be world, and we're're're be be be be be be be be be be be be be be be be be be be be be be be be be be be be the world, and it's the world, which which which which which which which which which which which we have to be, and we can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 19:28:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:28:32 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.797 | ppl 222.47 | bleu 0.94 | wps 2900.5 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 0.94
2022-03-23 19:28:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-23 19:28:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 19:28:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 19:28:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 4 @ 623 updates, score 0.94) (writing took 0.8704134952276945 seconds)
2022-03-23 19:28:33 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 19:28:33 | INFO | train | epoch 004 | loss 8.229 | ppl 300.02 | wps 7941.3 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 623 | lr 7.7875e-05 | gnorm 1.505 | loss_scale 4 | train_wall 434 | gb_free 13.4 | wall 2004
2022-03-23 19:28:33 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 19:28:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:32:02 | INFO | train_inner | epoch 005:     77 / 157 loss=7.923, ppl=242.61, wps=7350.9, ups=0.3, wpb=24464.6, bsz=968, num_updates=700, lr=8.75e-05, gnorm=1.976, loss_scale=4, train_wall=270, gb_free=14.6, wall=2214
2022-03-23 19:35:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:35:55 | INFO | fairseq.tasks.translation | example hypothesis: we have in the world in the world in the world in the world.
2022-03-23 19:35:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:36:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most of the most of the world.
2022-03-23 19:36:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:36:09 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go to be the two of the way of the two of the way of the way of the way of the way.
2022-03-23 19:36:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:36:16 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the world, and it's a lot of the world, and it's a lot of the way, and it's a lot of the way, and it's a lot of it
2022-03-23 19:36:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:36:24 | INFO | fairseq.tasks.translation | example hypothesis: this is that we're going to do that we're not not not not not not not not going to be a lot of the world of the world of the world of the way of the way of the way of the way of the way of
2022-03-23 19:36:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:36:32 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of the lot of the world, and the world of the world, and the way of the world, and the way of the world, and the way of the world of the world, and the world of the world, and the world, and the world of the world
2022-03-23 19:36:32 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:36:40 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the lot of the lot of the way, but they're not not not not not not not not not not not not not not not a lot of the lot of the lot of the lot of the lot of the lot of the way of the way of the way, but they can't have to have to be a lot of the
2022-03-23 19:36:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:36:48 | INFO | fairseq.tasks.translation | example hypothesis: we can have a lot of the lot of the way that we can see that we can have a lot of the world, and we can have a lot of the world, and we can see that we can see that we can see the way of the lot of the lot of the way of the way of the way of the world, and we can see the way of the way of the way that we can see that we can see that we can see that we
2022-03-23 19:36:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:36:57 | INFO | fairseq.tasks.translation | example hypothesis: , it's a lot of the way, and it's a lot of the way, "it's a lot of the way," it's a lot of the way, "it's a lot of the way," it's a lot of the way, and it's a lot of the way, "it's a lot of the way, and it's a lot of the way," it's a lot of the way, and it's a lot of the way, "it's a lot of the way, and it's a lot of the way," it's a lot of the way, "it's a lot of the way, and it's a lot of the way," it's a lot of the way, "it's a lot of the way, and it's a lot of the way, and it's a lot of the way, and it,"
2022-03-23 19:36:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:37:00 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the lot of the way that we have to be a lot of the way that we can't have a lot of the way that we can't have a lot of the way that that we have to be a lot of the way of the way of the way that that we have a lot of the way that that we have to be a lot of the way that that we have a lot of the way that that we have to be a lot of the way of the way that that we have to be a lot of the way that that that that that that we can't have a lot of the lot of the way that we can't have to be a lot of the way that that we can't have a lot of the way that that that that that that that that that that that that that that it, and it's a lot of the way of the way of the way of the way of the way of the way that that that that, and the way of the way of the way to be a lot of the way that that
2022-03-23 19:37:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:37:00 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.391 | ppl 167.9 | bleu 1.06 | wps 2515.1 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.06
2022-03-23 19:37:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 19:37:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 19:37:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 19:37:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.06) (writing took 0.901628578081727 seconds)
2022-03-23 19:37:01 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 19:37:01 | INFO | train | epoch 005 | loss 7.728 | ppl 212.03 | wps 7772.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 1.845 | loss_scale 4 | train_wall 435 | gb_free 13.6 | wall 2512
2022-03-23 19:37:01 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 19:37:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:37:55 | INFO | train_inner | epoch 006:     20 / 157 loss=7.609, ppl=195.24, wps=7200.3, ups=0.28, wpb=25435.1, bsz=1018.2, num_updates=800, lr=0.0001, gnorm=1.787, loss_scale=4, train_wall=280, gb_free=12.2, wall=2567
2022-03-23 19:42:34 | INFO | train_inner | epoch 006:    120 / 157 loss=7.322, ppl=160.02, wps=9074.3, ups=0.36, wpb=25302.4, bsz=1024.5, num_updates=900, lr=0.0001125, gnorm=1.635, loss_scale=4, train_wall=278, gb_free=13.6, wall=2846
2022-03-23 19:44:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:44:22 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see this.
2022-03-23 19:44:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:44:28 | INFO | fairseq.tasks.translation | example hypothesis: here's here here here here's the most of the world.
2022-03-23 19:44:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:44:34 | INFO | fairseq.tasks.translation | example hypothesis: we're new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 19:44:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:44:41 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the world, and it's a lot of the world, and it's a lot of it's going to be a lot, and it's going to be there.
2022-03-23 19:44:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:44:48 | INFO | fairseq.tasks.translation | example hypothesis: what we're going to do that we're not not going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do it's not not going
2022-03-23 19:44:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:44:56 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of people who are in the world, and people are the people for the world, and people for the world, and people for the world for the world, and people for the people people people people people are the people people people people people people people people people people people people
2022-03-23 19:44:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:45:05 | INFO | fairseq.tasks.translation | example hypothesis: if you're going to be going to be not not going to be, but they're going to be going to be going to be a lot of the world, but they're going to be going to be going to be going to be able to be able to be able to be a lot of the world, but they're going to be, but they
2022-03-23 19:45:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:45:13 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see that we're going to make the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to make the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world
2022-03-23 19:45:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:45:22 | INFO | fairseq.tasks.translation | example hypothesis: i said, "" you know, "you know," you're going to say, "you know," you know, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "" you're going to say, "you're going to say," "you're going to say," "" "" "" "" you're going to say, "" "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "" "" "you're going to say," "" "" "" "
2022-03-23 19:45:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:45:25 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to see that we're going to be a lot of the world, and we're going to be a lot of the world, we're going to be a lot of the world that we're going to be a lot of the world, and we're going to be that we're going to see that we're going to be a lot of the world that we're going to be a lot of the world that we're going to see the world that we're going to be going to see that we're going to see that we're going to see that we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be that we're going to see the world that we're going to see the world, and we're going to have to see that we're going to see the world, and we're going to be a lot of the world,
2022-03-23 19:45:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:45:25 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.982 | ppl 126.45 | bleu 1.39 | wps 2598.2 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.39
2022-03-23 19:45:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 19:45:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 19:45:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 19:45:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.39) (writing took 0.9172451342456043 seconds)
2022-03-23 19:45:26 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 19:45:26 | INFO | train | epoch 006 | loss 7.313 | ppl 159.01 | wps 7822.1 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.65 | loss_scale 4 | train_wall 435 | gb_free 14.3 | wall 3017
2022-03-23 19:45:26 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 19:45:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:48:19 | INFO | train_inner | epoch 007:     63 / 157 loss=7.081, ppl=135.42, wps=7286.8, ups=0.29, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.417, loss_scale=4, train_wall=275, gb_free=14.4, wall=3191
2022-03-23 19:52:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:52:44 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see this.
2022-03-23 19:52:44 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:52:50 | INFO | fairseq.tasks.translation | example hypothesis: here's the first idea of the first idea of the first thing that is here.
2022-03-23 19:52:50 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:52:57 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be new new new new new new new new new new new new new new new new new new new new new new new.
2022-03-23 19:52:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:53:04 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot, and it's going to be a lot, and it's going to be a lot of the brain.
2022-03-23 19:53:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:53:11 | INFO | fairseq.tasks.translation | example hypothesis: what we're going to do is that we're going to do, and we're going to do that we're going to do that we're going to do it, and we're going to do that we're going to be going to do
2022-03-23 19:53:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:53:18 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of people, and it's a lot of people, and it's a lot of people, and it's the people who's a lot of people, and people in the people, and people, and people in the people, and people.
2022-03-23 19:53:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:53:26 | INFO | fairseq.tasks.translation | example hypothesis: if you're going to look at a lot of the way, but you're going to get a lot of them, but they're going to get a lot of the same way, but they're going to be able to be able to be able to be able, but they're going to be able to be able, but they're going to be able
2022-03-23 19:53:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:53:34 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see that, and then we can get a lot of the brain, and we can see the brain, and we can see the brain, and we can see the brain, and we can see the brain, and we can see the brain.
2022-03-23 19:53:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:53:43 | INFO | fairseq.tasks.translation | example hypothesis: you can say, "you know," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," and then you're going to say, "and then you're going to say," and then you're going to say, "and then you're going to say," and then you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," and then you're going to say, "" "
2022-03-23 19:53:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:53:46 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see that, and then we're going to get a lot of the world, and then we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the world, and then that, and then that we're going to be able to be a lot of the world, and then it, and then we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 19:53:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:53:46 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.725 | ppl 105.77 | bleu 1.83 | wps 2673.3 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 1.83
2022-03-23 19:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 19:53:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 19:53:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 19:53:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 1.83) (writing took 0.9009348899126053 seconds)
2022-03-23 19:53:46 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 19:53:46 | INFO | train | epoch 007 | loss 6.998 | ppl 127.81 | wps 7884.6 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.516 | loss_scale 4 | train_wall 432 | gb_free 14 | wall 3518
2022-03-23 19:53:47 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 19:53:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:54:02 | INFO | train_inner | epoch 008:      6 / 157 loss=6.935, ppl=122.34, wps=7293, ups=0.29, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=1.543, loss_scale=4, train_wall=275, gb_free=13.9, wall=3534
2022-03-23 19:58:39 | INFO | train_inner | epoch 008:    106 / 157 loss=6.704, ppl=104.27, wps=9126.5, ups=0.36, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=1.511, loss_scale=4, train_wall=276, gb_free=14.2, wall=3810
2022-03-23 20:01:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:01:06 | INFO | fairseq.tasks.translation | example hypothesis: we put this in this.
2022-03-23 20:01:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:01:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most of the most of the most most of the most of the most of the most of the most of the most most.
2022-03-23 20:01:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:01:18 | INFO | fairseq.tasks.translation | example hypothesis: this is new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 20:01:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:01:26 | INFO | fairseq.tasks.translation | example hypothesis: it's an example where it's like that it's like the water, and it's like the water, and it's an ununununununeeeeeeeeee
2022-03-23 20:01:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:01:33 | INFO | fairseq.tasks.translation | example hypothesis: it's not what we're going to do is that we're going to do that we're not going to do that we're going to do that we're going to do that we're not going to do that we're going to do it
2022-03-23 20:01:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:01:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the people in the people in the most people who are in the people in the most people who are in the people in the most people who are in the people in the people in the most people who are in the people in the people in the most people who are in the people who
2022-03-23 20:01:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:01:49 | INFO | fairseq.tasks.translation | example hypothesis: some of you can see it, but it's a lot of the same way, but they're not like that they're going to see, but they're going to see, but they're going to see the same, but they're not like the same, but they're going to see, but it, but they're so they're going to get
2022-03-23 20:01:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:01:57 | INFO | fairseq.tasks.translation | example hypothesis: if we can take the brain, we can take the brain, we can use the brain, and we can take the brain, the brain, the brain, we can take the brain, and we can use the brain, and we can use the brain, the brain, and we can use the brain, and we can use the brain, we can take the brain, the brain, the brain, the brain, the brain, the brain, the brain, the
2022-03-23 20:01:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:02:07 | INFO | fairseq.tasks.translation | example hypothesis: in fact, if you say, "you know," "you know," "" the first first thing, "you can say," you know, "you know," you know, "you know," you know, "you know," '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '"
2022-03-23 20:02:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:02:09 | INFO | fairseq.tasks.translation | example hypothesis: in the fact, if we're going to see the most of the same way that we're going to make a, we're going to see the same way that we're going to see the same way that we're going to see the most of the most of the most of the world, which is that we're going to see the most of the most of the world, we're going to see the most of the world, which is that we're going to see the most of the most of the most of the world, which is that we're going to see that we're going to see the most of the most most most of the most of the most of the most of the world, and we're going to see that we're going to see the most of the most of the most of the world, which is that we're going to see that we're going to see that we're going to see that we're going to see that we're going to get to see that we're going to see that we're going to make a, and
2022-03-23 20:02:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:02:09 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.464 | ppl 88.28 | bleu 2.35 | wps 2587.8 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 2.35
2022-03-23 20:02:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 20:02:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 2.35) (writing took 0.9193666847422719 seconds)
2022-03-23 20:02:10 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 20:02:10 | INFO | train | epoch 008 | loss 6.756 | ppl 108.07 | wps 7842.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.432 | loss_scale 4 | train_wall 433 | gb_free 13.1 | wall 4022
2022-03-23 20:02:10 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 20:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:04:30 | INFO | train_inner | epoch 009:     49 / 157 loss=6.674, ppl=102.12, wps=7308.9, ups=0.28, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=1.398, loss_scale=4, train_wall=281, gb_free=14.5, wall=4161
2022-03-23 20:09:02 | INFO | train_inner | epoch 009:    149 / 157 loss=6.492, ppl=90.01, wps=9115.9, ups=0.37, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=1.428, loss_scale=4, train_wall=272, gb_free=13.9, wall=4434
2022-03-23 20:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:09:29 | INFO | fairseq.tasks.translation | example hypothesis: we found these in this room, we went on the top of the earth.
2022-03-23 20:09:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:09:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most most of the most most most most most of the most most most most of the most most most most most most.
2022-03-23 20:09:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:09:41 | INFO | fairseq.tasks.translation | example hypothesis: this new new new new new new new new new new new new new new new new new new new new are going to be two.
2022-03-23 20:09:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:09:48 | INFO | fairseq.tasks.translation | example hypothesis: there's an example of example, there's an example where you're going to see where you're going to see where you're going to see where it's going to see.
2022-03-23 20:09:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:09:55 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just just just just just a little bit of what we're going to do.
2022-03-23 20:09:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:10:02 | INFO | fairseq.tasks.translation | example hypothesis: in the people like people like people in the people in the people in the people, and the people in the people who are in the people in the people in the people in the people, and then it's going to be a few people for people in the people in the people in the people
2022-03-23 20:10:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:10:10 | INFO | fairseq.tasks.translation | example hypothesis: some of some of some of some of some of some of some of some of the things, but it's not, but if you can't get it, but it's the same time, but it's the same time, but it's the same time, but it's not the same time, but it's the same time, but it's not
2022-03-23 20:10:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:10:18 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to use the information that we're going to use these things that we can see the information that we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that we can be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 20:10:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:10:27 | INFO | fairseq.tasks.translation | example hypothesis: one of the one one one one of the one one of the one of the world, "it's going to say," you know, "you know," you know, "it's going to say," well, "well," well, "you know," well, "well," you know, "well," you're going to say, "" "you know," you know, "you know," "" "" "" you know, "well," it's the first first time, "you know," you know, "you're going to say," you know, "you know," you're going to say, "you're going to say," you know, "you know," well, "it's the first one of the first one of the first one of the" "" "" "" "
2022-03-23 20:10:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:10:30 | INFO | fairseq.tasks.translation | example hypothesis: then it's still still still still that the same time that we're going to have a lot of the world that we could have a lot of the world that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to the most of the world that we have a lot of the world, and then we have a lot of the world, and then we have a
2022-03-23 20:10:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:10:30 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.129 | ppl 69.96 | bleu 3.52 | wps 2685.1 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 3.52
2022-03-23 20:10:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 20:10:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:10:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:10:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 3.52) (writing took 0.9144786261022091 seconds)
2022-03-23 20:10:31 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 20:10:31 | INFO | train | epoch 009 | loss 6.49 | ppl 89.87 | wps 7884.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.46 | loss_scale 4 | train_wall 432 | gb_free 14.2 | wall 4522
2022-03-23 20:10:31 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 20:10:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:14:46 | INFO | train_inner | epoch 010:     92 / 157 loss=6.266, ppl=76.96, wps=7302.1, ups=0.29, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=1.399, loss_scale=4, train_wall=275, gb_free=13.8, wall=4777
2022-03-23 20:17:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:17:50 | INFO | fairseq.tasks.translation | example hypothesis: we did this in this room.
2022-03-23 20:17:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:17:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the name, the most of the most most most of the most most most.
2022-03-23 20:17:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:18:02 | INFO | fairseq.tasks.translation | example hypothesis: they're going to be new new new new new new new new new new york.
2022-03-23 20:18:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:18:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese, where you're going to go.
2022-03-23 20:18:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:18:14 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just just just just a little bit of his eyes, and what's going on.
2022-03-23 20:18:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:18:20 | INFO | fairseq.tasks.translation | example hypothesis: in the sun, people like the people who are used for the people for the people for the people, and that's a few years.
2022-03-23 20:18:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:18:27 | INFO | fairseq.tasks.translation | example hypothesis: some of these are some of the brain, but if you're not able to use the same energy, but if you don't get the energy, you don't get the energy, if you don't get the energy, if you don't get the energy, it, if you don't get the energy, it, you don't get the energy,
2022-03-23 20:18:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:18:35 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to use the information, we can use this information, we can use the brain, and we can use the brain with a light, and we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 20:18:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:18:44 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reasons, and it's really interesting about this, and it's really interesting for me, and then it's the first time, and then we're going to talk about the first time, and then you're going to talk about the first time, and then you're going to talk about the first time to be able to talk about the first time to be able to talk about the first time, and then you're going to talk about this is, and then we're going to be able to talk about the first time, and then you're going to talk about this is, and then you're going to talk about the first time to talk about this is, and then you're going to talk about the first time, and then you're going to talk about the first time with a little bit about this is, and then you're going to talk about the first time, and then
2022-03-23 20:18:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:18:46 | INFO | fairseq.tasks.translation | example hypothesis: then, it's always always always always been a lot of the mother, and then we're going to get a little bit of the world, and if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a
2022-03-23 20:18:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:18:46 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.724 | ppl 52.87 | bleu 5.76 | wps 2905 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 5.76
2022-03-23 20:18:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 20:18:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:18:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:18:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 5.76) (writing took 0.9113876069895923 seconds)
2022-03-23 20:18:47 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 20:18:47 | INFO | train | epoch 010 | loss 6.164 | ppl 71.68 | wps 7957.8 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.391 | loss_scale 4 | train_wall 432 | gb_free 13.3 | wall 5019
2022-03-23 20:18:47 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 20:18:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:20:22 | INFO | train_inner | epoch 011:     35 / 157 loss=6.071, ppl=67.22, wps=7397, ups=0.3, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=1.46, loss_scale=4, train_wall=272, gb_free=13, wall=5114
2022-03-23 20:25:01 | INFO | train_inner | epoch 011:    135 / 157 loss=5.828, ppl=56.8, wps=9154.8, ups=0.36, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=1.448, loss_scale=4, train_wall=279, gb_free=12.9, wall=5393
2022-03-23 20:26:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:26:06 | INFO | fairseq.tasks.translation | example hypothesis: we found this in the center.
2022-03-23 20:26:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:26:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the most ha ha, most most most most most most most most most most most most here.
2022-03-23 20:26:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:26:17 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be able to take new new new new new new technologies.
2022-03-23 20:26:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:26:23 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an chinese chinese chinese, where they're going to get a pocks, and it's going to be called.
2022-03-23 20:26:23 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:26:30 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just just a few few years on his head, and what's going to do.
2022-03-23 20:26:30 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:26:36 | INFO | fairseq.tasks.translation | example hypothesis: in fact, how people are the most people for the number of the number of animals, and the number of the number of the people.
2022-03-23 20:26:36 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:26:42 | INFO | fairseq.tasks.translation | example hypothesis: some of some of you are made from the water, but if you don't need to use the energy, if you don't need to use the energy, if you don't need the energy, you need to get the energy, it.
2022-03-23 20:26:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:26:48 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to use information that we can use this structure, we can use a structure of the structure, and the structure of the structure of the structure that are able to be able to be able to be able to be able to be able to be able to be able to be able to change the structure of the structure.
2022-03-23 20:26:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:26:55 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons, it's interesting, and it's interesting for me to talk to me, "why we're going to say," well, "if you're going to say," you know, "you know," well, "you know," well, "well," well, "well," well, "you know," you know, "you know," you know, "you know," well, "well," well, "well," you know, "well," well, "you know," well, "well," well, "well," you know, "well," well, "well," you know, "you know," you know, "you know," you know, "you know," well, "you know," well, "well," well, "well,"
2022-03-23 20:26:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:26:57 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still still the mother, and a lot of work that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 20:26:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:26:57 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.43 | ppl 43.12 | bleu 8.49 | wps 3209.4 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 8.49
2022-03-23 20:26:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 20:26:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:26:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:26:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 8.49) (writing took 0.8857411481440067 seconds)
2022-03-23 20:26:58 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 20:26:58 | INFO | train | epoch 011 | loss 5.895 | ppl 59.52 | wps 8048 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.467 | loss_scale 4 | train_wall 432 | gb_free 13.6 | wall 5509
2022-03-23 20:26:58 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 20:26:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:30:34 | INFO | train_inner | epoch 012:     78 / 157 loss=5.702, ppl=52.06, wps=7510, ups=0.3, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=1.414, loss_scale=4, train_wall=275, gb_free=13.5, wall=5725
2022-03-23 20:34:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:34:18 | INFO | fairseq.tasks.translation | example hypothesis: we did this machine in the clinics.
2022-03-23 20:34:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:34:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the key point of ha ha, most most most most most most most of the most most most.
2022-03-23 20:34:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:34:30 | INFO | fairseq.tasks.translation | example hypothesis: these new stars are going to be two ways of the new new new new new york.
2022-03-23 20:34:30 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:34:36 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an chinese chinese chinese chinese chinese chinese chinese chinese, where they're going to put it, and they're going to get it.
2022-03-23 20:34:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:34:43 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just just just just a few of his head on his head, and what's going to understand.
2022-03-23 20:34:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:34:49 | INFO | fairseq.tasks.translation | example hypothesis: in fact, the mamamamats of the ability for humans, the number of animals, the number of animals, and this is a number of animals in order to build a viiiiiiiiiiiiiiiiiiiiii
2022-03-23 20:34:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:34:56 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of you're going to look at the pattern, but if you don't need to use it, if you don't need the energy, you need to use your energy, and you need to use your energy.
2022-03-23 20:34:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:35:02 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, we can use this information, we can take a huge structure of the structure, we can use the structure of the structure, and all the structure of the structure, and all the structure of the structure, and all the information is all the information.
2022-03-23 20:35:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:35:09 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons it's interesting, and it's interesting for me to be talking about women, "then we're talking about women who said," if we said, "well," if you're talking about this time, "and then we said," well, "if you're talking about this is the first time," well, "you're talking about this is that we're going to love to you're talking about the women," and then you're talking about this is that we're going to love, "oh," oh, "oh," and then you're talking about this is that we're talking about the women's going to you're going to you're going to you're going to talk to talk to you're talking about the first time, "and then you're talking about this is that we're talking about this is that women," and then, "
2022-03-23 20:35:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:35:12 | INFO | fairseq.tasks.translation | example hypothesis: finally, it's still still the mother of the invention, and a huge design part of the work that we had to use a little bit of the energy, and if we had to use it, we had to use it into a huge system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to create a
2022-03-23 20:35:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:35:12 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 5.073 | ppl 33.66 | bleu 9.99 | wps 3038 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 9.99
2022-03-23 20:35:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 20:35:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:35:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:35:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 9.99) (writing took 1.0296969399787486 seconds)
2022-03-23 20:35:13 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 20:35:13 | INFO | train | epoch 012 | loss 5.55 | ppl 46.85 | wps 7981.8 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.417 | loss_scale 4 | train_wall 433 | gb_free 13.7 | wall 6004
2022-03-23 20:35:13 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 20:35:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:36:10 | INFO | train_inner | epoch 013:     21 / 157 loss=5.399, ppl=42.2, wps=7469.9, ups=0.3, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=1.492, loss_scale=4, train_wall=275, gb_free=13.4, wall=6061
2022-03-23 20:40:48 | INFO | train_inner | epoch 013:    121 / 157 loss=5.265, ppl=38.46, wps=9103.4, ups=0.36, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=1.362, loss_scale=4, train_wall=277, gb_free=13.1, wall=6339
2022-03-23 20:42:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:42:32 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppon the clinics.
2022-03-23 20:42:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:42:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the helidoha, the most most most most most most of the most.
2022-03-23 20:42:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:42:44 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to get two pounds of orores.
2022-03-23 20:42:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:42:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese chinese food, where they're going to be able.
2022-03-23 20:42:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:42:55 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just a couple of electrodes on his head, and what's going on on your mind.
2022-03-23 20:42:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:43:01 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamamamamamacy, the responsibility for the number of animals, and that's a number of reducing, and that has been done in iiiiibia.
2022-03-23 20:43:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:43:07 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you're able to go through the microscope lines, but it doesn't need your energy energy, if you don't need the energy energy and the energy.
2022-03-23 20:43:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:43:13 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, we can use this information, we can look at a traditional sphere, we can start with a huge shape of the structure, and the structure of the structure of the structure, and all the structure of the structure.
2022-03-23 20:43:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:43:19 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons, it's interesting, and interesting for example, for example, for example, for women, "oh," oh, "oh," if we say, "you're going to say," well, "if you're going to say," you've got to say, "well," well, "well," well, "you'll say," you've got a long time to say, "well," you're going to say, "well," you're going to say, "well," well, "you're going to say," well, "you've got to say," you've got a long time to say, "well," you've got to say, "you know," you've got to say, "you've got a third third third third time to say," you've got to say, "
2022-03-23 20:43:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:43:20 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still still the mother of the invention, and part of our work, we had to solve the airplane, a unique system that we had to use it to be able to be able to be able to be able to be able to use it.
2022-03-23 20:43:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:43:20 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.788 | ppl 27.62 | bleu 12.35 | wps 3409.1 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 12.35
2022-03-23 20:43:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 20:43:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:43:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:43:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 12.35) (writing took 0.8757699062116444 seconds)
2022-03-23 20:43:21 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 20:43:21 | INFO | train | epoch 013 | loss 5.233 | ppl 37.61 | wps 8086 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.373 | loss_scale 4 | train_wall 433 | gb_free 13 | wall 6493
2022-03-23 20:43:21 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 20:43:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:46:17 | INFO | train_inner | epoch 014:     64 / 157 loss=5.073, ppl=33.66, wps=7569.9, ups=0.3, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=1.332, loss_scale=4, train_wall=274, gb_free=13.6, wall=6669
2022-03-23 20:50:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:50:41 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppppine in the clinics.
2022-03-23 20:50:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:50:47 | INFO | fairseq.tasks.translation | example hypothesis: that's the car line of doha, ha, the most most of the most of you know.
2022-03-23 20:50:47 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:50:53 | INFO | fairseq.tasks.translation | example hypothesis: these are new stars going to create new dines that are going to get two new forces.
2022-03-23 20:50:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:50:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese chinese chinese chinese chinese food, where they're going to be checking and get rid of it.
2022-03-23 20:50:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:51:05 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just have a few electromagnetic electrodes on his head, and what all the thoughts are on the mind.
2022-03-23 20:51:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:51:12 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamace of people like the responsibility of responsibility, the number of animals, and the number of animals have become a lot of conservation.
2022-03-23 20:51:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:51:18 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the magnetic magnetic magnetic magnetic lines in the lines, but if you don't need to move the energy, if you need your energy, and you need to take the energy.
2022-03-23 20:51:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:51:24 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, the information reflection of this reflection, we can actually start with a traditional traditional symphony, we can start to start with a natural structure, and all the structure of the structure.
2022-03-23 20:51:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:51:30 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reasons it's interesting, and interesting, and it's interesting for me to be here for tedtedtalks about women, "if we've been talking to you're talking about this stage," and then we're talking to you're talking about the truth. "
2022-03-23 20:51:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:51:32 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, the mother's mother's mother, the invention of the invention of the design, and we had to see that if we had to use a huge solution to make a natural system, and if you're able to use it to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use a conconstructive with a conconstructive with a conconstructive.
2022-03-23 20:51:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:51:32 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.563 | ppl 23.64 | bleu 14.52 | wps 3228.7 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 14.52
2022-03-23 20:51:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 20:51:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:51:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:51:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 14.52) (writing took 0.9316564183682203 seconds)
2022-03-23 20:51:33 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 20:51:33 | INFO | train | epoch 014 | loss 4.907 | ppl 30 | wps 8031.9 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.303 | loss_scale 4 | train_wall 433 | gb_free 13.3 | wall 6984
2022-03-23 20:51:33 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 20:51:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:51:55 | INFO | train_inner | epoch 015:      7 / 157 loss=4.777, ppl=27.42, wps=7557.6, ups=0.3, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=1.21, loss_scale=4, train_wall=280, gb_free=13.4, wall=7007
2022-03-23 20:56:30 | INFO | train_inner | epoch 015:    107 / 157 loss=4.635, ppl=24.85, wps=9142.8, ups=0.36, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=1.319, loss_scale=4, train_wall=275, gb_free=13.5, wall=7282
2022-03-23 20:58:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:58:52 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppills in the clinics.
2022-03-23 20:58:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:58:58 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha ha, which most of you know.
2022-03-23 20:58:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:59:04 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new dindindines that make two new clients.
2022-03-23 20:59:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:59:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food food, where the legs are shaped with legs, and they're going to be salt.
2022-03-23 20:59:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:59:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just get a few electrodes on his head and understand what all your thoughts are on your mind.
2022-03-23 20:59:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:59:23 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamamaa, like the responsibility of responsibility, grew up to the number of animals, and this is a number of conservation for conservaiiiibia.
2022-03-23 20:59:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:59:29 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the magnetic magnetic magnetic lines in the lines, but it doesn't like the alalalalalalable energy, if you're going to move your energy, you need your energy, and you need your energy.
2022-03-23 20:59:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:59:36 | INFO | fairseq.tasks.translation | example hypothesis: if we use information that comes from this reflect reflect reflection, we can start with a traditional face of traditional faces, we can start able to start with a big shape of the shape of the information, and the information that gives you all the structure of the structure.
2022-03-23 20:59:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:59:42 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting, and interesting, for example, for example, for example, is that women are working at tedh -- is that when the best time was going to say, "oh," oh, when we're going to ask you're working with a long time. "
2022-03-23 20:59:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:59:45 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still still the invention of the invention of the invention, and one part of our work on the airplane, we had to solve a unique problem, which was that if we had to use a unique amount of power, or if we were able to use the power of the power of the power of the engine, it's a super-of-of-of-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-craft system, which is that it is that it is that we're still used to use, if you can see that it is that if you can use, if you can use, if you're still use, if you're used to use, if you're going to see that it's a lot of a lot of a lot of the power
2022-03-23 20:59:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:59:45 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.231 | ppl 18.77 | bleu 16.08 | wps 3122 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 16.08
2022-03-23 20:59:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 20:59:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:59:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 20:59:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 16.08) (writing took 0.8258339143358171 seconds)
2022-03-23 20:59:45 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 20:59:45 | INFO | train | epoch 015 | loss 4.661 | ppl 25.3 | wps 8012.7 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 1.277 | loss_scale 4 | train_wall 433 | gb_free 13.3 | wall 7477
2022-03-23 20:59:46 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 20:59:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:02:10 | INFO | train_inner | epoch 016:     50 / 157 loss=4.649, ppl=25.09, wps=7484.7, ups=0.29, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=1.23, loss_scale=4, train_wall=280, gb_free=13.8, wall=7622
2022-03-23 21:06:41 | INFO | train_inner | epoch 016:    150 / 157 loss=4.297, ppl=19.66, wps=9119.8, ups=0.37, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=1.128, loss_scale=4, train_wall=270, gb_free=14, wall=7892
2022-03-23 21:07:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:07:05 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in clinics.
2022-03-23 21:07:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:07:11 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which most of you know.
2022-03-23 21:07:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:07:16 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new dinburgh.
2022-03-23 21:07:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:07:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where happy legs are going to be posted with legs.
2022-03-23 21:07:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:07:28 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head, and understand what all the thoughts are.
2022-03-23 21:07:28 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:07:33 | INFO | fairseq.tasks.translation | example hypothesis: in the mamacy, the responsibility for the wild, grew up with the number of animals. and this is a foundation for conservation.
2022-03-23 21:07:33 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:07:39 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic lines in the field, but the superconductor doesn't move if they don't move their energy, if they need their energy, they need their energy, and then they need their energy.
2022-03-23 21:07:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:07:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection, we can start with a traditional face, we can start able to begin with a traditional face of the face of the face of the face, and then the shape of the face of the shape of the shape of the shape of the shape.
2022-03-23 21:07:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:07:51 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons we have interesting and measure for tedny. "
2022-03-23 21:07:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:07:52 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still able to use the invention, and a lot of design that we're doing on our airplane.
2022-03-23 21:07:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:07:52 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.149 | ppl 17.74 | bleu 13.03 | wps 3502.2 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 16.08
2022-03-23 21:07:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 21:07:52 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 21:07:52 | INFO | train | epoch 016 | loss 4.38 | ppl 20.81 | wps 8117.5 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 1.188 | loss_scale 4 | train_wall 433 | gb_free 13.6 | wall 7964
2022-03-23 21:07:52 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 21:07:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:12:12 | INFO | train_inner | epoch 017:     93 / 157 loss=4.205, ppl=18.44, wps=7624.5, ups=0.3, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=1.223, loss_scale=4, train_wall=279, gb_free=14.5, wall=8224
2022-03-23 21:15:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:15:13 | INFO | fairseq.tasks.translation | example hypothesis: we made this pink in the clinic clinics on the clinics.
2022-03-23 21:15:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:15:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably knows most of you here.
2022-03-23 21:15:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:15:25 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gulf dindindindindindines that are going to create two new trucks.
2022-03-23 21:15:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:15:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food food food food, where happy legs and fat.
2022-03-23 21:15:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:15:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head, and understand what all the thoughts on the ground are.
2022-03-23 21:15:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:15:45 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamaa, like the responsibility for the wild, grew up to the number of animals, and this is a foundation for conservation in namibia.
2022-03-23 21:15:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:15:51 | INFO | fairseq.tasks.translation | example hypothesis: first of the first, some of magnetic magnetic fields, but the sullant lines in the field, and the energy, if you don't need to move your energy, and you need to move the energy of electrode.
2022-03-23 21:15:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:15:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection reflection reflection reflection, we can start with a traditional face of the face, and the information that gives it through the whole structure, the whole structure of the structure, and the whole structure of the structure, the structure of the structure, the structure of the structure, the structure, the structure, the structure of this structure of reflect is reflection of this reflection, the structure
2022-03-23 21:15:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:16:07 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting for me and measure them, "then for example, when we're going to say," when we're going to support them, "and then," if we've been talking about them, "when we're working on a table," then we're working with you've been working on the game, "and then we've got a long time to help you're working with you're working with them," and then we've got a long time for you're working on the game, "oh," and then we've been working on the fact, "and then we've been working on the fact," and then you're working on a long time, "for you're working with you're working on a long time," for you're working with you're talking about it's a long time, "and then we've got
2022-03-23 21:16:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:16:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, need to still see the mother's invention, and a big part of the design that we've had to see is that we had to solve a unique result of the problems that we had to solve in the ground, if we had to put it into the ground, it's actually connected to the power of the engine, the engine, and if you can actually use the engine, if you can actually use to see that the engine, if you can use the engine, it to see that the engine, the engine, the engine, the engine, the engine, if you're actually use of a large, the engine, the engine, the engine, the engine, the engine, if you can use of a large, the engine, the engine, the engine, the engine, the engine, the engine, the engine, the engine, the engine, the engine, the engine, the engine, the engine, the engine, it's a large, the engine, the engine, the engine, the engine, the engine, the engine,
2022-03-23 21:16:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:16:10 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.945 | ppl 15.4 | bleu 16.27 | wps 2872.2 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 16.27
2022-03-23 21:16:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 21:16:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 21:16:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 21:16:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 16.27) (writing took 0.8512838259339333 seconds)
2022-03-23 21:16:11 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 21:16:11 | INFO | train | epoch 017 | loss 4.182 | ppl 18.16 | wps 7920.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 1.211 | loss_scale 4 | train_wall 434 | gb_free 13.2 | wall 8462
2022-03-23 21:16:11 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 21:16:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:17:54 | INFO | train_inner | epoch 018:     36 / 157 loss=4.11, ppl=17.27, wps=7395.9, ups=0.29, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=1.191, loss_scale=4, train_wall=277, gb_free=13.9, wall=8565
2022-03-23 21:22:25 | INFO | train_inner | epoch 018:    136 / 157 loss=3.937, ppl=15.31, wps=9134.1, ups=0.37, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=1.077, loss_scale=4, train_wall=271, gb_free=13.7, wall=8837
2022-03-23 21:23:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:23:30 | INFO | fairseq.tasks.translation | example hypothesis: we made this pill in the clinic.
2022-03-23 21:23:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:23:36 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline line from doha, which probably knows most of you.
2022-03-23 21:23:36 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:23:42 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gollocks of dindindindindindindines.
2022-03-23 21:23:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:23:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food food, where happy legs are getting salt and fat.
2022-03-23 21:23:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:23:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand exactly what all his thoughts are.
2022-03-23 21:23:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:24:00 | INFO | fairseq.tasks.translation | example hypothesis: in the maibia, like the people of responsibility for the wildlife, grew up to the number of wild animals, and that's a foundation for conservation.
2022-03-23 21:24:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:24:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic magnetic field in the inner lines, but the sususulant alalarm doesn't move, if you need your energy movements, you need energy, and you need the superconductor.
2022-03-23 21:24:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:24:12 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection reflection, we can start with a traditional face, we can start with a traditional face that can start able to start with a traditional face of the big configuration of the face, and the shape of the interfaces, and then you know, the whole structure of the whole structure.
2022-03-23 21:24:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:24:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here at tedwomen, that's that... yes, when the best thing was written, somebody said, "if you were in the best hand," somebody said, "you know," the men in a table, "and then we're talking to you're talking to you're talking to you're talking about the piano," oh, it's a long time, we've started to you've got to be a little bit of silence of silent, we've started to be a silent. "
2022-03-23 21:24:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:24:21 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of invention, and a big part of the design of the airplane that we've been able to solve in the plane, is that we had to solve a result of it was that we had to solve the unique problems that we had to solve it in the ground -- to solve it all the ground -- to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to put it all the power of a fluid out of a fluid up to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 21:24:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:24:21 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.585 | ppl 12 | bleu 20.94 | wps 3207.8 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.94
2022-03-23 21:24:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 21:24:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 21:24:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 21:24:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.94) (writing took 0.9092322373762727 seconds)
2022-03-23 21:24:22 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 21:24:22 | INFO | train | epoch 018 | loss 3.947 | ppl 15.42 | wps 8035.1 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 1.052 | loss_scale 4 | train_wall 433 | gb_free 13.2 | wall 8954
2022-03-23 21:24:22 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 21:24:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:28:05 | INFO | train_inner | epoch 019:     79 / 157 loss=3.818, ppl=14.11, wps=7544.1, ups=0.29, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=1.009, loss_scale=4, train_wall=282, gb_free=13.5, wall=9177
2022-03-23 21:31:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:31:41 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 21:31:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:31:47 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably knows most of you here.
2022-03-23 21:31:47 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:31:53 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gollocks of dindindines that are going to be written two new pigs.
2022-03-23 21:31:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:31:58 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are made with salz and fat.
2022-03-23 21:31:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:32:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a few electrodes on his head and understand exactly what all his thoughts are.
2022-03-23 21:32:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:32:10 | INFO | fairseq.tasks.translation | example hypothesis: in the mamakeas the people had been devoted for wildlife, grew up the number of wildlife again, and that's a foundation for conservation in namibia.
2022-03-23 21:32:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:32:16 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some blooding field lines in the inner, but the susulalalaly may not move when they need their energy, and so the conductor of the superconductor.
2022-03-23 21:32:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:32:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which can begin with a traditional face of the face of the face of the face and the fundamental shape of the information that the whole structure, the whole structure of the structure, and all the ports of the structure, and all the structure.
2022-03-23 21:32:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:32:29 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting and measured for me here at tedwomen is that... yes, when the best was the best one said, "the men died in a table, '"] ["] ["] ["] men,' '' '' '' '' '' ''"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [" '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' "
2022-03-23 21:32:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:32:31 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of invention, and a big part of the design of our airplane was a result that we had to solve the unique problems that we had to be connected to the ground -- all of us in the ground -- all of us, all the soil, and a sudden, and a major part of the aircraft, which is the aircraft, and that the aircraft, and that the aircraft, and the aircraft, and that we're going to the aircraft, and the aircraft, and that they're going to the aircraft, and that they're going to the aircraft, and that they're going to the aircraft, and that they're going to the aircraft, and that they're going to the aircraft, and they're going to the aircraft, and that they're going to the aircraft, and they're going to the ground, and that they're going to be a fluid up in the aircraft, except except except for us in the ground, except for us,
2022-03-23 21:32:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:32:31 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.502 | ppl 11.33 | bleu 21.54 | wps 3275.7 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.54
2022-03-23 21:32:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 21:32:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 21:32:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 21:32:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 21.54) (writing took 0.9013015730306506 seconds)
2022-03-23 21:32:32 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 21:32:32 | INFO | train | epoch 019 | loss 3.731 | ppl 13.28 | wps 8060.9 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 1.018 | loss_scale 4 | train_wall 432 | gb_free 13.4 | wall 9444
2022-03-23 21:32:32 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 21:32:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:33:34 | INFO | train_inner | epoch 020:     22 / 157 loss=3.625, ppl=12.34, wps=7531.7, ups=0.3, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.953, loss_scale=4, train_wall=272, gb_free=14.2, wall=9506
2022-03-23 21:38:17 | INFO | train_inner | epoch 020:    122 / 157 loss=3.544, ppl=11.67, wps=9144.9, ups=0.35, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.906, loss_scale=4, train_wall=283, gb_free=13.2, wall=9789
2022-03-23 21:39:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:39:52 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 21:39:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:39:58 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows most of you here.
2022-03-23 21:39:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:40:04 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golgollocks of dindindindines that are going to get rid of the two new pigments.
2022-03-23 21:40:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:40:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are being served with salz and fat.
2022-03-23 21:40:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:40:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to just bring a few electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 21:40:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:40:23 | INFO | fairseq.tasks.translation | example hypothesis: this is a foundation of how people have been transformed responsibility for wildlife, growing the number of wild animals again, and that's a foundation of conservation in namibia.
2022-03-23 21:40:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:40:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bols of magnetic fields are caught in the inner lines, but the susulant doesn't like it if you're moving your energy, and so the conductor of magnetic field.
2022-03-23 21:40:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:40:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from reflection, we can start with a traditional facial that can begin to start with a traditional facial of the face, and the basic shape of the information, and through that information that information, which is the whole structure of these reflection, and all the structure of these reflection, and all the structure, and all the structure, and all the structure, and all the structure of the shape of the structure, and
2022-03-23 21:40:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:40:43 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting to be interesting and measure it interesting, for me here at tedwomen, is that... you know, at the best time, when someone said, "well," someone said, "you know, the men who said," the men who are working on a table, and when the revolution starts to be able to be able to be able to be able to be able to support you here at tedtedtedtedted3, and then, and then, and then when the revolution with you know, and then we've been supported for you know, and then you know, and then we've been told me here at tedwomen who's a long time, "canded to be here at tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen," is that time, "is that time,"
2022-03-23 21:40:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:40:46 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention of invention, and a big part of the design work that we've had to solve at our plane at the plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from the ground, and everything from a continent, and a lot of the invention of the invention of the design of the design work that allows us to be able to be able to be able to be able to be able to be able to be able to be able to be able to get able to be able to be able to be able to be able to get able to be able to get able to be able to be able to put in a mechanism, or a mechanism, or a mechanism, or a mechanism that if you to get able to be able to get able to use the united states, or a mechanism, or a mechanism that if you to put it in the united states, or the united states, or the united states, if you can actually put it
2022-03-23 21:40:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:40:46 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.41 | ppl 10.63 | bleu 22.29 | wps 3054.9 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 22.29
2022-03-23 21:40:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 21:40:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 21:40:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 21:40:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 22.29) (writing took 0.8545929756946862 seconds)
2022-03-23 21:40:47 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 21:40:47 | INFO | train | epoch 020 | loss 3.527 | ppl 11.53 | wps 7983.4 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.945 | loss_scale 4 | train_wall 434 | gb_free 13.7 | wall 9938
2022-03-23 21:40:47 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 21:40:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:43:53 | INFO | train_inner | epoch 021:     65 / 157 loss=3.407, ppl=10.61, wps=7416.4, ups=0.3, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=1.006, loss_scale=4, train_wall=275, gb_free=13.4, wall=10124
2022-03-23 21:48:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:48:07 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic clinic.
2022-03-23 21:48:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:48:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know.
2022-03-23 21:48:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:48:19 | INFO | fairseq.tasks.translation | example hypothesis: stars will make new goldicks.
2022-03-23 21:48:19 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:48:24 | INFO | fairseq.tasks.translation | example hypothesis: for instance, there's french food, where frog legs are served with salz.
2022-03-23 21:48:24 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:48:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 21:48:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:48:37 | INFO | fairseq.tasks.translation | example hypothesis: so, in the maintenance of people, the number of wildlife animals grew back again, and that's a foundation for conservation in namibia.
2022-03-23 21:48:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:48:44 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bust of magnetic field lines are caught in the inner field, but the sulalous eggs don't like it, if you move your movements, your energy needs your energy, and that's what the prououts of magnetic field need.
2022-03-23 21:48:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:48:50 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face, which is the big constructions of the face, and the basic shape, and then it restores all the information that fold up and fold all the structure.
2022-03-23 21:48:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:48:56 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that makes it interesting, and if we're going to be here at tedwomen, you know, you know, you know, you know, you know, you know, when someone said, "hey, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know,
2022-03-23 21:48:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:48:57 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, and a big part of the design work that we're going to be able to put in our airplane, one of the things that we had to solve is that we had to solve the unique problems that were interconnected to the ground -- everything from a continuous variable system.
2022-03-23 21:48:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:48:57 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.276 | ppl 9.69 | bleu 23.3 | wps 3242.5 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 23.3
2022-03-23 21:48:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 21:48:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 21:48:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 21:48:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 21 @ 3292 updates, score 23.3) (writing took 0.8836568500846624 seconds)
2022-03-23 21:48:58 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 21:48:58 | INFO | train | epoch 021 | loss 3.398 | ppl 10.54 | wps 8031.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.94 | loss_scale 4 | train_wall 434 | gb_free 14.3 | wall 10430
2022-03-23 21:48:59 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 21:48:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:49:22 | INFO | train_inner | epoch 022:      8 / 157 loss=3.42, ppl=10.7, wps=7515.8, ups=0.3, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.923, loss_scale=4, train_wall=272, gb_free=13.4, wall=10454
2022-03-23 21:53:53 | INFO | train_inner | epoch 022:    108 / 157 loss=3.307, ppl=9.89, wps=9100.1, ups=0.37, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.933, loss_scale=4, train_wall=270, gb_free=13.4, wall=10725
2022-03-23 21:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:56:17 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 21:56:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:56:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline line of doha who probably know most of you here.
2022-03-23 21:56:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:56:29 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks.
2022-03-23 21:56:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:56:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz.
2022-03-23 21:56:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:56:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 21:56:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:56:47 | INFO | fairseq.tasks.translation | example hypothesis: in the mammals like the people of wildlife, the number of wild animals, and that's a foundation for conservation.
2022-03-23 21:56:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:56:52 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundbreaking magnetic field lines in the inner, but the sulouter eggs don't like them, because their movements need.
2022-03-23 21:56:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:56:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which is the great constructions of the face, and the basic shape of the information that pulls the whole ports and pulls all the ports of the ports that fold the whole porting the whole ports of porting the whole ports, and all the ports of the porting a structure.
2022-03-23 21:56:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:57:05 | INFO | fairseq.tasks.translation | example hypothesis: fifth: one of the reasons it's interesting to be here at tedwomen, is that... yeah, when somebody said, "turn it up to the men," and then we're told you, "you know, you're going to go to the men in your table, and then we're going to help you," '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'"
2022-03-23 21:57:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:57:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're in the airplane, was a result to solve the unique problems that were connected to the ground -- everything from a continuing to a continuous, and cooling system, and it allows us to refrigergergergerator, or that if you can use it to the aircraft.
2022-03-23 21:57:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:57:07 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.201 | ppl 9.2 | bleu 23.38 | wps 3283.3 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 23.38
2022-03-23 21:57:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 21:57:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 21:57:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 21:57:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 22 @ 3449 updates, score 23.38) (writing took 0.7960457131266594 seconds)
2022-03-23 21:57:08 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 21:57:08 | INFO | train | epoch 022 | loss 3.265 | ppl 9.61 | wps 8066.4 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.875 | loss_scale 4 | train_wall 432 | gb_free 14 | wall 10919
2022-03-23 21:57:08 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 21:57:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:59:29 | INFO | train_inner | epoch 023:     51 / 157 loss=3.196, ppl=9.17, wps=7588.7, ups=0.3, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.777, loss_scale=4, train_wall=279, gb_free=13.3, wall=11061
2022-03-23 22:04:06 | INFO | train_inner | epoch 023:    151 / 157 loss=3.064, ppl=8.37, wps=9164.8, ups=0.36, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.847, loss_scale=4, train_wall=277, gb_free=13.3, wall=11338
2022-03-23 22:04:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:04:27 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 22:04:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:04:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know.
2022-03-23 22:04:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:04:38 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks.
2022-03-23 22:04:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:04:44 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where happy legs are served with salz and ppet.
2022-03-23 22:04:44 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:04:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 22:04:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:04:56 | INFO | fairseq.tasks.translation | example hypothesis: in the mapping of people, the number of wildanimals grew back again. and this is a foundation for conservation in namibia.
2022-03-23 22:04:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:05:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are caught in the inner inner, but the supralan eggs don't like moving when they move around, because their energy movements need their energy movements, and so the superconductor of the superconductor.
2022-03-23 22:05:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:05:09 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial, the big constructions of the face, the basic constructions of the face of the face of the face, and the basic shape of the basic information that are restoring information, and the basic information that we're able to reform.
2022-03-23 22:05:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:05:16 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons it's very interesting and measured to me here in tedwomen is that... tyes, when the dinner dinner dinner dinner was shot at the best time when someone said, "well," turn you on the best place when someone said, "turn you to the men on a desperately and tell you," the revolution starts to support you. "
2022-03-23 22:05:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:05:19 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're on aircraft, was a result that we had to solve the unique problems that we had to solve with the unique problems that were connected to the unique problems that we had to operate with with with with with with that, and we have to operate on the ground -- everything from a continuous amount of refrigergerator, which allows us to refrigergerator to refrigergerator, which means that we have to be able to refrigergergergergergergergergergergergergergergergergergergergergergergerator, which means that we have to be able to do with a flight flight flight flight flight flight flight, which is the ground, which is that the most specific problems that we've got to be able to be able to deal with the ground, which means that we've got to deal with a very specific problems that we have to deal with a flight flight flight flight flight.
2022-03-23 22:05:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:05:19 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.18 | ppl 9.06 | bleu 24.66 | wps 3173.7 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 24.66
2022-03-23 22:05:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 22:05:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 22:05:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 22:05:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 24.66) (writing took 0.8104729200713336 seconds)
2022-03-23 22:05:20 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 22:05:20 | INFO | train | epoch 023 | loss 3.113 | ppl 8.65 | wps 8032.1 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.834 | loss_scale 4 | train_wall 433 | gb_free 14.2 | wall 11411
2022-03-23 22:05:20 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 22:05:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:09:39 | INFO | train_inner | epoch 024:     94 / 157 loss=3.045, ppl=8.26, wps=7478.3, ups=0.3, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.83, loss_scale=4, train_wall=275, gb_free=13.3, wall=11671
2022-03-23 22:12:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:12:39 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 22:12:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:12:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably the most familiar here.
2022-03-23 22:12:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:12:51 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gollocks that are going to be signed by two new pigs.
2022-03-23 22:12:51 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:12:56 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pill.
2022-03-23 22:12:56 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:13:02 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 22:13:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:13:08 | INFO | fairseq.tasks.translation | example hypothesis: in the maggarbage of people have been taking responsibility for wildlife, growing the number of wildanimals again, and that's a foundation for conservation in namibia.
2022-03-23 22:13:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:13:14 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic fields are caught in the inside, but the superconductor doesn't like it if you move, because your movements need their energy, and so the superconductor.
2022-03-23 22:13:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:13:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, the big configurations of the face and the basic form, which restores the whole portion of the visual and folds.
2022-03-23 22:13:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:13:26 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... tyes, when they were best summarized when someone said, "turn to the men on a table and say," when the revolution starts to support you. "
2022-03-23 22:13:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:13:28 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continually variable system and cooling and cooling and cooling, and that if you can see the power of a superior, or that you can't see the power of a superior to the car, or the fabric.
2022-03-23 22:13:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:13:28 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 2.955 | ppl 7.75 | bleu 26.51 | wps 3335.3 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 26.51
2022-03-23 22:13:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 22:13:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 22:13:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 22:13:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 26.51) (writing took 0.9123571249656379 seconds)
2022-03-23 22:13:29 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 22:13:29 | INFO | train | epoch 024 | loss 3.018 | ppl 8.1 | wps 8063.8 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.794 | loss_scale 4 | train_wall 433 | gb_free 13.9 | wall 11901
2022-03-23 22:13:30 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 22:13:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:15:15 | INFO | train_inner | epoch 025:     37 / 157 loss=2.916, ppl=7.55, wps=7585.3, ups=0.3, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.742, loss_scale=4, train_wall=280, gb_free=13.5, wall=12007
2022-03-23 22:19:49 | INFO | train_inner | epoch 025:    137 / 157 loss=3.002, ppl=8.01, wps=9137.6, ups=0.36, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.853, loss_scale=4, train_wall=274, gb_free=13.4, wall=12281
2022-03-23 22:20:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:20:49 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 22:20:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:20:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows.
2022-03-23 22:20:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:21:00 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to generate new goldicks that are two new pigs.
2022-03-23 22:21:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:21:06 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where happy legs are served with salz and pitcase.
2022-03-23 22:21:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:21:12 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 22:21:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:21:17 | INFO | fairseq.tasks.translation | example hypothesis: in the makewise, people have been revising wildlife, and that's a foundation for conservation conservation in namibia.
2022-03-23 22:21:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:21:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught in inner, but the superconductor doesn't like it if you're moving, because your movements need to disorder your energy, and so the superconductor disorders.
2022-03-23 22:21:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:21:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflective reflection, we can start with a traditional facial view, the big constructures of faces and the basic shape, which includes the information that pulls all the portion structure.
2022-03-23 22:21:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:21:35 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons it's interesting and measuring it for me here at tedwomen is that... tja, when he was best summarized when someone said, "turn you to your men on your desk and tell you," if the revolution begins, "we'll support you," the truth is that we've already started for a long time. "
2022-03-23 22:21:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:21:37 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great piece of design work that we're on our plane was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuously variable system and refrigering a liquid system, that allows us to fly in the aircraft, or if we're able to use the prophecy to the prophecy, if we can either get the prophecy to the prophecy to the prophecy to a specific, or to the prophecy, if we're going to the propheating the propelled in the aircraft, if we're going to the propelled to the prophecy, the prophecy, the propelled in the propelled in the propelled by a particular flight, or the propeller, if you can't see the aircraft.
2022-03-23 22:21:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:21:37 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 2.978 | ppl 7.88 | bleu 25.12 | wps 3386 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 26.51
2022-03-23 22:21:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 22:21:37 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 22:21:37 | INFO | train | epoch 025 | loss 2.942 | ppl 7.69 | wps 8092.2 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.804 | loss_scale 4 | train_wall 433 | gb_free 14.2 | wall 12389
2022-03-23 22:21:38 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 22:21:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:25:24 | INFO | train_inner | epoch 026:     80 / 157 loss=2.827, ppl=7.09, wps=7605, ups=0.3, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.738, loss_scale=4, train_wall=280, gb_free=13.5, wall=12616
2022-03-23 22:28:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:28:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these pietleep in the clinic.
2022-03-23 22:28:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:29:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 22:29:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:29:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to create two new sponsors.
2022-03-23 22:29:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:29:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salz and pitcase.
2022-03-23 22:29:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:29:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 22:29:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:29:27 | INFO | fairseq.tasks.translation | example hypothesis: in the makewise, like the people of responsibility for wildlife, grew up again, the number of wildwildanimals, and that's a foundation for conservation in namibia.
2022-03-23 22:29:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:29:33 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnet fields are caught in the inside, but the superconductor doesn't like it if they're moving, because their movements need energy, and so the supralty of magnetic field.
2022-03-23 22:29:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:29:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from these reflection reflection, we can start with a traditional facial can that restores the big constructures of the face and the basic form, and through the dieting of information, which includes all the porting structure and all the fits.
2022-03-23 22:29:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:29:46 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that's going to be high-interesting and appropriate for me here at tedwomen, is that... tja, it was best summarized when someone said, "turn you to your men on your table, and tell them," if the revolution starts to support you. "
2022-03-23 22:29:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:29:48 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a large part of the design work that we're at the stagent, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous marketplace and cooling system that allows us to do with a refrigerators to be able to use in the fly, to be able to be able to be able to be able to be able to be able to be able to be able to do with a drug drug drug drug that is to do, to be able to be able to be able to be able to be able to be able to do, to be able to be able to be able to be able to be able to be able to be able to be able to do, to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do with the
2022-03-23 22:29:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:29:48 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 2.793 | ppl 6.93 | bleu 28.52 | wps 3256.8 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.52
2022-03-23 22:29:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 22:29:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 22:29:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 22:29:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 28.52) (writing took 0.807119688950479 seconds)
2022-03-23 22:29:49 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 22:29:49 | INFO | train | epoch 026 | loss 2.816 | ppl 7.04 | wps 8031.5 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.739 | loss_scale 4 | train_wall 434 | gb_free 13.8 | wall 12881
2022-03-23 22:29:49 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 22:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:30:56 | INFO | train_inner | epoch 027:     23 / 157 loss=2.746, ppl=6.71, wps=7507.5, ups=0.3, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.721, loss_scale=4, train_wall=275, gb_free=14.3, wall=12948
2022-03-23 22:35:32 | INFO | train_inner | epoch 027:    123 / 157 loss=2.774, ppl=6.84, wps=9090.7, ups=0.36, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.729, loss_scale=4, train_wall=275, gb_free=13.1, wall=13223
2022-03-23 22:37:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:37:10 | INFO | fairseq.tasks.translation | example hypothesis: we put these pietters in the clinic.
2022-03-23 22:37:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:37:15 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 22:37:15 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:37:21 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-23 22:37:21 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:37:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frog legs are served with salz and pitcase.
2022-03-23 22:37:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:37:33 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 22:37:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:37:39 | INFO | fairseq.tasks.translation | example hypothesis: in the stomach like people's responsibility for wildlife, the number of wildwildwildlife grew again, and that's a foundation for conservation in namibia.
2022-03-23 22:37:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:37:45 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle lines are caught inside the inner, but the superconductor doesn't like it if you move, because your movements use, and so the superconductor disorder.
2022-03-23 22:37:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:37:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can, which restores the large constructures of the face and the basic shape, and through the dieting information that pulls the whole porter structure and all of a fold.
2022-03-23 22:37:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:37:56 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons it's going to be highly interesting and appropriate to me here at tedwomen is that... tyes, when he was best summarized when someone said, "turn you to the men on your table, and tell them," well, "the truth is women, we've already been supporting you in this game," hill "] [" '"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["'"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 22:37:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:37:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that we're on our airplane at the striests, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous fabric and a refrigerator system that allows us to use aircraft, or the propellers to the ground.
2022-03-23 22:37:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:37:58 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 2.743 | ppl 6.69 | bleu 28.18 | wps 3399 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 28.52
2022-03-23 22:37:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 22:37:58 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 22:37:58 | INFO | train | epoch 027 | loss 2.723 | ppl 6.6 | wps 8080.8 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.705 | loss_scale 4 | train_wall 434 | gb_free 13.5 | wall 13369
2022-03-23 22:37:58 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 22:37:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:41:01 | INFO | train_inner | epoch 028:     66 / 157 loss=2.656, ppl=6.3, wps=7551.5, ups=0.3, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.701, loss_scale=4, train_wall=275, gb_free=14.2, wall=13553
2022-03-23 22:45:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:45:19 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 22:45:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:45:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 22:45:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:45:30 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-23 22:45:30 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:45:36 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frogs are served with salz and psuitcase.
2022-03-23 22:45:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:45:42 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 22:45:42 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:45:48 | INFO | fairseq.tasks.translation | example hypothesis: in the case of how people were taking responsibility for wildlife, the number of wildlife animals grew back. and this has become a foundation for conservation in namibia.
2022-03-23 22:45:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:45:54 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught inside, but the superconductor doesn't like it if you move, because your movements use your energy, and the superconductor disorders.
2022-03-23 22:45:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:46:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big configurations of the face, and restoring it through the basic form of information that refers the whole porter structure and all the fits.
2022-03-23 22:46:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:46:06 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that's going to be high-interesting and measured to me here at tedwomen is that... tja, it was best summarized when someone said, "turn you on your desk, and tell you, 'when the revolution starts to help you.' ''" the truth is that we've already been supporting you for a long time. "
2022-03-23 22:46:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:46:09 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a large part of the design work that we're on our plane at the stump, was a result that we had to solve the unique problems that were connected to operating the ground -- everything from a continuous variable and a cooler system that allows us to use transportation to the aircraft, or to the shelter, or the air conditioning, or the air conditioning, or the air conditioning.
2022-03-23 22:46:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:46:09 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 2.709 | ppl 6.54 | bleu 29.06 | wps 3270.9 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.06
2022-03-23 22:46:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 22:46:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 22:46:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 22:46:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 29.06) (writing took 0.7957744617015123 seconds)
2022-03-23 22:46:10 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 22:46:10 | INFO | train | epoch 028 | loss 2.681 | ppl 6.41 | wps 8029.2 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.77 | loss_scale 4 | train_wall 434 | gb_free 13.3 | wall 13861
2022-03-23 22:46:10 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 22:46:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:46:36 | INFO | train_inner | epoch 029:      9 / 157 loss=2.722, ppl=6.6, wps=7537.8, ups=0.3, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.821, loss_scale=4, train_wall=277, gb_free=13.2, wall=13887
2022-03-23 22:51:12 | INFO | train_inner | epoch 029:    109 / 157 loss=2.563, ppl=5.91, wps=9089.7, ups=0.36, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.648, loss_scale=4, train_wall=276, gb_free=13.1, wall=14164
2022-03-23 22:53:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:53:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 22:53:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:53:36 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably know most here.
2022-03-23 22:53:36 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:53:42 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that are going to transcript two new pigs.
2022-03-23 22:53:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:53:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog is served with salz and parbitcase.
2022-03-23 22:53:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:53:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 22:53:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:54:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the maginy of how people refused responsibility for wildlife, the number of wildwildanimals grew again, and that's become a basis for conservation in namibia.
2022-03-23 22:54:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:54:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines in the inside, but the superconductor doesn't like it when you move, because your energy is so the superconductor.
2022-03-23 22:54:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:54:12 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial can that restores the large contextures of the face and the fundamental shape, and through the dieting information that refers all the ports and all the fussions.
2022-03-23 22:54:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:54:18 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it was very interesting and appropriate to me here at tedwomen, is that... tja, when he said, "when someone said," turn you up to the men on your desk and tell you, "when the revolution starts to you."
2022-03-23 22:54:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:54:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that we're proud at our plane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variables and a refrigeration system, that allows us to use aircraft, or if you can see the propellism, the air conditioning, you can see in the ground until you can see the propellism, or the propellity of a mechanism.
2022-03-23 22:54:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:54:20 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 2.744 | ppl 6.7 | bleu 28.35 | wps 3304.2 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 29.06
2022-03-23 22:54:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 22:54:20 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 22:54:20 | INFO | train | epoch 029 | loss 2.588 | ppl 6.01 | wps 8052.3 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.704 | loss_scale 4 | train_wall 434 | gb_free 12.9 | wall 14352
2022-03-23 22:54:20 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 22:54:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:56:45 | INFO | train_inner | epoch 030:     52 / 157 loss=2.609, ppl=6.1, wps=7532.9, ups=0.3, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.758, loss_scale=4, train_wall=277, gb_free=13.5, wall=14497
2022-03-23 23:01:21 | INFO | train_inner | epoch 030:    152 / 157 loss=2.465, ppl=5.52, wps=9163.4, ups=0.36, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.594, loss_scale=4, train_wall=276, gb_free=14.3, wall=14773
2022-03-23 23:01:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:01:41 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepsters in the clinic.
2022-03-23 23:01:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:01:46 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline from doha, which i think most of you here.
2022-03-23 23:01:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:01:52 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will be ruled by two new gay pigs.
2022-03-23 23:01:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:01:58 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are served with salt and pepper.
2022-03-23 23:01:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:02:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what's all your thoughts on the track.
2022-03-23 23:02:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:02:10 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of the people responsibility for wildlife, the number of wild animals grew back. and that's a foundation for conservation in namibia.
2022-03-23 23:02:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:02:16 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught in the inside, but the superconductor doesn't like it if they move, they use their movements, and so the superconducting disorders.
2022-03-23 23:02:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:02:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constraints of the face and the basic shape, and through the theft of information that pulls the entire porter structure and all the faters.
2022-03-23 23:02:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:02:28 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that makes it really interesting and measured to me here at tedwomen is that... tja, dinner was summarized at the best when someone said, "turn you to the men on your table and tell you," if the revolution starts to support you, "the truth is that we've already been supporting you for a long time."
2022-03-23 23:02:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:02:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable system that allows us to use in the aircraft until we can use a specific device to either be able to see the propeller, or if we can use the propellity of a specific problem, the propeller device, or if we had to be able to be able to see the propellable to be able to be able to be able to see the propelled by an aircraft.
2022-03-23 23:02:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:02:30 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 2.625 | ppl 6.17 | bleu 29.74 | wps 3319.1 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 29.74
2022-03-23 23:02:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 23:02:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 23:02:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 23:02:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 29.74) (writing took 0.7914233249612153 seconds)
2022-03-23 23:02:31 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 23:02:31 | INFO | train | epoch 030 | loss 2.499 | ppl 5.65 | wps 8046.1 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.644 | loss_scale 4 | train_wall 434 | gb_free 12.9 | wall 14842
2022-03-23 23:02:31 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 23:02:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:07:01 | INFO | train_inner | epoch 031:     95 / 157 loss=2.464, ppl=5.52, wps=7532, ups=0.29, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.66, loss_scale=4, train_wall=283, gb_free=13.1, wall=15112
2022-03-23 23:09:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:09:52 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 23:09:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:09:58 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 23:09:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:10:03 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to be headed by two new pigs.
2022-03-23 23:10:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:10:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where happy legs are served with salz and pitcase.
2022-03-23 23:10:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:10:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 23:10:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:10:21 | INFO | fairseq.tasks.translation | example hypothesis: in the stomach like human responsibility for wildlife, the number of wildlife survivors grew up again, and this has become a foundation for conservation in namibia.
2022-03-23 23:10:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:10:28 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines caught inside, but the superconductor doesn't like it when they move, they use their energy, and the superconductor.
2022-03-23 23:10:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:10:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constructures of the face, and the basic form of information that includes all the ports and all the fits.
2022-03-23 23:10:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:10:40 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... tja, when you were striking dinner, it was best summarized when someone said, "turn you to men on your table and say," if the revolution begins, then we support you. "
2022-03-23 23:10:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:10:42 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, it's still the mother of invention, and a big part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variables and a refrigeration system that allows us to use a portable traffic in the aircraft until you could see the surface of a specialist, or if you could see the propellers to a specific wall wall wall wall wall wall wall wall wall wall, or if you could use it, or if you could see the propelled to a specifiction, you could use it, or if you could be able to the air conditioning, you could use it, you could use it, you could use it, you could use it, you could use it to the air conditioning, you could use it to go into a specific to the air conditioning, or if you could use it, you could be able to the surface.
2022-03-23 23:10:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:10:42 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 2.59 | ppl 6.02 | bleu 30.27 | wps 3254.2 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 30.27
2022-03-23 23:10:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 23:10:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 23:10:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 23:10:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 30.27) (writing took 0.8019347391091287 seconds)
2022-03-23 23:10:43 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 23:10:43 | INFO | train | epoch 031 | loss 2.444 | ppl 5.44 | wps 8022.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.643 | loss_scale 4 | train_wall 435 | gb_free 12.9 | wall 15335
2022-03-23 23:10:43 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 23:10:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:12:32 | INFO | train_inner | epoch 032:     38 / 157 loss=2.363, ppl=5.15, wps=7514.1, ups=0.3, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.597, loss_scale=4, train_wall=274, gb_free=13.9, wall=15444
2022-03-23 23:17:10 | INFO | train_inner | epoch 032:    138 / 157 loss=2.399, ppl=5.27, wps=9103.3, ups=0.36, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.662, loss_scale=4, train_wall=277, gb_free=13.9, wall=15721
2022-03-23 23:17:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:18:04 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepses in the clinic.
2022-03-23 23:18:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:18:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 23:18:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:18:15 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to write two new pigs.
2022-03-23 23:18:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:18:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salz and pbuffer.
2022-03-23 23:18:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:18:27 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on track.
2022-03-23 23:18:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:18:33 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, like people's responsibility for wildlife, they grew up again, and this is a foundation for conservation in namibia.
2022-03-23 23:18:33 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:18:39 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnet field lines are caught inside, but the superconductor doesn't like it if you move, because your movements use your energy, and the superconductors.
2022-03-23 23:18:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:18:46 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional face, which is the large constraints of the face, and restores the basic shape, and then refuse it through that one information that pulls all the porter structure and all the fat.
2022-03-23 23:18:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:18:52 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons it's going to be very interesting and appropriate to me here at tedwomen is that... tyes, when he was striking dinner, it's best summarized when someone said, "turn you to men on your table and say to you, 'when the revolution begins, we're supporting you.' ''" 'the truth is that we've already started you at this theme for a long time. "
2022-03-23 23:18:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:18:54 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still a mother of invention, and a large part of the design work that we're on at our plane is a result that we had to solve the unique problems that were connected to it -- everything from a continuous variables and a refrigeration system that allows us to use a machine in the traffic, until one of them, until the contrast, or the propelled to a contrast, or the propeller, or the propelled to a conditioning, and the ground, until the propeller, if you can see it's in the air conditioning for a conditioning device, until the air conditioning, until the crash, until the crash, until the crash, or the crash, or the propelled to a conditioning, and the crash, until the propelled to a conditioning, until the air conditioning, it's been propelled to a conditioning, until the crash, until the crash, until the crash,
2022-03-23 23:18:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:18:54 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 2.556 | ppl 5.88 | bleu 30.22 | wps 3269.7 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 30.27
2022-03-23 23:18:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 23:18:54 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 23:18:54 | INFO | train | epoch 032 | loss 2.376 | ppl 5.19 | wps 8042.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.638 | loss_scale 4 | train_wall 434 | gb_free 14 | wall 15826
2022-03-23 23:18:54 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 23:18:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:22:42 | INFO | train_inner | epoch 033:     81 / 157 loss=2.277, ppl=4.85, wps=7545.5, ups=0.3, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.623, loss_scale=4, train_wall=276, gb_free=13.6, wall=16054
2022-03-23 23:26:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:26:16 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 23:26:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:26:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably most of you know here.
2022-03-23 23:26:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:26:27 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to create two new gay transcribers.
2022-03-23 23:26:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:26:33 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pitcase.
2022-03-23 23:26:33 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:26:40 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-23 23:26:40 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:26:46 | INFO | fairseq.tasks.translation | example hypothesis: in the stomach like the people's responsibility for wildlife, the number of wildwildwildlife returned again, and that's become a foundation for conservation in namibia.
2022-03-23 23:26:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:26:52 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it if you move, because your movements are deployed, and the superconductor disorders.
2022-03-23 23:26:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:26:58 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial can that restorates the big constructures of the face and the basic shape, and through the theft of information, which refers the whole porter structure and all the folds.
2022-03-23 23:26:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:27:04 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons it's going to be very interesting and appropriate for me to be here at tedwomen, is that... tja, dinner was best summarized when someone said, "turn you to the men on your desk and say to them," if the revolution starts to support you. "the truth is that we've already started supporting you at this theme of a long time,"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] don't you,
2022-03-23 23:27:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:27:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continual variables and a refrigerator system, that allows us to use a machine to the bus traffic, to a specialist, to the ground, to the wheel, to the point, to the wheels, if you're going to be able to make it, to the ground, to the wheels, to the wheels, to the wheels, to the ground, to the wheels, to the aircraft, to the aircraft, to the wheels, to the caseels, to the aircraft, to the aircraft, to the ground, to the table, to the wheels, to the caseels, to the table, to the cascacacacastles, to the table, to the ground, to the wheels
2022-03-23 23:27:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:27:07 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 2.529 | ppl 5.77 | bleu 31.57 | wps 3203.9 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.57
2022-03-23 23:27:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 23:27:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 23:27:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt
2022-03-23 23:27:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.08_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 31.57) (writing took 0.8755742642097175 seconds)
2022-03-23 23:27:08 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 23:27:08 | INFO | train | epoch 033 | loss 2.32 | ppl 4.99 | wps 8002.5 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.621 | loss_scale 4 | train_wall 435 | gb_free 13.5 | wall 16319
2022-03-23 23:27:08 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 23:27:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:28:18 | INFO | train_inner | epoch 034:     24 / 157 loss=2.356, ppl=5.12, wps=7479.3, ups=0.3, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.63, loss_scale=4, train_wall=277, gb_free=13.4, wall=16390
2022-03-23 23:32:56 | INFO | train_inner | epoch 034:    124 / 157 loss=2.245, ppl=4.74, wps=9043.2, ups=0.36, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.626, loss_scale=4, train_wall=278, gb_free=13.2, wall=16668
2022-03-23 23:34:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:34:32 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic hospital.
2022-03-23 23:34:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:34:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 23:34:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:34:43 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dining that are going to generate two new pigs.
2022-03-23 23:34:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:34:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salt and ppeffer.
2022-03-23 23:34:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:34:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:34:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:35:02 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife, the number of wildlife raised again, and this has become a foundation for conservation in namibia.
2022-03-23 23:35:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:35:08 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the strands of magnetic field are captured inside, but the superconductor doesn't like it if they move, because they use their movements, and so the superconductor disorders.
2022-03-23 23:35:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:35:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can, which restores the big constraints of the face and replace it through the thief information that pulls the entire porch structure and all the fat.
2022-03-23 23:35:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:35:21 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons it's going to be very interesting and appropriate to me here at tedwomen is that, well, if you're striking dinner, it's best summarized when someone said, "turn you to the men on your table and tell them, 'if the revolution starts to support you, we'll support you.' '" the truth is that we've already started supported you at this time, we've been supporting you with ravie ie gras,' "and then we've got to say, '" thank you to you. "
2022-03-23 23:35:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:35:23 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we are at our plane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous version of the design work, and a cooling system of refrigeration, that allows us to use in our airplane to be stressed to a traffic and to a relief, if we had to a mechanism, if we had to be able to see the ground, we had to be able to be able to see the aircraft.
2022-03-23 23:35:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:35:23 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 2.538 | ppl 5.81 | bleu 31.31 | wps 3180 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 31.57
2022-03-23 23:35:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 23:35:23 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 23:35:23 | INFO | train | epoch 034 | loss 2.274 | ppl 4.84 | wps 7970.9 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.647 | loss_scale 4 | train_wall 437 | gb_free 13.2 | wall 16815
2022-03-23 23:35:23 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 23:35:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:38:31 | INFO | train_inner | epoch 035:     67 / 157 loss=2.288, ppl=4.89, wps=7500.5, ups=0.3, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.657, loss_scale=4, train_wall=277, gb_free=14.2, wall=17003
2022-03-23 23:42:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:42:42 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic hospital.
2022-03-23 23:42:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:42:48 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline from doha, which i think most know here.
2022-03-23 23:42:48 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:42:54 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to create two new gay transcribers.
2022-03-23 23:42:54 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:42:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and ppeffer.
2022-03-23 23:42:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:43:06 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-23 23:43:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:43:12 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife survival, the number of wildwildwildwildlife grew again, and this has become a foundation for conservation in namibia.
2022-03-23 23:43:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:43:18 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, they use their movements, and so the superconductor disorder.
2022-03-23 23:43:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:43:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that restores the big configurations of the face and the basic shape, and then it passes through the diethest piece structure and all the fits.
2022-03-23 23:43:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:43:30 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... tyes, when dinner was summarized, it's best summarized when someone said, "turn you to the men of your table and tell you," if the revolution starts to support you. "the truth is that we've already been supporting you for a long time."
2022-03-23 23:43:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:43:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work we're on our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variety of refrigeration and a refrigeration system with refrigeration that allows us to use a machine in the go-traffic until either propelled by propelled by propellers to a mechanism, or if you can see the ground, it's connected to a mechanism, it's all the same way, it's connected to the propelled to the propelled to the ground -- everything from a continuously variable system of a continuously variables us to a continuously variable system of a continuously variable device that we can use of carbon conditioning place that's going to the air conditioning place that's going to the air conditioning place that's going on the aircraft and refrigerator in the air conditioning place, to the
2022-03-23 23:43:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:43:32 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 2.499 | ppl 5.65 | bleu 31.42 | wps 3273.3 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 31.57
2022-03-23 23:43:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 23:43:32 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 23:43:32 | INFO | train | epoch 035 | loss 2.215 | ppl 4.64 | wps 8073.3 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.595 | loss_scale 4 | train_wall 433 | gb_free 12.9 | wall 17304
2022-03-23 23:43:33 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 23:43:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:43:59 | INFO | train_inner | epoch 036:     10 / 157 loss=2.188, ppl=4.56, wps=7595.1, ups=0.3, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.575, loss_scale=4, train_wall=272, gb_free=14.2, wall=17331
2022-03-23 23:48:36 | INFO | train_inner | epoch 036:    110 / 157 loss=2.158, ppl=4.46, wps=9130.8, ups=0.36, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.596, loss_scale=4, train_wall=277, gb_free=14.2, wall=17608
2022-03-23 23:50:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:50:49 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 23:50:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:50:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 23:50:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:51:01 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks signs that will be overwhelmed two new pigs.
2022-03-23 23:51:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:51:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salt and pepper.
2022-03-23 23:51:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:51:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on track.
2022-03-23 23:51:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:51:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife, the number of wildlife grew back. and that became a foundation for conservation in namibia.
2022-03-23 23:51:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:51:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are captured inside, but the superconductor doesn't like it, if you move, because your movements use energy, and so the superconduction.
2022-03-23 23:51:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:51:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that restores the big constraints of the face and the basic shape, and then we can pull it through the theft structure, which refers the entire porn structure and all the fits.
2022-03-23 23:51:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:51:37 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that -- tja, when constrict dinner was best summarized when someone said, "turn to men at your table, and tell them, 'when the revolution begins, we're going to support you.' the truth is that we've already started supported you," well, women, we've already started supporting you about a long time. "
2022-03-23 23:51:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:51:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane stumbling the toes, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variables, and a refrigeration system of refrigeration that allows us to use a portable aircraft in the gogo traffic and traffic, and you're going to be able to be able to be able to be able to be able to be able to be able to use, and you're going to be able to be able to be able to be able to be able to use it, and you're going to use it, and you're going to do it, you know, you know, and you're going to have it, and you're going to get it, and you're going to get it, you're going to get it, you know, and you know, and you're going to have it,
2022-03-23 23:51:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:51:40 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 2.485 | ppl 5.6 | bleu 31.55 | wps 3245 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 31.57
2022-03-23 23:51:40 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 23:51:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 23:51:40 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 23:51:40 | INFO | train | epoch 036 | loss 2.171 | ppl 4.5 | wps 8098.5 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.611 | loss_scale 4 | train_wall 431 | gb_free 13.4 | wall 17791
2022-03-23 23:51:40 | INFO | fairseq_cli.train | done training in 17791.0 seconds
